# Folge 286 - Transkription und Code für den Stream: LLMs - Süßes oder Saures?

## Zusammenfassung

Diese Folge behandelt die praktischen Erfahrungen mit dem Einsatz von Large Language Models (LLMs) in der Softwareentwicklung, speziell am Beispiel der Automatisierung von Podcast-Transkriptionen und der Webseite-Entwicklung für den Software-Architektur-Podcast.

### Hauptthemen

**Mehrwert durch KI-Enablement**
Die Diskussion beginnt mit der wichtigen Erkenntnis, dass KI nicht primär kosteneinsparend wirken muss, um wertvoll zu sein. Stattdessen geht es um das „Enablement" – die Möglichkeit, Dinge zu schaffen, die vorher nicht möglich waren. Im Fall der Podcast-Transkriptionen ermöglichte die KI die Bereitstellung von barrierefreiem Content für gehörlose Hörer, was ohne KI-Unterstützung nicht umsetzbar gewesen wäre.

**Praktische Implementierung von Automatisierung**
Der Host beschreibt die Automatisierung der Transkriptionspipeline mit GitHub Actions. Obwohl die KI bei der Codegeneration half, zeigte sich dabei auch eine fundamentale Limitation: Die KI konnte keinen konsistenten Überblick über den gesamten Code bewahren und scheiterte bei der Fehlersuche in komplexeren Szenarien.

**Der Rebound-Effekt**
Ein wichtiges Konzept ist der „Rebound-Effekt": Wenn etwas billiger oder einfacher wird, nutzt man es mehr. Durch die KI-gestützte Erstellung von Zusammenfassungen und Transkriptionen wurden diese Services überhaupt erst möglich gemacht, was zu erhöhter Produktivität führte – nicht zu Kosteneinsparungen.

**Grenzen der KI bei komplexeren Aufgaben**
Ein kritischer Moment offenbarte sich bei der Fehlersuche in GitHub Actions: Die KI konnte zwar oberflächlich den Code verändern, verstand aber nicht das eigentliche Problem (abgelaufenes Personal Access Token). Sie verlor das mentale Modell des Systems und versuchte stattdessen, fehlgeschlagene Symptome zu beheben.

**Mentales Modell nach Peter Naur**
Das Konzept des „mentalen Modells" nach Peter Naur (1985) ist zentral für das Verständnis der Limitationen: Entwickler bauen sich ein mentales Modell auf, um die Frage nach dem „Warum" im Code beantworten zu können. LLMs können dieses Modell nicht aufbauen, da sie nur Text generieren.

**Legacy-Modernisierung und Code-Überblick**
Ein faszinierendes Problem entsteht bei der Legacy-Modernisierung: Wenn Entwickler sagen, Code müsse neu geschrieben werden, liegt oft das fehlende „Warum" vor. Wenn die KI den Code in eine moderne Sprache umschreibt, bleibt die Frage offen, ob die KI das mentale Modell wirklich erfasst hat.

**Webseite-Architektur und KI-Integration**
Bei der Implementierung einer Gast-Suchfunktion für die Website zeigte sich ein Architekturfehler: Die KI generierte HTML/JavaScript-Code, der nicht zur bestehenden Jekyll-basierten Markdown-Architektur passte. Der Code war isoliert und wiederverwendete nicht die vorhandenen CSS- und JavaScript-Strukturen.

**Softwareentwicklung als sozialer Prozess**
Eine Kernaussage der Episode: Softwareentwicklung ist fundamental ein sozialer Prozess. Das mentale Modell eines Teams findet seinen Ausdruck im Code. Eine KI kann diesen sozialen Prozess und die damit verbundenen Entscheidungen nicht abbilden – das ist ein konzeptionelles Missverständnis der KI-Industrie über Softwareentwicklung.

---

## Wichtige Keytakeaways

- **KI als Enabler statt Kostensparer**: Der Wert von KI liegt nicht primär in Kosteneinsparungen, sondern in der Möglichkeit, neue Funktionen zu realisieren (z.B. barrierefreie Transkriptionen)

- **Begrenzte Fähigkeit bei Fehlersuche**: LLMs verlieren das mentale Modell bei komplexeren Problemen und beheben Symptome statt Root Causes

- **Rebound-Effekt in der Praxis**: Erhöhte Produktivität durch KI führt zu mehr Output, nicht zu weniger Arbeit

- **Mentales Modell ist zentral**: Nach Peter Naur (1985) können LLMs das für Softwareentwicklung notwendige mentale Modell nicht aufbauen

- **Dokumentation des „Warum"**: Cloud.md- und Agent.md-Files mit dem „Warum" von Entscheidungen helfen der KI besser zu werden

- **Architektur-Mismatches**: KI-generierter Code passt oft nicht zur bestehenden Architektur und Designkonventionen

- **Soziale Prozesse sind nicht automatisierbar**: Softwareentwicklung ist fundamental ein sozialer Prozess mit gemeinsamen mentalen Modellen im Team

- **Abstraktion bricht bei Problemen zusammen**: Wenn Fehler auftreten, muss ein Mensch eingreifen – KI kann die Abstraktionsebene nicht halten

- **Token-Limits und Kontextverlust**: Claude konnte sich einen 5-Schritte-Plan machen, aber nicht iterativ über 180 Episoden prozessieren

- **Non-Developer Einsatz fraglich**: Ohne technisches Verständnis können Fehler nicht behoben werden – die KI bringt nicht-technische Personen an ihre Grenzen

---

## Behandelte Kernfragen

- Wie kann KI praktisch in bestehende Entwicklungsprozesse integriert werden?

- Ist KI primär ein Kostensparungstool oder ein Enablement-Tool?

- Warum verlieren LLMs bei komplexen Fehlersuche-Szenarien den Überblick?

- Was ist das mentale Modell in der Softwareentwicklung und kann die KI es erfassen?

- Wie dokumentiert man das „Warum" von Code-Entscheidungen für die KI?

- Kann KI bei Legacy-Modernisierung das ursprüngliche Design-Verständnis bewahren?

- Wie integriert man KI-generierten Code sauberstark in bestehende Architekturen?

- Ist Softwareentwicklung automatisierbar oder bleibt sie fundamental ein sozialer Prozess?

- Welche Fehler entstehen durch fehlende Architektur-Konsistenz bei KI-Code-Generierung?

- Können nicht-technische Menschen KI effektiv für Softwareentwicklung einsetzen?

---

## Glossar wichtiger Begriffe

### Mentales Modell
Konzept von Peter Naur (1985): Das mentale Modell ist das tiefe Verständnis eines Entwicklers oder Teams über die Struktur, das Design und die Entscheidungsgründe eines Softwaresystems. Es ermöglicht, die Frage nach dem „Warum" beantworten zu können. LLMs können dieses Modell nicht aufbauen, da sie nur auf Textbasis arbeiten.

### Rebound-Effekt
Ökonomisches Konzept: Wenn etwas billiger oder einfacher wird, nutzt man es stärker und in mehr Kontexten. Im KI-Kontext bedeutet das: Wenn die KI Transkriptionen billig macht, werden mehr Transkriptionen produziert – nicht weniger Arbeit insgesamt.

### LLM (Large Language Model)
Ein großes Sprachmodell wie ChatGPT oder Claude, das auf Basis von Trainings-Daten Texte vorhersagt und generiert. Es verarbeitet nur Textinput und generiert Text-Output.

### GitHub Actions
CI/CD-System von GitHub zur Automatisierung von Workflows. Wird üblicherweise für automatisierte Tests, Builds und Deployments verwendet.

### Personal Access Token
Ein Sicherheits-Token in GitHub zur Authentifizierung von Operationen wie Git-Push-Befehlen oder API-Aufrufen. Erfordert bestimmte Berechtigungen und kann ablaufen.

### Jekyll
Ein statischer Site-Generator, der Markdown-Files in HTML konvertiert. Wird häufig mit GitHub-Pages verwendet für einfache Websites.

### GitHub-Pages
GitHub-Hosting-Service für statische Websites. Rendert Jekyll-basierte Projekte automatisch.

### CMS (Content Management System)
System zur Verwaltung von Content. Im Fall des Podcasts: Markdown-Files sind der Content, der dann durch Ruby-Skripte zu HTML gerendert wird.

### Cloud.md / Agent.md
Dokumentationsdateien im Repository-Root, die einem KI-Agenten wichtige Informationen über das Projekt bereitstellen: Technology-Stack, Datei-Struktur, Architektur-Entscheidungen.

### Root Cause vs. Symptom
Root Cause = die eigentliche Ursache eines Problems (z.B. abgelaufenes Token). Symptom = die beobachtete Fehlererscheinung (z.B. Permissions-Fehler). KI behält oft nur auf der Symptom-Ebene.

### Abstraktion / Abstraktionsebene
In der Softwareentwicklung: ein Konzept, das Details verbirgt, um mit komplexeren Konzepten zu arbeiten. Beispiel: Arbeiten auf der Ebene „verwende einen API-Call" vs. auf der Ebene „handle Authentication-Tokens". KI kann die Abstraktion nicht halten, wenn Fehler auftreten.

### Vielkonzeption
Fehlkonzeption; falsches Verständnis eines Konzepts. Hier: KI-Industrie versteht Softwareentwicklung als primär technisches Problem, nicht als sozialen Prozess.

### Barrierefreiheit / Barrierefreier Content
Design-Prinzip, dass digitale Inhalte für alle zugänglich sein sollten, z.B. Transkriptionen für gehörlose Menschen, Alt-Text für Bilder.

### Pipeline
Automatisierter Prozess mit mehreren Verarbeitungsschritten. Im Podcast-Fall: MP3 aufnehmen → Intro entfernen → Transkription → Review → Veröffentlichung.

### Iterieren
Wiederholtes Durchlaufen eines Prozesses mit Verbesserungen. Beispiel: Claude konnte über die ersten 4 Episoden iterieren, aber nicht über alle 180.

### Legacy Code / Legacy Modernisation
Ältere, möglicherweise veraltete Software, die schwer zu verstehen oder warten ist. Modernisierung bedeutet, den Code in moderne Technologien oder Patterns zu überführen.