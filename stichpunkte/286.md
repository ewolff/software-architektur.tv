# Folge 286 - LLMs - Süßes oder Saures?

## Wichtige Keytakeaways

- **KI-Enablement vs. Kostenersparnis**: KI sollte primär als Ermöglichungstechnologie verstanden werden, die neue Möglichkeiten schafft, nicht nur Kosten spart. Transkripte für gehörlose Nutzer wurden erst durch KI-Unterstützung wirtschaftlich machbar.

- **Mentale Modelle sind zentral**: LLMs können kein echtes mentales Modell eines Systems aufbauen. Sie verstehen das "Warum" hinter Designentscheidungen nicht, was bei komplexeren Problemen zu fehlerhaften Lösungen führt.

- **Softwareentwicklung ist ein sozialer Prozess**: Code ist der Ausdruck eines gemeinsamen mentalen Modells eines Teams. KI kann diesen sozialen Aspekt nicht abbilden und scheitert daher bei der Bewahrung von Systemarchitektur über Zeit.

- **Produktivitätsgewinne sind marginal**: Umfragen zeigen, dass 40% der Mastodon-Community sogar Produktivitätseinbußen erlebt, 50% maximal einen Faktor 1-2x Gewinn. Ein wirklicher Durchbruch ist nicht in Sicht.

- **Kontextabhängigkeit der KI-Leistung**: LLMs performen sehr unterschiedlich je nach Technologie-Stack (Python: ~90% Erfolgsrate, Java 21: ~50%). Sie funktionieren gut bei etablierten Patterns, scheitern bei Randfällen.

- **Architektur-bewusste Prompts sind essenziell**: KI-Systeme müssen explizit mit Architektur-Constraints gefüttert werden. Ohne diese orientieren sich LLMs an ihren impliziten Vorlieben (z.B. JavaScript), nicht an bestehenden System-Strukturen.

## Behandelte Kernfragen

1. **Wie kann KI Accessibility verbessern, ohne dabei wirtschaftlich unrentabel zu werden?**
   Die automatisierte Transkription ermöglichte es, gehörlosen Nutzern Zugang zu Inhalten zu geben, ohne manuelle Ressourcen zu binden. Dies zeigt einen echten Mehrwert trotz erhöhter Laufzeitkosten.

2. **Warum scheitern KI-generierte Code-Lösungen bei der Fehlerdiagnose?**
   LLMs können keine kohärentes mentales Modell eines Systems bewahren. Bei Permission-Problemen fummelten sie am Code herum, statt die eigentliche Ursache (abgelaufener Token) zu erkennen.

3. **Wie unterscheidet sich die KI-Nutzung bei Exploration vs. Implementierung?**
   KI eignet sich hervorragend für explorative Fragen ("Wie mache ich X?"), scheitert aber bei der eigenständigen Implementierung komplexer, zusammenhängender Systeme.

4. **Warum funktionierte die erste Guest-List-Implementierung nicht?**
   Die KI löste das Problem mit JavaScript in Markdown, arbeitete damit gegen Jekyll-Architektur und schuf ein nicht-wartbares System ohne CSS-Wiederverwendung oder funktionierende Links.

5. **Kann KI das "Warum" im Legacy-Code rekonstruieren?**
   Möglicherweise könnte KI helfen, verlorengegangene mentale Modelle durch Modernisierung zu rekonstruieren – dies könnte ein vielversprechender Use-Case sein, bedarf aber weiterer Forschung.

6. **Wie sollte man KI-Systeme mit Architektur-Constraints instruieren?**
   Explizite Dokumentation von Technology Stack, Constraints und Designentscheidungen (z.B. "Warum ist dieses Personal Access Token nötig?") könnte KI-Ausgaben erheblich verbessern.

## Glossar wichtiger Begriffe

**Mentales Modell (nach Peter Naur, 1985)**
Das innere Verständnis eines Entwicklers oder Teams über die Struktur, das Design und die Rationale eines Softwaresystems. Es beantwortet die Frage "Warum wurde diese Entscheidung getroffen?" und ermöglicht sinnvolle Erweiterungen ohne Brüche. LLMs können dieses Modell nicht bilden.

**Rebound-Effekt**
Ökonomisches Phänomen: Wenn eine Ressource billiger oder verfügbarer wird, wird sie intensiver genutzt statt Einsparungen zu erzielen. Im Kontext von KI: Da Transkripte und Zusammenfassungen leicht generierbar sind, entstehen neue Inhalte statt Kostenreduktion.

**Minimal Invasive Architektur**
Architektur-Pattern, bei dem neue Features so implementiert werden, dass bestehende System-Strukturen und Konventionen minimal gestört werden. Gegensatz zu "aufgepfropften" Lösungen, die parallel zu bestehenden Patterns existieren.

**Abstraktion-Schicht-Problem**
Situation, in der ein Problem auf hoher Abstraktionsebene gelöst werden kann, aber bei der Ausführung in niedrigeren Schichten (z.B. Security-Token-Management) unerwartet Fehler auftauchen. KI bleibt dann stecken und kann nicht in tiefere Schichten hinabsteigen.

**Jekyll Static Site Generator**
Ruby-basiertes System zur Generierung statischer Webseiten aus Markdown- und Template-Dateien. Funktioniert mit GitHub Pages, hat aber strikte Struktur-Konventionen (Include-Verzeichnis, etc.), gegen die naïve KI-Lösungen arbeiten können.

**Theory Building (Programming as Theory Building)**
Konzept (Naur, erweitert): Programmierung ist das Aufbauen einer Theorie über ein Problem-Domain durch ein Team. Der Code ist nur die Manifestation dieser Theorie. Wechsel von Entwicklern ohne Theory-Transfer führt zu Erhaltungsproblemen.