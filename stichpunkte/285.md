# Experiencing Generative AI mit Oliver Zeigermann

## Wichtige Keytakeaways
- Generative AI basiert auf großen Sprachmodellen (LLMs) mit Milliarden von Parametern
- Custom GPTs nutzen eine Kombination aus Vektordatenbanken und LLMs
- Die Kontrolle über die Ausgaben ist eine der größten Herausforderungen
- Durch RAG (Retrieval Augmented Generation) kann man die Halluzinationen reduzieren
- Die "Temperatur" bestimmt wie deterministisch vs. kreativ die Ausgaben sind
- Auch mit RAG gibt es keine 100%ige Garantie für korrekte Antworten

## Behandelte Kernfragen
- Wie funktioniert ein Custom GPT technisch?
- Wie unterscheidet sich die Funktionsweise von ChatGPT von Custom GPTs?
- Wie kann man die Qualität der Antworten verbessern?
- Was ist die Bedeutung der "Temperatur" bei LLMs?
- Wie werden LLMs trainiert?
- Wie kann man Halluzinationen reduzieren?

## Glossar wichtiger Begriffe
- LLM (Large Language Model): Großes Sprachmodell mit Milliarden von Parametern
- Embedding: Umwandlung von Text in mathematische Vektoren
- RAG (Retrieval Augmented Generation): Technik zur Verbesserung von Antworten durch Hinzufügen von Kontext
- Vektordatenbank: Speichert Texte als mathematische Vektoren für Ähnlichkeitssuche
- Chunking: Aufteilung von Dokumenten in kleinere Abschnitte
- Temperatur: Parameter der die Zufälligkeit/Kreativität der Ausgabe steuert
- Instruction Tuning: Nachtraining eines LLMs auf Frage-Antwort Format