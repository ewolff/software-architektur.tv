{
  "text": "I have one more note. There is this training, Domain-Driven Design, Saniert Legacy, that is one afternoon on the 16th and 12th, about Socratory. It is not particularly expensive, if you are interested in this topic of Domain-Driven Design, especially the handling of legacy. This is an opportunity to actually experience something very practical with me again. So we do practical exercises and not only talk about it, but also do it. And that is, I think, a good addition to what we see here. Because, as I said, here we don't see how to deal with legacy. Well, the first thing I actually want to talk about is the topic of tactical design. That's also a bit of a breaking point for the last time. So we talked very roughly about the whole thing last time. So how do I divide a system into building contexts? How do I somehow build? What responsibilities do teams have? And so on and so forth. And this is a completely different level here now. This is actually the level of classes. And why tactical design now? So tactical design are object-oriented concepts. And it makes a lot of sense to me to build good object-oriented systems. Tactical design is exactly what helps. We can go through the patterns now. The first pattern is an entity. That's something that has an identity. So a person has an identity. That means, if I give the Eberhard Wolf again, there is now a completely identical copy, which looks like me, who lives there, where I live and is not so much identical. That's still another person. I can somehow distinguish them. And that means that things actually have an identity here. A person has an identity. A product has an identity. Such stories. And something like value objects, i.e. a value such as 2 euros or 2 meters. 2 meters are just 2 meters. And it doesn't really matter if these 2 euros are 2 euros. So these are actually things that only differ in value. Then there are domain events. These are things that are relevant to domain experts. So something has happened in the past. We talked about this last time. This is also something that plays a role in event storming, for example. These are things that I can implement as classes. Maybe two more general things. The one general note is that what we see here is that we have a fundamental dependency from top to bottom. That is, these are actually basic things that depend on nothing else. And the other thing is, we're talking about a real object-oriented concept. That means the things we see here have logic. So if I say, for example, I have 2 euros. I can somehow sum amounts of money. And I can try to round them. And whatever else I can do. These are things that I will model in this value object, for example. So these are things that actually contain logic. So, based on that, there are these aggregates on the next layer. They are made up of several different things. That's why they're a little higher. So that means there are entities and value objects that are summarized in aggregates. And there is an aggregate root that is now responsible for ensuring consistency there. That means, for example, if I have an order and I add something to this order that I would like to order. Then this is added to one and the other ensures that the total amount of the order is adjusted accordingly. Then the thing is consistent in itself. And the aggregate root ensures that this change takes place automatically. Which means that consistency conditions are implemented synchronously within aggregates. Not necessarily synchronously across aggregates. And I can also use aggregates to replicate them in the network. Then I also have eventual consistency. That means that all aggregates will eventually become consistent. This is interesting because a transfer, for example, changes two accounts. Now you might think, I want to have that consistent. And what Domain Driven Design says is, no, the account itself is consistent. So on the one hand, the amount would be correct. I have â‚¬ 240 after the transfer. And on the other hand, the transfer is actually booked or nothing from both. But the accounts can be inconsistent. Which, by the way, is exactly what reality looks like. If I now transfer money, it is somewhere between these two accounts for some time. So the money has been lost for some time. At least that's what I assume. So that's what plays a role here. What this also means is that in contexts that are roughly granular, not total consistency in itself, but aggregate consistency. This consists of entities. So my individual bookings would be, for example, some entities. And value objects, the account balance, for example, would be such a value object. Then I have repositories. They give me the illusion of a collection of aggregates, which is apparently stored in the memory, but is actually in the database. This is also a conceptual thing. And what I find particularly exciting is that repositories also implement the right questions. That means a repository will not say, I'll give you access to any objects, but the repository will say, okay, I now have the option of finding an account number, maybe also according to the name of the account holder and the date of birth, but not based on the account balance, because that somehow doesn't make any sense in terms of subject matter. And that would mean that the repository only exposes the subject matter of queries. Which I think is a very interesting design concept, because something like GraphQL, for example, says I can ask any questions. Repository says that doesn't really make any sense. We just want the subject matter-correct requirements to be able to ask questions. Then there are factories. Factories generate complex value objects or aggregates. Very similar to for patterns. I don't think you need to say much about it. If a constructor is not enough, I use a factory. And then there are services. Services are the things where I can't use business logic in a sense in an aggregate or entities. So there is business logic that is interdependent over different aggregates. So the transfer, for example, is something where I have two aggregates. So now I can't assign the two accounts to an account. So I'm probably going to build that into a service. And that makes it clear how it works. I say I have some logic. I'm going to put it in one of these classes. And it's not like entities, for example, should be logic-free. So now the question is, it's something that goes through this talk. I think it's always important to name alternatives. So we now have tactical domain-driven design. And now the question is, can I not implement tactical domain-driven design? And one way to do that is to make it functional. Then I have a side-effect-free functional core. That means I don't have entities, I don't have aggregates. When I change an entity, it has a side effect. The thing has a state. The account has an account state, for example. And that means this state changes. This is obviously a side effect or an effect. And with functional programming, I can't have that. That means, with functional programming, I would have a core that says, okay, I'm calculating the new account state from a set of interest. But then it's the job of the system all around to ensure that this side effect is generated, that this information is actually stored. So I would have a core that says, okay, this is the new account state. And then I would have something around this core that ensures that it is actually stored in the database. I talked about this topic with Mike Sperber some time ago. In fact, that was more than a year ago. So we discussed what a functional architecture should look like. Mike is someone who has dealt with it a lot. We looked at the ISRQB example task. So you can talk about this topic in detail. What other alternatives are there when I have less complex systems? So the premise for this set of patterns is, I have complex business logic. And if I have a system that copies data from A to B and I'm building a repository and aggregates and entities and value objects and so on, then the question is whether that's really smart. Because I invest a lot of effort in building these things. But the advantage that I have object-oriented possibilities to structure my logic, I don't have that much of that, because I don't have any logic. And for that there is an alternative, something like a transaction script. So a transaction script says, I process a request from the presentation layer directly and have a database code in there. So that means I have an HTTP request that comes into my system and then I say, insert into my great database table some value. And something similar is a table model, where I say, there is an object that represents a database table. And that has the advantage that I don't have all these layers. And I can relatively easily say, okay, if that comes from the HTTP layer, then I change exactly that in the database. And I see that at a glance. Of course, that goes massively wrong if I have complex logic there, because I would have to rub it in somehow. And that doesn't make much sense. Here, for example, I also have the advantage that I can now optimize the database requests, for example. I can now build in hand-optimized queries and construct some great things there without having to go to a lot of effort. Let's go through the example. The example we had was an e-commerce system. That means we would now take one of these building contexts out. I have now taken out the building context with the delivery. So that's the thing that says, okay, I want to send the clicker. How do I actually send this clicker? Or if I have something cheap, the iPhone, that's even more expensive. I might want to send that to the insurance company again, and so on and so on. And that's what I want to decide here now. That means I have some logic and start now and say, okay, I have an entity here, so I have a package. I have an address, that's a value object. So you can see it from Utrechtstrasse, where the Swaglab GmbH is located. That's a value, that's not an identity in this case. And I have that together in such a delivery. So that means in this delivery it says, this package goes to this address. Maybe there's some information in there like, what goods are actually in the respective package? That's how I assume it now, to build complicated, that I need a factory for that. And I also have such a delivery repository, where I can now say, give me a package for this customer. So that would be something that I might be able to motivate in question, that I would like to have in this car. That would be something that I might be able to motivate in question, and so on and so on. Alexander is writing, I'm a big fan of DDD, and I think it's way too little that people talk about, where you shouldn't use DDD. Good that it was mentioned here. Exactly, thank you very much. Another actual gap that I can have now is, for example, a customer. And I would have some information there now. Maybe he sent me a set of addresses, multiple things, or whatever. But then I would have a service here that says, okay, I'm just scheduling a delivery. So I say, for this customer, I would like to have this delivery somehow. And that means, this thing then ensures that these deliveries may arise, needs access to the customer. So now I can hardly give it to the customer or the delivery. The delivery would have things like, tell me what your value is, tell me if you're insured, things like that. And this general logic would now be in such a service. And I still have such an event here. The delivery has somehow been scheduled. That means, I have now said, this and that should be delivered then and then. And now anyone can react to that, if this person feels like it. I had a whole episode about it, where I discussed it again. It's actually from this year. And I'm actually talking about all these concepts for an hour. And I'll go into more detail about it. The question is how I implement that. And in a way, what we're discussing here is plain old Java objects. So that's actually just an object-oriented construct to somehow divide up logic. And that's why that could be enough. What that means is, I don't have any special technical requirements here. So I might still want to save entities. That means, I might have something like that, that I want to have a persistence solution. Maybe there's a persistence solution in the repositories, that actually implements that. But essentially, I just have an object-oriented system here. And there's something like xMolecules, which supports the concepts directly for different programming languages. And that's what the good Oliver Rothbohm described in a blog post. And that's what we talked about. That means, I can now build such a system with something like jMolecules. And it's also about dependencies, for example. So I would like to be able to use aggregates in a service, but aggregates shouldn't use services. That means, there are relationships that result quite directly from these patterns. And that means that I actually have these dependencies, like, for example, that services are allowed to use aggregates. And I can use such architecture management tools. So the architecture management tools, I've actually had several episodes about that. Incidentally, I also link all of this in the show notes. These are tools with which I can somehow say, okay, services are allowed to access aggregates, aggregates are allowed to access entities and value objects, and so on. And then these dependencies are implemented, so to speak. That means, I have a checker that runs over it and says, no, you can't do that. And there are very different tools. So there is something like Structure 101 or such a graph that somehow shows it more graphically, which I can also get into the image process. There is, for example, something like ArcUnit, where I have it as part of the unit test. And as I said, there is a big selection and you can look at all these tools, so to speak. So, in that context, I would like to talk again about the topic of design-level event storming. We talked about big-picture event storming in the last session. And big-picture event storming is ultimately something that I have domain events. I have domain events and I write down these domain events somehow and get information about how my domain works. And I can use that, for example, to identify building contexts. That means, I have such stories there, typically, like, I made an order, the thing is now delivered to me, things like that. Then I can somehow say certain functionalities, so the delivery and the accounting writing is perhaps in different building contexts. We talked about this last time. So, Jude Rude writes, which objects should not be immutable and thus have no logic? Exactly, they represent value and values are immutable. Two euros are just two euros. I can't say two euros are suddenly two euros and 10 cents, but that's just a value. Which means, for example, if I have the value of my order, and the old value object is still there. In other words, they are unchangeable. They have value semantics. And also... How should I put it? Things like comparisons are also a topic. If I compare meters or compare money amounts, maybe that's something I have in there as logic. So they also have logic. That's exactly the idea. Christian Trutz writes, for example, do you use Spring Modulus to structure packages? Exactly, that's what you can use, for example, to structure a system on this package level. Exactly. Good. I think we're done with that topic. I'll take a quick look to see if anything else comes in here. Otherwise I would actually continue with this design-level event storming. When it comes to design-level event storming, it's important to face what it's really about. I would like to understand how the business logic is. And I want to understand that in this big-picture event storming, which we discussed last time, roughly granular. And here I would like to understand it finely granular. So that means I have, for example, a read model. And a read model is something where I can now, for example, paste in a UI and say, okay, it just shows something. Then I have some actors, so people who do something and, for example, can issue a command. And either through an external system or through my own system, then some events arise. So I could say, for example, yes, I'm a customer, so I'm an actor here. I give the command, I would like to have it now. So I would like to submit this order. That goes to my system. Event, which somehow comes out, is order accepted. And then it could be that I have generated an order from it, which I can then display to myself. And here might be a policy that says, the next command is being created. So that's an automatism. That means, if the order has been accepted, I can have a policy that now says, okay, all right. Then I will now somehow, please write an invoice and make sure that the thing is delivered. So that's the idea. And that's how I get into a granular model. So I would have in the Big Picture Event Storming, which we discussed last time, I would only have this here, so the domain events. Here I have a lot of additional information that gives me a deeper, better understanding of what is actually happening. And I'll remind you again that this is something that we now want to create together with domain experts. And the goal is, so the domain is now at this detail level, that I need for a tactical domain-driven design, that I understand that on this level. And there is now no, so I would say, obviously there is no trivial mapping to tactical domain-driven design. In other words, what we see here now is a completely different field of view. So we're talking about systems, we're talking about read models, we're talking about UI. These are all things that don't occur in this tactical domain-driven design. That's why it might be very exciting to see how I'm actually mapping this now. And I would expect a command in tactical domain-driven design is a method call on an aggregate or on a service. So if I say now, I would like to order this, then I would expect there is a method somewhere or maybe several methods. Yes, I would even say one method. It would say, okay, I'll order this whole thing for you now. And in that case, it's probably in a service, because I have to make an order in the context of it and have to create various other things. But it could also be in an aggregate for simple cases. So then I have the system, that would be my aggregate or my service, when I see the fine granular. Now a domain event comes out of it. I could implement that directly as a domain event also in tactical domain-driven design. So that's something where this terminology is actually identical. Then I have a read model, and that's ultimately an aggregate again. That means the thing where I call the command here and the thing that I'm showing here can be the same object from my point of view. In one case, I use the reading stories and in the other case, the writing stories. I think it's a good practice to separate the methods that change state from the methods that give me information about the state. So I either have methods that say, I'll tell you something about the delivery, what's in there, about products or something. Or I have methods that make sure that something happens with this delivery. And this read model would then be part of the aggregate that actually gives this information about this state. We'll talk about things like CQS in a moment. We would actually separate the read model now and say, these are different classes, maybe even a different microservice. That's an option. I personally don't think it's necessary. And here you can see exactly one of the possibilities I have now. So I can sit down as an architect and say, okay, we have a relatively simple case. We just pack the commands and the read model together. Or I can say, for whatever reason, it's complicated and I want to separate that. Maybe I want to scale the class. Whatever. Then I'll do CQS. But that's not mandatory. I just want to understand what people want here. And for that, it might be quite interesting to see what I actually want to read here. And I get exactly this information from the design level events topic. The policy would now also be something where a domain event is reacted to. So some business logic that ensures that, for example, this invoice is written. That's something that might happen again in an aggregate or in a service. Where business logic is typically. And that's actually where I'm through with the topic so far. And can continue with the next topic. This is this story with the event sourcing. Let's see that I have the next table. Exactly, here it is. Here is a little bit. We still have about half time. Here is a little bit now. How should I say? This is another topic. Event sourcing and CQS are somehow possibilities how I just implement certain things. And they are independent of tactical domain design. I think I'll say again in a moment how I rate this topic as a whole. So whether it's mandatory or whatever. And event sourcing means that the events that have led to a certain state I also save. I can also save the state itself. Obviously I don't necessarily have to. Because I can emit this state from the events. And I can now as a system of record. So the system that should actually be the reliable one. I can either say that's the state or the events. That's up to me. So that means what I can do now. For example with an order. I have an event store here. And I have the state here. And now I have an interface here. And some calls, some messages are pressed on me. So I'm talking about a system which is dealing with to do something with orders. And here comes in a call which says this order 42 which should be delivered now. That means I notice in the event store that this order 42 should actually be delivered and is accepted. And then I have the state here which now somehow says the order 42 exists. Then comes the next call which somehow says okay, order 23 is somehow there. And then I have here as a state also the order 23. Then I say next the order 42 is cancelled. That's an event again. I notice that again in the state. And then I say the other is somehow delivered. And I notice that again in the state. So that means I have a system here which saves the state and also the events which led to this state. When ordering I'm not sure whether this is really necessary. With an account I'm relatively sure that this is really necessary. Because I'm not only interested how much money I have on my account right now but also whether the last transfers have entered me. And that leads to that we can distinguish systems here. So we have systems which only save the state. So I could now have a system which says hey, the order 42 is delivered to me, period. And I could calculate the state on the fly. I could, for example, determine the account state from the transfers and transactions that have occurred so far. Or I can save the account state and also the events that led to it. And when I save these events then it is event sourcing. There is one more note which is important to me. This is actually a persistence strategy. That means the question is how do I save my account or my order. And I can now say I save the state and also the events that led to it. A persistence strategy should be internal. That means whoever is responsible for something like accounts or whatever I have there should choose whether to do event sourcing or not. This means in particular that it should not be the case that the externally observable events lead to me having my local state. And there is actually in the show notes there is a video where I said when I save all events in Kafka and then somehow say okay, I can somehow use the local state of the microservices from these central events in Kafka for communication. I can reconstruct this state of the microservices. Then I actually have a database monolith. The microservices do not have independent data models, but they only have a cache for what is in Kafka. I can somehow remove their database. Then they say, no problem, I read all the events again. I have reconstructed the site. And that can not, that must lead to that I somehow have a high dependency there. And that's something I actually like to avoid. That's why I find it difficult. I'll link the video again. And there is another story. I have to get the article out again. Christian Stettler wrote an article about it that these internal events are possibly fine granular. Than what I want to announce externally. If I say now, I am responsible for that I register a customer. Then I have stories like, hey, your email address was not valid. Hey, your ID check did not work. And these are all things that do not interest me externally. I just want to say this person is now validated. And that's why it does. And there's the story again. The internal events are different than the external events. That's why I want to separate that. So what does that mean now? Can I do something like a ... So I have such a delivery. The delivery is scheduled. The delivery is accepted. Has been taken out of the warehouse. Has been packed into a truck. Has been delivered. And the customer said, I got it too. Now the question is, can I model this delivery or such an event store at all? Probably not. Because that's exactly what interests me. So I'm interested in who did what with it. Because then I can say later, okay, you said it arrived. Or that it was in your truck. Where did that come from? On the contrary, it's just that I'm not sure about this delivery. Whether I actually want to calculate the state of the delivery. So what do I get out of it if I don't save the state? So I would write in here next to the event store, yes, this delivery has arrived and the customer said, everything is fine. So I have a state that says, is successfully completed. And then I can, on the other hand, if someone is interested in how it came about, somehow pull out these events and can display them. That means this ... So that's a technical discussion. Actually, I say, that's the way I want to model something in a professional way. And that's something where I don't want to reconstruct the state, which is often sold as an advantage from the events. CQRS, that's the other approach. This is this command query responsibility separation, where I somehow separate reading and writing. And that would work now so that I have a command queue. So there are some commands, I don't generate an invoice, for example, but I have a command handler, which, for example, may ensure that when an invoice is generated, it is immediately paid. Then there is a database, where the invoices are stored, for example. And then there is a query handler and it is somehow separated. And there I can now, for example, read invoices. And the commands I may now still have in the command store. And that would be my model now. And now I would actually have this read model here. That would be what the query handler would use. And here I would have the model where I actually change things or this part, which is not the system, which takes commands from the design level event storming. So, if I build it that way, it means that the model for writing here through the commands and that of the queries is actually the same, because this is a common database. Do I have anything of it at all? Yes, I have something of it, because this query handler, for example, can use a read replica. So I can now somehow say, okay, I'll build the system as it says here. I now have the query handler. The query handler uses a read replica of the database. And I can read about it more scalably. I think that's a bit of an advantage that is essentially created here. These two parts are, for example, independently scalable. I can now execute the command handler and the query handler in two different microservices. And that also leads to that, how should I say, I'm not so sure about this pattern, how often I would actually want to use it. Because it only makes sense if I have something, or for scaling at least, it only makes sense if I somehow say, okay, I want to scale this query handler area independently of writing. And I think I have to come to significant scaling heights so that I have a profit there. I can do something else. I can say, the query handler has a snapshot and I build this snapshot through event sourcing stories together. So that would mean that I have these commands here. Something is built on logic here. So I say, for example, that the payment takes place. And then I have an event sourcing to the database for the snapshot. And there I would now somehow every time a calculation is created, a new entry is made into this database. That is decoupled even more. And that could be useful, for example, for something like statistics. So for statistics, I might really want to have a separate reading model. I also want to have other information, somehow rather sums. And that's something where I might really want to build such a CQS thing. So I have the data, so to speak, which is motion data. And then I have the data for the statistics. And that would probably mean that statistics are perhaps even a different context with a completely different data model. So maybe I have to model statistics and I have a reading model, because I can only write and create an invoice once and then I can only read it. That's actually technically correct. So I can't say, oops, I got lost in this invoice, let me change it for a moment, but I have to say, I got lost in the invoice, let me storm the invoice, I'll write a new one. That's a model that somehow says, okay, not allow queries, are just separated, work on the read replica. And I have the other thing that somehow generates this invoice. Maybe it's not bad at all to implement this policy strictly. Maybe it's not so bad from a technical point of view. Typhonix writes, the wording snapshot is actually something else in the event sourcing context, so that the data is saved in between when storing. Actually, projections are meant, right? Yes, it may well be that I got lost in the naming. Good point, thank you for the hint. So exactly, snapshot may actually refer to an aggregate. Good point. I also made a whole episode on this topic. I'll discuss the topic in more depth. You can take a look at it. And with that we come to this topic, where there was already interest last time. And I planned a little faster, so to speak. And that's the story with the layers. First of all, the hint is that this is actually a pattern from the original blue Domain Driven Design book. So there is layering as a pattern in this blue Domain Driven Design book. And that means that I have the UI, the logic and the persistence. And such layers always have dependencies from top to bottom. That means, I say the UI uses the logic, the logic uses the persistence. And that's exactly the story with the layering. For me, the prototypical model for a layering is actually something like this network stack, where I have a physical layer at the bottom, i.e. Ethernet or Wi-Fi. Then I have IP over it, then I have TCP over it and then some protocols like FTP or HTTP. And that's exactly such a layering. So HTTP uses TCP or UDP by now. TCP and UDP use IP. IP then uses what I'm using right now, Ethernet or Wi-Fi. And there is only the dependency in this direction. I mention this because I think this layering often makes sense from a technical perspective. But here we are talking about how we structure expertise. And now the question is to me, with network layering, for example, because I have this physical layer, I can now switch from Ethernet to Wi-Fi relatively trivially or from Wi-Fi to mobile communication. This is exactly hidden above that. So that means I can exchange this lower layer exactly and the rest of the system remains untouched. Here I would argue that this is not really a good reason, because I will probably rarely exchange the persistence. So the question is to me why this pattern is there after all. And what Eric said to me is, well, I separate the logic and have them in exactly one place. And that's how I build the system so that it's easy to understand. And in fact, it's like that. Domain Design doesn't say anything about the UI. So what Domain Design says is, OK, we have services, we have aggregates, such things. That we have a UI that uses it is somehow clear. But we don't say how it should be structured. There are also possibilities to structure something like that. And with the persistence, well, there is a repository as a pattern. But that doesn't say that much about how you want to implement it exactly. We just saw this transaction script, for example. There are definitely other possibilities. And that means that the core of this pattern only says, we have separated the logic. The logic is actually the area where Domain Design says a lot about it. Entity, aggregates and so on. These are all things that are somehow in this logic layer. And we separate that from the persistence, so that I don't, when I think about the logic and look at what's going on there, somehow get annoyed by SQL statements that have nothing to do with it. Or JPA stories that have nothing to do with it. But I have that somewhere else. And analogously, I also separated the UI from it. And on this abstraction layer, or on this abstraction level, hexagonal architecture is actually a solution to the same problem. In other words, Eric could have said in his book, we're not talking about layers, we're talking about hexagonal. That he didn't do that is because Domain Driven Design, if I'm not mistaken, is a bit older than hexagonal architecture. In other words, back then it was somehow this three-layer architecture with UI, logic and persistence that was typically done. So what's different about hexagonal architecture now? Clean Architecture is very similar, for example. I say the business logic exports some ports. So I have the business logic. It now has a port here, for example, to send out notifications. And then I have adapters that implement these ports. So I have an email adapter, for example. So that means I say here in the business logic, I have a notification interface. And the email adapter can now implement it. And here, for example, are some business events that I now output to the UI. Here's an admin thing that I output to the admin UI. And here's the persistence. And I have a database adapter that implements this persistence. So what I've achieved is that in all cases, the dependency from the outside, from the database adapter, for example, to persistence, it implements what the persistence would like to have here. Or here from the admin UI to admin. Or from the email adapter to notification. And that's not the case with layering. With layering, the logic uses the persistence. So that means logic depends on persistence. Everything depends on the logic here, including the implementation of the persistence of the database adapter. For me, this is relatively similar to this dependency inversion principle, where I say if I use something, well, then I can also define the interface here somehow. And then the dependency is exactly the other way around. So the business logic uses the database adapter, but it's not software-dependent, but it gives it the interface that the database adapter has to implement. So that means database adapter implements persistence port. As a result, the dependency is from outside, from these adapters to the ports. And that leads, for example, so first of all, I achieve the same goal as de-layering. So what Eric says is, I would like to separate the logic from something else. I can do that here too. Maybe even a little bit better, because I don't have this dependency into persistence. And I also have the advantage that I can test the stuff better, because the business logic core is free of any kind of technology. So that means if I have the layering, then it is in the logic that I actually somehow depend on the persistence. Maybe I have to catch some exceptions that the persistence throws. Here it is so that the database adapter is dependent on the business logic. It defines what to expect, so to speak, and what the interface should look like. And then the database adapter will implement that. So that means the persistence doesn't know anything about it. The business logic doesn't know anything about what exactly is happening here. And that leads to better testability, because I can now replace the database adapter and all other adapters with something in the test. So I can now say to myself, there is something that behaves like a database, or I can have something that, for example, asks for the notifications, which would otherwise go out as e-mails. That means I can test in isolation with the business logic core. And I think that's also a significant advantage. I just did an episode with Warren Vernon. Warren also wrote the book Domain Driven Design Compact. And actually I had expected, we're not talking about domain driven design, but he talked a lot about ports and adapters, or hexagonal architecture. And one thing that I think was totally exciting was that Warren basically said, well, is it really that much more complicated to build a hexagonal architecture? And that's actually a good point. So layering says, I separated these three things. And hexagonal architecture says, I isolated UI, logic and persistence. And hexagonal architecture now says, I isolated these three things. And the persistence depends on the logic. So if I'm here at layering, it would be that the logic uses the persistence and is dependent on it. Here it is exactly the other way around. Here I say, the logic does not know the persistence, but on the contrary, the database adapter implements this interface that the core of logic provides. In terms of the UI, it is identical anyway, because the UI uses the logic. Here, from top to bottom, the dependencies, that's the same here. So that means the UI comes now somehow and uses this port here. That means the dependency file is the same. So the only thing that actually changes is this other dependency file on the database adapter. And relatively stupidly, I can achieve that by somehow defining these interfaces in the business logic. And yes, I have to make sure that it is technology-independent. But that's what it is. So that means, actually, it's a point, if I separate that, then the big effort is no longer such a big difference in terms of effort between hexagonal architecture and layering. And I thought that was a very exciting idea, because hexagonal architecture has a bit of a reputation for being complicated. And I think that's exactly this input that's interesting to me. And as I said, the alternative to that is something like a transaction script, where I don't do this layering, where I no longer isolate the business logic that much, simply because there is too little of it or none at all. So I should maybe add one more thing. If I am forced to build a system as a developer that has no business logic, that means that I don't generate a lot of value either, I would say. And it may be that I actually build a system that doesn't really solve the business logic problem. So the customer comes and says, I would like to see the following data. Okay, is that business logic? No, I just want to display the data. But that's probably not what this person really wants. What she really wants is, she wants to decide now, when I look at the customer, I can decide whether it's a good or a bad customer. But then it's actually the case that there is a business logic behind it, which I can now try to implement. So I can now say, hey, according to our policy, this is a good customer, because he ordered a lot of things and returned little. And that means, if I build a system that only transports data from A to B or only displays data, this may be a misleading chance to build a system with more business logic. That means, this topic with the transaction script is the right solution, if I have little logic. But be careful, maybe it's just that the logic has been hidden from me, so to speak. In summary, I tried to paint this again. And to get an overview of all the things, from left to right, there are more and more details. And that was something I said last time. So the idea here is not that this is a waterfall, where I walk through once, but I work on different details. And the rough granule that I have is Big Picture Event Storming. I get an overview of the entire system, the events that run here. And I can then decide about it, for example, or a next step would be to say, what is my core domain? So what is it all about? I can use strategic design as an alternative to team topologies. I say which teams are responsible and who does what where. That's something... I don't know if it's more detailed. So here I'm actually talking about the business logic of Big Picture Event Storming. And here I say, for something like strategic design or team topologies or core domain, I actually say how I want to divide it on the level of teams. And they then work on one or more built-in contexts. And then there are these very specific techniques that we talked about, so tactical design, to actually implement a built-in context and to say how it is implemented. Design level event storming, to understand what the requirements are on this level. I can use something like event sourcing or CQRS, if I have the necessary prerequisites for it, in the sense that I generate an advantage if I store the events in the case of event sourcing, or in the case of CQRS, if I can actually separate the writing and the reading part from each other. And then there are layers or hexagonal architecture. I have now also put a question mark behind it. With event sourcing and CQRS, I would somehow say, okay, I'll use that when it fits, so to speak. With layers or hexagonal, I would say one of the two patterns I should somehow apply, because otherwise I would have mixed up the logic and the other things. Jude Ruth writes, Jude Ruth writes, additionally, warns of the naming of ports and adapters instead of hexagonal architecture. Good point, I don't remember that at all. And in fact, this is perhaps also a point that is a bit unfortunate here. So the hexagonal architecture is called hexagonal because the business logic core and the things around it, so to speak, are randomly painted as hexagons. And it is actually the case that ports and adapters are the better term, because I think that expresses better what it is actually about, namely to expose these ports from the business logic core and then to have adapters around it, which somehow implement that accordingly. Good. Then I think we're actually ready. A note, next week, as I said, there is this training round on the topic Domain-Driven Design Salutes Legacy. That's on the afternoon of the 16th and 12th. You are welcome to join. I think it's also reasonably moderate and it's a good opportunity to talk about how to build Legacy with DDD. The other thing is, next week, Ralf will talk to Lars RÃ¶wekamp about the topic Generative AI meets Software Architecture. And that will be at 3 p.m. So Friday at 3 p.m. That's a little later than usual. And maybe you want to switch on again. Otherwise, thank you very much for your attention. And thank you very much for the questions and for the comments. And then I would say, I wish you a pleasant and nice weekend. Until then. Thank you very much.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 5.28000020980835,
      "text": " I have one more note. There is this training, Domain-Driven Design, Saniert Legacy,",
      "tokens": [
        50364,
        286,
        362,
        472,
        544,
        3637,
        13,
        821,
        307,
        341,
        3097,
        11,
        16674,
        491,
        12,
        35,
        470,
        553,
        12748,
        11,
        5271,
        4859,
        42838,
        11,
        50628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5888501405715942,
      "compression_ratio": 1.6156716346740723,
      "no_speech_prob": 0.6193607449531555
    },
    {
      "id": 1,
      "seek": 0,
      "start": 5.28000020980835,
      "end": 8.319999694824219,
      "text": " that is one afternoon on the 16th and 12th, about Socratory.",
      "tokens": [
        50628,
        300,
        307,
        472,
        6499,
        322,
        264,
        3165,
        392,
        293,
        2272,
        392,
        11,
        466,
        407,
        10757,
        1639,
        88,
        13,
        50780
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5888501405715942,
      "compression_ratio": 1.6156716346740723,
      "no_speech_prob": 0.6193607449531555
    },
    {
      "id": 2,
      "seek": 0,
      "start": 8.319999694824219,
      "end": 13.5600004196167,
      "text": " It is not particularly expensive, if you are interested in this topic of Domain-Driven Design,",
      "tokens": [
        50780,
        467,
        307,
        406,
        4098,
        5124,
        11,
        498,
        291,
        366,
        3102,
        294,
        341,
        4829,
        295,
        16674,
        491,
        12,
        35,
        470,
        553,
        12748,
        11,
        51042
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5888501405715942,
      "compression_ratio": 1.6156716346740723,
      "no_speech_prob": 0.6193607449531555
    },
    {
      "id": 3,
      "seek": 0,
      "start": 13.5600004196167,
      "end": 15.199999809265137,
      "text": " especially the handling of legacy.",
      "tokens": [
        51042,
        2318,
        264,
        13175,
        295,
        11711,
        13,
        51124
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5888501405715942,
      "compression_ratio": 1.6156716346740723,
      "no_speech_prob": 0.6193607449531555
    },
    {
      "id": 4,
      "seek": 0,
      "start": 15.199999809265137,
      "end": 21.799999237060547,
      "text": " This is an opportunity to actually experience something very practical with me again.",
      "tokens": [
        51124,
        639,
        307,
        364,
        2650,
        281,
        767,
        1752,
        746,
        588,
        8496,
        365,
        385,
        797,
        13,
        51454
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5888501405715942,
      "compression_ratio": 1.6156716346740723,
      "no_speech_prob": 0.6193607449531555
    },
    {
      "id": 5,
      "seek": 0,
      "start": 21.799999237060547,
      "end": 27.15999984741211,
      "text": " So we do practical exercises and not only talk about it, but also do it.",
      "tokens": [
        51454,
        407,
        321,
        360,
        8496,
        11900,
        293,
        406,
        787,
        751,
        466,
        309,
        11,
        457,
        611,
        360,
        309,
        13,
        51722
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5888501405715942,
      "compression_ratio": 1.6156716346740723,
      "no_speech_prob": 0.6193607449531555
    },
    {
      "id": 6,
      "seek": 2716,
      "start": 27.68000030517578,
      "end": 35.20000076293945,
      "text": " And that is, I think, a good addition to what we see here.",
      "tokens": [
        50390,
        400,
        300,
        307,
        11,
        286,
        519,
        11,
        257,
        665,
        4500,
        281,
        437,
        321,
        536,
        510,
        13,
        50766
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49128997325897217,
      "compression_ratio": 1.5555555820465088,
      "no_speech_prob": 0.03560378775000572
    },
    {
      "id": 7,
      "seek": 2716,
      "start": 35.20000076293945,
      "end": 40.560001373291016,
      "text": " Because, as I said, here we don't see how to deal with legacy.",
      "tokens": [
        50766,
        1436,
        11,
        382,
        286,
        848,
        11,
        510,
        321,
        500,
        380,
        536,
        577,
        281,
        2028,
        365,
        11711,
        13,
        51034
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49128997325897217,
      "compression_ratio": 1.5555555820465088,
      "no_speech_prob": 0.03560378775000572
    },
    {
      "id": 8,
      "seek": 2716,
      "start": 40.560001373291016,
      "end": 47.119998931884766,
      "text": " Well, the first thing I actually want to talk about is the topic of tactical design.",
      "tokens": [
        51034,
        1042,
        11,
        264,
        700,
        551,
        286,
        767,
        528,
        281,
        751,
        466,
        307,
        264,
        4829,
        295,
        26323,
        1715,
        13,
        51362
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49128997325897217,
      "compression_ratio": 1.5555555820465088,
      "no_speech_prob": 0.03560378775000572
    },
    {
      "id": 9,
      "seek": 2716,
      "start": 49.439998626708984,
      "end": 51.720001220703125,
      "text": " That's also a bit of a breaking point for the last time.",
      "tokens": [
        51478,
        663,
        311,
        611,
        257,
        857,
        295,
        257,
        7697,
        935,
        337,
        264,
        1036,
        565,
        13,
        51592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49128997325897217,
      "compression_ratio": 1.5555555820465088,
      "no_speech_prob": 0.03560378775000572
    },
    {
      "id": 10,
      "seek": 2716,
      "start": 51.720001220703125,
      "end": 55.2400016784668,
      "text": " So we talked very roughly about the whole thing last time.",
      "tokens": [
        51592,
        407,
        321,
        2825,
        588,
        9810,
        466,
        264,
        1379,
        551,
        1036,
        565,
        13,
        51768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49128997325897217,
      "compression_ratio": 1.5555555820465088,
      "no_speech_prob": 0.03560378775000572
    },
    {
      "id": 11,
      "seek": 5524,
      "start": 55.2400016784668,
      "end": 58.84000015258789,
      "text": " So how do I divide a system into building contexts?",
      "tokens": [
        50364,
        407,
        577,
        360,
        286,
        9845,
        257,
        1185,
        666,
        2390,
        30628,
        30,
        50544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38476768136024475,
      "compression_ratio": 1.726141095161438,
      "no_speech_prob": 0.02701135165989399
    },
    {
      "id": 12,
      "seek": 5524,
      "start": 58.84000015258789,
      "end": 63.84000015258789,
      "text": " How do I somehow build? What responsibilities do teams have? And so on and so forth.",
      "tokens": [
        50544,
        1012,
        360,
        286,
        6063,
        1322,
        30,
        708,
        16190,
        360,
        5491,
        362,
        30,
        400,
        370,
        322,
        293,
        370,
        5220,
        13,
        50794
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38476768136024475,
      "compression_ratio": 1.726141095161438,
      "no_speech_prob": 0.02701135165989399
    },
    {
      "id": 13,
      "seek": 5524,
      "start": 63.84000015258789,
      "end": 67.12000274658203,
      "text": " And this is a completely different level here now.",
      "tokens": [
        50794,
        400,
        341,
        307,
        257,
        2584,
        819,
        1496,
        510,
        586,
        13,
        50958
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38476768136024475,
      "compression_ratio": 1.726141095161438,
      "no_speech_prob": 0.02701135165989399
    },
    {
      "id": 14,
      "seek": 5524,
      "start": 67.12000274658203,
      "end": 71.31999969482422,
      "text": " This is actually the level of classes.",
      "tokens": [
        50958,
        639,
        307,
        767,
        264,
        1496,
        295,
        5359,
        13,
        51168
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38476768136024475,
      "compression_ratio": 1.726141095161438,
      "no_speech_prob": 0.02701135165989399
    },
    {
      "id": 15,
      "seek": 5524,
      "start": 71.31999969482422,
      "end": 73.72000122070312,
      "text": " And why tactical design now?",
      "tokens": [
        51168,
        400,
        983,
        26323,
        1715,
        586,
        30,
        51288
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38476768136024475,
      "compression_ratio": 1.726141095161438,
      "no_speech_prob": 0.02701135165989399
    },
    {
      "id": 16,
      "seek": 5524,
      "start": 73.72000122070312,
      "end": 77.12000274658203,
      "text": " So tactical design are object-oriented concepts.",
      "tokens": [
        51288,
        407,
        26323,
        1715,
        366,
        2657,
        12,
        27414,
        10392,
        13,
        51458
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38476768136024475,
      "compression_ratio": 1.726141095161438,
      "no_speech_prob": 0.02701135165989399
    },
    {
      "id": 17,
      "seek": 5524,
      "start": 77.12000274658203,
      "end": 80.4000015258789,
      "text": " And it makes a lot of sense to me to build good object-oriented systems.",
      "tokens": [
        51458,
        400,
        309,
        1669,
        257,
        688,
        295,
        2020,
        281,
        385,
        281,
        1322,
        665,
        2657,
        12,
        27414,
        3652,
        13,
        51622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38476768136024475,
      "compression_ratio": 1.726141095161438,
      "no_speech_prob": 0.02701135165989399
    },
    {
      "id": 18,
      "seek": 5524,
      "start": 80.4000015258789,
      "end": 83.12000274658203,
      "text": " Tactical design is exactly what helps.",
      "tokens": [
        51622,
        47111,
        804,
        1715,
        307,
        2293,
        437,
        3665,
        13,
        51758
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38476768136024475,
      "compression_ratio": 1.726141095161438,
      "no_speech_prob": 0.02701135165989399
    },
    {
      "id": 19,
      "seek": 8312,
      "start": 83.27999877929688,
      "end": 86.04000091552734,
      "text": " We can go through the patterns now.",
      "tokens": [
        50372,
        492,
        393,
        352,
        807,
        264,
        8294,
        586,
        13,
        50510
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43934303522109985,
      "compression_ratio": 1.686635971069336,
      "no_speech_prob": 0.08718917518854141
    },
    {
      "id": 20,
      "seek": 8312,
      "start": 86.04000091552734,
      "end": 89.23999786376953,
      "text": " The first pattern is an entity.",
      "tokens": [
        50510,
        440,
        700,
        5102,
        307,
        364,
        13977,
        13,
        50670
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43934303522109985,
      "compression_ratio": 1.686635971069336,
      "no_speech_prob": 0.08718917518854141
    },
    {
      "id": 21,
      "seek": 8312,
      "start": 89.23999786376953,
      "end": 91.4000015258789,
      "text": " That's something that has an identity.",
      "tokens": [
        50670,
        663,
        311,
        746,
        300,
        575,
        364,
        6575,
        13,
        50778
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43934303522109985,
      "compression_ratio": 1.686635971069336,
      "no_speech_prob": 0.08718917518854141
    },
    {
      "id": 22,
      "seek": 8312,
      "start": 91.4000015258789,
      "end": 93.76000213623047,
      "text": " So a person has an identity.",
      "tokens": [
        50778,
        407,
        257,
        954,
        575,
        364,
        6575,
        13,
        50896
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43934303522109985,
      "compression_ratio": 1.686635971069336,
      "no_speech_prob": 0.08718917518854141
    },
    {
      "id": 23,
      "seek": 8312,
      "start": 93.76000213623047,
      "end": 97.87999725341797,
      "text": " That means, if I give the Eberhard Wolf again,",
      "tokens": [
        50896,
        663,
        1355,
        11,
        498,
        286,
        976,
        264,
        462,
        607,
        21491,
        16634,
        797,
        11,
        51102
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43934303522109985,
      "compression_ratio": 1.686635971069336,
      "no_speech_prob": 0.08718917518854141
    },
    {
      "id": 24,
      "seek": 8312,
      "start": 97.87999725341797,
      "end": 100.5999984741211,
      "text": " there is now a completely identical copy,",
      "tokens": [
        51102,
        456,
        307,
        586,
        257,
        2584,
        14800,
        5055,
        11,
        51238
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43934303522109985,
      "compression_ratio": 1.686635971069336,
      "no_speech_prob": 0.08718917518854141
    },
    {
      "id": 25,
      "seek": 8312,
      "start": 100.5999984741211,
      "end": 108.4000015258789,
      "text": " which looks like me, who lives there, where I live and is not so much identical.",
      "tokens": [
        51238,
        597,
        1542,
        411,
        385,
        11,
        567,
        2909,
        456,
        11,
        689,
        286,
        1621,
        293,
        307,
        406,
        370,
        709,
        14800,
        13,
        51628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43934303522109985,
      "compression_ratio": 1.686635971069336,
      "no_speech_prob": 0.08718917518854141
    },
    {
      "id": 26,
      "seek": 8312,
      "start": 108.4000015258789,
      "end": 110.16000366210938,
      "text": " That's still another person.",
      "tokens": [
        51628,
        663,
        311,
        920,
        1071,
        954,
        13,
        51716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43934303522109985,
      "compression_ratio": 1.686635971069336,
      "no_speech_prob": 0.08718917518854141
    },
    {
      "id": 27,
      "seek": 8312,
      "start": 110.16000366210938,
      "end": 112.12000274658203,
      "text": " I can somehow distinguish them.",
      "tokens": [
        51716,
        286,
        393,
        6063,
        20206,
        552,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43934303522109985,
      "compression_ratio": 1.686635971069336,
      "no_speech_prob": 0.08718917518854141
    },
    {
      "id": 28,
      "seek": 11212,
      "start": 112.16000366210938,
      "end": 116.76000213623047,
      "text": " And that means that things actually have an identity here.",
      "tokens": [
        50366,
        400,
        300,
        1355,
        300,
        721,
        767,
        362,
        364,
        6575,
        510,
        13,
        50596
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39128634333610535,
      "compression_ratio": 1.7041419744491577,
      "no_speech_prob": 0.0022495659068226814
    },
    {
      "id": 29,
      "seek": 11212,
      "start": 116.76000213623047,
      "end": 118.55999755859375,
      "text": " A person has an identity.",
      "tokens": [
        50596,
        316,
        954,
        575,
        364,
        6575,
        13,
        50686
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39128634333610535,
      "compression_ratio": 1.7041419744491577,
      "no_speech_prob": 0.0022495659068226814
    },
    {
      "id": 30,
      "seek": 11212,
      "start": 118.55999755859375,
      "end": 120.12000274658203,
      "text": " A product has an identity.",
      "tokens": [
        50686,
        316,
        1674,
        575,
        364,
        6575,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39128634333610535,
      "compression_ratio": 1.7041419744491577,
      "no_speech_prob": 0.0022495659068226814
    },
    {
      "id": 31,
      "seek": 11212,
      "start": 120.12000274658203,
      "end": 121.72000122070312,
      "text": " Such stories.",
      "tokens": [
        50764,
        9653,
        3676,
        13,
        50844
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39128634333610535,
      "compression_ratio": 1.7041419744491577,
      "no_speech_prob": 0.0022495659068226814
    },
    {
      "id": 32,
      "seek": 11212,
      "start": 121.72000122070312,
      "end": 125.04000091552734,
      "text": " And something like value objects,",
      "tokens": [
        50844,
        400,
        746,
        411,
        2158,
        6565,
        11,
        51010
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39128634333610535,
      "compression_ratio": 1.7041419744491577,
      "no_speech_prob": 0.0022495659068226814
    },
    {
      "id": 33,
      "seek": 11212,
      "start": 125.04000091552734,
      "end": 128.16000366210938,
      "text": " i.e. a value such as 2 euros or 2 meters.",
      "tokens": [
        51010,
        741,
        13,
        68,
        13,
        257,
        2158,
        1270,
        382,
        568,
        14160,
        420,
        568,
        8146,
        13,
        51166
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39128634333610535,
      "compression_ratio": 1.7041419744491577,
      "no_speech_prob": 0.0022495659068226814
    },
    {
      "id": 34,
      "seek": 11212,
      "start": 128.16000366210938,
      "end": 130.36000061035156,
      "text": " 2 meters are just 2 meters.",
      "tokens": [
        51166,
        568,
        8146,
        366,
        445,
        568,
        8146,
        13,
        51276
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39128634333610535,
      "compression_ratio": 1.7041419744491577,
      "no_speech_prob": 0.0022495659068226814
    },
    {
      "id": 35,
      "seek": 11212,
      "start": 130.36000061035156,
      "end": 136.52000427246094,
      "text": " And it doesn't really matter if these 2 euros are 2 euros.",
      "tokens": [
        51276,
        400,
        309,
        1177,
        380,
        534,
        1871,
        498,
        613,
        568,
        14160,
        366,
        568,
        14160,
        13,
        51584
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39128634333610535,
      "compression_ratio": 1.7041419744491577,
      "no_speech_prob": 0.0022495659068226814
    },
    {
      "id": 36,
      "seek": 13652,
      "start": 136.52000427246094,
      "end": 144.1999969482422,
      "text": " So these are actually things that only differ in value.",
      "tokens": [
        50364,
        407,
        613,
        366,
        767,
        721,
        300,
        787,
        743,
        294,
        2158,
        13,
        50748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4080211818218231,
      "compression_ratio": 1.7619047164916992,
      "no_speech_prob": 0.19890853762626648
    },
    {
      "id": 37,
      "seek": 13652,
      "start": 144.1999969482422,
      "end": 145.44000244140625,
      "text": " Then there are domain events.",
      "tokens": [
        50748,
        1396,
        456,
        366,
        9274,
        3931,
        13,
        50810
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4080211818218231,
      "compression_ratio": 1.7619047164916992,
      "no_speech_prob": 0.19890853762626648
    },
    {
      "id": 38,
      "seek": 13652,
      "start": 145.44000244140625,
      "end": 150.0399932861328,
      "text": " These are things that are relevant to domain experts.",
      "tokens": [
        50810,
        1981,
        366,
        721,
        300,
        366,
        7340,
        281,
        9274,
        8572,
        13,
        51040
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4080211818218231,
      "compression_ratio": 1.7619047164916992,
      "no_speech_prob": 0.19890853762626648
    },
    {
      "id": 39,
      "seek": 13652,
      "start": 150.0399932861328,
      "end": 153.83999633789062,
      "text": " So something has happened in the past.",
      "tokens": [
        51040,
        407,
        746,
        575,
        2011,
        294,
        264,
        1791,
        13,
        51230
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4080211818218231,
      "compression_ratio": 1.7619047164916992,
      "no_speech_prob": 0.19890853762626648
    },
    {
      "id": 40,
      "seek": 13652,
      "start": 153.83999633789062,
      "end": 155.44000244140625,
      "text": " We talked about this last time.",
      "tokens": [
        51230,
        492,
        2825,
        466,
        341,
        1036,
        565,
        13,
        51310
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4080211818218231,
      "compression_ratio": 1.7619047164916992,
      "no_speech_prob": 0.19890853762626648
    },
    {
      "id": 41,
      "seek": 13652,
      "start": 155.44000244140625,
      "end": 158.67999267578125,
      "text": " This is also something that plays a role in event storming, for example.",
      "tokens": [
        51310,
        639,
        307,
        611,
        746,
        300,
        5749,
        257,
        3090,
        294,
        2280,
        342,
        687,
        278,
        11,
        337,
        1365,
        13,
        51472
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4080211818218231,
      "compression_ratio": 1.7619047164916992,
      "no_speech_prob": 0.19890853762626648
    },
    {
      "id": 42,
      "seek": 13652,
      "start": 158.67999267578125,
      "end": 163.55999755859375,
      "text": " These are things that I can implement as classes.",
      "tokens": [
        51472,
        1981,
        366,
        721,
        300,
        286,
        393,
        4445,
        382,
        5359,
        13,
        51716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4080211818218231,
      "compression_ratio": 1.7619047164916992,
      "no_speech_prob": 0.19890853762626648
    },
    {
      "id": 43,
      "seek": 16356,
      "start": 163.60000610351562,
      "end": 166.47999572753906,
      "text": " Maybe two more general things.",
      "tokens": [
        50366,
        2704,
        732,
        544,
        2674,
        721,
        13,
        50510
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4592265486717224,
      "compression_ratio": 1.5549451112747192,
      "no_speech_prob": 0.006184902973473072
    },
    {
      "id": 44,
      "seek": 16356,
      "start": 166.47999572753906,
      "end": 179.36000061035156,
      "text": " The one general note is that what we see here is that we have a fundamental dependency from top to bottom.",
      "tokens": [
        50510,
        440,
        472,
        2674,
        3637,
        307,
        300,
        437,
        321,
        536,
        510,
        307,
        300,
        321,
        362,
        257,
        8088,
        33621,
        490,
        1192,
        281,
        2767,
        13,
        51154
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4592265486717224,
      "compression_ratio": 1.5549451112747192,
      "no_speech_prob": 0.006184902973473072
    },
    {
      "id": 45,
      "seek": 16356,
      "start": 179.36000061035156,
      "end": 185.9199981689453,
      "text": " That is, these are actually basic things that depend on nothing else.",
      "tokens": [
        51154,
        663,
        307,
        11,
        613,
        366,
        767,
        3875,
        721,
        300,
        5672,
        322,
        1825,
        1646,
        13,
        51482
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4592265486717224,
      "compression_ratio": 1.5549451112747192,
      "no_speech_prob": 0.006184902973473072
    },
    {
      "id": 46,
      "seek": 16356,
      "start": 185.9199981689453,
      "end": 191.1999969482422,
      "text": " And the other thing is, we're talking about a real object-oriented concept.",
      "tokens": [
        51482,
        400,
        264,
        661,
        551,
        307,
        11,
        321,
        434,
        1417,
        466,
        257,
        957,
        2657,
        12,
        27414,
        3410,
        13,
        51746
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4592265486717224,
      "compression_ratio": 1.5549451112747192,
      "no_speech_prob": 0.006184902973473072
    },
    {
      "id": 47,
      "seek": 19120,
      "start": 191.1999969482422,
      "end": 196.1199951171875,
      "text": " That means the things we see here have logic.",
      "tokens": [
        50364,
        663,
        1355,
        264,
        721,
        321,
        536,
        510,
        362,
        9952,
        13,
        50610
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43115997314453125,
      "compression_ratio": 1.5989304780960083,
      "no_speech_prob": 0.01448995340615511
    },
    {
      "id": 48,
      "seek": 19120,
      "start": 196.1199951171875,
      "end": 200.36000061035156,
      "text": " So if I say, for example, I have 2 euros.",
      "tokens": [
        50610,
        407,
        498,
        286,
        584,
        11,
        337,
        1365,
        11,
        286,
        362,
        568,
        14160,
        13,
        50822
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43115997314453125,
      "compression_ratio": 1.5989304780960083,
      "no_speech_prob": 0.01448995340615511
    },
    {
      "id": 49,
      "seek": 19120,
      "start": 200.36000061035156,
      "end": 203.0399932861328,
      "text": " I can somehow sum amounts of money.",
      "tokens": [
        50822,
        286,
        393,
        6063,
        2408,
        11663,
        295,
        1460,
        13,
        50956
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43115997314453125,
      "compression_ratio": 1.5989304780960083,
      "no_speech_prob": 0.01448995340615511
    },
    {
      "id": 50,
      "seek": 19120,
      "start": 203.0399932861328,
      "end": 205.72000122070312,
      "text": " And I can try to round them.",
      "tokens": [
        50956,
        400,
        286,
        393,
        853,
        281,
        3098,
        552,
        13,
        51090
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43115997314453125,
      "compression_ratio": 1.5989304780960083,
      "no_speech_prob": 0.01448995340615511
    },
    {
      "id": 51,
      "seek": 19120,
      "start": 205.72000122070312,
      "end": 208.24000549316406,
      "text": " And whatever else I can do.",
      "tokens": [
        51090,
        400,
        2035,
        1646,
        286,
        393,
        360,
        13,
        51216
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43115997314453125,
      "compression_ratio": 1.5989304780960083,
      "no_speech_prob": 0.01448995340615511
    },
    {
      "id": 52,
      "seek": 19120,
      "start": 208.24000549316406,
      "end": 211.52000427246094,
      "text": " These are things that I will model in this value object, for example.",
      "tokens": [
        51216,
        1981,
        366,
        721,
        300,
        286,
        486,
        2316,
        294,
        341,
        2158,
        2657,
        11,
        337,
        1365,
        13,
        51380
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43115997314453125,
      "compression_ratio": 1.5989304780960083,
      "no_speech_prob": 0.01448995340615511
    },
    {
      "id": 53,
      "seek": 19120,
      "start": 211.52000427246094,
      "end": 216.36000061035156,
      "text": " So these are things that actually contain logic.",
      "tokens": [
        51380,
        407,
        613,
        366,
        721,
        300,
        767,
        5304,
        9952,
        13,
        51622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43115997314453125,
      "compression_ratio": 1.5989304780960083,
      "no_speech_prob": 0.01448995340615511
    },
    {
      "id": 54,
      "seek": 21636,
      "start": 216.36000061035156,
      "end": 222.9600067138672,
      "text": " So, based on that, there are these aggregates on the next layer.",
      "tokens": [
        50364,
        407,
        11,
        2361,
        322,
        300,
        11,
        456,
        366,
        613,
        16743,
        1024,
        322,
        264,
        958,
        4583,
        13,
        50694
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4202474057674408,
      "compression_ratio": 1.6932270526885986,
      "no_speech_prob": 0.017403054982423782
    },
    {
      "id": 55,
      "seek": 21636,
      "start": 222.9600067138672,
      "end": 227.55999755859375,
      "text": " They are made up of several different things.",
      "tokens": [
        50694,
        814,
        366,
        1027,
        493,
        295,
        2940,
        819,
        721,
        13,
        50924
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4202474057674408,
      "compression_ratio": 1.6932270526885986,
      "no_speech_prob": 0.017403054982423782
    },
    {
      "id": 56,
      "seek": 21636,
      "start": 227.55999755859375,
      "end": 228.63999938964844,
      "text": " That's why they're a little higher.",
      "tokens": [
        50924,
        663,
        311,
        983,
        436,
        434,
        257,
        707,
        2946,
        13,
        50978
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4202474057674408,
      "compression_ratio": 1.6932270526885986,
      "no_speech_prob": 0.017403054982423782
    },
    {
      "id": 57,
      "seek": 21636,
      "start": 228.63999938964844,
      "end": 233.0399932861328,
      "text": " So that means there are entities and value objects that are summarized in aggregates.",
      "tokens": [
        50978,
        407,
        300,
        1355,
        456,
        366,
        16667,
        293,
        2158,
        6565,
        300,
        366,
        14611,
        1602,
        294,
        16743,
        1024,
        13,
        51198
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4202474057674408,
      "compression_ratio": 1.6932270526885986,
      "no_speech_prob": 0.017403054982423782
    },
    {
      "id": 58,
      "seek": 21636,
      "start": 233.0399932861328,
      "end": 238.72000122070312,
      "text": " And there is an aggregate root that is now responsible for ensuring consistency there.",
      "tokens": [
        51198,
        400,
        456,
        307,
        364,
        26118,
        5593,
        300,
        307,
        586,
        6250,
        337,
        16882,
        14416,
        456,
        13,
        51482
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4202474057674408,
      "compression_ratio": 1.6932270526885986,
      "no_speech_prob": 0.017403054982423782
    },
    {
      "id": 59,
      "seek": 21636,
      "start": 238.72000122070312,
      "end": 244.44000244140625,
      "text": " That means, for example, if I have an order and I add something to this order that I would like to order.",
      "tokens": [
        51482,
        663,
        1355,
        11,
        337,
        1365,
        11,
        498,
        286,
        362,
        364,
        1668,
        293,
        286,
        909,
        746,
        281,
        341,
        1668,
        300,
        286,
        576,
        411,
        281,
        1668,
        13,
        51768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4202474057674408,
      "compression_ratio": 1.6932270526885986,
      "no_speech_prob": 0.017403054982423782
    },
    {
      "id": 60,
      "seek": 24444,
      "start": 244.44000244140625,
      "end": 253.36000061035156,
      "text": " Then this is added to one and the other ensures that the total amount of the order is adjusted accordingly.",
      "tokens": [
        50364,
        1396,
        341,
        307,
        3869,
        281,
        472,
        293,
        264,
        661,
        28111,
        300,
        264,
        3217,
        2372,
        295,
        264,
        1668,
        307,
        19871,
        19717,
        13,
        50810
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4469945430755615,
      "compression_ratio": 1.6810810565948486,
      "no_speech_prob": 0.008218316361308098
    },
    {
      "id": 61,
      "seek": 24444,
      "start": 253.36000061035156,
      "end": 256.0400085449219,
      "text": " Then the thing is consistent in itself.",
      "tokens": [
        50810,
        1396,
        264,
        551,
        307,
        8398,
        294,
        2564,
        13,
        50944
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4469945430755615,
      "compression_ratio": 1.6810810565948486,
      "no_speech_prob": 0.008218316361308098
    },
    {
      "id": 62,
      "seek": 24444,
      "start": 256.0400085449219,
      "end": 263.7200012207031,
      "text": " And the aggregate root ensures that this change takes place automatically.",
      "tokens": [
        50944,
        400,
        264,
        26118,
        5593,
        28111,
        300,
        341,
        1319,
        2516,
        1081,
        6772,
        13,
        51328
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4469945430755615,
      "compression_ratio": 1.6810810565948486,
      "no_speech_prob": 0.008218316361308098
    },
    {
      "id": 63,
      "seek": 24444,
      "start": 263.7200012207031,
      "end": 269.6400146484375,
      "text": " Which means that consistency conditions are implemented synchronously within aggregates.",
      "tokens": [
        51328,
        3013,
        1355,
        300,
        14416,
        4487,
        366,
        12270,
        19331,
        5098,
        1951,
        16743,
        1024,
        13,
        51624
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4469945430755615,
      "compression_ratio": 1.6810810565948486,
      "no_speech_prob": 0.008218316361308098
    },
    {
      "id": 64,
      "seek": 26964,
      "start": 269.6400146484375,
      "end": 273.32000732421875,
      "text": " Not necessarily synchronously across aggregates.",
      "tokens": [
        50364,
        1726,
        4725,
        19331,
        5098,
        2108,
        16743,
        1024,
        13,
        50548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4469696879386902,
      "compression_ratio": 1.5614973306655884,
      "no_speech_prob": 0.31662386655807495
    },
    {
      "id": 65,
      "seek": 26964,
      "start": 273.32000732421875,
      "end": 278.32000732421875,
      "text": " And I can also use aggregates to replicate them in the network.",
      "tokens": [
        50548,
        400,
        286,
        393,
        611,
        764,
        16743,
        1024,
        281,
        25356,
        552,
        294,
        264,
        3209,
        13,
        50798
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4469696879386902,
      "compression_ratio": 1.5614973306655884,
      "no_speech_prob": 0.31662386655807495
    },
    {
      "id": 66,
      "seek": 26964,
      "start": 278.32000732421875,
      "end": 280.5199890136719,
      "text": " Then I also have eventual consistency.",
      "tokens": [
        50798,
        1396,
        286,
        611,
        362,
        33160,
        14416,
        13,
        50908
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4469696879386902,
      "compression_ratio": 1.5614973306655884,
      "no_speech_prob": 0.31662386655807495
    },
    {
      "id": 67,
      "seek": 26964,
      "start": 280.5199890136719,
      "end": 289.9599914550781,
      "text": " That means that all aggregates will eventually become consistent.",
      "tokens": [
        50908,
        663,
        1355,
        300,
        439,
        16743,
        1024,
        486,
        4728,
        1813,
        8398,
        13,
        51380
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4469696879386902,
      "compression_ratio": 1.5614973306655884,
      "no_speech_prob": 0.31662386655807495
    },
    {
      "id": 68,
      "seek": 26964,
      "start": 289.9599914550781,
      "end": 299.20001220703125,
      "text": " This is interesting because a transfer, for example, changes two accounts.",
      "tokens": [
        51380,
        639,
        307,
        1880,
        570,
        257,
        5003,
        11,
        337,
        1365,
        11,
        2962,
        732,
        9402,
        13,
        51842
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4469696879386902,
      "compression_ratio": 1.5614973306655884,
      "no_speech_prob": 0.31662386655807495
    },
    {
      "id": 69,
      "seek": 29920,
      "start": 299.239990234375,
      "end": 303.239990234375,
      "text": " Now you might think, I want to have that consistent.",
      "tokens": [
        50366,
        823,
        291,
        1062,
        519,
        11,
        286,
        528,
        281,
        362,
        300,
        8398,
        13,
        50566
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43431755900382996,
      "compression_ratio": 1.5892115831375122,
      "no_speech_prob": 0.0008821853552944958
    },
    {
      "id": 70,
      "seek": 29920,
      "start": 303.239990234375,
      "end": 307.6400146484375,
      "text": " And what Domain Driven Design says is, no, the account itself is consistent.",
      "tokens": [
        50566,
        400,
        437,
        16674,
        491,
        19150,
        553,
        12748,
        1619,
        307,
        11,
        572,
        11,
        264,
        2696,
        2564,
        307,
        8398,
        13,
        50786
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43431755900382996,
      "compression_ratio": 1.5892115831375122,
      "no_speech_prob": 0.0008821853552944958
    },
    {
      "id": 71,
      "seek": 29920,
      "start": 307.6400146484375,
      "end": 311.55999755859375,
      "text": " So on the one hand, the amount would be correct.",
      "tokens": [
        50786,
        407,
        322,
        264,
        472,
        1011,
        11,
        264,
        2372,
        576,
        312,
        3006,
        13,
        50982
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43431755900382996,
      "compression_ratio": 1.5892115831375122,
      "no_speech_prob": 0.0008821853552944958
    },
    {
      "id": 72,
      "seek": 29920,
      "start": 311.55999755859375,
      "end": 314.0,
      "text": " I have â‚¬ 240 after the transfer.",
      "tokens": [
        50982,
        286,
        362,
        17450,
        568,
        5254,
        934,
        264,
        5003,
        13,
        51104
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43431755900382996,
      "compression_ratio": 1.5892115831375122,
      "no_speech_prob": 0.0008821853552944958
    },
    {
      "id": 73,
      "seek": 29920,
      "start": 314.0,
      "end": 318.8800048828125,
      "text": " And on the other hand, the transfer is actually booked or nothing from both.",
      "tokens": [
        51104,
        400,
        322,
        264,
        661,
        1011,
        11,
        264,
        5003,
        307,
        767,
        748,
        9511,
        420,
        1825,
        490,
        1293,
        13,
        51348
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43431755900382996,
      "compression_ratio": 1.5892115831375122,
      "no_speech_prob": 0.0008821853552944958
    },
    {
      "id": 74,
      "seek": 29920,
      "start": 318.8800048828125,
      "end": 324.55999755859375,
      "text": " But the accounts can be inconsistent.",
      "tokens": [
        51348,
        583,
        264,
        9402,
        393,
        312,
        36891,
        13,
        51632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43431755900382996,
      "compression_ratio": 1.5892115831375122,
      "no_speech_prob": 0.0008821853552944958
    },
    {
      "id": 75,
      "seek": 29920,
      "start": 324.55999755859375,
      "end": 327.4800109863281,
      "text": " Which, by the way, is exactly what reality looks like.",
      "tokens": [
        51632,
        3013,
        11,
        538,
        264,
        636,
        11,
        307,
        2293,
        437,
        4103,
        1542,
        411,
        13,
        51778
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43431755900382996,
      "compression_ratio": 1.5892115831375122,
      "no_speech_prob": 0.0008821853552944958
    },
    {
      "id": 76,
      "seek": 32748,
      "start": 327.4800109863281,
      "end": 332.67999267578125,
      "text": " If I now transfer money, it is somewhere between these two accounts for some time.",
      "tokens": [
        50364,
        759,
        286,
        586,
        5003,
        1460,
        11,
        309,
        307,
        4079,
        1296,
        613,
        732,
        9402,
        337,
        512,
        565,
        13,
        50624
      ],
      "temperature": 0.0,
      "avg_logprob": -0.50421142578125,
      "compression_ratio": 1.7000000476837158,
      "no_speech_prob": 0.024409852921962738
    },
    {
      "id": 77,
      "seek": 32748,
      "start": 332.67999267578125,
      "end": 334.9200134277344,
      "text": " So the money has been lost for some time.",
      "tokens": [
        50624,
        407,
        264,
        1460,
        575,
        668,
        2731,
        337,
        512,
        565,
        13,
        50736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.50421142578125,
      "compression_ratio": 1.7000000476837158,
      "no_speech_prob": 0.024409852921962738
    },
    {
      "id": 78,
      "seek": 32748,
      "start": 334.9200134277344,
      "end": 336.4800109863281,
      "text": " At least that's what I assume.",
      "tokens": [
        50736,
        1711,
        1935,
        300,
        311,
        437,
        286,
        6552,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.50421142578125,
      "compression_ratio": 1.7000000476837158,
      "no_speech_prob": 0.024409852921962738
    },
    {
      "id": 79,
      "seek": 32748,
      "start": 336.4800109863281,
      "end": 338.8800048828125,
      "text": " So that's what plays a role here.",
      "tokens": [
        50814,
        407,
        300,
        311,
        437,
        5749,
        257,
        3090,
        510,
        13,
        50934
      ],
      "temperature": 0.0,
      "avg_logprob": -0.50421142578125,
      "compression_ratio": 1.7000000476837158,
      "no_speech_prob": 0.024409852921962738
    },
    {
      "id": 80,
      "seek": 32748,
      "start": 338.8800048828125,
      "end": 342.6000061035156,
      "text": " What this also means is that in contexts that are roughly granular,",
      "tokens": [
        50934,
        708,
        341,
        611,
        1355,
        307,
        300,
        294,
        30628,
        300,
        366,
        9810,
        39962,
        11,
        51120
      ],
      "temperature": 0.0,
      "avg_logprob": -0.50421142578125,
      "compression_ratio": 1.7000000476837158,
      "no_speech_prob": 0.024409852921962738
    },
    {
      "id": 81,
      "seek": 32748,
      "start": 342.6000061035156,
      "end": 348.55999755859375,
      "text": " not total consistency in itself, but aggregate consistency.",
      "tokens": [
        51120,
        406,
        3217,
        14416,
        294,
        2564,
        11,
        457,
        26118,
        14416,
        13,
        51418
      ],
      "temperature": 0.0,
      "avg_logprob": -0.50421142578125,
      "compression_ratio": 1.7000000476837158,
      "no_speech_prob": 0.024409852921962738
    },
    {
      "id": 82,
      "seek": 32748,
      "start": 348.55999755859375,
      "end": 350.760009765625,
      "text": " This consists of entities.",
      "tokens": [
        51418,
        639,
        14689,
        295,
        16667,
        13,
        51528
      ],
      "temperature": 0.0,
      "avg_logprob": -0.50421142578125,
      "compression_ratio": 1.7000000476837158,
      "no_speech_prob": 0.024409852921962738
    },
    {
      "id": 83,
      "seek": 32748,
      "start": 350.760009765625,
      "end": 355.8800048828125,
      "text": " So my individual bookings would be, for example, some entities.",
      "tokens": [
        51528,
        407,
        452,
        2609,
        1446,
        1109,
        576,
        312,
        11,
        337,
        1365,
        11,
        512,
        16667,
        13,
        51784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.50421142578125,
      "compression_ratio": 1.7000000476837158,
      "no_speech_prob": 0.024409852921962738
    },
    {
      "id": 84,
      "seek": 35588,
      "start": 355.9200134277344,
      "end": 360.3599853515625,
      "text": " And value objects, the account balance, for example, would be such a value object.",
      "tokens": [
        50366,
        400,
        2158,
        6565,
        11,
        264,
        2696,
        4772,
        11,
        337,
        1365,
        11,
        576,
        312,
        1270,
        257,
        2158,
        2657,
        13,
        50588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4052458703517914,
      "compression_ratio": 1.6211453676223755,
      "no_speech_prob": 0.0014517511008307338
    },
    {
      "id": 85,
      "seek": 35588,
      "start": 360.3599853515625,
      "end": 362.0400085449219,
      "text": " Then I have repositories.",
      "tokens": [
        50588,
        1396,
        286,
        362,
        22283,
        2083,
        13,
        50672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4052458703517914,
      "compression_ratio": 1.6211453676223755,
      "no_speech_prob": 0.0014517511008307338
    },
    {
      "id": 86,
      "seek": 35588,
      "start": 362.0400085449219,
      "end": 366.6400146484375,
      "text": " They give me the illusion of a collection of aggregates,",
      "tokens": [
        50672,
        814,
        976,
        385,
        264,
        18854,
        295,
        257,
        5765,
        295,
        16743,
        1024,
        11,
        50902
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4052458703517914,
      "compression_ratio": 1.6211453676223755,
      "no_speech_prob": 0.0014517511008307338
    },
    {
      "id": 87,
      "seek": 35588,
      "start": 366.6400146484375,
      "end": 371.5199890136719,
      "text": " which is apparently stored in the memory, but is actually in the database.",
      "tokens": [
        50902,
        597,
        307,
        7970,
        12187,
        294,
        264,
        4675,
        11,
        457,
        307,
        767,
        294,
        264,
        8149,
        13,
        51146
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4052458703517914,
      "compression_ratio": 1.6211453676223755,
      "no_speech_prob": 0.0014517511008307338
    },
    {
      "id": 88,
      "seek": 35588,
      "start": 371.5199890136719,
      "end": 373.9599914550781,
      "text": " This is also a conceptual thing.",
      "tokens": [
        51146,
        639,
        307,
        611,
        257,
        24106,
        551,
        13,
        51268
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4052458703517914,
      "compression_ratio": 1.6211453676223755,
      "no_speech_prob": 0.0014517511008307338
    },
    {
      "id": 89,
      "seek": 35588,
      "start": 373.9599914550781,
      "end": 384.0799865722656,
      "text": " And what I find particularly exciting is that repositories also implement the right questions.",
      "tokens": [
        51268,
        400,
        437,
        286,
        915,
        4098,
        4670,
        307,
        300,
        22283,
        2083,
        611,
        4445,
        264,
        558,
        1651,
        13,
        51774
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4052458703517914,
      "compression_ratio": 1.6211453676223755,
      "no_speech_prob": 0.0014517511008307338
    },
    {
      "id": 90,
      "seek": 38408,
      "start": 384.0799865722656,
      "end": 386.760009765625,
      "text": " That means a repository will not say,",
      "tokens": [
        50364,
        663,
        1355,
        257,
        25841,
        486,
        406,
        584,
        11,
        50498
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4424164593219757,
      "compression_ratio": 1.6540284156799316,
      "no_speech_prob": 0.009836687706410885
    },
    {
      "id": 91,
      "seek": 38408,
      "start": 386.760009765625,
      "end": 389.6000061035156,
      "text": " I'll give you access to any objects,",
      "tokens": [
        50498,
        286,
        603,
        976,
        291,
        2105,
        281,
        604,
        6565,
        11,
        50640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4424164593219757,
      "compression_ratio": 1.6540284156799316,
      "no_speech_prob": 0.009836687706410885
    },
    {
      "id": 92,
      "seek": 38408,
      "start": 389.6000061035156,
      "end": 391.239990234375,
      "text": " but the repository will say,",
      "tokens": [
        50640,
        457,
        264,
        25841,
        486,
        584,
        11,
        50722
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4424164593219757,
      "compression_ratio": 1.6540284156799316,
      "no_speech_prob": 0.009836687706410885
    },
    {
      "id": 93,
      "seek": 38408,
      "start": 391.239990234375,
      "end": 398.7200012207031,
      "text": " okay, I now have the option of finding an account number,",
      "tokens": [
        50722,
        1392,
        11,
        286,
        586,
        362,
        264,
        3614,
        295,
        5006,
        364,
        2696,
        1230,
        11,
        51096
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4424164593219757,
      "compression_ratio": 1.6540284156799316,
      "no_speech_prob": 0.009836687706410885
    },
    {
      "id": 94,
      "seek": 38408,
      "start": 398.7200012207031,
      "end": 402.6000061035156,
      "text": " maybe also according to the name of the account holder and the date of birth,",
      "tokens": [
        51096,
        1310,
        611,
        4650,
        281,
        264,
        1315,
        295,
        264,
        2696,
        20349,
        293,
        264,
        4002,
        295,
        3965,
        11,
        51290
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4424164593219757,
      "compression_ratio": 1.6540284156799316,
      "no_speech_prob": 0.009836687706410885
    },
    {
      "id": 95,
      "seek": 38408,
      "start": 402.6000061035156,
      "end": 405.239990234375,
      "text": " but not based on the account balance,",
      "tokens": [
        51290,
        457,
        406,
        2361,
        322,
        264,
        2696,
        4772,
        11,
        51422
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4424164593219757,
      "compression_ratio": 1.6540284156799316,
      "no_speech_prob": 0.009836687706410885
    },
    {
      "id": 96,
      "seek": 38408,
      "start": 405.239990234375,
      "end": 409.6400146484375,
      "text": " because that somehow doesn't make any sense in terms of subject matter.",
      "tokens": [
        51422,
        570,
        300,
        6063,
        1177,
        380,
        652,
        604,
        2020,
        294,
        2115,
        295,
        3983,
        1871,
        13,
        51642
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4424164593219757,
      "compression_ratio": 1.6540284156799316,
      "no_speech_prob": 0.009836687706410885
    },
    {
      "id": 97,
      "seek": 40964,
      "start": 409.6400146484375,
      "end": 415.4800109863281,
      "text": " And that would mean that the repository only exposes the subject matter of queries.",
      "tokens": [
        50364,
        400,
        300,
        576,
        914,
        300,
        264,
        25841,
        787,
        1278,
        4201,
        264,
        3983,
        1871,
        295,
        24109,
        13,
        50656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4871031641960144,
      "compression_ratio": 1.6534653902053833,
      "no_speech_prob": 0.012143380008637905
    },
    {
      "id": 98,
      "seek": 40964,
      "start": 415.4800109863281,
      "end": 418.9599914550781,
      "text": " Which I think is a very interesting design concept,",
      "tokens": [
        50656,
        3013,
        286,
        519,
        307,
        257,
        588,
        1880,
        1715,
        3410,
        11,
        50830
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4871031641960144,
      "compression_ratio": 1.6534653902053833,
      "no_speech_prob": 0.012143380008637905
    },
    {
      "id": 99,
      "seek": 40964,
      "start": 418.9599914550781,
      "end": 422.0799865722656,
      "text": " because something like GraphQL, for example,",
      "tokens": [
        50830,
        570,
        746,
        411,
        21884,
        13695,
        11,
        337,
        1365,
        11,
        50986
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4871031641960144,
      "compression_ratio": 1.6534653902053833,
      "no_speech_prob": 0.012143380008637905
    },
    {
      "id": 100,
      "seek": 40964,
      "start": 422.0799865722656,
      "end": 424.20001220703125,
      "text": " says I can ask any questions.",
      "tokens": [
        50986,
        1619,
        286,
        393,
        1029,
        604,
        1651,
        13,
        51092
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4871031641960144,
      "compression_ratio": 1.6534653902053833,
      "no_speech_prob": 0.012143380008637905
    },
    {
      "id": 101,
      "seek": 40964,
      "start": 424.20001220703125,
      "end": 425.9599914550781,
      "text": " Repository says that doesn't really make any sense.",
      "tokens": [
        51092,
        3696,
        9598,
        827,
        1619,
        300,
        1177,
        380,
        534,
        652,
        604,
        2020,
        13,
        51180
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4871031641960144,
      "compression_ratio": 1.6534653902053833,
      "no_speech_prob": 0.012143380008637905
    },
    {
      "id": 102,
      "seek": 40964,
      "start": 425.9599914550781,
      "end": 430.0,
      "text": " We just want the subject matter-correct requirements to be able to ask questions.",
      "tokens": [
        51180,
        492,
        445,
        528,
        264,
        3983,
        1871,
        12,
        19558,
        2554,
        7728,
        281,
        312,
        1075,
        281,
        1029,
        1651,
        13,
        51382
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4871031641960144,
      "compression_ratio": 1.6534653902053833,
      "no_speech_prob": 0.012143380008637905
    },
    {
      "id": 103,
      "seek": 40964,
      "start": 430.0,
      "end": 431.0799865722656,
      "text": " Then there are factories.",
      "tokens": [
        51382,
        1396,
        456,
        366,
        24813,
        13,
        51436
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4871031641960144,
      "compression_ratio": 1.6534653902053833,
      "no_speech_prob": 0.012143380008637905
    },
    {
      "id": 104,
      "seek": 40964,
      "start": 431.0799865722656,
      "end": 435.1199951171875,
      "text": " Factories generate complex value objects or aggregates.",
      "tokens": [
        51436,
        33375,
        2083,
        8460,
        3997,
        2158,
        6565,
        420,
        16743,
        1024,
        13,
        51638
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4871031641960144,
      "compression_ratio": 1.6534653902053833,
      "no_speech_prob": 0.012143380008637905
    },
    {
      "id": 105,
      "seek": 40964,
      "start": 435.1199951171875,
      "end": 436.6000061035156,
      "text": " Very similar to for patterns.",
      "tokens": [
        51638,
        4372,
        2531,
        281,
        337,
        8294,
        13,
        51712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4871031641960144,
      "compression_ratio": 1.6534653902053833,
      "no_speech_prob": 0.012143380008637905
    },
    {
      "id": 106,
      "seek": 40964,
      "start": 436.6000061035156,
      "end": 439.0400085449219,
      "text": " I don't think you need to say much about it.",
      "tokens": [
        51712,
        286,
        500,
        380,
        519,
        291,
        643,
        281,
        584,
        709,
        466,
        309,
        13,
        51834
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4871031641960144,
      "compression_ratio": 1.6534653902053833,
      "no_speech_prob": 0.012143380008637905
    },
    {
      "id": 107,
      "seek": 43904,
      "start": 439.0400085449219,
      "end": 441.7200012207031,
      "text": " If a constructor is not enough, I use a factory.",
      "tokens": [
        50364,
        759,
        257,
        47479,
        307,
        406,
        1547,
        11,
        286,
        764,
        257,
        9265,
        13,
        50498
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45316576957702637,
      "compression_ratio": 1.7867298126220703,
      "no_speech_prob": 0.05825264751911163
    },
    {
      "id": 108,
      "seek": 43904,
      "start": 441.7200012207031,
      "end": 444.20001220703125,
      "text": " And then there are services.",
      "tokens": [
        50498,
        400,
        550,
        456,
        366,
        3328,
        13,
        50622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45316576957702637,
      "compression_ratio": 1.7867298126220703,
      "no_speech_prob": 0.05825264751911163
    },
    {
      "id": 109,
      "seek": 43904,
      "start": 444.20001220703125,
      "end": 452.3599853515625,
      "text": " Services are the things where I can't use business logic in a sense in an aggregate or entities.",
      "tokens": [
        50622,
        12124,
        366,
        264,
        721,
        689,
        286,
        393,
        380,
        764,
        1606,
        9952,
        294,
        257,
        2020,
        294,
        364,
        26118,
        420,
        16667,
        13,
        51030
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45316576957702637,
      "compression_ratio": 1.7867298126220703,
      "no_speech_prob": 0.05825264751911163
    },
    {
      "id": 110,
      "seek": 43904,
      "start": 452.3599853515625,
      "end": 457.9200134277344,
      "text": " So there is business logic that is interdependent over different aggregates.",
      "tokens": [
        51030,
        407,
        456,
        307,
        1606,
        9952,
        300,
        307,
        728,
        36763,
        317,
        670,
        819,
        16743,
        1024,
        13,
        51308
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45316576957702637,
      "compression_ratio": 1.7867298126220703,
      "no_speech_prob": 0.05825264751911163
    },
    {
      "id": 111,
      "seek": 43904,
      "start": 457.9200134277344,
      "end": 461.2799987792969,
      "text": " So the transfer, for example, is something where I have two aggregates.",
      "tokens": [
        51308,
        407,
        264,
        5003,
        11,
        337,
        1365,
        11,
        307,
        746,
        689,
        286,
        362,
        732,
        16743,
        1024,
        13,
        51476
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45316576957702637,
      "compression_ratio": 1.7867298126220703,
      "no_speech_prob": 0.05825264751911163
    },
    {
      "id": 112,
      "seek": 43904,
      "start": 461.2799987792969,
      "end": 466.6400146484375,
      "text": " So now I can't assign the two accounts to an account.",
      "tokens": [
        51476,
        407,
        586,
        286,
        393,
        380,
        6269,
        264,
        732,
        9402,
        281,
        364,
        2696,
        13,
        51744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45316576957702637,
      "compression_ratio": 1.7867298126220703,
      "no_speech_prob": 0.05825264751911163
    },
    {
      "id": 113,
      "seek": 46664,
      "start": 466.6400146484375,
      "end": 470.4800109863281,
      "text": " So I'm probably going to build that into a service.",
      "tokens": [
        50364,
        407,
        286,
        478,
        1391,
        516,
        281,
        1322,
        300,
        666,
        257,
        2643,
        13,
        50556
      ],
      "temperature": 0.0,
      "avg_logprob": -0.519456148147583,
      "compression_ratio": 1.5545454025268555,
      "no_speech_prob": 0.008817789144814014
    },
    {
      "id": 114,
      "seek": 46664,
      "start": 470.4800109863281,
      "end": 474.0,
      "text": " And that makes it clear how it works.",
      "tokens": [
        50556,
        400,
        300,
        1669,
        309,
        1850,
        577,
        309,
        1985,
        13,
        50732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.519456148147583,
      "compression_ratio": 1.5545454025268555,
      "no_speech_prob": 0.008817789144814014
    },
    {
      "id": 115,
      "seek": 46664,
      "start": 474.0,
      "end": 475.20001220703125,
      "text": " I say I have some logic.",
      "tokens": [
        50732,
        286,
        584,
        286,
        362,
        512,
        9952,
        13,
        50792
      ],
      "temperature": 0.0,
      "avg_logprob": -0.519456148147583,
      "compression_ratio": 1.5545454025268555,
      "no_speech_prob": 0.008817789144814014
    },
    {
      "id": 116,
      "seek": 46664,
      "start": 475.20001220703125,
      "end": 477.6400146484375,
      "text": " I'm going to put it in one of these classes.",
      "tokens": [
        50792,
        286,
        478,
        516,
        281,
        829,
        309,
        294,
        472,
        295,
        613,
        5359,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.519456148147583,
      "compression_ratio": 1.5545454025268555,
      "no_speech_prob": 0.008817789144814014
    },
    {
      "id": 117,
      "seek": 46664,
      "start": 477.6400146484375,
      "end": 482.9599914550781,
      "text": " And it's not like entities, for example, should be logic-free.",
      "tokens": [
        50914,
        400,
        309,
        311,
        406,
        411,
        16667,
        11,
        337,
        1365,
        11,
        820,
        312,
        9952,
        12,
        10792,
        13,
        51180
      ],
      "temperature": 0.0,
      "avg_logprob": -0.519456148147583,
      "compression_ratio": 1.5545454025268555,
      "no_speech_prob": 0.008817789144814014
    },
    {
      "id": 118,
      "seek": 46664,
      "start": 482.9599914550781,
      "end": 486.20001220703125,
      "text": " So now the question is,",
      "tokens": [
        51180,
        407,
        586,
        264,
        1168,
        307,
        11,
        51342
      ],
      "temperature": 0.0,
      "avg_logprob": -0.519456148147583,
      "compression_ratio": 1.5545454025268555,
      "no_speech_prob": 0.008817789144814014
    },
    {
      "id": 119,
      "seek": 46664,
      "start": 486.20001220703125,
      "end": 491.9599914550781,
      "text": " it's something that goes through this talk.",
      "tokens": [
        51342,
        309,
        311,
        746,
        300,
        1709,
        807,
        341,
        751,
        13,
        51630
      ],
      "temperature": 0.0,
      "avg_logprob": -0.519456148147583,
      "compression_ratio": 1.5545454025268555,
      "no_speech_prob": 0.008817789144814014
    },
    {
      "id": 120,
      "seek": 46664,
      "start": 491.9599914550781,
      "end": 494.20001220703125,
      "text": " I think it's always important to name alternatives.",
      "tokens": [
        51630,
        286,
        519,
        309,
        311,
        1009,
        1021,
        281,
        1315,
        20478,
        13,
        51742
      ],
      "temperature": 0.0,
      "avg_logprob": -0.519456148147583,
      "compression_ratio": 1.5545454025268555,
      "no_speech_prob": 0.008817789144814014
    },
    {
      "id": 121,
      "seek": 49420,
      "start": 494.20001220703125,
      "end": 496.6000061035156,
      "text": " So we now have tactical domain-driven design.",
      "tokens": [
        50364,
        407,
        321,
        586,
        362,
        1846,
        349,
        804,
        9274,
        12,
        25456,
        1715,
        13,
        50484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40272587537765503,
      "compression_ratio": 1.7909090518951416,
      "no_speech_prob": 0.12537312507629395
    },
    {
      "id": 122,
      "seek": 49420,
      "start": 496.6000061035156,
      "end": 498.6400146484375,
      "text": " And now the question is,",
      "tokens": [
        50484,
        400,
        586,
        264,
        1168,
        307,
        11,
        50586
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40272587537765503,
      "compression_ratio": 1.7909090518951416,
      "no_speech_prob": 0.12537312507629395
    },
    {
      "id": 123,
      "seek": 49420,
      "start": 498.6400146484375,
      "end": 502.8800048828125,
      "text": " can I not implement tactical domain-driven design?",
      "tokens": [
        50586,
        393,
        286,
        406,
        4445,
        26323,
        9274,
        12,
        25456,
        1715,
        30,
        50798
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40272587537765503,
      "compression_ratio": 1.7909090518951416,
      "no_speech_prob": 0.12537312507629395
    },
    {
      "id": 124,
      "seek": 49420,
      "start": 502.8800048828125,
      "end": 504.760009765625,
      "text": " And one way to do that is to make it functional.",
      "tokens": [
        50798,
        400,
        472,
        636,
        281,
        360,
        300,
        307,
        281,
        652,
        309,
        11745,
        13,
        50892
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40272587537765503,
      "compression_ratio": 1.7909090518951416,
      "no_speech_prob": 0.12537312507629395
    },
    {
      "id": 125,
      "seek": 49420,
      "start": 504.760009765625,
      "end": 509.0400085449219,
      "text": " Then I have a side-effect-free functional core.",
      "tokens": [
        50892,
        1396,
        286,
        362,
        257,
        1252,
        12,
        46168,
        12,
        10792,
        11745,
        4965,
        13,
        51106
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40272587537765503,
      "compression_ratio": 1.7909090518951416,
      "no_speech_prob": 0.12537312507629395
    },
    {
      "id": 126,
      "seek": 49420,
      "start": 509.0400085449219,
      "end": 512.3200073242188,
      "text": " That means I don't have entities, I don't have aggregates.",
      "tokens": [
        51106,
        663,
        1355,
        286,
        500,
        380,
        362,
        16667,
        11,
        286,
        500,
        380,
        362,
        16743,
        1024,
        13,
        51270
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40272587537765503,
      "compression_ratio": 1.7909090518951416,
      "no_speech_prob": 0.12537312507629395
    },
    {
      "id": 127,
      "seek": 49420,
      "start": 512.3200073242188,
      "end": 517.4000244140625,
      "text": " When I change an entity, it has a side effect.",
      "tokens": [
        51270,
        1133,
        286,
        1319,
        364,
        13977,
        11,
        309,
        575,
        257,
        1252,
        1802,
        13,
        51524
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40272587537765503,
      "compression_ratio": 1.7909090518951416,
      "no_speech_prob": 0.12537312507629395
    },
    {
      "id": 128,
      "seek": 49420,
      "start": 517.4000244140625,
      "end": 519.5999755859375,
      "text": " The thing has a state.",
      "tokens": [
        51524,
        440,
        551,
        575,
        257,
        1785,
        13,
        51634
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40272587537765503,
      "compression_ratio": 1.7909090518951416,
      "no_speech_prob": 0.12537312507629395
    },
    {
      "id": 129,
      "seek": 49420,
      "start": 519.5999755859375,
      "end": 523.3200073242188,
      "text": " The account has an account state, for example.",
      "tokens": [
        51634,
        440,
        2696,
        575,
        364,
        2696,
        1785,
        11,
        337,
        1365,
        13,
        51820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40272587537765503,
      "compression_ratio": 1.7909090518951416,
      "no_speech_prob": 0.12537312507629395
    },
    {
      "id": 130,
      "seek": 52332,
      "start": 523.3200073242188,
      "end": 525.6400146484375,
      "text": " And that means this state changes.",
      "tokens": [
        50364,
        400,
        300,
        1355,
        341,
        1785,
        2962,
        13,
        50480
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41905227303504944,
      "compression_ratio": 1.7619047164916992,
      "no_speech_prob": 0.002208563731983304
    },
    {
      "id": 131,
      "seek": 52332,
      "start": 525.6400146484375,
      "end": 529.0,
      "text": " This is obviously a side effect or an effect.",
      "tokens": [
        50480,
        639,
        307,
        2745,
        257,
        1252,
        1802,
        420,
        364,
        1802,
        13,
        50648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41905227303504944,
      "compression_ratio": 1.7619047164916992,
      "no_speech_prob": 0.002208563731983304
    },
    {
      "id": 132,
      "seek": 52332,
      "start": 529.0,
      "end": 531.5999755859375,
      "text": " And with functional programming, I can't have that.",
      "tokens": [
        50648,
        400,
        365,
        11745,
        9410,
        11,
        286,
        393,
        380,
        362,
        300,
        13,
        50778
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41905227303504944,
      "compression_ratio": 1.7619047164916992,
      "no_speech_prob": 0.002208563731983304
    },
    {
      "id": 133,
      "seek": 52332,
      "start": 531.5999755859375,
      "end": 535.1199951171875,
      "text": " That means, with functional programming, I would have a core that says,",
      "tokens": [
        50778,
        663,
        1355,
        11,
        365,
        11745,
        9410,
        11,
        286,
        576,
        362,
        257,
        4965,
        300,
        1619,
        11,
        50954
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41905227303504944,
      "compression_ratio": 1.7619047164916992,
      "no_speech_prob": 0.002208563731983304
    },
    {
      "id": 134,
      "seek": 52332,
      "start": 535.1199951171875,
      "end": 540.760009765625,
      "text": " okay, I'm calculating the new account state from a set of interest.",
      "tokens": [
        50954,
        1392,
        11,
        286,
        478,
        28258,
        264,
        777,
        2696,
        1785,
        490,
        257,
        992,
        295,
        560,
        260,
        377,
        13,
        51236
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41905227303504944,
      "compression_ratio": 1.7619047164916992,
      "no_speech_prob": 0.002208563731983304
    },
    {
      "id": 135,
      "seek": 52332,
      "start": 540.760009765625,
      "end": 546.4000244140625,
      "text": " But then it's the job of the system all around",
      "tokens": [
        51236,
        583,
        550,
        309,
        311,
        264,
        1691,
        295,
        264,
        1185,
        439,
        926,
        51518
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41905227303504944,
      "compression_ratio": 1.7619047164916992,
      "no_speech_prob": 0.002208563731983304
    },
    {
      "id": 136,
      "seek": 52332,
      "start": 546.4000244140625,
      "end": 549.9199829101562,
      "text": " to ensure that this side effect is generated,",
      "tokens": [
        51518,
        281,
        5586,
        300,
        341,
        1252,
        1802,
        307,
        10833,
        11,
        51694
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41905227303504944,
      "compression_ratio": 1.7619047164916992,
      "no_speech_prob": 0.002208563731983304
    },
    {
      "id": 137,
      "seek": 52332,
      "start": 549.9199829101562,
      "end": 552.5999755859375,
      "text": " that this information is actually stored.",
      "tokens": [
        51694,
        300,
        341,
        1589,
        307,
        767,
        12187,
        13,
        51828
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41905227303504944,
      "compression_ratio": 1.7619047164916992,
      "no_speech_prob": 0.002208563731983304
    },
    {
      "id": 138,
      "seek": 55260,
      "start": 552.5999755859375,
      "end": 556.5599975585938,
      "text": " So I would have a core that says, okay, this is the new account state.",
      "tokens": [
        50364,
        407,
        286,
        576,
        362,
        257,
        4965,
        300,
        1619,
        11,
        1392,
        11,
        341,
        307,
        264,
        777,
        2696,
        1785,
        13,
        50562
      ],
      "temperature": 0.0,
      "avg_logprob": -0.439942330121994,
      "compression_ratio": 1.6420233249664307,
      "no_speech_prob": 0.027497680857777596
    },
    {
      "id": 139,
      "seek": 55260,
      "start": 556.5599975585938,
      "end": 560.6799926757812,
      "text": " And then I would have something around this core that ensures",
      "tokens": [
        50562,
        400,
        550,
        286,
        576,
        362,
        746,
        926,
        341,
        4965,
        300,
        28111,
        50768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.439942330121994,
      "compression_ratio": 1.6420233249664307,
      "no_speech_prob": 0.027497680857777596
    },
    {
      "id": 140,
      "seek": 55260,
      "start": 560.6799926757812,
      "end": 564.47998046875,
      "text": " that it is actually stored in the database.",
      "tokens": [
        50768,
        300,
        309,
        307,
        767,
        12187,
        294,
        264,
        8149,
        13,
        50958
      ],
      "temperature": 0.0,
      "avg_logprob": -0.439942330121994,
      "compression_ratio": 1.6420233249664307,
      "no_speech_prob": 0.027497680857777596
    },
    {
      "id": 141,
      "seek": 55260,
      "start": 564.47998046875,
      "end": 568.760009765625,
      "text": " I talked about this topic with Mike Sperber some time ago.",
      "tokens": [
        50958,
        286,
        2825,
        466,
        341,
        4829,
        365,
        6602,
        318,
        610,
        607,
        512,
        565,
        2057,
        13,
        51172
      ],
      "temperature": 0.0,
      "avg_logprob": -0.439942330121994,
      "compression_ratio": 1.6420233249664307,
      "no_speech_prob": 0.027497680857777596
    },
    {
      "id": 142,
      "seek": 55260,
      "start": 568.760009765625,
      "end": 570.2000122070312,
      "text": " In fact, that was more than a year ago.",
      "tokens": [
        51172,
        682,
        1186,
        11,
        300,
        390,
        544,
        813,
        257,
        1064,
        2057,
        13,
        51244
      ],
      "temperature": 0.0,
      "avg_logprob": -0.439942330121994,
      "compression_ratio": 1.6420233249664307,
      "no_speech_prob": 0.027497680857777596
    },
    {
      "id": 143,
      "seek": 55260,
      "start": 570.2000122070312,
      "end": 574.2000122070312,
      "text": " So we discussed what a functional architecture should look like.",
      "tokens": [
        51244,
        407,
        321,
        7152,
        437,
        257,
        11745,
        9482,
        820,
        574,
        411,
        13,
        51444
      ],
      "temperature": 0.0,
      "avg_logprob": -0.439942330121994,
      "compression_ratio": 1.6420233249664307,
      "no_speech_prob": 0.027497680857777596
    },
    {
      "id": 144,
      "seek": 55260,
      "start": 574.2000122070312,
      "end": 577.4400024414062,
      "text": " Mike is someone who has dealt with it a lot.",
      "tokens": [
        51444,
        6602,
        307,
        1580,
        567,
        575,
        15991,
        365,
        309,
        257,
        688,
        13,
        51606
      ],
      "temperature": 0.0,
      "avg_logprob": -0.439942330121994,
      "compression_ratio": 1.6420233249664307,
      "no_speech_prob": 0.027497680857777596
    },
    {
      "id": 145,
      "seek": 55260,
      "start": 577.4400024414062,
      "end": 580.0,
      "text": " We looked at the ISRQB example task.",
      "tokens": [
        51606,
        492,
        2956,
        412,
        264,
        6205,
        49,
        48,
        33,
        1365,
        5633,
        13,
        51734
      ],
      "temperature": 0.0,
      "avg_logprob": -0.439942330121994,
      "compression_ratio": 1.6420233249664307,
      "no_speech_prob": 0.027497680857777596
    },
    {
      "id": 146,
      "seek": 58000,
      "start": 580.0,
      "end": 583.719970703125,
      "text": " So you can talk about this topic in detail.",
      "tokens": [
        50364,
        407,
        291,
        393,
        751,
        466,
        341,
        4829,
        294,
        2607,
        13,
        50550
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3724322021007538,
      "compression_ratio": 1.547619104385376,
      "no_speech_prob": 0.11373455822467804
    },
    {
      "id": 147,
      "seek": 58000,
      "start": 583.719970703125,
      "end": 588.6400146484375,
      "text": " What other alternatives are there when I have less complex systems?",
      "tokens": [
        50550,
        708,
        661,
        20478,
        366,
        456,
        562,
        286,
        362,
        1570,
        3997,
        3652,
        30,
        50796
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3724322021007538,
      "compression_ratio": 1.547619104385376,
      "no_speech_prob": 0.11373455822467804
    },
    {
      "id": 148,
      "seek": 58000,
      "start": 588.6400146484375,
      "end": 594.0,
      "text": " So the premise for this set of patterns is,",
      "tokens": [
        50796,
        407,
        264,
        22045,
        337,
        341,
        992,
        295,
        8294,
        307,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3724322021007538,
      "compression_ratio": 1.547619104385376,
      "no_speech_prob": 0.11373455822467804
    },
    {
      "id": 149,
      "seek": 58000,
      "start": 594.0,
      "end": 598.0399780273438,
      "text": " I have complex business logic.",
      "tokens": [
        51064,
        286,
        362,
        3997,
        1606,
        9952,
        13,
        51266
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3724322021007538,
      "compression_ratio": 1.547619104385376,
      "no_speech_prob": 0.11373455822467804
    },
    {
      "id": 150,
      "seek": 58000,
      "start": 598.0399780273438,
      "end": 602.760009765625,
      "text": " And if I have a system that copies data from A to B",
      "tokens": [
        51266,
        400,
        498,
        286,
        362,
        257,
        1185,
        300,
        14341,
        1412,
        490,
        316,
        281,
        363,
        51502
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3724322021007538,
      "compression_ratio": 1.547619104385376,
      "no_speech_prob": 0.11373455822467804
    },
    {
      "id": 151,
      "seek": 58000,
      "start": 602.760009765625,
      "end": 609.4000244140625,
      "text": " and I'm building a repository and aggregates and entities and value objects and so on,",
      "tokens": [
        51502,
        293,
        286,
        478,
        2390,
        257,
        25841,
        293,
        623,
        33248,
        70,
        1024,
        293,
        16667,
        293,
        2158,
        6565,
        293,
        370,
        322,
        11,
        51834
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3724322021007538,
      "compression_ratio": 1.547619104385376,
      "no_speech_prob": 0.11373455822467804
    },
    {
      "id": 152,
      "seek": 60940,
      "start": 609.4000244140625,
      "end": 611.7999877929688,
      "text": " then the question is whether that's really smart.",
      "tokens": [
        50364,
        550,
        264,
        1168,
        307,
        1968,
        300,
        311,
        534,
        4069,
        13,
        50484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3943486213684082,
      "compression_ratio": 1.6992480754852295,
      "no_speech_prob": 0.0023414120078086853
    },
    {
      "id": 153,
      "seek": 60940,
      "start": 611.7999877929688,
      "end": 615.719970703125,
      "text": " Because I invest a lot of effort in building these things.",
      "tokens": [
        50484,
        1436,
        286,
        1963,
        257,
        688,
        295,
        4630,
        294,
        2390,
        613,
        721,
        13,
        50680
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3943486213684082,
      "compression_ratio": 1.6992480754852295,
      "no_speech_prob": 0.0023414120078086853
    },
    {
      "id": 154,
      "seek": 60940,
      "start": 615.719970703125,
      "end": 621.3599853515625,
      "text": " But the advantage that I have object-oriented possibilities to structure my logic,",
      "tokens": [
        50680,
        583,
        264,
        5002,
        300,
        286,
        362,
        2657,
        12,
        27414,
        12178,
        281,
        3877,
        452,
        9952,
        11,
        50962
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3943486213684082,
      "compression_ratio": 1.6992480754852295,
      "no_speech_prob": 0.0023414120078086853
    },
    {
      "id": 155,
      "seek": 60940,
      "start": 621.3599853515625,
      "end": 626.1599731445312,
      "text": " I don't have that much of that, because I don't have any logic.",
      "tokens": [
        50962,
        286,
        500,
        380,
        362,
        300,
        709,
        295,
        300,
        11,
        570,
        286,
        500,
        380,
        362,
        604,
        9952,
        13,
        51202
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3943486213684082,
      "compression_ratio": 1.6992480754852295,
      "no_speech_prob": 0.0023414120078086853
    },
    {
      "id": 156,
      "seek": 60940,
      "start": 626.1599731445312,
      "end": 630.6799926757812,
      "text": " And for that there is an alternative, something like a transaction script.",
      "tokens": [
        51202,
        400,
        337,
        300,
        456,
        307,
        364,
        8535,
        11,
        746,
        411,
        257,
        14425,
        5755,
        13,
        51428
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3943486213684082,
      "compression_ratio": 1.6992480754852295,
      "no_speech_prob": 0.0023414120078086853
    },
    {
      "id": 157,
      "seek": 60940,
      "start": 630.6799926757812,
      "end": 632.7999877929688,
      "text": " So a transaction script says,",
      "tokens": [
        51428,
        407,
        257,
        14425,
        5755,
        1619,
        11,
        51534
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3943486213684082,
      "compression_ratio": 1.6992480754852295,
      "no_speech_prob": 0.0023414120078086853
    },
    {
      "id": 158,
      "seek": 60940,
      "start": 632.7999877929688,
      "end": 636.6400146484375,
      "text": " I process a request from the presentation layer directly",
      "tokens": [
        51534,
        286,
        1399,
        257,
        5308,
        490,
        264,
        5860,
        4583,
        3838,
        51726
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3943486213684082,
      "compression_ratio": 1.6992480754852295,
      "no_speech_prob": 0.0023414120078086853
    },
    {
      "id": 159,
      "seek": 60940,
      "start": 636.6400146484375,
      "end": 638.5599975585938,
      "text": " and have a database code in there.",
      "tokens": [
        51726,
        293,
        362,
        257,
        8149,
        3089,
        294,
        456,
        13,
        51822
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3943486213684082,
      "compression_ratio": 1.6992480754852295,
      "no_speech_prob": 0.0023414120078086853
    },
    {
      "id": 160,
      "seek": 63856,
      "start": 638.5599975585938,
      "end": 642.239990234375,
      "text": " So that means I have an HTTP request that comes into my system",
      "tokens": [
        50364,
        407,
        300,
        1355,
        286,
        362,
        364,
        33283,
        5308,
        300,
        1487,
        666,
        452,
        1185,
        50548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4075510799884796,
      "compression_ratio": 1.60326087474823,
      "no_speech_prob": 0.03737938776612282
    },
    {
      "id": 161,
      "seek": 63856,
      "start": 642.239990234375,
      "end": 647.52001953125,
      "text": " and then I say, insert into my great database table some value.",
      "tokens": [
        50548,
        293,
        550,
        286,
        584,
        11,
        8969,
        666,
        452,
        869,
        8149,
        3199,
        512,
        2158,
        13,
        50812
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4075510799884796,
      "compression_ratio": 1.60326087474823,
      "no_speech_prob": 0.03737938776612282
    },
    {
      "id": 162,
      "seek": 63856,
      "start": 647.52001953125,
      "end": 650.5999755859375,
      "text": " And something similar is a table model, where I say,",
      "tokens": [
        50812,
        400,
        746,
        2531,
        307,
        257,
        3199,
        2316,
        11,
        689,
        286,
        584,
        11,
        50966
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4075510799884796,
      "compression_ratio": 1.60326087474823,
      "no_speech_prob": 0.03737938776612282
    },
    {
      "id": 163,
      "seek": 63856,
      "start": 650.5999755859375,
      "end": 659.47998046875,
      "text": " there is an object that represents a database table.",
      "tokens": [
        50966,
        456,
        307,
        364,
        2657,
        300,
        8855,
        257,
        8149,
        3199,
        13,
        51410
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4075510799884796,
      "compression_ratio": 1.60326087474823,
      "no_speech_prob": 0.03737938776612282
    },
    {
      "id": 164,
      "seek": 63856,
      "start": 659.47998046875,
      "end": 665.8400268554688,
      "text": " And that has the advantage that I don't have all these layers.",
      "tokens": [
        51410,
        400,
        300,
        575,
        264,
        5002,
        300,
        286,
        500,
        380,
        362,
        439,
        613,
        7914,
        13,
        51728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4075510799884796,
      "compression_ratio": 1.60326087474823,
      "no_speech_prob": 0.03737938776612282
    },
    {
      "id": 165,
      "seek": 66584,
      "start": 665.8400268554688,
      "end": 670.8800048828125,
      "text": " And I can relatively easily say, okay, if that comes from the HTTP layer,",
      "tokens": [
        50364,
        400,
        286,
        393,
        7226,
        3612,
        584,
        11,
        1392,
        11,
        498,
        300,
        1487,
        490,
        264,
        33283,
        4583,
        11,
        50616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46460920572280884,
      "compression_ratio": 1.639004111289978,
      "no_speech_prob": 0.022976558655500412
    },
    {
      "id": 166,
      "seek": 66584,
      "start": 670.8800048828125,
      "end": 673.7999877929688,
      "text": " then I change exactly that in the database.",
      "tokens": [
        50616,
        550,
        286,
        1319,
        2293,
        300,
        294,
        264,
        8149,
        13,
        50762
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46460920572280884,
      "compression_ratio": 1.639004111289978,
      "no_speech_prob": 0.022976558655500412
    },
    {
      "id": 167,
      "seek": 66584,
      "start": 673.7999877929688,
      "end": 676.0,
      "text": " And I see that at a glance.",
      "tokens": [
        50762,
        400,
        286,
        536,
        300,
        412,
        257,
        21094,
        13,
        50872
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46460920572280884,
      "compression_ratio": 1.639004111289978,
      "no_speech_prob": 0.022976558655500412
    },
    {
      "id": 168,
      "seek": 66584,
      "start": 676.0,
      "end": 679.9600219726562,
      "text": " Of course, that goes massively wrong",
      "tokens": [
        50872,
        2720,
        1164,
        11,
        300,
        1709,
        29379,
        2085,
        51070
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46460920572280884,
      "compression_ratio": 1.639004111289978,
      "no_speech_prob": 0.022976558655500412
    },
    {
      "id": 169,
      "seek": 66584,
      "start": 679.9600219726562,
      "end": 683.9199829101562,
      "text": " if I have complex logic there, because I would have to rub it in somehow.",
      "tokens": [
        51070,
        498,
        286,
        362,
        3997,
        9952,
        456,
        11,
        570,
        286,
        576,
        362,
        281,
        5915,
        309,
        294,
        6063,
        13,
        51268
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46460920572280884,
      "compression_ratio": 1.639004111289978,
      "no_speech_prob": 0.022976558655500412
    },
    {
      "id": 170,
      "seek": 66584,
      "start": 683.9199829101562,
      "end": 686.8400268554688,
      "text": " And that doesn't make much sense.",
      "tokens": [
        51268,
        400,
        300,
        1177,
        380,
        652,
        709,
        2020,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46460920572280884,
      "compression_ratio": 1.639004111289978,
      "no_speech_prob": 0.022976558655500412
    },
    {
      "id": 171,
      "seek": 66584,
      "start": 686.8400268554688,
      "end": 693.47998046875,
      "text": " Here, for example, I also have the advantage that I can now optimize the database requests, for example.",
      "tokens": [
        51414,
        1692,
        11,
        337,
        1365,
        11,
        286,
        611,
        362,
        264,
        5002,
        300,
        286,
        393,
        586,
        19719,
        264,
        8149,
        12475,
        11,
        337,
        1365,
        13,
        51746
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46460920572280884,
      "compression_ratio": 1.639004111289978,
      "no_speech_prob": 0.022976558655500412
    },
    {
      "id": 172,
      "seek": 69348,
      "start": 693.47998046875,
      "end": 696.9199829101562,
      "text": " I can now build in hand-optimized queries",
      "tokens": [
        50364,
        286,
        393,
        586,
        1322,
        294,
        1011,
        12,
        5747,
        332,
        1602,
        24109,
        50536
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46833235025405884,
      "compression_ratio": 1.6286920309066772,
      "no_speech_prob": 0.116684690117836
    },
    {
      "id": 173,
      "seek": 69348,
      "start": 696.9199829101562,
      "end": 700.8400268554688,
      "text": " and construct some great things there",
      "tokens": [
        50536,
        293,
        7690,
        512,
        869,
        721,
        456,
        50732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46833235025405884,
      "compression_ratio": 1.6286920309066772,
      "no_speech_prob": 0.116684690117836
    },
    {
      "id": 174,
      "seek": 69348,
      "start": 700.8400268554688,
      "end": 704.0800170898438,
      "text": " without having to go to a lot of effort.",
      "tokens": [
        50732,
        1553,
        1419,
        281,
        352,
        281,
        257,
        688,
        295,
        4630,
        13,
        50894
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46833235025405884,
      "compression_ratio": 1.6286920309066772,
      "no_speech_prob": 0.116684690117836
    },
    {
      "id": 175,
      "seek": 69348,
      "start": 705.52001953125,
      "end": 707.52001953125,
      "text": " Let's go through the example.",
      "tokens": [
        50966,
        961,
        311,
        352,
        807,
        264,
        1365,
        13,
        51066
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46833235025405884,
      "compression_ratio": 1.6286920309066772,
      "no_speech_prob": 0.116684690117836
    },
    {
      "id": 176,
      "seek": 69348,
      "start": 707.52001953125,
      "end": 711.0,
      "text": " The example we had was an e-commerce system.",
      "tokens": [
        51066,
        440,
        1365,
        321,
        632,
        390,
        364,
        308,
        12,
        26926,
        1185,
        13,
        51240
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46833235025405884,
      "compression_ratio": 1.6286920309066772,
      "no_speech_prob": 0.116684690117836
    },
    {
      "id": 177,
      "seek": 69348,
      "start": 711.0,
      "end": 714.7999877929688,
      "text": " That means we would now take one of these building contexts out.",
      "tokens": [
        51240,
        663,
        1355,
        321,
        576,
        586,
        747,
        472,
        295,
        613,
        2390,
        30628,
        484,
        13,
        51430
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46833235025405884,
      "compression_ratio": 1.6286920309066772,
      "no_speech_prob": 0.116684690117836
    },
    {
      "id": 178,
      "seek": 69348,
      "start": 714.7999877929688,
      "end": 717.2000122070312,
      "text": " I have now taken out the building context with the delivery.",
      "tokens": [
        51430,
        286,
        362,
        586,
        2726,
        484,
        264,
        2390,
        4319,
        365,
        264,
        8982,
        13,
        51550
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46833235025405884,
      "compression_ratio": 1.6286920309066772,
      "no_speech_prob": 0.116684690117836
    },
    {
      "id": 179,
      "seek": 69348,
      "start": 717.2000122070312,
      "end": 721.5599975585938,
      "text": " So that's the thing that says, okay, I want to send the clicker.",
      "tokens": [
        51550,
        407,
        300,
        311,
        264,
        551,
        300,
        1619,
        11,
        1392,
        11,
        286,
        528,
        281,
        2845,
        264,
        2052,
        260,
        13,
        51768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46833235025405884,
      "compression_ratio": 1.6286920309066772,
      "no_speech_prob": 0.116684690117836
    },
    {
      "id": 180,
      "seek": 72156,
      "start": 721.5599975585938,
      "end": 724.3599853515625,
      "text": " How do I actually send this clicker?",
      "tokens": [
        50364,
        1012,
        360,
        286,
        767,
        2845,
        341,
        2052,
        260,
        30,
        50504
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4099266827106476,
      "compression_ratio": 1.668161392211914,
      "no_speech_prob": 0.02709641121327877
    },
    {
      "id": 181,
      "seek": 72156,
      "start": 724.3599853515625,
      "end": 728.9199829101562,
      "text": " Or if I have something cheap, the iPhone, that's even more expensive.",
      "tokens": [
        50504,
        1610,
        498,
        286,
        362,
        746,
        7084,
        11,
        264,
        7252,
        11,
        300,
        311,
        754,
        544,
        5124,
        13,
        50732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4099266827106476,
      "compression_ratio": 1.668161392211914,
      "no_speech_prob": 0.02709641121327877
    },
    {
      "id": 182,
      "seek": 72156,
      "start": 728.9199829101562,
      "end": 733.2000122070312,
      "text": " I might want to send that to the insurance company again, and so on and so on.",
      "tokens": [
        50732,
        286,
        1062,
        528,
        281,
        2845,
        300,
        281,
        264,
        7214,
        2237,
        797,
        11,
        293,
        370,
        322,
        293,
        370,
        322,
        13,
        50946
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4099266827106476,
      "compression_ratio": 1.668161392211914,
      "no_speech_prob": 0.02709641121327877
    },
    {
      "id": 183,
      "seek": 72156,
      "start": 733.2000122070312,
      "end": 738.0800170898438,
      "text": " And that's what I want to decide here now.",
      "tokens": [
        50946,
        400,
        300,
        311,
        437,
        286,
        528,
        281,
        4536,
        510,
        586,
        13,
        51190
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4099266827106476,
      "compression_ratio": 1.668161392211914,
      "no_speech_prob": 0.02709641121327877
    },
    {
      "id": 184,
      "seek": 72156,
      "start": 738.0800170898438,
      "end": 742.1599731445312,
      "text": " That means I have some logic and start now and say, okay,",
      "tokens": [
        51190,
        663,
        1355,
        286,
        362,
        512,
        9952,
        293,
        722,
        586,
        293,
        584,
        11,
        1392,
        11,
        51394
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4099266827106476,
      "compression_ratio": 1.668161392211914,
      "no_speech_prob": 0.02709641121327877
    },
    {
      "id": 185,
      "seek": 72156,
      "start": 742.1599731445312,
      "end": 745.7999877929688,
      "text": " I have an entity here, so I have a package.",
      "tokens": [
        51394,
        286,
        362,
        364,
        13977,
        510,
        11,
        370,
        286,
        362,
        257,
        7372,
        13,
        51576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4099266827106476,
      "compression_ratio": 1.668161392211914,
      "no_speech_prob": 0.02709641121327877
    },
    {
      "id": 186,
      "seek": 72156,
      "start": 745.7999877929688,
      "end": 748.7999877929688,
      "text": " I have an address, that's a value object.",
      "tokens": [
        51576,
        286,
        362,
        364,
        2985,
        11,
        300,
        311,
        257,
        2158,
        2657,
        13,
        51726
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4099266827106476,
      "compression_ratio": 1.668161392211914,
      "no_speech_prob": 0.02709641121327877
    },
    {
      "id": 187,
      "seek": 74880,
      "start": 749.4000244140625,
      "end": 753.5599975585938,
      "text": " So you can see it from Utrechtstrasse, where the Swaglab GmbH is located.",
      "tokens": [
        50394,
        407,
        291,
        393,
        536,
        309,
        490,
        624,
        3599,
        4701,
        372,
        3906,
        405,
        11,
        689,
        264,
        3926,
        559,
        44990,
        460,
        2504,
        39,
        307,
        6870,
        13,
        50602
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5002815127372742,
      "compression_ratio": 1.5590908527374268,
      "no_speech_prob": 0.005297147668898106
    },
    {
      "id": 188,
      "seek": 74880,
      "start": 753.5599975585938,
      "end": 758.7999877929688,
      "text": " That's a value, that's not an identity in this case.",
      "tokens": [
        50602,
        663,
        311,
        257,
        2158,
        11,
        300,
        311,
        406,
        364,
        6575,
        294,
        341,
        1389,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5002815127372742,
      "compression_ratio": 1.5590908527374268,
      "no_speech_prob": 0.005297147668898106
    },
    {
      "id": 189,
      "seek": 74880,
      "start": 758.7999877929688,
      "end": 762.0,
      "text": " And I have that together in such a delivery.",
      "tokens": [
        50864,
        400,
        286,
        362,
        300,
        1214,
        294,
        1270,
        257,
        8982,
        13,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5002815127372742,
      "compression_ratio": 1.5590908527374268,
      "no_speech_prob": 0.005297147668898106
    },
    {
      "id": 190,
      "seek": 74880,
      "start": 762.0,
      "end": 767.280029296875,
      "text": " So that means in this delivery it says, this package goes to this address.",
      "tokens": [
        51024,
        407,
        300,
        1355,
        294,
        341,
        8982,
        309,
        1619,
        11,
        341,
        7372,
        1709,
        281,
        341,
        2985,
        13,
        51288
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5002815127372742,
      "compression_ratio": 1.5590908527374268,
      "no_speech_prob": 0.005297147668898106
    },
    {
      "id": 191,
      "seek": 74880,
      "start": 767.280029296875,
      "end": 770.0,
      "text": " Maybe there's some information in there like,",
      "tokens": [
        51288,
        2704,
        456,
        311,
        512,
        1589,
        294,
        456,
        411,
        11,
        51424
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5002815127372742,
      "compression_ratio": 1.5590908527374268,
      "no_speech_prob": 0.005297147668898106
    },
    {
      "id": 192,
      "seek": 74880,
      "start": 770.0,
      "end": 773.8400268554688,
      "text": " what goods are actually in the respective package?",
      "tokens": [
        51424,
        437,
        10179,
        366,
        767,
        294,
        264,
        23649,
        7372,
        30,
        51616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5002815127372742,
      "compression_ratio": 1.5590908527374268,
      "no_speech_prob": 0.005297147668898106
    },
    {
      "id": 193,
      "seek": 77384,
      "start": 774.239990234375,
      "end": 778.4000244140625,
      "text": " That's how I assume it now, to build complicated,",
      "tokens": [
        50384,
        663,
        311,
        577,
        286,
        6552,
        309,
        586,
        11,
        281,
        1322,
        6179,
        11,
        50592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4721917510032654,
      "compression_ratio": 1.54450261592865,
      "no_speech_prob": 0.14504387974739075
    },
    {
      "id": 194,
      "seek": 77384,
      "start": 778.4000244140625,
      "end": 780.4000244140625,
      "text": " that I need a factory for that.",
      "tokens": [
        50592,
        300,
        286,
        643,
        257,
        9265,
        337,
        300,
        13,
        50692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4721917510032654,
      "compression_ratio": 1.54450261592865,
      "no_speech_prob": 0.14504387974739075
    },
    {
      "id": 195,
      "seek": 77384,
      "start": 780.4000244140625,
      "end": 785.280029296875,
      "text": " And I also have such a delivery repository,",
      "tokens": [
        50692,
        400,
        286,
        611,
        362,
        1270,
        257,
        8982,
        25841,
        11,
        50936
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4721917510032654,
      "compression_ratio": 1.54450261592865,
      "no_speech_prob": 0.14504387974739075
    },
    {
      "id": 196,
      "seek": 77384,
      "start": 785.280029296875,
      "end": 791.719970703125,
      "text": " where I can now say, give me a package for this customer.",
      "tokens": [
        50936,
        689,
        286,
        393,
        586,
        584,
        11,
        976,
        385,
        257,
        7372,
        337,
        341,
        5474,
        13,
        51258
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4721917510032654,
      "compression_ratio": 1.54450261592865,
      "no_speech_prob": 0.14504387974739075
    },
    {
      "id": 197,
      "seek": 77384,
      "start": 791.719970703125,
      "end": 794.7999877929688,
      "text": " So that would be something that I might be able to motivate in question,",
      "tokens": [
        51258,
        407,
        300,
        576,
        312,
        746,
        300,
        286,
        1062,
        312,
        1075,
        281,
        28497,
        294,
        1168,
        11,
        51412
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4721917510032654,
      "compression_ratio": 1.54450261592865,
      "no_speech_prob": 0.14504387974739075
    },
    {
      "id": 198,
      "seek": 77384,
      "start": 794.7999877929688,
      "end": 800.239990234375,
      "text": " that I would like to have in this car.",
      "tokens": [
        51412,
        300,
        286,
        576,
        411,
        281,
        362,
        294,
        341,
        1032,
        13,
        51684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4721917510032654,
      "compression_ratio": 1.54450261592865,
      "no_speech_prob": 0.14504387974739075
    },
    {
      "id": 199,
      "seek": 80024,
      "start": 800.239990234375,
      "end": 804.1199951171875,
      "text": " That would be something that I might be able to motivate in question, and so on and so on.",
      "tokens": [
        50364,
        663,
        576,
        312,
        746,
        300,
        286,
        1062,
        312,
        1075,
        281,
        28497,
        294,
        1168,
        11,
        293,
        370,
        322,
        293,
        370,
        322,
        13,
        50558
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5529729127883911,
      "compression_ratio": 1.6041666269302368,
      "no_speech_prob": 0.18087013065814972
    },
    {
      "id": 200,
      "seek": 80024,
      "start": 806.1199951171875,
      "end": 809.0,
      "text": " Alexander is writing, I'm a big fan of DDD,",
      "tokens": [
        50658,
        14845,
        307,
        3579,
        11,
        286,
        478,
        257,
        955,
        3429,
        295,
        413,
        20818,
        11,
        50802
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5529729127883911,
      "compression_ratio": 1.6041666269302368,
      "no_speech_prob": 0.18087013065814972
    },
    {
      "id": 201,
      "seek": 80024,
      "start": 809.0,
      "end": 811.3200073242188,
      "text": " and I think it's way too little that people talk about,",
      "tokens": [
        50802,
        293,
        286,
        519,
        309,
        311,
        636,
        886,
        707,
        300,
        561,
        751,
        466,
        11,
        50918
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5529729127883911,
      "compression_ratio": 1.6041666269302368,
      "no_speech_prob": 0.18087013065814972
    },
    {
      "id": 202,
      "seek": 80024,
      "start": 811.3200073242188,
      "end": 812.9600219726562,
      "text": " where you shouldn't use DDD.",
      "tokens": [
        50918,
        689,
        291,
        4659,
        380,
        764,
        413,
        20818,
        13,
        51000
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5529729127883911,
      "compression_ratio": 1.6041666269302368,
      "no_speech_prob": 0.18087013065814972
    },
    {
      "id": 203,
      "seek": 80024,
      "start": 812.9600219726562,
      "end": 814.719970703125,
      "text": " Good that it was mentioned here.",
      "tokens": [
        51000,
        2205,
        300,
        309,
        390,
        2835,
        510,
        13,
        51088
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5529729127883911,
      "compression_ratio": 1.6041666269302368,
      "no_speech_prob": 0.18087013065814972
    },
    {
      "id": 204,
      "seek": 80024,
      "start": 814.719970703125,
      "end": 816.4400024414062,
      "text": " Exactly, thank you very much.",
      "tokens": [
        51088,
        7587,
        11,
        1309,
        291,
        588,
        709,
        13,
        51174
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5529729127883911,
      "compression_ratio": 1.6041666269302368,
      "no_speech_prob": 0.18087013065814972
    },
    {
      "id": 205,
      "seek": 80024,
      "start": 818.0800170898438,
      "end": 821.7999877929688,
      "text": " Another actual gap that I can have now is, for example, a customer.",
      "tokens": [
        51256,
        3996,
        3539,
        7417,
        300,
        286,
        393,
        362,
        586,
        307,
        11,
        337,
        1365,
        11,
        257,
        5474,
        13,
        51442
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5529729127883911,
      "compression_ratio": 1.6041666269302368,
      "no_speech_prob": 0.18087013065814972
    },
    {
      "id": 206,
      "seek": 80024,
      "start": 821.7999877929688,
      "end": 824.6799926757812,
      "text": " And I would have some information there now.",
      "tokens": [
        51442,
        400,
        286,
        576,
        362,
        512,
        1589,
        456,
        586,
        13,
        51586
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5529729127883911,
      "compression_ratio": 1.6041666269302368,
      "no_speech_prob": 0.18087013065814972
    },
    {
      "id": 207,
      "seek": 80024,
      "start": 824.6799926757812,
      "end": 827.8800048828125,
      "text": " Maybe he sent me a set of addresses, multiple things,",
      "tokens": [
        51586,
        2704,
        415,
        2279,
        385,
        257,
        992,
        295,
        16862,
        11,
        3866,
        721,
        11,
        51746
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5529729127883911,
      "compression_ratio": 1.6041666269302368,
      "no_speech_prob": 0.18087013065814972
    },
    {
      "id": 208,
      "seek": 80024,
      "start": 827.8800048828125,
      "end": 829.1599731445312,
      "text": " or whatever.",
      "tokens": [
        51746,
        420,
        2035,
        13,
        51810
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5529729127883911,
      "compression_ratio": 1.6041666269302368,
      "no_speech_prob": 0.18087013065814972
    },
    {
      "id": 209,
      "seek": 82916,
      "start": 829.1599731445312,
      "end": 831.280029296875,
      "text": " But then I would have a service here that says,",
      "tokens": [
        50364,
        583,
        550,
        286,
        576,
        362,
        257,
        2643,
        510,
        300,
        1619,
        11,
        50470
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43349531292915344,
      "compression_ratio": 1.8461538553237915,
      "no_speech_prob": 0.02382255531847477
    },
    {
      "id": 210,
      "seek": 82916,
      "start": 831.280029296875,
      "end": 834.52001953125,
      "text": " okay, I'm just scheduling a delivery.",
      "tokens": [
        50470,
        1392,
        11,
        286,
        478,
        445,
        29055,
        257,
        8982,
        13,
        50632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43349531292915344,
      "compression_ratio": 1.8461538553237915,
      "no_speech_prob": 0.02382255531847477
    },
    {
      "id": 211,
      "seek": 82916,
      "start": 834.52001953125,
      "end": 838.5599975585938,
      "text": " So I say, for this customer,",
      "tokens": [
        50632,
        407,
        286,
        584,
        11,
        337,
        341,
        5474,
        11,
        50834
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43349531292915344,
      "compression_ratio": 1.8461538553237915,
      "no_speech_prob": 0.02382255531847477
    },
    {
      "id": 212,
      "seek": 82916,
      "start": 838.5599975585938,
      "end": 841.5999755859375,
      "text": " I would like to have this delivery somehow.",
      "tokens": [
        50834,
        286,
        576,
        411,
        281,
        362,
        341,
        8982,
        6063,
        13,
        50986
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43349531292915344,
      "compression_ratio": 1.8461538553237915,
      "no_speech_prob": 0.02382255531847477
    },
    {
      "id": 213,
      "seek": 82916,
      "start": 841.5999755859375,
      "end": 845.47998046875,
      "text": " And that means, this thing then ensures that these deliveries may arise,",
      "tokens": [
        50986,
        400,
        300,
        1355,
        11,
        341,
        551,
        550,
        28111,
        300,
        613,
        46448,
        815,
        20288,
        11,
        51180
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43349531292915344,
      "compression_ratio": 1.8461538553237915,
      "no_speech_prob": 0.02382255531847477
    },
    {
      "id": 214,
      "seek": 82916,
      "start": 845.47998046875,
      "end": 847.1599731445312,
      "text": " needs access to the customer.",
      "tokens": [
        51180,
        2203,
        2105,
        281,
        264,
        5474,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43349531292915344,
      "compression_ratio": 1.8461538553237915,
      "no_speech_prob": 0.02382255531847477
    },
    {
      "id": 215,
      "seek": 82916,
      "start": 847.1599731445312,
      "end": 850.4000244140625,
      "text": " So now I can hardly give it to the customer or the delivery.",
      "tokens": [
        51264,
        407,
        586,
        286,
        393,
        13572,
        976,
        309,
        281,
        264,
        5474,
        420,
        264,
        8982,
        13,
        51426
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43349531292915344,
      "compression_ratio": 1.8461538553237915,
      "no_speech_prob": 0.02382255531847477
    },
    {
      "id": 216,
      "seek": 82916,
      "start": 850.4000244140625,
      "end": 852.3200073242188,
      "text": " The delivery would have things like,",
      "tokens": [
        51426,
        440,
        8982,
        576,
        362,
        721,
        411,
        11,
        51522
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43349531292915344,
      "compression_ratio": 1.8461538553237915,
      "no_speech_prob": 0.02382255531847477
    },
    {
      "id": 217,
      "seek": 82916,
      "start": 852.3200073242188,
      "end": 854.0800170898438,
      "text": " tell me what your value is,",
      "tokens": [
        51522,
        980,
        385,
        437,
        428,
        2158,
        307,
        11,
        51610
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43349531292915344,
      "compression_ratio": 1.8461538553237915,
      "no_speech_prob": 0.02382255531847477
    },
    {
      "id": 218,
      "seek": 82916,
      "start": 854.0800170898438,
      "end": 856.7999877929688,
      "text": " tell me if you're insured, things like that.",
      "tokens": [
        51610,
        980,
        385,
        498,
        291,
        434,
        1028,
        3831,
        11,
        721,
        411,
        300,
        13,
        51746
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43349531292915344,
      "compression_ratio": 1.8461538553237915,
      "no_speech_prob": 0.02382255531847477
    },
    {
      "id": 219,
      "seek": 85680,
      "start": 857.6400146484375,
      "end": 862.4000244140625,
      "text": " And this general logic would now be in such a service.",
      "tokens": [
        50406,
        400,
        341,
        2674,
        9952,
        576,
        586,
        312,
        294,
        1270,
        257,
        2643,
        13,
        50644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4465191066265106,
      "compression_ratio": 1.625,
      "no_speech_prob": 0.009358640760183334
    },
    {
      "id": 220,
      "seek": 85680,
      "start": 862.4000244140625,
      "end": 864.7999877929688,
      "text": " And I still have such an event here.",
      "tokens": [
        50644,
        400,
        286,
        920,
        362,
        1270,
        364,
        2280,
        510,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4465191066265106,
      "compression_ratio": 1.625,
      "no_speech_prob": 0.009358640760183334
    },
    {
      "id": 221,
      "seek": 85680,
      "start": 864.7999877929688,
      "end": 867.4000244140625,
      "text": " The delivery has somehow been scheduled.",
      "tokens": [
        50764,
        440,
        8982,
        575,
        6063,
        668,
        15678,
        13,
        50894
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4465191066265106,
      "compression_ratio": 1.625,
      "no_speech_prob": 0.009358640760183334
    },
    {
      "id": 222,
      "seek": 85680,
      "start": 867.4000244140625,
      "end": 868.4000244140625,
      "text": " That means, I have now said,",
      "tokens": [
        50894,
        663,
        1355,
        11,
        286,
        362,
        586,
        848,
        11,
        50944
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4465191066265106,
      "compression_ratio": 1.625,
      "no_speech_prob": 0.009358640760183334
    },
    {
      "id": 223,
      "seek": 85680,
      "start": 868.4000244140625,
      "end": 870.6400146484375,
      "text": " this and that should be delivered then and then.",
      "tokens": [
        50944,
        341,
        293,
        300,
        820,
        312,
        10144,
        550,
        293,
        550,
        13,
        51056
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4465191066265106,
      "compression_ratio": 1.625,
      "no_speech_prob": 0.009358640760183334
    },
    {
      "id": 224,
      "seek": 85680,
      "start": 870.6400146484375,
      "end": 873.3599853515625,
      "text": " And now anyone can react to that,",
      "tokens": [
        51056,
        400,
        586,
        2878,
        393,
        4515,
        281,
        300,
        11,
        51192
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4465191066265106,
      "compression_ratio": 1.625,
      "no_speech_prob": 0.009358640760183334
    },
    {
      "id": 225,
      "seek": 85680,
      "start": 873.3599853515625,
      "end": 875.5599975585938,
      "text": " if this person feels like it.",
      "tokens": [
        51192,
        498,
        341,
        954,
        3417,
        411,
        309,
        13,
        51302
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4465191066265106,
      "compression_ratio": 1.625,
      "no_speech_prob": 0.009358640760183334
    },
    {
      "id": 226,
      "seek": 85680,
      "start": 876.9600219726562,
      "end": 879.1599731445312,
      "text": " I had a whole episode about it,",
      "tokens": [
        51372,
        286,
        632,
        257,
        1379,
        3500,
        466,
        309,
        11,
        51482
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4465191066265106,
      "compression_ratio": 1.625,
      "no_speech_prob": 0.009358640760183334
    },
    {
      "id": 227,
      "seek": 85680,
      "start": 879.1599731445312,
      "end": 882.8800048828125,
      "text": " where I discussed it again.",
      "tokens": [
        51482,
        689,
        286,
        7152,
        309,
        797,
        13,
        51668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4465191066265106,
      "compression_ratio": 1.625,
      "no_speech_prob": 0.009358640760183334
    },
    {
      "id": 228,
      "seek": 85680,
      "start": 882.8800048828125,
      "end": 885.6400146484375,
      "text": " It's actually from this year.",
      "tokens": [
        51668,
        467,
        311,
        767,
        490,
        341,
        1064,
        13,
        51806
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4465191066265106,
      "compression_ratio": 1.625,
      "no_speech_prob": 0.009358640760183334
    },
    {
      "id": 229,
      "seek": 88564,
      "start": 885.6799926757812,
      "end": 891.4000244140625,
      "text": " And I'm actually talking about all these concepts for an hour.",
      "tokens": [
        50366,
        400,
        286,
        478,
        767,
        1417,
        466,
        439,
        613,
        10392,
        337,
        364,
        1773,
        13,
        50652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5232563018798828,
      "compression_ratio": 1.5330188274383545,
      "no_speech_prob": 0.0021255689207464457
    },
    {
      "id": 230,
      "seek": 88564,
      "start": 891.4000244140625,
      "end": 893.4000244140625,
      "text": " And I'll go into more detail about it.",
      "tokens": [
        50652,
        400,
        286,
        603,
        352,
        666,
        544,
        2607,
        466,
        309,
        13,
        50752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5232563018798828,
      "compression_ratio": 1.5330188274383545,
      "no_speech_prob": 0.0021255689207464457
    },
    {
      "id": 231,
      "seek": 88564,
      "start": 894.52001953125,
      "end": 897.0,
      "text": " The question is how I implement that.",
      "tokens": [
        50808,
        440,
        1168,
        307,
        577,
        286,
        4445,
        300,
        13,
        50932
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5232563018798828,
      "compression_ratio": 1.5330188274383545,
      "no_speech_prob": 0.0021255689207464457
    },
    {
      "id": 232,
      "seek": 88564,
      "start": 898.0800170898438,
      "end": 901.4400024414062,
      "text": " And in a way, what we're discussing here is",
      "tokens": [
        50986,
        400,
        294,
        257,
        636,
        11,
        437,
        321,
        434,
        10850,
        510,
        307,
        51154
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5232563018798828,
      "compression_ratio": 1.5330188274383545,
      "no_speech_prob": 0.0021255689207464457
    },
    {
      "id": 233,
      "seek": 88564,
      "start": 901.4400024414062,
      "end": 903.6799926757812,
      "text": " plain old Java objects.",
      "tokens": [
        51154,
        11121,
        1331,
        10745,
        6565,
        13,
        51266
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5232563018798828,
      "compression_ratio": 1.5330188274383545,
      "no_speech_prob": 0.0021255689207464457
    },
    {
      "id": 234,
      "seek": 88564,
      "start": 903.6799926757812,
      "end": 907.8400268554688,
      "text": " So that's actually just an object-oriented construct",
      "tokens": [
        51266,
        407,
        300,
        311,
        767,
        445,
        364,
        2657,
        12,
        27414,
        7690,
        51474
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5232563018798828,
      "compression_ratio": 1.5330188274383545,
      "no_speech_prob": 0.0021255689207464457
    },
    {
      "id": 235,
      "seek": 88564,
      "start": 907.8400268554688,
      "end": 910.4400024414062,
      "text": " to somehow divide up logic.",
      "tokens": [
        51474,
        281,
        6063,
        9845,
        493,
        9952,
        13,
        51604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5232563018798828,
      "compression_ratio": 1.5330188274383545,
      "no_speech_prob": 0.0021255689207464457
    },
    {
      "id": 236,
      "seek": 88564,
      "start": 910.4400024414062,
      "end": 912.3599853515625,
      "text": " And that's why that could be enough.",
      "tokens": [
        51604,
        400,
        300,
        311,
        983,
        300,
        727,
        312,
        1547,
        13,
        51700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5232563018798828,
      "compression_ratio": 1.5330188274383545,
      "no_speech_prob": 0.0021255689207464457
    },
    {
      "id": 237,
      "seek": 91236,
      "start": 913.3599853515625,
      "end": 915.6400146484375,
      "text": " What that means is,",
      "tokens": [
        50414,
        708,
        300,
        1355,
        307,
        11,
        50528
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48499569296836853,
      "compression_ratio": 1.7422221899032593,
      "no_speech_prob": 0.01367189735174179
    },
    {
      "id": 238,
      "seek": 91236,
      "start": 915.6400146484375,
      "end": 919.0399780273438,
      "text": " I don't have any special technical requirements here.",
      "tokens": [
        50528,
        286,
        500,
        380,
        362,
        604,
        2121,
        6191,
        7728,
        510,
        13,
        50698
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48499569296836853,
      "compression_ratio": 1.7422221899032593,
      "no_speech_prob": 0.01367189735174179
    },
    {
      "id": 239,
      "seek": 91236,
      "start": 919.0399780273438,
      "end": 921.6400146484375,
      "text": " So I might still want to save entities.",
      "tokens": [
        50698,
        407,
        286,
        1062,
        920,
        528,
        281,
        3155,
        16667,
        13,
        50828
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48499569296836853,
      "compression_ratio": 1.7422221899032593,
      "no_speech_prob": 0.01367189735174179
    },
    {
      "id": 240,
      "seek": 91236,
      "start": 921.6400146484375,
      "end": 923.0800170898438,
      "text": " That means, I might have something like that,",
      "tokens": [
        50828,
        663,
        1355,
        11,
        286,
        1062,
        362,
        746,
        411,
        300,
        11,
        50900
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48499569296836853,
      "compression_ratio": 1.7422221899032593,
      "no_speech_prob": 0.01367189735174179
    },
    {
      "id": 241,
      "seek": 91236,
      "start": 923.0800170898438,
      "end": 926.4400024414062,
      "text": " that I want to have a persistence solution.",
      "tokens": [
        50900,
        300,
        286,
        528,
        281,
        362,
        257,
        37617,
        3827,
        13,
        51068
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48499569296836853,
      "compression_ratio": 1.7422221899032593,
      "no_speech_prob": 0.01367189735174179
    },
    {
      "id": 242,
      "seek": 91236,
      "start": 926.4400024414062,
      "end": 930.3200073242188,
      "text": " Maybe there's a persistence solution in the repositories,",
      "tokens": [
        51068,
        2704,
        456,
        311,
        257,
        37617,
        3827,
        294,
        264,
        22283,
        2083,
        11,
        51262
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48499569296836853,
      "compression_ratio": 1.7422221899032593,
      "no_speech_prob": 0.01367189735174179
    },
    {
      "id": 243,
      "seek": 91236,
      "start": 930.3200073242188,
      "end": 932.239990234375,
      "text": " that actually implements that.",
      "tokens": [
        51262,
        300,
        767,
        704,
        17988,
        300,
        13,
        51358
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48499569296836853,
      "compression_ratio": 1.7422221899032593,
      "no_speech_prob": 0.01367189735174179
    },
    {
      "id": 244,
      "seek": 91236,
      "start": 932.239990234375,
      "end": 938.5599975585938,
      "text": " But essentially, I just have an object-oriented system here.",
      "tokens": [
        51358,
        583,
        4476,
        11,
        286,
        445,
        362,
        364,
        2657,
        12,
        27414,
        1185,
        510,
        13,
        51674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48499569296836853,
      "compression_ratio": 1.7422221899032593,
      "no_speech_prob": 0.01367189735174179
    },
    {
      "id": 245,
      "seek": 91236,
      "start": 938.5599975585938,
      "end": 940.8400268554688,
      "text": " And there's something like xMolecules,",
      "tokens": [
        51674,
        400,
        456,
        311,
        746,
        411,
        2031,
        44,
        4812,
        66,
        2271,
        82,
        11,
        51788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48499569296836853,
      "compression_ratio": 1.7422221899032593,
      "no_speech_prob": 0.01367189735174179
    },
    {
      "id": 246,
      "seek": 94084,
      "start": 941.239990234375,
      "end": 948.280029296875,
      "text": " which supports the concepts directly for different programming languages.",
      "tokens": [
        50384,
        597,
        9346,
        264,
        10392,
        3838,
        337,
        819,
        9410,
        8650,
        13,
        50736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5095481276512146,
      "compression_ratio": 1.5215517282485962,
      "no_speech_prob": 0.07321058213710785
    },
    {
      "id": 247,
      "seek": 94084,
      "start": 948.280029296875,
      "end": 954.7999877929688,
      "text": " And that's what the good Oliver Rothbohm described in a blog post.",
      "tokens": [
        50736,
        400,
        300,
        311,
        437,
        264,
        665,
        23440,
        28089,
        65,
        1445,
        76,
        7619,
        294,
        257,
        6968,
        2183,
        13,
        51062
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5095481276512146,
      "compression_ratio": 1.5215517282485962,
      "no_speech_prob": 0.07321058213710785
    },
    {
      "id": 248,
      "seek": 94084,
      "start": 954.7999877929688,
      "end": 956.5599975585938,
      "text": " And that's what we talked about.",
      "tokens": [
        51062,
        400,
        300,
        311,
        437,
        321,
        2825,
        466,
        13,
        51150
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5095481276512146,
      "compression_ratio": 1.5215517282485962,
      "no_speech_prob": 0.07321058213710785
    },
    {
      "id": 249,
      "seek": 94084,
      "start": 956.5599975585938,
      "end": 963.0399780273438,
      "text": " That means, I can now build such a system with something like jMolecules.",
      "tokens": [
        51150,
        663,
        1355,
        11,
        286,
        393,
        586,
        1322,
        1270,
        257,
        1185,
        365,
        746,
        411,
        361,
        44,
        4812,
        11570,
        13,
        51474
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5095481276512146,
      "compression_ratio": 1.5215517282485962,
      "no_speech_prob": 0.07321058213710785
    },
    {
      "id": 250,
      "seek": 94084,
      "start": 963.0399780273438,
      "end": 966.0,
      "text": " And it's also about dependencies, for example.",
      "tokens": [
        51474,
        400,
        309,
        311,
        611,
        466,
        36606,
        11,
        337,
        1365,
        13,
        51622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5095481276512146,
      "compression_ratio": 1.5215517282485962,
      "no_speech_prob": 0.07321058213710785
    },
    {
      "id": 251,
      "seek": 94084,
      "start": 966.0,
      "end": 969.719970703125,
      "text": " So I would like to be able to use aggregates in a service,",
      "tokens": [
        51622,
        407,
        286,
        576,
        411,
        281,
        312,
        1075,
        281,
        764,
        16743,
        1024,
        294,
        257,
        2643,
        11,
        51808
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5095481276512146,
      "compression_ratio": 1.5215517282485962,
      "no_speech_prob": 0.07321058213710785
    },
    {
      "id": 252,
      "seek": 96972,
      "start": 969.719970703125,
      "end": 972.4000244140625,
      "text": " but aggregates shouldn't use services.",
      "tokens": [
        50364,
        457,
        16743,
        1024,
        4659,
        380,
        764,
        3328,
        13,
        50498
      ],
      "temperature": 0.0,
      "avg_logprob": -0.453828364610672,
      "compression_ratio": 1.692307710647583,
      "no_speech_prob": 0.04242846742272377
    },
    {
      "id": 253,
      "seek": 96972,
      "start": 972.4000244140625,
      "end": 978.2000122070312,
      "text": " That means, there are relationships that result quite directly from these patterns.",
      "tokens": [
        50498,
        663,
        1355,
        11,
        456,
        366,
        6159,
        300,
        1874,
        1596,
        3838,
        490,
        613,
        8294,
        13,
        50788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.453828364610672,
      "compression_ratio": 1.692307710647583,
      "no_speech_prob": 0.04242846742272377
    },
    {
      "id": 254,
      "seek": 96972,
      "start": 978.2000122070312,
      "end": 989.5599975585938,
      "text": " And that means that I actually have these dependencies,",
      "tokens": [
        50788,
        400,
        300,
        1355,
        300,
        286,
        767,
        362,
        613,
        36606,
        11,
        51356
      ],
      "temperature": 0.0,
      "avg_logprob": -0.453828364610672,
      "compression_ratio": 1.692307710647583,
      "no_speech_prob": 0.04242846742272377
    },
    {
      "id": 255,
      "seek": 96972,
      "start": 989.5599975585938,
      "end": 992.239990234375,
      "text": " like, for example, that services are allowed to use aggregates.",
      "tokens": [
        51356,
        411,
        11,
        337,
        1365,
        11,
        300,
        3328,
        366,
        4350,
        281,
        764,
        16743,
        1024,
        13,
        51490
      ],
      "temperature": 0.0,
      "avg_logprob": -0.453828364610672,
      "compression_ratio": 1.692307710647583,
      "no_speech_prob": 0.04242846742272377
    },
    {
      "id": 256,
      "seek": 96972,
      "start": 992.239990234375,
      "end": 995.2000122070312,
      "text": " And I can use such architecture management tools.",
      "tokens": [
        51490,
        400,
        286,
        393,
        764,
        1270,
        9482,
        4592,
        3873,
        13,
        51638
      ],
      "temperature": 0.0,
      "avg_logprob": -0.453828364610672,
      "compression_ratio": 1.692307710647583,
      "no_speech_prob": 0.04242846742272377
    },
    {
      "id": 257,
      "seek": 96972,
      "start": 995.2000122070312,
      "end": 997.5999755859375,
      "text": " So the architecture management tools,",
      "tokens": [
        51638,
        407,
        264,
        9482,
        4592,
        3873,
        11,
        51758
      ],
      "temperature": 0.0,
      "avg_logprob": -0.453828364610672,
      "compression_ratio": 1.692307710647583,
      "no_speech_prob": 0.04242846742272377
    },
    {
      "id": 258,
      "seek": 99760,
      "start": 997.5999755859375,
      "end": 1000.5599975585938,
      "text": " I've actually had several episodes about that.",
      "tokens": [
        50364,
        286,
        600,
        767,
        632,
        2940,
        9313,
        466,
        300,
        13,
        50512
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41680413484573364,
      "compression_ratio": 1.694656491279602,
      "no_speech_prob": 0.05537637323141098
    },
    {
      "id": 259,
      "seek": 99760,
      "start": 1000.5599975585938,
      "end": 1004.0,
      "text": " Incidentally, I also link all of this in the show notes.",
      "tokens": [
        50512,
        7779,
        36578,
        11,
        286,
        611,
        2113,
        439,
        295,
        341,
        294,
        264,
        855,
        5570,
        13,
        50684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41680413484573364,
      "compression_ratio": 1.694656491279602,
      "no_speech_prob": 0.05537637323141098
    },
    {
      "id": 260,
      "seek": 99760,
      "start": 1004.0,
      "end": 1006.0,
      "text": " These are tools with which I can somehow say,",
      "tokens": [
        50684,
        1981,
        366,
        3873,
        365,
        597,
        286,
        393,
        6063,
        584,
        11,
        50784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41680413484573364,
      "compression_ratio": 1.694656491279602,
      "no_speech_prob": 0.05537637323141098
    },
    {
      "id": 261,
      "seek": 99760,
      "start": 1006.0,
      "end": 1010.0399780273438,
      "text": " okay, services are allowed to access aggregates,",
      "tokens": [
        50784,
        1392,
        11,
        3328,
        366,
        4350,
        281,
        2105,
        16743,
        1024,
        11,
        50986
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41680413484573364,
      "compression_ratio": 1.694656491279602,
      "no_speech_prob": 0.05537637323141098
    },
    {
      "id": 262,
      "seek": 99760,
      "start": 1010.0399780273438,
      "end": 1013.760009765625,
      "text": " aggregates are allowed to access entities and value objects, and so on.",
      "tokens": [
        50986,
        16743,
        1024,
        366,
        4350,
        281,
        2105,
        16667,
        293,
        2158,
        6565,
        11,
        293,
        370,
        322,
        13,
        51172
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41680413484573364,
      "compression_ratio": 1.694656491279602,
      "no_speech_prob": 0.05537637323141098
    },
    {
      "id": 263,
      "seek": 99760,
      "start": 1013.760009765625,
      "end": 1017.47998046875,
      "text": " And then these dependencies are implemented, so to speak.",
      "tokens": [
        51172,
        400,
        550,
        613,
        36606,
        366,
        12270,
        11,
        370,
        281,
        1710,
        13,
        51358
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41680413484573364,
      "compression_ratio": 1.694656491279602,
      "no_speech_prob": 0.05537637323141098
    },
    {
      "id": 264,
      "seek": 99760,
      "start": 1017.47998046875,
      "end": 1020.4000244140625,
      "text": " That means, I have a checker that runs over it and says,",
      "tokens": [
        51358,
        663,
        1355,
        11,
        286,
        362,
        257,
        1520,
        260,
        300,
        6676,
        670,
        309,
        293,
        1619,
        11,
        51504
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41680413484573364,
      "compression_ratio": 1.694656491279602,
      "no_speech_prob": 0.05537637323141098
    },
    {
      "id": 265,
      "seek": 99760,
      "start": 1020.4000244140625,
      "end": 1022.5599975585938,
      "text": " no, you can't do that.",
      "tokens": [
        51504,
        572,
        11,
        291,
        393,
        380,
        360,
        300,
        13,
        51612
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41680413484573364,
      "compression_ratio": 1.694656491279602,
      "no_speech_prob": 0.05537637323141098
    },
    {
      "id": 266,
      "seek": 99760,
      "start": 1022.5599975585938,
      "end": 1024.4000244140625,
      "text": " And there are very different tools.",
      "tokens": [
        51612,
        400,
        456,
        366,
        588,
        819,
        3873,
        13,
        51704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41680413484573364,
      "compression_ratio": 1.694656491279602,
      "no_speech_prob": 0.05537637323141098
    },
    {
      "id": 267,
      "seek": 102440,
      "start": 1024.4000244140625,
      "end": 1029.280029296875,
      "text": " So there is something like Structure 101 or such a graph",
      "tokens": [
        50364,
        407,
        456,
        307,
        746,
        411,
        745,
        2885,
        21055,
        420,
        1270,
        257,
        4295,
        50608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45276618003845215,
      "compression_ratio": 1.606177568435669,
      "no_speech_prob": 0.28890910744667053
    },
    {
      "id": 268,
      "seek": 102440,
      "start": 1029.280029296875,
      "end": 1032.0,
      "text": " that somehow shows it more graphically,",
      "tokens": [
        50608,
        300,
        6063,
        3110,
        309,
        544,
        4295,
        984,
        11,
        50744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45276618003845215,
      "compression_ratio": 1.606177568435669,
      "no_speech_prob": 0.28890910744667053
    },
    {
      "id": 269,
      "seek": 102440,
      "start": 1032.0,
      "end": 1034.199951171875,
      "text": " which I can also get into the image process.",
      "tokens": [
        50744,
        597,
        286,
        393,
        611,
        483,
        666,
        264,
        3256,
        1399,
        13,
        50854
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45276618003845215,
      "compression_ratio": 1.606177568435669,
      "no_speech_prob": 0.28890910744667053
    },
    {
      "id": 270,
      "seek": 102440,
      "start": 1034.199951171875,
      "end": 1035.8800048828125,
      "text": " There is, for example, something like ArcUnit,",
      "tokens": [
        50854,
        821,
        307,
        11,
        337,
        1365,
        11,
        746,
        411,
        21727,
        12405,
        270,
        11,
        50938
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45276618003845215,
      "compression_ratio": 1.606177568435669,
      "no_speech_prob": 0.28890910744667053
    },
    {
      "id": 271,
      "seek": 102440,
      "start": 1035.8800048828125,
      "end": 1038.4000244140625,
      "text": " where I have it as part of the unit test.",
      "tokens": [
        50938,
        689,
        286,
        362,
        309,
        382,
        644,
        295,
        264,
        4985,
        1500,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45276618003845215,
      "compression_ratio": 1.606177568435669,
      "no_speech_prob": 0.28890910744667053
    },
    {
      "id": 272,
      "seek": 102440,
      "start": 1038.4000244140625,
      "end": 1040.8800048828125,
      "text": " And as I said, there is a big selection",
      "tokens": [
        51064,
        400,
        382,
        286,
        848,
        11,
        456,
        307,
        257,
        955,
        9450,
        51188
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45276618003845215,
      "compression_ratio": 1.606177568435669,
      "no_speech_prob": 0.28890910744667053
    },
    {
      "id": 273,
      "seek": 102440,
      "start": 1040.8800048828125,
      "end": 1046.47998046875,
      "text": " and you can look at all these tools, so to speak.",
      "tokens": [
        51188,
        293,
        291,
        393,
        574,
        412,
        439,
        613,
        3873,
        11,
        370,
        281,
        1710,
        13,
        51468
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45276618003845215,
      "compression_ratio": 1.606177568435669,
      "no_speech_prob": 0.28890910744667053
    },
    {
      "id": 274,
      "seek": 102440,
      "start": 1046.47998046875,
      "end": 1053.0799560546875,
      "text": " So, in that context, I would like to talk again about the topic of design-level event storming.",
      "tokens": [
        51468,
        407,
        11,
        294,
        300,
        4319,
        11,
        286,
        576,
        411,
        281,
        751,
        797,
        466,
        264,
        4829,
        295,
        1715,
        12,
        12418,
        2280,
        7679,
        278,
        13,
        51798
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45276618003845215,
      "compression_ratio": 1.606177568435669,
      "no_speech_prob": 0.28890910744667053
    },
    {
      "id": 275,
      "seek": 105308,
      "start": 1053.0799560546875,
      "end": 1057.6800537109375,
      "text": " We talked about big-picture event storming in the last session.",
      "tokens": [
        50364,
        492,
        2825,
        466,
        955,
        12,
        79,
        985,
        540,
        2280,
        7679,
        278,
        294,
        264,
        1036,
        5481,
        13,
        50594
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49392712116241455,
      "compression_ratio": 1.7671233415603638,
      "no_speech_prob": 0.01291548740118742
    },
    {
      "id": 276,
      "seek": 105308,
      "start": 1057.6800537109375,
      "end": 1060.719970703125,
      "text": " And big-picture event storming is ultimately something",
      "tokens": [
        50594,
        400,
        955,
        12,
        79,
        985,
        540,
        2280,
        7679,
        278,
        307,
        6284,
        746,
        50746
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49392712116241455,
      "compression_ratio": 1.7671233415603638,
      "no_speech_prob": 0.01291548740118742
    },
    {
      "id": 277,
      "seek": 105308,
      "start": 1060.719970703125,
      "end": 1063.6800537109375,
      "text": " that I have domain events.",
      "tokens": [
        50746,
        300,
        286,
        362,
        9274,
        3931,
        13,
        50894
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49392712116241455,
      "compression_ratio": 1.7671233415603638,
      "no_speech_prob": 0.01291548740118742
    },
    {
      "id": 278,
      "seek": 105308,
      "start": 1066.0799560546875,
      "end": 1072.43994140625,
      "text": " I have domain events and I write down these domain events somehow",
      "tokens": [
        51014,
        286,
        362,
        9274,
        3931,
        293,
        286,
        2464,
        760,
        613,
        9274,
        3931,
        6063,
        51332
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49392712116241455,
      "compression_ratio": 1.7671233415603638,
      "no_speech_prob": 0.01291548740118742
    },
    {
      "id": 279,
      "seek": 105308,
      "start": 1072.43994140625,
      "end": 1078.6800537109375,
      "text": " and get information about how my domain works.",
      "tokens": [
        51332,
        293,
        483,
        1589,
        466,
        577,
        452,
        9274,
        1985,
        13,
        51644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49392712116241455,
      "compression_ratio": 1.7671233415603638,
      "no_speech_prob": 0.01291548740118742
    },
    {
      "id": 280,
      "seek": 107868,
      "start": 1078.6800537109375,
      "end": 1083.0799560546875,
      "text": " And I can use that, for example, to identify building contexts.",
      "tokens": [
        50364,
        400,
        286,
        393,
        764,
        300,
        11,
        337,
        1365,
        11,
        281,
        5876,
        2390,
        30628,
        13,
        50584
      ],
      "temperature": 0.0,
      "avg_logprob": -0.534903347492218,
      "compression_ratio": 1.6282527446746826,
      "no_speech_prob": 0.29541832208633423
    },
    {
      "id": 281,
      "seek": 107868,
      "start": 1083.0799560546875,
      "end": 1085.47998046875,
      "text": " That means, I have such stories there, typically,",
      "tokens": [
        50584,
        663,
        1355,
        11,
        286,
        362,
        1270,
        3676,
        456,
        11,
        5850,
        11,
        50704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.534903347492218,
      "compression_ratio": 1.6282527446746826,
      "no_speech_prob": 0.29541832208633423
    },
    {
      "id": 282,
      "seek": 107868,
      "start": 1085.47998046875,
      "end": 1088.1600341796875,
      "text": " like, I made an order,",
      "tokens": [
        50704,
        411,
        11,
        286,
        1027,
        364,
        1668,
        11,
        50838
      ],
      "temperature": 0.0,
      "avg_logprob": -0.534903347492218,
      "compression_ratio": 1.6282527446746826,
      "no_speech_prob": 0.29541832208633423
    },
    {
      "id": 283,
      "seek": 107868,
      "start": 1088.1600341796875,
      "end": 1091.0799560546875,
      "text": " the thing is now delivered to me, things like that.",
      "tokens": [
        50838,
        264,
        551,
        307,
        586,
        10144,
        281,
        385,
        11,
        721,
        411,
        300,
        13,
        50984
      ],
      "temperature": 0.0,
      "avg_logprob": -0.534903347492218,
      "compression_ratio": 1.6282527446746826,
      "no_speech_prob": 0.29541832208633423
    },
    {
      "id": 284,
      "seek": 107868,
      "start": 1091.0799560546875,
      "end": 1093.47998046875,
      "text": " Then I can somehow say certain functionalities,",
      "tokens": [
        50984,
        1396,
        286,
        393,
        6063,
        584,
        1629,
        11745,
        1088,
        11,
        51104
      ],
      "temperature": 0.0,
      "avg_logprob": -0.534903347492218,
      "compression_ratio": 1.6282527446746826,
      "no_speech_prob": 0.29541832208633423
    },
    {
      "id": 285,
      "seek": 107868,
      "start": 1093.47998046875,
      "end": 1095.47998046875,
      "text": " so the delivery and the accounting writing",
      "tokens": [
        51104,
        370,
        264,
        8982,
        293,
        264,
        19163,
        3579,
        51204
      ],
      "temperature": 0.0,
      "avg_logprob": -0.534903347492218,
      "compression_ratio": 1.6282527446746826,
      "no_speech_prob": 0.29541832208633423
    },
    {
      "id": 286,
      "seek": 107868,
      "start": 1095.47998046875,
      "end": 1096.8800048828125,
      "text": " is perhaps in different building contexts.",
      "tokens": [
        51204,
        307,
        4317,
        294,
        819,
        2390,
        30628,
        13,
        51274
      ],
      "temperature": 0.0,
      "avg_logprob": -0.534903347492218,
      "compression_ratio": 1.6282527446746826,
      "no_speech_prob": 0.29541832208633423
    },
    {
      "id": 287,
      "seek": 107868,
      "start": 1096.8800048828125,
      "end": 1099.47998046875,
      "text": " We talked about this last time.",
      "tokens": [
        51274,
        492,
        2825,
        466,
        341,
        1036,
        565,
        13,
        51404
      ],
      "temperature": 0.0,
      "avg_logprob": -0.534903347492218,
      "compression_ratio": 1.6282527446746826,
      "no_speech_prob": 0.29541832208633423
    },
    {
      "id": 288,
      "seek": 107868,
      "start": 1099.47998046875,
      "end": 1100.8800048828125,
      "text": " So, Jude Rude writes,",
      "tokens": [
        51404,
        407,
        11,
        36521,
        497,
        2303,
        13657,
        11,
        51474
      ],
      "temperature": 0.0,
      "avg_logprob": -0.534903347492218,
      "compression_ratio": 1.6282527446746826,
      "no_speech_prob": 0.29541832208633423
    },
    {
      "id": 289,
      "seek": 107868,
      "start": 1100.8800048828125,
      "end": 1106.8800048828125,
      "text": " which objects should not be immutable and thus have no logic?",
      "tokens": [
        51474,
        597,
        6565,
        820,
        406,
        312,
        3397,
        32148,
        293,
        8807,
        362,
        572,
        9952,
        30,
        51774
      ],
      "temperature": 0.0,
      "avg_logprob": -0.534903347492218,
      "compression_ratio": 1.6282527446746826,
      "no_speech_prob": 0.29541832208633423
    },
    {
      "id": 290,
      "seek": 110688,
      "start": 1106.8800048828125,
      "end": 1109.8800048828125,
      "text": " Exactly, they represent value and values are immutable.",
      "tokens": [
        50364,
        7587,
        11,
        436,
        2906,
        2158,
        293,
        4190,
        366,
        3397,
        32148,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4219801425933838,
      "compression_ratio": 1.4805195331573486,
      "no_speech_prob": 0.0273976419121027
    },
    {
      "id": 291,
      "seek": 110688,
      "start": 1109.8800048828125,
      "end": 1111.47998046875,
      "text": " Two euros are just two euros.",
      "tokens": [
        50514,
        4453,
        14160,
        366,
        445,
        732,
        14160,
        13,
        50594
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4219801425933838,
      "compression_ratio": 1.4805195331573486,
      "no_speech_prob": 0.0273976419121027
    },
    {
      "id": 292,
      "seek": 110688,
      "start": 1111.47998046875,
      "end": 1114.8800048828125,
      "text": " I can't say two euros are suddenly two euros and 10 cents,",
      "tokens": [
        50594,
        286,
        393,
        380,
        584,
        732,
        14160,
        366,
        5800,
        732,
        14160,
        293,
        1266,
        14941,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4219801425933838,
      "compression_ratio": 1.4805195331573486,
      "no_speech_prob": 0.0273976419121027
    },
    {
      "id": 293,
      "seek": 110688,
      "start": 1114.8800048828125,
      "end": 1116.8800048828125,
      "text": " but that's just a value.",
      "tokens": [
        50764,
        457,
        300,
        311,
        445,
        257,
        2158,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4219801425933838,
      "compression_ratio": 1.4805195331573486,
      "no_speech_prob": 0.0273976419121027
    },
    {
      "id": 294,
      "seek": 110688,
      "start": 1116.8800048828125,
      "end": 1120.47998046875,
      "text": " Which means, for example, if I have the value of my order,",
      "tokens": [
        50864,
        3013,
        1355,
        11,
        337,
        1365,
        11,
        498,
        286,
        362,
        264,
        2158,
        295,
        452,
        1668,
        11,
        51044
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4219801425933838,
      "compression_ratio": 1.4805195331573486,
      "no_speech_prob": 0.0273976419121027
    },
    {
      "id": 0,
      "seek": 0,
      "start": 1135.63,
      "end": 1140.13,
      "text": " and the old value object is still there.",
      "tokens": [
        50364,
        293,
        264,
        1331,
        2158,
        2657,
        307,
        920,
        456,
        13,
        50589
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6786402463912964,
      "compression_ratio": 1.54358971118927,
      "no_speech_prob": 0.911963701248169
    },
    {
      "id": 1,
      "seek": 0,
      "start": 1140.13,
      "end": 1142.63,
      "text": " In other words, they are unchangeable.",
      "tokens": [
        50589,
        682,
        661,
        2283,
        11,
        436,
        366,
        517,
        15431,
        712,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6786402463912964,
      "compression_ratio": 1.54358971118927,
      "no_speech_prob": 0.911963701248169
    },
    {
      "id": 2,
      "seek": 0,
      "start": 1142.63,
      "end": 1144.63,
      "text": " They have value semantics.",
      "tokens": [
        50714,
        814,
        362,
        2158,
        4361,
        45298,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6786402463912964,
      "compression_ratio": 1.54358971118927,
      "no_speech_prob": 0.911963701248169
    },
    {
      "id": 3,
      "seek": 0,
      "start": 1144.63,
      "end": 1148.63,
      "text": " And also...",
      "tokens": [
        50814,
        400,
        611,
        485,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6786402463912964,
      "compression_ratio": 1.54358971118927,
      "no_speech_prob": 0.911963701248169
    },
    {
      "id": 4,
      "seek": 0,
      "start": 1148.63,
      "end": 1149.63,
      "text": " How should I put it?",
      "tokens": [
        51014,
        1012,
        820,
        286,
        829,
        309,
        30,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6786402463912964,
      "compression_ratio": 1.54358971118927,
      "no_speech_prob": 0.911963701248169
    },
    {
      "id": 5,
      "seek": 0,
      "start": 1149.63,
      "end": 1152.63,
      "text": " Things like comparisons are also a topic.",
      "tokens": [
        51064,
        9514,
        411,
        33157,
        366,
        611,
        257,
        4829,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6786402463912964,
      "compression_ratio": 1.54358971118927,
      "no_speech_prob": 0.911963701248169
    },
    {
      "id": 6,
      "seek": 0,
      "start": 1152.63,
      "end": 1157.63,
      "text": " If I compare meters or compare money amounts,",
      "tokens": [
        51214,
        759,
        286,
        6794,
        8146,
        420,
        6794,
        1460,
        11663,
        11,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6786402463912964,
      "compression_ratio": 1.54358971118927,
      "no_speech_prob": 0.911963701248169
    },
    {
      "id": 7,
      "seek": 0,
      "start": 1157.63,
      "end": 1160.63,
      "text": " maybe that's something I have in there as logic.",
      "tokens": [
        51464,
        1310,
        300,
        311,
        746,
        286,
        362,
        294,
        456,
        382,
        9952,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6786402463912964,
      "compression_ratio": 1.54358971118927,
      "no_speech_prob": 0.911963701248169
    },
    {
      "id": 8,
      "seek": 0,
      "start": 1160.63,
      "end": 1163.63,
      "text": " So they also have logic.",
      "tokens": [
        51614,
        407,
        436,
        611,
        362,
        9952,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6786402463912964,
      "compression_ratio": 1.54358971118927,
      "no_speech_prob": 0.911963701248169
    },
    {
      "id": 9,
      "seek": 2800,
      "start": 1163.63,
      "end": 1166.63,
      "text": " That's exactly the idea.",
      "tokens": [
        50364,
        663,
        311,
        2293,
        264,
        1558,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3913462162017822,
      "compression_ratio": 1.5725806951522827,
      "no_speech_prob": 0.13456672430038452
    },
    {
      "id": 10,
      "seek": 2800,
      "start": 1166.63,
      "end": 1167.63,
      "text": " Christian Trutz writes,",
      "tokens": [
        50514,
        5778,
        1765,
        12950,
        13657,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3913462162017822,
      "compression_ratio": 1.5725806951522827,
      "no_speech_prob": 0.13456672430038452
    },
    {
      "id": 11,
      "seek": 2800,
      "start": 1167.63,
      "end": 1170.63,
      "text": " for example, do you use Spring Modulus to structure packages?",
      "tokens": [
        50564,
        337,
        1365,
        11,
        360,
        291,
        764,
        14013,
        6583,
        26107,
        281,
        3877,
        17401,
        30,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3913462162017822,
      "compression_ratio": 1.5725806951522827,
      "no_speech_prob": 0.13456672430038452
    },
    {
      "id": 12,
      "seek": 2800,
      "start": 1170.63,
      "end": 1172.63,
      "text": " Exactly, that's what you can use, for example,",
      "tokens": [
        50714,
        7587,
        11,
        300,
        311,
        437,
        291,
        393,
        764,
        11,
        337,
        1365,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3913462162017822,
      "compression_ratio": 1.5725806951522827,
      "no_speech_prob": 0.13456672430038452
    },
    {
      "id": 13,
      "seek": 2800,
      "start": 1172.63,
      "end": 1176.63,
      "text": " to structure a system on this package level.",
      "tokens": [
        50814,
        281,
        3877,
        257,
        1185,
        322,
        341,
        7372,
        1496,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3913462162017822,
      "compression_ratio": 1.5725806951522827,
      "no_speech_prob": 0.13456672430038452
    },
    {
      "id": 14,
      "seek": 2800,
      "start": 1176.63,
      "end": 1178.63,
      "text": " Exactly.",
      "tokens": [
        51014,
        7587,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3913462162017822,
      "compression_ratio": 1.5725806951522827,
      "no_speech_prob": 0.13456672430038452
    },
    {
      "id": 15,
      "seek": 2800,
      "start": 1178.63,
      "end": 1179.63,
      "text": " Good.",
      "tokens": [
        51114,
        2205,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3913462162017822,
      "compression_ratio": 1.5725806951522827,
      "no_speech_prob": 0.13456672430038452
    },
    {
      "id": 16,
      "seek": 2800,
      "start": 1179.63,
      "end": 1182.63,
      "text": " I think we're done with that topic.",
      "tokens": [
        51164,
        286,
        519,
        321,
        434,
        1096,
        365,
        300,
        4829,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3913462162017822,
      "compression_ratio": 1.5725806951522827,
      "no_speech_prob": 0.13456672430038452
    },
    {
      "id": 17,
      "seek": 2800,
      "start": 1182.63,
      "end": 1187.63,
      "text": " I'll take a quick look to see if anything else comes in here.",
      "tokens": [
        51314,
        286,
        603,
        747,
        257,
        1702,
        574,
        281,
        536,
        498,
        1340,
        1646,
        1487,
        294,
        510,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3913462162017822,
      "compression_ratio": 1.5725806951522827,
      "no_speech_prob": 0.13456672430038452
    },
    {
      "id": 18,
      "seek": 2800,
      "start": 1187.63,
      "end": 1192.63,
      "text": " Otherwise I would actually continue with this design-level event storming.",
      "tokens": [
        51564,
        10328,
        286,
        576,
        767,
        2354,
        365,
        341,
        1715,
        12,
        12418,
        2280,
        5967,
        2810,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3913462162017822,
      "compression_ratio": 1.5725806951522827,
      "no_speech_prob": 0.13456672430038452
    },
    {
      "id": 19,
      "seek": 5700,
      "start": 1192.63,
      "end": 1195.63,
      "text": " When it comes to design-level event storming,",
      "tokens": [
        50364,
        1133,
        309,
        1487,
        281,
        1715,
        12,
        12418,
        2280,
        7679,
        278,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4028545320034027,
      "compression_ratio": 1.689814805984497,
      "no_speech_prob": 0.0076468815095722675
    },
    {
      "id": 20,
      "seek": 5700,
      "start": 1195.63,
      "end": 1198.63,
      "text": " it's important to face what it's really about.",
      "tokens": [
        50514,
        309,
        311,
        1021,
        281,
        1851,
        437,
        309,
        311,
        534,
        466,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4028545320034027,
      "compression_ratio": 1.689814805984497,
      "no_speech_prob": 0.0076468815095722675
    },
    {
      "id": 21,
      "seek": 5700,
      "start": 1198.63,
      "end": 1202.63,
      "text": " I would like to understand how the business logic is.",
      "tokens": [
        50664,
        286,
        576,
        411,
        281,
        1223,
        577,
        264,
        1606,
        9952,
        307,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4028545320034027,
      "compression_ratio": 1.689814805984497,
      "no_speech_prob": 0.0076468815095722675
    },
    {
      "id": 22,
      "seek": 5700,
      "start": 1202.63,
      "end": 1205.63,
      "text": " And I want to understand that in this big-picture event storming,",
      "tokens": [
        50864,
        400,
        286,
        528,
        281,
        1223,
        300,
        294,
        341,
        955,
        12,
        79,
        985,
        540,
        2280,
        7679,
        278,
        11,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4028545320034027,
      "compression_ratio": 1.689814805984497,
      "no_speech_prob": 0.0076468815095722675
    },
    {
      "id": 23,
      "seek": 5700,
      "start": 1205.63,
      "end": 1209.63,
      "text": " which we discussed last time, roughly granular.",
      "tokens": [
        51014,
        597,
        321,
        7152,
        1036,
        565,
        11,
        9810,
        39962,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4028545320034027,
      "compression_ratio": 1.689814805984497,
      "no_speech_prob": 0.0076468815095722675
    },
    {
      "id": 24,
      "seek": 5700,
      "start": 1209.63,
      "end": 1213.63,
      "text": " And here I would like to understand it finely granular.",
      "tokens": [
        51214,
        400,
        510,
        286,
        576,
        411,
        281,
        1223,
        309,
        31529,
        39962,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4028545320034027,
      "compression_ratio": 1.689814805984497,
      "no_speech_prob": 0.0076468815095722675
    },
    {
      "id": 25,
      "seek": 5700,
      "start": 1213.63,
      "end": 1217.63,
      "text": " So that means I have, for example, a read model.",
      "tokens": [
        51414,
        407,
        300,
        1355,
        286,
        362,
        11,
        337,
        1365,
        11,
        257,
        1401,
        2316,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4028545320034027,
      "compression_ratio": 1.689814805984497,
      "no_speech_prob": 0.0076468815095722675
    },
    {
      "id": 26,
      "seek": 8200,
      "start": 1218.63,
      "end": 1222.63,
      "text": " And a read model is something where I can now, for example,",
      "tokens": [
        50414,
        400,
        257,
        1401,
        2316,
        307,
        746,
        689,
        286,
        393,
        586,
        11,
        337,
        1365,
        11,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37568047642707825,
      "compression_ratio": 1.663265347480774,
      "no_speech_prob": 0.07443958520889282
    },
    {
      "id": 27,
      "seek": 8200,
      "start": 1222.63,
      "end": 1227.63,
      "text": " paste in a UI and say, okay, it just shows something.",
      "tokens": [
        50614,
        9163,
        294,
        257,
        15682,
        293,
        584,
        11,
        1392,
        11,
        309,
        445,
        3110,
        746,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37568047642707825,
      "compression_ratio": 1.663265347480774,
      "no_speech_prob": 0.07443958520889282
    },
    {
      "id": 28,
      "seek": 8200,
      "start": 1229.63,
      "end": 1231.63,
      "text": " Then I have some actors,",
      "tokens": [
        50964,
        1396,
        286,
        362,
        512,
        10037,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37568047642707825,
      "compression_ratio": 1.663265347480774,
      "no_speech_prob": 0.07443958520889282
    },
    {
      "id": 29,
      "seek": 8200,
      "start": 1231.63,
      "end": 1234.63,
      "text": " so people who do something and, for example,",
      "tokens": [
        51064,
        370,
        561,
        567,
        360,
        746,
        293,
        11,
        337,
        1365,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37568047642707825,
      "compression_ratio": 1.663265347480774,
      "no_speech_prob": 0.07443958520889282
    },
    {
      "id": 30,
      "seek": 8200,
      "start": 1234.63,
      "end": 1236.63,
      "text": " can issue a command.",
      "tokens": [
        51214,
        393,
        2734,
        257,
        5622,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37568047642707825,
      "compression_ratio": 1.663265347480774,
      "no_speech_prob": 0.07443958520889282
    },
    {
      "id": 31,
      "seek": 8200,
      "start": 1236.63,
      "end": 1241.63,
      "text": " And either through an external system or through my own system,",
      "tokens": [
        51314,
        400,
        2139,
        807,
        364,
        8320,
        1185,
        420,
        807,
        452,
        1065,
        1185,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37568047642707825,
      "compression_ratio": 1.663265347480774,
      "no_speech_prob": 0.07443958520889282
    },
    {
      "id": 32,
      "seek": 8200,
      "start": 1241.63,
      "end": 1244.63,
      "text": " then some events arise.",
      "tokens": [
        51564,
        550,
        512,
        3931,
        20288,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37568047642707825,
      "compression_ratio": 1.663265347480774,
      "no_speech_prob": 0.07443958520889282
    },
    {
      "id": 33,
      "seek": 8200,
      "start": 1244.63,
      "end": 1246.63,
      "text": " So I could say, for example, yes,",
      "tokens": [
        51714,
        407,
        286,
        727,
        584,
        11,
        337,
        1365,
        11,
        2086,
        11,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37568047642707825,
      "compression_ratio": 1.663265347480774,
      "no_speech_prob": 0.07443958520889282
    },
    {
      "id": 34,
      "seek": 11100,
      "start": 1246.63,
      "end": 1249.63,
      "text": " I'm a customer, so I'm an actor here.",
      "tokens": [
        50364,
        286,
        478,
        257,
        5474,
        11,
        370,
        286,
        478,
        364,
        8747,
        510,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39651551842689514,
      "compression_ratio": 1.6554621458053589,
      "no_speech_prob": 0.004889755044132471
    },
    {
      "id": 35,
      "seek": 11100,
      "start": 1249.63,
      "end": 1251.63,
      "text": " I give the command, I would like to have it now.",
      "tokens": [
        50514,
        286,
        976,
        264,
        5622,
        11,
        286,
        576,
        411,
        281,
        362,
        309,
        586,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39651551842689514,
      "compression_ratio": 1.6554621458053589,
      "no_speech_prob": 0.004889755044132471
    },
    {
      "id": 36,
      "seek": 11100,
      "start": 1251.63,
      "end": 1254.63,
      "text": " So I would like to submit this order.",
      "tokens": [
        50614,
        407,
        286,
        576,
        411,
        281,
        10315,
        341,
        1668,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39651551842689514,
      "compression_ratio": 1.6554621458053589,
      "no_speech_prob": 0.004889755044132471
    },
    {
      "id": 37,
      "seek": 11100,
      "start": 1254.63,
      "end": 1255.63,
      "text": " That goes to my system.",
      "tokens": [
        50764,
        663,
        1709,
        281,
        452,
        1185,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39651551842689514,
      "compression_ratio": 1.6554621458053589,
      "no_speech_prob": 0.004889755044132471
    },
    {
      "id": 38,
      "seek": 11100,
      "start": 1255.63,
      "end": 1259.63,
      "text": " Event, which somehow comes out, is order accepted.",
      "tokens": [
        50814,
        13222,
        11,
        597,
        6063,
        1487,
        484,
        11,
        307,
        1668,
        9035,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39651551842689514,
      "compression_ratio": 1.6554621458053589,
      "no_speech_prob": 0.004889755044132471
    },
    {
      "id": 39,
      "seek": 11100,
      "start": 1259.63,
      "end": 1264.63,
      "text": " And then it could be that I have generated an order from it,",
      "tokens": [
        51014,
        400,
        550,
        309,
        727,
        312,
        300,
        286,
        362,
        10833,
        364,
        1668,
        490,
        309,
        11,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39651551842689514,
      "compression_ratio": 1.6554621458053589,
      "no_speech_prob": 0.004889755044132471
    },
    {
      "id": 40,
      "seek": 11100,
      "start": 1264.63,
      "end": 1267.63,
      "text": " which I can then display to myself.",
      "tokens": [
        51264,
        597,
        286,
        393,
        550,
        4674,
        281,
        2059,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39651551842689514,
      "compression_ratio": 1.6554621458053589,
      "no_speech_prob": 0.004889755044132471
    },
    {
      "id": 41,
      "seek": 11100,
      "start": 1267.63,
      "end": 1270.63,
      "text": " And here might be a policy that says,",
      "tokens": [
        51414,
        400,
        510,
        1062,
        312,
        257,
        3897,
        300,
        1619,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39651551842689514,
      "compression_ratio": 1.6554621458053589,
      "no_speech_prob": 0.004889755044132471
    },
    {
      "id": 42,
      "seek": 11100,
      "start": 1270.63,
      "end": 1273.63,
      "text": " the next command is being created.",
      "tokens": [
        51564,
        264,
        958,
        5622,
        307,
        885,
        2942,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39651551842689514,
      "compression_ratio": 1.6554621458053589,
      "no_speech_prob": 0.004889755044132471
    },
    {
      "id": 43,
      "seek": 11100,
      "start": 1273.63,
      "end": 1274.63,
      "text": " So that's an automatism.",
      "tokens": [
        51714,
        407,
        300,
        311,
        364,
        28034,
        1434,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39651551842689514,
      "compression_ratio": 1.6554621458053589,
      "no_speech_prob": 0.004889755044132471
    },
    {
      "id": 44,
      "seek": 13900,
      "start": 1274.63,
      "end": 1277.63,
      "text": " That means, if the order has been accepted,",
      "tokens": [
        50364,
        663,
        1355,
        11,
        498,
        264,
        1668,
        575,
        668,
        9035,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34869590401649475,
      "compression_ratio": 1.4954954385757446,
      "no_speech_prob": 0.03808383643627167
    },
    {
      "id": 45,
      "seek": 13900,
      "start": 1277.63,
      "end": 1280.63,
      "text": " I can have a policy that now says, okay, all right.",
      "tokens": [
        50514,
        286,
        393,
        362,
        257,
        3897,
        300,
        586,
        1619,
        11,
        1392,
        11,
        439,
        558,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34869590401649475,
      "compression_ratio": 1.4954954385757446,
      "no_speech_prob": 0.03808383643627167
    },
    {
      "id": 46,
      "seek": 13900,
      "start": 1280.63,
      "end": 1284.63,
      "text": " Then I will now somehow, please write an invoice",
      "tokens": [
        50664,
        1396,
        286,
        486,
        586,
        6063,
        11,
        1767,
        2464,
        364,
        47919,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34869590401649475,
      "compression_ratio": 1.4954954385757446,
      "no_speech_prob": 0.03808383643627167
    },
    {
      "id": 47,
      "seek": 13900,
      "start": 1284.63,
      "end": 1290.63,
      "text": " and make sure that the thing is delivered.",
      "tokens": [
        50864,
        293,
        652,
        988,
        300,
        264,
        551,
        307,
        10144,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34869590401649475,
      "compression_ratio": 1.4954954385757446,
      "no_speech_prob": 0.03808383643627167
    },
    {
      "id": 48,
      "seek": 13900,
      "start": 1290.63,
      "end": 1292.63,
      "text": " So that's the idea.",
      "tokens": [
        51164,
        407,
        300,
        311,
        264,
        1558,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34869590401649475,
      "compression_ratio": 1.4954954385757446,
      "no_speech_prob": 0.03808383643627167
    },
    {
      "id": 49,
      "seek": 13900,
      "start": 1292.63,
      "end": 1296.63,
      "text": " And that's how I get into a granular model.",
      "tokens": [
        51264,
        400,
        300,
        311,
        577,
        286,
        483,
        666,
        257,
        39962,
        2316,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34869590401649475,
      "compression_ratio": 1.4954954385757446,
      "no_speech_prob": 0.03808383643627167
    },
    {
      "id": 50,
      "seek": 13900,
      "start": 1296.63,
      "end": 1300.63,
      "text": " So I would have in the Big Picture Event Storming,",
      "tokens": [
        51464,
        407,
        286,
        576,
        362,
        294,
        264,
        5429,
        35730,
        13222,
        745,
        284,
        2810,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34869590401649475,
      "compression_ratio": 1.4954954385757446,
      "no_speech_prob": 0.03808383643627167
    },
    {
      "id": 51,
      "seek": 13900,
      "start": 1300.63,
      "end": 1302.63,
      "text": " which we discussed last time,",
      "tokens": [
        51664,
        597,
        321,
        7152,
        1036,
        565,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34869590401649475,
      "compression_ratio": 1.4954954385757446,
      "no_speech_prob": 0.03808383643627167
    },
    {
      "id": 52,
      "seek": 16700,
      "start": 1302.63,
      "end": 1305.63,
      "text": " I would only have this here, so the domain events.",
      "tokens": [
        50364,
        286,
        576,
        787,
        362,
        341,
        510,
        11,
        370,
        264,
        9274,
        3931,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3870775103569031,
      "compression_ratio": 1.615384578704834,
      "no_speech_prob": 0.06163713335990906
    },
    {
      "id": 53,
      "seek": 16700,
      "start": 1305.63,
      "end": 1308.63,
      "text": " Here I have a lot of additional information",
      "tokens": [
        50514,
        1692,
        286,
        362,
        257,
        688,
        295,
        4497,
        1589,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3870775103569031,
      "compression_ratio": 1.615384578704834,
      "no_speech_prob": 0.06163713335990906
    },
    {
      "id": 54,
      "seek": 16700,
      "start": 1308.63,
      "end": 1312.63,
      "text": " that gives me a deeper, better understanding",
      "tokens": [
        50664,
        300,
        2709,
        385,
        257,
        7731,
        11,
        1101,
        3701,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3870775103569031,
      "compression_ratio": 1.615384578704834,
      "no_speech_prob": 0.06163713335990906
    },
    {
      "id": 55,
      "seek": 16700,
      "start": 1312.63,
      "end": 1314.63,
      "text": " of what is actually happening.",
      "tokens": [
        50864,
        295,
        437,
        307,
        767,
        2737,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3870775103569031,
      "compression_ratio": 1.615384578704834,
      "no_speech_prob": 0.06163713335990906
    },
    {
      "id": 56,
      "seek": 16700,
      "start": 1314.63,
      "end": 1317.63,
      "text": " And I'll remind you again that this is something",
      "tokens": [
        50964,
        400,
        286,
        603,
        4160,
        291,
        797,
        300,
        341,
        307,
        746,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3870775103569031,
      "compression_ratio": 1.615384578704834,
      "no_speech_prob": 0.06163713335990906
    },
    {
      "id": 57,
      "seek": 16700,
      "start": 1317.63,
      "end": 1320.63,
      "text": " that we now want to create together with domain experts.",
      "tokens": [
        51114,
        300,
        321,
        586,
        528,
        281,
        1884,
        1214,
        365,
        9274,
        8572,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3870775103569031,
      "compression_ratio": 1.615384578704834,
      "no_speech_prob": 0.06163713335990906
    },
    {
      "id": 58,
      "seek": 16700,
      "start": 1320.63,
      "end": 1326.63,
      "text": " And the goal is, so the domain is now at this detail level,",
      "tokens": [
        51264,
        400,
        264,
        3387,
        307,
        11,
        370,
        264,
        9274,
        307,
        586,
        412,
        341,
        2607,
        1496,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3870775103569031,
      "compression_ratio": 1.615384578704834,
      "no_speech_prob": 0.06163713335990906
    },
    {
      "id": 59,
      "seek": 19100,
      "start": 1326.63,
      "end": 1333.63,
      "text": " that I need for a tactical domain-driven design,",
      "tokens": [
        50364,
        300,
        286,
        643,
        337,
        257,
        26323,
        9274,
        12,
        25456,
        1715,
        11,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.340833455324173,
      "compression_ratio": 1.634730577468872,
      "no_speech_prob": 0.08844739198684692
    },
    {
      "id": 60,
      "seek": 19100,
      "start": 1333.63,
      "end": 1338.63,
      "text": " that I understand that on this level.",
      "tokens": [
        50714,
        300,
        286,
        1223,
        300,
        322,
        341,
        1496,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.340833455324173,
      "compression_ratio": 1.634730577468872,
      "no_speech_prob": 0.08844739198684692
    },
    {
      "id": 61,
      "seek": 19100,
      "start": 1338.63,
      "end": 1341.63,
      "text": " And there is now no,",
      "tokens": [
        50964,
        400,
        456,
        307,
        586,
        572,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.340833455324173,
      "compression_ratio": 1.634730577468872,
      "no_speech_prob": 0.08844739198684692
    },
    {
      "id": 62,
      "seek": 19100,
      "start": 1341.63,
      "end": 1343.63,
      "text": " so I would say,",
      "tokens": [
        51114,
        370,
        286,
        576,
        584,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.340833455324173,
      "compression_ratio": 1.634730577468872,
      "no_speech_prob": 0.08844739198684692
    },
    {
      "id": 63,
      "seek": 19100,
      "start": 1343.63,
      "end": 1346.63,
      "text": " obviously there is no trivial mapping",
      "tokens": [
        51214,
        2745,
        456,
        307,
        572,
        26703,
        18350,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.340833455324173,
      "compression_ratio": 1.634730577468872,
      "no_speech_prob": 0.08844739198684692
    },
    {
      "id": 64,
      "seek": 19100,
      "start": 1346.63,
      "end": 1348.63,
      "text": " to tactical domain-driven design.",
      "tokens": [
        51364,
        281,
        26323,
        9274,
        12,
        25456,
        1715,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.340833455324173,
      "compression_ratio": 1.634730577468872,
      "no_speech_prob": 0.08844739198684692
    },
    {
      "id": 65,
      "seek": 19100,
      "start": 1348.63,
      "end": 1351.63,
      "text": " In other words, what we see here now",
      "tokens": [
        51464,
        682,
        661,
        2283,
        11,
        437,
        321,
        536,
        510,
        586,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.340833455324173,
      "compression_ratio": 1.634730577468872,
      "no_speech_prob": 0.08844739198684692
    },
    {
      "id": 66,
      "seek": 19100,
      "start": 1351.63,
      "end": 1354.63,
      "text": " is a completely different field of view.",
      "tokens": [
        51614,
        307,
        257,
        2584,
        819,
        2519,
        295,
        1910,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.340833455324173,
      "compression_ratio": 1.634730577468872,
      "no_speech_prob": 0.08844739198684692
    },
    {
      "id": 67,
      "seek": 21900,
      "start": 1354.63,
      "end": 1357.63,
      "text": " So we're talking about systems, we're talking about read models,",
      "tokens": [
        50364,
        407,
        321,
        434,
        1417,
        466,
        3652,
        11,
        321,
        434,
        1417,
        466,
        1401,
        5245,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26575520634651184,
      "compression_ratio": 1.8326530456542969,
      "no_speech_prob": 0.053315989673137665
    },
    {
      "id": 68,
      "seek": 21900,
      "start": 1357.63,
      "end": 1359.63,
      "text": " we're talking about UI.",
      "tokens": [
        50514,
        321,
        434,
        1417,
        466,
        15682,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26575520634651184,
      "compression_ratio": 1.8326530456542969,
      "no_speech_prob": 0.053315989673137665
    },
    {
      "id": 69,
      "seek": 21900,
      "start": 1359.63,
      "end": 1362.63,
      "text": " These are all things that don't occur in this tactical domain-driven design.",
      "tokens": [
        50614,
        1981,
        366,
        439,
        721,
        300,
        500,
        380,
        5160,
        294,
        341,
        26323,
        9274,
        12,
        25456,
        1715,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26575520634651184,
      "compression_ratio": 1.8326530456542969,
      "no_speech_prob": 0.053315989673137665
    },
    {
      "id": 70,
      "seek": 21900,
      "start": 1362.63,
      "end": 1365.63,
      "text": " That's why it might be very exciting to see",
      "tokens": [
        50764,
        663,
        311,
        983,
        309,
        1062,
        312,
        588,
        4670,
        281,
        536,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26575520634651184,
      "compression_ratio": 1.8326530456542969,
      "no_speech_prob": 0.053315989673137665
    },
    {
      "id": 71,
      "seek": 21900,
      "start": 1365.63,
      "end": 1367.63,
      "text": " how I'm actually mapping this now.",
      "tokens": [
        50914,
        577,
        286,
        478,
        767,
        18350,
        341,
        586,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26575520634651184,
      "compression_ratio": 1.8326530456542969,
      "no_speech_prob": 0.053315989673137665
    },
    {
      "id": 72,
      "seek": 21900,
      "start": 1367.63,
      "end": 1373.63,
      "text": " And I would expect a command in tactical domain-driven design",
      "tokens": [
        51014,
        400,
        286,
        576,
        2066,
        257,
        5622,
        294,
        26323,
        9274,
        12,
        25456,
        1715,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26575520634651184,
      "compression_ratio": 1.8326530456542969,
      "no_speech_prob": 0.053315989673137665
    },
    {
      "id": 73,
      "seek": 21900,
      "start": 1373.63,
      "end": 1377.63,
      "text": " is a method call on an aggregate or on a service.",
      "tokens": [
        51314,
        307,
        257,
        3170,
        818,
        322,
        364,
        26118,
        420,
        322,
        257,
        2643,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26575520634651184,
      "compression_ratio": 1.8326530456542969,
      "no_speech_prob": 0.053315989673137665
    },
    {
      "id": 74,
      "seek": 21900,
      "start": 1377.63,
      "end": 1380.63,
      "text": " So if I say now, I would like to order this,",
      "tokens": [
        51514,
        407,
        498,
        286,
        584,
        586,
        11,
        286,
        576,
        411,
        281,
        1668,
        341,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26575520634651184,
      "compression_ratio": 1.8326530456542969,
      "no_speech_prob": 0.053315989673137665
    },
    {
      "id": 75,
      "seek": 21900,
      "start": 1380.63,
      "end": 1383.63,
      "text": " then I would expect there is a method somewhere",
      "tokens": [
        51664,
        550,
        286,
        576,
        2066,
        456,
        307,
        257,
        3170,
        4079,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26575520634651184,
      "compression_ratio": 1.8326530456542969,
      "no_speech_prob": 0.053315989673137665
    },
    {
      "id": 76,
      "seek": 24800,
      "start": 1383.63,
      "end": 1385.63,
      "text": " or maybe several methods.",
      "tokens": [
        50364,
        420,
        1310,
        2940,
        7150,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4046212136745453,
      "compression_ratio": 1.6480686664581299,
      "no_speech_prob": 0.00635412847623229
    },
    {
      "id": 77,
      "seek": 24800,
      "start": 1385.63,
      "end": 1387.63,
      "text": " Yes, I would even say one method.",
      "tokens": [
        50464,
        1079,
        11,
        286,
        576,
        754,
        584,
        472,
        3170,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4046212136745453,
      "compression_ratio": 1.6480686664581299,
      "no_speech_prob": 0.00635412847623229
    },
    {
      "id": 78,
      "seek": 24800,
      "start": 1387.63,
      "end": 1392.63,
      "text": " It would say, okay, I'll order this whole thing for you now.",
      "tokens": [
        50564,
        467,
        576,
        584,
        11,
        1392,
        11,
        286,
        603,
        1668,
        341,
        1379,
        551,
        337,
        291,
        586,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4046212136745453,
      "compression_ratio": 1.6480686664581299,
      "no_speech_prob": 0.00635412847623229
    },
    {
      "id": 79,
      "seek": 24800,
      "start": 1392.63,
      "end": 1398.63,
      "text": " And in that case, it's probably in a service,",
      "tokens": [
        50814,
        400,
        294,
        300,
        1389,
        11,
        309,
        311,
        1391,
        294,
        257,
        2643,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4046212136745453,
      "compression_ratio": 1.6480686664581299,
      "no_speech_prob": 0.00635412847623229
    },
    {
      "id": 80,
      "seek": 24800,
      "start": 1398.63,
      "end": 1400.63,
      "text": " because I have to make an order in the context of it",
      "tokens": [
        51114,
        570,
        286,
        362,
        281,
        652,
        364,
        1668,
        294,
        264,
        4319,
        295,
        309,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4046212136745453,
      "compression_ratio": 1.6480686664581299,
      "no_speech_prob": 0.00635412847623229
    },
    {
      "id": 81,
      "seek": 24800,
      "start": 1400.63,
      "end": 1403.63,
      "text": " and have to create various other things.",
      "tokens": [
        51214,
        293,
        362,
        281,
        1884,
        3683,
        661,
        721,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4046212136745453,
      "compression_ratio": 1.6480686664581299,
      "no_speech_prob": 0.00635412847623229
    },
    {
      "id": 82,
      "seek": 24800,
      "start": 1403.63,
      "end": 1407.63,
      "text": " But it could also be in an aggregate for simple cases.",
      "tokens": [
        51364,
        583,
        309,
        727,
        611,
        312,
        294,
        364,
        26118,
        337,
        2199,
        3331,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4046212136745453,
      "compression_ratio": 1.6480686664581299,
      "no_speech_prob": 0.00635412847623229
    },
    {
      "id": 83,
      "seek": 24800,
      "start": 1407.63,
      "end": 1409.63,
      "text": " So then I have the system,",
      "tokens": [
        51564,
        407,
        550,
        286,
        362,
        264,
        1185,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4046212136745453,
      "compression_ratio": 1.6480686664581299,
      "no_speech_prob": 0.00635412847623229
    },
    {
      "id": 84,
      "seek": 24800,
      "start": 1409.63,
      "end": 1411.63,
      "text": " that would be my aggregate or my service,",
      "tokens": [
        51664,
        300,
        576,
        312,
        452,
        26118,
        420,
        452,
        2643,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4046212136745453,
      "compression_ratio": 1.6480686664581299,
      "no_speech_prob": 0.00635412847623229
    },
    {
      "id": 85,
      "seek": 27600,
      "start": 1411.63,
      "end": 1413.63,
      "text": " when I see the fine granular.",
      "tokens": [
        50364,
        562,
        286,
        536,
        264,
        2489,
        677,
        282,
        1040,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35180890560150146,
      "compression_ratio": 1.684000015258789,
      "no_speech_prob": 0.035316385328769684
    },
    {
      "id": 86,
      "seek": 27600,
      "start": 1413.63,
      "end": 1415.63,
      "text": " Now a domain event comes out of it.",
      "tokens": [
        50464,
        823,
        257,
        9274,
        2280,
        1487,
        484,
        295,
        309,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35180890560150146,
      "compression_ratio": 1.684000015258789,
      "no_speech_prob": 0.035316385328769684
    },
    {
      "id": 87,
      "seek": 27600,
      "start": 1415.63,
      "end": 1417.63,
      "text": " I could implement that directly as a domain event",
      "tokens": [
        50564,
        286,
        727,
        566,
        43704,
        300,
        3838,
        382,
        257,
        9274,
        2280,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35180890560150146,
      "compression_ratio": 1.684000015258789,
      "no_speech_prob": 0.035316385328769684
    },
    {
      "id": 88,
      "seek": 27600,
      "start": 1417.63,
      "end": 1420.63,
      "text": " also in tactical domain-driven design.",
      "tokens": [
        50664,
        611,
        294,
        26323,
        9274,
        12,
        25456,
        1715,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35180890560150146,
      "compression_ratio": 1.684000015258789,
      "no_speech_prob": 0.035316385328769684
    },
    {
      "id": 89,
      "seek": 27600,
      "start": 1420.63,
      "end": 1424.63,
      "text": " So that's something where this terminology is actually identical.",
      "tokens": [
        50814,
        407,
        300,
        311,
        746,
        689,
        341,
        27575,
        307,
        767,
        14800,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35180890560150146,
      "compression_ratio": 1.684000015258789,
      "no_speech_prob": 0.035316385328769684
    },
    {
      "id": 90,
      "seek": 27600,
      "start": 1424.63,
      "end": 1426.63,
      "text": " Then I have a read model,",
      "tokens": [
        51014,
        1396,
        286,
        362,
        257,
        1401,
        2316,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35180890560150146,
      "compression_ratio": 1.684000015258789,
      "no_speech_prob": 0.035316385328769684
    },
    {
      "id": 91,
      "seek": 27600,
      "start": 1426.63,
      "end": 1430.63,
      "text": " and that's ultimately an aggregate again.",
      "tokens": [
        51114,
        293,
        300,
        311,
        6284,
        364,
        26118,
        797,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35180890560150146,
      "compression_ratio": 1.684000015258789,
      "no_speech_prob": 0.035316385328769684
    },
    {
      "id": 92,
      "seek": 27600,
      "start": 1430.63,
      "end": 1433.63,
      "text": " That means the thing where I call the command here",
      "tokens": [
        51314,
        663,
        1355,
        264,
        551,
        689,
        286,
        818,
        264,
        5622,
        510,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35180890560150146,
      "compression_ratio": 1.684000015258789,
      "no_speech_prob": 0.035316385328769684
    },
    {
      "id": 93,
      "seek": 27600,
      "start": 1433.63,
      "end": 1435.63,
      "text": " and the thing that I'm showing here",
      "tokens": [
        51464,
        293,
        264,
        551,
        300,
        286,
        478,
        4099,
        510,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35180890560150146,
      "compression_ratio": 1.684000015258789,
      "no_speech_prob": 0.035316385328769684
    },
    {
      "id": 94,
      "seek": 27600,
      "start": 1435.63,
      "end": 1439.63,
      "text": " can be the same object from my point of view.",
      "tokens": [
        51564,
        393,
        312,
        264,
        912,
        2657,
        490,
        452,
        935,
        295,
        1910,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35180890560150146,
      "compression_ratio": 1.684000015258789,
      "no_speech_prob": 0.035316385328769684
    },
    {
      "id": 95,
      "seek": 30400,
      "start": 1440.63,
      "end": 1444.63,
      "text": " In one case, I use the reading stories",
      "tokens": [
        50414,
        682,
        472,
        1389,
        11,
        286,
        764,
        264,
        3760,
        3676,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2847576439380646,
      "compression_ratio": 1.8226600885391235,
      "no_speech_prob": 0.012010333128273487
    },
    {
      "id": 96,
      "seek": 30400,
      "start": 1444.63,
      "end": 1448.63,
      "text": " and in the other case, the writing stories.",
      "tokens": [
        50614,
        293,
        294,
        264,
        661,
        1389,
        11,
        264,
        3579,
        3676,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2847576439380646,
      "compression_ratio": 1.8226600885391235,
      "no_speech_prob": 0.012010333128273487
    },
    {
      "id": 97,
      "seek": 30400,
      "start": 1448.63,
      "end": 1451.63,
      "text": " I think it's a good practice",
      "tokens": [
        50814,
        286,
        519,
        309,
        311,
        257,
        665,
        3124,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2847576439380646,
      "compression_ratio": 1.8226600885391235,
      "no_speech_prob": 0.012010333128273487
    },
    {
      "id": 98,
      "seek": 30400,
      "start": 1451.63,
      "end": 1454.63,
      "text": " to separate the methods that change state",
      "tokens": [
        50964,
        281,
        4994,
        264,
        7150,
        300,
        1319,
        1785,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2847576439380646,
      "compression_ratio": 1.8226600885391235,
      "no_speech_prob": 0.012010333128273487
    },
    {
      "id": 99,
      "seek": 30400,
      "start": 1454.63,
      "end": 1457.63,
      "text": " from the methods that give me information about the state.",
      "tokens": [
        51114,
        490,
        264,
        7150,
        300,
        976,
        385,
        1589,
        466,
        264,
        1785,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2847576439380646,
      "compression_ratio": 1.8226600885391235,
      "no_speech_prob": 0.012010333128273487
    },
    {
      "id": 100,
      "seek": 30400,
      "start": 1457.63,
      "end": 1459.63,
      "text": " So I either have methods that say,",
      "tokens": [
        51264,
        407,
        286,
        2139,
        362,
        7150,
        300,
        584,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2847576439380646,
      "compression_ratio": 1.8226600885391235,
      "no_speech_prob": 0.012010333128273487
    },
    {
      "id": 101,
      "seek": 30400,
      "start": 1459.63,
      "end": 1463.63,
      "text": " I'll tell you something about the delivery,",
      "tokens": [
        51364,
        286,
        603,
        980,
        291,
        746,
        466,
        264,
        8982,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2847576439380646,
      "compression_ratio": 1.8226600885391235,
      "no_speech_prob": 0.012010333128273487
    },
    {
      "id": 102,
      "seek": 30400,
      "start": 1463.63,
      "end": 1466.63,
      "text": " what's in there, about products or something.",
      "tokens": [
        51564,
        437,
        311,
        294,
        456,
        11,
        466,
        3383,
        420,
        746,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2847576439380646,
      "compression_ratio": 1.8226600885391235,
      "no_speech_prob": 0.012010333128273487
    },
    {
      "id": 103,
      "seek": 30400,
      "start": 1466.63,
      "end": 1468.63,
      "text": " Or I have methods that make sure",
      "tokens": [
        51714,
        1610,
        286,
        362,
        7150,
        300,
        652,
        988,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2847576439380646,
      "compression_ratio": 1.8226600885391235,
      "no_speech_prob": 0.012010333128273487
    },
    {
      "id": 104,
      "seek": 33300,
      "start": 1468.63,
      "end": 1470.63,
      "text": " that something happens with this delivery.",
      "tokens": [
        50364,
        300,
        746,
        2314,
        365,
        341,
        8982,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3025442361831665,
      "compression_ratio": 1.6729323863983154,
      "no_speech_prob": 0.013073979876935482
    },
    {
      "id": 105,
      "seek": 33300,
      "start": 1470.63,
      "end": 1473.63,
      "text": " And this read model would then be part of the aggregate",
      "tokens": [
        50464,
        400,
        341,
        1401,
        2316,
        576,
        550,
        312,
        644,
        295,
        264,
        26118,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3025442361831665,
      "compression_ratio": 1.6729323863983154,
      "no_speech_prob": 0.013073979876935482
    },
    {
      "id": 106,
      "seek": 33300,
      "start": 1473.63,
      "end": 1477.63,
      "text": " that actually gives this information about this state.",
      "tokens": [
        50614,
        300,
        767,
        2709,
        341,
        1589,
        466,
        341,
        1785,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3025442361831665,
      "compression_ratio": 1.6729323863983154,
      "no_speech_prob": 0.013073979876935482
    },
    {
      "id": 107,
      "seek": 33300,
      "start": 1477.63,
      "end": 1482.63,
      "text": " We'll talk about things like CQS in a moment.",
      "tokens": [
        50814,
        492,
        603,
        751,
        466,
        721,
        411,
        383,
        48,
        50,
        294,
        257,
        1623,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3025442361831665,
      "compression_ratio": 1.6729323863983154,
      "no_speech_prob": 0.013073979876935482
    },
    {
      "id": 108,
      "seek": 33300,
      "start": 1482.63,
      "end": 1485.63,
      "text": " We would actually separate the read model now",
      "tokens": [
        51064,
        492,
        576,
        767,
        4994,
        264,
        1401,
        2316,
        586,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3025442361831665,
      "compression_ratio": 1.6729323863983154,
      "no_speech_prob": 0.013073979876935482
    },
    {
      "id": 109,
      "seek": 33300,
      "start": 1485.63,
      "end": 1487.63,
      "text": " and say, these are different classes,",
      "tokens": [
        51214,
        293,
        584,
        11,
        613,
        366,
        819,
        5359,
        11,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3025442361831665,
      "compression_ratio": 1.6729323863983154,
      "no_speech_prob": 0.013073979876935482
    },
    {
      "id": 110,
      "seek": 33300,
      "start": 1487.63,
      "end": 1489.63,
      "text": " maybe even a different microservice.",
      "tokens": [
        51314,
        1310,
        754,
        257,
        819,
        15547,
        25006,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3025442361831665,
      "compression_ratio": 1.6729323863983154,
      "no_speech_prob": 0.013073979876935482
    },
    {
      "id": 111,
      "seek": 33300,
      "start": 1489.63,
      "end": 1490.63,
      "text": " That's an option.",
      "tokens": [
        51414,
        663,
        311,
        364,
        3614,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3025442361831665,
      "compression_ratio": 1.6729323863983154,
      "no_speech_prob": 0.013073979876935482
    },
    {
      "id": 112,
      "seek": 33300,
      "start": 1490.63,
      "end": 1493.63,
      "text": " I personally don't think it's necessary.",
      "tokens": [
        51464,
        286,
        5665,
        500,
        380,
        519,
        309,
        311,
        4818,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3025442361831665,
      "compression_ratio": 1.6729323863983154,
      "no_speech_prob": 0.013073979876935482
    },
    {
      "id": 113,
      "seek": 33300,
      "start": 1493.63,
      "end": 1497.63,
      "text": " And here you can see exactly one of the possibilities I have now.",
      "tokens": [
        51614,
        400,
        510,
        291,
        393,
        536,
        2293,
        472,
        295,
        264,
        12178,
        286,
        362,
        586,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3025442361831665,
      "compression_ratio": 1.6729323863983154,
      "no_speech_prob": 0.013073979876935482
    },
    {
      "id": 114,
      "seek": 36200,
      "start": 1497.63,
      "end": 1500.63,
      "text": " So I can sit down as an architect and say,",
      "tokens": [
        50364,
        407,
        286,
        393,
        1394,
        760,
        382,
        364,
        6331,
        293,
        584,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3215049207210541,
      "compression_ratio": 1.6417909860610962,
      "no_speech_prob": 0.030217409133911133
    },
    {
      "id": 115,
      "seek": 36200,
      "start": 1500.63,
      "end": 1503.63,
      "text": " okay, we have a relatively simple case.",
      "tokens": [
        50514,
        1392,
        11,
        321,
        362,
        257,
        7226,
        2199,
        1389,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3215049207210541,
      "compression_ratio": 1.6417909860610962,
      "no_speech_prob": 0.030217409133911133
    },
    {
      "id": 116,
      "seek": 36200,
      "start": 1503.63,
      "end": 1508.63,
      "text": " We just pack the commands and the read model together.",
      "tokens": [
        50664,
        492,
        445,
        2844,
        264,
        16901,
        293,
        264,
        1401,
        2316,
        1214,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3215049207210541,
      "compression_ratio": 1.6417909860610962,
      "no_speech_prob": 0.030217409133911133
    },
    {
      "id": 117,
      "seek": 36200,
      "start": 1508.63,
      "end": 1511.63,
      "text": " Or I can say, for whatever reason, it's complicated",
      "tokens": [
        50914,
        1610,
        286,
        393,
        584,
        11,
        337,
        2035,
        1778,
        11,
        309,
        311,
        6179,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3215049207210541,
      "compression_ratio": 1.6417909860610962,
      "no_speech_prob": 0.030217409133911133
    },
    {
      "id": 118,
      "seek": 36200,
      "start": 1511.63,
      "end": 1513.63,
      "text": " and I want to separate that.",
      "tokens": [
        51064,
        293,
        286,
        528,
        281,
        4994,
        300,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3215049207210541,
      "compression_ratio": 1.6417909860610962,
      "no_speech_prob": 0.030217409133911133
    },
    {
      "id": 119,
      "seek": 36200,
      "start": 1513.63,
      "end": 1515.63,
      "text": " Maybe I want to scale the class.",
      "tokens": [
        51164,
        2704,
        286,
        528,
        281,
        4373,
        264,
        1508,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3215049207210541,
      "compression_ratio": 1.6417909860610962,
      "no_speech_prob": 0.030217409133911133
    },
    {
      "id": 120,
      "seek": 36200,
      "start": 1515.63,
      "end": 1516.63,
      "text": " Whatever.",
      "tokens": [
        51264,
        8541,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3215049207210541,
      "compression_ratio": 1.6417909860610962,
      "no_speech_prob": 0.030217409133911133
    },
    {
      "id": 121,
      "seek": 36200,
      "start": 1516.63,
      "end": 1517.63,
      "text": " Then I'll do CQS.",
      "tokens": [
        51314,
        1396,
        286,
        603,
        360,
        383,
        48,
        50,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3215049207210541,
      "compression_ratio": 1.6417909860610962,
      "no_speech_prob": 0.030217409133911133
    },
    {
      "id": 122,
      "seek": 36200,
      "start": 1517.63,
      "end": 1518.63,
      "text": " But that's not mandatory.",
      "tokens": [
        51364,
        583,
        300,
        311,
        406,
        22173,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3215049207210541,
      "compression_ratio": 1.6417909860610962,
      "no_speech_prob": 0.030217409133911133
    },
    {
      "id": 123,
      "seek": 36200,
      "start": 1518.63,
      "end": 1521.63,
      "text": " I just want to understand what people want here.",
      "tokens": [
        51414,
        286,
        445,
        528,
        281,
        1223,
        437,
        561,
        528,
        510,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3215049207210541,
      "compression_ratio": 1.6417909860610962,
      "no_speech_prob": 0.030217409133911133
    },
    {
      "id": 124,
      "seek": 36200,
      "start": 1521.63,
      "end": 1523.63,
      "text": " And for that, it might be quite interesting to see",
      "tokens": [
        51564,
        400,
        337,
        300,
        11,
        309,
        1062,
        312,
        1596,
        1880,
        281,
        536,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3215049207210541,
      "compression_ratio": 1.6417909860610962,
      "no_speech_prob": 0.030217409133911133
    },
    {
      "id": 125,
      "seek": 36200,
      "start": 1523.63,
      "end": 1525.63,
      "text": " what I actually want to read here.",
      "tokens": [
        51664,
        437,
        286,
        767,
        528,
        281,
        1401,
        510,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3215049207210541,
      "compression_ratio": 1.6417909860610962,
      "no_speech_prob": 0.030217409133911133
    },
    {
      "id": 126,
      "seek": 39000,
      "start": 1525.63,
      "end": 1527.63,
      "text": " And I get exactly this information",
      "tokens": [
        50364,
        400,
        286,
        483,
        2293,
        341,
        1589,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40939250588417053,
      "compression_ratio": 1.6188524961471558,
      "no_speech_prob": 0.42895740270614624
    },
    {
      "id": 127,
      "seek": 39000,
      "start": 1527.63,
      "end": 1529.63,
      "text": " from the design level events topic.",
      "tokens": [
        50464,
        490,
        264,
        1715,
        1496,
        3931,
        4829,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40939250588417053,
      "compression_ratio": 1.6188524961471558,
      "no_speech_prob": 0.42895740270614624
    },
    {
      "id": 128,
      "seek": 39000,
      "start": 1529.63,
      "end": 1532.63,
      "text": " The policy would now also be something",
      "tokens": [
        50564,
        440,
        3897,
        576,
        586,
        611,
        312,
        746,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40939250588417053,
      "compression_ratio": 1.6188524961471558,
      "no_speech_prob": 0.42895740270614624
    },
    {
      "id": 129,
      "seek": 39000,
      "start": 1532.63,
      "end": 1534.63,
      "text": " where a domain event is reacted to.",
      "tokens": [
        50714,
        689,
        257,
        9274,
        2280,
        307,
        34037,
        281,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40939250588417053,
      "compression_ratio": 1.6188524961471558,
      "no_speech_prob": 0.42895740270614624
    },
    {
      "id": 130,
      "seek": 39000,
      "start": 1534.63,
      "end": 1536.63,
      "text": " So some business logic that ensures",
      "tokens": [
        50814,
        407,
        512,
        1606,
        9952,
        300,
        28111,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40939250588417053,
      "compression_ratio": 1.6188524961471558,
      "no_speech_prob": 0.42895740270614624
    },
    {
      "id": 131,
      "seek": 39000,
      "start": 1536.63,
      "end": 1538.63,
      "text": " that, for example, this invoice is written.",
      "tokens": [
        50914,
        300,
        11,
        337,
        1365,
        11,
        341,
        47919,
        307,
        3720,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40939250588417053,
      "compression_ratio": 1.6188524961471558,
      "no_speech_prob": 0.42895740270614624
    },
    {
      "id": 132,
      "seek": 39000,
      "start": 1538.63,
      "end": 1540.63,
      "text": " That's something that might happen again",
      "tokens": [
        51014,
        663,
        311,
        746,
        300,
        1062,
        1051,
        797,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40939250588417053,
      "compression_ratio": 1.6188524961471558,
      "no_speech_prob": 0.42895740270614624
    },
    {
      "id": 133,
      "seek": 39000,
      "start": 1540.63,
      "end": 1543.63,
      "text": " in an aggregate or in a service.",
      "tokens": [
        51114,
        294,
        364,
        26118,
        420,
        294,
        257,
        2643,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40939250588417053,
      "compression_ratio": 1.6188524961471558,
      "no_speech_prob": 0.42895740270614624
    },
    {
      "id": 134,
      "seek": 39000,
      "start": 1543.63,
      "end": 1546.63,
      "text": " Where business logic is typically.",
      "tokens": [
        51264,
        2305,
        1606,
        9952,
        307,
        5850,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40939250588417053,
      "compression_ratio": 1.6188524961471558,
      "no_speech_prob": 0.42895740270614624
    },
    {
      "id": 135,
      "seek": 39000,
      "start": 1546.63,
      "end": 1553.63,
      "text": " And that's actually where I'm through with the topic so far.",
      "tokens": [
        51414,
        400,
        300,
        311,
        767,
        689,
        286,
        478,
        807,
        365,
        264,
        4829,
        370,
        1400,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40939250588417053,
      "compression_ratio": 1.6188524961471558,
      "no_speech_prob": 0.42895740270614624
    },
    {
      "id": 136,
      "seek": 41800,
      "start": 1554.63,
      "end": 1560.63,
      "text": " And can continue with the next topic.",
      "tokens": [
        50414,
        400,
        393,
        2354,
        365,
        264,
        958,
        4829,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43516239523887634,
      "compression_ratio": 1.4905660152435303,
      "no_speech_prob": 0.3504922389984131
    },
    {
      "id": 137,
      "seek": 41800,
      "start": 1560.63,
      "end": 1563.63,
      "text": " This is this story with the event sourcing.",
      "tokens": [
        50714,
        639,
        307,
        341,
        1657,
        365,
        264,
        2280,
        11006,
        2175,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43516239523887634,
      "compression_ratio": 1.4905660152435303,
      "no_speech_prob": 0.3504922389984131
    },
    {
      "id": 138,
      "seek": 41800,
      "start": 1563.63,
      "end": 1565.63,
      "text": " Let's see that I have the next table.",
      "tokens": [
        50864,
        961,
        311,
        536,
        300,
        286,
        362,
        264,
        958,
        3199,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43516239523887634,
      "compression_ratio": 1.4905660152435303,
      "no_speech_prob": 0.3504922389984131
    },
    {
      "id": 139,
      "seek": 41800,
      "start": 1565.63,
      "end": 1567.63,
      "text": " Exactly, here it is.",
      "tokens": [
        50964,
        7587,
        11,
        510,
        309,
        307,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43516239523887634,
      "compression_ratio": 1.4905660152435303,
      "no_speech_prob": 0.3504922389984131
    },
    {
      "id": 140,
      "seek": 41800,
      "start": 1570.63,
      "end": 1572.63,
      "text": " Here is a little bit.",
      "tokens": [
        51214,
        1692,
        307,
        257,
        707,
        857,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43516239523887634,
      "compression_ratio": 1.4905660152435303,
      "no_speech_prob": 0.3504922389984131
    },
    {
      "id": 141,
      "seek": 41800,
      "start": 1572.63,
      "end": 1574.63,
      "text": " We still have about half time.",
      "tokens": [
        51314,
        492,
        920,
        362,
        466,
        1922,
        565,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43516239523887634,
      "compression_ratio": 1.4905660152435303,
      "no_speech_prob": 0.3504922389984131
    },
    {
      "id": 142,
      "seek": 41800,
      "start": 1574.63,
      "end": 1576.63,
      "text": " Here is a little bit now.",
      "tokens": [
        51414,
        1692,
        307,
        257,
        707,
        857,
        586,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43516239523887634,
      "compression_ratio": 1.4905660152435303,
      "no_speech_prob": 0.3504922389984131
    },
    {
      "id": 143,
      "seek": 41800,
      "start": 1576.63,
      "end": 1578.63,
      "text": " How should I say?",
      "tokens": [
        51514,
        1012,
        820,
        286,
        584,
        30,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43516239523887634,
      "compression_ratio": 1.4905660152435303,
      "no_speech_prob": 0.3504922389984131
    },
    {
      "id": 144,
      "seek": 44300,
      "start": 1579.63,
      "end": 1582.63,
      "text": " This is another topic.",
      "tokens": [
        50414,
        639,
        307,
        1071,
        4829,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34817105531692505,
      "compression_ratio": 1.5981308221817017,
      "no_speech_prob": 0.06819044053554535
    },
    {
      "id": 145,
      "seek": 44300,
      "start": 1582.63,
      "end": 1585.63,
      "text": " Event sourcing and CQS are somehow possibilities",
      "tokens": [
        50564,
        13222,
        11006,
        2175,
        293,
        383,
        48,
        50,
        366,
        6063,
        12178,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34817105531692505,
      "compression_ratio": 1.5981308221817017,
      "no_speech_prob": 0.06819044053554535
    },
    {
      "id": 146,
      "seek": 44300,
      "start": 1585.63,
      "end": 1587.63,
      "text": " how I just implement certain things.",
      "tokens": [
        50714,
        577,
        286,
        445,
        4445,
        1629,
        721,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34817105531692505,
      "compression_ratio": 1.5981308221817017,
      "no_speech_prob": 0.06819044053554535
    },
    {
      "id": 147,
      "seek": 44300,
      "start": 1587.63,
      "end": 1593.63,
      "text": " And they are independent of tactical domain design.",
      "tokens": [
        50814,
        400,
        436,
        366,
        6695,
        295,
        26323,
        9274,
        1715,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34817105531692505,
      "compression_ratio": 1.5981308221817017,
      "no_speech_prob": 0.06819044053554535
    },
    {
      "id": 148,
      "seek": 44300,
      "start": 1593.63,
      "end": 1595.63,
      "text": " I think I'll say again in a moment",
      "tokens": [
        51114,
        286,
        519,
        286,
        603,
        584,
        797,
        294,
        257,
        1623,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34817105531692505,
      "compression_ratio": 1.5981308221817017,
      "no_speech_prob": 0.06819044053554535
    },
    {
      "id": 149,
      "seek": 44300,
      "start": 1595.63,
      "end": 1598.63,
      "text": " how I rate this topic as a whole.",
      "tokens": [
        51214,
        577,
        286,
        3314,
        341,
        4829,
        382,
        257,
        1379,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34817105531692505,
      "compression_ratio": 1.5981308221817017,
      "no_speech_prob": 0.06819044053554535
    },
    {
      "id": 150,
      "seek": 44300,
      "start": 1598.63,
      "end": 1600.63,
      "text": " So whether it's mandatory or whatever.",
      "tokens": [
        51364,
        407,
        1968,
        309,
        311,
        22173,
        420,
        2035,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34817105531692505,
      "compression_ratio": 1.5981308221817017,
      "no_speech_prob": 0.06819044053554535
    },
    {
      "id": 151,
      "seek": 44300,
      "start": 1600.63,
      "end": 1604.63,
      "text": " And event sourcing means that the events",
      "tokens": [
        51464,
        400,
        2280,
        11006,
        2175,
        1355,
        300,
        264,
        3931,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34817105531692505,
      "compression_ratio": 1.5981308221817017,
      "no_speech_prob": 0.06819044053554535
    },
    {
      "id": 152,
      "seek": 44300,
      "start": 1604.63,
      "end": 1607.63,
      "text": " that have led to a certain state",
      "tokens": [
        51664,
        300,
        362,
        4684,
        281,
        257,
        1629,
        1785,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34817105531692505,
      "compression_ratio": 1.5981308221817017,
      "no_speech_prob": 0.06819044053554535
    },
    {
      "id": 153,
      "seek": 47200,
      "start": 1607.63,
      "end": 1610.63,
      "text": " I also save.",
      "tokens": [
        50364,
        286,
        611,
        3155,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3348214328289032,
      "compression_ratio": 1.6875,
      "no_speech_prob": 0.0054659112356603146
    },
    {
      "id": 154,
      "seek": 47200,
      "start": 1610.63,
      "end": 1613.63,
      "text": " I can also save the state itself.",
      "tokens": [
        50514,
        286,
        393,
        611,
        3155,
        264,
        1785,
        2564,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3348214328289032,
      "compression_ratio": 1.6875,
      "no_speech_prob": 0.0054659112356603146
    },
    {
      "id": 155,
      "seek": 47200,
      "start": 1613.63,
      "end": 1615.63,
      "text": " Obviously I don't necessarily have to.",
      "tokens": [
        50664,
        7580,
        286,
        500,
        380,
        4725,
        362,
        281,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3348214328289032,
      "compression_ratio": 1.6875,
      "no_speech_prob": 0.0054659112356603146
    },
    {
      "id": 156,
      "seek": 47200,
      "start": 1615.63,
      "end": 1618.63,
      "text": " Because I can emit this state from the events.",
      "tokens": [
        50764,
        1436,
        286,
        393,
        32084,
        341,
        1785,
        490,
        264,
        3931,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3348214328289032,
      "compression_ratio": 1.6875,
      "no_speech_prob": 0.0054659112356603146
    },
    {
      "id": 157,
      "seek": 47200,
      "start": 1618.63,
      "end": 1622.63,
      "text": " And I can now as a system of record.",
      "tokens": [
        50914,
        400,
        286,
        393,
        586,
        382,
        257,
        1185,
        295,
        2136,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3348214328289032,
      "compression_ratio": 1.6875,
      "no_speech_prob": 0.0054659112356603146
    },
    {
      "id": 158,
      "seek": 47200,
      "start": 1622.63,
      "end": 1626.63,
      "text": " So the system that should actually be the reliable one.",
      "tokens": [
        51114,
        407,
        264,
        1185,
        300,
        820,
        767,
        312,
        264,
        12924,
        472,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3348214328289032,
      "compression_ratio": 1.6875,
      "no_speech_prob": 0.0054659112356603146
    },
    {
      "id": 159,
      "seek": 47200,
      "start": 1626.63,
      "end": 1629.63,
      "text": " I can either say that's the state or the events.",
      "tokens": [
        51314,
        286,
        393,
        2139,
        584,
        300,
        311,
        264,
        1785,
        420,
        264,
        3931,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3348214328289032,
      "compression_ratio": 1.6875,
      "no_speech_prob": 0.0054659112356603146
    },
    {
      "id": 160,
      "seek": 47200,
      "start": 1629.63,
      "end": 1631.63,
      "text": " That's up to me.",
      "tokens": [
        51464,
        663,
        311,
        493,
        281,
        385,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3348214328289032,
      "compression_ratio": 1.6875,
      "no_speech_prob": 0.0054659112356603146
    },
    {
      "id": 161,
      "seek": 47200,
      "start": 1633.63,
      "end": 1636.63,
      "text": " So that means what I can do now.",
      "tokens": [
        51664,
        407,
        300,
        1355,
        437,
        286,
        393,
        360,
        586,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3348214328289032,
      "compression_ratio": 1.6875,
      "no_speech_prob": 0.0054659112356603146
    },
    {
      "id": 162,
      "seek": 50100,
      "start": 1636.63,
      "end": 1638.63,
      "text": " For example with an order.",
      "tokens": [
        50364,
        1171,
        1365,
        365,
        364,
        1668,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3916284441947937,
      "compression_ratio": 1.6976743936538696,
      "no_speech_prob": 0.006181319709867239
    },
    {
      "id": 163,
      "seek": 50100,
      "start": 1638.63,
      "end": 1641.63,
      "text": " I have an event store here.",
      "tokens": [
        50464,
        286,
        362,
        364,
        2280,
        3531,
        510,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3916284441947937,
      "compression_ratio": 1.6976743936538696,
      "no_speech_prob": 0.006181319709867239
    },
    {
      "id": 164,
      "seek": 50100,
      "start": 1641.63,
      "end": 1643.63,
      "text": " And I have the state here.",
      "tokens": [
        50614,
        400,
        286,
        362,
        264,
        1785,
        510,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3916284441947937,
      "compression_ratio": 1.6976743936538696,
      "no_speech_prob": 0.006181319709867239
    },
    {
      "id": 165,
      "seek": 50100,
      "start": 1643.63,
      "end": 1645.63,
      "text": " And now I have an interface here.",
      "tokens": [
        50714,
        400,
        586,
        286,
        362,
        364,
        9226,
        510,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3916284441947937,
      "compression_ratio": 1.6976743936538696,
      "no_speech_prob": 0.006181319709867239
    },
    {
      "id": 166,
      "seek": 50100,
      "start": 1645.63,
      "end": 1648.63,
      "text": " And some calls, some messages",
      "tokens": [
        50814,
        400,
        512,
        5498,
        11,
        512,
        7897,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3916284441947937,
      "compression_ratio": 1.6976743936538696,
      "no_speech_prob": 0.006181319709867239
    },
    {
      "id": 167,
      "seek": 50100,
      "start": 1648.63,
      "end": 1650.63,
      "text": " are pressed on me.",
      "tokens": [
        50964,
        366,
        17355,
        322,
        385,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3916284441947937,
      "compression_ratio": 1.6976743936538696,
      "no_speech_prob": 0.006181319709867239
    },
    {
      "id": 168,
      "seek": 50100,
      "start": 1650.63,
      "end": 1652.63,
      "text": " So I'm talking about a system",
      "tokens": [
        51064,
        407,
        286,
        478,
        1417,
        466,
        257,
        1185,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3916284441947937,
      "compression_ratio": 1.6976743936538696,
      "no_speech_prob": 0.006181319709867239
    },
    {
      "id": 169,
      "seek": 50100,
      "start": 1652.63,
      "end": 1654.63,
      "text": " which is dealing with",
      "tokens": [
        51164,
        597,
        307,
        6260,
        365,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3916284441947937,
      "compression_ratio": 1.6976743936538696,
      "no_speech_prob": 0.006181319709867239
    },
    {
      "id": 170,
      "seek": 50100,
      "start": 1654.63,
      "end": 1656.63,
      "text": " to do something with orders.",
      "tokens": [
        51264,
        281,
        360,
        746,
        365,
        9470,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3916284441947937,
      "compression_ratio": 1.6976743936538696,
      "no_speech_prob": 0.006181319709867239
    },
    {
      "id": 171,
      "seek": 50100,
      "start": 1656.63,
      "end": 1659.63,
      "text": " And here comes in a call",
      "tokens": [
        51364,
        400,
        510,
        1487,
        294,
        257,
        818,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3916284441947937,
      "compression_ratio": 1.6976743936538696,
      "no_speech_prob": 0.006181319709867239
    },
    {
      "id": 172,
      "seek": 50100,
      "start": 1659.63,
      "end": 1661.63,
      "text": " which says this order 42",
      "tokens": [
        51514,
        597,
        1619,
        341,
        1668,
        14034,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3916284441947937,
      "compression_ratio": 1.6976743936538696,
      "no_speech_prob": 0.006181319709867239
    },
    {
      "id": 173,
      "seek": 50100,
      "start": 1661.63,
      "end": 1663.63,
      "text": " which should be delivered now.",
      "tokens": [
        51614,
        597,
        820,
        312,
        10144,
        586,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3916284441947937,
      "compression_ratio": 1.6976743936538696,
      "no_speech_prob": 0.006181319709867239
    },
    {
      "id": 174,
      "seek": 50100,
      "start": 1663.63,
      "end": 1665.63,
      "text": " That means I notice in the event store",
      "tokens": [
        51714,
        663,
        1355,
        286,
        3449,
        294,
        264,
        2280,
        3531,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3916284441947937,
      "compression_ratio": 1.6976743936538696,
      "no_speech_prob": 0.006181319709867239
    },
    {
      "id": 175,
      "seek": 53000,
      "start": 1665.63,
      "end": 1667.63,
      "text": " that this order 42",
      "tokens": [
        50364,
        300,
        341,
        1668,
        14034,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30846747756004333,
      "compression_ratio": 1.7902438640594482,
      "no_speech_prob": 0.0051315040327608585
    },
    {
      "id": 176,
      "seek": 53000,
      "start": 1667.63,
      "end": 1670.63,
      "text": " should actually be delivered",
      "tokens": [
        50464,
        820,
        767,
        312,
        368,
        75,
        1837,
        292,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30846747756004333,
      "compression_ratio": 1.7902438640594482,
      "no_speech_prob": 0.0051315040327608585
    },
    {
      "id": 177,
      "seek": 53000,
      "start": 1670.63,
      "end": 1672.63,
      "text": " and is accepted.",
      "tokens": [
        50614,
        293,
        307,
        9035,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30846747756004333,
      "compression_ratio": 1.7902438640594482,
      "no_speech_prob": 0.0051315040327608585
    },
    {
      "id": 178,
      "seek": 53000,
      "start": 1672.63,
      "end": 1673.63,
      "text": " And then I have the state here",
      "tokens": [
        50714,
        400,
        550,
        286,
        362,
        264,
        1785,
        510,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30846747756004333,
      "compression_ratio": 1.7902438640594482,
      "no_speech_prob": 0.0051315040327608585
    },
    {
      "id": 179,
      "seek": 53000,
      "start": 1673.63,
      "end": 1674.63,
      "text": " which now somehow says",
      "tokens": [
        50764,
        597,
        586,
        6063,
        1619,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30846747756004333,
      "compression_ratio": 1.7902438640594482,
      "no_speech_prob": 0.0051315040327608585
    },
    {
      "id": 180,
      "seek": 53000,
      "start": 1674.63,
      "end": 1676.63,
      "text": " the order 42 exists.",
      "tokens": [
        50814,
        264,
        1668,
        14034,
        8198,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30846747756004333,
      "compression_ratio": 1.7902438640594482,
      "no_speech_prob": 0.0051315040327608585
    },
    {
      "id": 181,
      "seek": 53000,
      "start": 1676.63,
      "end": 1677.63,
      "text": " Then comes the next call",
      "tokens": [
        50914,
        1396,
        1487,
        264,
        958,
        818,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30846747756004333,
      "compression_ratio": 1.7902438640594482,
      "no_speech_prob": 0.0051315040327608585
    },
    {
      "id": 182,
      "seek": 53000,
      "start": 1677.63,
      "end": 1678.63,
      "text": " which somehow says",
      "tokens": [
        50964,
        597,
        6063,
        1619,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30846747756004333,
      "compression_ratio": 1.7902438640594482,
      "no_speech_prob": 0.0051315040327608585
    },
    {
      "id": 183,
      "seek": 53000,
      "start": 1678.63,
      "end": 1681.63,
      "text": " okay, order 23 is somehow there.",
      "tokens": [
        51014,
        1392,
        11,
        1668,
        6673,
        307,
        6063,
        456,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30846747756004333,
      "compression_ratio": 1.7902438640594482,
      "no_speech_prob": 0.0051315040327608585
    },
    {
      "id": 184,
      "seek": 53000,
      "start": 1681.63,
      "end": 1685.63,
      "text": " And then I have here as a state",
      "tokens": [
        51164,
        400,
        550,
        286,
        362,
        510,
        382,
        257,
        1785,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30846747756004333,
      "compression_ratio": 1.7902438640594482,
      "no_speech_prob": 0.0051315040327608585
    },
    {
      "id": 185,
      "seek": 53000,
      "start": 1685.63,
      "end": 1687.63,
      "text": " also the order 23.",
      "tokens": [
        51364,
        611,
        264,
        1668,
        6673,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30846747756004333,
      "compression_ratio": 1.7902438640594482,
      "no_speech_prob": 0.0051315040327608585
    },
    {
      "id": 186,
      "seek": 53000,
      "start": 1687.63,
      "end": 1688.63,
      "text": " Then I say next",
      "tokens": [
        51464,
        1396,
        286,
        584,
        958,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30846747756004333,
      "compression_ratio": 1.7902438640594482,
      "no_speech_prob": 0.0051315040327608585
    },
    {
      "id": 187,
      "seek": 53000,
      "start": 1688.63,
      "end": 1690.63,
      "text": " the order 42 is cancelled.",
      "tokens": [
        51514,
        264,
        1668,
        14034,
        307,
        25103,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30846747756004333,
      "compression_ratio": 1.7902438640594482,
      "no_speech_prob": 0.0051315040327608585
    },
    {
      "id": 188,
      "seek": 53000,
      "start": 1690.63,
      "end": 1692.63,
      "text": " That's an event again.",
      "tokens": [
        51614,
        663,
        311,
        364,
        2280,
        797,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30846747756004333,
      "compression_ratio": 1.7902438640594482,
      "no_speech_prob": 0.0051315040327608585
    },
    {
      "id": 189,
      "seek": 53000,
      "start": 1692.63,
      "end": 1694.63,
      "text": " I notice that again in the state.",
      "tokens": [
        51714,
        286,
        3449,
        300,
        797,
        294,
        264,
        1785,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30846747756004333,
      "compression_ratio": 1.7902438640594482,
      "no_speech_prob": 0.0051315040327608585
    },
    {
      "id": 190,
      "seek": 55900,
      "start": 1694.63,
      "end": 1695.63,
      "text": " And then I say",
      "tokens": [
        50364,
        400,
        550,
        286,
        584,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3038838803768158,
      "compression_ratio": 1.725274682044983,
      "no_speech_prob": 0.0013881949707865715
    },
    {
      "id": 191,
      "seek": 55900,
      "start": 1695.63,
      "end": 1696.63,
      "text": " the other is somehow delivered.",
      "tokens": [
        50414,
        264,
        661,
        307,
        6063,
        10144,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3038838803768158,
      "compression_ratio": 1.725274682044983,
      "no_speech_prob": 0.0013881949707865715
    },
    {
      "id": 192,
      "seek": 55900,
      "start": 1696.63,
      "end": 1698.63,
      "text": " And I notice that again in the state.",
      "tokens": [
        50464,
        400,
        286,
        3449,
        300,
        797,
        294,
        264,
        1785,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3038838803768158,
      "compression_ratio": 1.725274682044983,
      "no_speech_prob": 0.0013881949707865715
    },
    {
      "id": 193,
      "seek": 55900,
      "start": 1698.63,
      "end": 1700.63,
      "text": " So that means",
      "tokens": [
        50564,
        407,
        300,
        1355,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3038838803768158,
      "compression_ratio": 1.725274682044983,
      "no_speech_prob": 0.0013881949707865715
    },
    {
      "id": 194,
      "seek": 55900,
      "start": 1700.63,
      "end": 1702.63,
      "text": " I have a system here",
      "tokens": [
        50664,
        286,
        362,
        257,
        1185,
        510,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3038838803768158,
      "compression_ratio": 1.725274682044983,
      "no_speech_prob": 0.0013881949707865715
    },
    {
      "id": 195,
      "seek": 55900,
      "start": 1702.63,
      "end": 1705.63,
      "text": " which saves the state",
      "tokens": [
        50764,
        597,
        19155,
        264,
        1785,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3038838803768158,
      "compression_ratio": 1.725274682044983,
      "no_speech_prob": 0.0013881949707865715
    },
    {
      "id": 196,
      "seek": 55900,
      "start": 1705.63,
      "end": 1707.63,
      "text": " and also the events",
      "tokens": [
        50914,
        293,
        611,
        264,
        3931,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3038838803768158,
      "compression_ratio": 1.725274682044983,
      "no_speech_prob": 0.0013881949707865715
    },
    {
      "id": 197,
      "seek": 55900,
      "start": 1707.63,
      "end": 1710.63,
      "text": " which led to this state.",
      "tokens": [
        51014,
        597,
        4684,
        281,
        341,
        1785,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3038838803768158,
      "compression_ratio": 1.725274682044983,
      "no_speech_prob": 0.0013881949707865715
    },
    {
      "id": 198,
      "seek": 55900,
      "start": 1710.63,
      "end": 1713.63,
      "text": " When ordering",
      "tokens": [
        51164,
        1133,
        21739,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3038838803768158,
      "compression_ratio": 1.725274682044983,
      "no_speech_prob": 0.0013881949707865715
    },
    {
      "id": 199,
      "seek": 55900,
      "start": 1713.63,
      "end": 1714.63,
      "text": " I'm not sure",
      "tokens": [
        51314,
        286,
        478,
        406,
        988,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3038838803768158,
      "compression_ratio": 1.725274682044983,
      "no_speech_prob": 0.0013881949707865715
    },
    {
      "id": 200,
      "seek": 55900,
      "start": 1714.63,
      "end": 1717.63,
      "text": " whether this is really necessary.",
      "tokens": [
        51364,
        1968,
        341,
        307,
        534,
        4818,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3038838803768158,
      "compression_ratio": 1.725274682044983,
      "no_speech_prob": 0.0013881949707865715
    },
    {
      "id": 201,
      "seek": 55900,
      "start": 1717.63,
      "end": 1719.63,
      "text": " With an account",
      "tokens": [
        51514,
        2022,
        364,
        2696,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3038838803768158,
      "compression_ratio": 1.725274682044983,
      "no_speech_prob": 0.0013881949707865715
    },
    {
      "id": 202,
      "seek": 55900,
      "start": 1719.63,
      "end": 1721.63,
      "text": " I'm relatively sure",
      "tokens": [
        51614,
        286,
        478,
        7226,
        988,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3038838803768158,
      "compression_ratio": 1.725274682044983,
      "no_speech_prob": 0.0013881949707865715
    },
    {
      "id": 203,
      "seek": 55900,
      "start": 1721.63,
      "end": 1723.63,
      "text": " that this is really necessary.",
      "tokens": [
        51714,
        300,
        341,
        307,
        534,
        4818,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3038838803768158,
      "compression_ratio": 1.725274682044983,
      "no_speech_prob": 0.0013881949707865715
    },
    {
      "id": 204,
      "seek": 58800,
      "start": 1723.63,
      "end": 1726.63,
      "text": " Because I'm not only interested",
      "tokens": [
        50364,
        1436,
        286,
        478,
        406,
        787,
        3102,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3556089401245117,
      "compression_ratio": 1.601941704750061,
      "no_speech_prob": 0.02671993151307106
    },
    {
      "id": 205,
      "seek": 58800,
      "start": 1726.63,
      "end": 1728.63,
      "text": " how much money I have on my account right now",
      "tokens": [
        50514,
        577,
        709,
        1460,
        286,
        362,
        322,
        452,
        2696,
        558,
        586,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3556089401245117,
      "compression_ratio": 1.601941704750061,
      "no_speech_prob": 0.02671993151307106
    },
    {
      "id": 206,
      "seek": 58800,
      "start": 1728.63,
      "end": 1729.63,
      "text": " but also whether the last transfers",
      "tokens": [
        50614,
        457,
        611,
        1968,
        264,
        1036,
        29137,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3556089401245117,
      "compression_ratio": 1.601941704750061,
      "no_speech_prob": 0.02671993151307106
    },
    {
      "id": 207,
      "seek": 58800,
      "start": 1729.63,
      "end": 1732.63,
      "text": " have entered me.",
      "tokens": [
        50664,
        362,
        9065,
        385,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3556089401245117,
      "compression_ratio": 1.601941704750061,
      "no_speech_prob": 0.02671993151307106
    },
    {
      "id": 208,
      "seek": 58800,
      "start": 1732.63,
      "end": 1735.63,
      "text": " And that leads to",
      "tokens": [
        50814,
        400,
        300,
        6689,
        281,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3556089401245117,
      "compression_ratio": 1.601941704750061,
      "no_speech_prob": 0.02671993151307106
    },
    {
      "id": 209,
      "seek": 58800,
      "start": 1735.63,
      "end": 1741.63,
      "text": " that we can distinguish systems here.",
      "tokens": [
        50964,
        300,
        321,
        393,
        20206,
        3652,
        510,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3556089401245117,
      "compression_ratio": 1.601941704750061,
      "no_speech_prob": 0.02671993151307106
    },
    {
      "id": 210,
      "seek": 58800,
      "start": 1741.63,
      "end": 1742.63,
      "text": " So we have systems",
      "tokens": [
        51264,
        407,
        321,
        362,
        3652,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3556089401245117,
      "compression_ratio": 1.601941704750061,
      "no_speech_prob": 0.02671993151307106
    },
    {
      "id": 211,
      "seek": 58800,
      "start": 1742.63,
      "end": 1744.63,
      "text": " which only save the state.",
      "tokens": [
        51314,
        597,
        787,
        3155,
        264,
        1785,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3556089401245117,
      "compression_ratio": 1.601941704750061,
      "no_speech_prob": 0.02671993151307106
    },
    {
      "id": 212,
      "seek": 58800,
      "start": 1744.63,
      "end": 1745.63,
      "text": " So I could now have a system",
      "tokens": [
        51414,
        407,
        286,
        727,
        586,
        362,
        257,
        1185,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3556089401245117,
      "compression_ratio": 1.601941704750061,
      "no_speech_prob": 0.02671993151307106
    },
    {
      "id": 213,
      "seek": 58800,
      "start": 1745.63,
      "end": 1746.63,
      "text": " which says",
      "tokens": [
        51464,
        597,
        1619,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3556089401245117,
      "compression_ratio": 1.601941704750061,
      "no_speech_prob": 0.02671993151307106
    },
    {
      "id": 214,
      "seek": 58800,
      "start": 1746.63,
      "end": 1747.63,
      "text": " hey, the order 42",
      "tokens": [
        51514,
        4177,
        11,
        264,
        1668,
        14034,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3556089401245117,
      "compression_ratio": 1.601941704750061,
      "no_speech_prob": 0.02671993151307106
    },
    {
      "id": 215,
      "seek": 58800,
      "start": 1747.63,
      "end": 1749.63,
      "text": " is delivered to me, period.",
      "tokens": [
        51564,
        307,
        10144,
        281,
        385,
        11,
        2896,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3556089401245117,
      "compression_ratio": 1.601941704750061,
      "no_speech_prob": 0.02671993151307106
    },
    {
      "id": 216,
      "seek": 58800,
      "start": 1749.63,
      "end": 1751.63,
      "text": " And I could",
      "tokens": [
        51664,
        400,
        286,
        727,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3556089401245117,
      "compression_ratio": 1.601941704750061,
      "no_speech_prob": 0.02671993151307106
    },
    {
      "id": 217,
      "seek": 61600,
      "start": 1751.63,
      "end": 1753.63,
      "text": " calculate the state on the fly.",
      "tokens": [
        50364,
        8873,
        264,
        1785,
        322,
        264,
        3603,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3086245357990265,
      "compression_ratio": 1.6966824531555176,
      "no_speech_prob": 0.2965995669364929
    },
    {
      "id": 218,
      "seek": 61600,
      "start": 1753.63,
      "end": 1754.63,
      "text": " I could, for example,",
      "tokens": [
        50464,
        286,
        727,
        11,
        337,
        1365,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3086245357990265,
      "compression_ratio": 1.6966824531555176,
      "no_speech_prob": 0.2965995669364929
    },
    {
      "id": 219,
      "seek": 61600,
      "start": 1754.63,
      "end": 1756.63,
      "text": " determine the account state",
      "tokens": [
        50514,
        6997,
        264,
        2696,
        1785,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3086245357990265,
      "compression_ratio": 1.6966824531555176,
      "no_speech_prob": 0.2965995669364929
    },
    {
      "id": 220,
      "seek": 61600,
      "start": 1756.63,
      "end": 1757.63,
      "text": " from the transfers and transactions",
      "tokens": [
        50614,
        490,
        264,
        29137,
        293,
        16856,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3086245357990265,
      "compression_ratio": 1.6966824531555176,
      "no_speech_prob": 0.2965995669364929
    },
    {
      "id": 221,
      "seek": 61600,
      "start": 1757.63,
      "end": 1759.63,
      "text": " that have occurred so far.",
      "tokens": [
        50664,
        300,
        362,
        11068,
        370,
        1400,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3086245357990265,
      "compression_ratio": 1.6966824531555176,
      "no_speech_prob": 0.2965995669364929
    },
    {
      "id": 222,
      "seek": 61600,
      "start": 1759.63,
      "end": 1761.63,
      "text": " Or I can save the account state",
      "tokens": [
        50764,
        1610,
        286,
        393,
        3155,
        264,
        2696,
        1785,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3086245357990265,
      "compression_ratio": 1.6966824531555176,
      "no_speech_prob": 0.2965995669364929
    },
    {
      "id": 223,
      "seek": 61600,
      "start": 1761.63,
      "end": 1762.63,
      "text": " and also the events",
      "tokens": [
        50864,
        293,
        611,
        264,
        3931,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3086245357990265,
      "compression_ratio": 1.6966824531555176,
      "no_speech_prob": 0.2965995669364929
    },
    {
      "id": 224,
      "seek": 61600,
      "start": 1762.63,
      "end": 1764.63,
      "text": " that led to it.",
      "tokens": [
        50914,
        300,
        4684,
        281,
        309,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3086245357990265,
      "compression_ratio": 1.6966824531555176,
      "no_speech_prob": 0.2965995669364929
    },
    {
      "id": 225,
      "seek": 61600,
      "start": 1764.63,
      "end": 1766.63,
      "text": " And when I save these events",
      "tokens": [
        51014,
        400,
        562,
        286,
        3155,
        613,
        3931,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3086245357990265,
      "compression_ratio": 1.6966824531555176,
      "no_speech_prob": 0.2965995669364929
    },
    {
      "id": 226,
      "seek": 61600,
      "start": 1766.63,
      "end": 1771.63,
      "text": " then it is event sourcing.",
      "tokens": [
        51114,
        550,
        309,
        307,
        2280,
        11006,
        2175,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3086245357990265,
      "compression_ratio": 1.6966824531555176,
      "no_speech_prob": 0.2965995669364929
    },
    {
      "id": 227,
      "seek": 61600,
      "start": 1771.63,
      "end": 1773.63,
      "text": " There is one more note",
      "tokens": [
        51364,
        821,
        307,
        472,
        544,
        3637,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3086245357990265,
      "compression_ratio": 1.6966824531555176,
      "no_speech_prob": 0.2965995669364929
    },
    {
      "id": 228,
      "seek": 61600,
      "start": 1773.63,
      "end": 1775.63,
      "text": " which is important to me.",
      "tokens": [
        51464,
        597,
        307,
        1021,
        281,
        385,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3086245357990265,
      "compression_ratio": 1.6966824531555176,
      "no_speech_prob": 0.2965995669364929
    },
    {
      "id": 229,
      "seek": 61600,
      "start": 1775.63,
      "end": 1777.63,
      "text": " This is actually",
      "tokens": [
        51564,
        639,
        307,
        767,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3086245357990265,
      "compression_ratio": 1.6966824531555176,
      "no_speech_prob": 0.2965995669364929
    },
    {
      "id": 230,
      "seek": 61600,
      "start": 1777.63,
      "end": 1779.63,
      "text": " a persistence strategy.",
      "tokens": [
        51664,
        257,
        37617,
        5206,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3086245357990265,
      "compression_ratio": 1.6966824531555176,
      "no_speech_prob": 0.2965995669364929
    },
    {
      "id": 231,
      "seek": 64400,
      "start": 1779.63,
      "end": 1781.63,
      "text": " That means the question is",
      "tokens": [
        50364,
        663,
        1355,
        264,
        1168,
        307,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2468189150094986,
      "compression_ratio": 1.6473430395126343,
      "no_speech_prob": 0.006089194677770138
    },
    {
      "id": 232,
      "seek": 64400,
      "start": 1781.63,
      "end": 1783.63,
      "text": " how do I save my account",
      "tokens": [
        50464,
        577,
        360,
        286,
        3155,
        452,
        2696,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2468189150094986,
      "compression_ratio": 1.6473430395126343,
      "no_speech_prob": 0.006089194677770138
    },
    {
      "id": 233,
      "seek": 64400,
      "start": 1783.63,
      "end": 1784.63,
      "text": " or my order.",
      "tokens": [
        50564,
        420,
        452,
        1668,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2468189150094986,
      "compression_ratio": 1.6473430395126343,
      "no_speech_prob": 0.006089194677770138
    },
    {
      "id": 234,
      "seek": 64400,
      "start": 1784.63,
      "end": 1785.63,
      "text": " And I can now say",
      "tokens": [
        50614,
        400,
        286,
        393,
        586,
        584,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2468189150094986,
      "compression_ratio": 1.6473430395126343,
      "no_speech_prob": 0.006089194677770138
    },
    {
      "id": 235,
      "seek": 64400,
      "start": 1785.63,
      "end": 1787.63,
      "text": " I save the state",
      "tokens": [
        50664,
        286,
        3155,
        264,
        1785,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2468189150094986,
      "compression_ratio": 1.6473430395126343,
      "no_speech_prob": 0.006089194677770138
    },
    {
      "id": 236,
      "seek": 64400,
      "start": 1787.63,
      "end": 1788.63,
      "text": " and also the events",
      "tokens": [
        50764,
        293,
        611,
        264,
        3931,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2468189150094986,
      "compression_ratio": 1.6473430395126343,
      "no_speech_prob": 0.006089194677770138
    },
    {
      "id": 237,
      "seek": 64400,
      "start": 1788.63,
      "end": 1790.63,
      "text": " that led to it.",
      "tokens": [
        50814,
        300,
        4684,
        281,
        309,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2468189150094986,
      "compression_ratio": 1.6473430395126343,
      "no_speech_prob": 0.006089194677770138
    },
    {
      "id": 238,
      "seek": 64400,
      "start": 1790.63,
      "end": 1791.63,
      "text": " A persistence strategy",
      "tokens": [
        50914,
        316,
        37617,
        5206,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2468189150094986,
      "compression_ratio": 1.6473430395126343,
      "no_speech_prob": 0.006089194677770138
    },
    {
      "id": 239,
      "seek": 64400,
      "start": 1791.63,
      "end": 1793.63,
      "text": " should be internal.",
      "tokens": [
        50964,
        820,
        312,
        6920,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2468189150094986,
      "compression_ratio": 1.6473430395126343,
      "no_speech_prob": 0.006089194677770138
    },
    {
      "id": 240,
      "seek": 64400,
      "start": 1793.63,
      "end": 1794.63,
      "text": " That means",
      "tokens": [
        51064,
        663,
        1355,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2468189150094986,
      "compression_ratio": 1.6473430395126343,
      "no_speech_prob": 0.006089194677770138
    },
    {
      "id": 241,
      "seek": 64400,
      "start": 1794.63,
      "end": 1795.63,
      "text": " whoever is responsible",
      "tokens": [
        51114,
        11387,
        307,
        6250,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2468189150094986,
      "compression_ratio": 1.6473430395126343,
      "no_speech_prob": 0.006089194677770138
    },
    {
      "id": 242,
      "seek": 64400,
      "start": 1795.63,
      "end": 1797.63,
      "text": " for something like accounts",
      "tokens": [
        51164,
        337,
        746,
        411,
        9402,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2468189150094986,
      "compression_ratio": 1.6473430395126343,
      "no_speech_prob": 0.006089194677770138
    },
    {
      "id": 243,
      "seek": 64400,
      "start": 1797.63,
      "end": 1799.63,
      "text": " or whatever I have there",
      "tokens": [
        51264,
        420,
        2035,
        286,
        362,
        456,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2468189150094986,
      "compression_ratio": 1.6473430395126343,
      "no_speech_prob": 0.006089194677770138
    },
    {
      "id": 244,
      "seek": 64400,
      "start": 1799.63,
      "end": 1800.63,
      "text": " should choose",
      "tokens": [
        51364,
        820,
        2826,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2468189150094986,
      "compression_ratio": 1.6473430395126343,
      "no_speech_prob": 0.006089194677770138
    },
    {
      "id": 245,
      "seek": 64400,
      "start": 1800.63,
      "end": 1802.63,
      "text": " whether to do event sourcing or not.",
      "tokens": [
        51414,
        1968,
        281,
        360,
        2280,
        11006,
        2175,
        420,
        406,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2468189150094986,
      "compression_ratio": 1.6473430395126343,
      "no_speech_prob": 0.006089194677770138
    },
    {
      "id": 246,
      "seek": 64400,
      "start": 1802.63,
      "end": 1804.63,
      "text": " This means in particular",
      "tokens": [
        51514,
        639,
        1355,
        294,
        1729,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2468189150094986,
      "compression_ratio": 1.6473430395126343,
      "no_speech_prob": 0.006089194677770138
    },
    {
      "id": 247,
      "seek": 66900,
      "start": 1804.63,
      "end": 1809.63,
      "text": " that it should not be the case",
      "tokens": [
        50364,
        300,
        309,
        820,
        406,
        312,
        264,
        1389,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38823992013931274,
      "compression_ratio": 1.42148756980896,
      "no_speech_prob": 0.6362496018409729
    },
    {
      "id": 248,
      "seek": 66900,
      "start": 1809.63,
      "end": 1813.63,
      "text": " that the externally observable events",
      "tokens": [
        50614,
        300,
        264,
        40899,
        9951,
        712,
        3931,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38823992013931274,
      "compression_ratio": 1.42148756980896,
      "no_speech_prob": 0.6362496018409729
    },
    {
      "id": 249,
      "seek": 66900,
      "start": 1813.63,
      "end": 1822.63,
      "text": " lead to me having my local state.",
      "tokens": [
        50814,
        1477,
        281,
        385,
        1419,
        452,
        2654,
        1785,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38823992013931274,
      "compression_ratio": 1.42148756980896,
      "no_speech_prob": 0.6362496018409729
    },
    {
      "id": 250,
      "seek": 66900,
      "start": 1822.63,
      "end": 1825.63,
      "text": " And there is actually",
      "tokens": [
        51264,
        400,
        456,
        307,
        767,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38823992013931274,
      "compression_ratio": 1.42148756980896,
      "no_speech_prob": 0.6362496018409729
    },
    {
      "id": 251,
      "seek": 66900,
      "start": 1825.63,
      "end": 1830.63,
      "text": " in the show notes",
      "tokens": [
        51414,
        294,
        264,
        855,
        5570,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38823992013931274,
      "compression_ratio": 1.42148756980896,
      "no_speech_prob": 0.6362496018409729
    },
    {
      "id": 252,
      "seek": 66900,
      "start": 1830.63,
      "end": 1831.63,
      "text": " there is a video",
      "tokens": [
        51664,
        456,
        307,
        257,
        960,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38823992013931274,
      "compression_ratio": 1.42148756980896,
      "no_speech_prob": 0.6362496018409729
    },
    {
      "id": 253,
      "seek": 66900,
      "start": 1831.63,
      "end": 1833.63,
      "text": " where I said",
      "tokens": [
        51714,
        689,
        286,
        848,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38823992013931274,
      "compression_ratio": 1.42148756980896,
      "no_speech_prob": 0.6362496018409729
    },
    {
      "id": 254,
      "seek": 69800,
      "start": 1833.63,
      "end": 1836.63,
      "text": " when I save all events in Kafka",
      "tokens": [
        50364,
        562,
        286,
        3155,
        439,
        3931,
        294,
        47064,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29294314980506897,
      "compression_ratio": 1.8805969953536987,
      "no_speech_prob": 0.08975730091333389
    },
    {
      "id": 255,
      "seek": 69800,
      "start": 1836.63,
      "end": 1838.63,
      "text": " and then somehow say",
      "tokens": [
        50514,
        293,
        550,
        6063,
        584,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29294314980506897,
      "compression_ratio": 1.8805969953536987,
      "no_speech_prob": 0.08975730091333389
    },
    {
      "id": 256,
      "seek": 69800,
      "start": 1838.63,
      "end": 1839.63,
      "text": " okay, I can somehow",
      "tokens": [
        50614,
        1392,
        11,
        286,
        393,
        6063,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29294314980506897,
      "compression_ratio": 1.8805969953536987,
      "no_speech_prob": 0.08975730091333389
    },
    {
      "id": 257,
      "seek": 69800,
      "start": 1839.63,
      "end": 1840.63,
      "text": " use the local state",
      "tokens": [
        50664,
        764,
        264,
        2654,
        1785,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29294314980506897,
      "compression_ratio": 1.8805969953536987,
      "no_speech_prob": 0.08975730091333389
    },
    {
      "id": 258,
      "seek": 69800,
      "start": 1840.63,
      "end": 1842.63,
      "text": " of the microservices",
      "tokens": [
        50714,
        295,
        264,
        15547,
        47480,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29294314980506897,
      "compression_ratio": 1.8805969953536987,
      "no_speech_prob": 0.08975730091333389
    },
    {
      "id": 259,
      "seek": 69800,
      "start": 1842.63,
      "end": 1843.63,
      "text": " from these central events",
      "tokens": [
        50814,
        490,
        613,
        5777,
        3931,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29294314980506897,
      "compression_ratio": 1.8805969953536987,
      "no_speech_prob": 0.08975730091333389
    },
    {
      "id": 260,
      "seek": 69800,
      "start": 1843.63,
      "end": 1844.63,
      "text": " in Kafka",
      "tokens": [
        50864,
        294,
        47064,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29294314980506897,
      "compression_ratio": 1.8805969953536987,
      "no_speech_prob": 0.08975730091333389
    },
    {
      "id": 261,
      "seek": 69800,
      "start": 1844.63,
      "end": 1846.63,
      "text": " for communication.",
      "tokens": [
        50914,
        337,
        6101,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29294314980506897,
      "compression_ratio": 1.8805969953536987,
      "no_speech_prob": 0.08975730091333389
    },
    {
      "id": 262,
      "seek": 69800,
      "start": 1846.63,
      "end": 1847.63,
      "text": " I can reconstruct this state",
      "tokens": [
        51014,
        286,
        393,
        31499,
        341,
        1785,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29294314980506897,
      "compression_ratio": 1.8805969953536987,
      "no_speech_prob": 0.08975730091333389
    },
    {
      "id": 263,
      "seek": 69800,
      "start": 1847.63,
      "end": 1849.63,
      "text": " of the microservices.",
      "tokens": [
        51064,
        295,
        264,
        15547,
        47480,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29294314980506897,
      "compression_ratio": 1.8805969953536987,
      "no_speech_prob": 0.08975730091333389
    },
    {
      "id": 264,
      "seek": 69800,
      "start": 1849.63,
      "end": 1850.63,
      "text": " Then I actually have",
      "tokens": [
        51164,
        1396,
        286,
        767,
        362,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29294314980506897,
      "compression_ratio": 1.8805969953536987,
      "no_speech_prob": 0.08975730091333389
    },
    {
      "id": 265,
      "seek": 69800,
      "start": 1850.63,
      "end": 1852.63,
      "text": " a database monolith.",
      "tokens": [
        51214,
        257,
        8149,
        1108,
        29131,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29294314980506897,
      "compression_ratio": 1.8805969953536987,
      "no_speech_prob": 0.08975730091333389
    },
    {
      "id": 266,
      "seek": 69800,
      "start": 1852.63,
      "end": 1854.63,
      "text": " The microservices do not have",
      "tokens": [
        51314,
        440,
        15547,
        47480,
        360,
        406,
        362,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29294314980506897,
      "compression_ratio": 1.8805969953536987,
      "no_speech_prob": 0.08975730091333389
    },
    {
      "id": 267,
      "seek": 69800,
      "start": 1854.63,
      "end": 1856.63,
      "text": " independent data models,",
      "tokens": [
        51414,
        6695,
        1412,
        5245,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29294314980506897,
      "compression_ratio": 1.8805969953536987,
      "no_speech_prob": 0.08975730091333389
    },
    {
      "id": 268,
      "seek": 69800,
      "start": 1856.63,
      "end": 1857.63,
      "text": " but they only have a cache",
      "tokens": [
        51514,
        457,
        436,
        787,
        362,
        257,
        19459,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29294314980506897,
      "compression_ratio": 1.8805969953536987,
      "no_speech_prob": 0.08975730091333389
    },
    {
      "id": 269,
      "seek": 69800,
      "start": 1857.63,
      "end": 1861.63,
      "text": " for what is in Kafka.",
      "tokens": [
        51564,
        337,
        437,
        307,
        294,
        47064,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29294314980506897,
      "compression_ratio": 1.8805969953536987,
      "no_speech_prob": 0.08975730091333389
    },
    {
      "id": 270,
      "seek": 69800,
      "start": 1861.63,
      "end": 1862.63,
      "text": " I can somehow",
      "tokens": [
        51764,
        286,
        393,
        6063,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29294314980506897,
      "compression_ratio": 1.8805969953536987,
      "no_speech_prob": 0.08975730091333389
    },
    {
      "id": 271,
      "seek": 72700,
      "start": 1862.63,
      "end": 1863.63,
      "text": " remove their database.",
      "tokens": [
        50364,
        4159,
        641,
        8149,
        13,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37107327580451965,
      "compression_ratio": 1.7011070251464844,
      "no_speech_prob": 0.029265379533171654
    },
    {
      "id": 272,
      "seek": 72700,
      "start": 1863.63,
      "end": 1864.63,
      "text": " Then they say,",
      "tokens": [
        50414,
        1396,
        436,
        584,
        11,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37107327580451965,
      "compression_ratio": 1.7011070251464844,
      "no_speech_prob": 0.029265379533171654
    },
    {
      "id": 273,
      "seek": 72700,
      "start": 1864.63,
      "end": 1865.63,
      "text": " no problem,",
      "tokens": [
        50464,
        572,
        1154,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37107327580451965,
      "compression_ratio": 1.7011070251464844,
      "no_speech_prob": 0.029265379533171654
    },
    {
      "id": 274,
      "seek": 72700,
      "start": 1865.63,
      "end": 1866.63,
      "text": " I read all the events again.",
      "tokens": [
        50514,
        286,
        1401,
        439,
        264,
        3931,
        797,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37107327580451965,
      "compression_ratio": 1.7011070251464844,
      "no_speech_prob": 0.029265379533171654
    },
    {
      "id": 275,
      "seek": 72700,
      "start": 1866.63,
      "end": 1867.63,
      "text": " I have reconstructed the site.",
      "tokens": [
        50564,
        286,
        362,
        9993,
        372,
        1757,
        292,
        264,
        3621,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37107327580451965,
      "compression_ratio": 1.7011070251464844,
      "no_speech_prob": 0.029265379533171654
    },
    {
      "id": 276,
      "seek": 72700,
      "start": 1867.63,
      "end": 1868.63,
      "text": " And that can not,",
      "tokens": [
        50614,
        400,
        300,
        393,
        406,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37107327580451965,
      "compression_ratio": 1.7011070251464844,
      "no_speech_prob": 0.029265379533171654
    },
    {
      "id": 277,
      "seek": 72700,
      "start": 1868.63,
      "end": 1870.63,
      "text": " that must lead to",
      "tokens": [
        50664,
        300,
        1633,
        1477,
        281,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37107327580451965,
      "compression_ratio": 1.7011070251464844,
      "no_speech_prob": 0.029265379533171654
    },
    {
      "id": 278,
      "seek": 72700,
      "start": 1870.63,
      "end": 1871.63,
      "text": " that I somehow have",
      "tokens": [
        50764,
        300,
        286,
        6063,
        362,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37107327580451965,
      "compression_ratio": 1.7011070251464844,
      "no_speech_prob": 0.029265379533171654
    },
    {
      "id": 279,
      "seek": 72700,
      "start": 1871.63,
      "end": 1872.63,
      "text": " a high dependency there.",
      "tokens": [
        50814,
        257,
        1090,
        33621,
        456,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37107327580451965,
      "compression_ratio": 1.7011070251464844,
      "no_speech_prob": 0.029265379533171654
    },
    {
      "id": 280,
      "seek": 72700,
      "start": 1872.63,
      "end": 1873.63,
      "text": " And that's something",
      "tokens": [
        50864,
        400,
        300,
        311,
        746,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37107327580451965,
      "compression_ratio": 1.7011070251464844,
      "no_speech_prob": 0.029265379533171654
    },
    {
      "id": 281,
      "seek": 72700,
      "start": 1873.63,
      "end": 1875.63,
      "text": " I actually like to avoid.",
      "tokens": [
        50914,
        286,
        767,
        411,
        281,
        5042,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37107327580451965,
      "compression_ratio": 1.7011070251464844,
      "no_speech_prob": 0.029265379533171654
    },
    {
      "id": 282,
      "seek": 72700,
      "start": 1875.63,
      "end": 1877.63,
      "text": " That's why I find it difficult.",
      "tokens": [
        51014,
        663,
        311,
        983,
        286,
        915,
        309,
        2252,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37107327580451965,
      "compression_ratio": 1.7011070251464844,
      "no_speech_prob": 0.029265379533171654
    },
    {
      "id": 283,
      "seek": 72700,
      "start": 1877.63,
      "end": 1879.63,
      "text": " I'll link the video again.",
      "tokens": [
        51114,
        286,
        603,
        2113,
        264,
        960,
        797,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37107327580451965,
      "compression_ratio": 1.7011070251464844,
      "no_speech_prob": 0.029265379533171654
    },
    {
      "id": 284,
      "seek": 72700,
      "start": 1879.63,
      "end": 1883.63,
      "text": " And there is another story.",
      "tokens": [
        51214,
        400,
        456,
        307,
        1071,
        1657,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37107327580451965,
      "compression_ratio": 1.7011070251464844,
      "no_speech_prob": 0.029265379533171654
    },
    {
      "id": 285,
      "seek": 72700,
      "start": 1883.63,
      "end": 1885.63,
      "text": " I have to get the article out again.",
      "tokens": [
        51414,
        286,
        362,
        281,
        483,
        264,
        7222,
        484,
        797,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37107327580451965,
      "compression_ratio": 1.7011070251464844,
      "no_speech_prob": 0.029265379533171654
    },
    {
      "id": 286,
      "seek": 72700,
      "start": 1885.63,
      "end": 1886.63,
      "text": " Christian Stettler",
      "tokens": [
        51514,
        5778,
        745,
        3093,
        1918,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37107327580451965,
      "compression_ratio": 1.7011070251464844,
      "no_speech_prob": 0.029265379533171654
    },
    {
      "id": 287,
      "seek": 72700,
      "start": 1886.63,
      "end": 1888.63,
      "text": " wrote an article about it",
      "tokens": [
        51564,
        4114,
        364,
        7222,
        466,
        309,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37107327580451965,
      "compression_ratio": 1.7011070251464844,
      "no_speech_prob": 0.029265379533171654
    },
    {
      "id": 288,
      "seek": 72700,
      "start": 1888.63,
      "end": 1889.63,
      "text": " that these internal events",
      "tokens": [
        51664,
        300,
        613,
        6920,
        3931,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37107327580451965,
      "compression_ratio": 1.7011070251464844,
      "no_speech_prob": 0.029265379533171654
    },
    {
      "id": 289,
      "seek": 72700,
      "start": 1889.63,
      "end": 1891.63,
      "text": " are possibly fine granular.",
      "tokens": [
        51714,
        366,
        6264,
        2489,
        39962,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37107327580451965,
      "compression_ratio": 1.7011070251464844,
      "no_speech_prob": 0.029265379533171654
    },
    {
      "id": 290,
      "seek": 75600,
      "start": 1891.63,
      "end": 1894.63,
      "text": " Than what I want to announce externally.",
      "tokens": [
        50364,
        18289,
        437,
        286,
        528,
        281,
        7478,
        40899,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3664603531360626,
      "compression_ratio": 1.7424242496490479,
      "no_speech_prob": 0.08374866098165512
    },
    {
      "id": 291,
      "seek": 75600,
      "start": 1894.63,
      "end": 1896.63,
      "text": " If I say now,",
      "tokens": [
        50514,
        759,
        286,
        584,
        586,
        11,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3664603531360626,
      "compression_ratio": 1.7424242496490479,
      "no_speech_prob": 0.08374866098165512
    },
    {
      "id": 292,
      "seek": 75600,
      "start": 1896.63,
      "end": 1897.63,
      "text": " I am responsible for",
      "tokens": [
        50614,
        286,
        669,
        6250,
        337,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3664603531360626,
      "compression_ratio": 1.7424242496490479,
      "no_speech_prob": 0.08374866098165512
    },
    {
      "id": 293,
      "seek": 75600,
      "start": 1897.63,
      "end": 1899.63,
      "text": " that I register a customer.",
      "tokens": [
        50664,
        300,
        286,
        7280,
        257,
        5474,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3664603531360626,
      "compression_ratio": 1.7424242496490479,
      "no_speech_prob": 0.08374866098165512
    },
    {
      "id": 294,
      "seek": 75600,
      "start": 1899.63,
      "end": 1901.63,
      "text": " Then I have stories like,",
      "tokens": [
        50764,
        1396,
        286,
        362,
        3676,
        411,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3664603531360626,
      "compression_ratio": 1.7424242496490479,
      "no_speech_prob": 0.08374866098165512
    },
    {
      "id": 295,
      "seek": 75600,
      "start": 1901.63,
      "end": 1903.63,
      "text": " hey, your email address was not valid.",
      "tokens": [
        50864,
        4177,
        11,
        428,
        3796,
        2985,
        390,
        406,
        7363,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3664603531360626,
      "compression_ratio": 1.7424242496490479,
      "no_speech_prob": 0.08374866098165512
    },
    {
      "id": 296,
      "seek": 75600,
      "start": 1903.63,
      "end": 1905.63,
      "text": " Hey, your ID check",
      "tokens": [
        50964,
        1911,
        11,
        428,
        7348,
        1520,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3664603531360626,
      "compression_ratio": 1.7424242496490479,
      "no_speech_prob": 0.08374866098165512
    },
    {
      "id": 297,
      "seek": 75600,
      "start": 1905.63,
      "end": 1906.63,
      "text": " did not work.",
      "tokens": [
        51064,
        630,
        406,
        589,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3664603531360626,
      "compression_ratio": 1.7424242496490479,
      "no_speech_prob": 0.08374866098165512
    },
    {
      "id": 298,
      "seek": 75600,
      "start": 1906.63,
      "end": 1907.63,
      "text": " And these are all things",
      "tokens": [
        51114,
        400,
        613,
        366,
        439,
        721,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3664603531360626,
      "compression_ratio": 1.7424242496490479,
      "no_speech_prob": 0.08374866098165512
    },
    {
      "id": 299,
      "seek": 75600,
      "start": 1907.63,
      "end": 1909.63,
      "text": " that do not interest me externally.",
      "tokens": [
        51164,
        300,
        360,
        406,
        1179,
        385,
        40899,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3664603531360626,
      "compression_ratio": 1.7424242496490479,
      "no_speech_prob": 0.08374866098165512
    },
    {
      "id": 300,
      "seek": 75600,
      "start": 1909.63,
      "end": 1910.63,
      "text": " I just want to say",
      "tokens": [
        51264,
        286,
        445,
        528,
        281,
        584,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3664603531360626,
      "compression_ratio": 1.7424242496490479,
      "no_speech_prob": 0.08374866098165512
    },
    {
      "id": 301,
      "seek": 75600,
      "start": 1910.63,
      "end": 1912.63,
      "text": " this person is now validated.",
      "tokens": [
        51314,
        341,
        954,
        307,
        586,
        40693,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3664603531360626,
      "compression_ratio": 1.7424242496490479,
      "no_speech_prob": 0.08374866098165512
    },
    {
      "id": 302,
      "seek": 75600,
      "start": 1912.63,
      "end": 1913.63,
      "text": " And that's why it does.",
      "tokens": [
        51414,
        400,
        300,
        311,
        983,
        309,
        775,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3664603531360626,
      "compression_ratio": 1.7424242496490479,
      "no_speech_prob": 0.08374866098165512
    },
    {
      "id": 303,
      "seek": 75600,
      "start": 1913.63,
      "end": 1915.63,
      "text": " And there's the story again.",
      "tokens": [
        51464,
        400,
        456,
        311,
        264,
        1657,
        797,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3664603531360626,
      "compression_ratio": 1.7424242496490479,
      "no_speech_prob": 0.08374866098165512
    },
    {
      "id": 304,
      "seek": 75600,
      "start": 1915.63,
      "end": 1916.63,
      "text": " The internal events are different",
      "tokens": [
        51564,
        440,
        6920,
        3931,
        366,
        819,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3664603531360626,
      "compression_ratio": 1.7424242496490479,
      "no_speech_prob": 0.08374866098165512
    },
    {
      "id": 305,
      "seek": 75600,
      "start": 1916.63,
      "end": 1918.63,
      "text": " than the external events.",
      "tokens": [
        51614,
        813,
        264,
        8320,
        3931,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3664603531360626,
      "compression_ratio": 1.7424242496490479,
      "no_speech_prob": 0.08374866098165512
    },
    {
      "id": 306,
      "seek": 75600,
      "start": 1918.63,
      "end": 1920.63,
      "text": " That's why I want to separate that.",
      "tokens": [
        51714,
        663,
        311,
        983,
        286,
        528,
        281,
        4994,
        300,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3664603531360626,
      "compression_ratio": 1.7424242496490479,
      "no_speech_prob": 0.08374866098165512
    },
    {
      "id": 307,
      "seek": 78500,
      "start": 1921.63,
      "end": 1924.63,
      "text": " So what does that mean now?",
      "tokens": [
        50414,
        407,
        437,
        775,
        300,
        914,
        586,
        30,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36183667182922363,
      "compression_ratio": 1.6142857074737549,
      "no_speech_prob": 0.008049987256526947
    },
    {
      "id": 308,
      "seek": 78500,
      "start": 1924.63,
      "end": 1925.63,
      "text": " Can I do something like a ...",
      "tokens": [
        50564,
        1664,
        286,
        360,
        746,
        411,
        257,
        1097,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36183667182922363,
      "compression_ratio": 1.6142857074737549,
      "no_speech_prob": 0.008049987256526947
    },
    {
      "id": 309,
      "seek": 78500,
      "start": 1925.63,
      "end": 1927.63,
      "text": " So I have such a delivery.",
      "tokens": [
        50614,
        407,
        286,
        362,
        1270,
        257,
        8982,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36183667182922363,
      "compression_ratio": 1.6142857074737549,
      "no_speech_prob": 0.008049987256526947
    },
    {
      "id": 310,
      "seek": 78500,
      "start": 1927.63,
      "end": 1929.63,
      "text": " The delivery is scheduled.",
      "tokens": [
        50714,
        440,
        8982,
        307,
        15678,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36183667182922363,
      "compression_ratio": 1.6142857074737549,
      "no_speech_prob": 0.008049987256526947
    },
    {
      "id": 311,
      "seek": 78500,
      "start": 1929.63,
      "end": 1931.63,
      "text": " The delivery is accepted.",
      "tokens": [
        50814,
        440,
        8982,
        307,
        9035,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36183667182922363,
      "compression_ratio": 1.6142857074737549,
      "no_speech_prob": 0.008049987256526947
    },
    {
      "id": 312,
      "seek": 78500,
      "start": 1931.63,
      "end": 1934.63,
      "text": " Has been taken out of the warehouse.",
      "tokens": [
        50914,
        8646,
        668,
        2726,
        484,
        295,
        264,
        22244,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36183667182922363,
      "compression_ratio": 1.6142857074737549,
      "no_speech_prob": 0.008049987256526947
    },
    {
      "id": 313,
      "seek": 78500,
      "start": 1934.63,
      "end": 1938.63,
      "text": " Has been packed into a truck.",
      "tokens": [
        51064,
        8646,
        668,
        13265,
        666,
        257,
        5898,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36183667182922363,
      "compression_ratio": 1.6142857074737549,
      "no_speech_prob": 0.008049987256526947
    },
    {
      "id": 314,
      "seek": 78500,
      "start": 1938.63,
      "end": 1939.63,
      "text": " Has been delivered.",
      "tokens": [
        51264,
        8646,
        668,
        10144,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36183667182922363,
      "compression_ratio": 1.6142857074737549,
      "no_speech_prob": 0.008049987256526947
    },
    {
      "id": 315,
      "seek": 78500,
      "start": 1939.63,
      "end": 1941.63,
      "text": " And the customer said,",
      "tokens": [
        51314,
        400,
        264,
        5474,
        848,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36183667182922363,
      "compression_ratio": 1.6142857074737549,
      "no_speech_prob": 0.008049987256526947
    },
    {
      "id": 316,
      "seek": 78500,
      "start": 1941.63,
      "end": 1942.63,
      "text": " I got it too.",
      "tokens": [
        51414,
        286,
        658,
        309,
        886,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36183667182922363,
      "compression_ratio": 1.6142857074737549,
      "no_speech_prob": 0.008049987256526947
    },
    {
      "id": 317,
      "seek": 78500,
      "start": 1942.63,
      "end": 1944.63,
      "text": " Now the question is,",
      "tokens": [
        51464,
        823,
        264,
        1168,
        307,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36183667182922363,
      "compression_ratio": 1.6142857074737549,
      "no_speech_prob": 0.008049987256526947
    },
    {
      "id": 318,
      "seek": 78500,
      "start": 1944.63,
      "end": 1946.63,
      "text": " can I model this delivery",
      "tokens": [
        51564,
        393,
        286,
        2316,
        341,
        8982,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36183667182922363,
      "compression_ratio": 1.6142857074737549,
      "no_speech_prob": 0.008049987256526947
    },
    {
      "id": 319,
      "seek": 78500,
      "start": 1946.63,
      "end": 1949.63,
      "text": " or such an event store at all?",
      "tokens": [
        51664,
        420,
        1270,
        364,
        2280,
        3531,
        412,
        439,
        30,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36183667182922363,
      "compression_ratio": 1.6142857074737549,
      "no_speech_prob": 0.008049987256526947
    },
    {
      "id": 320,
      "seek": 81500,
      "start": 1950.63,
      "end": 1952.63,
      "text": " Probably not.",
      "tokens": [
        50364,
        9210,
        406,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397895097732544,
      "compression_ratio": 1.6527196168899536,
      "no_speech_prob": 0.00733592314645648
    },
    {
      "id": 321,
      "seek": 81500,
      "start": 1952.63,
      "end": 1954.63,
      "text": " Because that's exactly what interests me.",
      "tokens": [
        50464,
        1436,
        300,
        311,
        2293,
        437,
        8847,
        385,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397895097732544,
      "compression_ratio": 1.6527196168899536,
      "no_speech_prob": 0.00733592314645648
    },
    {
      "id": 322,
      "seek": 81500,
      "start": 1954.63,
      "end": 1955.63,
      "text": " So I'm interested in",
      "tokens": [
        50564,
        407,
        286,
        478,
        3102,
        294,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397895097732544,
      "compression_ratio": 1.6527196168899536,
      "no_speech_prob": 0.00733592314645648
    },
    {
      "id": 323,
      "seek": 81500,
      "start": 1955.63,
      "end": 1956.63,
      "text": " who did what with it.",
      "tokens": [
        50614,
        567,
        630,
        437,
        365,
        309,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397895097732544,
      "compression_ratio": 1.6527196168899536,
      "no_speech_prob": 0.00733592314645648
    },
    {
      "id": 324,
      "seek": 81500,
      "start": 1956.63,
      "end": 1958.63,
      "text": " Because then I can say later,",
      "tokens": [
        50664,
        1436,
        550,
        286,
        393,
        584,
        1780,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397895097732544,
      "compression_ratio": 1.6527196168899536,
      "no_speech_prob": 0.00733592314645648
    },
    {
      "id": 325,
      "seek": 81500,
      "start": 1958.63,
      "end": 1961.63,
      "text": " okay, you said it arrived.",
      "tokens": [
        50764,
        1392,
        11,
        291,
        848,
        309,
        6678,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397895097732544,
      "compression_ratio": 1.6527196168899536,
      "no_speech_prob": 0.00733592314645648
    },
    {
      "id": 326,
      "seek": 81500,
      "start": 1961.63,
      "end": 1964.63,
      "text": " Or that it was in your truck.",
      "tokens": [
        50914,
        1610,
        300,
        309,
        390,
        294,
        428,
        5898,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397895097732544,
      "compression_ratio": 1.6527196168899536,
      "no_speech_prob": 0.00733592314645648
    },
    {
      "id": 327,
      "seek": 81500,
      "start": 1964.63,
      "end": 1966.63,
      "text": " Where did that come from?",
      "tokens": [
        51064,
        2305,
        630,
        300,
        808,
        490,
        30,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397895097732544,
      "compression_ratio": 1.6527196168899536,
      "no_speech_prob": 0.00733592314645648
    },
    {
      "id": 328,
      "seek": 81500,
      "start": 1966.63,
      "end": 1967.63,
      "text": " On the contrary,",
      "tokens": [
        51164,
        1282,
        264,
        19506,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397895097732544,
      "compression_ratio": 1.6527196168899536,
      "no_speech_prob": 0.00733592314645648
    },
    {
      "id": 329,
      "seek": 81500,
      "start": 1967.63,
      "end": 1969.63,
      "text": " it's just that I'm not sure",
      "tokens": [
        51214,
        309,
        311,
        445,
        300,
        286,
        478,
        406,
        988,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397895097732544,
      "compression_ratio": 1.6527196168899536,
      "no_speech_prob": 0.00733592314645648
    },
    {
      "id": 330,
      "seek": 81500,
      "start": 1969.63,
      "end": 1970.63,
      "text": " about this delivery.",
      "tokens": [
        51314,
        466,
        341,
        8982,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397895097732544,
      "compression_ratio": 1.6527196168899536,
      "no_speech_prob": 0.00733592314645648
    },
    {
      "id": 331,
      "seek": 81500,
      "start": 1970.63,
      "end": 1972.63,
      "text": " Whether I actually want to calculate",
      "tokens": [
        51364,
        8503,
        286,
        767,
        528,
        281,
        8873,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397895097732544,
      "compression_ratio": 1.6527196168899536,
      "no_speech_prob": 0.00733592314645648
    },
    {
      "id": 332,
      "seek": 81500,
      "start": 1972.63,
      "end": 1974.63,
      "text": " the state of the delivery.",
      "tokens": [
        51464,
        264,
        1785,
        295,
        264,
        8982,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397895097732544,
      "compression_ratio": 1.6527196168899536,
      "no_speech_prob": 0.00733592314645648
    },
    {
      "id": 333,
      "seek": 81500,
      "start": 1974.63,
      "end": 1976.63,
      "text": " So what do I get out of it",
      "tokens": [
        51564,
        407,
        437,
        360,
        286,
        483,
        484,
        295,
        309,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397895097732544,
      "compression_ratio": 1.6527196168899536,
      "no_speech_prob": 0.00733592314645648
    },
    {
      "id": 334,
      "seek": 81500,
      "start": 1976.63,
      "end": 1979.63,
      "text": " if I don't save the state?",
      "tokens": [
        51664,
        498,
        286,
        500,
        380,
        3155,
        264,
        1785,
        30,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397895097732544,
      "compression_ratio": 1.6527196168899536,
      "no_speech_prob": 0.00733592314645648
    },
    {
      "id": 335,
      "seek": 84400,
      "start": 1979.63,
      "end": 1981.63,
      "text": " So I would write in here",
      "tokens": [
        50364,
        407,
        286,
        576,
        2464,
        294,
        510,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3584279716014862,
      "compression_ratio": 1.634615421295166,
      "no_speech_prob": 0.014047660864889622
    },
    {
      "id": 336,
      "seek": 84400,
      "start": 1981.63,
      "end": 1983.63,
      "text": " next to the event store,",
      "tokens": [
        50464,
        958,
        281,
        264,
        2280,
        3531,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3584279716014862,
      "compression_ratio": 1.634615421295166,
      "no_speech_prob": 0.014047660864889622
    },
    {
      "id": 337,
      "seek": 84400,
      "start": 1983.63,
      "end": 1985.63,
      "text": " yes, this delivery has arrived",
      "tokens": [
        50564,
        2086,
        11,
        341,
        8982,
        575,
        6678,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3584279716014862,
      "compression_ratio": 1.634615421295166,
      "no_speech_prob": 0.014047660864889622
    },
    {
      "id": 338,
      "seek": 84400,
      "start": 1985.63,
      "end": 1986.63,
      "text": " and the customer said,",
      "tokens": [
        50664,
        293,
        264,
        5474,
        848,
        11,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3584279716014862,
      "compression_ratio": 1.634615421295166,
      "no_speech_prob": 0.014047660864889622
    },
    {
      "id": 339,
      "seek": 84400,
      "start": 1986.63,
      "end": 1987.63,
      "text": " everything is fine.",
      "tokens": [
        50714,
        1203,
        307,
        2489,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3584279716014862,
      "compression_ratio": 1.634615421295166,
      "no_speech_prob": 0.014047660864889622
    },
    {
      "id": 340,
      "seek": 84400,
      "start": 1987.63,
      "end": 1989.63,
      "text": " So I have a state that says,",
      "tokens": [
        50764,
        407,
        286,
        362,
        257,
        1785,
        300,
        1619,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3584279716014862,
      "compression_ratio": 1.634615421295166,
      "no_speech_prob": 0.014047660864889622
    },
    {
      "id": 341,
      "seek": 84400,
      "start": 1989.63,
      "end": 1992.63,
      "text": " is successfully completed.",
      "tokens": [
        50864,
        307,
        10727,
        7365,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3584279716014862,
      "compression_ratio": 1.634615421295166,
      "no_speech_prob": 0.014047660864889622
    },
    {
      "id": 342,
      "seek": 84400,
      "start": 1992.63,
      "end": 1993.63,
      "text": " And then I can,",
      "tokens": [
        51014,
        400,
        550,
        286,
        393,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3584279716014862,
      "compression_ratio": 1.634615421295166,
      "no_speech_prob": 0.014047660864889622
    },
    {
      "id": 343,
      "seek": 84400,
      "start": 1993.63,
      "end": 1994.63,
      "text": " on the other hand,",
      "tokens": [
        51064,
        322,
        264,
        661,
        1011,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3584279716014862,
      "compression_ratio": 1.634615421295166,
      "no_speech_prob": 0.014047660864889622
    },
    {
      "id": 344,
      "seek": 84400,
      "start": 1994.63,
      "end": 1995.63,
      "text": " if someone is interested in",
      "tokens": [
        51114,
        498,
        1580,
        307,
        3102,
        294,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3584279716014862,
      "compression_ratio": 1.634615421295166,
      "no_speech_prob": 0.014047660864889622
    },
    {
      "id": 345,
      "seek": 84400,
      "start": 1995.63,
      "end": 1996.63,
      "text": " how it came about,",
      "tokens": [
        51164,
        577,
        309,
        1361,
        466,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3584279716014862,
      "compression_ratio": 1.634615421295166,
      "no_speech_prob": 0.014047660864889622
    },
    {
      "id": 346,
      "seek": 84400,
      "start": 1996.63,
      "end": 1997.63,
      "text": " somehow pull out these events",
      "tokens": [
        51214,
        6063,
        2235,
        484,
        613,
        3931,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3584279716014862,
      "compression_ratio": 1.634615421295166,
      "no_speech_prob": 0.014047660864889622
    },
    {
      "id": 347,
      "seek": 84400,
      "start": 1997.63,
      "end": 1999.63,
      "text": " and can display them.",
      "tokens": [
        51264,
        293,
        393,
        4674,
        552,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3584279716014862,
      "compression_ratio": 1.634615421295166,
      "no_speech_prob": 0.014047660864889622
    },
    {
      "id": 348,
      "seek": 84400,
      "start": 1999.63,
      "end": 2001.63,
      "text": " That means this ...",
      "tokens": [
        51364,
        663,
        1355,
        341,
        1097,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3584279716014862,
      "compression_ratio": 1.634615421295166,
      "no_speech_prob": 0.014047660864889622
    },
    {
      "id": 349,
      "seek": 84400,
      "start": 2001.63,
      "end": 2003.63,
      "text": " So that's a technical discussion.",
      "tokens": [
        51464,
        407,
        300,
        311,
        257,
        6191,
        5017,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3584279716014862,
      "compression_ratio": 1.634615421295166,
      "no_speech_prob": 0.014047660864889622
    },
    {
      "id": 350,
      "seek": 84400,
      "start": 2003.63,
      "end": 2005.63,
      "text": " Actually, I say,",
      "tokens": [
        51564,
        5135,
        11,
        286,
        584,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3584279716014862,
      "compression_ratio": 1.634615421295166,
      "no_speech_prob": 0.014047660864889622
    },
    {
      "id": 351,
      "seek": 84400,
      "start": 2005.63,
      "end": 2007.63,
      "text": " that's the way I want to model something",
      "tokens": [
        51664,
        300,
        311,
        264,
        636,
        286,
        528,
        281,
        2316,
        746,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3584279716014862,
      "compression_ratio": 1.634615421295166,
      "no_speech_prob": 0.014047660864889622
    },
    {
      "id": 352,
      "seek": 87200,
      "start": 2007.63,
      "end": 2009.63,
      "text": " in a professional way.",
      "tokens": [
        50364,
        294,
        257,
        4843,
        636,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3932122588157654,
      "compression_ratio": 1.449735403060913,
      "no_speech_prob": 0.08613356202840805
    },
    {
      "id": 353,
      "seek": 87200,
      "start": 2009.63,
      "end": 2011.63,
      "text": " And that's something",
      "tokens": [
        50464,
        400,
        300,
        311,
        746,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3932122588157654,
      "compression_ratio": 1.449735403060913,
      "no_speech_prob": 0.08613356202840805
    },
    {
      "id": 354,
      "seek": 87200,
      "start": 2013.63,
      "end": 2015.63,
      "text": " where I don't want to",
      "tokens": [
        50664,
        689,
        286,
        500,
        380,
        528,
        281,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3932122588157654,
      "compression_ratio": 1.449735403060913,
      "no_speech_prob": 0.08613356202840805
    },
    {
      "id": 355,
      "seek": 87200,
      "start": 2015.63,
      "end": 2017.63,
      "text": " reconstruct the state,",
      "tokens": [
        50764,
        31499,
        264,
        1785,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3932122588157654,
      "compression_ratio": 1.449735403060913,
      "no_speech_prob": 0.08613356202840805
    },
    {
      "id": 356,
      "seek": 87200,
      "start": 2017.63,
      "end": 2019.63,
      "text": " which is often sold as an advantage",
      "tokens": [
        50864,
        597,
        307,
        2049,
        3718,
        382,
        364,
        5002,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3932122588157654,
      "compression_ratio": 1.449735403060913,
      "no_speech_prob": 0.08613356202840805
    },
    {
      "id": 357,
      "seek": 87200,
      "start": 2019.63,
      "end": 2021.63,
      "text": " from the events.",
      "tokens": [
        50964,
        490,
        264,
        3931,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3932122588157654,
      "compression_ratio": 1.449735403060913,
      "no_speech_prob": 0.08613356202840805
    },
    {
      "id": 358,
      "seek": 87200,
      "start": 2022.63,
      "end": 2024.63,
      "text": " CQRS,",
      "tokens": [
        51114,
        383,
        48,
        43580,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3932122588157654,
      "compression_ratio": 1.449735403060913,
      "no_speech_prob": 0.08613356202840805
    },
    {
      "id": 359,
      "seek": 87200,
      "start": 2024.63,
      "end": 2026.63,
      "text": " that's the other approach.",
      "tokens": [
        51214,
        300,
        311,
        264,
        661,
        3109,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3932122588157654,
      "compression_ratio": 1.449735403060913,
      "no_speech_prob": 0.08613356202840805
    },
    {
      "id": 360,
      "seek": 87200,
      "start": 2026.63,
      "end": 2027.63,
      "text": " This is this command",
      "tokens": [
        51314,
        639,
        307,
        341,
        5622,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3932122588157654,
      "compression_ratio": 1.449735403060913,
      "no_speech_prob": 0.08613356202840805
    },
    {
      "id": 361,
      "seek": 87200,
      "start": 2027.63,
      "end": 2030.63,
      "text": " query responsibility separation,",
      "tokens": [
        51364,
        14581,
        6357,
        14634,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3932122588157654,
      "compression_ratio": 1.449735403060913,
      "no_speech_prob": 0.08613356202840805
    },
    {
      "id": 362,
      "seek": 87200,
      "start": 2030.63,
      "end": 2032.63,
      "text": " where I somehow separate",
      "tokens": [
        51514,
        689,
        286,
        6063,
        4994,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3932122588157654,
      "compression_ratio": 1.449735403060913,
      "no_speech_prob": 0.08613356202840805
    },
    {
      "id": 363,
      "seek": 87200,
      "start": 2032.63,
      "end": 2034.63,
      "text": " reading and writing.",
      "tokens": [
        51614,
        3760,
        293,
        3579,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3932122588157654,
      "compression_ratio": 1.449735403060913,
      "no_speech_prob": 0.08613356202840805
    },
    {
      "id": 364,
      "seek": 89900,
      "start": 2034.63,
      "end": 2037.63,
      "text": " And that would work now",
      "tokens": [
        50364,
        400,
        300,
        576,
        589,
        586,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.342935174703598,
      "compression_ratio": 2.020746946334839,
      "no_speech_prob": 0.003933162894099951
    },
    {
      "id": 365,
      "seek": 89900,
      "start": 2037.63,
      "end": 2039.63,
      "text": " so that I have a command queue.",
      "tokens": [
        50514,
        370,
        300,
        286,
        362,
        257,
        5622,
        18639,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.342935174703598,
      "compression_ratio": 2.020746946334839,
      "no_speech_prob": 0.003933162894099951
    },
    {
      "id": 366,
      "seek": 89900,
      "start": 2039.63,
      "end": 2040.63,
      "text": " So there are some commands,",
      "tokens": [
        50614,
        407,
        456,
        366,
        512,
        16901,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.342935174703598,
      "compression_ratio": 2.020746946334839,
      "no_speech_prob": 0.003933162894099951
    },
    {
      "id": 367,
      "seek": 89900,
      "start": 2040.63,
      "end": 2042.63,
      "text": " I don't generate an invoice, for example,",
      "tokens": [
        50664,
        286,
        500,
        380,
        8460,
        364,
        47919,
        11,
        337,
        1365,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.342935174703598,
      "compression_ratio": 2.020746946334839,
      "no_speech_prob": 0.003933162894099951
    },
    {
      "id": 368,
      "seek": 89900,
      "start": 2042.63,
      "end": 2044.63,
      "text": " but I have a command handler,",
      "tokens": [
        50764,
        457,
        286,
        362,
        257,
        5622,
        41967,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.342935174703598,
      "compression_ratio": 2.020746946334839,
      "no_speech_prob": 0.003933162894099951
    },
    {
      "id": 369,
      "seek": 89900,
      "start": 2044.63,
      "end": 2045.63,
      "text": " which, for example,",
      "tokens": [
        50864,
        597,
        11,
        337,
        1365,
        11,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.342935174703598,
      "compression_ratio": 2.020746946334839,
      "no_speech_prob": 0.003933162894099951
    },
    {
      "id": 370,
      "seek": 89900,
      "start": 2045.63,
      "end": 2046.63,
      "text": " may ensure that",
      "tokens": [
        50914,
        815,
        5586,
        300,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.342935174703598,
      "compression_ratio": 2.020746946334839,
      "no_speech_prob": 0.003933162894099951
    },
    {
      "id": 371,
      "seek": 89900,
      "start": 2046.63,
      "end": 2047.63,
      "text": " when an invoice is generated,",
      "tokens": [
        50964,
        562,
        364,
        47919,
        307,
        10833,
        11,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.342935174703598,
      "compression_ratio": 2.020746946334839,
      "no_speech_prob": 0.003933162894099951
    },
    {
      "id": 372,
      "seek": 89900,
      "start": 2047.63,
      "end": 2049.63,
      "text": " it is immediately paid.",
      "tokens": [
        51014,
        309,
        307,
        4258,
        4835,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.342935174703598,
      "compression_ratio": 2.020746946334839,
      "no_speech_prob": 0.003933162894099951
    },
    {
      "id": 373,
      "seek": 89900,
      "start": 2049.63,
      "end": 2050.63,
      "text": " Then there is a database,",
      "tokens": [
        51114,
        1396,
        456,
        307,
        257,
        8149,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.342935174703598,
      "compression_ratio": 2.020746946334839,
      "no_speech_prob": 0.003933162894099951
    },
    {
      "id": 374,
      "seek": 89900,
      "start": 2050.63,
      "end": 2052.63,
      "text": " where the invoices are stored, for example.",
      "tokens": [
        51164,
        689,
        264,
        1048,
        78,
        1473,
        366,
        12187,
        11,
        337,
        1365,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.342935174703598,
      "compression_ratio": 2.020746946334839,
      "no_speech_prob": 0.003933162894099951
    },
    {
      "id": 375,
      "seek": 89900,
      "start": 2052.63,
      "end": 2054.63,
      "text": " And then there is a query handler",
      "tokens": [
        51264,
        400,
        550,
        456,
        307,
        257,
        14581,
        41967,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.342935174703598,
      "compression_ratio": 2.020746946334839,
      "no_speech_prob": 0.003933162894099951
    },
    {
      "id": 376,
      "seek": 89900,
      "start": 2054.63,
      "end": 2056.63,
      "text": " and it is somehow separated.",
      "tokens": [
        51364,
        293,
        309,
        307,
        6063,
        12005,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.342935174703598,
      "compression_ratio": 2.020746946334839,
      "no_speech_prob": 0.003933162894099951
    },
    {
      "id": 377,
      "seek": 89900,
      "start": 2056.63,
      "end": 2057.63,
      "text": " And there I can now, for example,",
      "tokens": [
        51464,
        400,
        456,
        286,
        393,
        586,
        11,
        337,
        1365,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.342935174703598,
      "compression_ratio": 2.020746946334839,
      "no_speech_prob": 0.003933162894099951
    },
    {
      "id": 378,
      "seek": 89900,
      "start": 2057.63,
      "end": 2058.63,
      "text": " read invoices.",
      "tokens": [
        51514,
        1401,
        1048,
        78,
        1473,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.342935174703598,
      "compression_ratio": 2.020746946334839,
      "no_speech_prob": 0.003933162894099951
    },
    {
      "id": 379,
      "seek": 89900,
      "start": 2058.63,
      "end": 2060.63,
      "text": " And the commands I may now",
      "tokens": [
        51564,
        400,
        264,
        16901,
        286,
        815,
        586,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.342935174703598,
      "compression_ratio": 2.020746946334839,
      "no_speech_prob": 0.003933162894099951
    },
    {
      "id": 380,
      "seek": 89900,
      "start": 2060.63,
      "end": 2063.63,
      "text": " still have in the command store.",
      "tokens": [
        51664,
        920,
        362,
        294,
        264,
        5622,
        3531,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.342935174703598,
      "compression_ratio": 2.020746946334839,
      "no_speech_prob": 0.003933162894099951
    },
    {
      "id": 381,
      "seek": 92800,
      "start": 2063.63,
      "end": 2067.63,
      "text": " And that would be my model now.",
      "tokens": [
        50364,
        400,
        300,
        576,
        312,
        452,
        2316,
        586,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3593928813934326,
      "compression_ratio": 1.7176470756530762,
      "no_speech_prob": 0.0011323587968945503
    },
    {
      "id": 382,
      "seek": 92800,
      "start": 2067.63,
      "end": 2072.63,
      "text": " And now I would actually have this read model here.",
      "tokens": [
        50564,
        400,
        586,
        286,
        576,
        767,
        362,
        341,
        1401,
        2316,
        510,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3593928813934326,
      "compression_ratio": 1.7176470756530762,
      "no_speech_prob": 0.0011323587968945503
    },
    {
      "id": 383,
      "seek": 92800,
      "start": 2072.63,
      "end": 2074.63,
      "text": " That would be what the query handler would use.",
      "tokens": [
        50814,
        663,
        576,
        312,
        437,
        264,
        14581,
        41967,
        576,
        764,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3593928813934326,
      "compression_ratio": 1.7176470756530762,
      "no_speech_prob": 0.0011323587968945503
    },
    {
      "id": 384,
      "seek": 92800,
      "start": 2074.63,
      "end": 2077.63,
      "text": " And here I would have the model",
      "tokens": [
        50914,
        400,
        510,
        286,
        576,
        362,
        264,
        2316,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3593928813934326,
      "compression_ratio": 1.7176470756530762,
      "no_speech_prob": 0.0011323587968945503
    },
    {
      "id": 385,
      "seek": 92800,
      "start": 2077.63,
      "end": 2079.63,
      "text": " where I actually change things",
      "tokens": [
        51064,
        689,
        286,
        767,
        1319,
        721,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3593928813934326,
      "compression_ratio": 1.7176470756530762,
      "no_speech_prob": 0.0011323587968945503
    },
    {
      "id": 386,
      "seek": 92800,
      "start": 2079.63,
      "end": 2081.63,
      "text": " or this part,",
      "tokens": [
        51164,
        420,
        341,
        644,
        11,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3593928813934326,
      "compression_ratio": 1.7176470756530762,
      "no_speech_prob": 0.0011323587968945503
    },
    {
      "id": 387,
      "seek": 92800,
      "start": 2081.63,
      "end": 2083.63,
      "text": " which is not the system,",
      "tokens": [
        51264,
        597,
        307,
        406,
        264,
        1185,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3593928813934326,
      "compression_ratio": 1.7176470756530762,
      "no_speech_prob": 0.0011323587968945503
    },
    {
      "id": 388,
      "seek": 92800,
      "start": 2083.63,
      "end": 2085.63,
      "text": " which takes commands from",
      "tokens": [
        51364,
        597,
        2516,
        16901,
        490,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3593928813934326,
      "compression_ratio": 1.7176470756530762,
      "no_speech_prob": 0.0011323587968945503
    },
    {
      "id": 389,
      "seek": 92800,
      "start": 2089.63,
      "end": 2091.63,
      "text": " the design level event storming.",
      "tokens": [
        51664,
        264,
        1715,
        1496,
        2280,
        7679,
        278,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3593928813934326,
      "compression_ratio": 1.7176470756530762,
      "no_speech_prob": 0.0011323587968945503
    },
    {
      "id": 390,
      "seek": 95600,
      "start": 2092.63,
      "end": 2094.63,
      "text": " So, if I build it that way,",
      "tokens": [
        50414,
        407,
        11,
        498,
        286,
        1322,
        309,
        300,
        636,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3285774290561676,
      "compression_ratio": 1.650224208831787,
      "no_speech_prob": 0.002212373772636056
    },
    {
      "id": 391,
      "seek": 95600,
      "start": 2094.63,
      "end": 2097.63,
      "text": " it means that the model",
      "tokens": [
        50514,
        309,
        1355,
        300,
        264,
        2316,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3285774290561676,
      "compression_ratio": 1.650224208831787,
      "no_speech_prob": 0.002212373772636056
    },
    {
      "id": 392,
      "seek": 95600,
      "start": 2097.63,
      "end": 2099.63,
      "text": " for writing here",
      "tokens": [
        50664,
        337,
        3579,
        510,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3285774290561676,
      "compression_ratio": 1.650224208831787,
      "no_speech_prob": 0.002212373772636056
    },
    {
      "id": 393,
      "seek": 95600,
      "start": 2099.63,
      "end": 2100.63,
      "text": " through the commands",
      "tokens": [
        50764,
        807,
        264,
        16901,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3285774290561676,
      "compression_ratio": 1.650224208831787,
      "no_speech_prob": 0.002212373772636056
    },
    {
      "id": 394,
      "seek": 95600,
      "start": 2100.63,
      "end": 2101.63,
      "text": " and that of the queries",
      "tokens": [
        50814,
        293,
        300,
        295,
        264,
        24109,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3285774290561676,
      "compression_ratio": 1.650224208831787,
      "no_speech_prob": 0.002212373772636056
    },
    {
      "id": 395,
      "seek": 95600,
      "start": 2101.63,
      "end": 2104.63,
      "text": " is actually the same,",
      "tokens": [
        50864,
        307,
        767,
        264,
        912,
        11,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3285774290561676,
      "compression_ratio": 1.650224208831787,
      "no_speech_prob": 0.002212373772636056
    },
    {
      "id": 396,
      "seek": 95600,
      "start": 2104.63,
      "end": 2107.63,
      "text": " because this is a common database.",
      "tokens": [
        51014,
        570,
        341,
        307,
        257,
        2689,
        8149,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3285774290561676,
      "compression_ratio": 1.650224208831787,
      "no_speech_prob": 0.002212373772636056
    },
    {
      "id": 397,
      "seek": 95600,
      "start": 2108.63,
      "end": 2110.63,
      "text": " Do I have anything of it at all?",
      "tokens": [
        51214,
        1144,
        286,
        362,
        1340,
        295,
        309,
        412,
        439,
        30,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3285774290561676,
      "compression_ratio": 1.650224208831787,
      "no_speech_prob": 0.002212373772636056
    },
    {
      "id": 398,
      "seek": 95600,
      "start": 2110.63,
      "end": 2112.63,
      "text": " Yes, I have something of it,",
      "tokens": [
        51314,
        1079,
        11,
        286,
        362,
        746,
        295,
        309,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3285774290561676,
      "compression_ratio": 1.650224208831787,
      "no_speech_prob": 0.002212373772636056
    },
    {
      "id": 399,
      "seek": 95600,
      "start": 2112.63,
      "end": 2113.63,
      "text": " because this query handler, for example,",
      "tokens": [
        51414,
        570,
        341,
        14581,
        41967,
        11,
        337,
        1365,
        11,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3285774290561676,
      "compression_ratio": 1.650224208831787,
      "no_speech_prob": 0.002212373772636056
    },
    {
      "id": 400,
      "seek": 95600,
      "start": 2113.63,
      "end": 2115.63,
      "text": " can use a read replica.",
      "tokens": [
        51464,
        393,
        764,
        257,
        1401,
        35456,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3285774290561676,
      "compression_ratio": 1.650224208831787,
      "no_speech_prob": 0.002212373772636056
    },
    {
      "id": 401,
      "seek": 95600,
      "start": 2115.63,
      "end": 2116.63,
      "text": " So I can now somehow say,",
      "tokens": [
        51564,
        407,
        286,
        393,
        586,
        6063,
        584,
        11,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3285774290561676,
      "compression_ratio": 1.650224208831787,
      "no_speech_prob": 0.002212373772636056
    },
    {
      "id": 402,
      "seek": 95600,
      "start": 2116.63,
      "end": 2118.63,
      "text": " okay, I'll build the system",
      "tokens": [
        51614,
        1392,
        11,
        286,
        603,
        1322,
        264,
        1185,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3285774290561676,
      "compression_ratio": 1.650224208831787,
      "no_speech_prob": 0.002212373772636056
    },
    {
      "id": 403,
      "seek": 95600,
      "start": 2118.63,
      "end": 2119.63,
      "text": " as it says here.",
      "tokens": [
        51714,
        382,
        309,
        1619,
        510,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3285774290561676,
      "compression_ratio": 1.650224208831787,
      "no_speech_prob": 0.002212373772636056
    },
    {
      "id": 404,
      "seek": 98400,
      "start": 2119.63,
      "end": 2121.63,
      "text": " I now have the query handler.",
      "tokens": [
        50364,
        286,
        586,
        362,
        264,
        14581,
        41967,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31820255517959595,
      "compression_ratio": 1.6944444179534912,
      "no_speech_prob": 0.0022817798890173435
    },
    {
      "id": 405,
      "seek": 98400,
      "start": 2121.63,
      "end": 2122.63,
      "text": " The query handler uses",
      "tokens": [
        50464,
        440,
        14581,
        41967,
        4960,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31820255517959595,
      "compression_ratio": 1.6944444179534912,
      "no_speech_prob": 0.0022817798890173435
    },
    {
      "id": 406,
      "seek": 98400,
      "start": 2122.63,
      "end": 2124.63,
      "text": " a read replica of the database.",
      "tokens": [
        50514,
        257,
        1401,
        35456,
        295,
        264,
        8149,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31820255517959595,
      "compression_ratio": 1.6944444179534912,
      "no_speech_prob": 0.0022817798890173435
    },
    {
      "id": 407,
      "seek": 98400,
      "start": 2124.63,
      "end": 2125.63,
      "text": " And I can read about it",
      "tokens": [
        50614,
        400,
        286,
        393,
        1401,
        466,
        309,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31820255517959595,
      "compression_ratio": 1.6944444179534912,
      "no_speech_prob": 0.0022817798890173435
    },
    {
      "id": 408,
      "seek": 98400,
      "start": 2125.63,
      "end": 2127.63,
      "text": " more scalably.",
      "tokens": [
        50664,
        544,
        15664,
        1188,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31820255517959595,
      "compression_ratio": 1.6944444179534912,
      "no_speech_prob": 0.0022817798890173435
    },
    {
      "id": 409,
      "seek": 98400,
      "start": 2127.63,
      "end": 2130.63,
      "text": " I think that's a bit of an advantage",
      "tokens": [
        50764,
        286,
        519,
        300,
        311,
        257,
        857,
        295,
        364,
        5002,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31820255517959595,
      "compression_ratio": 1.6944444179534912,
      "no_speech_prob": 0.0022817798890173435
    },
    {
      "id": 410,
      "seek": 98400,
      "start": 2130.63,
      "end": 2132.63,
      "text": " that is essentially created here.",
      "tokens": [
        50914,
        300,
        307,
        4476,
        2942,
        510,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31820255517959595,
      "compression_ratio": 1.6944444179534912,
      "no_speech_prob": 0.0022817798890173435
    },
    {
      "id": 411,
      "seek": 98400,
      "start": 2132.63,
      "end": 2134.63,
      "text": " These two parts are, for example,",
      "tokens": [
        51014,
        1981,
        732,
        3166,
        366,
        11,
        337,
        1365,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31820255517959595,
      "compression_ratio": 1.6944444179534912,
      "no_speech_prob": 0.0022817798890173435
    },
    {
      "id": 412,
      "seek": 98400,
      "start": 2134.63,
      "end": 2136.63,
      "text": " independently scalable.",
      "tokens": [
        51114,
        21761,
        38481,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31820255517959595,
      "compression_ratio": 1.6944444179534912,
      "no_speech_prob": 0.0022817798890173435
    },
    {
      "id": 413,
      "seek": 98400,
      "start": 2136.63,
      "end": 2137.63,
      "text": " I can now execute the command handler",
      "tokens": [
        51214,
        286,
        393,
        586,
        14483,
        264,
        5622,
        41967,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31820255517959595,
      "compression_ratio": 1.6944444179534912,
      "no_speech_prob": 0.0022817798890173435
    },
    {
      "id": 414,
      "seek": 98400,
      "start": 2137.63,
      "end": 2138.63,
      "text": " and the query handler",
      "tokens": [
        51264,
        293,
        264,
        14581,
        41967,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31820255517959595,
      "compression_ratio": 1.6944444179534912,
      "no_speech_prob": 0.0022817798890173435
    },
    {
      "id": 415,
      "seek": 98400,
      "start": 2138.63,
      "end": 2140.63,
      "text": " in two different microservices.",
      "tokens": [
        51314,
        294,
        732,
        819,
        15547,
        47480,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31820255517959595,
      "compression_ratio": 1.6944444179534912,
      "no_speech_prob": 0.0022817798890173435
    },
    {
      "id": 416,
      "seek": 98400,
      "start": 2140.63,
      "end": 2142.63,
      "text": " And that also leads to",
      "tokens": [
        51414,
        400,
        300,
        611,
        6689,
        281,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31820255517959595,
      "compression_ratio": 1.6944444179534912,
      "no_speech_prob": 0.0022817798890173435
    },
    {
      "id": 417,
      "seek": 98400,
      "start": 2142.63,
      "end": 2144.63,
      "text": " that, how should I say,",
      "tokens": [
        51514,
        300,
        11,
        577,
        820,
        286,
        584,
        11,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31820255517959595,
      "compression_ratio": 1.6944444179534912,
      "no_speech_prob": 0.0022817798890173435
    },
    {
      "id": 418,
      "seek": 98400,
      "start": 2144.63,
      "end": 2147.63,
      "text": " I'm not so sure about this pattern,",
      "tokens": [
        51614,
        286,
        478,
        406,
        370,
        988,
        466,
        341,
        5102,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31820255517959595,
      "compression_ratio": 1.6944444179534912,
      "no_speech_prob": 0.0022817798890173435
    },
    {
      "id": 419,
      "seek": 101200,
      "start": 2147.63,
      "end": 2148.63,
      "text": " how often I would actually",
      "tokens": [
        50364,
        577,
        2049,
        286,
        576,
        767,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3314443826675415,
      "compression_ratio": 1.7000000476837158,
      "no_speech_prob": 0.06921765208244324
    },
    {
      "id": 420,
      "seek": 101200,
      "start": 2148.63,
      "end": 2150.63,
      "text": " want to use it.",
      "tokens": [
        50414,
        528,
        281,
        764,
        309,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3314443826675415,
      "compression_ratio": 1.7000000476837158,
      "no_speech_prob": 0.06921765208244324
    },
    {
      "id": 421,
      "seek": 101200,
      "start": 2150.63,
      "end": 2155.63,
      "text": " Because it only makes sense",
      "tokens": [
        50514,
        1436,
        309,
        787,
        1669,
        2020,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3314443826675415,
      "compression_ratio": 1.7000000476837158,
      "no_speech_prob": 0.06921765208244324
    },
    {
      "id": 422,
      "seek": 101200,
      "start": 2155.63,
      "end": 2156.63,
      "text": " if I have something,",
      "tokens": [
        50764,
        498,
        286,
        362,
        746,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3314443826675415,
      "compression_ratio": 1.7000000476837158,
      "no_speech_prob": 0.06921765208244324
    },
    {
      "id": 423,
      "seek": 101200,
      "start": 2156.63,
      "end": 2158.63,
      "text": " or for scaling at least,",
      "tokens": [
        50814,
        420,
        337,
        21589,
        412,
        1935,
        11,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3314443826675415,
      "compression_ratio": 1.7000000476837158,
      "no_speech_prob": 0.06921765208244324
    },
    {
      "id": 424,
      "seek": 101200,
      "start": 2158.63,
      "end": 2159.63,
      "text": " it only makes sense",
      "tokens": [
        50914,
        309,
        787,
        1669,
        2020,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3314443826675415,
      "compression_ratio": 1.7000000476837158,
      "no_speech_prob": 0.06921765208244324
    },
    {
      "id": 425,
      "seek": 101200,
      "start": 2159.63,
      "end": 2160.63,
      "text": " if I somehow say,",
      "tokens": [
        50964,
        498,
        286,
        6063,
        584,
        11,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3314443826675415,
      "compression_ratio": 1.7000000476837158,
      "no_speech_prob": 0.06921765208244324
    },
    {
      "id": 426,
      "seek": 101200,
      "start": 2160.63,
      "end": 2162.63,
      "text": " okay, I want to",
      "tokens": [
        51014,
        1392,
        11,
        286,
        528,
        281,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3314443826675415,
      "compression_ratio": 1.7000000476837158,
      "no_speech_prob": 0.06921765208244324
    },
    {
      "id": 427,
      "seek": 101200,
      "start": 2162.63,
      "end": 2164.63,
      "text": " scale this query handler area",
      "tokens": [
        51114,
        4373,
        341,
        14581,
        41967,
        1859,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3314443826675415,
      "compression_ratio": 1.7000000476837158,
      "no_speech_prob": 0.06921765208244324
    },
    {
      "id": 428,
      "seek": 101200,
      "start": 2164.63,
      "end": 2166.63,
      "text": " independently of writing.",
      "tokens": [
        51214,
        21761,
        295,
        3579,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3314443826675415,
      "compression_ratio": 1.7000000476837158,
      "no_speech_prob": 0.06921765208244324
    },
    {
      "id": 429,
      "seek": 101200,
      "start": 2166.63,
      "end": 2168.63,
      "text": " And I think I have to",
      "tokens": [
        51314,
        400,
        286,
        519,
        286,
        362,
        281,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3314443826675415,
      "compression_ratio": 1.7000000476837158,
      "no_speech_prob": 0.06921765208244324
    },
    {
      "id": 430,
      "seek": 101200,
      "start": 2168.63,
      "end": 2171.63,
      "text": " come to significant scaling heights",
      "tokens": [
        51414,
        808,
        281,
        4776,
        21589,
        25930,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3314443826675415,
      "compression_ratio": 1.7000000476837158,
      "no_speech_prob": 0.06921765208244324
    },
    {
      "id": 431,
      "seek": 101200,
      "start": 2171.63,
      "end": 2174.63,
      "text": " so that I have a profit there.",
      "tokens": [
        51564,
        370,
        300,
        286,
        362,
        257,
        7475,
        456,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3314443826675415,
      "compression_ratio": 1.7000000476837158,
      "no_speech_prob": 0.06921765208244324
    },
    {
      "id": 432,
      "seek": 101200,
      "start": 2174.63,
      "end": 2176.63,
      "text": " I can do something else.",
      "tokens": [
        51714,
        286,
        393,
        360,
        746,
        1646,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3314443826675415,
      "compression_ratio": 1.7000000476837158,
      "no_speech_prob": 0.06921765208244324
    },
    {
      "id": 433,
      "seek": 104100,
      "start": 2176.63,
      "end": 2177.63,
      "text": " I can say,",
      "tokens": [
        50364,
        286,
        393,
        584,
        11,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3330968916416168,
      "compression_ratio": 1.6782177686691284,
      "no_speech_prob": 0.03378737345337868
    },
    {
      "id": 434,
      "seek": 104100,
      "start": 2177.63,
      "end": 2179.63,
      "text": " the query handler has a snapshot",
      "tokens": [
        50414,
        264,
        14581,
        41967,
        575,
        257,
        30163,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3330968916416168,
      "compression_ratio": 1.6782177686691284,
      "no_speech_prob": 0.03378737345337868
    },
    {
      "id": 435,
      "seek": 104100,
      "start": 2179.63,
      "end": 2181.63,
      "text": " and I build this snapshot",
      "tokens": [
        50514,
        293,
        286,
        1322,
        341,
        30163,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3330968916416168,
      "compression_ratio": 1.6782177686691284,
      "no_speech_prob": 0.03378737345337868
    },
    {
      "id": 436,
      "seek": 104100,
      "start": 2181.63,
      "end": 2185.63,
      "text": " through event sourcing stories together.",
      "tokens": [
        50614,
        807,
        2280,
        11006,
        2175,
        3676,
        1214,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3330968916416168,
      "compression_ratio": 1.6782177686691284,
      "no_speech_prob": 0.03378737345337868
    },
    {
      "id": 437,
      "seek": 104100,
      "start": 2185.63,
      "end": 2187.63,
      "text": " So that would mean",
      "tokens": [
        50814,
        407,
        300,
        576,
        914,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3330968916416168,
      "compression_ratio": 1.6782177686691284,
      "no_speech_prob": 0.03378737345337868
    },
    {
      "id": 438,
      "seek": 104100,
      "start": 2187.63,
      "end": 2189.63,
      "text": " that I have these commands here.",
      "tokens": [
        50914,
        300,
        286,
        362,
        613,
        16901,
        510,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3330968916416168,
      "compression_ratio": 1.6782177686691284,
      "no_speech_prob": 0.03378737345337868
    },
    {
      "id": 439,
      "seek": 104100,
      "start": 2189.63,
      "end": 2191.63,
      "text": " Something is built on logic here.",
      "tokens": [
        51014,
        6595,
        307,
        3094,
        322,
        9952,
        510,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3330968916416168,
      "compression_ratio": 1.6782177686691284,
      "no_speech_prob": 0.03378737345337868
    },
    {
      "id": 440,
      "seek": 104100,
      "start": 2191.63,
      "end": 2192.63,
      "text": " So I say, for example,",
      "tokens": [
        51114,
        407,
        286,
        584,
        11,
        337,
        1365,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3330968916416168,
      "compression_ratio": 1.6782177686691284,
      "no_speech_prob": 0.03378737345337868
    },
    {
      "id": 441,
      "seek": 104100,
      "start": 2192.63,
      "end": 2197.63,
      "text": " that the payment takes place.",
      "tokens": [
        51164,
        300,
        264,
        10224,
        2516,
        1081,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3330968916416168,
      "compression_ratio": 1.6782177686691284,
      "no_speech_prob": 0.03378737345337868
    },
    {
      "id": 442,
      "seek": 104100,
      "start": 2197.63,
      "end": 2199.63,
      "text": " And then I have an event sourcing",
      "tokens": [
        51414,
        400,
        550,
        286,
        362,
        364,
        2280,
        11006,
        2175,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3330968916416168,
      "compression_ratio": 1.6782177686691284,
      "no_speech_prob": 0.03378737345337868
    },
    {
      "id": 443,
      "seek": 104100,
      "start": 2199.63,
      "end": 2203.63,
      "text": " to the database for the snapshot.",
      "tokens": [
        51514,
        281,
        264,
        8149,
        337,
        264,
        30163,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3330968916416168,
      "compression_ratio": 1.6782177686691284,
      "no_speech_prob": 0.03378737345337868
    },
    {
      "id": 444,
      "seek": 104100,
      "start": 2203.63,
      "end": 2205.63,
      "text": " And there I would now",
      "tokens": [
        51714,
        400,
        456,
        286,
        576,
        586,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3330968916416168,
      "compression_ratio": 1.6782177686691284,
      "no_speech_prob": 0.03378737345337868
    },
    {
      "id": 445,
      "seek": 107000,
      "start": 2205.63,
      "end": 2206.63,
      "text": " somehow every time",
      "tokens": [
        50364,
        6063,
        633,
        565,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4059288501739502,
      "compression_ratio": 1.620192289352417,
      "no_speech_prob": 0.005291554145514965
    },
    {
      "id": 446,
      "seek": 107000,
      "start": 2206.63,
      "end": 2209.63,
      "text": " a calculation is created,",
      "tokens": [
        50414,
        257,
        17108,
        307,
        2942,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4059288501739502,
      "compression_ratio": 1.620192289352417,
      "no_speech_prob": 0.005291554145514965
    },
    {
      "id": 447,
      "seek": 107000,
      "start": 2209.63,
      "end": 2211.63,
      "text": " a new entry is made",
      "tokens": [
        50564,
        257,
        777,
        8729,
        307,
        1027,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4059288501739502,
      "compression_ratio": 1.620192289352417,
      "no_speech_prob": 0.005291554145514965
    },
    {
      "id": 448,
      "seek": 107000,
      "start": 2211.63,
      "end": 2213.63,
      "text": " into this database.",
      "tokens": [
        50664,
        666,
        341,
        8149,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4059288501739502,
      "compression_ratio": 1.620192289352417,
      "no_speech_prob": 0.005291554145514965
    },
    {
      "id": 449,
      "seek": 107000,
      "start": 2213.63,
      "end": 2216.63,
      "text": " That is decoupled even more.",
      "tokens": [
        50764,
        663,
        307,
        979,
        263,
        15551,
        754,
        544,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4059288501739502,
      "compression_ratio": 1.620192289352417,
      "no_speech_prob": 0.005291554145514965
    },
    {
      "id": 450,
      "seek": 107000,
      "start": 2216.63,
      "end": 2219.63,
      "text": " And that could be useful,",
      "tokens": [
        50914,
        400,
        300,
        727,
        312,
        4420,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4059288501739502,
      "compression_ratio": 1.620192289352417,
      "no_speech_prob": 0.005291554145514965
    },
    {
      "id": 451,
      "seek": 107000,
      "start": 2219.63,
      "end": 2220.63,
      "text": " for example,",
      "tokens": [
        51064,
        337,
        1365,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4059288501739502,
      "compression_ratio": 1.620192289352417,
      "no_speech_prob": 0.005291554145514965
    },
    {
      "id": 452,
      "seek": 107000,
      "start": 2220.63,
      "end": 2222.63,
      "text": " for something like statistics.",
      "tokens": [
        51114,
        337,
        746,
        411,
        12523,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4059288501739502,
      "compression_ratio": 1.620192289352417,
      "no_speech_prob": 0.005291554145514965
    },
    {
      "id": 453,
      "seek": 107000,
      "start": 2222.63,
      "end": 2223.63,
      "text": " So for statistics,",
      "tokens": [
        51214,
        407,
        337,
        12523,
        11,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4059288501739502,
      "compression_ratio": 1.620192289352417,
      "no_speech_prob": 0.005291554145514965
    },
    {
      "id": 454,
      "seek": 107000,
      "start": 2223.63,
      "end": 2224.63,
      "text": " I might really want",
      "tokens": [
        51264,
        286,
        1062,
        534,
        528,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4059288501739502,
      "compression_ratio": 1.620192289352417,
      "no_speech_prob": 0.005291554145514965
    },
    {
      "id": 455,
      "seek": 107000,
      "start": 2224.63,
      "end": 2227.63,
      "text": " to have a separate reading model.",
      "tokens": [
        51314,
        281,
        362,
        257,
        4994,
        3760,
        2316,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4059288501739502,
      "compression_ratio": 1.620192289352417,
      "no_speech_prob": 0.005291554145514965
    },
    {
      "id": 456,
      "seek": 107000,
      "start": 2227.63,
      "end": 2229.63,
      "text": " I also want to have other information,",
      "tokens": [
        51464,
        286,
        611,
        528,
        281,
        362,
        661,
        1589,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4059288501739502,
      "compression_ratio": 1.620192289352417,
      "no_speech_prob": 0.005291554145514965
    },
    {
      "id": 457,
      "seek": 107000,
      "start": 2229.63,
      "end": 2231.63,
      "text": " somehow rather sums.",
      "tokens": [
        51564,
        6063,
        2831,
        34499,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4059288501739502,
      "compression_ratio": 1.620192289352417,
      "no_speech_prob": 0.005291554145514965
    },
    {
      "id": 458,
      "seek": 107000,
      "start": 2231.63,
      "end": 2233.63,
      "text": " And that's something",
      "tokens": [
        51664,
        400,
        300,
        311,
        746,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4059288501739502,
      "compression_ratio": 1.620192289352417,
      "no_speech_prob": 0.005291554145514965
    },
    {
      "id": 459,
      "seek": 109800,
      "start": 2233.63,
      "end": 2235.63,
      "text": " where I might really want to build",
      "tokens": [
        50364,
        689,
        286,
        1062,
        534,
        528,
        281,
        1322,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32592102885246277,
      "compression_ratio": 1.640211582183838,
      "no_speech_prob": 0.09926427900791168
    },
    {
      "id": 460,
      "seek": 109800,
      "start": 2235.63,
      "end": 2236.63,
      "text": " such a CQS thing.",
      "tokens": [
        50464,
        1270,
        257,
        383,
        48,
        50,
        551,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32592102885246277,
      "compression_ratio": 1.640211582183838,
      "no_speech_prob": 0.09926427900791168
    },
    {
      "id": 461,
      "seek": 109800,
      "start": 2236.63,
      "end": 2239.63,
      "text": " So I have the data, so to speak,",
      "tokens": [
        50514,
        407,
        286,
        362,
        264,
        1412,
        11,
        370,
        281,
        1710,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32592102885246277,
      "compression_ratio": 1.640211582183838,
      "no_speech_prob": 0.09926427900791168
    },
    {
      "id": 462,
      "seek": 109800,
      "start": 2239.63,
      "end": 2243.63,
      "text": " which is motion data.",
      "tokens": [
        50664,
        597,
        307,
        5394,
        1412,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32592102885246277,
      "compression_ratio": 1.640211582183838,
      "no_speech_prob": 0.09926427900791168
    },
    {
      "id": 463,
      "seek": 109800,
      "start": 2243.63,
      "end": 2244.63,
      "text": " And then I have the data",
      "tokens": [
        50864,
        400,
        550,
        286,
        362,
        264,
        1412,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32592102885246277,
      "compression_ratio": 1.640211582183838,
      "no_speech_prob": 0.09926427900791168
    },
    {
      "id": 464,
      "seek": 109800,
      "start": 2244.63,
      "end": 2247.63,
      "text": " for the statistics.",
      "tokens": [
        50914,
        337,
        264,
        12523,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32592102885246277,
      "compression_ratio": 1.640211582183838,
      "no_speech_prob": 0.09926427900791168
    },
    {
      "id": 465,
      "seek": 109800,
      "start": 2247.63,
      "end": 2251.63,
      "text": " And that would probably mean",
      "tokens": [
        51064,
        400,
        300,
        576,
        1391,
        914,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32592102885246277,
      "compression_ratio": 1.640211582183838,
      "no_speech_prob": 0.09926427900791168
    },
    {
      "id": 466,
      "seek": 109800,
      "start": 2251.63,
      "end": 2252.63,
      "text": " that statistics are perhaps",
      "tokens": [
        51264,
        300,
        12523,
        366,
        4317,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32592102885246277,
      "compression_ratio": 1.640211582183838,
      "no_speech_prob": 0.09926427900791168
    },
    {
      "id": 467,
      "seek": 109800,
      "start": 2252.63,
      "end": 2254.63,
      "text": " even a different context",
      "tokens": [
        51314,
        754,
        257,
        819,
        4319,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32592102885246277,
      "compression_ratio": 1.640211582183838,
      "no_speech_prob": 0.09926427900791168
    },
    {
      "id": 468,
      "seek": 109800,
      "start": 2254.63,
      "end": 2259.63,
      "text": " with a completely different data model.",
      "tokens": [
        51414,
        365,
        257,
        2584,
        819,
        1412,
        2316,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32592102885246277,
      "compression_ratio": 1.640211582183838,
      "no_speech_prob": 0.09926427900791168
    },
    {
      "id": 469,
      "seek": 109800,
      "start": 2259.63,
      "end": 2261.63,
      "text": " So maybe I have to model statistics",
      "tokens": [
        51664,
        407,
        1310,
        286,
        362,
        281,
        2316,
        12523,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32592102885246277,
      "compression_ratio": 1.640211582183838,
      "no_speech_prob": 0.09926427900791168
    },
    {
      "id": 470,
      "seek": 112600,
      "start": 2261.63,
      "end": 2263.63,
      "text": " and",
      "tokens": [
        50414,
        293,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45936259627342224,
      "compression_ratio": 0.27272728085517883,
      "no_speech_prob": 0.8801608681678772
    },
    {
      "id": 0,
      "seek": 0,
      "start": 2278.84,
      "end": 2284.84,
      "text": " I have a reading model, because I can only write and create an invoice once and then I can only read it.",
      "tokens": [
        50364,
        286,
        362,
        257,
        3760,
        2316,
        11,
        570,
        286,
        393,
        787,
        2464,
        293,
        1884,
        364,
        47919,
        1564,
        293,
        550,
        286,
        393,
        787,
        1401,
        309,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4894447326660156,
      "compression_ratio": 1.7838983535766602,
      "no_speech_prob": 0.9035325050354004
    },
    {
      "id": 1,
      "seek": 0,
      "start": 2284.84,
      "end": 2286.84,
      "text": " That's actually technically correct.",
      "tokens": [
        50664,
        663,
        311,
        767,
        12120,
        3006,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4894447326660156,
      "compression_ratio": 1.7838983535766602,
      "no_speech_prob": 0.9035325050354004
    },
    {
      "id": 2,
      "seek": 0,
      "start": 2286.84,
      "end": 2291.84,
      "text": " So I can't say, oops, I got lost in this invoice, let me change it for a moment,",
      "tokens": [
        50764,
        407,
        286,
        393,
        380,
        584,
        11,
        34166,
        11,
        286,
        658,
        2731,
        294,
        341,
        47919,
        11,
        718,
        385,
        1319,
        309,
        337,
        257,
        1623,
        11,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4894447326660156,
      "compression_ratio": 1.7838983535766602,
      "no_speech_prob": 0.9035325050354004
    },
    {
      "id": 3,
      "seek": 0,
      "start": 2291.84,
      "end": 2296.84,
      "text": " but I have to say, I got lost in the invoice, let me storm the invoice, I'll write a new one.",
      "tokens": [
        51014,
        457,
        286,
        362,
        281,
        584,
        11,
        286,
        658,
        2731,
        294,
        264,
        47919,
        11,
        718,
        385,
        7679,
        264,
        47919,
        11,
        286,
        603,
        2464,
        257,
        777,
        472,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4894447326660156,
      "compression_ratio": 1.7838983535766602,
      "no_speech_prob": 0.9035325050354004
    },
    {
      "id": 4,
      "seek": 0,
      "start": 2296.84,
      "end": 2304.84,
      "text": " That's a model that somehow says, okay, not allow queries, are just separated, work on the read replica.",
      "tokens": [
        51264,
        663,
        311,
        257,
        2316,
        300,
        6063,
        1619,
        11,
        1392,
        11,
        406,
        2089,
        24109,
        11,
        366,
        445,
        12005,
        11,
        589,
        322,
        264,
        1401,
        35456,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4894447326660156,
      "compression_ratio": 1.7838983535766602,
      "no_speech_prob": 0.9035325050354004
    },
    {
      "id": 5,
      "seek": 2600,
      "start": 2305.84,
      "end": 2309.84,
      "text": " And I have the other thing that somehow generates this invoice.",
      "tokens": [
        50414,
        400,
        286,
        362,
        264,
        661,
        551,
        300,
        6063,
        23815,
        341,
        47919,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4363342225551605,
      "compression_ratio": 1.5625,
      "no_speech_prob": 0.05812545493245125
    },
    {
      "id": 6,
      "seek": 2600,
      "start": 2309.84,
      "end": 2313.84,
      "text": " Maybe it's not bad at all to implement this policy strictly.",
      "tokens": [
        50614,
        2704,
        309,
        311,
        406,
        1578,
        412,
        439,
        281,
        4445,
        341,
        3897,
        20792,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4363342225551605,
      "compression_ratio": 1.5625,
      "no_speech_prob": 0.05812545493245125
    },
    {
      "id": 7,
      "seek": 2600,
      "start": 2313.84,
      "end": 2316.84,
      "text": " Maybe it's not so bad from a technical point of view.",
      "tokens": [
        50814,
        2704,
        309,
        311,
        406,
        370,
        1578,
        490,
        257,
        6191,
        935,
        295,
        1910,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4363342225551605,
      "compression_ratio": 1.5625,
      "no_speech_prob": 0.05812545493245125
    },
    {
      "id": 8,
      "seek": 2600,
      "start": 2320.84,
      "end": 2327.84,
      "text": " Typhonix writes, the wording snapshot is actually something else in the event sourcing context,",
      "tokens": [
        51164,
        5569,
        29285,
        970,
        13657,
        11,
        264,
        47602,
        30163,
        307,
        767,
        746,
        1646,
        294,
        264,
        2280,
        11006,
        2175,
        4319,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4363342225551605,
      "compression_ratio": 1.5625,
      "no_speech_prob": 0.05812545493245125
    },
    {
      "id": 9,
      "seek": 2600,
      "start": 2327.84,
      "end": 2332.84,
      "text": " so that the data is saved in between when storing.",
      "tokens": [
        51514,
        370,
        300,
        264,
        1412,
        307,
        6624,
        294,
        1296,
        562,
        26085,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4363342225551605,
      "compression_ratio": 1.5625,
      "no_speech_prob": 0.05812545493245125
    },
    {
      "id": 10,
      "seek": 5400,
      "start": 2332.84,
      "end": 2335.84,
      "text": " Actually, projections are meant, right?",
      "tokens": [
        50364,
        5135,
        11,
        32371,
        366,
        4140,
        11,
        558,
        30,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4437731206417084,
      "compression_ratio": 1.4337348937988281,
      "no_speech_prob": 0.020549127832055092
    },
    {
      "id": 11,
      "seek": 5400,
      "start": 2335.84,
      "end": 2343.84,
      "text": " Yes, it may well be that I got lost in the naming.",
      "tokens": [
        50514,
        1079,
        11,
        309,
        815,
        731,
        312,
        300,
        286,
        658,
        2731,
        294,
        264,
        25290,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4437731206417084,
      "compression_ratio": 1.4337348937988281,
      "no_speech_prob": 0.020549127832055092
    },
    {
      "id": 12,
      "seek": 5400,
      "start": 2343.84,
      "end": 2345.84,
      "text": " Good point, thank you for the hint.",
      "tokens": [
        50914,
        2205,
        935,
        11,
        1309,
        291,
        337,
        264,
        12075,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4437731206417084,
      "compression_ratio": 1.4337348937988281,
      "no_speech_prob": 0.020549127832055092
    },
    {
      "id": 13,
      "seek": 5400,
      "start": 2345.84,
      "end": 2353.84,
      "text": " So exactly, snapshot may actually refer to an aggregate.",
      "tokens": [
        51014,
        407,
        2293,
        11,
        30163,
        815,
        767,
        2864,
        281,
        364,
        26118,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4437731206417084,
      "compression_ratio": 1.4337348937988281,
      "no_speech_prob": 0.020549127832055092
    },
    {
      "id": 14,
      "seek": 5400,
      "start": 2353.84,
      "end": 2354.84,
      "text": " Good point.",
      "tokens": [
        51414,
        2205,
        935,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4437731206417084,
      "compression_ratio": 1.4337348937988281,
      "no_speech_prob": 0.020549127832055092
    },
    {
      "id": 15,
      "seek": 5400,
      "start": 2356.84,
      "end": 2359.84,
      "text": " I also made a whole episode on this topic.",
      "tokens": [
        51564,
        286,
        611,
        1027,
        257,
        1379,
        3500,
        322,
        341,
        4829,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4437731206417084,
      "compression_ratio": 1.4337348937988281,
      "no_speech_prob": 0.020549127832055092
    },
    {
      "id": 16,
      "seek": 8100,
      "start": 2359.84,
      "end": 2362.84,
      "text": " I'll discuss the topic in more depth.",
      "tokens": [
        50364,
        286,
        603,
        2248,
        264,
        4829,
        294,
        544,
        7161,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4168011248111725,
      "compression_ratio": 1.536697268486023,
      "no_speech_prob": 0.04574187844991684
    },
    {
      "id": 17,
      "seek": 8100,
      "start": 2362.84,
      "end": 2364.84,
      "text": " You can take a look at it.",
      "tokens": [
        50514,
        509,
        393,
        747,
        257,
        574,
        412,
        309,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4168011248111725,
      "compression_ratio": 1.536697268486023,
      "no_speech_prob": 0.04574187844991684
    },
    {
      "id": 18,
      "seek": 8100,
      "start": 2365.84,
      "end": 2371.84,
      "text": " And with that we come to this topic, where there was already interest last time.",
      "tokens": [
        50664,
        400,
        365,
        300,
        321,
        808,
        281,
        341,
        4829,
        11,
        689,
        456,
        390,
        1217,
        1179,
        1036,
        565,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4168011248111725,
      "compression_ratio": 1.536697268486023,
      "no_speech_prob": 0.04574187844991684
    },
    {
      "id": 19,
      "seek": 8100,
      "start": 2372.84,
      "end": 2374.84,
      "text": " And I planned a little faster, so to speak.",
      "tokens": [
        51014,
        400,
        286,
        8589,
        257,
        707,
        4663,
        11,
        370,
        281,
        1710,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4168011248111725,
      "compression_ratio": 1.536697268486023,
      "no_speech_prob": 0.04574187844991684
    },
    {
      "id": 20,
      "seek": 8100,
      "start": 2374.84,
      "end": 2376.84,
      "text": " And that's the story with the layers.",
      "tokens": [
        51114,
        400,
        300,
        311,
        264,
        1657,
        365,
        264,
        7914,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4168011248111725,
      "compression_ratio": 1.536697268486023,
      "no_speech_prob": 0.04574187844991684
    },
    {
      "id": 21,
      "seek": 8100,
      "start": 2379.84,
      "end": 2387.84,
      "text": " First of all, the hint is that this is actually a pattern from the original blue Domain Driven Design book.",
      "tokens": [
        51364,
        2386,
        295,
        439,
        11,
        264,
        12075,
        307,
        300,
        341,
        307,
        767,
        257,
        5102,
        490,
        264,
        3380,
        3344,
        16674,
        491,
        19150,
        553,
        12748,
        1446,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4168011248111725,
      "compression_ratio": 1.536697268486023,
      "no_speech_prob": 0.04574187844991684
    },
    {
      "id": 22,
      "seek": 10900,
      "start": 2387.84,
      "end": 2392.84,
      "text": " So there is layering as a pattern in this blue Domain Driven Design book.",
      "tokens": [
        50364,
        407,
        456,
        307,
        40754,
        382,
        257,
        5102,
        294,
        341,
        3344,
        16674,
        491,
        19150,
        553,
        12748,
        1446,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30022573471069336,
      "compression_ratio": 1.73221755027771,
      "no_speech_prob": 0.010817217640578747
    },
    {
      "id": 23,
      "seek": 10900,
      "start": 2392.84,
      "end": 2397.84,
      "text": " And that means that I have the UI, the logic and the persistence.",
      "tokens": [
        50614,
        400,
        300,
        1355,
        300,
        286,
        362,
        264,
        15682,
        11,
        264,
        9952,
        293,
        264,
        37617,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30022573471069336,
      "compression_ratio": 1.73221755027771,
      "no_speech_prob": 0.010817217640578747
    },
    {
      "id": 24,
      "seek": 10900,
      "start": 2397.84,
      "end": 2401.84,
      "text": " And such layers always have dependencies from top to bottom.",
      "tokens": [
        50864,
        400,
        1270,
        7914,
        1009,
        362,
        36606,
        490,
        1192,
        281,
        2767,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30022573471069336,
      "compression_ratio": 1.73221755027771,
      "no_speech_prob": 0.010817217640578747
    },
    {
      "id": 25,
      "seek": 10900,
      "start": 2401.84,
      "end": 2405.84,
      "text": " That means, I say the UI uses the logic, the logic uses the persistence.",
      "tokens": [
        51064,
        663,
        1355,
        11,
        286,
        584,
        264,
        15682,
        4960,
        264,
        9952,
        11,
        264,
        9952,
        4960,
        264,
        37617,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30022573471069336,
      "compression_ratio": 1.73221755027771,
      "no_speech_prob": 0.010817217640578747
    },
    {
      "id": 26,
      "seek": 10900,
      "start": 2405.84,
      "end": 2409.84,
      "text": " And that's exactly the story with the layering.",
      "tokens": [
        51264,
        400,
        300,
        311,
        2293,
        264,
        1657,
        365,
        264,
        40754,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30022573471069336,
      "compression_ratio": 1.73221755027771,
      "no_speech_prob": 0.010817217640578747
    },
    {
      "id": 27,
      "seek": 10900,
      "start": 2409.84,
      "end": 2414.84,
      "text": " For me, the prototypical model for a layering is actually something like this network stack,",
      "tokens": [
        51464,
        1171,
        385,
        11,
        264,
        46219,
        34061,
        2316,
        337,
        257,
        40754,
        307,
        767,
        746,
        411,
        341,
        3209,
        8630,
        11,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30022573471069336,
      "compression_ratio": 1.73221755027771,
      "no_speech_prob": 0.010817217640578747
    },
    {
      "id": 28,
      "seek": 13600,
      "start": 2414.84,
      "end": 2418.84,
      "text": " where I have a physical layer at the bottom, i.e. Ethernet or Wi-Fi.",
      "tokens": [
        50364,
        689,
        286,
        362,
        257,
        4001,
        4583,
        412,
        264,
        2767,
        11,
        741,
        13,
        68,
        13,
        38636,
        7129,
        420,
        14035,
        12,
        13229,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28749242424964905,
      "compression_ratio": 1.5964125394821167,
      "no_speech_prob": 0.01930687204003334
    },
    {
      "id": 29,
      "seek": 13600,
      "start": 2418.84,
      "end": 2424.84,
      "text": " Then I have IP over it, then I have TCP over it and then some protocols like FTP or HTTP.",
      "tokens": [
        50564,
        1396,
        286,
        362,
        8671,
        670,
        309,
        11,
        550,
        286,
        362,
        48965,
        670,
        309,
        293,
        550,
        512,
        20618,
        411,
        479,
        16804,
        420,
        33283,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28749242424964905,
      "compression_ratio": 1.5964125394821167,
      "no_speech_prob": 0.01930687204003334
    },
    {
      "id": 30,
      "seek": 13600,
      "start": 2424.84,
      "end": 2426.84,
      "text": " And that's exactly such a layering.",
      "tokens": [
        50864,
        400,
        300,
        311,
        2293,
        1270,
        257,
        40754,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28749242424964905,
      "compression_ratio": 1.5964125394821167,
      "no_speech_prob": 0.01930687204003334
    },
    {
      "id": 31,
      "seek": 13600,
      "start": 2426.84,
      "end": 2430.84,
      "text": " So HTTP uses TCP or UDP by now.",
      "tokens": [
        50964,
        407,
        33283,
        4960,
        48965,
        420,
        624,
        11373,
        538,
        586,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28749242424964905,
      "compression_ratio": 1.5964125394821167,
      "no_speech_prob": 0.01930687204003334
    },
    {
      "id": 32,
      "seek": 13600,
      "start": 2430.84,
      "end": 2432.84,
      "text": " TCP and UDP use IP.",
      "tokens": [
        51164,
        48965,
        293,
        624,
        11373,
        764,
        8671,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28749242424964905,
      "compression_ratio": 1.5964125394821167,
      "no_speech_prob": 0.01930687204003334
    },
    {
      "id": 33,
      "seek": 13600,
      "start": 2432.84,
      "end": 2437.84,
      "text": " IP then uses what I'm using right now, Ethernet or Wi-Fi.",
      "tokens": [
        51264,
        8671,
        550,
        4960,
        437,
        286,
        478,
        1228,
        558,
        586,
        11,
        38636,
        7129,
        420,
        14035,
        12,
        13229,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28749242424964905,
      "compression_ratio": 1.5964125394821167,
      "no_speech_prob": 0.01930687204003334
    },
    {
      "id": 34,
      "seek": 13600,
      "start": 2437.84,
      "end": 2441.84,
      "text": " And there is only the dependency in this direction.",
      "tokens": [
        51514,
        400,
        456,
        307,
        787,
        264,
        33621,
        294,
        341,
        3513,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28749242424964905,
      "compression_ratio": 1.5964125394821167,
      "no_speech_prob": 0.01930687204003334
    },
    {
      "id": 35,
      "seek": 16300,
      "start": 2441.84,
      "end": 2447.84,
      "text": " I mention this because I think this layering often makes sense from a technical perspective.",
      "tokens": [
        50364,
        286,
        2152,
        341,
        570,
        286,
        519,
        341,
        40754,
        2049,
        1669,
        2020,
        490,
        257,
        6191,
        4585,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3286626636981964,
      "compression_ratio": 1.5829596519470215,
      "no_speech_prob": 0.051697611808776855
    },
    {
      "id": 36,
      "seek": 16300,
      "start": 2449.84,
      "end": 2453.84,
      "text": " But here we are talking about how we structure expertise.",
      "tokens": [
        50764,
        583,
        510,
        321,
        366,
        1417,
        466,
        577,
        321,
        3877,
        11769,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3286626636981964,
      "compression_ratio": 1.5829596519470215,
      "no_speech_prob": 0.051697611808776855
    },
    {
      "id": 37,
      "seek": 16300,
      "start": 2453.84,
      "end": 2456.84,
      "text": " And now the question is to me,",
      "tokens": [
        50964,
        400,
        586,
        264,
        1168,
        307,
        281,
        385,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3286626636981964,
      "compression_ratio": 1.5829596519470215,
      "no_speech_prob": 0.051697611808776855
    },
    {
      "id": 38,
      "seek": 16300,
      "start": 2456.84,
      "end": 2459.84,
      "text": " with network layering, for example,",
      "tokens": [
        51114,
        365,
        3209,
        40754,
        11,
        337,
        1365,
        11,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3286626636981964,
      "compression_ratio": 1.5829596519470215,
      "no_speech_prob": 0.051697611808776855
    },
    {
      "id": 39,
      "seek": 16300,
      "start": 2459.84,
      "end": 2462.84,
      "text": " because I have this physical layer,",
      "tokens": [
        51264,
        570,
        286,
        362,
        341,
        4001,
        4583,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3286626636981964,
      "compression_ratio": 1.5829596519470215,
      "no_speech_prob": 0.051697611808776855
    },
    {
      "id": 40,
      "seek": 16300,
      "start": 2462.84,
      "end": 2466.84,
      "text": " I can now switch from Ethernet to Wi-Fi relatively trivially",
      "tokens": [
        51414,
        286,
        393,
        586,
        3679,
        490,
        38636,
        7129,
        281,
        14035,
        12,
        13229,
        7226,
        1376,
        85,
        2270,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3286626636981964,
      "compression_ratio": 1.5829596519470215,
      "no_speech_prob": 0.051697611808776855
    },
    {
      "id": 41,
      "seek": 16300,
      "start": 2466.84,
      "end": 2469.84,
      "text": " or from Wi-Fi to mobile communication.",
      "tokens": [
        51614,
        420,
        490,
        14035,
        12,
        13229,
        281,
        6013,
        6101,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3286626636981964,
      "compression_ratio": 1.5829596519470215,
      "no_speech_prob": 0.051697611808776855
    },
    {
      "id": 42,
      "seek": 19100,
      "start": 2469.84,
      "end": 2472.84,
      "text": " This is exactly hidden above that.",
      "tokens": [
        50364,
        639,
        307,
        2293,
        7633,
        3673,
        300,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3798165023326874,
      "compression_ratio": 1.616740107536316,
      "no_speech_prob": 0.013623423874378204
    },
    {
      "id": 43,
      "seek": 19100,
      "start": 2472.84,
      "end": 2476.84,
      "text": " So that means I can exchange this lower layer exactly",
      "tokens": [
        50514,
        407,
        300,
        1355,
        286,
        393,
        454,
        15431,
        341,
        3126,
        4583,
        2293,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3798165023326874,
      "compression_ratio": 1.616740107536316,
      "no_speech_prob": 0.013623423874378204
    },
    {
      "id": 44,
      "seek": 19100,
      "start": 2476.84,
      "end": 2479.84,
      "text": " and the rest of the system remains untouched.",
      "tokens": [
        50714,
        293,
        264,
        1472,
        295,
        264,
        1185,
        7023,
        1701,
        36740,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3798165023326874,
      "compression_ratio": 1.616740107536316,
      "no_speech_prob": 0.013623423874378204
    },
    {
      "id": 45,
      "seek": 19100,
      "start": 2481.84,
      "end": 2485.84,
      "text": " Here I would argue that this is not really a good reason,",
      "tokens": [
        50964,
        1692,
        286,
        576,
        9695,
        300,
        341,
        307,
        406,
        534,
        257,
        665,
        1778,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3798165023326874,
      "compression_ratio": 1.616740107536316,
      "no_speech_prob": 0.013623423874378204
    },
    {
      "id": 46,
      "seek": 19100,
      "start": 2485.84,
      "end": 2489.84,
      "text": " because I will probably rarely exchange the persistence.",
      "tokens": [
        51164,
        570,
        286,
        486,
        1391,
        13752,
        7742,
        264,
        37617,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3798165023326874,
      "compression_ratio": 1.616740107536316,
      "no_speech_prob": 0.013623423874378204
    },
    {
      "id": 47,
      "seek": 19100,
      "start": 2489.84,
      "end": 2493.84,
      "text": " So the question is to me why this pattern is there after all.",
      "tokens": [
        51364,
        407,
        264,
        1168,
        307,
        281,
        385,
        983,
        341,
        5102,
        307,
        456,
        934,
        439,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3798165023326874,
      "compression_ratio": 1.616740107536316,
      "no_speech_prob": 0.013623423874378204
    },
    {
      "id": 48,
      "seek": 19100,
      "start": 2493.84,
      "end": 2496.84,
      "text": " And what Eric said to me is, well, I separate the logic",
      "tokens": [
        51564,
        400,
        437,
        9336,
        848,
        281,
        385,
        307,
        11,
        731,
        11,
        286,
        4994,
        264,
        9952,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3798165023326874,
      "compression_ratio": 1.616740107536316,
      "no_speech_prob": 0.013623423874378204
    },
    {
      "id": 49,
      "seek": 21800,
      "start": 2496.84,
      "end": 2499.84,
      "text": " and have them in exactly one place.",
      "tokens": [
        50364,
        293,
        362,
        552,
        294,
        2293,
        472,
        1081,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3629695773124695,
      "compression_ratio": 1.6892430782318115,
      "no_speech_prob": 0.039980705827474594
    },
    {
      "id": 50,
      "seek": 21800,
      "start": 2499.84,
      "end": 2503.84,
      "text": " And that's how I build the system so that it's easy to understand.",
      "tokens": [
        50514,
        400,
        300,
        311,
        577,
        286,
        1322,
        264,
        1185,
        370,
        300,
        309,
        311,
        1858,
        281,
        1223,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3629695773124695,
      "compression_ratio": 1.6892430782318115,
      "no_speech_prob": 0.039980705827474594
    },
    {
      "id": 51,
      "seek": 21800,
      "start": 2504.84,
      "end": 2506.84,
      "text": " And in fact, it's like that.",
      "tokens": [
        50764,
        400,
        294,
        1186,
        11,
        309,
        311,
        411,
        300,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3629695773124695,
      "compression_ratio": 1.6892430782318115,
      "no_speech_prob": 0.039980705827474594
    },
    {
      "id": 52,
      "seek": 21800,
      "start": 2506.84,
      "end": 2509.84,
      "text": " Domain Design doesn't say anything about the UI.",
      "tokens": [
        50864,
        16674,
        491,
        12748,
        1177,
        380,
        584,
        1340,
        466,
        264,
        15682,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3629695773124695,
      "compression_ratio": 1.6892430782318115,
      "no_speech_prob": 0.039980705827474594
    },
    {
      "id": 53,
      "seek": 21800,
      "start": 2509.84,
      "end": 2511.84,
      "text": " So what Domain Design says is,",
      "tokens": [
        51014,
        407,
        437,
        16674,
        491,
        12748,
        1619,
        307,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3629695773124695,
      "compression_ratio": 1.6892430782318115,
      "no_speech_prob": 0.039980705827474594
    },
    {
      "id": 54,
      "seek": 21800,
      "start": 2511.84,
      "end": 2514.84,
      "text": " OK, we have services, we have aggregates, such things.",
      "tokens": [
        51114,
        2264,
        11,
        321,
        362,
        3328,
        11,
        321,
        362,
        16743,
        1024,
        11,
        1270,
        721,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3629695773124695,
      "compression_ratio": 1.6892430782318115,
      "no_speech_prob": 0.039980705827474594
    },
    {
      "id": 55,
      "seek": 21800,
      "start": 2514.84,
      "end": 2517.84,
      "text": " That we have a UI that uses it is somehow clear.",
      "tokens": [
        51264,
        663,
        321,
        362,
        257,
        15682,
        300,
        4960,
        309,
        307,
        6063,
        1850,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3629695773124695,
      "compression_ratio": 1.6892430782318115,
      "no_speech_prob": 0.039980705827474594
    },
    {
      "id": 56,
      "seek": 21800,
      "start": 2517.84,
      "end": 2520.84,
      "text": " But we don't say how it should be structured.",
      "tokens": [
        51414,
        583,
        321,
        500,
        380,
        584,
        577,
        309,
        820,
        312,
        18519,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3629695773124695,
      "compression_ratio": 1.6892430782318115,
      "no_speech_prob": 0.039980705827474594
    },
    {
      "id": 57,
      "seek": 21800,
      "start": 2520.84,
      "end": 2524.84,
      "text": " There are also possibilities to structure something like that.",
      "tokens": [
        51564,
        821,
        366,
        611,
        12178,
        281,
        3877,
        746,
        411,
        300,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3629695773124695,
      "compression_ratio": 1.6892430782318115,
      "no_speech_prob": 0.039980705827474594
    },
    {
      "id": 58,
      "seek": 24600,
      "start": 2524.84,
      "end": 2529.84,
      "text": " And with the persistence, well, there is a repository as a pattern.",
      "tokens": [
        50364,
        400,
        365,
        264,
        37617,
        11,
        731,
        11,
        456,
        307,
        257,
        25841,
        382,
        257,
        5102,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3858024775981903,
      "compression_ratio": 1.541062831878662,
      "no_speech_prob": 0.020924143493175507
    },
    {
      "id": 59,
      "seek": 24600,
      "start": 2529.84,
      "end": 2533.84,
      "text": " But that doesn't say that much about",
      "tokens": [
        50614,
        583,
        300,
        1177,
        380,
        584,
        300,
        709,
        466,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3858024775981903,
      "compression_ratio": 1.541062831878662,
      "no_speech_prob": 0.020924143493175507
    },
    {
      "id": 60,
      "seek": 24600,
      "start": 2533.84,
      "end": 2537.84,
      "text": " how you want to implement it exactly.",
      "tokens": [
        50814,
        577,
        291,
        528,
        281,
        4445,
        309,
        2293,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3858024775981903,
      "compression_ratio": 1.541062831878662,
      "no_speech_prob": 0.020924143493175507
    },
    {
      "id": 61,
      "seek": 24600,
      "start": 2539.84,
      "end": 2543.84,
      "text": " We just saw this transaction script, for example.",
      "tokens": [
        51114,
        492,
        445,
        1866,
        341,
        14425,
        5755,
        11,
        337,
        1365,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3858024775981903,
      "compression_ratio": 1.541062831878662,
      "no_speech_prob": 0.020924143493175507
    },
    {
      "id": 62,
      "seek": 24600,
      "start": 2543.84,
      "end": 2546.84,
      "text": " There are definitely other possibilities.",
      "tokens": [
        51314,
        821,
        366,
        2138,
        661,
        12178,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3858024775981903,
      "compression_ratio": 1.541062831878662,
      "no_speech_prob": 0.020924143493175507
    },
    {
      "id": 63,
      "seek": 24600,
      "start": 2546.84,
      "end": 2551.84,
      "text": " And that means that the core of this pattern only says,",
      "tokens": [
        51464,
        400,
        300,
        1355,
        300,
        264,
        4965,
        295,
        341,
        5102,
        787,
        1619,
        11,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3858024775981903,
      "compression_ratio": 1.541062831878662,
      "no_speech_prob": 0.020924143493175507
    },
    {
      "id": 64,
      "seek": 24600,
      "start": 2551.84,
      "end": 2553.84,
      "text": " we have separated the logic.",
      "tokens": [
        51714,
        321,
        362,
        12005,
        264,
        9952,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3858024775981903,
      "compression_ratio": 1.541062831878662,
      "no_speech_prob": 0.020924143493175507
    },
    {
      "id": 65,
      "seek": 27500,
      "start": 2553.84,
      "end": 2558.84,
      "text": " The logic is actually the area where Domain Design says a lot about it.",
      "tokens": [
        50364,
        440,
        9952,
        307,
        767,
        264,
        1859,
        689,
        16674,
        491,
        12748,
        1619,
        257,
        688,
        466,
        309,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3215648829936981,
      "compression_ratio": 1.7446043491363525,
      "no_speech_prob": 0.008522721007466316
    },
    {
      "id": 66,
      "seek": 27500,
      "start": 2558.84,
      "end": 2560.84,
      "text": " Entity, aggregates and so on.",
      "tokens": [
        50614,
        3951,
        507,
        11,
        16743,
        1024,
        293,
        370,
        322,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3215648829936981,
      "compression_ratio": 1.7446043491363525,
      "no_speech_prob": 0.008522721007466316
    },
    {
      "id": 67,
      "seek": 27500,
      "start": 2560.84,
      "end": 2563.84,
      "text": " These are all things that are somehow in this logic layer.",
      "tokens": [
        50714,
        1981,
        366,
        439,
        721,
        300,
        366,
        6063,
        294,
        341,
        9952,
        4583,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3215648829936981,
      "compression_ratio": 1.7446043491363525,
      "no_speech_prob": 0.008522721007466316
    },
    {
      "id": 68,
      "seek": 27500,
      "start": 2563.84,
      "end": 2565.84,
      "text": " And we separate that from the persistence,",
      "tokens": [
        50864,
        400,
        321,
        4994,
        300,
        490,
        264,
        37617,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3215648829936981,
      "compression_ratio": 1.7446043491363525,
      "no_speech_prob": 0.008522721007466316
    },
    {
      "id": 69,
      "seek": 27500,
      "start": 2565.84,
      "end": 2569.84,
      "text": " so that I don't, when I think about the logic and look at what's going on there,",
      "tokens": [
        50964,
        370,
        300,
        286,
        500,
        380,
        11,
        562,
        286,
        519,
        466,
        264,
        9952,
        293,
        574,
        412,
        437,
        311,
        516,
        322,
        456,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3215648829936981,
      "compression_ratio": 1.7446043491363525,
      "no_speech_prob": 0.008522721007466316
    },
    {
      "id": 70,
      "seek": 27500,
      "start": 2569.84,
      "end": 2573.84,
      "text": " somehow get annoyed by SQL statements that have nothing to do with it.",
      "tokens": [
        51164,
        6063,
        483,
        25921,
        538,
        19200,
        12363,
        300,
        362,
        1825,
        281,
        360,
        365,
        309,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3215648829936981,
      "compression_ratio": 1.7446043491363525,
      "no_speech_prob": 0.008522721007466316
    },
    {
      "id": 71,
      "seek": 27500,
      "start": 2573.84,
      "end": 2576.84,
      "text": " Or JPA stories that have nothing to do with it.",
      "tokens": [
        51364,
        1610,
        508,
        10297,
        3676,
        300,
        362,
        1825,
        281,
        360,
        365,
        309,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3215648829936981,
      "compression_ratio": 1.7446043491363525,
      "no_speech_prob": 0.008522721007466316
    },
    {
      "id": 72,
      "seek": 27500,
      "start": 2576.84,
      "end": 2578.84,
      "text": " But I have that somewhere else.",
      "tokens": [
        51514,
        583,
        286,
        362,
        300,
        4079,
        1646,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3215648829936981,
      "compression_ratio": 1.7446043491363525,
      "no_speech_prob": 0.008522721007466316
    },
    {
      "id": 73,
      "seek": 27500,
      "start": 2578.84,
      "end": 2581.84,
      "text": " And analogously, I also separated the UI from it.",
      "tokens": [
        51614,
        400,
        16660,
        5098,
        11,
        286,
        611,
        12005,
        264,
        15682,
        490,
        309,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3215648829936981,
      "compression_ratio": 1.7446043491363525,
      "no_speech_prob": 0.008522721007466316
    },
    {
      "id": 74,
      "seek": 30300,
      "start": 2582.84,
      "end": 2587.84,
      "text": " And on this abstraction layer, or on this abstraction level,",
      "tokens": [
        50414,
        400,
        322,
        341,
        37765,
        4583,
        11,
        420,
        322,
        341,
        410,
        9733,
        2894,
        1496,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3526248335838318,
      "compression_ratio": 1.6023391485214233,
      "no_speech_prob": 0.007320079021155834
    },
    {
      "id": 75,
      "seek": 30300,
      "start": 2587.84,
      "end": 2596.84,
      "text": " hexagonal architecture is actually a solution to the same problem.",
      "tokens": [
        50664,
        23291,
        6709,
        304,
        9482,
        307,
        767,
        257,
        3827,
        281,
        264,
        912,
        1154,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3526248335838318,
      "compression_ratio": 1.6023391485214233,
      "no_speech_prob": 0.007320079021155834
    },
    {
      "id": 76,
      "seek": 30300,
      "start": 2596.84,
      "end": 2601.84,
      "text": " In other words, Eric could have said in his book,",
      "tokens": [
        51114,
        682,
        661,
        2283,
        11,
        9336,
        727,
        362,
        848,
        294,
        702,
        1446,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3526248335838318,
      "compression_ratio": 1.6023391485214233,
      "no_speech_prob": 0.007320079021155834
    },
    {
      "id": 77,
      "seek": 30300,
      "start": 2601.84,
      "end": 2605.84,
      "text": " we're not talking about layers, we're talking about hexagonal.",
      "tokens": [
        51364,
        321,
        434,
        406,
        1417,
        466,
        7914,
        11,
        321,
        434,
        1417,
        466,
        23291,
        6709,
        304,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3526248335838318,
      "compression_ratio": 1.6023391485214233,
      "no_speech_prob": 0.007320079021155834
    },
    {
      "id": 78,
      "seek": 30300,
      "start": 2605.84,
      "end": 2608.84,
      "text": " That he didn't do that is because",
      "tokens": [
        51564,
        663,
        415,
        994,
        380,
        360,
        300,
        307,
        570,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3526248335838318,
      "compression_ratio": 1.6023391485214233,
      "no_speech_prob": 0.007320079021155834
    },
    {
      "id": 79,
      "seek": 33000,
      "start": 2608.84,
      "end": 2614.84,
      "text": " Domain Driven Design, if I'm not mistaken, is a bit older than hexagonal architecture.",
      "tokens": [
        50364,
        16674,
        491,
        19150,
        553,
        12748,
        11,
        498,
        286,
        478,
        406,
        21333,
        11,
        307,
        257,
        857,
        4906,
        813,
        23291,
        6709,
        304,
        9482,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34483927488327026,
      "compression_ratio": 1.7041198015213013,
      "no_speech_prob": 0.03217428922653198
    },
    {
      "id": 80,
      "seek": 33000,
      "start": 2614.84,
      "end": 2617.84,
      "text": " In other words, back then it was somehow this three-layer architecture",
      "tokens": [
        50664,
        682,
        661,
        2283,
        11,
        646,
        550,
        309,
        390,
        6063,
        341,
        1045,
        12,
        8376,
        260,
        9482,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34483927488327026,
      "compression_ratio": 1.7041198015213013,
      "no_speech_prob": 0.03217428922653198
    },
    {
      "id": 81,
      "seek": 33000,
      "start": 2617.84,
      "end": 2621.84,
      "text": " with UI, logic and persistence that was typically done.",
      "tokens": [
        50814,
        365,
        15682,
        11,
        9952,
        293,
        37617,
        300,
        390,
        5850,
        1096,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34483927488327026,
      "compression_ratio": 1.7041198015213013,
      "no_speech_prob": 0.03217428922653198
    },
    {
      "id": 82,
      "seek": 33000,
      "start": 2621.84,
      "end": 2624.84,
      "text": " So what's different about hexagonal architecture now?",
      "tokens": [
        51014,
        407,
        437,
        311,
        819,
        466,
        23291,
        6709,
        304,
        9482,
        586,
        30,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34483927488327026,
      "compression_ratio": 1.7041198015213013,
      "no_speech_prob": 0.03217428922653198
    },
    {
      "id": 83,
      "seek": 33000,
      "start": 2624.84,
      "end": 2627.84,
      "text": " Clean Architecture is very similar, for example.",
      "tokens": [
        51164,
        18463,
        43049,
        307,
        588,
        2531,
        11,
        337,
        1365,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34483927488327026,
      "compression_ratio": 1.7041198015213013,
      "no_speech_prob": 0.03217428922653198
    },
    {
      "id": 84,
      "seek": 33000,
      "start": 2627.84,
      "end": 2630.84,
      "text": " I say the business logic exports some ports.",
      "tokens": [
        51314,
        286,
        584,
        264,
        1606,
        9952,
        31428,
        512,
        18160,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34483927488327026,
      "compression_ratio": 1.7041198015213013,
      "no_speech_prob": 0.03217428922653198
    },
    {
      "id": 85,
      "seek": 33000,
      "start": 2630.84,
      "end": 2632.84,
      "text": " So I have the business logic.",
      "tokens": [
        51464,
        407,
        286,
        362,
        264,
        1606,
        9952,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34483927488327026,
      "compression_ratio": 1.7041198015213013,
      "no_speech_prob": 0.03217428922653198
    },
    {
      "id": 86,
      "seek": 33000,
      "start": 2632.84,
      "end": 2636.84,
      "text": " It now has a port here, for example, to send out notifications.",
      "tokens": [
        51564,
        467,
        586,
        575,
        257,
        2436,
        510,
        11,
        337,
        1365,
        11,
        281,
        2845,
        484,
        13426,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34483927488327026,
      "compression_ratio": 1.7041198015213013,
      "no_speech_prob": 0.03217428922653198
    },
    {
      "id": 87,
      "seek": 35800,
      "start": 2636.84,
      "end": 2640.84,
      "text": " And then I have adapters that implement these ports.",
      "tokens": [
        50364,
        400,
        550,
        286,
        362,
        23169,
        1559,
        300,
        4445,
        613,
        18160,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28080520033836365,
      "compression_ratio": 1.8706467151641846,
      "no_speech_prob": 0.012958621606230736
    },
    {
      "id": 88,
      "seek": 35800,
      "start": 2640.84,
      "end": 2642.84,
      "text": " So I have an email adapter, for example.",
      "tokens": [
        50564,
        407,
        286,
        362,
        364,
        3796,
        22860,
        11,
        337,
        1365,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28080520033836365,
      "compression_ratio": 1.8706467151641846,
      "no_speech_prob": 0.012958621606230736
    },
    {
      "id": 89,
      "seek": 35800,
      "start": 2642.84,
      "end": 2645.84,
      "text": " So that means I say here in the business logic,",
      "tokens": [
        50664,
        407,
        300,
        1355,
        286,
        584,
        510,
        294,
        264,
        1606,
        9952,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28080520033836365,
      "compression_ratio": 1.8706467151641846,
      "no_speech_prob": 0.012958621606230736
    },
    {
      "id": 90,
      "seek": 35800,
      "start": 2645.84,
      "end": 2650.84,
      "text": " I have a notification interface.",
      "tokens": [
        50814,
        286,
        362,
        257,
        11554,
        9226,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28080520033836365,
      "compression_ratio": 1.8706467151641846,
      "no_speech_prob": 0.012958621606230736
    },
    {
      "id": 91,
      "seek": 35800,
      "start": 2650.84,
      "end": 2654.84,
      "text": " And the email adapter can now implement it.",
      "tokens": [
        51064,
        400,
        264,
        3796,
        22860,
        393,
        586,
        4445,
        309,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28080520033836365,
      "compression_ratio": 1.8706467151641846,
      "no_speech_prob": 0.012958621606230736
    },
    {
      "id": 92,
      "seek": 35800,
      "start": 2654.84,
      "end": 2659.84,
      "text": " And here, for example, are some business events that I now output to the UI.",
      "tokens": [
        51264,
        400,
        510,
        11,
        337,
        1365,
        11,
        366,
        512,
        1606,
        3931,
        300,
        286,
        586,
        5598,
        281,
        264,
        15682,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28080520033836365,
      "compression_ratio": 1.8706467151641846,
      "no_speech_prob": 0.012958621606230736
    },
    {
      "id": 93,
      "seek": 35800,
      "start": 2659.84,
      "end": 2663.84,
      "text": " Here's an admin thing that I output to the admin UI.",
      "tokens": [
        51514,
        1692,
        311,
        364,
        24236,
        551,
        300,
        286,
        5598,
        281,
        264,
        24236,
        15682,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28080520033836365,
      "compression_ratio": 1.8706467151641846,
      "no_speech_prob": 0.012958621606230736
    },
    {
      "id": 94,
      "seek": 35800,
      "start": 2663.84,
      "end": 2664.84,
      "text": " And here's the persistence.",
      "tokens": [
        51714,
        400,
        510,
        311,
        264,
        37617,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28080520033836365,
      "compression_ratio": 1.8706467151641846,
      "no_speech_prob": 0.012958621606230736
    },
    {
      "id": 95,
      "seek": 38600,
      "start": 2664.84,
      "end": 2668.84,
      "text": " And I have a database adapter that implements this persistence.",
      "tokens": [
        50364,
        400,
        286,
        362,
        257,
        8149,
        22860,
        300,
        704,
        17988,
        341,
        37617,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3606351613998413,
      "compression_ratio": 1.7894736528396606,
      "no_speech_prob": 0.04001934453845024
    },
    {
      "id": 96,
      "seek": 38600,
      "start": 2668.84,
      "end": 2674.84,
      "text": " So what I've achieved is that in all cases,",
      "tokens": [
        50564,
        407,
        437,
        286,
        600,
        11042,
        307,
        300,
        294,
        439,
        3331,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3606351613998413,
      "compression_ratio": 1.7894736528396606,
      "no_speech_prob": 0.04001934453845024
    },
    {
      "id": 97,
      "seek": 38600,
      "start": 2674.84,
      "end": 2678.84,
      "text": " the dependency from the outside, from the database adapter, for example, to persistence,",
      "tokens": [
        50864,
        264,
        33621,
        490,
        264,
        2380,
        11,
        490,
        264,
        8149,
        22860,
        11,
        337,
        1365,
        11,
        281,
        37617,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3606351613998413,
      "compression_ratio": 1.7894736528396606,
      "no_speech_prob": 0.04001934453845024
    },
    {
      "id": 98,
      "seek": 38600,
      "start": 2678.84,
      "end": 2682.84,
      "text": " it implements what the persistence would like to have here.",
      "tokens": [
        51064,
        309,
        704,
        17988,
        437,
        264,
        37617,
        576,
        411,
        281,
        362,
        510,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3606351613998413,
      "compression_ratio": 1.7894736528396606,
      "no_speech_prob": 0.04001934453845024
    },
    {
      "id": 99,
      "seek": 38600,
      "start": 2682.84,
      "end": 2685.84,
      "text": " Or here from the admin UI to admin.",
      "tokens": [
        51264,
        1610,
        510,
        490,
        264,
        24236,
        15682,
        281,
        24236,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3606351613998413,
      "compression_ratio": 1.7894736528396606,
      "no_speech_prob": 0.04001934453845024
    },
    {
      "id": 100,
      "seek": 38600,
      "start": 2685.84,
      "end": 2688.84,
      "text": " Or from the email adapter to notification.",
      "tokens": [
        51414,
        1610,
        490,
        264,
        3796,
        22860,
        281,
        11554,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3606351613998413,
      "compression_ratio": 1.7894736528396606,
      "no_speech_prob": 0.04001934453845024
    },
    {
      "id": 101,
      "seek": 38600,
      "start": 2688.84,
      "end": 2691.84,
      "text": " And that's not the case with layering.",
      "tokens": [
        51564,
        400,
        300,
        311,
        406,
        264,
        1389,
        365,
        40754,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3606351613998413,
      "compression_ratio": 1.7894736528396606,
      "no_speech_prob": 0.04001934453845024
    },
    {
      "id": 102,
      "seek": 41300,
      "start": 2691.84,
      "end": 2695.84,
      "text": " With layering, the logic uses the persistence.",
      "tokens": [
        50364,
        2022,
        40754,
        11,
        264,
        9952,
        4960,
        264,
        37617,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3551783859729767,
      "compression_ratio": 1.705607533454895,
      "no_speech_prob": 0.17067046463489532
    },
    {
      "id": 103,
      "seek": 41300,
      "start": 2695.84,
      "end": 2698.84,
      "text": " So that means logic depends on persistence.",
      "tokens": [
        50564,
        407,
        300,
        1355,
        9952,
        5946,
        322,
        37617,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3551783859729767,
      "compression_ratio": 1.705607533454895,
      "no_speech_prob": 0.17067046463489532
    },
    {
      "id": 104,
      "seek": 41300,
      "start": 2698.84,
      "end": 2701.84,
      "text": " Everything depends on the logic here,",
      "tokens": [
        50714,
        5471,
        5946,
        322,
        264,
        9952,
        510,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3551783859729767,
      "compression_ratio": 1.705607533454895,
      "no_speech_prob": 0.17067046463489532
    },
    {
      "id": 105,
      "seek": 41300,
      "start": 2701.84,
      "end": 2705.84,
      "text": " including the implementation of the persistence of the database adapter.",
      "tokens": [
        50864,
        3009,
        264,
        11420,
        295,
        264,
        37617,
        295,
        264,
        8149,
        22860,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3551783859729767,
      "compression_ratio": 1.705607533454895,
      "no_speech_prob": 0.17067046463489532
    },
    {
      "id": 106,
      "seek": 41300,
      "start": 2705.84,
      "end": 2712.84,
      "text": " For me, this is relatively similar to this dependency inversion principle,",
      "tokens": [
        51064,
        1171,
        385,
        11,
        341,
        307,
        7226,
        2531,
        281,
        341,
        33621,
        43576,
        8665,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3551783859729767,
      "compression_ratio": 1.705607533454895,
      "no_speech_prob": 0.17067046463489532
    },
    {
      "id": 107,
      "seek": 41300,
      "start": 2712.84,
      "end": 2714.84,
      "text": " where I say if I use something,",
      "tokens": [
        51414,
        689,
        286,
        584,
        498,
        286,
        764,
        746,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3551783859729767,
      "compression_ratio": 1.705607533454895,
      "no_speech_prob": 0.17067046463489532
    },
    {
      "id": 108,
      "seek": 41300,
      "start": 2714.84,
      "end": 2719.84,
      "text": " well, then I can also define the interface here somehow.",
      "tokens": [
        51514,
        731,
        11,
        550,
        286,
        393,
        611,
        6964,
        264,
        9226,
        510,
        6063,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3551783859729767,
      "compression_ratio": 1.705607533454895,
      "no_speech_prob": 0.17067046463489532
    },
    {
      "id": 109,
      "seek": 44100,
      "start": 2719.84,
      "end": 2722.84,
      "text": " And then the dependency is exactly the other way around.",
      "tokens": [
        50364,
        400,
        550,
        264,
        33621,
        307,
        2293,
        264,
        661,
        636,
        926,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37962883710861206,
      "compression_ratio": 1.818652868270874,
      "no_speech_prob": 0.010137545876204967
    },
    {
      "id": 110,
      "seek": 44100,
      "start": 2722.84,
      "end": 2726.84,
      "text": " So the business logic uses the database adapter,",
      "tokens": [
        50514,
        407,
        264,
        1606,
        9952,
        4960,
        264,
        8149,
        22860,
        11,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37962883710861206,
      "compression_ratio": 1.818652868270874,
      "no_speech_prob": 0.010137545876204967
    },
    {
      "id": 111,
      "seek": 44100,
      "start": 2726.84,
      "end": 2729.84,
      "text": " but it's not software-dependent,",
      "tokens": [
        50714,
        457,
        309,
        311,
        406,
        4722,
        12,
        36763,
        317,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37962883710861206,
      "compression_ratio": 1.818652868270874,
      "no_speech_prob": 0.010137545876204967
    },
    {
      "id": 112,
      "seek": 44100,
      "start": 2729.84,
      "end": 2734.84,
      "text": " but it gives it the interface that the database adapter has to implement.",
      "tokens": [
        50864,
        457,
        309,
        2709,
        309,
        264,
        9226,
        300,
        264,
        8149,
        22860,
        575,
        281,
        4445,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37962883710861206,
      "compression_ratio": 1.818652868270874,
      "no_speech_prob": 0.010137545876204967
    },
    {
      "id": 113,
      "seek": 44100,
      "start": 2734.84,
      "end": 2738.84,
      "text": " So that means database adapter implements persistence port.",
      "tokens": [
        51114,
        407,
        300,
        1355,
        8149,
        22860,
        704,
        17988,
        37617,
        2436,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37962883710861206,
      "compression_ratio": 1.818652868270874,
      "no_speech_prob": 0.010137545876204967
    },
    {
      "id": 114,
      "seek": 44100,
      "start": 2738.84,
      "end": 2743.84,
      "text": " As a result, the dependency is from outside, from these adapters to the ports.",
      "tokens": [
        51314,
        1018,
        257,
        1874,
        11,
        264,
        33621,
        307,
        490,
        2380,
        11,
        490,
        613,
        23169,
        1559,
        281,
        264,
        18160,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37962883710861206,
      "compression_ratio": 1.818652868270874,
      "no_speech_prob": 0.010137545876204967
    },
    {
      "id": 115,
      "seek": 46500,
      "start": 2743.84,
      "end": 2745.84,
      "text": " And that leads, for example,",
      "tokens": [
        50364,
        400,
        300,
        6689,
        11,
        337,
        1365,
        11,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35428687930107117,
      "compression_ratio": 1.6007905006408691,
      "no_speech_prob": 0.3253520131111145
    },
    {
      "id": 116,
      "seek": 46500,
      "start": 2745.84,
      "end": 2751.84,
      "text": " so first of all, I achieve the same goal as de-layering.",
      "tokens": [
        50464,
        370,
        700,
        295,
        439,
        11,
        286,
        4584,
        264,
        912,
        3387,
        382,
        368,
        12,
        8376,
        1794,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35428687930107117,
      "compression_ratio": 1.6007905006408691,
      "no_speech_prob": 0.3253520131111145
    },
    {
      "id": 117,
      "seek": 46500,
      "start": 2751.84,
      "end": 2753.84,
      "text": " So what Eric says is,",
      "tokens": [
        50764,
        407,
        437,
        9336,
        1619,
        307,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35428687930107117,
      "compression_ratio": 1.6007905006408691,
      "no_speech_prob": 0.3253520131111145
    },
    {
      "id": 118,
      "seek": 46500,
      "start": 2753.84,
      "end": 2756.84,
      "text": " I would like to separate the logic from something else.",
      "tokens": [
        50864,
        286,
        576,
        411,
        281,
        4994,
        264,
        9952,
        490,
        746,
        1646,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35428687930107117,
      "compression_ratio": 1.6007905006408691,
      "no_speech_prob": 0.3253520131111145
    },
    {
      "id": 119,
      "seek": 46500,
      "start": 2756.84,
      "end": 2757.84,
      "text": " I can do that here too.",
      "tokens": [
        51014,
        286,
        393,
        360,
        300,
        510,
        886,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35428687930107117,
      "compression_ratio": 1.6007905006408691,
      "no_speech_prob": 0.3253520131111145
    },
    {
      "id": 120,
      "seek": 46500,
      "start": 2757.84,
      "end": 2759.84,
      "text": " Maybe even a little bit better,",
      "tokens": [
        51064,
        2704,
        754,
        257,
        707,
        857,
        1101,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35428687930107117,
      "compression_ratio": 1.6007905006408691,
      "no_speech_prob": 0.3253520131111145
    },
    {
      "id": 121,
      "seek": 46500,
      "start": 2759.84,
      "end": 2762.84,
      "text": " because I don't have this dependency into persistence.",
      "tokens": [
        51164,
        570,
        286,
        500,
        380,
        362,
        341,
        33621,
        666,
        37617,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35428687930107117,
      "compression_ratio": 1.6007905006408691,
      "no_speech_prob": 0.3253520131111145
    },
    {
      "id": 122,
      "seek": 46500,
      "start": 2762.84,
      "end": 2765.84,
      "text": " And I also have the advantage that I can test the stuff better,",
      "tokens": [
        51314,
        400,
        286,
        611,
        362,
        264,
        5002,
        300,
        286,
        393,
        1500,
        264,
        1507,
        1101,
        11,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35428687930107117,
      "compression_ratio": 1.6007905006408691,
      "no_speech_prob": 0.3253520131111145
    },
    {
      "id": 123,
      "seek": 46500,
      "start": 2765.84,
      "end": 2769.84,
      "text": " because the business logic core is free of any kind of technology.",
      "tokens": [
        51464,
        570,
        264,
        1606,
        9952,
        4965,
        307,
        1737,
        295,
        604,
        733,
        295,
        2899,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35428687930107117,
      "compression_ratio": 1.6007905006408691,
      "no_speech_prob": 0.3253520131111145
    },
    {
      "id": 124,
      "seek": 49100,
      "start": 2769.84,
      "end": 2772.84,
      "text": " So that means if I have the layering,",
      "tokens": [
        50364,
        407,
        300,
        1355,
        498,
        286,
        362,
        264,
        40754,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3394300639629364,
      "compression_ratio": 1.8104838132858276,
      "no_speech_prob": 0.12057308107614517
    },
    {
      "id": 125,
      "seek": 49100,
      "start": 2772.84,
      "end": 2777.84,
      "text": " then it is in the logic that I actually somehow depend on the persistence.",
      "tokens": [
        50514,
        550,
        309,
        307,
        294,
        264,
        9952,
        300,
        286,
        767,
        6063,
        5672,
        322,
        264,
        37617,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3394300639629364,
      "compression_ratio": 1.8104838132858276,
      "no_speech_prob": 0.12057308107614517
    },
    {
      "id": 126,
      "seek": 49100,
      "start": 2777.84,
      "end": 2780.84,
      "text": " Maybe I have to catch some exceptions that the persistence throws.",
      "tokens": [
        50764,
        2704,
        286,
        362,
        281,
        3745,
        512,
        22847,
        300,
        264,
        37617,
        19251,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3394300639629364,
      "compression_ratio": 1.8104838132858276,
      "no_speech_prob": 0.12057308107614517
    },
    {
      "id": 127,
      "seek": 49100,
      "start": 2780.84,
      "end": 2785.84,
      "text": " Here it is so that the database adapter is dependent on the business logic.",
      "tokens": [
        50914,
        1692,
        309,
        307,
        370,
        300,
        264,
        8149,
        22860,
        307,
        12334,
        322,
        264,
        1606,
        9952,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3394300639629364,
      "compression_ratio": 1.8104838132858276,
      "no_speech_prob": 0.12057308107614517
    },
    {
      "id": 128,
      "seek": 49100,
      "start": 2785.84,
      "end": 2788.84,
      "text": " It defines what to expect, so to speak,",
      "tokens": [
        51164,
        467,
        23122,
        437,
        281,
        2066,
        11,
        370,
        281,
        1710,
        11,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3394300639629364,
      "compression_ratio": 1.8104838132858276,
      "no_speech_prob": 0.12057308107614517
    },
    {
      "id": 129,
      "seek": 49100,
      "start": 2788.84,
      "end": 2790.84,
      "text": " and what the interface should look like.",
      "tokens": [
        51314,
        293,
        437,
        264,
        9226,
        820,
        574,
        411,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3394300639629364,
      "compression_ratio": 1.8104838132858276,
      "no_speech_prob": 0.12057308107614517
    },
    {
      "id": 130,
      "seek": 49100,
      "start": 2790.84,
      "end": 2793.84,
      "text": " And then the database adapter will implement that.",
      "tokens": [
        51414,
        400,
        550,
        264,
        8149,
        22860,
        486,
        4445,
        300,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3394300639629364,
      "compression_ratio": 1.8104838132858276,
      "no_speech_prob": 0.12057308107614517
    },
    {
      "id": 131,
      "seek": 49100,
      "start": 2793.84,
      "end": 2795.84,
      "text": " So that means the persistence doesn't know anything about it.",
      "tokens": [
        51564,
        407,
        300,
        1355,
        264,
        37617,
        1177,
        380,
        458,
        1340,
        466,
        309,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3394300639629364,
      "compression_ratio": 1.8104838132858276,
      "no_speech_prob": 0.12057308107614517
    },
    {
      "id": 132,
      "seek": 51700,
      "start": 2796.84,
      "end": 2799.84,
      "text": " The business logic doesn't know anything about what exactly is happening here.",
      "tokens": [
        50414,
        440,
        1606,
        9952,
        1177,
        380,
        458,
        1340,
        466,
        437,
        2293,
        307,
        2737,
        510,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35491272807121277,
      "compression_ratio": 1.7727272510528564,
      "no_speech_prob": 0.118585504591465
    },
    {
      "id": 133,
      "seek": 51700,
      "start": 2799.84,
      "end": 2801.84,
      "text": " And that leads to better testability,",
      "tokens": [
        50564,
        400,
        300,
        6689,
        281,
        1101,
        1500,
        2310,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35491272807121277,
      "compression_ratio": 1.7727272510528564,
      "no_speech_prob": 0.118585504591465
    },
    {
      "id": 134,
      "seek": 51700,
      "start": 2801.84,
      "end": 2803.84,
      "text": " because I can now replace the database adapter",
      "tokens": [
        50664,
        570,
        286,
        393,
        586,
        7406,
        264,
        8149,
        22860,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35491272807121277,
      "compression_ratio": 1.7727272510528564,
      "no_speech_prob": 0.118585504591465
    },
    {
      "id": 135,
      "seek": 51700,
      "start": 2803.84,
      "end": 2806.84,
      "text": " and all other adapters with something in the test.",
      "tokens": [
        50764,
        293,
        439,
        661,
        23169,
        1559,
        365,
        746,
        294,
        264,
        1500,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35491272807121277,
      "compression_ratio": 1.7727272510528564,
      "no_speech_prob": 0.118585504591465
    },
    {
      "id": 136,
      "seek": 51700,
      "start": 2806.84,
      "end": 2807.84,
      "text": " So I can now say to myself,",
      "tokens": [
        50914,
        407,
        286,
        393,
        586,
        584,
        281,
        2059,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35491272807121277,
      "compression_ratio": 1.7727272510528564,
      "no_speech_prob": 0.118585504591465
    },
    {
      "id": 137,
      "seek": 51700,
      "start": 2807.84,
      "end": 2810.84,
      "text": " there is something that behaves like a database,",
      "tokens": [
        50964,
        456,
        307,
        512,
        825,
        300,
        36896,
        411,
        257,
        8149,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35491272807121277,
      "compression_ratio": 1.7727272510528564,
      "no_speech_prob": 0.118585504591465
    },
    {
      "id": 138,
      "seek": 51700,
      "start": 2810.84,
      "end": 2813.84,
      "text": " or I can have something that, for example,",
      "tokens": [
        51114,
        420,
        286,
        393,
        362,
        746,
        300,
        11,
        337,
        1365,
        11,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35491272807121277,
      "compression_ratio": 1.7727272510528564,
      "no_speech_prob": 0.118585504591465
    },
    {
      "id": 139,
      "seek": 51700,
      "start": 2813.84,
      "end": 2815.84,
      "text": " asks for the notifications,",
      "tokens": [
        51264,
        8962,
        337,
        264,
        13426,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35491272807121277,
      "compression_ratio": 1.7727272510528564,
      "no_speech_prob": 0.118585504591465
    },
    {
      "id": 140,
      "seek": 51700,
      "start": 2815.84,
      "end": 2817.84,
      "text": " which would otherwise go out as e-mails.",
      "tokens": [
        51364,
        597,
        576,
        5911,
        352,
        484,
        382,
        308,
        12,
        76,
        6227,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35491272807121277,
      "compression_ratio": 1.7727272510528564,
      "no_speech_prob": 0.118585504591465
    },
    {
      "id": 141,
      "seek": 51700,
      "start": 2817.84,
      "end": 2823.84,
      "text": " That means I can test in isolation with the business logic core.",
      "tokens": [
        51464,
        663,
        1355,
        286,
        393,
        1500,
        294,
        16001,
        365,
        264,
        1606,
        9952,
        4965,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35491272807121277,
      "compression_ratio": 1.7727272510528564,
      "no_speech_prob": 0.118585504591465
    },
    {
      "id": 142,
      "seek": 54500,
      "start": 2823.84,
      "end": 2825.84,
      "text": " And I think that's also a significant advantage.",
      "tokens": [
        50364,
        400,
        286,
        519,
        300,
        311,
        611,
        257,
        4776,
        5002,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36402627825737,
      "compression_ratio": 1.5889830589294434,
      "no_speech_prob": 0.415387898683548
    },
    {
      "id": 143,
      "seek": 54500,
      "start": 2826.84,
      "end": 2828.84,
      "text": " I just did an episode with Warren Vernon.",
      "tokens": [
        50514,
        286,
        445,
        630,
        364,
        3500,
        365,
        20538,
        47516,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36402627825737,
      "compression_ratio": 1.5889830589294434,
      "no_speech_prob": 0.415387898683548
    },
    {
      "id": 144,
      "seek": 54500,
      "start": 2828.84,
      "end": 2832.84,
      "text": " Warren also wrote the book Domain Driven Design Compact.",
      "tokens": [
        50614,
        20538,
        611,
        4114,
        264,
        1446,
        16674,
        491,
        19150,
        553,
        12748,
        6620,
        578,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36402627825737,
      "compression_ratio": 1.5889830589294434,
      "no_speech_prob": 0.415387898683548
    },
    {
      "id": 145,
      "seek": 54500,
      "start": 2832.84,
      "end": 2835.84,
      "text": " And actually I had expected,",
      "tokens": [
        50814,
        400,
        767,
        286,
        632,
        5176,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36402627825737,
      "compression_ratio": 1.5889830589294434,
      "no_speech_prob": 0.415387898683548
    },
    {
      "id": 146,
      "seek": 54500,
      "start": 2835.84,
      "end": 2836.84,
      "text": " we're not talking about domain driven design,",
      "tokens": [
        50964,
        321,
        434,
        406,
        1417,
        466,
        9274,
        9555,
        1715,
        11,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36402627825737,
      "compression_ratio": 1.5889830589294434,
      "no_speech_prob": 0.415387898683548
    },
    {
      "id": 147,
      "seek": 54500,
      "start": 2836.84,
      "end": 2839.84,
      "text": " but he talked a lot about ports and adapters,",
      "tokens": [
        51014,
        457,
        415,
        2825,
        257,
        688,
        466,
        18160,
        293,
        23169,
        1559,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36402627825737,
      "compression_ratio": 1.5889830589294434,
      "no_speech_prob": 0.415387898683548
    },
    {
      "id": 148,
      "seek": 54500,
      "start": 2839.84,
      "end": 2841.84,
      "text": " or hexagonal architecture.",
      "tokens": [
        51164,
        420,
        23291,
        6709,
        304,
        9482,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36402627825737,
      "compression_ratio": 1.5889830589294434,
      "no_speech_prob": 0.415387898683548
    },
    {
      "id": 149,
      "seek": 54500,
      "start": 2841.84,
      "end": 2847.84,
      "text": " And one thing that I think was totally exciting",
      "tokens": [
        51264,
        400,
        472,
        551,
        300,
        286,
        519,
        390,
        3879,
        4670,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36402627825737,
      "compression_ratio": 1.5889830589294434,
      "no_speech_prob": 0.415387898683548
    },
    {
      "id": 150,
      "seek": 54500,
      "start": 2847.84,
      "end": 2851.84,
      "text": " was that Warren basically said,",
      "tokens": [
        51564,
        390,
        300,
        20538,
        1936,
        848,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36402627825737,
      "compression_ratio": 1.5889830589294434,
      "no_speech_prob": 0.415387898683548
    },
    {
      "id": 151,
      "seek": 57300,
      "start": 2851.84,
      "end": 2855.84,
      "text": " well, is it really that much more complicated",
      "tokens": [
        50364,
        731,
        11,
        307,
        309,
        534,
        300,
        709,
        544,
        6179,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2918584942817688,
      "compression_ratio": 1.836363673210144,
      "no_speech_prob": 0.013439096510410309
    },
    {
      "id": 152,
      "seek": 57300,
      "start": 2855.84,
      "end": 2857.84,
      "text": " to build a hexagonal architecture?",
      "tokens": [
        50564,
        281,
        1322,
        257,
        23291,
        6709,
        304,
        9482,
        30,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2918584942817688,
      "compression_ratio": 1.836363673210144,
      "no_speech_prob": 0.013439096510410309
    },
    {
      "id": 153,
      "seek": 57300,
      "start": 2857.84,
      "end": 2860.84,
      "text": " And that's actually a good point.",
      "tokens": [
        50664,
        400,
        300,
        311,
        767,
        257,
        665,
        935,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2918584942817688,
      "compression_ratio": 1.836363673210144,
      "no_speech_prob": 0.013439096510410309
    },
    {
      "id": 154,
      "seek": 57300,
      "start": 2860.84,
      "end": 2863.84,
      "text": " So layering says,",
      "tokens": [
        50814,
        407,
        40754,
        1619,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2918584942817688,
      "compression_ratio": 1.836363673210144,
      "no_speech_prob": 0.013439096510410309
    },
    {
      "id": 155,
      "seek": 57300,
      "start": 2863.84,
      "end": 2865.84,
      "text": " I separated these three things.",
      "tokens": [
        50964,
        286,
        12005,
        613,
        1045,
        721,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2918584942817688,
      "compression_ratio": 1.836363673210144,
      "no_speech_prob": 0.013439096510410309
    },
    {
      "id": 156,
      "seek": 57300,
      "start": 2865.84,
      "end": 2868.84,
      "text": " And hexagonal architecture says,",
      "tokens": [
        51064,
        400,
        23291,
        6709,
        304,
        9482,
        1619,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2918584942817688,
      "compression_ratio": 1.836363673210144,
      "no_speech_prob": 0.013439096510410309
    },
    {
      "id": 157,
      "seek": 57300,
      "start": 2868.84,
      "end": 2874.84,
      "text": " I isolated UI, logic and persistence.",
      "tokens": [
        51214,
        286,
        14621,
        15682,
        11,
        9952,
        293,
        37617,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2918584942817688,
      "compression_ratio": 1.836363673210144,
      "no_speech_prob": 0.013439096510410309
    },
    {
      "id": 158,
      "seek": 57300,
      "start": 2874.84,
      "end": 2877.84,
      "text": " And hexagonal architecture now says,",
      "tokens": [
        51514,
        400,
        23291,
        6709,
        304,
        9482,
        586,
        1619,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2918584942817688,
      "compression_ratio": 1.836363673210144,
      "no_speech_prob": 0.013439096510410309
    },
    {
      "id": 159,
      "seek": 57300,
      "start": 2877.84,
      "end": 2880.84,
      "text": " I isolated these three things.",
      "tokens": [
        51664,
        286,
        14621,
        613,
        1045,
        721,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2918584942817688,
      "compression_ratio": 1.836363673210144,
      "no_speech_prob": 0.013439096510410309
    },
    {
      "id": 160,
      "seek": 60200,
      "start": 2880.84,
      "end": 2885.84,
      "text": " And the persistence depends on the logic.",
      "tokens": [
        50364,
        400,
        264,
        37617,
        5946,
        322,
        264,
        9952,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3448052704334259,
      "compression_ratio": 1.4330708980560303,
      "no_speech_prob": 0.4312193691730499
    },
    {
      "id": 161,
      "seek": 60200,
      "start": 2897.84,
      "end": 2899.84,
      "text": " So if I'm here at layering,",
      "tokens": [
        51214,
        407,
        498,
        286,
        478,
        510,
        412,
        40754,
        11,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3448052704334259,
      "compression_ratio": 1.4330708980560303,
      "no_speech_prob": 0.4312193691730499
    },
    {
      "id": 162,
      "seek": 60200,
      "start": 2899.84,
      "end": 2902.84,
      "text": " it would be that the logic uses the persistence",
      "tokens": [
        51314,
        309,
        576,
        312,
        300,
        264,
        9952,
        4960,
        264,
        37617,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3448052704334259,
      "compression_ratio": 1.4330708980560303,
      "no_speech_prob": 0.4312193691730499
    },
    {
      "id": 163,
      "seek": 60200,
      "start": 2902.84,
      "end": 2904.84,
      "text": " and is dependent on it.",
      "tokens": [
        51464,
        293,
        307,
        12334,
        322,
        309,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3448052704334259,
      "compression_ratio": 1.4330708980560303,
      "no_speech_prob": 0.4312193691730499
    },
    {
      "id": 164,
      "seek": 60200,
      "start": 2904.84,
      "end": 2906.84,
      "text": " Here it is exactly the other way around.",
      "tokens": [
        51564,
        1692,
        309,
        307,
        2293,
        264,
        661,
        636,
        926,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3448052704334259,
      "compression_ratio": 1.4330708980560303,
      "no_speech_prob": 0.4312193691730499
    },
    {
      "id": 165,
      "seek": 62800,
      "start": 2906.84,
      "end": 2912.84,
      "text": " Here I say, the logic does not know the persistence,",
      "tokens": [
        50364,
        1692,
        286,
        584,
        11,
        264,
        9952,
        775,
        406,
        458,
        264,
        37617,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41375070810317993,
      "compression_ratio": 1.763157844543457,
      "no_speech_prob": 0.22489942610263824
    },
    {
      "id": 166,
      "seek": 62800,
      "start": 2912.84,
      "end": 2915.84,
      "text": " but on the contrary, the database adapter implements",
      "tokens": [
        50664,
        457,
        322,
        264,
        19506,
        11,
        264,
        1137,
        5509,
        405,
        22860,
        704,
        17988,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41375070810317993,
      "compression_ratio": 1.763157844543457,
      "no_speech_prob": 0.22489942610263824
    },
    {
      "id": 167,
      "seek": 62800,
      "start": 2915.84,
      "end": 2917.84,
      "text": " this interface that the core of logic provides.",
      "tokens": [
        50814,
        341,
        9226,
        300,
        264,
        4965,
        295,
        9952,
        6417,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41375070810317993,
      "compression_ratio": 1.763157844543457,
      "no_speech_prob": 0.22489942610263824
    },
    {
      "id": 168,
      "seek": 62800,
      "start": 2917.84,
      "end": 2920.84,
      "text": " In terms of the UI, it is identical anyway,",
      "tokens": [
        50914,
        682,
        2115,
        295,
        264,
        15682,
        11,
        309,
        307,
        14800,
        4033,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41375070810317993,
      "compression_ratio": 1.763157844543457,
      "no_speech_prob": 0.22489942610263824
    },
    {
      "id": 169,
      "seek": 62800,
      "start": 2920.84,
      "end": 2923.84,
      "text": " because the UI uses the logic.",
      "tokens": [
        51064,
        570,
        264,
        15682,
        4960,
        264,
        9952,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41375070810317993,
      "compression_ratio": 1.763157844543457,
      "no_speech_prob": 0.22489942610263824
    },
    {
      "id": 170,
      "seek": 62800,
      "start": 2923.84,
      "end": 2926.84,
      "text": " Here, from top to bottom, the dependencies,",
      "tokens": [
        51214,
        1692,
        11,
        490,
        1192,
        281,
        2767,
        11,
        264,
        36606,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41375070810317993,
      "compression_ratio": 1.763157844543457,
      "no_speech_prob": 0.22489942610263824
    },
    {
      "id": 171,
      "seek": 62800,
      "start": 2926.84,
      "end": 2927.84,
      "text": " that's the same here.",
      "tokens": [
        51364,
        300,
        311,
        264,
        912,
        510,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41375070810317993,
      "compression_ratio": 1.763157844543457,
      "no_speech_prob": 0.22489942610263824
    },
    {
      "id": 172,
      "seek": 62800,
      "start": 2927.84,
      "end": 2929.84,
      "text": " So that means the UI comes now somehow",
      "tokens": [
        51414,
        407,
        300,
        1355,
        264,
        15682,
        1487,
        586,
        6063,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41375070810317993,
      "compression_ratio": 1.763157844543457,
      "no_speech_prob": 0.22489942610263824
    },
    {
      "id": 173,
      "seek": 62800,
      "start": 2929.84,
      "end": 2932.84,
      "text": " and uses this port here.",
      "tokens": [
        51514,
        293,
        4960,
        341,
        2436,
        510,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41375070810317993,
      "compression_ratio": 1.763157844543457,
      "no_speech_prob": 0.22489942610263824
    },
    {
      "id": 174,
      "seek": 62800,
      "start": 2932.84,
      "end": 2934.84,
      "text": " That means the dependency file is the same.",
      "tokens": [
        51664,
        663,
        1355,
        264,
        33621,
        3991,
        307,
        264,
        912,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41375070810317993,
      "compression_ratio": 1.763157844543457,
      "no_speech_prob": 0.22489942610263824
    },
    {
      "id": 175,
      "seek": 65600,
      "start": 2934.84,
      "end": 2936.84,
      "text": " So the only thing that actually changes",
      "tokens": [
        50364,
        407,
        264,
        787,
        551,
        300,
        767,
        2962,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.353217214345932,
      "compression_ratio": 1.6074765920639038,
      "no_speech_prob": 0.023187896236777306
    },
    {
      "id": 176,
      "seek": 65600,
      "start": 2936.84,
      "end": 2939.84,
      "text": " is this other dependency file",
      "tokens": [
        50464,
        307,
        341,
        661,
        33621,
        3991,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.353217214345932,
      "compression_ratio": 1.6074765920639038,
      "no_speech_prob": 0.023187896236777306
    },
    {
      "id": 177,
      "seek": 65600,
      "start": 2939.84,
      "end": 2941.84,
      "text": " on the database adapter.",
      "tokens": [
        50614,
        322,
        264,
        1137,
        5509,
        405,
        22860,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.353217214345932,
      "compression_ratio": 1.6074765920639038,
      "no_speech_prob": 0.023187896236777306
    },
    {
      "id": 178,
      "seek": 65600,
      "start": 2941.84,
      "end": 2943.84,
      "text": " And relatively stupidly,",
      "tokens": [
        50714,
        400,
        7226,
        6631,
        356,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.353217214345932,
      "compression_ratio": 1.6074765920639038,
      "no_speech_prob": 0.023187896236777306
    },
    {
      "id": 179,
      "seek": 65600,
      "start": 2943.84,
      "end": 2947.84,
      "text": " I can achieve that by somehow defining",
      "tokens": [
        50814,
        286,
        393,
        4584,
        300,
        538,
        6063,
        17827,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.353217214345932,
      "compression_ratio": 1.6074765920639038,
      "no_speech_prob": 0.023187896236777306
    },
    {
      "id": 180,
      "seek": 65600,
      "start": 2947.84,
      "end": 2949.84,
      "text": " these interfaces in the business logic.",
      "tokens": [
        51014,
        613,
        28416,
        294,
        264,
        1606,
        9952,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.353217214345932,
      "compression_ratio": 1.6074765920639038,
      "no_speech_prob": 0.023187896236777306
    },
    {
      "id": 181,
      "seek": 65600,
      "start": 2949.84,
      "end": 2951.84,
      "text": " And yes, I have to make sure",
      "tokens": [
        51114,
        400,
        2086,
        11,
        286,
        362,
        281,
        652,
        988,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.353217214345932,
      "compression_ratio": 1.6074765920639038,
      "no_speech_prob": 0.023187896236777306
    },
    {
      "id": 182,
      "seek": 65600,
      "start": 2951.84,
      "end": 2952.84,
      "text": " that it is technology-independent.",
      "tokens": [
        51214,
        300,
        309,
        307,
        2899,
        12,
        471,
        4217,
        317,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.353217214345932,
      "compression_ratio": 1.6074765920639038,
      "no_speech_prob": 0.023187896236777306
    },
    {
      "id": 183,
      "seek": 65600,
      "start": 2952.84,
      "end": 2954.84,
      "text": " But that's what it is.",
      "tokens": [
        51264,
        583,
        300,
        311,
        437,
        309,
        307,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.353217214345932,
      "compression_ratio": 1.6074765920639038,
      "no_speech_prob": 0.023187896236777306
    },
    {
      "id": 184,
      "seek": 65600,
      "start": 2954.84,
      "end": 2956.84,
      "text": " So that means, actually, it's a point,",
      "tokens": [
        51364,
        407,
        300,
        1355,
        11,
        767,
        11,
        309,
        311,
        257,
        935,
        11,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.353217214345932,
      "compression_ratio": 1.6074765920639038,
      "no_speech_prob": 0.023187896236777306
    },
    {
      "id": 185,
      "seek": 65600,
      "start": 2956.84,
      "end": 2958.84,
      "text": " if I separate that,",
      "tokens": [
        51464,
        498,
        286,
        4994,
        300,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.353217214345932,
      "compression_ratio": 1.6074765920639038,
      "no_speech_prob": 0.023187896236777306
    },
    {
      "id": 186,
      "seek": 68000,
      "start": 2958.84,
      "end": 2963.84,
      "text": " then the big effort is no longer",
      "tokens": [
        50364,
        550,
        264,
        955,
        4630,
        307,
        572,
        2854,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35750773549079895,
      "compression_ratio": 1.655502438545227,
      "no_speech_prob": 0.739036500453949
    },
    {
      "id": 187,
      "seek": 68000,
      "start": 2963.84,
      "end": 2965.84,
      "text": " such a big difference in terms of effort",
      "tokens": [
        50614,
        1270,
        257,
        955,
        2649,
        294,
        2115,
        295,
        4630,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35750773549079895,
      "compression_ratio": 1.655502438545227,
      "no_speech_prob": 0.739036500453949
    },
    {
      "id": 188,
      "seek": 68000,
      "start": 2965.84,
      "end": 2969.84,
      "text": " between hexagonal architecture and layering.",
      "tokens": [
        50714,
        1296,
        23291,
        6709,
        304,
        9482,
        293,
        40754,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35750773549079895,
      "compression_ratio": 1.655502438545227,
      "no_speech_prob": 0.739036500453949
    },
    {
      "id": 189,
      "seek": 68000,
      "start": 2969.84,
      "end": 2973.84,
      "text": " And I thought that was a very exciting idea,",
      "tokens": [
        50914,
        400,
        286,
        1194,
        300,
        390,
        257,
        588,
        4670,
        1558,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35750773549079895,
      "compression_ratio": 1.655502438545227,
      "no_speech_prob": 0.739036500453949
    },
    {
      "id": 190,
      "seek": 68000,
      "start": 2973.84,
      "end": 2976.84,
      "text": " because hexagonal architecture",
      "tokens": [
        51114,
        570,
        23291,
        6709,
        304,
        9482,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35750773549079895,
      "compression_ratio": 1.655502438545227,
      "no_speech_prob": 0.739036500453949
    },
    {
      "id": 191,
      "seek": 68000,
      "start": 2976.84,
      "end": 2980.84,
      "text": " has a bit of a reputation for being complicated.",
      "tokens": [
        51264,
        575,
        257,
        857,
        295,
        257,
        13061,
        337,
        885,
        6179,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35750773549079895,
      "compression_ratio": 1.655502438545227,
      "no_speech_prob": 0.739036500453949
    },
    {
      "id": 192,
      "seek": 68000,
      "start": 2980.84,
      "end": 2983.84,
      "text": " And I think that's exactly this input",
      "tokens": [
        51464,
        400,
        286,
        519,
        300,
        311,
        2293,
        341,
        4846,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35750773549079895,
      "compression_ratio": 1.655502438545227,
      "no_speech_prob": 0.739036500453949
    },
    {
      "id": 193,
      "seek": 68000,
      "start": 2983.84,
      "end": 2984.84,
      "text": " that's interesting to me.",
      "tokens": [
        51614,
        300,
        311,
        1880,
        281,
        385,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35750773549079895,
      "compression_ratio": 1.655502438545227,
      "no_speech_prob": 0.739036500453949
    },
    {
      "id": 194,
      "seek": 68000,
      "start": 2984.84,
      "end": 2987.84,
      "text": " And as I said, the alternative to that",
      "tokens": [
        51664,
        400,
        382,
        286,
        848,
        11,
        264,
        8535,
        281,
        300,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35750773549079895,
      "compression_ratio": 1.655502438545227,
      "no_speech_prob": 0.739036500453949
    },
    {
      "id": 195,
      "seek": 70900,
      "start": 2987.84,
      "end": 2989.84,
      "text": " is something like a transaction script,",
      "tokens": [
        50364,
        307,
        746,
        411,
        257,
        14425,
        5755,
        11,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31066015362739563,
      "compression_ratio": 1.616740107536316,
      "no_speech_prob": 0.06249554455280304
    },
    {
      "id": 196,
      "seek": 70900,
      "start": 2989.84,
      "end": 2991.84,
      "text": " where I don't do this layering,",
      "tokens": [
        50464,
        689,
        286,
        500,
        380,
        360,
        341,
        40754,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31066015362739563,
      "compression_ratio": 1.616740107536316,
      "no_speech_prob": 0.06249554455280304
    },
    {
      "id": 197,
      "seek": 70900,
      "start": 2991.84,
      "end": 2995.84,
      "text": " where I no longer isolate the business logic",
      "tokens": [
        50564,
        689,
        286,
        572,
        2854,
        25660,
        264,
        1606,
        9952,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31066015362739563,
      "compression_ratio": 1.616740107536316,
      "no_speech_prob": 0.06249554455280304
    },
    {
      "id": 198,
      "seek": 70900,
      "start": 2995.84,
      "end": 2996.84,
      "text": " that much,",
      "tokens": [
        50764,
        300,
        709,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31066015362739563,
      "compression_ratio": 1.616740107536316,
      "no_speech_prob": 0.06249554455280304
    },
    {
      "id": 199,
      "seek": 70900,
      "start": 2996.84,
      "end": 2998.84,
      "text": " simply because there is too little of it",
      "tokens": [
        50814,
        2935,
        570,
        456,
        307,
        886,
        707,
        295,
        309,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31066015362739563,
      "compression_ratio": 1.616740107536316,
      "no_speech_prob": 0.06249554455280304
    },
    {
      "id": 200,
      "seek": 70900,
      "start": 2998.84,
      "end": 2999.84,
      "text": " or none at all.",
      "tokens": [
        50914,
        420,
        6022,
        412,
        439,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31066015362739563,
      "compression_ratio": 1.616740107536316,
      "no_speech_prob": 0.06249554455280304
    },
    {
      "id": 201,
      "seek": 70900,
      "start": 2999.84,
      "end": 3002.84,
      "text": " So I should maybe add one more thing.",
      "tokens": [
        50964,
        407,
        286,
        820,
        1310,
        909,
        472,
        544,
        551,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31066015362739563,
      "compression_ratio": 1.616740107536316,
      "no_speech_prob": 0.06249554455280304
    },
    {
      "id": 202,
      "seek": 70900,
      "start": 3005.84,
      "end": 3007.84,
      "text": " If I am forced to build a system",
      "tokens": [
        51264,
        759,
        286,
        669,
        7579,
        281,
        1322,
        257,
        1185,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31066015362739563,
      "compression_ratio": 1.616740107536316,
      "no_speech_prob": 0.06249554455280304
    },
    {
      "id": 203,
      "seek": 70900,
      "start": 3007.84,
      "end": 3010.84,
      "text": " as a developer that has no business logic,",
      "tokens": [
        51364,
        382,
        257,
        10754,
        300,
        575,
        572,
        1606,
        9952,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31066015362739563,
      "compression_ratio": 1.616740107536316,
      "no_speech_prob": 0.06249554455280304
    },
    {
      "id": 204,
      "seek": 70900,
      "start": 3010.84,
      "end": 3012.84,
      "text": " that means that I don't generate",
      "tokens": [
        51514,
        300,
        1355,
        300,
        286,
        500,
        380,
        8460,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31066015362739563,
      "compression_ratio": 1.616740107536316,
      "no_speech_prob": 0.06249554455280304
    },
    {
      "id": 205,
      "seek": 70900,
      "start": 3012.84,
      "end": 3014.84,
      "text": " a lot of value either, I would say.",
      "tokens": [
        51614,
        257,
        688,
        295,
        2158,
        2139,
        11,
        286,
        576,
        584,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31066015362739563,
      "compression_ratio": 1.616740107536316,
      "no_speech_prob": 0.06249554455280304
    },
    {
      "id": 206,
      "seek": 73600,
      "start": 3014.84,
      "end": 3018.84,
      "text": " And it may be that I actually build a system",
      "tokens": [
        50364,
        400,
        309,
        815,
        312,
        300,
        286,
        767,
        1322,
        257,
        1185,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25529640913009644,
      "compression_ratio": 1.6103286743164062,
      "no_speech_prob": 0.024436257779598236
    },
    {
      "id": 207,
      "seek": 73600,
      "start": 3018.84,
      "end": 3023.84,
      "text": " that doesn't really solve the business logic problem.",
      "tokens": [
        50564,
        300,
        1177,
        380,
        534,
        5039,
        264,
        1606,
        9952,
        1154,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25529640913009644,
      "compression_ratio": 1.6103286743164062,
      "no_speech_prob": 0.024436257779598236
    },
    {
      "id": 208,
      "seek": 73600,
      "start": 3023.84,
      "end": 3026.84,
      "text": " So the customer comes and says,",
      "tokens": [
        50814,
        407,
        264,
        5474,
        1487,
        293,
        1619,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25529640913009644,
      "compression_ratio": 1.6103286743164062,
      "no_speech_prob": 0.024436257779598236
    },
    {
      "id": 209,
      "seek": 73600,
      "start": 3026.84,
      "end": 3028.84,
      "text": " I would like to see the following data.",
      "tokens": [
        50964,
        286,
        576,
        411,
        281,
        536,
        264,
        3480,
        1412,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25529640913009644,
      "compression_ratio": 1.6103286743164062,
      "no_speech_prob": 0.024436257779598236
    },
    {
      "id": 210,
      "seek": 73600,
      "start": 3028.84,
      "end": 3030.84,
      "text": " Okay, is that business logic?",
      "tokens": [
        51064,
        1033,
        11,
        307,
        300,
        1606,
        9952,
        30,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25529640913009644,
      "compression_ratio": 1.6103286743164062,
      "no_speech_prob": 0.024436257779598236
    },
    {
      "id": 211,
      "seek": 73600,
      "start": 3030.84,
      "end": 3032.84,
      "text": " No, I just want to display the data.",
      "tokens": [
        51164,
        883,
        11,
        286,
        445,
        528,
        281,
        4674,
        264,
        1412,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25529640913009644,
      "compression_ratio": 1.6103286743164062,
      "no_speech_prob": 0.024436257779598236
    },
    {
      "id": 212,
      "seek": 73600,
      "start": 3034.84,
      "end": 3038.84,
      "text": " But that's probably not what",
      "tokens": [
        51364,
        583,
        300,
        311,
        1391,
        406,
        437,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25529640913009644,
      "compression_ratio": 1.6103286743164062,
      "no_speech_prob": 0.024436257779598236
    },
    {
      "id": 213,
      "seek": 73600,
      "start": 3038.84,
      "end": 3040.84,
      "text": " this person really wants.",
      "tokens": [
        51564,
        341,
        954,
        534,
        2738,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25529640913009644,
      "compression_ratio": 1.6103286743164062,
      "no_speech_prob": 0.024436257779598236
    },
    {
      "id": 214,
      "seek": 73600,
      "start": 3040.84,
      "end": 3041.84,
      "text": " What she really wants is,",
      "tokens": [
        51664,
        708,
        750,
        534,
        2738,
        307,
        11,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25529640913009644,
      "compression_ratio": 1.6103286743164062,
      "no_speech_prob": 0.024436257779598236
    },
    {
      "id": 215,
      "seek": 73600,
      "start": 3041.84,
      "end": 3043.84,
      "text": " she wants to decide now,",
      "tokens": [
        51714,
        750,
        2738,
        281,
        4536,
        586,
        11,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25529640913009644,
      "compression_ratio": 1.6103286743164062,
      "no_speech_prob": 0.024436257779598236
    },
    {
      "id": 216,
      "seek": 76500,
      "start": 3043.84,
      "end": 3045.84,
      "text": " when I look at the customer,",
      "tokens": [
        50364,
        562,
        286,
        574,
        412,
        264,
        5474,
        11,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33690738677978516,
      "compression_ratio": 1.7689530849456787,
      "no_speech_prob": 0.0024205404333770275
    },
    {
      "id": 217,
      "seek": 76500,
      "start": 3045.84,
      "end": 3048.84,
      "text": " I can decide whether it's a good or a bad customer.",
      "tokens": [
        50464,
        286,
        393,
        4536,
        1968,
        309,
        311,
        257,
        665,
        420,
        257,
        1578,
        5474,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33690738677978516,
      "compression_ratio": 1.7689530849456787,
      "no_speech_prob": 0.0024205404333770275
    },
    {
      "id": 218,
      "seek": 76500,
      "start": 3048.84,
      "end": 3050.84,
      "text": " But then it's actually the case that",
      "tokens": [
        50614,
        583,
        550,
        309,
        311,
        767,
        264,
        1389,
        300,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33690738677978516,
      "compression_ratio": 1.7689530849456787,
      "no_speech_prob": 0.0024205404333770275
    },
    {
      "id": 219,
      "seek": 76500,
      "start": 3050.84,
      "end": 3051.84,
      "text": " there is a business logic behind it,",
      "tokens": [
        50714,
        456,
        307,
        257,
        1606,
        9952,
        2261,
        309,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33690738677978516,
      "compression_ratio": 1.7689530849456787,
      "no_speech_prob": 0.0024205404333770275
    },
    {
      "id": 220,
      "seek": 76500,
      "start": 3051.84,
      "end": 3053.84,
      "text": " which I can now try to implement.",
      "tokens": [
        50764,
        597,
        286,
        393,
        586,
        853,
        281,
        4445,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33690738677978516,
      "compression_ratio": 1.7689530849456787,
      "no_speech_prob": 0.0024205404333770275
    },
    {
      "id": 221,
      "seek": 76500,
      "start": 3053.84,
      "end": 3054.84,
      "text": " So I can now say,",
      "tokens": [
        50864,
        407,
        286,
        393,
        586,
        584,
        11,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33690738677978516,
      "compression_ratio": 1.7689530849456787,
      "no_speech_prob": 0.0024205404333770275
    },
    {
      "id": 222,
      "seek": 76500,
      "start": 3054.84,
      "end": 3056.84,
      "text": " hey, according to our policy,",
      "tokens": [
        50914,
        4177,
        11,
        4650,
        281,
        527,
        3897,
        11,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33690738677978516,
      "compression_ratio": 1.7689530849456787,
      "no_speech_prob": 0.0024205404333770275
    },
    {
      "id": 223,
      "seek": 76500,
      "start": 3056.84,
      "end": 3057.84,
      "text": " this is a good customer,",
      "tokens": [
        51014,
        341,
        307,
        257,
        665,
        5474,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33690738677978516,
      "compression_ratio": 1.7689530849456787,
      "no_speech_prob": 0.0024205404333770275
    },
    {
      "id": 224,
      "seek": 76500,
      "start": 3057.84,
      "end": 3059.84,
      "text": " because he ordered a lot of things",
      "tokens": [
        51064,
        570,
        415,
        8866,
        257,
        688,
        295,
        721,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33690738677978516,
      "compression_ratio": 1.7689530849456787,
      "no_speech_prob": 0.0024205404333770275
    },
    {
      "id": 225,
      "seek": 76500,
      "start": 3059.84,
      "end": 3061.84,
      "text": " and returned little.",
      "tokens": [
        51164,
        293,
        8752,
        707,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33690738677978516,
      "compression_ratio": 1.7689530849456787,
      "no_speech_prob": 0.0024205404333770275
    },
    {
      "id": 226,
      "seek": 76500,
      "start": 3061.84,
      "end": 3062.84,
      "text": " And that means,",
      "tokens": [
        51264,
        400,
        300,
        1355,
        11,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33690738677978516,
      "compression_ratio": 1.7689530849456787,
      "no_speech_prob": 0.0024205404333770275
    },
    {
      "id": 227,
      "seek": 76500,
      "start": 3062.84,
      "end": 3066.84,
      "text": " if I build a system that only transports data from A to B",
      "tokens": [
        51314,
        498,
        286,
        1322,
        257,
        1185,
        300,
        787,
        5495,
        82,
        1412,
        490,
        316,
        281,
        363,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33690738677978516,
      "compression_ratio": 1.7689530849456787,
      "no_speech_prob": 0.0024205404333770275
    },
    {
      "id": 228,
      "seek": 76500,
      "start": 3066.84,
      "end": 3068.84,
      "text": " or only displays data,",
      "tokens": [
        51514,
        420,
        787,
        20119,
        1412,
        11,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33690738677978516,
      "compression_ratio": 1.7689530849456787,
      "no_speech_prob": 0.0024205404333770275
    },
    {
      "id": 229,
      "seek": 76500,
      "start": 3068.84,
      "end": 3070.84,
      "text": " this may be a misleading chance",
      "tokens": [
        51614,
        341,
        815,
        312,
        257,
        3346,
        306,
        8166,
        2931,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33690738677978516,
      "compression_ratio": 1.7689530849456787,
      "no_speech_prob": 0.0024205404333770275
    },
    {
      "id": 230,
      "seek": 76500,
      "start": 3070.84,
      "end": 3072.84,
      "text": " to build a system with more business logic.",
      "tokens": [
        51714,
        281,
        1322,
        257,
        1185,
        365,
        544,
        1606,
        9952,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33690738677978516,
      "compression_ratio": 1.7689530849456787,
      "no_speech_prob": 0.0024205404333770275
    },
    {
      "id": 231,
      "seek": 79400,
      "start": 3072.84,
      "end": 3073.84,
      "text": " That means,",
      "tokens": [
        50364,
        663,
        1355,
        11,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36863502860069275,
      "compression_ratio": 1.4025157690048218,
      "no_speech_prob": 0.010965140536427498
    },
    {
      "id": 232,
      "seek": 79400,
      "start": 3077.84,
      "end": 3079.84,
      "text": " this topic with the transaction script",
      "tokens": [
        50614,
        341,
        4829,
        365,
        264,
        14425,
        5755,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36863502860069275,
      "compression_ratio": 1.4025157690048218,
      "no_speech_prob": 0.010965140536427498
    },
    {
      "id": 233,
      "seek": 79400,
      "start": 3079.84,
      "end": 3081.84,
      "text": " is the right solution,",
      "tokens": [
        50714,
        307,
        264,
        558,
        3827,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36863502860069275,
      "compression_ratio": 1.4025157690048218,
      "no_speech_prob": 0.010965140536427498
    },
    {
      "id": 234,
      "seek": 79400,
      "start": 3081.84,
      "end": 3083.84,
      "text": " if I have little logic.",
      "tokens": [
        50814,
        498,
        286,
        362,
        707,
        9952,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36863502860069275,
      "compression_ratio": 1.4025157690048218,
      "no_speech_prob": 0.010965140536427498
    },
    {
      "id": 235,
      "seek": 79400,
      "start": 3083.84,
      "end": 3084.84,
      "text": " But be careful,",
      "tokens": [
        50914,
        583,
        312,
        5026,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36863502860069275,
      "compression_ratio": 1.4025157690048218,
      "no_speech_prob": 0.010965140536427498
    },
    {
      "id": 236,
      "seek": 79400,
      "start": 3084.84,
      "end": 3086.84,
      "text": " maybe it's just that",
      "tokens": [
        50964,
        1310,
        309,
        311,
        445,
        300,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36863502860069275,
      "compression_ratio": 1.4025157690048218,
      "no_speech_prob": 0.010965140536427498
    },
    {
      "id": 237,
      "seek": 79400,
      "start": 3086.84,
      "end": 3089.84,
      "text": " the logic has been hidden from me, so to speak.",
      "tokens": [
        51064,
        264,
        9952,
        575,
        668,
        7633,
        490,
        385,
        11,
        370,
        281,
        1710,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36863502860069275,
      "compression_ratio": 1.4025157690048218,
      "no_speech_prob": 0.010965140536427498
    },
    {
      "id": 238,
      "seek": 79400,
      "start": 3091.84,
      "end": 3093.84,
      "text": " In summary,",
      "tokens": [
        51314,
        682,
        12691,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36863502860069275,
      "compression_ratio": 1.4025157690048218,
      "no_speech_prob": 0.010965140536427498
    },
    {
      "id": 239,
      "seek": 79400,
      "start": 3093.84,
      "end": 3097.84,
      "text": " I tried to paint this again.",
      "tokens": [
        51414,
        286,
        3031,
        281,
        4225,
        341,
        797,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36863502860069275,
      "compression_ratio": 1.4025157690048218,
      "no_speech_prob": 0.010965140536427498
    },
    {
      "id": 240,
      "seek": 81900,
      "start": 3098.84,
      "end": 3104.84,
      "text": " And to get an overview of all the things,",
      "tokens": [
        50414,
        400,
        281,
        483,
        364,
        12492,
        295,
        439,
        264,
        721,
        11,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4553709328174591,
      "compression_ratio": 1.6034482717514038,
      "no_speech_prob": 0.10188747942447662
    },
    {
      "id": 241,
      "seek": 81900,
      "start": 3104.84,
      "end": 3106.84,
      "text": " from left to right,",
      "tokens": [
        50714,
        490,
        1411,
        281,
        558,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4553709328174591,
      "compression_ratio": 1.6034482717514038,
      "no_speech_prob": 0.10188747942447662
    },
    {
      "id": 242,
      "seek": 81900,
      "start": 3106.84,
      "end": 3109.84,
      "text": " there are more and more details.",
      "tokens": [
        50814,
        456,
        366,
        544,
        293,
        544,
        4365,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4553709328174591,
      "compression_ratio": 1.6034482717514038,
      "no_speech_prob": 0.10188747942447662
    },
    {
      "id": 243,
      "seek": 81900,
      "start": 3110.84,
      "end": 3113.84,
      "text": " And that was something I said last time.",
      "tokens": [
        51014,
        400,
        300,
        390,
        746,
        286,
        848,
        1036,
        565,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4553709328174591,
      "compression_ratio": 1.6034482717514038,
      "no_speech_prob": 0.10188747942447662
    },
    {
      "id": 244,
      "seek": 81900,
      "start": 3113.84,
      "end": 3115.84,
      "text": " So the idea here is not",
      "tokens": [
        51164,
        407,
        264,
        1558,
        510,
        307,
        406,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4553709328174591,
      "compression_ratio": 1.6034482717514038,
      "no_speech_prob": 0.10188747942447662
    },
    {
      "id": 245,
      "seek": 81900,
      "start": 3115.84,
      "end": 3117.84,
      "text": " that this is a waterfall,",
      "tokens": [
        51264,
        300,
        341,
        307,
        257,
        27848,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4553709328174591,
      "compression_ratio": 1.6034482717514038,
      "no_speech_prob": 0.10188747942447662
    },
    {
      "id": 246,
      "seek": 81900,
      "start": 3117.84,
      "end": 3119.84,
      "text": " where I walk through once,",
      "tokens": [
        51364,
        689,
        286,
        1792,
        807,
        1564,
        11,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4553709328174591,
      "compression_ratio": 1.6034482717514038,
      "no_speech_prob": 0.10188747942447662
    },
    {
      "id": 247,
      "seek": 81900,
      "start": 3119.84,
      "end": 3121.84,
      "text": " but I work on different details.",
      "tokens": [
        51464,
        457,
        286,
        589,
        322,
        819,
        4365,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4553709328174591,
      "compression_ratio": 1.6034482717514038,
      "no_speech_prob": 0.10188747942447662
    },
    {
      "id": 248,
      "seek": 81900,
      "start": 3121.84,
      "end": 3123.84,
      "text": " And the rough granule that I have",
      "tokens": [
        51564,
        400,
        264,
        5903,
        290,
        4257,
        425,
        68,
        300,
        286,
        362,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4553709328174591,
      "compression_ratio": 1.6034482717514038,
      "no_speech_prob": 0.10188747942447662
    },
    {
      "id": 249,
      "seek": 84500,
      "start": 3123.84,
      "end": 3127.84,
      "text": " is Big Picture Event Storming.",
      "tokens": [
        50364,
        307,
        5429,
        35730,
        13222,
        745,
        284,
        2810,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3735119104385376,
      "compression_ratio": 1.517543911933899,
      "no_speech_prob": 0.15214693546295166
    },
    {
      "id": 250,
      "seek": 84500,
      "start": 3128.84,
      "end": 3131.84,
      "text": " I get an overview of the entire system,",
      "tokens": [
        50614,
        286,
        483,
        364,
        12492,
        295,
        264,
        2302,
        1185,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3735119104385376,
      "compression_ratio": 1.517543911933899,
      "no_speech_prob": 0.15214693546295166
    },
    {
      "id": 251,
      "seek": 84500,
      "start": 3131.84,
      "end": 3133.84,
      "text": " the events that run here.",
      "tokens": [
        50764,
        264,
        3931,
        300,
        1190,
        510,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3735119104385376,
      "compression_ratio": 1.517543911933899,
      "no_speech_prob": 0.15214693546295166
    },
    {
      "id": 252,
      "seek": 84500,
      "start": 3133.84,
      "end": 3137.84,
      "text": " And I can then decide about it, for example,",
      "tokens": [
        50864,
        400,
        286,
        393,
        550,
        4536,
        466,
        309,
        11,
        337,
        1365,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3735119104385376,
      "compression_ratio": 1.517543911933899,
      "no_speech_prob": 0.15214693546295166
    },
    {
      "id": 253,
      "seek": 84500,
      "start": 3137.84,
      "end": 3140.84,
      "text": " or a next step would be to say,",
      "tokens": [
        51064,
        420,
        257,
        958,
        1823,
        576,
        312,
        281,
        584,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3735119104385376,
      "compression_ratio": 1.517543911933899,
      "no_speech_prob": 0.15214693546295166
    },
    {
      "id": 254,
      "seek": 84500,
      "start": 3140.84,
      "end": 3142.84,
      "text": " what is my core domain?",
      "tokens": [
        51214,
        437,
        307,
        452,
        4965,
        9274,
        30,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3735119104385376,
      "compression_ratio": 1.517543911933899,
      "no_speech_prob": 0.15214693546295166
    },
    {
      "id": 255,
      "seek": 84500,
      "start": 3142.84,
      "end": 3144.84,
      "text": " So what is it all about?",
      "tokens": [
        51314,
        407,
        437,
        307,
        309,
        439,
        466,
        30,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3735119104385376,
      "compression_ratio": 1.517543911933899,
      "no_speech_prob": 0.15214693546295166
    },
    {
      "id": 256,
      "seek": 84500,
      "start": 3144.84,
      "end": 3146.84,
      "text": " I can use strategic design",
      "tokens": [
        51414,
        286,
        393,
        764,
        10924,
        1715,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3735119104385376,
      "compression_ratio": 1.517543911933899,
      "no_speech_prob": 0.15214693546295166
    },
    {
      "id": 257,
      "seek": 84500,
      "start": 3146.84,
      "end": 3148.84,
      "text": " as an alternative to team topologies.",
      "tokens": [
        51514,
        382,
        364,
        8535,
        281,
        1469,
        1192,
        6204,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3735119104385376,
      "compression_ratio": 1.517543911933899,
      "no_speech_prob": 0.15214693546295166
    },
    {
      "id": 258,
      "seek": 84500,
      "start": 3148.84,
      "end": 3150.84,
      "text": " I say which teams are responsible",
      "tokens": [
        51614,
        286,
        584,
        597,
        5491,
        366,
        6250,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3735119104385376,
      "compression_ratio": 1.517543911933899,
      "no_speech_prob": 0.15214693546295166
    },
    {
      "id": 259,
      "seek": 84500,
      "start": 3150.84,
      "end": 3152.84,
      "text": " and who does what where.",
      "tokens": [
        51714,
        293,
        567,
        775,
        437,
        689,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3735119104385376,
      "compression_ratio": 1.517543911933899,
      "no_speech_prob": 0.15214693546295166
    },
    {
      "id": 260,
      "seek": 87400,
      "start": 3153.84,
      "end": 3155.84,
      "text": " That's something...",
      "tokens": [
        50414,
        663,
        311,
        746,
        485,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538177013397217,
      "compression_ratio": 1.592307686805725,
      "no_speech_prob": 0.012954979203641415
    },
    {
      "id": 261,
      "seek": 87400,
      "start": 3157.84,
      "end": 3159.84,
      "text": " I don't know if it's more detailed.",
      "tokens": [
        50614,
        286,
        500,
        380,
        458,
        498,
        309,
        311,
        544,
        9942,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538177013397217,
      "compression_ratio": 1.592307686805725,
      "no_speech_prob": 0.012954979203641415
    },
    {
      "id": 262,
      "seek": 87400,
      "start": 3159.84,
      "end": 3161.84,
      "text": " So here I'm actually talking about",
      "tokens": [
        50714,
        407,
        510,
        286,
        478,
        767,
        1417,
        466,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538177013397217,
      "compression_ratio": 1.592307686805725,
      "no_speech_prob": 0.012954979203641415
    },
    {
      "id": 263,
      "seek": 87400,
      "start": 3161.84,
      "end": 3163.84,
      "text": " the business logic of Big Picture Event Storming.",
      "tokens": [
        50814,
        264,
        1606,
        9952,
        295,
        5429,
        35730,
        13222,
        20494,
        278,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538177013397217,
      "compression_ratio": 1.592307686805725,
      "no_speech_prob": 0.012954979203641415
    },
    {
      "id": 264,
      "seek": 87400,
      "start": 3163.84,
      "end": 3164.84,
      "text": " And here I say,",
      "tokens": [
        50914,
        400,
        510,
        286,
        584,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538177013397217,
      "compression_ratio": 1.592307686805725,
      "no_speech_prob": 0.012954979203641415
    },
    {
      "id": 265,
      "seek": 87400,
      "start": 3164.84,
      "end": 3166.84,
      "text": " for something like strategic design",
      "tokens": [
        50964,
        337,
        746,
        411,
        10924,
        1715,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538177013397217,
      "compression_ratio": 1.592307686805725,
      "no_speech_prob": 0.012954979203641415
    },
    {
      "id": 266,
      "seek": 87400,
      "start": 3166.84,
      "end": 3168.84,
      "text": " or team topologies or core domain,",
      "tokens": [
        51064,
        420,
        1469,
        1192,
        6204,
        420,
        4965,
        9274,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538177013397217,
      "compression_ratio": 1.592307686805725,
      "no_speech_prob": 0.012954979203641415
    },
    {
      "id": 267,
      "seek": 87400,
      "start": 3168.84,
      "end": 3170.84,
      "text": " I actually say how I want to divide it",
      "tokens": [
        51164,
        286,
        767,
        584,
        577,
        286,
        528,
        281,
        9845,
        309,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538177013397217,
      "compression_ratio": 1.592307686805725,
      "no_speech_prob": 0.012954979203641415
    },
    {
      "id": 268,
      "seek": 87400,
      "start": 3170.84,
      "end": 3172.84,
      "text": " on the level of teams.",
      "tokens": [
        51264,
        322,
        264,
        1496,
        295,
        5491,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538177013397217,
      "compression_ratio": 1.592307686805725,
      "no_speech_prob": 0.012954979203641415
    },
    {
      "id": 269,
      "seek": 87400,
      "start": 3172.84,
      "end": 3174.84,
      "text": " And they then work on",
      "tokens": [
        51364,
        400,
        436,
        550,
        589,
        322,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538177013397217,
      "compression_ratio": 1.592307686805725,
      "no_speech_prob": 0.012954979203641415
    },
    {
      "id": 270,
      "seek": 87400,
      "start": 3174.84,
      "end": 3176.84,
      "text": " one or more built-in contexts.",
      "tokens": [
        51464,
        472,
        420,
        544,
        3094,
        12,
        259,
        30628,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538177013397217,
      "compression_ratio": 1.592307686805725,
      "no_speech_prob": 0.012954979203641415
    },
    {
      "id": 271,
      "seek": 87400,
      "start": 3176.84,
      "end": 3179.84,
      "text": " And then there are these very specific techniques",
      "tokens": [
        51564,
        400,
        550,
        456,
        366,
        613,
        588,
        2685,
        7512,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538177013397217,
      "compression_ratio": 1.592307686805725,
      "no_speech_prob": 0.012954979203641415
    },
    {
      "id": 272,
      "seek": 87400,
      "start": 3179.84,
      "end": 3181.84,
      "text": " that we talked about,",
      "tokens": [
        51714,
        300,
        321,
        2825,
        466,
        11,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538177013397217,
      "compression_ratio": 1.592307686805725,
      "no_speech_prob": 0.012954979203641415
    },
    {
      "id": 273,
      "seek": 90300,
      "start": 3181.84,
      "end": 3182.84,
      "text": " so tactical design,",
      "tokens": [
        50364,
        370,
        26323,
        1715,
        11,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397325575351715,
      "compression_ratio": 1.6576576232910156,
      "no_speech_prob": 0.051719170063734055
    },
    {
      "id": 274,
      "seek": 90300,
      "start": 3182.84,
      "end": 3185.84,
      "text": " to actually implement a built-in context",
      "tokens": [
        50414,
        281,
        767,
        4445,
        257,
        3094,
        12,
        259,
        4319,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397325575351715,
      "compression_ratio": 1.6576576232910156,
      "no_speech_prob": 0.051719170063734055
    },
    {
      "id": 275,
      "seek": 90300,
      "start": 3185.84,
      "end": 3188.84,
      "text": " and to say how it is implemented.",
      "tokens": [
        50564,
        293,
        281,
        584,
        577,
        309,
        307,
        12270,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397325575351715,
      "compression_ratio": 1.6576576232910156,
      "no_speech_prob": 0.051719170063734055
    },
    {
      "id": 276,
      "seek": 90300,
      "start": 3188.84,
      "end": 3190.84,
      "text": " Design level event storming,",
      "tokens": [
        50714,
        12748,
        1496,
        2280,
        7679,
        278,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397325575351715,
      "compression_ratio": 1.6576576232910156,
      "no_speech_prob": 0.051719170063734055
    },
    {
      "id": 277,
      "seek": 90300,
      "start": 3190.84,
      "end": 3193.84,
      "text": " to understand what the requirements are on this level.",
      "tokens": [
        50814,
        281,
        1223,
        437,
        264,
        7728,
        366,
        322,
        341,
        1496,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397325575351715,
      "compression_ratio": 1.6576576232910156,
      "no_speech_prob": 0.051719170063734055
    },
    {
      "id": 278,
      "seek": 90300,
      "start": 3193.84,
      "end": 3197.84,
      "text": " I can use something like event sourcing or CQRS,",
      "tokens": [
        50964,
        286,
        393,
        764,
        746,
        411,
        2280,
        11006,
        2175,
        420,
        383,
        48,
        43580,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397325575351715,
      "compression_ratio": 1.6576576232910156,
      "no_speech_prob": 0.051719170063734055
    },
    {
      "id": 279,
      "seek": 90300,
      "start": 3197.84,
      "end": 3200.84,
      "text": " if I have the necessary prerequisites for it,",
      "tokens": [
        51164,
        498,
        286,
        362,
        264,
        4818,
        38333,
        15398,
        3324,
        337,
        309,
        11,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397325575351715,
      "compression_ratio": 1.6576576232910156,
      "no_speech_prob": 0.051719170063734055
    },
    {
      "id": 280,
      "seek": 90300,
      "start": 3200.84,
      "end": 3204.84,
      "text": " in the sense that I generate an advantage",
      "tokens": [
        51314,
        294,
        264,
        2020,
        300,
        286,
        8460,
        364,
        5002,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397325575351715,
      "compression_ratio": 1.6576576232910156,
      "no_speech_prob": 0.051719170063734055
    },
    {
      "id": 281,
      "seek": 90300,
      "start": 3204.84,
      "end": 3210.84,
      "text": " if I store the events in the case of event sourcing,",
      "tokens": [
        51514,
        498,
        286,
        3531,
        264,
        3931,
        294,
        264,
        1389,
        295,
        2280,
        11006,
        2175,
        11,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397325575351715,
      "compression_ratio": 1.6576576232910156,
      "no_speech_prob": 0.051719170063734055
    },
    {
      "id": 282,
      "seek": 93200,
      "start": 3210.84,
      "end": 3212.84,
      "text": " or in the case of CQRS,",
      "tokens": [
        50364,
        420,
        294,
        264,
        1389,
        295,
        383,
        48,
        43580,
        11,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29986587166786194,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.005873772315680981
    },
    {
      "id": 283,
      "seek": 93200,
      "start": 3212.84,
      "end": 3220.84,
      "text": " if I can actually separate the writing and the reading part from each other.",
      "tokens": [
        50464,
        498,
        286,
        393,
        767,
        4994,
        264,
        3579,
        293,
        264,
        3760,
        644,
        490,
        1184,
        661,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29986587166786194,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.005873772315680981
    },
    {
      "id": 284,
      "seek": 93200,
      "start": 3220.84,
      "end": 3224.84,
      "text": " And then there are layers or hexagonal architecture.",
      "tokens": [
        50864,
        400,
        550,
        456,
        366,
        7914,
        420,
        23291,
        6709,
        304,
        9482,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29986587166786194,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.005873772315680981
    },
    {
      "id": 285,
      "seek": 93200,
      "start": 3226.84,
      "end": 3228.84,
      "text": " I have now also put a question mark behind it.",
      "tokens": [
        51164,
        286,
        362,
        586,
        611,
        829,
        257,
        1168,
        1491,
        2261,
        309,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29986587166786194,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.005873772315680981
    },
    {
      "id": 286,
      "seek": 93200,
      "start": 3228.84,
      "end": 3230.84,
      "text": " With event sourcing and CQRS,",
      "tokens": [
        51264,
        2022,
        2280,
        11006,
        2175,
        293,
        383,
        48,
        43580,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29986587166786194,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.005873772315680981
    },
    {
      "id": 287,
      "seek": 93200,
      "start": 3230.84,
      "end": 3231.84,
      "text": " I would somehow say,",
      "tokens": [
        51364,
        286,
        576,
        6063,
        584,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29986587166786194,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.005873772315680981
    },
    {
      "id": 288,
      "seek": 93200,
      "start": 3231.84,
      "end": 3234.84,
      "text": " okay, I'll use that when it fits, so to speak.",
      "tokens": [
        51414,
        1392,
        11,
        286,
        603,
        764,
        300,
        562,
        309,
        9001,
        11,
        370,
        281,
        1710,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29986587166786194,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.005873772315680981
    },
    {
      "id": 289,
      "seek": 93200,
      "start": 3234.84,
      "end": 3236.84,
      "text": " With layers or hexagonal,",
      "tokens": [
        51564,
        2022,
        7914,
        420,
        23291,
        6709,
        304,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29986587166786194,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.005873772315680981
    },
    {
      "id": 290,
      "seek": 93200,
      "start": 3236.84,
      "end": 3238.84,
      "text": " I would say one of the two patterns",
      "tokens": [
        51664,
        286,
        576,
        584,
        472,
        295,
        264,
        732,
        8294,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29986587166786194,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.005873772315680981
    },
    {
      "id": 291,
      "seek": 96000,
      "start": 3238.84,
      "end": 3240.84,
      "text": " I should somehow apply,",
      "tokens": [
        50364,
        286,
        820,
        6063,
        3079,
        11,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5212177038192749,
      "compression_ratio": 1.517241358757019,
      "no_speech_prob": 0.10010677576065063
    },
    {
      "id": 292,
      "seek": 96000,
      "start": 3240.84,
      "end": 3246.84,
      "text": " because otherwise I would have mixed up the logic and the other things.",
      "tokens": [
        50464,
        570,
        5911,
        286,
        576,
        362,
        7467,
        493,
        264,
        9952,
        293,
        264,
        661,
        721,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5212177038192749,
      "compression_ratio": 1.517241358757019,
      "no_speech_prob": 0.10010677576065063
    },
    {
      "id": 293,
      "seek": 96000,
      "start": 3246.84,
      "end": 3247.84,
      "text": " Jude Ruth writes,",
      "tokens": [
        50764,
        36521,
        23544,
        13657,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5212177038192749,
      "compression_ratio": 1.517241358757019,
      "no_speech_prob": 0.10010677576065063
    },
    {
      "id": 294,
      "seek": 96000,
      "start": 3247.84,
      "end": 3248.84,
      "text": " Jude Ruth writes,",
      "tokens": [
        50814,
        36521,
        23544,
        13657,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5212177038192749,
      "compression_ratio": 1.517241358757019,
      "no_speech_prob": 0.10010677576065063
    },
    {
      "id": 295,
      "seek": 96000,
      "start": 3248.84,
      "end": 3249.84,
      "text": " additionally,",
      "tokens": [
        50864,
        43181,
        11,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5212177038192749,
      "compression_ratio": 1.517241358757019,
      "no_speech_prob": 0.10010677576065063
    },
    {
      "id": 296,
      "seek": 96000,
      "start": 3249.84,
      "end": 3251.84,
      "text": " warns of the naming of ports and adapters",
      "tokens": [
        50914,
        12286,
        82,
        295,
        264,
        25290,
        295,
        18160,
        293,
        23169,
        1559,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5212177038192749,
      "compression_ratio": 1.517241358757019,
      "no_speech_prob": 0.10010677576065063
    },
    {
      "id": 297,
      "seek": 96000,
      "start": 3251.84,
      "end": 3257.84,
      "text": " instead of hexagonal architecture.",
      "tokens": [
        51014,
        2602,
        295,
        23291,
        6709,
        304,
        9482,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5212177038192749,
      "compression_ratio": 1.517241358757019,
      "no_speech_prob": 0.10010677576065063
    },
    {
      "id": 298,
      "seek": 96000,
      "start": 3261.84,
      "end": 3264.84,
      "text": " Good point, I don't remember that at all.",
      "tokens": [
        51514,
        2205,
        935,
        11,
        286,
        500,
        380,
        1604,
        300,
        412,
        439,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5212177038192749,
      "compression_ratio": 1.517241358757019,
      "no_speech_prob": 0.10010677576065063
    },
    {
      "id": 299,
      "seek": 98600,
      "start": 3264.84,
      "end": 3265.84,
      "text": " And in fact,",
      "tokens": [
        50364,
        400,
        294,
        1186,
        11,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35785412788391113,
      "compression_ratio": 1.8971192836761475,
      "no_speech_prob": 0.042208585888147354
    },
    {
      "id": 300,
      "seek": 98600,
      "start": 3265.84,
      "end": 3268.84,
      "text": " this is perhaps also a point that is a bit unfortunate here.",
      "tokens": [
        50414,
        341,
        307,
        4317,
        611,
        257,
        935,
        300,
        307,
        257,
        857,
        17843,
        510,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35785412788391113,
      "compression_ratio": 1.8971192836761475,
      "no_speech_prob": 0.042208585888147354
    },
    {
      "id": 301,
      "seek": 98600,
      "start": 3268.84,
      "end": 3271.84,
      "text": " So the hexagonal architecture is called hexagonal",
      "tokens": [
        50564,
        407,
        264,
        23291,
        6709,
        304,
        9482,
        307,
        1219,
        23291,
        6709,
        304,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35785412788391113,
      "compression_ratio": 1.8971192836761475,
      "no_speech_prob": 0.042208585888147354
    },
    {
      "id": 302,
      "seek": 98600,
      "start": 3271.84,
      "end": 3273.84,
      "text": " because the business logic core",
      "tokens": [
        50714,
        570,
        264,
        1606,
        9952,
        4965,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35785412788391113,
      "compression_ratio": 1.8971192836761475,
      "no_speech_prob": 0.042208585888147354
    },
    {
      "id": 303,
      "seek": 98600,
      "start": 3273.84,
      "end": 3274.84,
      "text": " and the things around it, so to speak,",
      "tokens": [
        50814,
        293,
        264,
        721,
        926,
        309,
        11,
        370,
        281,
        1710,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35785412788391113,
      "compression_ratio": 1.8971192836761475,
      "no_speech_prob": 0.042208585888147354
    },
    {
      "id": 304,
      "seek": 98600,
      "start": 3274.84,
      "end": 3277.84,
      "text": " are randomly painted as hexagons.",
      "tokens": [
        50864,
        366,
        16979,
        11797,
        382,
        23291,
        559,
        892,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35785412788391113,
      "compression_ratio": 1.8971192836761475,
      "no_speech_prob": 0.042208585888147354
    },
    {
      "id": 305,
      "seek": 98600,
      "start": 3277.84,
      "end": 3278.84,
      "text": " And it is actually the case",
      "tokens": [
        51014,
        400,
        309,
        307,
        767,
        264,
        1389,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35785412788391113,
      "compression_ratio": 1.8971192836761475,
      "no_speech_prob": 0.042208585888147354
    },
    {
      "id": 306,
      "seek": 98600,
      "start": 3278.84,
      "end": 3281.84,
      "text": " that ports and adapters are the better term,",
      "tokens": [
        51064,
        300,
        18160,
        293,
        23169,
        1559,
        366,
        264,
        1101,
        1433,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35785412788391113,
      "compression_ratio": 1.8971192836761475,
      "no_speech_prob": 0.042208585888147354
    },
    {
      "id": 307,
      "seek": 98600,
      "start": 3281.84,
      "end": 3285.84,
      "text": " because I think that expresses better what it is actually about,",
      "tokens": [
        51214,
        570,
        286,
        519,
        300,
        39204,
        1101,
        437,
        309,
        307,
        767,
        466,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35785412788391113,
      "compression_ratio": 1.8971192836761475,
      "no_speech_prob": 0.042208585888147354
    },
    {
      "id": 308,
      "seek": 98600,
      "start": 3285.84,
      "end": 3291.84,
      "text": " namely to expose these ports from the business logic core",
      "tokens": [
        51414,
        20926,
        281,
        19219,
        613,
        18160,
        490,
        264,
        1606,
        9952,
        4965,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35785412788391113,
      "compression_ratio": 1.8971192836761475,
      "no_speech_prob": 0.042208585888147354
    },
    {
      "id": 309,
      "seek": 98600,
      "start": 3291.84,
      "end": 3293.84,
      "text": " and then to have adapters around it,",
      "tokens": [
        51714,
        293,
        550,
        281,
        362,
        23169,
        1559,
        926,
        309,
        11,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35785412788391113,
      "compression_ratio": 1.8971192836761475,
      "no_speech_prob": 0.042208585888147354
    },
    {
      "id": 310,
      "seek": 101500,
      "start": 3293.84,
      "end": 3296.84,
      "text": " which somehow implement that accordingly.",
      "tokens": [
        50364,
        597,
        6063,
        4445,
        300,
        19717,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44703209400177,
      "compression_ratio": 1.4553191661834717,
      "no_speech_prob": 0.027434665709733963
    },
    {
      "id": 311,
      "seek": 101500,
      "start": 3296.84,
      "end": 3297.84,
      "text": " Good.",
      "tokens": [
        50514,
        2205,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44703209400177,
      "compression_ratio": 1.4553191661834717,
      "no_speech_prob": 0.027434665709733963
    },
    {
      "id": 312,
      "seek": 101500,
      "start": 3297.84,
      "end": 3301.84,
      "text": " Then I think we're actually ready.",
      "tokens": [
        50564,
        1396,
        286,
        519,
        321,
        434,
        767,
        1919,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44703209400177,
      "compression_ratio": 1.4553191661834717,
      "no_speech_prob": 0.027434665709733963
    },
    {
      "id": 313,
      "seek": 101500,
      "start": 3303.84,
      "end": 3305.84,
      "text": " A note,",
      "tokens": [
        50864,
        316,
        3637,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44703209400177,
      "compression_ratio": 1.4553191661834717,
      "no_speech_prob": 0.027434665709733963
    },
    {
      "id": 314,
      "seek": 101500,
      "start": 3305.84,
      "end": 3307.84,
      "text": " next week,",
      "tokens": [
        50964,
        958,
        1243,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44703209400177,
      "compression_ratio": 1.4553191661834717,
      "no_speech_prob": 0.027434665709733963
    },
    {
      "id": 315,
      "seek": 101500,
      "start": 3307.84,
      "end": 3308.84,
      "text": " as I said,",
      "tokens": [
        51064,
        382,
        286,
        848,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44703209400177,
      "compression_ratio": 1.4553191661834717,
      "no_speech_prob": 0.027434665709733963
    },
    {
      "id": 316,
      "seek": 101500,
      "start": 3308.84,
      "end": 3310.84,
      "text": " there is this training round on the topic",
      "tokens": [
        51114,
        456,
        307,
        341,
        3097,
        3098,
        322,
        264,
        4829,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44703209400177,
      "compression_ratio": 1.4553191661834717,
      "no_speech_prob": 0.027434665709733963
    },
    {
      "id": 317,
      "seek": 101500,
      "start": 3310.84,
      "end": 3312.84,
      "text": " Domain-Driven Design Salutes Legacy.",
      "tokens": [
        51214,
        16674,
        491,
        12,
        35,
        470,
        553,
        12748,
        5996,
        1819,
        42838,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44703209400177,
      "compression_ratio": 1.4553191661834717,
      "no_speech_prob": 0.027434665709733963
    },
    {
      "id": 318,
      "seek": 101500,
      "start": 3312.84,
      "end": 3315.84,
      "text": " That's on the afternoon of the 16th and 12th.",
      "tokens": [
        51314,
        663,
        311,
        322,
        264,
        6499,
        295,
        264,
        3165,
        392,
        293,
        2272,
        392,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44703209400177,
      "compression_ratio": 1.4553191661834717,
      "no_speech_prob": 0.027434665709733963
    },
    {
      "id": 319,
      "seek": 101500,
      "start": 3315.84,
      "end": 3316.84,
      "text": " You are welcome to join.",
      "tokens": [
        51464,
        509,
        366,
        2928,
        281,
        3917,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44703209400177,
      "compression_ratio": 1.4553191661834717,
      "no_speech_prob": 0.027434665709733963
    },
    {
      "id": 320,
      "seek": 101500,
      "start": 3316.84,
      "end": 3318.84,
      "text": " I think it's also reasonably moderate",
      "tokens": [
        51514,
        286,
        519,
        309,
        311,
        611,
        23551,
        18174,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44703209400177,
      "compression_ratio": 1.4553191661834717,
      "no_speech_prob": 0.027434665709733963
    },
    {
      "id": 321,
      "seek": 101500,
      "start": 3318.84,
      "end": 3320.84,
      "text": " and it's a good opportunity to talk about",
      "tokens": [
        51614,
        293,
        309,
        311,
        257,
        665,
        2650,
        281,
        751,
        466,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44703209400177,
      "compression_ratio": 1.4553191661834717,
      "no_speech_prob": 0.027434665709733963
    },
    {
      "id": 322,
      "seek": 104200,
      "start": 3320.84,
      "end": 3323.84,
      "text": " how to build Legacy with DDD.",
      "tokens": [
        50364,
        577,
        281,
        1322,
        42838,
        365,
        413,
        20818,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028169572353363,
      "compression_ratio": 1.4043477773666382,
      "no_speech_prob": 0.20912940800189972
    },
    {
      "id": 323,
      "seek": 104200,
      "start": 3323.84,
      "end": 3325.84,
      "text": " The other thing is,",
      "tokens": [
        50514,
        440,
        661,
        551,
        307,
        11,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028169572353363,
      "compression_ratio": 1.4043477773666382,
      "no_speech_prob": 0.20912940800189972
    },
    {
      "id": 324,
      "seek": 104200,
      "start": 3325.84,
      "end": 3326.84,
      "text": " next week,",
      "tokens": [
        50614,
        958,
        1243,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028169572353363,
      "compression_ratio": 1.4043477773666382,
      "no_speech_prob": 0.20912940800189972
    },
    {
      "id": 325,
      "seek": 104200,
      "start": 3326.84,
      "end": 3330.84,
      "text": " Ralf will talk to Lars RÃ¶wekamp",
      "tokens": [
        50664,
        497,
        1678,
        486,
        751,
        281,
        41563,
        497,
        973,
        826,
        74,
        1215,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028169572353363,
      "compression_ratio": 1.4043477773666382,
      "no_speech_prob": 0.20912940800189972
    },
    {
      "id": 326,
      "seek": 104200,
      "start": 3330.84,
      "end": 3331.84,
      "text": " about the topic",
      "tokens": [
        50864,
        466,
        264,
        4829,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028169572353363,
      "compression_ratio": 1.4043477773666382,
      "no_speech_prob": 0.20912940800189972
    },
    {
      "id": 327,
      "seek": 104200,
      "start": 3331.84,
      "end": 3334.84,
      "text": " Generative AI meets Software Architecture.",
      "tokens": [
        50914,
        15409,
        1166,
        7318,
        13961,
        27428,
        43049,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028169572353363,
      "compression_ratio": 1.4043477773666382,
      "no_speech_prob": 0.20912940800189972
    },
    {
      "id": 328,
      "seek": 104200,
      "start": 3334.84,
      "end": 3337.84,
      "text": " And that will be at 3 p.m.",
      "tokens": [
        51064,
        400,
        300,
        486,
        312,
        412,
        805,
        280,
        13,
        76,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028169572353363,
      "compression_ratio": 1.4043477773666382,
      "no_speech_prob": 0.20912940800189972
    },
    {
      "id": 329,
      "seek": 104200,
      "start": 3337.84,
      "end": 3338.84,
      "text": " So Friday at 3 p.m.",
      "tokens": [
        51214,
        407,
        6984,
        412,
        805,
        280,
        13,
        76,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028169572353363,
      "compression_ratio": 1.4043477773666382,
      "no_speech_prob": 0.20912940800189972
    },
    {
      "id": 330,
      "seek": 104200,
      "start": 3338.84,
      "end": 3341.84,
      "text": " That's a little later than usual.",
      "tokens": [
        51264,
        663,
        311,
        257,
        707,
        1780,
        813,
        7713,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028169572353363,
      "compression_ratio": 1.4043477773666382,
      "no_speech_prob": 0.20912940800189972
    },
    {
      "id": 331,
      "seek": 104200,
      "start": 3341.84,
      "end": 3344.84,
      "text": " And maybe you want to switch on again.",
      "tokens": [
        51414,
        400,
        1310,
        291,
        528,
        281,
        3679,
        322,
        797,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028169572353363,
      "compression_ratio": 1.4043477773666382,
      "no_speech_prob": 0.20912940800189972
    },
    {
      "id": 332,
      "seek": 104200,
      "start": 3344.84,
      "end": 3347.84,
      "text": " Otherwise, thank you very much for your attention.",
      "tokens": [
        51564,
        10328,
        11,
        1309,
        291,
        588,
        709,
        337,
        428,
        3202,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028169572353363,
      "compression_ratio": 1.4043477773666382,
      "no_speech_prob": 0.20912940800189972
    },
    {
      "id": 333,
      "seek": 106900,
      "start": 3347.84,
      "end": 3350.84,
      "text": " And thank you very much for the questions and for the comments.",
      "tokens": [
        50364,
        400,
        1309,
        291,
        588,
        709,
        337,
        264,
        1651,
        293,
        337,
        264,
        3053,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3553640842437744,
      "compression_ratio": 1.362069010734558,
      "no_speech_prob": 0.08816879987716675
    },
    {
      "id": 334,
      "seek": 106900,
      "start": 3350.84,
      "end": 3352.84,
      "text": " And then I would say,",
      "tokens": [
        50514,
        400,
        550,
        286,
        576,
        584,
        11,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3553640842437744,
      "compression_ratio": 1.362069010734558,
      "no_speech_prob": 0.08816879987716675
    },
    {
      "id": 335,
      "seek": 106900,
      "start": 3352.84,
      "end": 3356.84,
      "text": " I wish you a pleasant and nice weekend.",
      "tokens": [
        50614,
        286,
        3172,
        291,
        257,
        16232,
        293,
        1481,
        6711,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3553640842437744,
      "compression_ratio": 1.362069010734558,
      "no_speech_prob": 0.08816879987716675
    },
    {
      "id": 336,
      "seek": 106900,
      "start": 3356.84,
      "end": 3357.84,
      "text": " Until then.",
      "tokens": [
        50814,
        9088,
        550,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3553640842437744,
      "compression_ratio": 1.362069010734558,
      "no_speech_prob": 0.08816879987716675
    },
    {
      "id": 337,
      "seek": 106900,
      "start": 3357.84,
      "end": 3358.84,
      "text": " Thank you very much.",
      "tokens": [
        50864,
        1044,
        291,
        588,
        709,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3553640842437744,
      "compression_ratio": 1.362069010734558,
      "no_speech_prob": 0.08816879987716675
    }
  ],
  "language": "english"
}