{
  "text": "Today's topic is Green Software Development with Aydin. Nice to have you here. Before we get started, a few more notes. One thing, there are still places at my Architecture Kickstart. That's a bit close to my heart because it's an event that I think is somehow very interesting. In four weeks, each four hours, you will have the most important topics from the area of Software Architecture, Building Context, Strategic Domain-Driven Design, Legacy Systems and how to achieve qualities. And the whole thing with very few slides, actually no slides at all and very interactive. It starts on November 14th. That means if you still feel like registering, I would be happy. But now actually to the main topic. Aydin, nice to have you here, as I said. Would you like to briefly say something about who you are and what you do? Yes, of course. First of all, thank you for the invitation. My name is Aydin. Aydin Mir-Mohammadin. I am the result of a German-Iranian love. With the unbeatable advantage, if you know how to write me, there is only one Google meeting. And that's exactly the challenge. I am a software entrepreneur. I am the founder and managing director of Bluehands, a small software company here in the south, in Karlsruhe. With about 22 people in the projects. And I am community-driven. Everything I learn, everything I have learned, comes from somewhere in the community, from conferences and so on. That's why I also call myself a community enthusiast. That's my background. And what I'm working on right now, in addition to my daily job in software, in management, is green software. Sustainability in IT. Exactly. And I think that brings us directly to the topic. So it's about green software development. What is that anyway? Are my slides visible right now? Not yet, but I'll fix that now. I can do it with or without a slide. Now the slides are there, sorry. So here again, if anyone wants to ping me or over LinkedIn. We're actually talking about this figure. That's 4% of global emissions caused by our sector, i.e. the ITK area, the entire sector. These are figures from 2020. The total emissions caused by our sector are currently massively increasing, exploding. We have about 8% of electricity consumption in Europe. It goes on. And that's actually the background of what it's all about. Namely, these massive, rising emissions that we ask for in software development, I would say, to reduce. So at least to keep, but actually also to reduce. And just to clarify, I brought a picture with me. This is a data center by Microsoft, an Azure data center in Dublin. And these are just huge things. And Microsoft builds such a data center worldwide every three days. That was 23, 24, 25, 26, if we do a little less. And Microsoft is number two. So Amazon is even more. And all the other data centers. So we have massive, rising things everywhere. And that's always an issue. And it's true that software doesn't actually have emissions. So the emissions are generated on the computer, on the servers, on the end devices. But the software is at the beginning of the chain. And it's about how we can make our contribution within our profession. Exactly. So in fact, two parallel, similar questions have arisen. One is about the formula. The question is, do all our efforts towards green software play a role at all, if you see that old nuclear power plants are being reanimated because of AI? I think that's this thing in Philipsburg, where there was this plan to reanimate it again, where there was the nuclear pain in the late 70s. And even if it's being rebuilt, it's not just a drop on the hot stone. And question two, it depends on YouTube, has already asked, does the use of AI increase the tendency? I think these are two related questions. So once the question, does it help us at all if we do AI? And then AI somehow leads to this thing getting worse. So that this share is getting worse. So it always gets worse. So, as I said, it's exploding. And AI is also part of the software development. So it's not a law that these LLMs consume such gigantic amounts of energy and resources. It works differently. We also have the small models. So that's not a law of nature. That's the way it is. And yes, we also have crypto mining. We have a lot of cat pictures on the net. So TikTok and so on, you can question everything. But that's no use. So that's always, so to speak, I can, this has such a feeling of helplessness. And in fact, it's not like that. So these 4 percent, AI is not really in there yet. So that's increasing. And AI is not really there yet. So we do have this massive expansion. But these three, these LLMs, Tata and Business. That's not AI yet. And overall, the IT sector is responsible for making it less. And if we have to do something with AI, we do it with AI. If we have to do something in B2B, we do it in B2B. And if we are in B2C, we do it in B2C. So all areas are then. But it's always about software. And I think a little bit from our previous conversation, I also remember that you said that this is the area that we can influence immediately. And I think that's an important aspect. And I think there is also an association in it, when you say green software developer, green software, that you have a lot of attention to code and code optimization. So also in the demarcation, for example, to green IT, where we say a focus on hardware, that hardware is designed more efficiently or refurbished and so on. But actually it's all the same. So when you say green IT, green coding, green software, green software development, green software design, these are all keywords that all start at the same time. Namely, the beginning of the chain are requirements that come from the software. And the software itself, as I said, has no mission, but is a computer. And the question is, how do we actually operate our software? How do we operate the AI? And how do we just do everything? So in the end, it's about producing software and then operating software. And we have an awful lot of options. And we haven't even touched on the requirements yet. What do you want to have? But I think if you take the focus away from grinding and optimizing, I think you already understand why both AI and our normal profession, be it architecture or something like that, play a role. So in the end, it's just a cross-sectional topic. That's how I feel, where it's just about increasing efficiency. And so, how should I say, you can now somehow say, so I think that's what you're saying, you can now say the requirements in the direction of AI, that you want to have something like that, you can hardly ignore them now. But we can try to make it more efficient. And then it's just more of a spur that something is still happening. There is also a movement. It's not that people are not interested in it. But it's also expensive. Now another question. I always find the questions from the chat very exciting. It's a bit surprising for me. I don't know if you'll answer it right away. Is open source tend to be the greener software? I think it's about the business model. Not about the code. First of all, not. No. I think I'll have to pick it up for a moment. I'll pick up what's going on. If we just look at the sources of emissions, then it is so that we are on one, so you can just divide it, 30, 50 percent or something, of the emissions, of the total emissions of the software, they have already arisen. Because you provide hardware, because you have built hardware, you have produced cables for the networks, the switches, the computers, the whole thing, cooling. And on the other hand, we have another 50, 70 percent of emissions that arise from the fact that I run the computer. The role that is now here, even if I am open source, I would just take the open source as a question. It actually has to do with why I run software at all. What is the background? And if you now have these two sources in mind and say, okay, I want to reduce the total emissions now, then action fields arise. And these action fields, you can divide them like this. Clever people have come up with ideas to categorize it that way. You talk about hardware and energy efficiency, I'll get to that in a moment. It's also about data efficiency and about this CO2 intensity, which is totally exciting. Every single one of these steps has a massive need for optimization. There are a lot of experts here and experts in the stream project, they don't go straight to it. But when I, for example, the hardware efficiency, it's about using a maximum amount of hardware. That means as much software as possible on a hardware point. In German, server consolidation and life extension. So if I take a hardware and instead of four, I do five or six, so from four to six, I actually halve the bound emissions. If my open source software is so fluffy that if I, let's take Nextcloud, in contrast to Microsoft Office 365, if Nextcloud in each of its versions makes sure that it still works with the old hardware, then it's greener than when new versions come out and the hardware has to deliver more power. That doesn't necessarily depend on open source, but on what's in there. And yes, for example, LibreOffice, OpenOffice is more economical than Microsoft Office, because a lot of business models in a Microsoft Office are also advertising and tracking. Then it does performance or some features that aren't in there. So you can evaluate, I wouldn't want to make it partial. But regardless of that, Nextcloud or Office 365, we're talking about server consolidation or maximum server optimization. And it doesn't help at all if I take a server and run Nextcloud on it and the server gets bored. Because what I have to do is I have to pump up as much as possible. And if I now have a software that is commercial and closed source and it's containerized and it can be totally packed, then it's greener again than a software that's there. So I would say it's not necessarily whether it's open source or not, but how do I run the software? And if I can do this server consolidation now, by doing Kubernetes, for example, instead of bare metal, an application, then I haven't won at all. So I think this picture shows how many emissions are reduced per application, when I pack that up. And my experience shows a lot. The servers are not exhausted. Exactly what you said in the previous interview, these hot standby servers, which, by definition, are not exhausted. We'll get to that again. So we normally don't have an outage. And then there's the fact that we're doing hot standby again. And maybe one more thing for this efficiency issue. We play everything in the same order to get an understanding there too. If I turn on a computer, if I turn on a server, then it consumes energy. That means it runs, but actually it doesn't do anything. Or it does and doesn't do anything. As you wish. That's just blind performance. And this idle gap, I have to distribute it to a lot of applications. And if you come up with codes now, then you might think, okay, if I can now, if my server, if my CPU performance is somewhere here in the area and I then reduce that by shipped programming, then that's great. But actually it doesn't matter for this 100 watts that I used. Exactly, so briefly, maybe the graphics say if you turn on the computer, the server already consumes 100 watts. At 50 percent, 180 watts and at 100 percent, 200 watts. So that means between 50 and 100 percent are 20 watts. And it already consumes 100 watts when it is even switched on, which means that I actually want to run the thing at full load. And what you're saying now is a nice try if I optimize 5 or 10 percent utilization, i.e. from 10 to 5 percent. I actually want to load the thing on another level. Exactly, and for that I have to add more applications. And there is a rumor that Google alarms go off when the server utilization is below 98 percent. I don't know if that's true. But it's a rumor. And there again, so if I take the open source again, the question, so yes, maybe an open source is more efficiently programmed. Some open source tool. But maybe then it doesn't matter. So that's why what is an exciting thing is that this data is also efficient. Sorry, maybe briefly on that point. What you just called Google, what you mentioned now as a question and we were just discussing the hot standbys. So if I'm in a data center now, then I have computers that are not overloaded and just run because they are hot standbys. That would be the question, shouldn't I just go to the cloud? So in the cloud I already have someone who takes care of it professionally, to use as few servers as possible. There is serverless. That's also a concept that's only good for load time and so on and so on. So the cloud, so I would say yes. Cloud in the sense of platform as a service. So when I say I do cloud in the sense of infrastructure as a service, that means I actually run my VMs that I have on-prem on cloud, then I have an advantage because usually the power usage effectiveness of the data centers are better than mine, so Microsoft and AWS and so on. They are all somewhere roughly 1.1, 1.2. So the second comma point differs with them and there is always a 1 in front of it. And if I go to a normal data center, there can also be a 2 in front of it. So that's much more efficient, much better. But if I still reserve my CPU cores and my RAM, then I actually haven't really gained much from that point of view, except for the PoE. But if I use this hardware efficiency and energy efficiency at the moment by doing platform as a service, serverless, all these app services, AWS doesn't sound too good, but if you take functions like Manage Kubernetes and so on, then the operation already ensures that it is massively packed. And that is unbeatable. But it also works on-prem. So it's not like that. But most of the time you don't do it. Most of the time the on-prem data centers are simply deployed in front of you and the applications run in front of you. That's the other thing that also came up in the past. I used to work for a company called VMware and somehow got to know what their model is. And that's basically what you're explaining right now. So you just throw out servers, consolidate through virtualization, you just win money. You can just calculate that. So that we actually tell this story for a longer time. Just because you want to reduce costs. So the nice thing about green software is that it is a climate-friendly resource-saving software that is actually always cheaper in operation. So the efficiency just makes euros. That's great. That means, if I have a green software, I usually work with cheap software. The new thing with us in IT, costs are not the driver. What we have in software development as a driver are features. That we develop business models, that we advance the system, generate benefits. And if costs are higher, then they are higher. Until at some point they are no longer bearable and then a consolidation happens again. But actually, it's more like we're going to another level. Exactly. I would like to take the data efficiency with me again and also throw in this open source question. Because at the moment the blue angel is ... It depends. On YouTube, there is a DIN norm for something like that. It quoted Environment Management Systems in 14001. You say there is a blue angel for software. That seems to be something similar. It's not a norm, it's a seal. So we also have a norm. I would like to address both. First of all, about the seal. The blue angel is from the Environment Agency. There is an environmental seal in Germany and worldwide. And there is also one for software, so it just came out. And what the blue angel does for software is that it specifies and requires transparency. That's the most important thing. It doesn't say that you have to be energy efficient, it just says that you have to document and show for all scenarios of use that exist. Plus user autonomy. There is open source in the game. That means you don't have a vendor log. You can get your data out of there. Updates have to be made secure and tracking-free. And the data, the data is quite a hit in the CO2. Because we're talking here, it's actually not the amount of data, but bandwidth latency. Because the cables, the glass fibers, they're all under power. The switches are under power, they're all running. So it doesn't matter what we modulate in. But if what we're transmitting doesn't fit in, we have to do it again and again. So we're talking a lot about availability here. And it's about reducing availability. And actually, we have a lot of business models on the Internet or in our world that are based on advertising and tracking. So if my business model is not based on advertising and tracking, then I have a lot less data. In general. Sometimes that sucks. To the other question about the norm. The blue arrow is a seal. There are also seals regarding websites, where you can optimize websites. I can recommend CleanerWeb, they do that. I can open the website. You're talking about the Green Web Foundation, I think. I have the link. So CleanerWeb. These are colleagues from Munich. So they help with the optimization. They also have a seal. And the Green Web Foundation, they take care of the topic like web, HTTP, websites and such protocols. They also have a framework, a tool, CO2JS, where I can measure that. And here you can create a correlation between data transmission and CO2 emissions. So that's a correlation. You don't have much more to measure, but it works quite well. So here's another seal. And then there's the Green Software Foundation. There's the STI, the Software Carbon Intensity. We can go back to that. This is an ISO standard. And that determines how I can measure the emissions of software. And to be complete, I would like to show that. Because that's the question that always comes up. I'll put the links in the description of the podcast and the video. I have a graphic here for those who only hear that. The Software Carbon Intensity is a number that describes the CO2 emissions of software. And what you do is you take the energy that the software uses, that is, the power consumption, multiply it with the emission factor of the power grid, that is, the Grid Carbon Intensity, the CO2 intensity of the power grid, and add the binding emissions, i.e. the hardware emissions. And that gives me an overall amount of CO2. And to evaluate that, similar to a blue angel, I can make a functional unit for it. So I can say per order process, per logged in user, per something, per usage scenario, what you have there. And then I get a number. And that's maybe an average number. If I want to, I can make it more detailed. And that's relatively easy to measure and relatively easy to document. And a lot of people, me and all other people, when we produce software, that we publish this software Carbon Intensity. Live, for example. Question 2 from Eddie Penz, he asked if you can describe the R again in more detail. I think you have that right now. Is the hardware, the software per request or per order? Oh, you can define that. And if I now, that's what the blue angel wants to do, that software may become comparable at some point. So that's more likely to be possible in the consumer area. Difficult, but definitely transparency. And if I have transparency, then I can also make decisions. I don't have transparency anymore. Okay, that means, so I assume now, correct me, that I somehow sit down and see how much energy I use for, you said order processes now, then I multiply that with the CO2 intensity. There was this electricity map, which you mentioned before. Then I take, I look at how many servers are involved in it. And then I say, this system consumes or produces so and so much CO2. And then I divide that by the number of orders that go through it. And then I get out what an order costs, so to speak. And if you want to look consumer-oriented, for example, then I can say, okay, what does a minute of Zoom cost in terms of CO2? And what does a minute of Jitsi cost? And what does a minute of Teams cost, for example? Okay. Then you can just, so that would be such a functional one, video per second. Exactly. Perhaps the Gromio on YouTube asked which tools you would recommend to measure the individual efficiency metrics on your own hardware or in the cloud. What you already said is that somehow the data that goes in and out is a good indicator. I found it exciting. What else? Yes, I would like to briefly pick up first to see how you can measure it. So how can you, so how can you, I'll say estimate and how can you measure it? Estimating is actually what is mostly done, especially when you're in the cloud, because you can't connect a measuring device to a server. This is the so-called Etsy, invented by Etsy, Cloud Jewels. And here I also show a picture. So what I have, so a cloud or a computer always consists of compute, storage, network and memory, so memory. These are, so to speak, the four core components of a cloud, no matter what is put on top of it. And I can count these individual core components. So I can, I know how many CPU hours, so how many core hours I have. I know how many gigabytes per hour I store somewhere. I know how many megabytes per second, network and so on. So I can count it all, I'll say. And for each of these things we have an emission factor. There are a lot of hardworking people who have put it together. The colleagues from Sourceworks have done a gigantic job. So I then have compute hours with the emission factor, multiply it with the energy efficiency, with the power usage effectiveness, multiply it with, then I have an energy, then I take the energy and then calculate the CO2 by looking at how much, what the grid intensity is and then I get it. So, and we then reduce the measurement problem actually by looking at how many compute hours I had. And the nice thing about cloud and everywhere, computing centers and so on, when it's a bit managed, well, it's on the account. So you put it in my account, so Azure puts it in my account. It's a bit complicated, because the CPU utilization, for example, is not in it. I could still catch up, but good enough. And then I can sort it out. There is a tool, the thing is called Cloud Carbon Footprint. I'll show it again here. Cloud Carbon Footprint is open source, is on GitHub, was mainly made by Sourceworks. And that also works for on-prem. And you can do that. If you want to measure correctly, especially for blue-hanged, there are the Green Coding Solutions in Berlin, the ARNAS. And they have the so-called Green Matrix tools. There are a lot of them. So, the CECD, they have a lot of tools. And, where is it? I don't know, I can't find it right now. But they have a tool called Green Soft Matrix. And that measures my software based on the actual energy consumption that I get from the CPU via RAPL. RAPL is an interface, I assume, which is also used for laptops or something like that. Exactly, as a server, that's a specification. I think it's also a chip, where the energy consumption of all components that are on such a mine is measured. That's how you can measure it. So, I think that's the question, how can I measure it? So, I can measure it and I can download it. And with that, we actually have everything behind us. If it's okay for you, I could ask a new topic, which I think results from a question. This is from Marco Wesselmann. He asked, what about small-scale emissions or power consumption, which occurs, for example, through computing time with JavaScript in the browser? Should apps rather do without something like that? I don't think it's really relevant. First of all, you have to see it in its dimension. So, if I have a web application and a server is running, I have a back-end somewhere, there are a few servers running, then data is being transferred. So, the typical Angular model. There is a database, there is a back-end server, a few services, and then I have front-end. The question is, do I do server-side generated or client-side generated applications? In the overall system, the back-end is the deciding factor. And on the end device, we have the data transfer. I guess it's probably similar. And then I have the end device. And now I'm talking about how many emissions I have on the end device. And there it is actually the monitor that is the topic. Or runtime, because the laptop doesn't do anything. And then I'm talking about micro-optimization again. And if I can do my database queries better, maybe I can cache them, then I get more out of it. But that's not a free ride, because it's all a matter of scale. So, if I have applications now, especially websites or web applications that have an incredibly high scale, then it is of course very efficient when I, for example, reduce the amount of data transfer. So maybe I make my JSON smarter, make my bundle smarter, maybe I don't have to get everything and so on. So there's a lot going on. Which might even mean that you look even better with an intelligent back-end. Exactly, could be even worse, yes. Then HappyTree asked on YouTube, also a question that, I think, goes a little bit in the other direction. He asked, he or she asked, if you now press the energy through any measure, don't you get directly into the rebound effect, that then the input is simply used to let something else run? That's very much like this story. Always the same. Yes, I agree, of course. Rebound is always... That's why it's like this, if you... So even bigger, right? So we're talking about social politics now. So I'm just in my profession. What can I, as a software developer, as an architect, do? And that is, reduce the CO2 emissions of your software. From coding to operation. But yes, then you just have more rebound again. And that is, for example, a criticism of this norm, that there is a functional unit here in the Carbon Intensity software. So where I say, I have an emission per order process. If now the number of orders goes up, then the CO2 emission actually goes up in my entire system. But my Carbon Intensity software could stay constant or even go down a bit. And now the rebound comes here. So it all looks good. So the energy consumption is great, but overall it is higher. That means the efficiency that I had in it, it was eaten by growth. And I actually have to, to maintain a constant CO2 emission, I have to increase my efficiency more than my growth. This is an effect that we had with lamps, which used to have these light bulbs. And then we exchanged them for LEDs, in the hope that the energy consumption for the lighting goes down. Exactly the other way around. The energy consumption for the lighting goes higher, because now you have LEDs everywhere. Then, of course, the consumption per lamp has become lower, but much more. But that's actually the rebound effect. So what you just said, that I somehow say, I have less consumption per lamp now, but I now illuminate things that I didn't illuminate before, because I can suddenly afford that. And that with the order is actually this rebound effect. So it just means that I am economically successful and have more orders. Rebound would be if I now say, okay, I now have an increase in efficiency in relation to, for example, order processes. And now I'm just starting and digitizing the rest too, because I now have free resources that I can use for other things. And I can't really imagine that, can I? Misunderstood, sorry. The rebound actually comes from the fact that you think you're good. So that's... So I can now... So the LED lamp doesn't cost anything now, so to speak, energy. Then I just make it a little nicer or let it run, because it doesn't matter. And then it happens. Then it kicks me off, so to speak, because I don't even notice it. And if I now have my emissions in such a factor, then I don't notice it. And that's why many say that you always have to monitor the entire system to avoid exactly this rebound effect, because it's out of sight. Okay, that means you're telling me this number per unit is somehow deceitful, because when the units grow, then I have an overall problem and have to work harder, so to speak. There are still several questions. So one has... So here's the question again. Can you name your definition of a functional unit again? Is a computer or a service a functional unit? I think we actually cleared that with the order. So an order could... So you usually try to run it professionally. You can of course also say per request or something, but on a technical level, you try to run it professionally. So per order, per tax, that I somehow have, tax notice that I have, or whatever. Then the question from Twilight Depends asked, does the blue angel bring me a market advantage for my software or my network? Hopefully. You just said that it's kind of insanely fresh, right? So for toilet paper, for printers... So with printers it's quite a lot. Or paper. So with printers it's... You go there and say, I'll make a blue angel. I mean, I'm aware of it, I know, I'm part of the problem, but I'm also part of the solution. And then he also wrote, there will be something like this, I assume that this blue angel will be audited. Yes, so that's actually not the case that anyone gives it away, but there are auditors, they have to be accredited at the Federal Environment Office, there is also an exam, so not just say what I want, but above all there are criteria. So it's just like an authority in Siebel does. Exactly, just as we imagine it here in this country. Exactly. I would really like to get rid of one more topic. No, I think we've actually worked it up a bit, these few things have come up. But yes, exactly, then I would say, go ahead. So we had this efficiency, these action areas, and I would like to tease two things. One is, when I'm in the cloud at some point, what helps a lot is shutdown. So strategy number one, turn off the stuff. We have, according to experience, a lot of test systems, CICD systems, customer imaging systems, and these things run. Run and run, even though you don't need them. So you can turn it all off. Yes, it's a bit placid. The shutdown is the problem, but it's turning it on. And there's a lot going on. So you could build some kind of system where you drive the things up again. You send an email and then it just drives up a thousand things. So we've tried a lot. What also works very well are such on-demand, so if I'm in container apps, for example, then I can just put a request on it and then the system drives itself up because there's a load balancer on it. So there's a lot going on. Turn off stuff. You can also avoid something. So produce some reports that no one reads. I don't need that anyway. And on some things you can also do without. Does every weather app have a high availability of 9.9999%? Do I have to look at the weather everywhere? You can avoid things. You can do without it. You can question things. You can turn it on and off. There are massive low-hanging fruits. You can't even imagine that. We don't even have to start coding yet. But if we do, of course, everything plays into this maximum server utilization. So container, path and so on. And this... Sorry. What... Where there's a lot going on and it's dynamic scaling. So here, architecture stream. So everyone knows how it works. Typically, our software systems have a time-dependent load. And I have a graphic here. So the load depends on the time. It goes up and down. And then I need several computer units to represent this load. So maybe three computer units at the top. And one computer unit at the bottom. And the industrial standard is essentially that we provide maximum load. And then there are always three servers running all the time. But I could scale dynamically. That is, when my load increases, I add computer units and then switch them off again. And actually turn off the computer when possible. In on-prem or in the cloud, I can release the resource. And then the emission is actually gone from this hardware. Both energy and bound emissions. And if you think about the savings, then there are easily 30, 40, 50 percent CO2 emissions. Just because you turned on a horizontal scaler in Kubernetes. Just because you release the load at the end. This is a no-brainer from a technical point of view. Go read a book, if you don't know it. And that really hits the spot. I would really like to share that with you. Because I see a lot of systems. It is really an industrial standard to provide maximum load. Because of reasons, so to speak. There are always reasons. And our job as a techie is actually to change these reasons. Of course, a system is as it is. The system also has a quality problem, because it is so. It doesn't fall from the sky either. And the other thing is the CO2 intensity. This is something that we don't have in mind. This is the connection between energy, i.e. electricity, and CO2. The CO2 intensity, i.e. the CO2 generation from electricity, depends on how much renewable energy I have at the moment. Germany now has an average of about 60 percent. But that changes over time. I have a website here called Electricity Maps. For all those who can only listen. There you can see at the moment how high the CO2 intensity is in the individual networks. Germany, Luxembourg, for example. Or Norway, France. How high the CO2 intensity is there. We are now at 10 o'clock. We are a bit delayed. In Germany, 436 grams of CO2 per kilowatt hour. In Norway, we have 30 grams of CO2 at the same time. Because Norway has a lot of hydropower. Poland has a lot of coal. There it is now 558 grams. In France, you can now weigh it as you like. Also 40 grams. But they have a lot of atoms. They have 30 percent regenerative. The rest is basically atoms. When I have static things, I can think about it. Okay, so number crunch or something. I do it in a region that always has green electricity. Or because the electricity, over time, the share of renewable energies fluctuates. Now I have a website from the Fraunhofer Institute. This is the power station. There you can see that the share of renewables fluctuates over the day. Typically, we have a good afternoon. There is no wind today. That's why it's bad this afternoon at 5 p.m. And then it gets better again. There are predictions. The idea is that, similar to electric car charging or other things, it always consumes electricity when it is generated by renewable energies. So I push the load of my software to times where I have little CO2 in the electricity. There are a lot of tools for this. The basis is again the Green Software Foundation. There is a Carbon Aware SDK. I took that and built it into tooling and did a project with the Fraunhofer Institute to get predictions about the CO2 intensity of the power grid in the next 24 hours. Question 2. Can I choose this as the first approach to optimize what we are seeing right now? Yes. We are in the software. It always starts from there. If I may give you points. Turn off the stuff you don't need. All these test systems, CECD, all the machinery has to run on each comet. I only do that with Merge Request. Can I turn off any systems? Really turn it off. Do my things have to run at night? Turning it off helps. Number 2, which is going really well, is dynamic scaling. A totally low-hanging, incredibly efficient. Number 3 is Carbon Aware Computing. This time-shifting, where you say, okay, I'll push it there. The more batch jobs you have, the better it is to shield. This is the beginning, of course, because we also have to take other resources with us. We are actually optimizing resources here, namely compute resources and CO2. The number we have at the moment is CO2. But if I'm in the cloud, for example, and I have batch jobs, then I can combine that with Spot VMs. These are basically the VMs from our data center. I combine them. And with that, I have a maximum without effort. Would you like to briefly explain what Spot VMs are? I'm not sure if everyone understands that. The big hyperscalers, if they have too many free compute resources, then you can order a kind of VM. You get it at some point. And it's taken away from you again when you need the resources. But I have a free time. I can use the VM. And it's much cheaper. I take the rest of the compute. If I understand that correctly, I pay so and so many euros for this thing. And if the price is below that, then this resource is given to me. And then it runs for a while and at some point it will be withdrawn again. This is the beta model. At Microsoft, for example, there is the Azure Batch as a service. Then you can say, I would like Spot VMs. Then you just get them at some point. And they are 30-40% cheaper. And I think you can also offer them somewhere else. Yes, that was AWS. But that's ten years ago or so. I did exactly that. And I also found that the things are just gone at some point. Just like that. It's behind the scenes, so to speak. Yes, exactly. You have to respect the software. Yes, it is definitely very valid. And especially if you look at the CO2 intensity, it fluctuates from 600 or 700 grams of CO2 per kilowatt hour to 50. So that's good. If you calculate an hour, then it's good. Exactly, that's a factor of 10. So it's good. And there is tooling. So that's also very easy. Here on the website there are jobs and PowerShell and web and APs and everything. Exactly. So I would really like to include that, because these are actually all low-hanging fruits. And when I go there and say, okay, I have harvested my low-hanging, then I can go back to the software, can continue to optimize, to pay for these individual fields of action. Then you can think about what's going on. Exactly, that's actually a very good point. I don't think you said it explicitly, but it comes out implicitly. It's actually just about how I run the software. So we haven't even talked about it yet. I don't know, wasn't there a question? Let me take a quick look. Or rather, this is one of the topics that is always going around the area. Which programming language should I use? And we haven't really discussed that. It would be a bit of a question. So is that even a topic? So yes, no. So academically, I would say. First of all, the programming language that is suitable for us. So what should I tell people? Don't do Python, do Rust. But it's not that bad, because Python of course uses the C libraries at the end. Or Java or .NET or something. Well, it also depends on the runtime environment. So do I do .NET Core, do I do .NET Framework, do I do Java with any Enterprise Beans or Schlank? Do I have Spring with me or not? So in my opinion, it's not the programming language. If so, it's the runtime environment and the Frameworks that we make. But I think it's mainly the mindset. It's software engineering. It's just normal software engineering. We can all do that. We know how it works. If we don't know it, we'll learn it right away. These are similar practices. And in software engineering, we have our focus on evolvability. And in green software, in green coding, we use the same tools with a focus on climate-friendly. And in doing so, we somehow also save money in advance. And that's actually something where you can get active right away, as you said very clearly. One thing, I have to see if I can find it out. I don't know if you're also keen on it, because we were just talking about programming languages. There's a new paper that says the previous view that programming languages bring a lot of things is falsified because programming languages are typically used for certain problem areas. And in reality, the problem areas are what creates different efficiency. I don't know the paper, but I would confirm it. What I don't know yet, for example, whether I can continue with static code analysis. There is the Environment Campus Trier and in the environment, it's called Birkenfeld. And there was, for example, a master's thesis that examined this. And in fact, we get performance problems through static code analysis, but more than we can do performance analysis. What we can do through static code analysis. But really, that doesn't make the code any better. So we don't get better programming paradigms that go beyond performance. So profiler land. I think you said that very nicely. Once this very nice graphic where you showed that if I dynamically scale, then it saves a lot. That the server load is actually very important. That the run-time is so expensive. And also this story that depending on where I generate the CO2 or where I get the power, that's obviously the big factors. You also have this CO2 challenge in Karlsruhe, right? Yes, thank you. The question is, what can I do? A, I can stay in my profession. And I always say smuggle in. And as an entrepreneur, we have a large corporate network in Karlsruhe, one of the largest in Europe. We have now launched a campaign where companies commit to reducing their software products by 40% within a year. There is mentoring for this. People, experts from the network are honored to be there. So if someone is in the stream and is an expert, please report it. Or people in Karlsruhe are against it. The big ones are still there. For example, Teamviewer, NBW. I don't know. February you might know. And a few small ones. There are still a few missing as I can see. They all do it together. In principle, you take responsibility for your products. That's what I like about this campaign. Anything else you would like to say? We are here from the community. There are some renters worldwide on the topic of green software. Karlsruhe, of course. Munich, Düsseldorf, Stuttgart, Frankfurt, Hamburg and Berlin from time to time. Also in Nuremberg. We have people from everywhere. In Karlsruhe, you can do it hybrid. There is also Green Software Foundation. What we started 15 years ago, 20 years ago, with agility, with software craftsmanship, the same movement starts now with green software. So in the sense of a roots movement, you mean. Exactly. Maybe one more thing. I don't know if that's obvious. You also save operating costs relatively obviously. We can discuss the quantities now. But it's not like you invest and only CO2 is saved. It gets better. We are in an optimized system at the moment. We are always looking for optimum. It's our job. Do it better, do it well. What we are doing now is that we add another aspect to our profession. What we used to do with agility, we had software craftsmanship and now the climate is added. It needs a kind of activation energy. But the next optimum we produce is better than what we had. It's cheaper. We just have to do it. We are a bit at the end of time. I don't know if you still have topics. I could talk for hours. But I think it's good. If there are questions, just ping on LinkedIn, connect. I'll link your profile again. We'll have a lot of things anyway. Then I would say thank you to you. Nice that you took the time. I found it very exciting and I think it's a very important topic. Short preview for the next time. The next time is again next Friday. That's the topic Code Retreat. Marco Emmerich and I will sit at the computer together. Marco can actually encode on the computer. We will show together how such a Code Retreat works. This is a story from the software craftsmanship area. It's about things like system development, refactoring and all these things to practice. This is a bit of a preview of the Global Day of Code Retreat, which is on the 8th and 11th. That means it's a bit of an appetizer for it. Thank you very much and see you there.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 6.559999942779541,
      "text": " Today's topic is Green Software Development with Aydin.",
      "tokens": [
        50364,
        2692,
        311,
        4829,
        307,
        6969,
        27428,
        15041,
        365,
        316,
        6655,
        259,
        13,
        50692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6213119626045227,
      "compression_ratio": 1.3969849348068237,
      "no_speech_prob": 0.4980144500732422
    },
    {
      "id": 1,
      "seek": 0,
      "start": 6.559999942779541,
      "end": 7.559999942779541,
      "text": " Nice to have you here.",
      "tokens": [
        50692,
        5490,
        281,
        362,
        291,
        510,
        13,
        50742
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6213119626045227,
      "compression_ratio": 1.3969849348068237,
      "no_speech_prob": 0.4980144500732422
    },
    {
      "id": 2,
      "seek": 0,
      "start": 9.15999984741211,
      "end": 13.039999961853027,
      "text": " Before we get started, a few more notes.",
      "tokens": [
        50822,
        4546,
        321,
        483,
        1409,
        11,
        257,
        1326,
        544,
        5570,
        13,
        51016
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6213119626045227,
      "compression_ratio": 1.3969849348068237,
      "no_speech_prob": 0.4980144500732422
    },
    {
      "id": 3,
      "seek": 0,
      "start": 14.239999771118164,
      "end": 20.360000610351562,
      "text": " One thing, there are still places at my Architecture Kickstart.",
      "tokens": [
        51076,
        1485,
        551,
        11,
        456,
        366,
        920,
        3190,
        412,
        452,
        43049,
        20886,
        24419,
        13,
        51382
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6213119626045227,
      "compression_ratio": 1.3969849348068237,
      "no_speech_prob": 0.4980144500732422
    },
    {
      "id": 4,
      "seek": 0,
      "start": 20.68000030517578,
      "end": 27.84000015258789,
      "text": " That's a bit close to my heart because it's an event that I think is somehow very interesting.",
      "tokens": [
        51398,
        663,
        311,
        257,
        857,
        1998,
        281,
        452,
        1917,
        570,
        309,
        311,
        364,
        2280,
        300,
        286,
        519,
        307,
        6063,
        588,
        1880,
        13,
        51756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6213119626045227,
      "compression_ratio": 1.3969849348068237,
      "no_speech_prob": 0.4980144500732422
    },
    {
      "id": 5,
      "seek": 2784,
      "start": 28.1200008392334,
      "end": 34.52000045776367,
      "text": " In four weeks, each four hours, you will have the most important topics from the area of",
      "tokens": [
        50378,
        682,
        1451,
        3259,
        11,
        1184,
        1451,
        2496,
        11,
        291,
        486,
        362,
        264,
        881,
        1021,
        8378,
        490,
        264,
        1859,
        295,
        50698
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5716331601142883,
      "compression_ratio": 1.4734848737716675,
      "no_speech_prob": 0.022128846496343613
    },
    {
      "id": 6,
      "seek": 2784,
      "start": 34.52000045776367,
      "end": 37.599998474121094,
      "text": " Software Architecture, Building Context, Strategic Domain-Driven Design,",
      "tokens": [
        50698,
        27428,
        43049,
        11,
        18974,
        4839,
        3828,
        11,
        47805,
        16674,
        491,
        12,
        35,
        470,
        553,
        12748,
        11,
        50852
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5716331601142883,
      "compression_ratio": 1.4734848737716675,
      "no_speech_prob": 0.022128846496343613
    },
    {
      "id": 7,
      "seek": 2784,
      "start": 37.599998474121094,
      "end": 40.84000015258789,
      "text": " Legacy Systems and how to achieve qualities.",
      "tokens": [
        50852,
        42838,
        27059,
        293,
        577,
        281,
        4584,
        16477,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5716331601142883,
      "compression_ratio": 1.4734848737716675,
      "no_speech_prob": 0.022128846496343613
    },
    {
      "id": 8,
      "seek": 2784,
      "start": 40.84000015258789,
      "end": 46.84000015258789,
      "text": " And the whole thing with very few slides, actually no slides at all and very interactive.",
      "tokens": [
        51014,
        400,
        264,
        1379,
        551,
        365,
        588,
        1326,
        9788,
        11,
        767,
        572,
        9788,
        412,
        439,
        293,
        588,
        15141,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5716331601142883,
      "compression_ratio": 1.4734848737716675,
      "no_speech_prob": 0.022128846496343613
    },
    {
      "id": 9,
      "seek": 2784,
      "start": 47.279998779296875,
      "end": 49.0,
      "text": " It starts on November 14th.",
      "tokens": [
        51336,
        467,
        3719,
        322,
        7674,
        3499,
        392,
        13,
        51422
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5716331601142883,
      "compression_ratio": 1.4734848737716675,
      "no_speech_prob": 0.022128846496343613
    },
    {
      "id": 10,
      "seek": 2784,
      "start": 49.0,
      "end": 53.0,
      "text": " That means if you still feel like registering, I would be happy.",
      "tokens": [
        51422,
        663,
        1355,
        498,
        291,
        920,
        841,
        411,
        47329,
        11,
        286,
        576,
        312,
        2055,
        13,
        51622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5716331601142883,
      "compression_ratio": 1.4734848737716675,
      "no_speech_prob": 0.022128846496343613
    },
    {
      "id": 11,
      "seek": 5300,
      "start": 54.0,
      "end": 56.0,
      "text": " But now actually to the main topic.",
      "tokens": [
        50414,
        583,
        586,
        767,
        281,
        264,
        2135,
        4829,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3906284272670746,
      "compression_ratio": 1.5659722089767456,
      "no_speech_prob": 0.03963948041200638
    },
    {
      "id": 12,
      "seek": 5300,
      "start": 56.0,
      "end": 59.0,
      "text": " Aydin, nice to have you here, as I said.",
      "tokens": [
        50514,
        316,
        6655,
        259,
        11,
        1481,
        281,
        362,
        291,
        510,
        11,
        382,
        286,
        848,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3906284272670746,
      "compression_ratio": 1.5659722089767456,
      "no_speech_prob": 0.03963948041200638
    },
    {
      "id": 13,
      "seek": 5300,
      "start": 59.0,
      "end": 62.0,
      "text": " Would you like to briefly say something about who you are and what you do?",
      "tokens": [
        50664,
        6068,
        291,
        411,
        281,
        10515,
        584,
        746,
        466,
        567,
        291,
        366,
        293,
        437,
        291,
        360,
        30,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3906284272670746,
      "compression_ratio": 1.5659722089767456,
      "no_speech_prob": 0.03963948041200638
    },
    {
      "id": 14,
      "seek": 5300,
      "start": 62.0,
      "end": 63.0,
      "text": " Yes, of course.",
      "tokens": [
        50814,
        1079,
        11,
        295,
        1164,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3906284272670746,
      "compression_ratio": 1.5659722089767456,
      "no_speech_prob": 0.03963948041200638
    },
    {
      "id": 15,
      "seek": 5300,
      "start": 63.0,
      "end": 65.0,
      "text": " First of all, thank you for the invitation.",
      "tokens": [
        50864,
        2386,
        295,
        439,
        11,
        1309,
        291,
        337,
        264,
        17890,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3906284272670746,
      "compression_ratio": 1.5659722089767456,
      "no_speech_prob": 0.03963948041200638
    },
    {
      "id": 16,
      "seek": 5300,
      "start": 65.0,
      "end": 66.0,
      "text": " My name is Aydin.",
      "tokens": [
        50964,
        1222,
        1315,
        307,
        316,
        6655,
        259,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3906284272670746,
      "compression_ratio": 1.5659722089767456,
      "no_speech_prob": 0.03963948041200638
    },
    {
      "id": 17,
      "seek": 5300,
      "start": 66.0,
      "end": 67.0,
      "text": " Aydin Mir-Mohammadin.",
      "tokens": [
        51014,
        316,
        6655,
        259,
        9421,
        12,
        44,
        1445,
        15481,
        259,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3906284272670746,
      "compression_ratio": 1.5659722089767456,
      "no_speech_prob": 0.03963948041200638
    },
    {
      "id": 18,
      "seek": 5300,
      "start": 67.0,
      "end": 70.0,
      "text": " I am the result of a German-Iranian love.",
      "tokens": [
        51064,
        286,
        669,
        264,
        1874,
        295,
        257,
        6521,
        12,
        40,
        4257,
        952,
        959,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3906284272670746,
      "compression_ratio": 1.5659722089767456,
      "no_speech_prob": 0.03963948041200638
    },
    {
      "id": 19,
      "seek": 5300,
      "start": 70.0,
      "end": 77.0,
      "text": " With the unbeatable advantage, if you know how to write me, there is only one Google meeting.",
      "tokens": [
        51214,
        2022,
        264,
        517,
        4169,
        712,
        5002,
        11,
        498,
        291,
        458,
        577,
        281,
        2464,
        385,
        11,
        456,
        307,
        787,
        472,
        3329,
        3440,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3906284272670746,
      "compression_ratio": 1.5659722089767456,
      "no_speech_prob": 0.03963948041200638
    },
    {
      "id": 20,
      "seek": 5300,
      "start": 77.0,
      "end": 79.0,
      "text": " And that's exactly the challenge.",
      "tokens": [
        51564,
        400,
        300,
        311,
        2293,
        264,
        3430,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3906284272670746,
      "compression_ratio": 1.5659722089767456,
      "no_speech_prob": 0.03963948041200638
    },
    {
      "id": 21,
      "seek": 5300,
      "start": 79.0,
      "end": 82.0,
      "text": " I am a software entrepreneur.",
      "tokens": [
        51664,
        286,
        669,
        257,
        4722,
        14307,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3906284272670746,
      "compression_ratio": 1.5659722089767456,
      "no_speech_prob": 0.03963948041200638
    },
    {
      "id": 22,
      "seek": 8200,
      "start": 82.0,
      "end": 90.0,
      "text": " I am the founder and managing director of Bluehands, a small software company here in the south,",
      "tokens": [
        50364,
        286,
        669,
        264,
        14917,
        293,
        11642,
        5391,
        295,
        8510,
        71,
        2967,
        11,
        257,
        1359,
        4722,
        2237,
        510,
        294,
        264,
        7377,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3972948491573334,
      "compression_ratio": 1.5130890607833862,
      "no_speech_prob": 0.01142713613808155
    },
    {
      "id": 23,
      "seek": 8200,
      "start": 90.0,
      "end": 92.0,
      "text": " in Karlsruhe.",
      "tokens": [
        50764,
        294,
        20405,
        82,
        894,
        675,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3972948491573334,
      "compression_ratio": 1.5130890607833862,
      "no_speech_prob": 0.01142713613808155
    },
    {
      "id": 24,
      "seek": 8200,
      "start": 92.0,
      "end": 95.0,
      "text": " With about 22 people in the projects.",
      "tokens": [
        50864,
        2022,
        466,
        220,
        7490,
        561,
        294,
        264,
        4455,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3972948491573334,
      "compression_ratio": 1.5130890607833862,
      "no_speech_prob": 0.01142713613808155
    },
    {
      "id": 25,
      "seek": 8200,
      "start": 96.0,
      "end": 101.0,
      "text": " And I am community-driven.",
      "tokens": [
        51064,
        400,
        286,
        669,
        1768,
        12,
        25456,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3972948491573334,
      "compression_ratio": 1.5130890607833862,
      "no_speech_prob": 0.01142713613808155
    },
    {
      "id": 26,
      "seek": 8200,
      "start": 101.0,
      "end": 108.0,
      "text": " Everything I learn, everything I have learned, comes from somewhere in the community,",
      "tokens": [
        51314,
        5471,
        286,
        1466,
        11,
        1203,
        286,
        362,
        3264,
        11,
        1487,
        490,
        4079,
        294,
        264,
        1768,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3972948491573334,
      "compression_ratio": 1.5130890607833862,
      "no_speech_prob": 0.01142713613808155
    },
    {
      "id": 27,
      "seek": 8200,
      "start": 108.0,
      "end": 109.0,
      "text": " from conferences and so on.",
      "tokens": [
        51664,
        490,
        22032,
        293,
        370,
        322,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3972948491573334,
      "compression_ratio": 1.5130890607833862,
      "no_speech_prob": 0.01142713613808155
    },
    {
      "id": 28,
      "seek": 10900,
      "start": 109.0,
      "end": 113.0,
      "text": " That's why I also call myself a community enthusiast.",
      "tokens": [
        50364,
        663,
        311,
        983,
        286,
        611,
        818,
        2059,
        257,
        1768,
        18076,
        525,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38468265533447266,
      "compression_ratio": 1.4224598407745361,
      "no_speech_prob": 0.0090255131945014
    },
    {
      "id": 29,
      "seek": 10900,
      "start": 113.0,
      "end": 116.0,
      "text": " That's my background.",
      "tokens": [
        50564,
        663,
        311,
        452,
        3678,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38468265533447266,
      "compression_ratio": 1.4224598407745361,
      "no_speech_prob": 0.0090255131945014
    },
    {
      "id": 30,
      "seek": 10900,
      "start": 116.0,
      "end": 126.0,
      "text": " And what I'm working on right now, in addition to my daily job in software,",
      "tokens": [
        50714,
        400,
        437,
        286,
        478,
        1364,
        322,
        558,
        586,
        11,
        294,
        4500,
        281,
        452,
        5212,
        1691,
        294,
        4722,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38468265533447266,
      "compression_ratio": 1.4224598407745361,
      "no_speech_prob": 0.0090255131945014
    },
    {
      "id": 31,
      "seek": 10900,
      "start": 126.0,
      "end": 129.0,
      "text": " in management, is green software.",
      "tokens": [
        51214,
        294,
        4592,
        11,
        307,
        3092,
        4722,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38468265533447266,
      "compression_ratio": 1.4224598407745361,
      "no_speech_prob": 0.0090255131945014
    },
    {
      "id": 32,
      "seek": 10900,
      "start": 129.0,
      "end": 132.0,
      "text": " Sustainability in IT.",
      "tokens": [
        51364,
        34407,
        2310,
        294,
        6783,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38468265533447266,
      "compression_ratio": 1.4224598407745361,
      "no_speech_prob": 0.0090255131945014
    },
    {
      "id": 33,
      "seek": 10900,
      "start": 132.0,
      "end": 133.0,
      "text": " Exactly.",
      "tokens": [
        51514,
        7587,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38468265533447266,
      "compression_ratio": 1.4224598407745361,
      "no_speech_prob": 0.0090255131945014
    },
    {
      "id": 34,
      "seek": 10900,
      "start": 133.0,
      "end": 137.0,
      "text": " And I think that brings us directly to the topic.",
      "tokens": [
        51564,
        400,
        286,
        519,
        300,
        5607,
        505,
        3838,
        281,
        264,
        4829,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38468265533447266,
      "compression_ratio": 1.4224598407745361,
      "no_speech_prob": 0.0090255131945014
    },
    {
      "id": 35,
      "seek": 13700,
      "start": 137.0,
      "end": 139.0,
      "text": " So it's about green software development.",
      "tokens": [
        50364,
        407,
        309,
        311,
        466,
        3092,
        4722,
        3250,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4216890037059784,
      "compression_ratio": 1.4120879173278809,
      "no_speech_prob": 0.06984823942184448
    },
    {
      "id": 36,
      "seek": 13700,
      "start": 139.0,
      "end": 141.0,
      "text": " What is that anyway?",
      "tokens": [
        50464,
        708,
        307,
        300,
        4033,
        30,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4216890037059784,
      "compression_ratio": 1.4120879173278809,
      "no_speech_prob": 0.06984823942184448
    },
    {
      "id": 37,
      "seek": 13700,
      "start": 144.0,
      "end": 147.0,
      "text": " Are my slides visible right now?",
      "tokens": [
        50714,
        2014,
        452,
        9788,
        8974,
        558,
        586,
        30,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4216890037059784,
      "compression_ratio": 1.4120879173278809,
      "no_speech_prob": 0.06984823942184448
    },
    {
      "id": 38,
      "seek": 13700,
      "start": 147.0,
      "end": 152.0,
      "text": " Not yet, but I'll fix that now.",
      "tokens": [
        50864,
        1726,
        1939,
        11,
        457,
        286,
        603,
        3191,
        300,
        586,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4216890037059784,
      "compression_ratio": 1.4120879173278809,
      "no_speech_prob": 0.06984823942184448
    },
    {
      "id": 39,
      "seek": 13700,
      "start": 152.0,
      "end": 155.0,
      "text": " I can do it with or without a slide.",
      "tokens": [
        51114,
        286,
        393,
        360,
        309,
        365,
        420,
        1553,
        257,
        4137,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4216890037059784,
      "compression_ratio": 1.4120879173278809,
      "no_speech_prob": 0.06984823942184448
    },
    {
      "id": 40,
      "seek": 13700,
      "start": 155.0,
      "end": 157.0,
      "text": " Now the slides are there, sorry.",
      "tokens": [
        51264,
        823,
        264,
        9788,
        366,
        456,
        11,
        2597,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4216890037059784,
      "compression_ratio": 1.4120879173278809,
      "no_speech_prob": 0.06984823942184448
    },
    {
      "id": 41,
      "seek": 13700,
      "start": 157.0,
      "end": 164.0,
      "text": " So here again, if anyone wants to ping me or over LinkedIn.",
      "tokens": [
        51364,
        407,
        510,
        797,
        11,
        498,
        2878,
        2738,
        281,
        26151,
        385,
        420,
        670,
        20657,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4216890037059784,
      "compression_ratio": 1.4120879173278809,
      "no_speech_prob": 0.06984823942184448
    },
    {
      "id": 42,
      "seek": 16400,
      "start": 165.0,
      "end": 168.0,
      "text": " We're actually talking about this figure.",
      "tokens": [
        50414,
        492,
        434,
        767,
        1417,
        466,
        341,
        2573,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4000650942325592,
      "compression_ratio": 1.5308642387390137,
      "no_speech_prob": 0.011964264325797558
    },
    {
      "id": 43,
      "seek": 16400,
      "start": 168.0,
      "end": 180.0,
      "text": " That's 4% of global emissions caused by our sector, i.e. the ITK area, the entire sector.",
      "tokens": [
        50564,
        663,
        311,
        1017,
        4,
        295,
        4338,
        14607,
        7008,
        538,
        527,
        6977,
        11,
        741,
        13,
        68,
        13,
        264,
        6783,
        42,
        1859,
        11,
        264,
        2302,
        6977,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4000650942325592,
      "compression_ratio": 1.5308642387390137,
      "no_speech_prob": 0.011964264325797558
    },
    {
      "id": 44,
      "seek": 16400,
      "start": 180.0,
      "end": 183.0,
      "text": " These are figures from 2020.",
      "tokens": [
        51164,
        1981,
        366,
        9624,
        490,
        4808,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4000650942325592,
      "compression_ratio": 1.5308642387390137,
      "no_speech_prob": 0.011964264325797558
    },
    {
      "id": 45,
      "seek": 16400,
      "start": 183.0,
      "end": 192.0,
      "text": " The total emissions caused by our sector are currently massively increasing, exploding.",
      "tokens": [
        51314,
        440,
        3217,
        14607,
        7008,
        538,
        527,
        6977,
        366,
        4362,
        29379,
        5662,
        11,
        35175,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4000650942325592,
      "compression_ratio": 1.5308642387390137,
      "no_speech_prob": 0.011964264325797558
    },
    {
      "id": 46,
      "seek": 19200,
      "start": 193.0,
      "end": 197.0,
      "text": " We have about 8% of electricity consumption in Europe.",
      "tokens": [
        50414,
        492,
        362,
        466,
        1649,
        4,
        295,
        10356,
        12126,
        294,
        3315,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39746809005737305,
      "compression_ratio": 1.4358974695205688,
      "no_speech_prob": 0.012191678397357464
    },
    {
      "id": 47,
      "seek": 19200,
      "start": 197.0,
      "end": 199.0,
      "text": " It goes on.",
      "tokens": [
        50614,
        467,
        1709,
        322,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39746809005737305,
      "compression_ratio": 1.4358974695205688,
      "no_speech_prob": 0.012191678397357464
    },
    {
      "id": 48,
      "seek": 19200,
      "start": 199.0,
      "end": 206.0,
      "text": " And that's actually the background of what it's all about.",
      "tokens": [
        50714,
        400,
        300,
        311,
        767,
        264,
        3678,
        295,
        437,
        309,
        311,
        439,
        466,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39746809005737305,
      "compression_ratio": 1.4358974695205688,
      "no_speech_prob": 0.012191678397357464
    },
    {
      "id": 49,
      "seek": 19200,
      "start": 206.0,
      "end": 214.0,
      "text": " Namely, these massive, rising emissions that we ask for in software development,",
      "tokens": [
        51064,
        10684,
        736,
        11,
        613,
        5994,
        11,
        11636,
        14607,
        300,
        321,
        1029,
        337,
        294,
        4722,
        3250,
        11,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39746809005737305,
      "compression_ratio": 1.4358974695205688,
      "no_speech_prob": 0.012191678397357464
    },
    {
      "id": 50,
      "seek": 19200,
      "start": 214.0,
      "end": 216.0,
      "text": " I would say, to reduce.",
      "tokens": [
        51464,
        286,
        576,
        584,
        11,
        281,
        5407,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39746809005737305,
      "compression_ratio": 1.4358974695205688,
      "no_speech_prob": 0.012191678397357464
    },
    {
      "id": 51,
      "seek": 19200,
      "start": 216.0,
      "end": 219.0,
      "text": " So at least to keep, but actually also to reduce.",
      "tokens": [
        51564,
        407,
        412,
        1935,
        281,
        1066,
        11,
        457,
        767,
        611,
        281,
        5407,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39746809005737305,
      "compression_ratio": 1.4358974695205688,
      "no_speech_prob": 0.012191678397357464
    },
    {
      "id": 52,
      "seek": 21900,
      "start": 220.0,
      "end": 224.0,
      "text": " And just to clarify, I brought a picture with me.",
      "tokens": [
        50414,
        400,
        445,
        281,
        17594,
        11,
        286,
        3038,
        257,
        3036,
        365,
        385,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3165918290615082,
      "compression_ratio": 1.5954545736312866,
      "no_speech_prob": 0.1171223521232605
    },
    {
      "id": 53,
      "seek": 21900,
      "start": 224.0,
      "end": 229.0,
      "text": " This is a data center by Microsoft, an Azure data center in Dublin.",
      "tokens": [
        50614,
        639,
        307,
        257,
        1412,
        3056,
        538,
        8116,
        11,
        364,
        11969,
        1412,
        3056,
        294,
        42323,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3165918290615082,
      "compression_ratio": 1.5954545736312866,
      "no_speech_prob": 0.1171223521232605
    },
    {
      "id": 54,
      "seek": 21900,
      "start": 229.0,
      "end": 231.0,
      "text": " And these are just huge things.",
      "tokens": [
        50864,
        400,
        613,
        366,
        445,
        2603,
        721,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3165918290615082,
      "compression_ratio": 1.5954545736312866,
      "no_speech_prob": 0.1171223521232605
    },
    {
      "id": 55,
      "seek": 21900,
      "start": 231.0,
      "end": 237.0,
      "text": " And Microsoft builds such a data center worldwide every three days.",
      "tokens": [
        50964,
        400,
        8116,
        15182,
        1270,
        257,
        1412,
        3056,
        13485,
        633,
        1045,
        1708,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3165918290615082,
      "compression_ratio": 1.5954545736312866,
      "no_speech_prob": 0.1171223521232605
    },
    {
      "id": 56,
      "seek": 21900,
      "start": 237.0,
      "end": 241.0,
      "text": " That was 23, 24, 25, 26, if we do a little less.",
      "tokens": [
        51264,
        663,
        390,
        6673,
        11,
        4022,
        11,
        3552,
        11,
        7551,
        11,
        498,
        321,
        360,
        257,
        707,
        1570,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3165918290615082,
      "compression_ratio": 1.5954545736312866,
      "no_speech_prob": 0.1171223521232605
    },
    {
      "id": 57,
      "seek": 21900,
      "start": 241.0,
      "end": 243.0,
      "text": " And Microsoft is number two.",
      "tokens": [
        51464,
        400,
        8116,
        307,
        1230,
        732,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3165918290615082,
      "compression_ratio": 1.5954545736312866,
      "no_speech_prob": 0.1171223521232605
    },
    {
      "id": 58,
      "seek": 21900,
      "start": 243.0,
      "end": 245.0,
      "text": " So Amazon is even more.",
      "tokens": [
        51564,
        407,
        6795,
        307,
        754,
        544,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3165918290615082,
      "compression_ratio": 1.5954545736312866,
      "no_speech_prob": 0.1171223521232605
    },
    {
      "id": 59,
      "seek": 21900,
      "start": 245.0,
      "end": 247.0,
      "text": " And all the other data centers.",
      "tokens": [
        51664,
        400,
        439,
        264,
        661,
        1412,
        10898,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3165918290615082,
      "compression_ratio": 1.5954545736312866,
      "no_speech_prob": 0.1171223521232605
    },
    {
      "id": 60,
      "seek": 24700,
      "start": 247.0,
      "end": 252.0,
      "text": " So we have massive, rising things everywhere.",
      "tokens": [
        50364,
        407,
        321,
        362,
        5994,
        11,
        11636,
        721,
        5315,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3658433258533478,
      "compression_ratio": 1.6585365533828735,
      "no_speech_prob": 0.04160275682806969
    },
    {
      "id": 61,
      "seek": 24700,
      "start": 252.0,
      "end": 254.0,
      "text": " And that's always an issue.",
      "tokens": [
        50614,
        400,
        300,
        311,
        1009,
        364,
        2734,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3658433258533478,
      "compression_ratio": 1.6585365533828735,
      "no_speech_prob": 0.04160275682806969
    },
    {
      "id": 62,
      "seek": 24700,
      "start": 254.0,
      "end": 259.0,
      "text": " And it's true that software doesn't actually have emissions.",
      "tokens": [
        50714,
        400,
        309,
        311,
        2074,
        300,
        4722,
        1177,
        380,
        767,
        362,
        14607,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3658433258533478,
      "compression_ratio": 1.6585365533828735,
      "no_speech_prob": 0.04160275682806969
    },
    {
      "id": 63,
      "seek": 24700,
      "start": 259.0,
      "end": 264.0,
      "text": " So the emissions are generated on the computer, on the servers, on the end devices.",
      "tokens": [
        50964,
        407,
        264,
        14607,
        366,
        10833,
        322,
        264,
        3820,
        11,
        322,
        264,
        15909,
        11,
        322,
        264,
        917,
        5759,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3658433258533478,
      "compression_ratio": 1.6585365533828735,
      "no_speech_prob": 0.04160275682806969
    },
    {
      "id": 64,
      "seek": 24700,
      "start": 264.0,
      "end": 267.0,
      "text": " But the software is at the beginning of the chain.",
      "tokens": [
        51214,
        583,
        264,
        4722,
        307,
        412,
        264,
        2863,
        295,
        264,
        5021,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3658433258533478,
      "compression_ratio": 1.6585365533828735,
      "no_speech_prob": 0.04160275682806969
    },
    {
      "id": 65,
      "seek": 24700,
      "start": 267.0,
      "end": 276.0,
      "text": " And it's about how we can make our contribution within our profession.",
      "tokens": [
        51364,
        400,
        309,
        311,
        466,
        577,
        321,
        393,
        652,
        527,
        13150,
        1951,
        527,
        7032,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3658433258533478,
      "compression_ratio": 1.6585365533828735,
      "no_speech_prob": 0.04160275682806969
    },
    {
      "id": 66,
      "seek": 27600,
      "start": 276.0,
      "end": 277.0,
      "text": " Exactly.",
      "tokens": [
        50364,
        7587,
        13,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41748467087745667,
      "compression_ratio": 1.6302521228790283,
      "no_speech_prob": 0.08312404900789261
    },
    {
      "id": 67,
      "seek": 27600,
      "start": 277.0,
      "end": 283.0,
      "text": " So in fact, two parallel, similar questions have arisen.",
      "tokens": [
        50414,
        407,
        294,
        1186,
        11,
        732,
        8952,
        11,
        2531,
        1651,
        362,
        594,
        11106,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41748467087745667,
      "compression_ratio": 1.6302521228790283,
      "no_speech_prob": 0.08312404900789261
    },
    {
      "id": 68,
      "seek": 27600,
      "start": 283.0,
      "end": 285.0,
      "text": " One is about the formula.",
      "tokens": [
        50714,
        1485,
        307,
        466,
        264,
        1254,
        84,
        875,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41748467087745667,
      "compression_ratio": 1.6302521228790283,
      "no_speech_prob": 0.08312404900789261
    },
    {
      "id": 69,
      "seek": 27600,
      "start": 285.0,
      "end": 289.0,
      "text": " The question is, do all our efforts towards green software play a role at all,",
      "tokens": [
        50814,
        440,
        1168,
        307,
        11,
        360,
        439,
        527,
        6484,
        281,
        6925,
        16063,
        3092,
        4722,
        862,
        257,
        3090,
        412,
        439,
        11,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41748467087745667,
      "compression_ratio": 1.6302521228790283,
      "no_speech_prob": 0.08312404900789261
    },
    {
      "id": 70,
      "seek": 27600,
      "start": 289.0,
      "end": 293.0,
      "text": " if you see that old nuclear power plants are being reanimated because of AI?",
      "tokens": [
        51014,
        498,
        291,
        536,
        300,
        1331,
        8179,
        1347,
        5972,
        366,
        885,
        319,
        17869,
        770,
        570,
        295,
        7318,
        30,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41748467087745667,
      "compression_ratio": 1.6302521228790283,
      "no_speech_prob": 0.08312404900789261
    },
    {
      "id": 71,
      "seek": 27600,
      "start": 293.0,
      "end": 298.0,
      "text": " I think that's this thing in Philipsburg, where there was this plan to reanimate it again,",
      "tokens": [
        51214,
        286,
        519,
        300,
        311,
        341,
        551,
        294,
        7777,
        2600,
        8342,
        11,
        689,
        456,
        390,
        341,
        1393,
        281,
        319,
        282,
        2905,
        309,
        797,
        11,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41748467087745667,
      "compression_ratio": 1.6302521228790283,
      "no_speech_prob": 0.08312404900789261
    },
    {
      "id": 72,
      "seek": 27600,
      "start": 298.0,
      "end": 302.0,
      "text": " where there was the nuclear pain in the late 70s.",
      "tokens": [
        51464,
        689,
        456,
        390,
        264,
        8179,
        1822,
        294,
        264,
        3469,
        5285,
        82,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41748467087745667,
      "compression_ratio": 1.6302521228790283,
      "no_speech_prob": 0.08312404900789261
    },
    {
      "id": 73,
      "seek": 30200,
      "start": 302.0,
      "end": 306.0,
      "text": " And even if it's being rebuilt, it's not just a drop on the hot stone.",
      "tokens": [
        50364,
        400,
        754,
        498,
        309,
        311,
        885,
        38532,
        11,
        309,
        311,
        406,
        445,
        257,
        3270,
        322,
        264,
        2368,
        7581,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41327622532844543,
      "compression_ratio": 1.6796536445617676,
      "no_speech_prob": 0.19666896760463715
    },
    {
      "id": 74,
      "seek": 30200,
      "start": 306.0,
      "end": 311.0,
      "text": " And question two, it depends on YouTube, has already asked,",
      "tokens": [
        50564,
        400,
        1168,
        732,
        11,
        309,
        5946,
        322,
        3088,
        11,
        575,
        1217,
        2351,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41327622532844543,
      "compression_ratio": 1.6796536445617676,
      "no_speech_prob": 0.19666896760463715
    },
    {
      "id": 75,
      "seek": 30200,
      "start": 311.0,
      "end": 315.0,
      "text": " does the use of AI increase the tendency?",
      "tokens": [
        50814,
        775,
        264,
        764,
        295,
        7318,
        3488,
        264,
        18187,
        30,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41327622532844543,
      "compression_ratio": 1.6796536445617676,
      "no_speech_prob": 0.19666896760463715
    },
    {
      "id": 76,
      "seek": 30200,
      "start": 315.0,
      "end": 317.0,
      "text": " I think these are two related questions.",
      "tokens": [
        51014,
        286,
        519,
        613,
        366,
        732,
        4077,
        1651,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41327622532844543,
      "compression_ratio": 1.6796536445617676,
      "no_speech_prob": 0.19666896760463715
    },
    {
      "id": 77,
      "seek": 30200,
      "start": 317.0,
      "end": 320.0,
      "text": " So once the question, does it help us at all if we do AI?",
      "tokens": [
        51114,
        407,
        1564,
        264,
        1168,
        11,
        775,
        309,
        854,
        505,
        412,
        439,
        498,
        321,
        360,
        7318,
        30,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41327622532844543,
      "compression_ratio": 1.6796536445617676,
      "no_speech_prob": 0.19666896760463715
    },
    {
      "id": 78,
      "seek": 30200,
      "start": 320.0,
      "end": 325.0,
      "text": " And then AI somehow leads to this thing getting worse.",
      "tokens": [
        51264,
        400,
        550,
        7318,
        6063,
        6689,
        281,
        341,
        551,
        1242,
        5324,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41327622532844543,
      "compression_ratio": 1.6796536445617676,
      "no_speech_prob": 0.19666896760463715
    },
    {
      "id": 79,
      "seek": 30200,
      "start": 325.0,
      "end": 327.0,
      "text": " So that this share is getting worse.",
      "tokens": [
        51514,
        407,
        300,
        341,
        2073,
        307,
        1242,
        5324,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41327622532844543,
      "compression_ratio": 1.6796536445617676,
      "no_speech_prob": 0.19666896760463715
    },
    {
      "id": 80,
      "seek": 30200,
      "start": 327.0,
      "end": 329.0,
      "text": " So it always gets worse.",
      "tokens": [
        51614,
        407,
        309,
        1009,
        2170,
        5324,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41327622532844543,
      "compression_ratio": 1.6796536445617676,
      "no_speech_prob": 0.19666896760463715
    },
    {
      "id": 81,
      "seek": 32900,
      "start": 329.0,
      "end": 334.0,
      "text": " So, as I said, it's exploding.",
      "tokens": [
        50364,
        407,
        11,
        382,
        286,
        848,
        11,
        309,
        311,
        35175,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.329626202583313,
      "compression_ratio": 1.5245097875595093,
      "no_speech_prob": 0.03810315206646919
    },
    {
      "id": 82,
      "seek": 32900,
      "start": 334.0,
      "end": 337.0,
      "text": " And AI is also part of the software development.",
      "tokens": [
        50614,
        400,
        7318,
        307,
        611,
        644,
        295,
        264,
        4722,
        3250,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.329626202583313,
      "compression_ratio": 1.5245097875595093,
      "no_speech_prob": 0.03810315206646919
    },
    {
      "id": 83,
      "seek": 32900,
      "start": 337.0,
      "end": 345.0,
      "text": " So it's not a law that these LLMs consume such gigantic amounts of energy and resources.",
      "tokens": [
        50764,
        407,
        309,
        311,
        406,
        257,
        2101,
        300,
        613,
        441,
        43,
        26386,
        14732,
        1270,
        26800,
        11663,
        295,
        2281,
        293,
        3593,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.329626202583313,
      "compression_ratio": 1.5245097875595093,
      "no_speech_prob": 0.03810315206646919
    },
    {
      "id": 84,
      "seek": 32900,
      "start": 345.0,
      "end": 347.0,
      "text": " It works differently.",
      "tokens": [
        51164,
        467,
        1985,
        7614,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.329626202583313,
      "compression_ratio": 1.5245097875595093,
      "no_speech_prob": 0.03810315206646919
    },
    {
      "id": 85,
      "seek": 32900,
      "start": 347.0,
      "end": 349.0,
      "text": " We also have the small models.",
      "tokens": [
        51264,
        492,
        611,
        362,
        264,
        1359,
        5245,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.329626202583313,
      "compression_ratio": 1.5245097875595093,
      "no_speech_prob": 0.03810315206646919
    },
    {
      "id": 86,
      "seek": 32900,
      "start": 349.0,
      "end": 352.0,
      "text": " So that's not a law of nature.",
      "tokens": [
        51364,
        407,
        300,
        311,
        406,
        257,
        2101,
        295,
        3687,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.329626202583313,
      "compression_ratio": 1.5245097875595093,
      "no_speech_prob": 0.03810315206646919
    },
    {
      "id": 87,
      "seek": 32900,
      "start": 352.0,
      "end": 354.0,
      "text": " That's the way it is.",
      "tokens": [
        51514,
        663,
        311,
        264,
        636,
        309,
        307,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.329626202583313,
      "compression_ratio": 1.5245097875595093,
      "no_speech_prob": 0.03810315206646919
    },
    {
      "id": 88,
      "seek": 32900,
      "start": 354.0,
      "end": 357.0,
      "text": " And yes, we also have crypto mining.",
      "tokens": [
        51614,
        400,
        2086,
        11,
        321,
        611,
        362,
        17240,
        15512,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.329626202583313,
      "compression_ratio": 1.5245097875595093,
      "no_speech_prob": 0.03810315206646919
    },
    {
      "id": 89,
      "seek": 35700,
      "start": 358.0,
      "end": 362.0,
      "text": " We have a lot of cat pictures on the net.",
      "tokens": [
        50414,
        492,
        362,
        257,
        688,
        295,
        3857,
        5242,
        322,
        264,
        2533,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43811628222465515,
      "compression_ratio": 1.396226406097412,
      "no_speech_prob": 0.022797677665948868
    },
    {
      "id": 90,
      "seek": 35700,
      "start": 363.0,
      "end": 366.0,
      "text": " So TikTok and so on, you can question everything.",
      "tokens": [
        50664,
        407,
        20211,
        293,
        370,
        322,
        11,
        291,
        393,
        1168,
        1203,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43811628222465515,
      "compression_ratio": 1.396226406097412,
      "no_speech_prob": 0.022797677665948868
    },
    {
      "id": 91,
      "seek": 35700,
      "start": 367.0,
      "end": 374.0,
      "text": " But that's no use.",
      "tokens": [
        50864,
        583,
        300,
        311,
        572,
        764,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43811628222465515,
      "compression_ratio": 1.396226406097412,
      "no_speech_prob": 0.022797677665948868
    },
    {
      "id": 92,
      "seek": 35700,
      "start": 375.0,
      "end": 381.0,
      "text": " So that's always, so to speak, I can, this has such a feeling of helplessness.",
      "tokens": [
        51264,
        407,
        300,
        311,
        1009,
        11,
        370,
        281,
        1710,
        11,
        286,
        393,
        11,
        341,
        575,
        1270,
        257,
        2633,
        295,
        27596,
        1287,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43811628222465515,
      "compression_ratio": 1.396226406097412,
      "no_speech_prob": 0.022797677665948868
    },
    {
      "id": 93,
      "seek": 35700,
      "start": 381.0,
      "end": 383.0,
      "text": " And in fact, it's not like that.",
      "tokens": [
        51564,
        400,
        294,
        1186,
        11,
        309,
        311,
        406,
        411,
        300,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43811628222465515,
      "compression_ratio": 1.396226406097412,
      "no_speech_prob": 0.022797677665948868
    },
    {
      "id": 94,
      "seek": 38300,
      "start": 383.0,
      "end": 388.0,
      "text": " So these 4 percent, AI is not really in there yet.",
      "tokens": [
        50364,
        407,
        613,
        1017,
        3043,
        11,
        7318,
        307,
        406,
        534,
        294,
        456,
        1939,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4250752925872803,
      "compression_ratio": 1.5664739608764648,
      "no_speech_prob": 0.031871065497398376
    },
    {
      "id": 95,
      "seek": 38300,
      "start": 388.0,
      "end": 390.0,
      "text": " So that's increasing.",
      "tokens": [
        50614,
        407,
        300,
        311,
        5662,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4250752925872803,
      "compression_ratio": 1.5664739608764648,
      "no_speech_prob": 0.031871065497398376
    },
    {
      "id": 96,
      "seek": 38300,
      "start": 390.0,
      "end": 392.0,
      "text": " And AI is not really there yet.",
      "tokens": [
        50714,
        400,
        7318,
        307,
        406,
        534,
        456,
        1939,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4250752925872803,
      "compression_ratio": 1.5664739608764648,
      "no_speech_prob": 0.031871065497398376
    },
    {
      "id": 97,
      "seek": 38300,
      "start": 392.0,
      "end": 396.0,
      "text": " So we do have this massive expansion.",
      "tokens": [
        50814,
        407,
        321,
        360,
        362,
        341,
        5994,
        11260,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4250752925872803,
      "compression_ratio": 1.5664739608764648,
      "no_speech_prob": 0.031871065497398376
    },
    {
      "id": 98,
      "seek": 38300,
      "start": 396.0,
      "end": 401.0,
      "text": " But these three, these LLMs, Tata and Business.",
      "tokens": [
        51014,
        583,
        613,
        1045,
        11,
        613,
        441,
        43,
        26386,
        11,
        314,
        3274,
        293,
        10715,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4250752925872803,
      "compression_ratio": 1.5664739608764648,
      "no_speech_prob": 0.031871065497398376
    },
    {
      "id": 99,
      "seek": 38300,
      "start": 401.0,
      "end": 403.0,
      "text": " That's not AI yet.",
      "tokens": [
        51264,
        663,
        311,
        406,
        7318,
        1939,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4250752925872803,
      "compression_ratio": 1.5664739608764648,
      "no_speech_prob": 0.031871065497398376
    },
    {
      "id": 100,
      "seek": 38300,
      "start": 404.0,
      "end": 412.0,
      "text": " And overall, the IT sector is responsible for making it less.",
      "tokens": [
        51414,
        400,
        4787,
        11,
        264,
        6783,
        6977,
        307,
        6250,
        337,
        1455,
        309,
        1570,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4250752925872803,
      "compression_ratio": 1.5664739608764648,
      "no_speech_prob": 0.031871065497398376
    },
    {
      "id": 101,
      "seek": 41200,
      "start": 413.0,
      "end": 416.0,
      "text": " And if we have to do something with AI, we do it with AI.",
      "tokens": [
        50414,
        400,
        498,
        321,
        362,
        281,
        360,
        746,
        365,
        7318,
        11,
        321,
        360,
        309,
        365,
        7318,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2878386080265045,
      "compression_ratio": 1.7590909004211426,
      "no_speech_prob": 0.04743588715791702
    },
    {
      "id": 102,
      "seek": 41200,
      "start": 416.0,
      "end": 419.0,
      "text": " If we have to do something in B2B, we do it in B2B.",
      "tokens": [
        50564,
        759,
        321,
        362,
        281,
        360,
        746,
        294,
        363,
        17,
        33,
        11,
        321,
        360,
        309,
        294,
        363,
        17,
        33,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2878386080265045,
      "compression_ratio": 1.7590909004211426,
      "no_speech_prob": 0.04743588715791702
    },
    {
      "id": 103,
      "seek": 41200,
      "start": 419.0,
      "end": 421.0,
      "text": " And if we are in B2C, we do it in B2C.",
      "tokens": [
        50714,
        400,
        498,
        321,
        366,
        294,
        363,
        17,
        34,
        11,
        321,
        360,
        309,
        294,
        363,
        17,
        34,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2878386080265045,
      "compression_ratio": 1.7590909004211426,
      "no_speech_prob": 0.04743588715791702
    },
    {
      "id": 104,
      "seek": 41200,
      "start": 421.0,
      "end": 423.0,
      "text": " So all areas are then.",
      "tokens": [
        50814,
        407,
        439,
        3179,
        366,
        550,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2878386080265045,
      "compression_ratio": 1.7590909004211426,
      "no_speech_prob": 0.04743588715791702
    },
    {
      "id": 105,
      "seek": 41200,
      "start": 423.0,
      "end": 425.0,
      "text": " But it's always about software.",
      "tokens": [
        50914,
        583,
        309,
        311,
        1009,
        466,
        4722,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2878386080265045,
      "compression_ratio": 1.7590909004211426,
      "no_speech_prob": 0.04743588715791702
    },
    {
      "id": 106,
      "seek": 41200,
      "start": 425.0,
      "end": 429.0,
      "text": " And I think a little bit from our previous conversation,",
      "tokens": [
        51014,
        400,
        286,
        519,
        257,
        707,
        857,
        490,
        527,
        659,
        4917,
        563,
        3761,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2878386080265045,
      "compression_ratio": 1.7590909004211426,
      "no_speech_prob": 0.04743588715791702
    },
    {
      "id": 107,
      "seek": 41200,
      "start": 429.0,
      "end": 435.0,
      "text": " I also remember that you said that this is the area that we can influence immediately.",
      "tokens": [
        51214,
        286,
        611,
        1604,
        300,
        291,
        848,
        300,
        341,
        307,
        264,
        1859,
        300,
        321,
        393,
        6503,
        4258,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2878386080265045,
      "compression_ratio": 1.7590909004211426,
      "no_speech_prob": 0.04743588715791702
    },
    {
      "id": 108,
      "seek": 41200,
      "start": 435.0,
      "end": 438.0,
      "text": " And I think that's an important aspect.",
      "tokens": [
        51514,
        400,
        286,
        519,
        300,
        311,
        364,
        1021,
        4171,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2878386080265045,
      "compression_ratio": 1.7590909004211426,
      "no_speech_prob": 0.04743588715791702
    },
    {
      "id": 109,
      "seek": 43800,
      "start": 439.0,
      "end": 445.0,
      "text": " And I think there is also an association in it,",
      "tokens": [
        50414,
        400,
        286,
        519,
        456,
        307,
        611,
        364,
        14598,
        294,
        309,
        11,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4055408239364624,
      "compression_ratio": 1.6150000095367432,
      "no_speech_prob": 0.02839506044983864
    },
    {
      "id": 110,
      "seek": 43800,
      "start": 445.0,
      "end": 448.0,
      "text": " when you say green software developer, green software,",
      "tokens": [
        50714,
        562,
        291,
        584,
        3092,
        4722,
        10754,
        11,
        3092,
        4722,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4055408239364624,
      "compression_ratio": 1.6150000095367432,
      "no_speech_prob": 0.02839506044983864
    },
    {
      "id": 111,
      "seek": 43800,
      "start": 448.0,
      "end": 453.0,
      "text": " that you have a lot of attention to code and code optimization.",
      "tokens": [
        50864,
        300,
        291,
        362,
        257,
        688,
        295,
        3202,
        281,
        3089,
        293,
        3089,
        19618,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4055408239364624,
      "compression_ratio": 1.6150000095367432,
      "no_speech_prob": 0.02839506044983864
    },
    {
      "id": 112,
      "seek": 43800,
      "start": 455.0,
      "end": 459.0,
      "text": " So also in the demarcation, for example, to green IT,",
      "tokens": [
        51214,
        407,
        611,
        294,
        264,
        1371,
        40088,
        399,
        11,
        337,
        1365,
        11,
        281,
        3092,
        6783,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4055408239364624,
      "compression_ratio": 1.6150000095367432,
      "no_speech_prob": 0.02839506044983864
    },
    {
      "id": 113,
      "seek": 43800,
      "start": 459.0,
      "end": 462.0,
      "text": " where we say a focus on hardware,",
      "tokens": [
        51414,
        689,
        321,
        584,
        257,
        1879,
        322,
        8837,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4055408239364624,
      "compression_ratio": 1.6150000095367432,
      "no_speech_prob": 0.02839506044983864
    },
    {
      "id": 114,
      "seek": 43800,
      "start": 462.0,
      "end": 467.0,
      "text": " that hardware is designed more efficiently or refurbished and so on.",
      "tokens": [
        51564,
        300,
        8837,
        307,
        4761,
        544,
        19621,
        420,
        1895,
        16659,
        4729,
        293,
        370,
        322,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4055408239364624,
      "compression_ratio": 1.6150000095367432,
      "no_speech_prob": 0.02839506044983864
    },
    {
      "id": 115,
      "seek": 46800,
      "start": 468.0,
      "end": 470.0,
      "text": " But actually it's all the same.",
      "tokens": [
        50364,
        583,
        767,
        309,
        311,
        439,
        264,
        912,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.290679931640625,
      "compression_ratio": 1.7044334411621094,
      "no_speech_prob": 0.002967336680740118
    },
    {
      "id": 116,
      "seek": 46800,
      "start": 470.0,
      "end": 473.0,
      "text": " So when you say green IT, green coding, green software,",
      "tokens": [
        50464,
        407,
        562,
        291,
        584,
        3092,
        6783,
        11,
        3092,
        17720,
        11,
        3092,
        4722,
        11,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.290679931640625,
      "compression_ratio": 1.7044334411621094,
      "no_speech_prob": 0.002967336680740118
    },
    {
      "id": 117,
      "seek": 46800,
      "start": 473.0,
      "end": 475.0,
      "text": " green software development, green software design,",
      "tokens": [
        50614,
        3092,
        4722,
        3250,
        11,
        3092,
        4722,
        1715,
        11,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.290679931640625,
      "compression_ratio": 1.7044334411621094,
      "no_speech_prob": 0.002967336680740118
    },
    {
      "id": 118,
      "seek": 46800,
      "start": 475.0,
      "end": 482.0,
      "text": " these are all keywords that all start at the same time.",
      "tokens": [
        50714,
        613,
        366,
        439,
        21009,
        300,
        439,
        722,
        412,
        264,
        912,
        565,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.290679931640625,
      "compression_ratio": 1.7044334411621094,
      "no_speech_prob": 0.002967336680740118
    },
    {
      "id": 119,
      "seek": 46800,
      "start": 482.0,
      "end": 487.0,
      "text": " Namely, the beginning of the chain are requirements that come from the software.",
      "tokens": [
        51064,
        10684,
        736,
        11,
        264,
        2863,
        295,
        264,
        5021,
        366,
        7728,
        300,
        808,
        490,
        264,
        4722,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.290679931640625,
      "compression_ratio": 1.7044334411621094,
      "no_speech_prob": 0.002967336680740118
    },
    {
      "id": 120,
      "seek": 46800,
      "start": 488.0,
      "end": 494.0,
      "text": " And the software itself, as I said, has no mission, but is a computer.",
      "tokens": [
        51364,
        400,
        264,
        4722,
        2564,
        11,
        382,
        286,
        848,
        11,
        575,
        572,
        4447,
        11,
        457,
        307,
        257,
        3820,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.290679931640625,
      "compression_ratio": 1.7044334411621094,
      "no_speech_prob": 0.002967336680740118
    },
    {
      "id": 121,
      "seek": 49400,
      "start": 494.0,
      "end": 498.0,
      "text": " And the question is, how do we actually operate our software?",
      "tokens": [
        50364,
        400,
        264,
        1168,
        307,
        11,
        577,
        360,
        321,
        767,
        9651,
        527,
        4722,
        30,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3495710790157318,
      "compression_ratio": 1.674008846282959,
      "no_speech_prob": 0.02769978903234005
    },
    {
      "id": 122,
      "seek": 49400,
      "start": 498.0,
      "end": 501.0,
      "text": " How do we operate the AI?",
      "tokens": [
        50564,
        1012,
        360,
        321,
        9651,
        264,
        7318,
        30,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3495710790157318,
      "compression_ratio": 1.674008846282959,
      "no_speech_prob": 0.02769978903234005
    },
    {
      "id": 123,
      "seek": 49400,
      "start": 501.0,
      "end": 505.0,
      "text": " And how do we just do everything?",
      "tokens": [
        50714,
        400,
        577,
        360,
        321,
        445,
        360,
        1203,
        30,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3495710790157318,
      "compression_ratio": 1.674008846282959,
      "no_speech_prob": 0.02769978903234005
    },
    {
      "id": 124,
      "seek": 49400,
      "start": 505.0,
      "end": 508.0,
      "text": " So in the end, it's about producing software and then operating software.",
      "tokens": [
        50914,
        407,
        294,
        264,
        917,
        11,
        309,
        311,
        466,
        10501,
        4722,
        293,
        550,
        7447,
        4722,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3495710790157318,
      "compression_ratio": 1.674008846282959,
      "no_speech_prob": 0.02769978903234005
    },
    {
      "id": 125,
      "seek": 49400,
      "start": 508.0,
      "end": 511.0,
      "text": " And we have an awful lot of options.",
      "tokens": [
        51064,
        400,
        321,
        362,
        364,
        11232,
        688,
        295,
        3956,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3495710790157318,
      "compression_ratio": 1.674008846282959,
      "no_speech_prob": 0.02769978903234005
    },
    {
      "id": 126,
      "seek": 49400,
      "start": 511.0,
      "end": 515.0,
      "text": " And we haven't even touched on the requirements yet.",
      "tokens": [
        51214,
        400,
        321,
        2378,
        380,
        754,
        9828,
        322,
        264,
        7728,
        1939,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3495710790157318,
      "compression_ratio": 1.674008846282959,
      "no_speech_prob": 0.02769978903234005
    },
    {
      "id": 127,
      "seek": 49400,
      "start": 515.0,
      "end": 517.0,
      "text": " What do you want to have?",
      "tokens": [
        51414,
        708,
        360,
        291,
        528,
        281,
        362,
        30,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3495710790157318,
      "compression_ratio": 1.674008846282959,
      "no_speech_prob": 0.02769978903234005
    },
    {
      "id": 128,
      "seek": 49400,
      "start": 518.0,
      "end": 523.0,
      "text": " But I think if you take the focus away from grinding and optimizing,",
      "tokens": [
        51564,
        583,
        286,
        519,
        498,
        291,
        747,
        264,
        1879,
        1314,
        490,
        25300,
        293,
        40425,
        11,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3495710790157318,
      "compression_ratio": 1.674008846282959,
      "no_speech_prob": 0.02769978903234005
    },
    {
      "id": 129,
      "seek": 52300,
      "start": 523.0,
      "end": 530.0,
      "text": " I think you already understand why both AI and our normal profession,",
      "tokens": [
        50364,
        286,
        519,
        291,
        1217,
        1223,
        983,
        1293,
        7318,
        293,
        527,
        2710,
        7032,
        11,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3961765468120575,
      "compression_ratio": 1.7100372314453125,
      "no_speech_prob": 0.006945089902728796
    },
    {
      "id": 130,
      "seek": 52300,
      "start": 530.0,
      "end": 533.0,
      "text": " be it architecture or something like that, play a role.",
      "tokens": [
        50714,
        312,
        309,
        9482,
        420,
        746,
        411,
        300,
        11,
        862,
        257,
        3090,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3961765468120575,
      "compression_ratio": 1.7100372314453125,
      "no_speech_prob": 0.006945089902728796
    },
    {
      "id": 131,
      "seek": 52300,
      "start": 533.0,
      "end": 536.0,
      "text": " So in the end, it's just a cross-sectional topic.",
      "tokens": [
        50864,
        407,
        294,
        264,
        917,
        11,
        309,
        311,
        445,
        257,
        3278,
        12,
        11963,
        304,
        4829,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3961765468120575,
      "compression_ratio": 1.7100372314453125,
      "no_speech_prob": 0.006945089902728796
    },
    {
      "id": 132,
      "seek": 52300,
      "start": 536.0,
      "end": 539.0,
      "text": " That's how I feel, where it's just about increasing efficiency.",
      "tokens": [
        51014,
        663,
        311,
        577,
        286,
        841,
        11,
        689,
        309,
        311,
        445,
        466,
        5662,
        10493,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3961765468120575,
      "compression_ratio": 1.7100372314453125,
      "no_speech_prob": 0.006945089902728796
    },
    {
      "id": 133,
      "seek": 52300,
      "start": 539.0,
      "end": 543.0,
      "text": " And so, how should I say, you can now somehow say,",
      "tokens": [
        51164,
        400,
        370,
        11,
        577,
        820,
        286,
        584,
        11,
        291,
        393,
        586,
        6063,
        584,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3961765468120575,
      "compression_ratio": 1.7100372314453125,
      "no_speech_prob": 0.006945089902728796
    },
    {
      "id": 134,
      "seek": 52300,
      "start": 543.0,
      "end": 545.0,
      "text": " so I think that's what you're saying,",
      "tokens": [
        51364,
        370,
        286,
        519,
        300,
        311,
        437,
        291,
        434,
        1566,
        11,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3961765468120575,
      "compression_ratio": 1.7100372314453125,
      "no_speech_prob": 0.006945089902728796
    },
    {
      "id": 135,
      "seek": 52300,
      "start": 545.0,
      "end": 547.0,
      "text": " you can now say the requirements in the direction of AI,",
      "tokens": [
        51464,
        291,
        393,
        586,
        584,
        264,
        7728,
        294,
        264,
        3513,
        295,
        7318,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3961765468120575,
      "compression_ratio": 1.7100372314453125,
      "no_speech_prob": 0.006945089902728796
    },
    {
      "id": 136,
      "seek": 52300,
      "start": 547.0,
      "end": 549.0,
      "text": " that you want to have something like that,",
      "tokens": [
        51564,
        300,
        291,
        528,
        281,
        362,
        746,
        411,
        300,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3961765468120575,
      "compression_ratio": 1.7100372314453125,
      "no_speech_prob": 0.006945089902728796
    },
    {
      "id": 137,
      "seek": 52300,
      "start": 549.0,
      "end": 550.0,
      "text": " you can hardly ignore them now.",
      "tokens": [
        51664,
        291,
        393,
        13572,
        11200,
        552,
        586,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3961765468120575,
      "compression_ratio": 1.7100372314453125,
      "no_speech_prob": 0.006945089902728796
    },
    {
      "id": 138,
      "seek": 55000,
      "start": 550.0,
      "end": 553.0,
      "text": " But we can try to make it more efficient.",
      "tokens": [
        50364,
        583,
        321,
        393,
        853,
        281,
        652,
        309,
        544,
        7148,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4409397542476654,
      "compression_ratio": 1.5807859897613525,
      "no_speech_prob": 0.11398500949144363
    },
    {
      "id": 139,
      "seek": 55000,
      "start": 553.0,
      "end": 557.0,
      "text": " And then it's just more of a spur that something is still happening.",
      "tokens": [
        50514,
        400,
        550,
        309,
        311,
        445,
        544,
        295,
        257,
        35657,
        300,
        746,
        307,
        920,
        2737,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4409397542476654,
      "compression_ratio": 1.5807859897613525,
      "no_speech_prob": 0.11398500949144363
    },
    {
      "id": 140,
      "seek": 55000,
      "start": 557.0,
      "end": 559.0,
      "text": " There is also a movement.",
      "tokens": [
        50714,
        821,
        307,
        611,
        257,
        3963,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4409397542476654,
      "compression_ratio": 1.5807859897613525,
      "no_speech_prob": 0.11398500949144363
    },
    {
      "id": 141,
      "seek": 55000,
      "start": 559.0,
      "end": 562.0,
      "text": " It's not that people are not interested in it.",
      "tokens": [
        50814,
        467,
        311,
        406,
        300,
        561,
        366,
        406,
        3102,
        294,
        309,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4409397542476654,
      "compression_ratio": 1.5807859897613525,
      "no_speech_prob": 0.11398500949144363
    },
    {
      "id": 142,
      "seek": 55000,
      "start": 562.0,
      "end": 564.0,
      "text": " But it's also expensive.",
      "tokens": [
        50964,
        583,
        309,
        311,
        611,
        5124,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4409397542476654,
      "compression_ratio": 1.5807859897613525,
      "no_speech_prob": 0.11398500949144363
    },
    {
      "id": 143,
      "seek": 55000,
      "start": 564.0,
      "end": 567.0,
      "text": " Now another question.",
      "tokens": [
        51064,
        823,
        1071,
        1168,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4409397542476654,
      "compression_ratio": 1.5807859897613525,
      "no_speech_prob": 0.11398500949144363
    },
    {
      "id": 144,
      "seek": 55000,
      "start": 567.0,
      "end": 570.0,
      "text": " I always find the questions from the chat very exciting.",
      "tokens": [
        51214,
        286,
        1009,
        915,
        264,
        1651,
        490,
        264,
        5081,
        588,
        4670,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4409397542476654,
      "compression_ratio": 1.5807859897613525,
      "no_speech_prob": 0.11398500949144363
    },
    {
      "id": 145,
      "seek": 55000,
      "start": 570.0,
      "end": 574.0,
      "text": " It's a bit surprising for me.",
      "tokens": [
        51364,
        467,
        311,
        257,
        857,
        8830,
        337,
        385,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4409397542476654,
      "compression_ratio": 1.5807859897613525,
      "no_speech_prob": 0.11398500949144363
    },
    {
      "id": 146,
      "seek": 55000,
      "start": 574.0,
      "end": 576.0,
      "text": " I don't know if you'll answer it right away.",
      "tokens": [
        51564,
        286,
        500,
        380,
        458,
        498,
        291,
        603,
        1867,
        309,
        558,
        1314,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4409397542476654,
      "compression_ratio": 1.5807859897613525,
      "no_speech_prob": 0.11398500949144363
    },
    {
      "id": 147,
      "seek": 57600,
      "start": 576.0,
      "end": 579.0,
      "text": " Is open source tend to be the greener software?",
      "tokens": [
        50364,
        1119,
        1269,
        4009,
        535,
        273,
        281,
        312,
        264,
        3092,
        260,
        4722,
        30,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4529935419559479,
      "compression_ratio": 1.4137930870056152,
      "no_speech_prob": 0.5075626969337463
    },
    {
      "id": 148,
      "seek": 57600,
      "start": 585.0,
      "end": 587.0,
      "text": " I think it's about the business model.",
      "tokens": [
        50814,
        286,
        519,
        309,
        311,
        466,
        264,
        1606,
        2316,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4529935419559479,
      "compression_ratio": 1.4137930870056152,
      "no_speech_prob": 0.5075626969337463
    },
    {
      "id": 149,
      "seek": 57600,
      "start": 587.0,
      "end": 590.0,
      "text": " Not about the code.",
      "tokens": [
        50914,
        1726,
        466,
        264,
        3089,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4529935419559479,
      "compression_ratio": 1.4137930870056152,
      "no_speech_prob": 0.5075626969337463
    },
    {
      "id": 150,
      "seek": 57600,
      "start": 590.0,
      "end": 593.0,
      "text": " First of all, not.",
      "tokens": [
        51064,
        2386,
        295,
        439,
        11,
        406,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4529935419559479,
      "compression_ratio": 1.4137930870056152,
      "no_speech_prob": 0.5075626969337463
    },
    {
      "id": 151,
      "seek": 57600,
      "start": 593.0,
      "end": 594.0,
      "text": " No.",
      "tokens": [
        51214,
        883,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4529935419559479,
      "compression_ratio": 1.4137930870056152,
      "no_speech_prob": 0.5075626969337463
    },
    {
      "id": 152,
      "seek": 57600,
      "start": 597.0,
      "end": 600.0,
      "text": " I think I'll have to pick it up for a moment.",
      "tokens": [
        51414,
        286,
        519,
        286,
        603,
        362,
        281,
        1888,
        309,
        493,
        337,
        257,
        1623,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4529935419559479,
      "compression_ratio": 1.4137930870056152,
      "no_speech_prob": 0.5075626969337463
    },
    {
      "id": 153,
      "seek": 57600,
      "start": 600.0,
      "end": 602.0,
      "text": " I'll pick up what's going on.",
      "tokens": [
        51564,
        286,
        603,
        1888,
        493,
        437,
        311,
        516,
        322,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4529935419559479,
      "compression_ratio": 1.4137930870056152,
      "no_speech_prob": 0.5075626969337463
    },
    {
      "id": 154,
      "seek": 60200,
      "start": 603.0,
      "end": 606.0,
      "text": " If we just look at the sources of emissions,",
      "tokens": [
        50414,
        759,
        321,
        445,
        574,
        412,
        264,
        7139,
        295,
        14607,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4319019019603729,
      "compression_ratio": 1.7305935621261597,
      "no_speech_prob": 0.03597653657197952
    },
    {
      "id": 155,
      "seek": 60200,
      "start": 606.0,
      "end": 609.0,
      "text": " then it is so that we are on one,",
      "tokens": [
        50564,
        550,
        309,
        307,
        370,
        300,
        321,
        366,
        322,
        472,
        11,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4319019019603729,
      "compression_ratio": 1.7305935621261597,
      "no_speech_prob": 0.03597653657197952
    },
    {
      "id": 156,
      "seek": 60200,
      "start": 609.0,
      "end": 612.0,
      "text": " so you can just divide it,",
      "tokens": [
        50714,
        370,
        291,
        393,
        445,
        9845,
        309,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4319019019603729,
      "compression_ratio": 1.7305935621261597,
      "no_speech_prob": 0.03597653657197952
    },
    {
      "id": 157,
      "seek": 60200,
      "start": 612.0,
      "end": 615.0,
      "text": " 30, 50 percent or something,",
      "tokens": [
        50864,
        2217,
        11,
        2625,
        3043,
        420,
        746,
        11,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4319019019603729,
      "compression_ratio": 1.7305935621261597,
      "no_speech_prob": 0.03597653657197952
    },
    {
      "id": 158,
      "seek": 60200,
      "start": 615.0,
      "end": 618.0,
      "text": " of the emissions, of the total emissions of the software,",
      "tokens": [
        51014,
        295,
        264,
        14607,
        11,
        295,
        264,
        3217,
        14607,
        295,
        264,
        4722,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4319019019603729,
      "compression_ratio": 1.7305935621261597,
      "no_speech_prob": 0.03597653657197952
    },
    {
      "id": 159,
      "seek": 60200,
      "start": 618.0,
      "end": 619.0,
      "text": " they have already arisen.",
      "tokens": [
        51164,
        436,
        362,
        1217,
        594,
        11106,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4319019019603729,
      "compression_ratio": 1.7305935621261597,
      "no_speech_prob": 0.03597653657197952
    },
    {
      "id": 160,
      "seek": 60200,
      "start": 619.0,
      "end": 621.0,
      "text": " Because you provide hardware,",
      "tokens": [
        51214,
        1436,
        291,
        2893,
        8837,
        11,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4319019019603729,
      "compression_ratio": 1.7305935621261597,
      "no_speech_prob": 0.03597653657197952
    },
    {
      "id": 161,
      "seek": 60200,
      "start": 621.0,
      "end": 622.0,
      "text": " because you have built hardware,",
      "tokens": [
        51314,
        570,
        291,
        362,
        3094,
        8837,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4319019019603729,
      "compression_ratio": 1.7305935621261597,
      "no_speech_prob": 0.03597653657197952
    },
    {
      "id": 162,
      "seek": 60200,
      "start": 622.0,
      "end": 625.0,
      "text": " you have produced cables for the networks,",
      "tokens": [
        51364,
        291,
        362,
        7126,
        17555,
        337,
        264,
        9590,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4319019019603729,
      "compression_ratio": 1.7305935621261597,
      "no_speech_prob": 0.03597653657197952
    },
    {
      "id": 163,
      "seek": 60200,
      "start": 625.0,
      "end": 628.0,
      "text": " the switches, the computers, the whole thing, cooling.",
      "tokens": [
        51514,
        264,
        19458,
        11,
        264,
        10807,
        11,
        264,
        1379,
        551,
        11,
        14785,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4319019019603729,
      "compression_ratio": 1.7305935621261597,
      "no_speech_prob": 0.03597653657197952
    },
    {
      "id": 164,
      "seek": 62800,
      "start": 629.0,
      "end": 631.0,
      "text": " And on the other hand,",
      "tokens": [
        50414,
        400,
        322,
        264,
        661,
        1011,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4514428675174713,
      "compression_ratio": 1.494505524635315,
      "no_speech_prob": 0.01609031669795513
    },
    {
      "id": 165,
      "seek": 62800,
      "start": 631.0,
      "end": 634.0,
      "text": " we have another 50, 70 percent of emissions",
      "tokens": [
        50514,
        321,
        362,
        1071,
        2625,
        11,
        5285,
        3043,
        295,
        14607,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4514428675174713,
      "compression_ratio": 1.494505524635315,
      "no_speech_prob": 0.01609031669795513
    },
    {
      "id": 166,
      "seek": 62800,
      "start": 634.0,
      "end": 637.0,
      "text": " that arise from the fact that I run the computer.",
      "tokens": [
        50664,
        300,
        20288,
        490,
        264,
        1186,
        300,
        286,
        1190,
        264,
        3820,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4514428675174713,
      "compression_ratio": 1.494505524635315,
      "no_speech_prob": 0.01609031669795513
    },
    {
      "id": 167,
      "seek": 62800,
      "start": 640.0,
      "end": 643.0,
      "text": " The role that is now here,",
      "tokens": [
        50964,
        440,
        3090,
        300,
        307,
        586,
        510,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4514428675174713,
      "compression_ratio": 1.494505524635315,
      "no_speech_prob": 0.01609031669795513
    },
    {
      "id": 168,
      "seek": 62800,
      "start": 643.0,
      "end": 645.0,
      "text": " even if I am open source,",
      "tokens": [
        51114,
        754,
        498,
        286,
        669,
        1269,
        4009,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4514428675174713,
      "compression_ratio": 1.494505524635315,
      "no_speech_prob": 0.01609031669795513
    },
    {
      "id": 169,
      "seek": 62800,
      "start": 645.0,
      "end": 648.0,
      "text": " I would just take the open source as a question.",
      "tokens": [
        51214,
        286,
        576,
        445,
        747,
        264,
        1269,
        4009,
        382,
        257,
        1168,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4514428675174713,
      "compression_ratio": 1.494505524635315,
      "no_speech_prob": 0.01609031669795513
    },
    {
      "id": 170,
      "seek": 62800,
      "start": 650.0,
      "end": 652.0,
      "text": " It actually has to do with",
      "tokens": [
        51464,
        467,
        767,
        575,
        281,
        360,
        365,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4514428675174713,
      "compression_ratio": 1.494505524635315,
      "no_speech_prob": 0.01609031669795513
    },
    {
      "id": 171,
      "seek": 62800,
      "start": 652.0,
      "end": 655.0,
      "text": " why I run software at all.",
      "tokens": [
        51564,
        983,
        286,
        1190,
        4722,
        412,
        439,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4514428675174713,
      "compression_ratio": 1.494505524635315,
      "no_speech_prob": 0.01609031669795513
    },
    {
      "id": 172,
      "seek": 65500,
      "start": 655.0,
      "end": 658.0,
      "text": " What is the background?",
      "tokens": [
        50364,
        708,
        307,
        264,
        3678,
        30,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37539833784103394,
      "compression_ratio": 1.541850209236145,
      "no_speech_prob": 0.003753241151571274
    },
    {
      "id": 173,
      "seek": 65500,
      "start": 658.0,
      "end": 663.0,
      "text": " And if you now have these two sources in mind",
      "tokens": [
        50514,
        400,
        498,
        291,
        586,
        362,
        613,
        732,
        7139,
        294,
        1575,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37539833784103394,
      "compression_ratio": 1.541850209236145,
      "no_speech_prob": 0.003753241151571274
    },
    {
      "id": 174,
      "seek": 65500,
      "start": 664.0,
      "end": 665.0,
      "text": " and say,",
      "tokens": [
        50814,
        293,
        584,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37539833784103394,
      "compression_ratio": 1.541850209236145,
      "no_speech_prob": 0.003753241151571274
    },
    {
      "id": 175,
      "seek": 65500,
      "start": 665.0,
      "end": 668.0,
      "text": " okay, I want to reduce the total emissions now,",
      "tokens": [
        50864,
        1392,
        11,
        286,
        528,
        281,
        5407,
        264,
        3217,
        14607,
        586,
        11,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37539833784103394,
      "compression_ratio": 1.541850209236145,
      "no_speech_prob": 0.003753241151571274
    },
    {
      "id": 176,
      "seek": 65500,
      "start": 668.0,
      "end": 671.0,
      "text": " then action fields arise.",
      "tokens": [
        51014,
        550,
        3069,
        7909,
        20288,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37539833784103394,
      "compression_ratio": 1.541850209236145,
      "no_speech_prob": 0.003753241151571274
    },
    {
      "id": 177,
      "seek": 65500,
      "start": 671.0,
      "end": 674.0,
      "text": " And these action fields,",
      "tokens": [
        51164,
        400,
        613,
        3069,
        7909,
        11,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37539833784103394,
      "compression_ratio": 1.541850209236145,
      "no_speech_prob": 0.003753241151571274
    },
    {
      "id": 178,
      "seek": 65500,
      "start": 674.0,
      "end": 676.0,
      "text": " you can divide them like this.",
      "tokens": [
        51314,
        291,
        393,
        9845,
        552,
        411,
        341,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37539833784103394,
      "compression_ratio": 1.541850209236145,
      "no_speech_prob": 0.003753241151571274
    },
    {
      "id": 179,
      "seek": 65500,
      "start": 676.0,
      "end": 678.0,
      "text": " Clever people have come up with ideas",
      "tokens": [
        51414,
        8834,
        331,
        561,
        362,
        808,
        493,
        365,
        3487,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37539833784103394,
      "compression_ratio": 1.541850209236145,
      "no_speech_prob": 0.003753241151571274
    },
    {
      "id": 180,
      "seek": 65500,
      "start": 678.0,
      "end": 679.0,
      "text": " to categorize it that way.",
      "tokens": [
        51514,
        281,
        19250,
        1125,
        309,
        300,
        636,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37539833784103394,
      "compression_ratio": 1.541850209236145,
      "no_speech_prob": 0.003753241151571274
    },
    {
      "id": 181,
      "seek": 65500,
      "start": 679.0,
      "end": 682.0,
      "text": " You talk about hardware and energy efficiency,",
      "tokens": [
        51564,
        509,
        751,
        466,
        8837,
        293,
        2281,
        10493,
        11,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37539833784103394,
      "compression_ratio": 1.541850209236145,
      "no_speech_prob": 0.003753241151571274
    },
    {
      "id": 182,
      "seek": 65500,
      "start": 682.0,
      "end": 683.0,
      "text": " I'll get to that in a moment.",
      "tokens": [
        51714,
        286,
        603,
        483,
        281,
        300,
        294,
        257,
        1623,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37539833784103394,
      "compression_ratio": 1.541850209236145,
      "no_speech_prob": 0.003753241151571274
    },
    {
      "id": 183,
      "seek": 68300,
      "start": 683.0,
      "end": 685.0,
      "text": " It's also about data efficiency",
      "tokens": [
        50364,
        467,
        311,
        611,
        466,
        1412,
        10493,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4162965416908264,
      "compression_ratio": 1.5462554693222046,
      "no_speech_prob": 0.04591987654566765
    },
    {
      "id": 184,
      "seek": 68300,
      "start": 685.0,
      "end": 687.0,
      "text": " and about this CO2 intensity,",
      "tokens": [
        50464,
        293,
        466,
        341,
        3002,
        17,
        13749,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4162965416908264,
      "compression_ratio": 1.5462554693222046,
      "no_speech_prob": 0.04591987654566765
    },
    {
      "id": 185,
      "seek": 68300,
      "start": 687.0,
      "end": 689.0,
      "text": " which is totally exciting.",
      "tokens": [
        50564,
        597,
        307,
        3879,
        4670,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4162965416908264,
      "compression_ratio": 1.5462554693222046,
      "no_speech_prob": 0.04591987654566765
    },
    {
      "id": 186,
      "seek": 68300,
      "start": 691.0,
      "end": 694.0,
      "text": " Every single one of these steps",
      "tokens": [
        50764,
        2048,
        2167,
        472,
        295,
        613,
        4439,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4162965416908264,
      "compression_ratio": 1.5462554693222046,
      "no_speech_prob": 0.04591987654566765
    },
    {
      "id": 187,
      "seek": 68300,
      "start": 694.0,
      "end": 697.0,
      "text": " has a massive need for optimization.",
      "tokens": [
        50914,
        575,
        257,
        5994,
        643,
        337,
        19618,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4162965416908264,
      "compression_ratio": 1.5462554693222046,
      "no_speech_prob": 0.04591987654566765
    },
    {
      "id": 188,
      "seek": 68300,
      "start": 699.0,
      "end": 701.0,
      "text": " There are a lot of experts here",
      "tokens": [
        51164,
        821,
        366,
        257,
        688,
        295,
        8572,
        510,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4162965416908264,
      "compression_ratio": 1.5462554693222046,
      "no_speech_prob": 0.04591987654566765
    },
    {
      "id": 189,
      "seek": 68300,
      "start": 701.0,
      "end": 703.0,
      "text": " and experts in the stream project,",
      "tokens": [
        51264,
        293,
        8572,
        294,
        264,
        4309,
        1716,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4162965416908264,
      "compression_ratio": 1.5462554693222046,
      "no_speech_prob": 0.04591987654566765
    },
    {
      "id": 190,
      "seek": 68300,
      "start": 703.0,
      "end": 704.0,
      "text": " they don't go straight to it.",
      "tokens": [
        51364,
        436,
        500,
        380,
        352,
        2997,
        281,
        309,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4162965416908264,
      "compression_ratio": 1.5462554693222046,
      "no_speech_prob": 0.04591987654566765
    },
    {
      "id": 191,
      "seek": 68300,
      "start": 704.0,
      "end": 705.0,
      "text": " But when I, for example,",
      "tokens": [
        51414,
        583,
        562,
        286,
        11,
        337,
        1365,
        11,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4162965416908264,
      "compression_ratio": 1.5462554693222046,
      "no_speech_prob": 0.04591987654566765
    },
    {
      "id": 192,
      "seek": 68300,
      "start": 705.0,
      "end": 706.0,
      "text": " the hardware efficiency,",
      "tokens": [
        51464,
        264,
        8837,
        10493,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4162965416908264,
      "compression_ratio": 1.5462554693222046,
      "no_speech_prob": 0.04591987654566765
    },
    {
      "id": 193,
      "seek": 68300,
      "start": 706.0,
      "end": 711.0,
      "text": " it's about using a maximum amount of hardware.",
      "tokens": [
        51514,
        309,
        311,
        466,
        1228,
        257,
        6674,
        2372,
        295,
        8837,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4162965416908264,
      "compression_ratio": 1.5462554693222046,
      "no_speech_prob": 0.04591987654566765
    },
    {
      "id": 194,
      "seek": 71100,
      "start": 711.0,
      "end": 714.0,
      "text": " That means as much software as possible",
      "tokens": [
        50364,
        663,
        1355,
        382,
        709,
        4722,
        382,
        1944,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36853229999542236,
      "compression_ratio": 1.5222222805023193,
      "no_speech_prob": 0.0127840805798769
    },
    {
      "id": 195,
      "seek": 71100,
      "start": 714.0,
      "end": 716.0,
      "text": " on a hardware point.",
      "tokens": [
        50514,
        322,
        257,
        8837,
        935,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36853229999542236,
      "compression_ratio": 1.5222222805023193,
      "no_speech_prob": 0.0127840805798769
    },
    {
      "id": 196,
      "seek": 71100,
      "start": 718.0,
      "end": 720.0,
      "text": " In German, server consolidation",
      "tokens": [
        50714,
        682,
        6521,
        11,
        7154,
        39114,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36853229999542236,
      "compression_ratio": 1.5222222805023193,
      "no_speech_prob": 0.0127840805798769
    },
    {
      "id": 197,
      "seek": 71100,
      "start": 720.0,
      "end": 721.0,
      "text": " and life extension.",
      "tokens": [
        50814,
        293,
        993,
        10320,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36853229999542236,
      "compression_ratio": 1.5222222805023193,
      "no_speech_prob": 0.0127840805798769
    },
    {
      "id": 198,
      "seek": 71100,
      "start": 721.0,
      "end": 723.0,
      "text": " So if I take a hardware",
      "tokens": [
        50864,
        407,
        498,
        286,
        747,
        257,
        8837,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36853229999542236,
      "compression_ratio": 1.5222222805023193,
      "no_speech_prob": 0.0127840805798769
    },
    {
      "id": 199,
      "seek": 71100,
      "start": 723.0,
      "end": 726.0,
      "text": " and instead of four, I do five or six,",
      "tokens": [
        50964,
        293,
        2602,
        295,
        1451,
        11,
        286,
        360,
        1732,
        420,
        2309,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36853229999542236,
      "compression_ratio": 1.5222222805023193,
      "no_speech_prob": 0.0127840805798769
    },
    {
      "id": 200,
      "seek": 71100,
      "start": 726.0,
      "end": 728.0,
      "text": " so from four to six,",
      "tokens": [
        51114,
        370,
        490,
        1451,
        281,
        2309,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36853229999542236,
      "compression_ratio": 1.5222222805023193,
      "no_speech_prob": 0.0127840805798769
    },
    {
      "id": 201,
      "seek": 71100,
      "start": 728.0,
      "end": 731.0,
      "text": " I actually halve the bound emissions.",
      "tokens": [
        51214,
        286,
        767,
        7523,
        303,
        264,
        5472,
        14607,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36853229999542236,
      "compression_ratio": 1.5222222805023193,
      "no_speech_prob": 0.0127840805798769
    },
    {
      "id": 202,
      "seek": 71100,
      "start": 732.0,
      "end": 736.0,
      "text": " If my open source software is so fluffy",
      "tokens": [
        51414,
        759,
        452,
        1269,
        4009,
        4722,
        307,
        370,
        5029,
        602,
        88,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36853229999542236,
      "compression_ratio": 1.5222222805023193,
      "no_speech_prob": 0.0127840805798769
    },
    {
      "id": 203,
      "seek": 73600,
      "start": 737.0,
      "end": 740.0,
      "text": " that if I, let's take Nextcloud,",
      "tokens": [
        50414,
        300,
        498,
        286,
        11,
        718,
        311,
        747,
        3087,
        44495,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39536428451538086,
      "compression_ratio": 1.4941176176071167,
      "no_speech_prob": 0.007984795607626438
    },
    {
      "id": 204,
      "seek": 73600,
      "start": 742.0,
      "end": 745.0,
      "text": " in contrast to Microsoft Office 365,",
      "tokens": [
        50664,
        294,
        8712,
        281,
        8116,
        8935,
        22046,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39536428451538086,
      "compression_ratio": 1.4941176176071167,
      "no_speech_prob": 0.007984795607626438
    },
    {
      "id": 205,
      "seek": 73600,
      "start": 747.0,
      "end": 749.0,
      "text": " if Nextcloud in each of its versions",
      "tokens": [
        50914,
        498,
        3087,
        44495,
        294,
        1184,
        295,
        1080,
        9606,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39536428451538086,
      "compression_ratio": 1.4941176176071167,
      "no_speech_prob": 0.007984795607626438
    },
    {
      "id": 206,
      "seek": 73600,
      "start": 749.0,
      "end": 751.0,
      "text": " makes sure that it still works",
      "tokens": [
        51014,
        1669,
        988,
        300,
        309,
        920,
        1985,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39536428451538086,
      "compression_ratio": 1.4941176176071167,
      "no_speech_prob": 0.007984795607626438
    },
    {
      "id": 207,
      "seek": 73600,
      "start": 751.0,
      "end": 753.0,
      "text": " with the old hardware,",
      "tokens": [
        51114,
        365,
        264,
        1331,
        8837,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39536428451538086,
      "compression_ratio": 1.4941176176071167,
      "no_speech_prob": 0.007984795607626438
    },
    {
      "id": 208,
      "seek": 73600,
      "start": 754.0,
      "end": 761.0,
      "text": " then it's greener than when new versions come out",
      "tokens": [
        51264,
        550,
        309,
        311,
        3092,
        260,
        813,
        562,
        777,
        9606,
        808,
        484,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39536428451538086,
      "compression_ratio": 1.4941176176071167,
      "no_speech_prob": 0.007984795607626438
    },
    {
      "id": 209,
      "seek": 73600,
      "start": 761.0,
      "end": 763.0,
      "text": " and the hardware has to deliver more power.",
      "tokens": [
        51614,
        293,
        264,
        8837,
        575,
        281,
        4239,
        544,
        1347,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39536428451538086,
      "compression_ratio": 1.4941176176071167,
      "no_speech_prob": 0.007984795607626438
    },
    {
      "id": 210,
      "seek": 76300,
      "start": 764.0,
      "end": 767.0,
      "text": " That doesn't necessarily depend on open source,",
      "tokens": [
        50414,
        663,
        1177,
        380,
        4725,
        5672,
        322,
        1269,
        4009,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3618673086166382,
      "compression_ratio": 1.546296238899231,
      "no_speech_prob": 0.012328664772212505
    },
    {
      "id": 211,
      "seek": 76300,
      "start": 769.0,
      "end": 771.0,
      "text": " but on what's in there.",
      "tokens": [
        50664,
        457,
        322,
        437,
        311,
        294,
        456,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3618673086166382,
      "compression_ratio": 1.546296238899231,
      "no_speech_prob": 0.012328664772212505
    },
    {
      "id": 212,
      "seek": 76300,
      "start": 772.0,
      "end": 774.0,
      "text": " And yes, for example,",
      "tokens": [
        50814,
        400,
        2086,
        11,
        337,
        1365,
        11,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3618673086166382,
      "compression_ratio": 1.546296238899231,
      "no_speech_prob": 0.012328664772212505
    },
    {
      "id": 213,
      "seek": 76300,
      "start": 774.0,
      "end": 777.0,
      "text": " LibreOffice, OpenOffice is more economical",
      "tokens": [
        50914,
        15834,
        265,
        29745,
        573,
        11,
        7238,
        29745,
        573,
        307,
        544,
        42473,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3618673086166382,
      "compression_ratio": 1.546296238899231,
      "no_speech_prob": 0.012328664772212505
    },
    {
      "id": 214,
      "seek": 76300,
      "start": 777.0,
      "end": 778.0,
      "text": " than Microsoft Office,",
      "tokens": [
        51064,
        813,
        8116,
        8935,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3618673086166382,
      "compression_ratio": 1.546296238899231,
      "no_speech_prob": 0.012328664772212505
    },
    {
      "id": 215,
      "seek": 76300,
      "start": 779.0,
      "end": 781.0,
      "text": " because a lot of business models",
      "tokens": [
        51164,
        570,
        257,
        688,
        295,
        1606,
        5245,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3618673086166382,
      "compression_ratio": 1.546296238899231,
      "no_speech_prob": 0.012328664772212505
    },
    {
      "id": 216,
      "seek": 76300,
      "start": 781.0,
      "end": 782.0,
      "text": " in a Microsoft Office",
      "tokens": [
        51264,
        294,
        257,
        8116,
        8935,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3618673086166382,
      "compression_ratio": 1.546296238899231,
      "no_speech_prob": 0.012328664772212505
    },
    {
      "id": 217,
      "seek": 76300,
      "start": 782.0,
      "end": 784.0,
      "text": " are also advertising and tracking.",
      "tokens": [
        51314,
        366,
        611,
        13097,
        293,
        11603,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3618673086166382,
      "compression_ratio": 1.546296238899231,
      "no_speech_prob": 0.012328664772212505
    },
    {
      "id": 218,
      "seek": 76300,
      "start": 785.0,
      "end": 786.0,
      "text": " Then it does performance",
      "tokens": [
        51464,
        1396,
        309,
        775,
        3389,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3618673086166382,
      "compression_ratio": 1.546296238899231,
      "no_speech_prob": 0.012328664772212505
    },
    {
      "id": 219,
      "seek": 76300,
      "start": 786.0,
      "end": 789.0,
      "text": " or some features that aren't in there.",
      "tokens": [
        51514,
        420,
        512,
        4122,
        300,
        3212,
        380,
        294,
        456,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3618673086166382,
      "compression_ratio": 1.546296238899231,
      "no_speech_prob": 0.012328664772212505
    },
    {
      "id": 220,
      "seek": 76300,
      "start": 789.0,
      "end": 791.0,
      "text": " So you can evaluate,",
      "tokens": [
        51664,
        407,
        291,
        393,
        13059,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3618673086166382,
      "compression_ratio": 1.546296238899231,
      "no_speech_prob": 0.012328664772212505
    },
    {
      "id": 221,
      "seek": 79100,
      "start": 791.0,
      "end": 793.0,
      "text": " I wouldn't want to make it partial.",
      "tokens": [
        50364,
        286,
        2759,
        380,
        528,
        281,
        652,
        309,
        14641,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34510210156440735,
      "compression_ratio": 1.4431818723678589,
      "no_speech_prob": 0.0029610125347971916
    },
    {
      "id": 222,
      "seek": 79100,
      "start": 794.0,
      "end": 796.0,
      "text": " But regardless of that,",
      "tokens": [
        50514,
        583,
        10060,
        295,
        300,
        11,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34510210156440735,
      "compression_ratio": 1.4431818723678589,
      "no_speech_prob": 0.0029610125347971916
    },
    {
      "id": 223,
      "seek": 79100,
      "start": 796.0,
      "end": 798.0,
      "text": " Nextcloud or Office 365,",
      "tokens": [
        50614,
        3087,
        44495,
        420,
        8935,
        22046,
        11,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34510210156440735,
      "compression_ratio": 1.4431818723678589,
      "no_speech_prob": 0.0029610125347971916
    },
    {
      "id": 224,
      "seek": 79100,
      "start": 799.0,
      "end": 801.0,
      "text": " we're talking about server consolidation",
      "tokens": [
        50764,
        321,
        434,
        1417,
        466,
        7154,
        39114,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34510210156440735,
      "compression_ratio": 1.4431818723678589,
      "no_speech_prob": 0.0029610125347971916
    },
    {
      "id": 225,
      "seek": 79100,
      "start": 802.0,
      "end": 805.0,
      "text": " or maximum server optimization.",
      "tokens": [
        50914,
        420,
        11469,
        332,
        449,
        7154,
        19618,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34510210156440735,
      "compression_ratio": 1.4431818723678589,
      "no_speech_prob": 0.0029610125347971916
    },
    {
      "id": 226,
      "seek": 79100,
      "start": 808.0,
      "end": 810.0,
      "text": " And it doesn't help at all",
      "tokens": [
        51214,
        400,
        309,
        1177,
        380,
        854,
        412,
        439,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34510210156440735,
      "compression_ratio": 1.4431818723678589,
      "no_speech_prob": 0.0029610125347971916
    },
    {
      "id": 227,
      "seek": 79100,
      "start": 810.0,
      "end": 812.0,
      "text": " if I take a server",
      "tokens": [
        51314,
        498,
        286,
        747,
        257,
        7154,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34510210156440735,
      "compression_ratio": 1.4431818723678589,
      "no_speech_prob": 0.0029610125347971916
    },
    {
      "id": 228,
      "seek": 79100,
      "start": 812.0,
      "end": 814.0,
      "text": " and run Nextcloud on it",
      "tokens": [
        51414,
        293,
        1190,
        3087,
        44495,
        322,
        309,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34510210156440735,
      "compression_ratio": 1.4431818723678589,
      "no_speech_prob": 0.0029610125347971916
    },
    {
      "id": 229,
      "seek": 79100,
      "start": 814.0,
      "end": 816.0,
      "text": " and the server gets bored.",
      "tokens": [
        51514,
        293,
        264,
        7154,
        2170,
        13521,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34510210156440735,
      "compression_ratio": 1.4431818723678589,
      "no_speech_prob": 0.0029610125347971916
    },
    {
      "id": 230,
      "seek": 81600,
      "start": 817.0,
      "end": 820.0,
      "text": " Because what I have to do is",
      "tokens": [
        50414,
        1436,
        437,
        286,
        362,
        281,
        360,
        307,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31426796317100525,
      "compression_ratio": 1.6504853963851929,
      "no_speech_prob": 0.007559281308203936
    },
    {
      "id": 231,
      "seek": 81600,
      "start": 820.0,
      "end": 822.0,
      "text": " I have to pump up as much as possible.",
      "tokens": [
        50564,
        286,
        362,
        281,
        5889,
        493,
        382,
        709,
        382,
        1944,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31426796317100525,
      "compression_ratio": 1.6504853963851929,
      "no_speech_prob": 0.007559281308203936
    },
    {
      "id": 232,
      "seek": 81600,
      "start": 823.0,
      "end": 824.0,
      "text": " And if I now have a software",
      "tokens": [
        50714,
        400,
        498,
        286,
        586,
        362,
        257,
        4722,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31426796317100525,
      "compression_ratio": 1.6504853963851929,
      "no_speech_prob": 0.007559281308203936
    },
    {
      "id": 233,
      "seek": 81600,
      "start": 824.0,
      "end": 826.0,
      "text": " that is commercial and closed source",
      "tokens": [
        50764,
        300,
        307,
        6841,
        293,
        5395,
        4009,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31426796317100525,
      "compression_ratio": 1.6504853963851929,
      "no_speech_prob": 0.007559281308203936
    },
    {
      "id": 234,
      "seek": 81600,
      "start": 826.0,
      "end": 828.0,
      "text": " and it's containerized",
      "tokens": [
        50864,
        293,
        309,
        311,
        10129,
        1602,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31426796317100525,
      "compression_ratio": 1.6504853963851929,
      "no_speech_prob": 0.007559281308203936
    },
    {
      "id": 235,
      "seek": 81600,
      "start": 828.0,
      "end": 830.0,
      "text": " and it can be totally packed,",
      "tokens": [
        50964,
        293,
        309,
        393,
        312,
        3879,
        13265,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31426796317100525,
      "compression_ratio": 1.6504853963851929,
      "no_speech_prob": 0.007559281308203936
    },
    {
      "id": 236,
      "seek": 81600,
      "start": 830.0,
      "end": 831.0,
      "text": " then it's greener again",
      "tokens": [
        51064,
        550,
        309,
        311,
        3092,
        260,
        797,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31426796317100525,
      "compression_ratio": 1.6504853963851929,
      "no_speech_prob": 0.007559281308203936
    },
    {
      "id": 237,
      "seek": 81600,
      "start": 831.0,
      "end": 833.0,
      "text": " than a software that's there.",
      "tokens": [
        51114,
        813,
        257,
        4722,
        300,
        311,
        456,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31426796317100525,
      "compression_ratio": 1.6504853963851929,
      "no_speech_prob": 0.007559281308203936
    },
    {
      "id": 238,
      "seek": 81600,
      "start": 833.0,
      "end": 834.0,
      "text": " So I would say",
      "tokens": [
        51214,
        407,
        286,
        576,
        584,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31426796317100525,
      "compression_ratio": 1.6504853963851929,
      "no_speech_prob": 0.007559281308203936
    },
    {
      "id": 239,
      "seek": 81600,
      "start": 834.0,
      "end": 836.0,
      "text": " it's not necessarily",
      "tokens": [
        51264,
        309,
        311,
        406,
        4725,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31426796317100525,
      "compression_ratio": 1.6504853963851929,
      "no_speech_prob": 0.007559281308203936
    },
    {
      "id": 240,
      "seek": 81600,
      "start": 838.0,
      "end": 840.0,
      "text": " whether it's open source or not,",
      "tokens": [
        51464,
        1968,
        309,
        311,
        1269,
        4009,
        420,
        406,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31426796317100525,
      "compression_ratio": 1.6504853963851929,
      "no_speech_prob": 0.007559281308203936
    },
    {
      "id": 241,
      "seek": 81600,
      "start": 840.0,
      "end": 842.0,
      "text": " but how do I run the software?",
      "tokens": [
        51564,
        457,
        577,
        360,
        286,
        1190,
        264,
        4722,
        30,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31426796317100525,
      "compression_ratio": 1.6504853963851929,
      "no_speech_prob": 0.007559281308203936
    },
    {
      "id": 242,
      "seek": 84200,
      "start": 843.0,
      "end": 847.0,
      "text": " And if I can do this server consolidation now,",
      "tokens": [
        50414,
        400,
        498,
        286,
        393,
        360,
        341,
        7154,
        39114,
        586,
        11,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41949087381362915,
      "compression_ratio": 1.563265323638916,
      "no_speech_prob": 0.040724460035562515
    },
    {
      "id": 243,
      "seek": 84200,
      "start": 847.0,
      "end": 849.0,
      "text": " by doing Kubernetes, for example,",
      "tokens": [
        50614,
        538,
        884,
        23145,
        11,
        337,
        1365,
        11,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41949087381362915,
      "compression_ratio": 1.563265323638916,
      "no_speech_prob": 0.040724460035562515
    },
    {
      "id": 244,
      "seek": 84200,
      "start": 849.0,
      "end": 851.0,
      "text": " instead of bare metal, an application,",
      "tokens": [
        50714,
        2602,
        295,
        6949,
        5760,
        11,
        364,
        3861,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41949087381362915,
      "compression_ratio": 1.563265323638916,
      "no_speech_prob": 0.040724460035562515
    },
    {
      "id": 245,
      "seek": 84200,
      "start": 851.0,
      "end": 853.0,
      "text": " then I haven't won at all.",
      "tokens": [
        50814,
        550,
        286,
        2378,
        380,
        1582,
        412,
        439,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41949087381362915,
      "compression_ratio": 1.563265323638916,
      "no_speech_prob": 0.040724460035562515
    },
    {
      "id": 246,
      "seek": 84200,
      "start": 853.0,
      "end": 855.0,
      "text": " So I think this picture shows",
      "tokens": [
        50914,
        407,
        286,
        519,
        341,
        3036,
        3110,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41949087381362915,
      "compression_ratio": 1.563265323638916,
      "no_speech_prob": 0.040724460035562515
    },
    {
      "id": 247,
      "seek": 84200,
      "start": 855.0,
      "end": 857.0,
      "text": " how many emissions are reduced",
      "tokens": [
        51014,
        577,
        867,
        14607,
        366,
        9212,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41949087381362915,
      "compression_ratio": 1.563265323638916,
      "no_speech_prob": 0.040724460035562515
    },
    {
      "id": 248,
      "seek": 84200,
      "start": 857.0,
      "end": 858.0,
      "text": " per application,",
      "tokens": [
        51114,
        680,
        3861,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41949087381362915,
      "compression_ratio": 1.563265323638916,
      "no_speech_prob": 0.040724460035562515
    },
    {
      "id": 249,
      "seek": 84200,
      "start": 858.0,
      "end": 860.0,
      "text": " when I pack that up.",
      "tokens": [
        51164,
        562,
        286,
        2844,
        300,
        493,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41949087381362915,
      "compression_ratio": 1.563265323638916,
      "no_speech_prob": 0.040724460035562515
    },
    {
      "id": 250,
      "seek": 84200,
      "start": 860.0,
      "end": 862.0,
      "text": " And my experience shows a lot.",
      "tokens": [
        51264,
        400,
        452,
        1752,
        3110,
        257,
        688,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41949087381362915,
      "compression_ratio": 1.563265323638916,
      "no_speech_prob": 0.040724460035562515
    },
    {
      "id": 251,
      "seek": 84200,
      "start": 862.0,
      "end": 865.0,
      "text": " The servers are not exhausted.",
      "tokens": [
        51364,
        440,
        15909,
        366,
        406,
        17992,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41949087381362915,
      "compression_ratio": 1.563265323638916,
      "no_speech_prob": 0.040724460035562515
    },
    {
      "id": 252,
      "seek": 84200,
      "start": 867.0,
      "end": 868.0,
      "text": " Exactly what you said in the previous interview,",
      "tokens": [
        51614,
        7587,
        437,
        291,
        848,
        294,
        264,
        659,
        4917,
        563,
        4049,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41949087381362915,
      "compression_ratio": 1.563265323638916,
      "no_speech_prob": 0.040724460035562515
    },
    {
      "id": 253,
      "seek": 84200,
      "start": 868.0,
      "end": 870.0,
      "text": " these hot standby servers,",
      "tokens": [
        51664,
        613,
        2368,
        50170,
        15909,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41949087381362915,
      "compression_ratio": 1.563265323638916,
      "no_speech_prob": 0.040724460035562515
    },
    {
      "id": 254,
      "seek": 87000,
      "start": 870.0,
      "end": 872.0,
      "text": " which, by definition, are not exhausted.",
      "tokens": [
        50364,
        597,
        11,
        538,
        7123,
        11,
        366,
        406,
        17992,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5801254510879517,
      "compression_ratio": 1.507853388786316,
      "no_speech_prob": 0.013283031061291695
    },
    {
      "id": 255,
      "seek": 87000,
      "start": 872.0,
      "end": 874.0,
      "text": " We'll get to that again.",
      "tokens": [
        50464,
        492,
        603,
        483,
        281,
        300,
        797,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5801254510879517,
      "compression_ratio": 1.507853388786316,
      "no_speech_prob": 0.013283031061291695
    },
    {
      "id": 256,
      "seek": 87000,
      "start": 874.0,
      "end": 877.0,
      "text": " So we normally don't have an outage.",
      "tokens": [
        50564,
        407,
        321,
        5646,
        500,
        380,
        362,
        364,
        484,
        609,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5801254510879517,
      "compression_ratio": 1.507853388786316,
      "no_speech_prob": 0.013283031061291695
    },
    {
      "id": 257,
      "seek": 87000,
      "start": 879.0,
      "end": 880.0,
      "text": " And then there's the fact",
      "tokens": [
        50814,
        400,
        550,
        456,
        311,
        264,
        1186,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5801254510879517,
      "compression_ratio": 1.507853388786316,
      "no_speech_prob": 0.013283031061291695
    },
    {
      "id": 258,
      "seek": 87000,
      "start": 880.0,
      "end": 883.0,
      "text": " that we're doing hot standby again.",
      "tokens": [
        50864,
        300,
        321,
        434,
        884,
        2368,
        50170,
        797,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5801254510879517,
      "compression_ratio": 1.507853388786316,
      "no_speech_prob": 0.013283031061291695
    },
    {
      "id": 259,
      "seek": 87000,
      "start": 885.0,
      "end": 888.0,
      "text": " And maybe one more thing",
      "tokens": [
        51114,
        400,
        1310,
        472,
        544,
        551,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5801254510879517,
      "compression_ratio": 1.507853388786316,
      "no_speech_prob": 0.013283031061291695
    },
    {
      "id": 260,
      "seek": 87000,
      "start": 888.0,
      "end": 891.0,
      "text": " for this efficiency issue.",
      "tokens": [
        51264,
        337,
        341,
        10493,
        2734,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5801254510879517,
      "compression_ratio": 1.507853388786316,
      "no_speech_prob": 0.013283031061291695
    },
    {
      "id": 261,
      "seek": 87000,
      "start": 893.0,
      "end": 895.0,
      "text": " We play everything in the same order",
      "tokens": [
        51514,
        492,
        862,
        1203,
        294,
        264,
        912,
        1668,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5801254510879517,
      "compression_ratio": 1.507853388786316,
      "no_speech_prob": 0.013283031061291695
    },
    {
      "id": 262,
      "seek": 87000,
      "start": 895.0,
      "end": 897.0,
      "text": " to get an understanding there too.",
      "tokens": [
        51614,
        281,
        483,
        364,
        3701,
        456,
        886,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5801254510879517,
      "compression_ratio": 1.507853388786316,
      "no_speech_prob": 0.013283031061291695
    },
    {
      "id": 263,
      "seek": 89700,
      "start": 898.0,
      "end": 900.0,
      "text": " If I turn on a computer,",
      "tokens": [
        50414,
        759,
        286,
        1261,
        322,
        257,
        3820,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38348710536956787,
      "compression_ratio": 1.610576868057251,
      "no_speech_prob": 0.00665461178869009
    },
    {
      "id": 264,
      "seek": 89700,
      "start": 900.0,
      "end": 902.0,
      "text": " if I turn on a server,",
      "tokens": [
        50514,
        498,
        286,
        1261,
        322,
        257,
        7154,
        11,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38348710536956787,
      "compression_ratio": 1.610576868057251,
      "no_speech_prob": 0.00665461178869009
    },
    {
      "id": 265,
      "seek": 89700,
      "start": 902.0,
      "end": 904.0,
      "text": " then it consumes energy.",
      "tokens": [
        50614,
        550,
        309,
        48823,
        2281,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38348710536956787,
      "compression_ratio": 1.610576868057251,
      "no_speech_prob": 0.00665461178869009
    },
    {
      "id": 266,
      "seek": 89700,
      "start": 904.0,
      "end": 906.0,
      "text": " That means it runs,",
      "tokens": [
        50714,
        663,
        1355,
        309,
        6676,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38348710536956787,
      "compression_ratio": 1.610576868057251,
      "no_speech_prob": 0.00665461178869009
    },
    {
      "id": 267,
      "seek": 89700,
      "start": 906.0,
      "end": 908.0,
      "text": " but actually it doesn't do anything.",
      "tokens": [
        50814,
        457,
        767,
        309,
        1177,
        380,
        360,
        1340,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38348710536956787,
      "compression_ratio": 1.610576868057251,
      "no_speech_prob": 0.00665461178869009
    },
    {
      "id": 268,
      "seek": 89700,
      "start": 908.0,
      "end": 910.0,
      "text": " Or it does and doesn't do anything.",
      "tokens": [
        50914,
        1610,
        309,
        775,
        293,
        1177,
        380,
        360,
        1340,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38348710536956787,
      "compression_ratio": 1.610576868057251,
      "no_speech_prob": 0.00665461178869009
    },
    {
      "id": 269,
      "seek": 89700,
      "start": 910.0,
      "end": 911.0,
      "text": " As you wish.",
      "tokens": [
        51014,
        1018,
        291,
        3172,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38348710536956787,
      "compression_ratio": 1.610576868057251,
      "no_speech_prob": 0.00665461178869009
    },
    {
      "id": 270,
      "seek": 89700,
      "start": 911.0,
      "end": 913.0,
      "text": " That's just blind performance.",
      "tokens": [
        51064,
        663,
        311,
        445,
        6865,
        3389,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38348710536956787,
      "compression_ratio": 1.610576868057251,
      "no_speech_prob": 0.00665461178869009
    },
    {
      "id": 271,
      "seek": 89700,
      "start": 914.0,
      "end": 916.0,
      "text": " And this idle gap,",
      "tokens": [
        51214,
        400,
        341,
        30650,
        7417,
        11,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38348710536956787,
      "compression_ratio": 1.610576868057251,
      "no_speech_prob": 0.00665461178869009
    },
    {
      "id": 272,
      "seek": 89700,
      "start": 917.0,
      "end": 918.0,
      "text": " I have to distribute it",
      "tokens": [
        51364,
        286,
        362,
        281,
        20594,
        309,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38348710536956787,
      "compression_ratio": 1.610576868057251,
      "no_speech_prob": 0.00665461178869009
    },
    {
      "id": 273,
      "seek": 89700,
      "start": 918.0,
      "end": 920.0,
      "text": " to a lot of applications.",
      "tokens": [
        51414,
        281,
        257,
        688,
        295,
        5821,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38348710536956787,
      "compression_ratio": 1.610576868057251,
      "no_speech_prob": 0.00665461178869009
    },
    {
      "id": 274,
      "seek": 89700,
      "start": 920.0,
      "end": 923.0,
      "text": " And if you come up with codes now,",
      "tokens": [
        51514,
        400,
        498,
        291,
        808,
        493,
        365,
        14211,
        586,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38348710536956787,
      "compression_ratio": 1.610576868057251,
      "no_speech_prob": 0.00665461178869009
    },
    {
      "id": 275,
      "seek": 89700,
      "start": 924.0,
      "end": 925.0,
      "text": " then you might think,",
      "tokens": [
        51714,
        550,
        291,
        1062,
        519,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38348710536956787,
      "compression_ratio": 1.610576868057251,
      "no_speech_prob": 0.00665461178869009
    },
    {
      "id": 276,
      "seek": 92500,
      "start": 925.0,
      "end": 927.0,
      "text": " okay, if I can now,",
      "tokens": [
        50364,
        1392,
        11,
        498,
        286,
        393,
        586,
        11,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4245888590812683,
      "compression_ratio": 1.5064377784729004,
      "no_speech_prob": 0.001223327242769301
    },
    {
      "id": 277,
      "seek": 92500,
      "start": 927.0,
      "end": 929.0,
      "text": " if my server,",
      "tokens": [
        50464,
        498,
        452,
        7154,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4245888590812683,
      "compression_ratio": 1.5064377784729004,
      "no_speech_prob": 0.001223327242769301
    },
    {
      "id": 278,
      "seek": 92500,
      "start": 929.0,
      "end": 931.0,
      "text": " if my CPU performance is somewhere",
      "tokens": [
        50564,
        498,
        452,
        13199,
        3389,
        307,
        4079,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4245888590812683,
      "compression_ratio": 1.5064377784729004,
      "no_speech_prob": 0.001223327242769301
    },
    {
      "id": 279,
      "seek": 92500,
      "start": 931.0,
      "end": 933.0,
      "text": " here in the area",
      "tokens": [
        50664,
        510,
        294,
        264,
        1859,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4245888590812683,
      "compression_ratio": 1.5064377784729004,
      "no_speech_prob": 0.001223327242769301
    },
    {
      "id": 280,
      "seek": 92500,
      "start": 933.0,
      "end": 935.0,
      "text": " and I then reduce that",
      "tokens": [
        50764,
        293,
        286,
        550,
        5407,
        300,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4245888590812683,
      "compression_ratio": 1.5064377784729004,
      "no_speech_prob": 0.001223327242769301
    },
    {
      "id": 281,
      "seek": 92500,
      "start": 935.0,
      "end": 937.0,
      "text": " by shipped programming,",
      "tokens": [
        50864,
        538,
        402,
        72,
        3320,
        9410,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4245888590812683,
      "compression_ratio": 1.5064377784729004,
      "no_speech_prob": 0.001223327242769301
    },
    {
      "id": 282,
      "seek": 92500,
      "start": 937.0,
      "end": 939.0,
      "text": " then that's great.",
      "tokens": [
        50964,
        550,
        300,
        311,
        869,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4245888590812683,
      "compression_ratio": 1.5064377784729004,
      "no_speech_prob": 0.001223327242769301
    },
    {
      "id": 283,
      "seek": 92500,
      "start": 939.0,
      "end": 941.0,
      "text": " But actually it doesn't matter",
      "tokens": [
        51064,
        583,
        767,
        309,
        1177,
        380,
        1871,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4245888590812683,
      "compression_ratio": 1.5064377784729004,
      "no_speech_prob": 0.001223327242769301
    },
    {
      "id": 284,
      "seek": 92500,
      "start": 941.0,
      "end": 943.0,
      "text": " for this 100 watts that I used.",
      "tokens": [
        51164,
        337,
        341,
        2319,
        31247,
        300,
        286,
        1143,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4245888590812683,
      "compression_ratio": 1.5064377784729004,
      "no_speech_prob": 0.001223327242769301
    },
    {
      "id": 285,
      "seek": 92500,
      "start": 944.0,
      "end": 945.0,
      "text": " Exactly, so briefly,",
      "tokens": [
        51314,
        7587,
        11,
        370,
        10515,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4245888590812683,
      "compression_ratio": 1.5064377784729004,
      "no_speech_prob": 0.001223327242769301
    },
    {
      "id": 286,
      "seek": 92500,
      "start": 945.0,
      "end": 947.0,
      "text": " maybe the graphics say",
      "tokens": [
        51364,
        1310,
        264,
        11837,
        584,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4245888590812683,
      "compression_ratio": 1.5064377784729004,
      "no_speech_prob": 0.001223327242769301
    },
    {
      "id": 287,
      "seek": 92500,
      "start": 947.0,
      "end": 949.0,
      "text": " if you turn on the computer,",
      "tokens": [
        51464,
        498,
        291,
        1261,
        322,
        264,
        3820,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4245888590812683,
      "compression_ratio": 1.5064377784729004,
      "no_speech_prob": 0.001223327242769301
    },
    {
      "id": 288,
      "seek": 92500,
      "start": 949.0,
      "end": 951.0,
      "text": " the server already consumes 100 watts.",
      "tokens": [
        51564,
        264,
        7154,
        1217,
        48823,
        2319,
        31247,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4245888590812683,
      "compression_ratio": 1.5064377784729004,
      "no_speech_prob": 0.001223327242769301
    },
    {
      "id": 289,
      "seek": 92500,
      "start": 951.0,
      "end": 953.0,
      "text": " At 50 percent, 180 watts",
      "tokens": [
        51664,
        1711,
        2625,
        3043,
        11,
        11971,
        31247,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4245888590812683,
      "compression_ratio": 1.5064377784729004,
      "no_speech_prob": 0.001223327242769301
    },
    {
      "id": 290,
      "seek": 95300,
      "start": 954.0,
      "end": 956.0,
      "text": " and at 100 percent, 200 watts.",
      "tokens": [
        50414,
        293,
        412,
        2319,
        3043,
        11,
        2331,
        31247,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37576648592948914,
      "compression_ratio": 1.660465121269226,
      "no_speech_prob": 0.0017812502337619662
    },
    {
      "id": 291,
      "seek": 95300,
      "start": 957.0,
      "end": 958.0,
      "text": " So that means",
      "tokens": [
        50564,
        407,
        300,
        1355,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37576648592948914,
      "compression_ratio": 1.660465121269226,
      "no_speech_prob": 0.0017812502337619662
    },
    {
      "id": 292,
      "seek": 95300,
      "start": 958.0,
      "end": 960.0,
      "text": " between 50 and 100 percent",
      "tokens": [
        50614,
        1296,
        2625,
        293,
        2319,
        3043,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37576648592948914,
      "compression_ratio": 1.660465121269226,
      "no_speech_prob": 0.0017812502337619662
    },
    {
      "id": 293,
      "seek": 95300,
      "start": 960.0,
      "end": 962.0,
      "text": " are 20 watts.",
      "tokens": [
        50714,
        366,
        945,
        31247,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37576648592948914,
      "compression_ratio": 1.660465121269226,
      "no_speech_prob": 0.0017812502337619662
    },
    {
      "id": 294,
      "seek": 95300,
      "start": 964.0,
      "end": 965.0,
      "text": " And it already consumes 100 watts",
      "tokens": [
        50914,
        400,
        309,
        1217,
        48823,
        2319,
        31247,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37576648592948914,
      "compression_ratio": 1.660465121269226,
      "no_speech_prob": 0.0017812502337619662
    },
    {
      "id": 295,
      "seek": 95300,
      "start": 965.0,
      "end": 967.0,
      "text": " when it is even switched on,",
      "tokens": [
        50964,
        562,
        309,
        307,
        754,
        16858,
        322,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37576648592948914,
      "compression_ratio": 1.660465121269226,
      "no_speech_prob": 0.0017812502337619662
    },
    {
      "id": 296,
      "seek": 95300,
      "start": 967.0,
      "end": 969.0,
      "text": " which means that I actually want to",
      "tokens": [
        51064,
        597,
        1355,
        300,
        286,
        767,
        528,
        281,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37576648592948914,
      "compression_ratio": 1.660465121269226,
      "no_speech_prob": 0.0017812502337619662
    },
    {
      "id": 297,
      "seek": 95300,
      "start": 969.0,
      "end": 971.0,
      "text": " run the thing at full load.",
      "tokens": [
        51164,
        1190,
        264,
        551,
        412,
        1577,
        3677,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37576648592948914,
      "compression_ratio": 1.660465121269226,
      "no_speech_prob": 0.0017812502337619662
    },
    {
      "id": 298,
      "seek": 95300,
      "start": 971.0,
      "end": 973.0,
      "text": " And what you're saying now is",
      "tokens": [
        51264,
        400,
        437,
        291,
        434,
        1566,
        586,
        307,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37576648592948914,
      "compression_ratio": 1.660465121269226,
      "no_speech_prob": 0.0017812502337619662
    },
    {
      "id": 299,
      "seek": 95300,
      "start": 973.0,
      "end": 975.0,
      "text": " a nice try if I optimize",
      "tokens": [
        51364,
        257,
        1481,
        853,
        498,
        286,
        19719,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37576648592948914,
      "compression_ratio": 1.660465121269226,
      "no_speech_prob": 0.0017812502337619662
    },
    {
      "id": 300,
      "seek": 95300,
      "start": 975.0,
      "end": 977.0,
      "text": " 5 or 10 percent utilization,",
      "tokens": [
        51464,
        1025,
        420,
        1266,
        3043,
        37074,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37576648592948914,
      "compression_ratio": 1.660465121269226,
      "no_speech_prob": 0.0017812502337619662
    },
    {
      "id": 301,
      "seek": 95300,
      "start": 977.0,
      "end": 979.0,
      "text": " i.e. from 10 to 5 percent.",
      "tokens": [
        51564,
        741,
        13,
        68,
        13,
        490,
        1266,
        281,
        1025,
        3043,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37576648592948914,
      "compression_ratio": 1.660465121269226,
      "no_speech_prob": 0.0017812502337619662
    },
    {
      "id": 302,
      "seek": 95300,
      "start": 979.0,
      "end": 981.0,
      "text": " I actually want to load the thing",
      "tokens": [
        51664,
        286,
        767,
        528,
        281,
        3677,
        264,
        551,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37576648592948914,
      "compression_ratio": 1.660465121269226,
      "no_speech_prob": 0.0017812502337619662
    },
    {
      "id": 303,
      "seek": 98100,
      "start": 981.0,
      "end": 983.0,
      "text": " on another level.",
      "tokens": [
        50364,
        322,
        1071,
        1496,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34408923983573914,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.024724163115024567
    },
    {
      "id": 304,
      "seek": 98100,
      "start": 983.0,
      "end": 985.0,
      "text": " Exactly, and for that I have to",
      "tokens": [
        50464,
        7587,
        11,
        293,
        337,
        300,
        286,
        362,
        281,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34408923983573914,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.024724163115024567
    },
    {
      "id": 305,
      "seek": 98100,
      "start": 985.0,
      "end": 987.0,
      "text": " add more applications.",
      "tokens": [
        50564,
        909,
        544,
        5821,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34408923983573914,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.024724163115024567
    },
    {
      "id": 306,
      "seek": 98100,
      "start": 987.0,
      "end": 989.0,
      "text": " And there is a rumor that",
      "tokens": [
        50664,
        400,
        456,
        307,
        257,
        29639,
        300,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34408923983573914,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.024724163115024567
    },
    {
      "id": 307,
      "seek": 98100,
      "start": 989.0,
      "end": 991.0,
      "text": " Google alarms go off",
      "tokens": [
        50764,
        3329,
        45039,
        352,
        766,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34408923983573914,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.024724163115024567
    },
    {
      "id": 308,
      "seek": 98100,
      "start": 991.0,
      "end": 993.0,
      "text": " when the server utilization",
      "tokens": [
        50864,
        562,
        264,
        7154,
        37074,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34408923983573914,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.024724163115024567
    },
    {
      "id": 309,
      "seek": 98100,
      "start": 993.0,
      "end": 995.0,
      "text": " is below 98 percent.",
      "tokens": [
        50964,
        307,
        2507,
        20860,
        3043,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34408923983573914,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.024724163115024567
    },
    {
      "id": 310,
      "seek": 98100,
      "start": 995.0,
      "end": 997.0,
      "text": " I don't know if that's true.",
      "tokens": [
        51064,
        286,
        500,
        380,
        458,
        498,
        300,
        311,
        2074,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34408923983573914,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.024724163115024567
    },
    {
      "id": 311,
      "seek": 98100,
      "start": 997.0,
      "end": 999.0,
      "text": " But it's a rumor.",
      "tokens": [
        51164,
        583,
        309,
        311,
        257,
        29639,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34408923983573914,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.024724163115024567
    },
    {
      "id": 312,
      "seek": 98100,
      "start": 999.0,
      "end": 1001.0,
      "text": " And there again,",
      "tokens": [
        51264,
        400,
        456,
        797,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34408923983573914,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.024724163115024567
    },
    {
      "id": 313,
      "seek": 98100,
      "start": 1001.0,
      "end": 1003.0,
      "text": " so if I take the open source",
      "tokens": [
        51364,
        370,
        498,
        286,
        747,
        264,
        1269,
        4009,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34408923983573914,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.024724163115024567
    },
    {
      "id": 314,
      "seek": 98100,
      "start": 1003.0,
      "end": 1005.0,
      "text": " again, the question,",
      "tokens": [
        51464,
        797,
        11,
        264,
        1168,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34408923983573914,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.024724163115024567
    },
    {
      "id": 315,
      "seek": 98100,
      "start": 1005.0,
      "end": 1007.0,
      "text": " so yes, maybe an open source",
      "tokens": [
        51564,
        370,
        2086,
        11,
        1310,
        364,
        1269,
        4009,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34408923983573914,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.024724163115024567
    },
    {
      "id": 316,
      "seek": 98100,
      "start": 1007.0,
      "end": 1009.0,
      "text": " is more efficiently programmed.",
      "tokens": [
        51664,
        307,
        544,
        19621,
        31092,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34408923983573914,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.024724163115024567
    },
    {
      "id": 317,
      "seek": 100900,
      "start": 1009.0,
      "end": 1011.0,
      "text": " Some open source tool.",
      "tokens": [
        50364,
        2188,
        1269,
        4009,
        2290,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4327610433101654,
      "compression_ratio": 1.3986486196517944,
      "no_speech_prob": 0.00842948816716671
    },
    {
      "id": 318,
      "seek": 100900,
      "start": 1013.0,
      "end": 1015.0,
      "text": " But",
      "tokens": [
        50564,
        583,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4327610433101654,
      "compression_ratio": 1.3986486196517944,
      "no_speech_prob": 0.00842948816716671
    },
    {
      "id": 319,
      "seek": 100900,
      "start": 1015.0,
      "end": 1017.0,
      "text": " maybe then it doesn't matter.",
      "tokens": [
        50664,
        1310,
        550,
        309,
        1177,
        380,
        1871,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4327610433101654,
      "compression_ratio": 1.3986486196517944,
      "no_speech_prob": 0.00842948816716671
    },
    {
      "id": 320,
      "seek": 100900,
      "start": 1019.0,
      "end": 1021.0,
      "text": " So that's why",
      "tokens": [
        50864,
        407,
        300,
        311,
        983,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4327610433101654,
      "compression_ratio": 1.3986486196517944,
      "no_speech_prob": 0.00842948816716671
    },
    {
      "id": 321,
      "seek": 100900,
      "start": 1025.0,
      "end": 1027.0,
      "text": " what is an exciting thing",
      "tokens": [
        51164,
        437,
        307,
        364,
        4670,
        551,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4327610433101654,
      "compression_ratio": 1.3986486196517944,
      "no_speech_prob": 0.00842948816716671
    },
    {
      "id": 322,
      "seek": 100900,
      "start": 1027.0,
      "end": 1029.0,
      "text": " is that this data is also",
      "tokens": [
        51264,
        307,
        300,
        341,
        1412,
        307,
        611,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4327610433101654,
      "compression_ratio": 1.3986486196517944,
      "no_speech_prob": 0.00842948816716671
    },
    {
      "id": 323,
      "seek": 100900,
      "start": 1029.0,
      "end": 1031.0,
      "text": " efficient.",
      "tokens": [
        51364,
        7148,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4327610433101654,
      "compression_ratio": 1.3986486196517944,
      "no_speech_prob": 0.00842948816716671
    },
    {
      "id": 324,
      "seek": 100900,
      "start": 1031.0,
      "end": 1033.0,
      "text": " Sorry, maybe briefly on that point.",
      "tokens": [
        51464,
        4919,
        11,
        1310,
        10515,
        322,
        300,
        935,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4327610433101654,
      "compression_ratio": 1.3986486196517944,
      "no_speech_prob": 0.00842948816716671
    },
    {
      "id": 325,
      "seek": 100900,
      "start": 1033.0,
      "end": 1035.0,
      "text": " What you just called",
      "tokens": [
        51564,
        708,
        291,
        445,
        1219,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4327610433101654,
      "compression_ratio": 1.3986486196517944,
      "no_speech_prob": 0.00842948816716671
    },
    {
      "id": 326,
      "seek": 100900,
      "start": 1035.0,
      "end": 1037.0,
      "text": " Google, what you",
      "tokens": [
        51664,
        3329,
        11,
        437,
        291,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4327610433101654,
      "compression_ratio": 1.3986486196517944,
      "no_speech_prob": 0.00842948816716671
    },
    {
      "id": 327,
      "seek": 103700,
      "start": 1037.0,
      "end": 1039.0,
      "text": " mentioned now as a question",
      "tokens": [
        50364,
        2835,
        586,
        382,
        257,
        1168,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3834480345249176,
      "compression_ratio": 1.6787148714065552,
      "no_speech_prob": 0.06596029549837112
    },
    {
      "id": 328,
      "seek": 103700,
      "start": 1039.0,
      "end": 1041.0,
      "text": " and we were just discussing",
      "tokens": [
        50464,
        293,
        321,
        645,
        445,
        10850,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3834480345249176,
      "compression_ratio": 1.6787148714065552,
      "no_speech_prob": 0.06596029549837112
    },
    {
      "id": 329,
      "seek": 103700,
      "start": 1041.0,
      "end": 1043.0,
      "text": " the hot standbys.",
      "tokens": [
        50564,
        264,
        2368,
        1463,
        65,
        749,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3834480345249176,
      "compression_ratio": 1.6787148714065552,
      "no_speech_prob": 0.06596029549837112
    },
    {
      "id": 330,
      "seek": 103700,
      "start": 1043.0,
      "end": 1045.0,
      "text": " So if I'm in a data center now,",
      "tokens": [
        50664,
        407,
        498,
        286,
        478,
        294,
        257,
        1412,
        3056,
        586,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3834480345249176,
      "compression_ratio": 1.6787148714065552,
      "no_speech_prob": 0.06596029549837112
    },
    {
      "id": 331,
      "seek": 103700,
      "start": 1045.0,
      "end": 1047.0,
      "text": " then I have computers that are not",
      "tokens": [
        50764,
        550,
        286,
        362,
        10807,
        300,
        366,
        406,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3834480345249176,
      "compression_ratio": 1.6787148714065552,
      "no_speech_prob": 0.06596029549837112
    },
    {
      "id": 332,
      "seek": 103700,
      "start": 1047.0,
      "end": 1049.0,
      "text": " overloaded and just run because",
      "tokens": [
        50864,
        28777,
        292,
        293,
        445,
        1190,
        570,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3834480345249176,
      "compression_ratio": 1.6787148714065552,
      "no_speech_prob": 0.06596029549837112
    },
    {
      "id": 333,
      "seek": 103700,
      "start": 1049.0,
      "end": 1051.0,
      "text": " they are hot standbys.",
      "tokens": [
        50964,
        436,
        366,
        2368,
        1463,
        65,
        749,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3834480345249176,
      "compression_ratio": 1.6787148714065552,
      "no_speech_prob": 0.06596029549837112
    },
    {
      "id": 334,
      "seek": 103700,
      "start": 1051.0,
      "end": 1053.0,
      "text": " That would be the question,",
      "tokens": [
        51064,
        663,
        576,
        312,
        264,
        1168,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3834480345249176,
      "compression_ratio": 1.6787148714065552,
      "no_speech_prob": 0.06596029549837112
    },
    {
      "id": 335,
      "seek": 103700,
      "start": 1053.0,
      "end": 1055.0,
      "text": " shouldn't I just go to the cloud?",
      "tokens": [
        51164,
        4659,
        380,
        286,
        445,
        352,
        281,
        264,
        4588,
        30,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3834480345249176,
      "compression_ratio": 1.6787148714065552,
      "no_speech_prob": 0.06596029549837112
    },
    {
      "id": 336,
      "seek": 103700,
      "start": 1055.0,
      "end": 1057.0,
      "text": " So in the cloud I already have someone",
      "tokens": [
        51264,
        407,
        294,
        264,
        4588,
        286,
        1217,
        362,
        1580,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3834480345249176,
      "compression_ratio": 1.6787148714065552,
      "no_speech_prob": 0.06596029549837112
    },
    {
      "id": 337,
      "seek": 103700,
      "start": 1057.0,
      "end": 1059.0,
      "text": " who takes care of it professionally,",
      "tokens": [
        51364,
        567,
        2516,
        1127,
        295,
        309,
        27941,
        11,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3834480345249176,
      "compression_ratio": 1.6787148714065552,
      "no_speech_prob": 0.06596029549837112
    },
    {
      "id": 338,
      "seek": 103700,
      "start": 1059.0,
      "end": 1061.0,
      "text": " to use as few servers as possible.",
      "tokens": [
        51464,
        281,
        764,
        382,
        1326,
        15909,
        382,
        1944,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3834480345249176,
      "compression_ratio": 1.6787148714065552,
      "no_speech_prob": 0.06596029549837112
    },
    {
      "id": 339,
      "seek": 103700,
      "start": 1061.0,
      "end": 1063.0,
      "text": " There is serverless.",
      "tokens": [
        51564,
        821,
        307,
        7154,
        1832,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3834480345249176,
      "compression_ratio": 1.6787148714065552,
      "no_speech_prob": 0.06596029549837112
    },
    {
      "id": 340,
      "seek": 103700,
      "start": 1063.0,
      "end": 1065.0,
      "text": " That's also a concept that's",
      "tokens": [
        51664,
        663,
        311,
        611,
        257,
        3410,
        300,
        311,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3834480345249176,
      "compression_ratio": 1.6787148714065552,
      "no_speech_prob": 0.06596029549837112
    },
    {
      "id": 341,
      "seek": 106500,
      "start": 1065.0,
      "end": 1067.0,
      "text": " only good for load time",
      "tokens": [
        50364,
        787,
        665,
        337,
        3677,
        565,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29613548517227173,
      "compression_ratio": 1.6358696222305298,
      "no_speech_prob": 0.2035813182592392
    },
    {
      "id": 342,
      "seek": 106500,
      "start": 1067.0,
      "end": 1069.0,
      "text": " and so on and so on.",
      "tokens": [
        50464,
        293,
        370,
        322,
        293,
        370,
        322,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29613548517227173,
      "compression_ratio": 1.6358696222305298,
      "no_speech_prob": 0.2035813182592392
    },
    {
      "id": 343,
      "seek": 106500,
      "start": 1069.0,
      "end": 1071.0,
      "text": " So the cloud,",
      "tokens": [
        50564,
        407,
        264,
        4588,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29613548517227173,
      "compression_ratio": 1.6358696222305298,
      "no_speech_prob": 0.2035813182592392
    },
    {
      "id": 344,
      "seek": 106500,
      "start": 1071.0,
      "end": 1073.0,
      "text": " so I would say yes.",
      "tokens": [
        50664,
        370,
        286,
        576,
        584,
        2086,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29613548517227173,
      "compression_ratio": 1.6358696222305298,
      "no_speech_prob": 0.2035813182592392
    },
    {
      "id": 345,
      "seek": 106500,
      "start": 1073.0,
      "end": 1075.0,
      "text": " Cloud in the sense of",
      "tokens": [
        50764,
        8061,
        294,
        264,
        2020,
        295,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29613548517227173,
      "compression_ratio": 1.6358696222305298,
      "no_speech_prob": 0.2035813182592392
    },
    {
      "id": 346,
      "seek": 106500,
      "start": 1075.0,
      "end": 1077.0,
      "text": " platform as a service.",
      "tokens": [
        50864,
        3663,
        382,
        257,
        2643,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29613548517227173,
      "compression_ratio": 1.6358696222305298,
      "no_speech_prob": 0.2035813182592392
    },
    {
      "id": 347,
      "seek": 106500,
      "start": 1077.0,
      "end": 1079.0,
      "text": " So",
      "tokens": [
        50964,
        407,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29613548517227173,
      "compression_ratio": 1.6358696222305298,
      "no_speech_prob": 0.2035813182592392
    },
    {
      "id": 348,
      "seek": 106500,
      "start": 1079.0,
      "end": 1081.0,
      "text": " when I say I do",
      "tokens": [
        51064,
        562,
        286,
        584,
        286,
        360,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29613548517227173,
      "compression_ratio": 1.6358696222305298,
      "no_speech_prob": 0.2035813182592392
    },
    {
      "id": 349,
      "seek": 106500,
      "start": 1081.0,
      "end": 1083.0,
      "text": " cloud in the sense of",
      "tokens": [
        51164,
        4588,
        294,
        264,
        2020,
        295,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29613548517227173,
      "compression_ratio": 1.6358696222305298,
      "no_speech_prob": 0.2035813182592392
    },
    {
      "id": 350,
      "seek": 106500,
      "start": 1083.0,
      "end": 1085.0,
      "text": " infrastructure as a service, that means",
      "tokens": [
        51264,
        6896,
        382,
        257,
        2643,
        11,
        300,
        1355,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29613548517227173,
      "compression_ratio": 1.6358696222305298,
      "no_speech_prob": 0.2035813182592392
    },
    {
      "id": 351,
      "seek": 106500,
      "start": 1085.0,
      "end": 1087.0,
      "text": " I actually run my",
      "tokens": [
        51364,
        286,
        767,
        1190,
        452,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29613548517227173,
      "compression_ratio": 1.6358696222305298,
      "no_speech_prob": 0.2035813182592392
    },
    {
      "id": 352,
      "seek": 106500,
      "start": 1087.0,
      "end": 1089.0,
      "text": " VMs that I have on-prem on cloud,",
      "tokens": [
        51464,
        18038,
        82,
        300,
        286,
        362,
        322,
        12,
        29403,
        322,
        4588,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29613548517227173,
      "compression_ratio": 1.6358696222305298,
      "no_speech_prob": 0.2035813182592392
    },
    {
      "id": 353,
      "seek": 106500,
      "start": 1089.0,
      "end": 1091.0,
      "text": " then I have an advantage",
      "tokens": [
        51564,
        550,
        286,
        362,
        364,
        5002,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29613548517227173,
      "compression_ratio": 1.6358696222305298,
      "no_speech_prob": 0.2035813182592392
    },
    {
      "id": 354,
      "seek": 106500,
      "start": 1091.0,
      "end": 1093.0,
      "text": " because usually the",
      "tokens": [
        51664,
        570,
        2673,
        264,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29613548517227173,
      "compression_ratio": 1.6358696222305298,
      "no_speech_prob": 0.2035813182592392
    },
    {
      "id": 355,
      "seek": 109300,
      "start": 1093.0,
      "end": 1095.0,
      "text": " power usage effectiveness of the",
      "tokens": [
        50364,
        1347,
        14924,
        21208,
        295,
        264,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3106292188167572,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.2944704592227936
    },
    {
      "id": 356,
      "seek": 109300,
      "start": 1095.0,
      "end": 1097.0,
      "text": " data centers are better than",
      "tokens": [
        50464,
        1412,
        10898,
        366,
        1101,
        813,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3106292188167572,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.2944704592227936
    },
    {
      "id": 357,
      "seek": 109300,
      "start": 1097.0,
      "end": 1099.0,
      "text": " mine, so Microsoft",
      "tokens": [
        50564,
        3892,
        11,
        370,
        8116,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3106292188167572,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.2944704592227936
    },
    {
      "id": 358,
      "seek": 109300,
      "start": 1099.0,
      "end": 1101.0,
      "text": " and AWS and so on.",
      "tokens": [
        50664,
        293,
        17650,
        293,
        370,
        322,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3106292188167572,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.2944704592227936
    },
    {
      "id": 359,
      "seek": 109300,
      "start": 1101.0,
      "end": 1103.0,
      "text": " They are all somewhere",
      "tokens": [
        50764,
        814,
        366,
        439,
        4079,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3106292188167572,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.2944704592227936
    },
    {
      "id": 360,
      "seek": 109300,
      "start": 1103.0,
      "end": 1105.0,
      "text": " roughly 1.1, 1.2.",
      "tokens": [
        50864,
        9810,
        502,
        13,
        16,
        11,
        502,
        13,
        17,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3106292188167572,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.2944704592227936
    },
    {
      "id": 361,
      "seek": 109300,
      "start": 1105.0,
      "end": 1107.0,
      "text": " So",
      "tokens": [
        50964,
        407,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3106292188167572,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.2944704592227936
    },
    {
      "id": 362,
      "seek": 109300,
      "start": 1107.0,
      "end": 1109.0,
      "text": " the second comma point differs",
      "tokens": [
        51064,
        264,
        1150,
        22117,
        935,
        37761,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3106292188167572,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.2944704592227936
    },
    {
      "id": 363,
      "seek": 109300,
      "start": 1109.0,
      "end": 1111.0,
      "text": " with them and there is always a 1 in front of it.",
      "tokens": [
        51164,
        365,
        552,
        293,
        456,
        307,
        1009,
        257,
        502,
        294,
        1868,
        295,
        309,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3106292188167572,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.2944704592227936
    },
    {
      "id": 364,
      "seek": 109300,
      "start": 1111.0,
      "end": 1113.0,
      "text": " And if I go to a normal data center,",
      "tokens": [
        51264,
        400,
        498,
        286,
        352,
        281,
        257,
        2710,
        1412,
        3056,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3106292188167572,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.2944704592227936
    },
    {
      "id": 365,
      "seek": 109300,
      "start": 1113.0,
      "end": 1115.0,
      "text": " there can also be a 2 in front of it.",
      "tokens": [
        51364,
        456,
        393,
        611,
        312,
        257,
        568,
        294,
        1868,
        295,
        309,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3106292188167572,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.2944704592227936
    },
    {
      "id": 366,
      "seek": 109300,
      "start": 1115.0,
      "end": 1117.0,
      "text": " So that's",
      "tokens": [
        51464,
        407,
        300,
        311,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3106292188167572,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.2944704592227936
    },
    {
      "id": 367,
      "seek": 109300,
      "start": 1117.0,
      "end": 1119.0,
      "text": " much more efficient,",
      "tokens": [
        51564,
        709,
        544,
        7148,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3106292188167572,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.2944704592227936
    },
    {
      "id": 368,
      "seek": 109300,
      "start": 1119.0,
      "end": 1121.0,
      "text": " much better.",
      "tokens": [
        51664,
        709,
        1101,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3106292188167572,
      "compression_ratio": 1.5662100315093994,
      "no_speech_prob": 0.2944704592227936
    },
    {
      "id": 369,
      "seek": 112100,
      "start": 1121.0,
      "end": 1123.0,
      "text": " But",
      "tokens": [
        50364,
        583,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33150947093963623,
      "compression_ratio": 1.4977375268936157,
      "no_speech_prob": 0.016546038910746574
    },
    {
      "id": 370,
      "seek": 112100,
      "start": 1123.0,
      "end": 1125.0,
      "text": " if I still reserve my CPU cores",
      "tokens": [
        50464,
        498,
        286,
        920,
        17824,
        452,
        13199,
        24826,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33150947093963623,
      "compression_ratio": 1.4977375268936157,
      "no_speech_prob": 0.016546038910746574
    },
    {
      "id": 371,
      "seek": 112100,
      "start": 1125.0,
      "end": 1127.0,
      "text": " and my RAM,",
      "tokens": [
        50564,
        293,
        452,
        14561,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33150947093963623,
      "compression_ratio": 1.4977375268936157,
      "no_speech_prob": 0.016546038910746574
    },
    {
      "id": 372,
      "seek": 112100,
      "start": 1127.0,
      "end": 1129.0,
      "text": " then I actually",
      "tokens": [
        50664,
        550,
        286,
        767,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33150947093963623,
      "compression_ratio": 1.4977375268936157,
      "no_speech_prob": 0.016546038910746574
    },
    {
      "id": 373,
      "seek": 112100,
      "start": 1129.0,
      "end": 1131.0,
      "text": " haven't really gained much from that point of view,",
      "tokens": [
        50764,
        2378,
        380,
        534,
        12634,
        709,
        490,
        300,
        935,
        295,
        1910,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33150947093963623,
      "compression_ratio": 1.4977375268936157,
      "no_speech_prob": 0.016546038910746574
    },
    {
      "id": 374,
      "seek": 112100,
      "start": 1131.0,
      "end": 1133.0,
      "text": " except for the PoE.",
      "tokens": [
        50864,
        3993,
        337,
        264,
        6165,
        36,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33150947093963623,
      "compression_ratio": 1.4977375268936157,
      "no_speech_prob": 0.016546038910746574
    },
    {
      "id": 375,
      "seek": 112100,
      "start": 1133.0,
      "end": 1135.0,
      "text": " But if I use this",
      "tokens": [
        50964,
        583,
        498,
        286,
        764,
        341,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33150947093963623,
      "compression_ratio": 1.4977375268936157,
      "no_speech_prob": 0.016546038910746574
    },
    {
      "id": 376,
      "seek": 112100,
      "start": 1135.0,
      "end": 1137.0,
      "text": " hardware efficiency and",
      "tokens": [
        51064,
        8837,
        10493,
        293,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33150947093963623,
      "compression_ratio": 1.4977375268936157,
      "no_speech_prob": 0.016546038910746574
    },
    {
      "id": 377,
      "seek": 112100,
      "start": 1137.0,
      "end": 1139.0,
      "text": " energy efficiency at the moment",
      "tokens": [
        51164,
        2281,
        10493,
        412,
        264,
        1623,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33150947093963623,
      "compression_ratio": 1.4977375268936157,
      "no_speech_prob": 0.016546038910746574
    },
    {
      "id": 378,
      "seek": 112100,
      "start": 1139.0,
      "end": 1141.0,
      "text": " by doing platform as a service,",
      "tokens": [
        51264,
        538,
        884,
        3663,
        382,
        257,
        2643,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33150947093963623,
      "compression_ratio": 1.4977375268936157,
      "no_speech_prob": 0.016546038910746574
    },
    {
      "id": 379,
      "seek": 112100,
      "start": 1141.0,
      "end": 1143.0,
      "text": " serverless,",
      "tokens": [
        51364,
        7154,
        1832,
        11,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33150947093963623,
      "compression_ratio": 1.4977375268936157,
      "no_speech_prob": 0.016546038910746574
    },
    {
      "id": 380,
      "seek": 112100,
      "start": 1143.0,
      "end": 1145.0,
      "text": " all these app services,",
      "tokens": [
        51464,
        439,
        613,
        724,
        3328,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33150947093963623,
      "compression_ratio": 1.4977375268936157,
      "no_speech_prob": 0.016546038910746574
    },
    {
      "id": 381,
      "seek": 112100,
      "start": 1145.0,
      "end": 1147.0,
      "text": " AWS doesn't sound too good,",
      "tokens": [
        51564,
        17650,
        1177,
        380,
        1626,
        886,
        665,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33150947093963623,
      "compression_ratio": 1.4977375268936157,
      "no_speech_prob": 0.016546038910746574
    },
    {
      "id": 382,
      "seek": 112100,
      "start": 1147.0,
      "end": 1149.0,
      "text": " but if you take functions",
      "tokens": [
        51664,
        457,
        498,
        291,
        747,
        6828,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33150947093963623,
      "compression_ratio": 1.4977375268936157,
      "no_speech_prob": 0.016546038910746574
    },
    {
      "id": 383,
      "seek": 114900,
      "start": 1149.0,
      "end": 1151.0,
      "text": " like Manage Kubernetes and so on,",
      "tokens": [
        50364,
        411,
        2458,
        609,
        23145,
        293,
        370,
        322,
        11,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3788527548313141,
      "compression_ratio": 1.6666666269302368,
      "no_speech_prob": 0.17046819627285004
    },
    {
      "id": 384,
      "seek": 114900,
      "start": 1151.0,
      "end": 1153.0,
      "text": " then the operation",
      "tokens": [
        50464,
        550,
        264,
        6916,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3788527548313141,
      "compression_ratio": 1.6666666269302368,
      "no_speech_prob": 0.17046819627285004
    },
    {
      "id": 385,
      "seek": 114900,
      "start": 1153.0,
      "end": 1155.0,
      "text": " already ensures that it is massively packed.",
      "tokens": [
        50564,
        1217,
        28111,
        300,
        309,
        307,
        29379,
        13265,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3788527548313141,
      "compression_ratio": 1.6666666269302368,
      "no_speech_prob": 0.17046819627285004
    },
    {
      "id": 386,
      "seek": 114900,
      "start": 1155.0,
      "end": 1157.0,
      "text": " And that is",
      "tokens": [
        50664,
        400,
        300,
        307,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3788527548313141,
      "compression_ratio": 1.6666666269302368,
      "no_speech_prob": 0.17046819627285004
    },
    {
      "id": 387,
      "seek": 114900,
      "start": 1157.0,
      "end": 1159.0,
      "text": " unbeatable.",
      "tokens": [
        50764,
        517,
        4169,
        712,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3788527548313141,
      "compression_ratio": 1.6666666269302368,
      "no_speech_prob": 0.17046819627285004
    },
    {
      "id": 388,
      "seek": 114900,
      "start": 1159.0,
      "end": 1161.0,
      "text": " But it also works",
      "tokens": [
        50864,
        583,
        309,
        611,
        1985,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3788527548313141,
      "compression_ratio": 1.6666666269302368,
      "no_speech_prob": 0.17046819627285004
    },
    {
      "id": 389,
      "seek": 114900,
      "start": 1161.0,
      "end": 1163.0,
      "text": " on-prem. So it's not like that.",
      "tokens": [
        50964,
        322,
        12,
        29403,
        13,
        407,
        309,
        311,
        406,
        411,
        300,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3788527548313141,
      "compression_ratio": 1.6666666269302368,
      "no_speech_prob": 0.17046819627285004
    },
    {
      "id": 390,
      "seek": 114900,
      "start": 1163.0,
      "end": 1165.0,
      "text": " But most of the time",
      "tokens": [
        51064,
        583,
        881,
        295,
        264,
        565,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3788527548313141,
      "compression_ratio": 1.6666666269302368,
      "no_speech_prob": 0.17046819627285004
    },
    {
      "id": 391,
      "seek": 114900,
      "start": 1165.0,
      "end": 1167.0,
      "text": " you don't do it. Most of the time",
      "tokens": [
        51164,
        291,
        500,
        380,
        360,
        309,
        13,
        4534,
        295,
        264,
        565,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3788527548313141,
      "compression_ratio": 1.6666666269302368,
      "no_speech_prob": 0.17046819627285004
    },
    {
      "id": 392,
      "seek": 114900,
      "start": 1167.0,
      "end": 1169.0,
      "text": " the on-prem data centers are simply",
      "tokens": [
        51264,
        264,
        322,
        12,
        29403,
        1412,
        10898,
        366,
        2935,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3788527548313141,
      "compression_ratio": 1.6666666269302368,
      "no_speech_prob": 0.17046819627285004
    },
    {
      "id": 393,
      "seek": 114900,
      "start": 1169.0,
      "end": 1171.0,
      "text": " deployed in front of you",
      "tokens": [
        51364,
        17826,
        294,
        1868,
        295,
        291,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3788527548313141,
      "compression_ratio": 1.6666666269302368,
      "no_speech_prob": 0.17046819627285004
    },
    {
      "id": 394,
      "seek": 114900,
      "start": 1171.0,
      "end": 1173.0,
      "text": " and the applications run in front of you.",
      "tokens": [
        51464,
        293,
        264,
        5821,
        1190,
        294,
        1868,
        295,
        291,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3788527548313141,
      "compression_ratio": 1.6666666269302368,
      "no_speech_prob": 0.17046819627285004
    },
    {
      "id": 395,
      "seek": 114900,
      "start": 1173.0,
      "end": 1175.0,
      "text": " That's the other thing",
      "tokens": [
        51564,
        663,
        311,
        264,
        661,
        551,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3788527548313141,
      "compression_ratio": 1.6666666269302368,
      "no_speech_prob": 0.17046819627285004
    },
    {
      "id": 396,
      "seek": 114900,
      "start": 1175.0,
      "end": 1177.0,
      "text": " that also came up",
      "tokens": [
        51664,
        300,
        611,
        1361,
        493,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3788527548313141,
      "compression_ratio": 1.6666666269302368,
      "no_speech_prob": 0.17046819627285004
    },
    {
      "id": 397,
      "seek": 117700,
      "start": 1177.0,
      "end": 1179.0,
      "text": " in the past.",
      "tokens": [
        50364,
        294,
        264,
        1791,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39095211029052734,
      "compression_ratio": 1.562248945236206,
      "no_speech_prob": 0.0539383739233017
    },
    {
      "id": 398,
      "seek": 117700,
      "start": 1179.0,
      "end": 1181.0,
      "text": " I used to work for a company called VMware",
      "tokens": [
        50464,
        286,
        1143,
        281,
        589,
        337,
        257,
        2237,
        1219,
        40146,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39095211029052734,
      "compression_ratio": 1.562248945236206,
      "no_speech_prob": 0.0539383739233017
    },
    {
      "id": 399,
      "seek": 117700,
      "start": 1181.0,
      "end": 1183.0,
      "text": " and somehow got to know",
      "tokens": [
        50564,
        293,
        6063,
        658,
        281,
        458,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39095211029052734,
      "compression_ratio": 1.562248945236206,
      "no_speech_prob": 0.0539383739233017
    },
    {
      "id": 400,
      "seek": 117700,
      "start": 1183.0,
      "end": 1185.0,
      "text": " what their model is.",
      "tokens": [
        50664,
        437,
        641,
        2316,
        307,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39095211029052734,
      "compression_ratio": 1.562248945236206,
      "no_speech_prob": 0.0539383739233017
    },
    {
      "id": 401,
      "seek": 117700,
      "start": 1185.0,
      "end": 1187.0,
      "text": " And that's basically what you're explaining right now.",
      "tokens": [
        50764,
        400,
        300,
        311,
        1936,
        437,
        291,
        434,
        13468,
        558,
        586,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39095211029052734,
      "compression_ratio": 1.562248945236206,
      "no_speech_prob": 0.0539383739233017
    },
    {
      "id": 402,
      "seek": 117700,
      "start": 1187.0,
      "end": 1189.0,
      "text": " So you just throw out servers, consolidate",
      "tokens": [
        50864,
        407,
        291,
        445,
        3507,
        484,
        15909,
        11,
        49521,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39095211029052734,
      "compression_ratio": 1.562248945236206,
      "no_speech_prob": 0.0539383739233017
    },
    {
      "id": 403,
      "seek": 117700,
      "start": 1189.0,
      "end": 1191.0,
      "text": " through virtualization, you just win money.",
      "tokens": [
        50964,
        807,
        6374,
        2144,
        11,
        291,
        445,
        1942,
        1460,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39095211029052734,
      "compression_ratio": 1.562248945236206,
      "no_speech_prob": 0.0539383739233017
    },
    {
      "id": 404,
      "seek": 117700,
      "start": 1191.0,
      "end": 1193.0,
      "text": " You can just calculate that.",
      "tokens": [
        51064,
        509,
        393,
        445,
        8873,
        300,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39095211029052734,
      "compression_ratio": 1.562248945236206,
      "no_speech_prob": 0.0539383739233017
    },
    {
      "id": 405,
      "seek": 117700,
      "start": 1193.0,
      "end": 1195.0,
      "text": " So that we",
      "tokens": [
        51164,
        407,
        300,
        321,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39095211029052734,
      "compression_ratio": 1.562248945236206,
      "no_speech_prob": 0.0539383739233017
    },
    {
      "id": 406,
      "seek": 117700,
      "start": 1195.0,
      "end": 1197.0,
      "text": " actually tell this story",
      "tokens": [
        51264,
        767,
        980,
        341,
        1657,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39095211029052734,
      "compression_ratio": 1.562248945236206,
      "no_speech_prob": 0.0539383739233017
    },
    {
      "id": 407,
      "seek": 117700,
      "start": 1197.0,
      "end": 1199.0,
      "text": " for a longer time.",
      "tokens": [
        51364,
        337,
        257,
        2854,
        565,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39095211029052734,
      "compression_ratio": 1.562248945236206,
      "no_speech_prob": 0.0539383739233017
    },
    {
      "id": 408,
      "seek": 117700,
      "start": 1199.0,
      "end": 1201.0,
      "text": " Just because",
      "tokens": [
        51464,
        1449,
        570,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39095211029052734,
      "compression_ratio": 1.562248945236206,
      "no_speech_prob": 0.0539383739233017
    },
    {
      "id": 409,
      "seek": 117700,
      "start": 1201.0,
      "end": 1203.0,
      "text": " you want to reduce costs.",
      "tokens": [
        51564,
        291,
        528,
        281,
        5407,
        5497,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39095211029052734,
      "compression_ratio": 1.562248945236206,
      "no_speech_prob": 0.0539383739233017
    },
    {
      "id": 410,
      "seek": 117700,
      "start": 1203.0,
      "end": 1205.0,
      "text": " So the nice thing about",
      "tokens": [
        51664,
        407,
        264,
        1481,
        551,
        466,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39095211029052734,
      "compression_ratio": 1.562248945236206,
      "no_speech_prob": 0.0539383739233017
    },
    {
      "id": 411,
      "seek": 120500,
      "start": 1205.0,
      "end": 1207.0,
      "text": " green software is",
      "tokens": [
        50364,
        3092,
        4722,
        307,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34570321440696716,
      "compression_ratio": 1.5499999523162842,
      "no_speech_prob": 0.06106085330247879
    },
    {
      "id": 412,
      "seek": 120500,
      "start": 1207.0,
      "end": 1209.0,
      "text": " that it is",
      "tokens": [
        50464,
        300,
        309,
        307,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34570321440696716,
      "compression_ratio": 1.5499999523162842,
      "no_speech_prob": 0.06106085330247879
    },
    {
      "id": 413,
      "seek": 120500,
      "start": 1209.0,
      "end": 1211.0,
      "text": " a climate-friendly",
      "tokens": [
        50564,
        257,
        5659,
        12,
        22864,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34570321440696716,
      "compression_ratio": 1.5499999523162842,
      "no_speech_prob": 0.06106085330247879
    },
    {
      "id": 414,
      "seek": 120500,
      "start": 1211.0,
      "end": 1213.0,
      "text": " resource-saving software",
      "tokens": [
        50664,
        7684,
        12,
        82,
        6152,
        4722,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34570321440696716,
      "compression_ratio": 1.5499999523162842,
      "no_speech_prob": 0.06106085330247879
    },
    {
      "id": 415,
      "seek": 120500,
      "start": 1213.0,
      "end": 1215.0,
      "text": " that is actually",
      "tokens": [
        50764,
        300,
        307,
        767,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34570321440696716,
      "compression_ratio": 1.5499999523162842,
      "no_speech_prob": 0.06106085330247879
    },
    {
      "id": 416,
      "seek": 120500,
      "start": 1215.0,
      "end": 1217.0,
      "text": " always cheaper in operation.",
      "tokens": [
        50864,
        1009,
        12284,
        294,
        6916,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34570321440696716,
      "compression_ratio": 1.5499999523162842,
      "no_speech_prob": 0.06106085330247879
    },
    {
      "id": 417,
      "seek": 120500,
      "start": 1217.0,
      "end": 1219.0,
      "text": " So the efficiency",
      "tokens": [
        50964,
        407,
        264,
        10493,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34570321440696716,
      "compression_ratio": 1.5499999523162842,
      "no_speech_prob": 0.06106085330247879
    },
    {
      "id": 418,
      "seek": 120500,
      "start": 1219.0,
      "end": 1221.0,
      "text": " just makes euros.",
      "tokens": [
        51064,
        445,
        1669,
        14160,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34570321440696716,
      "compression_ratio": 1.5499999523162842,
      "no_speech_prob": 0.06106085330247879
    },
    {
      "id": 419,
      "seek": 120500,
      "start": 1221.0,
      "end": 1223.0,
      "text": " That's great.",
      "tokens": [
        51164,
        663,
        311,
        869,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34570321440696716,
      "compression_ratio": 1.5499999523162842,
      "no_speech_prob": 0.06106085330247879
    },
    {
      "id": 420,
      "seek": 120500,
      "start": 1223.0,
      "end": 1225.0,
      "text": " That means, if I have a green software,",
      "tokens": [
        51264,
        663,
        1355,
        11,
        498,
        286,
        362,
        257,
        3092,
        4722,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34570321440696716,
      "compression_ratio": 1.5499999523162842,
      "no_speech_prob": 0.06106085330247879
    },
    {
      "id": 421,
      "seek": 120500,
      "start": 1225.0,
      "end": 1227.0,
      "text": " I usually work with cheap software.",
      "tokens": [
        51364,
        286,
        2673,
        589,
        365,
        7084,
        4722,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34570321440696716,
      "compression_ratio": 1.5499999523162842,
      "no_speech_prob": 0.06106085330247879
    },
    {
      "id": 422,
      "seek": 120500,
      "start": 1227.0,
      "end": 1229.0,
      "text": " The",
      "tokens": [
        51464,
        440,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34570321440696716,
      "compression_ratio": 1.5499999523162842,
      "no_speech_prob": 0.06106085330247879
    },
    {
      "id": 423,
      "seek": 120500,
      "start": 1229.0,
      "end": 1231.0,
      "text": " new thing with us in",
      "tokens": [
        51564,
        777,
        551,
        365,
        505,
        294,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34570321440696716,
      "compression_ratio": 1.5499999523162842,
      "no_speech_prob": 0.06106085330247879
    },
    {
      "id": 424,
      "seek": 120500,
      "start": 1231.0,
      "end": 1233.0,
      "text": " IT, costs",
      "tokens": [
        51664,
        6783,
        11,
        5497,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34570321440696716,
      "compression_ratio": 1.5499999523162842,
      "no_speech_prob": 0.06106085330247879
    },
    {
      "id": 425,
      "seek": 123300,
      "start": 1233.0,
      "end": 1235.0,
      "text": " are not the driver.",
      "tokens": [
        50364,
        366,
        406,
        264,
        6787,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30370181798934937,
      "compression_ratio": 1.580086588859558,
      "no_speech_prob": 0.07179155200719833
    },
    {
      "id": 426,
      "seek": 123300,
      "start": 1235.0,
      "end": 1237.0,
      "text": " What we have in software development",
      "tokens": [
        50464,
        708,
        321,
        362,
        294,
        4722,
        3250,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30370181798934937,
      "compression_ratio": 1.580086588859558,
      "no_speech_prob": 0.07179155200719833
    },
    {
      "id": 427,
      "seek": 123300,
      "start": 1237.0,
      "end": 1239.0,
      "text": " as a driver are features.",
      "tokens": [
        50564,
        382,
        257,
        6787,
        366,
        4122,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30370181798934937,
      "compression_ratio": 1.580086588859558,
      "no_speech_prob": 0.07179155200719833
    },
    {
      "id": 428,
      "seek": 123300,
      "start": 1239.0,
      "end": 1241.0,
      "text": " That we develop",
      "tokens": [
        50664,
        663,
        321,
        1499,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30370181798934937,
      "compression_ratio": 1.580086588859558,
      "no_speech_prob": 0.07179155200719833
    },
    {
      "id": 429,
      "seek": 123300,
      "start": 1241.0,
      "end": 1243.0,
      "text": " business models, that we",
      "tokens": [
        50764,
        1606,
        5245,
        11,
        300,
        321,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30370181798934937,
      "compression_ratio": 1.580086588859558,
      "no_speech_prob": 0.07179155200719833
    },
    {
      "id": 430,
      "seek": 123300,
      "start": 1243.0,
      "end": 1245.0,
      "text": " advance the system, generate",
      "tokens": [
        50864,
        7295,
        264,
        1185,
        11,
        8460,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30370181798934937,
      "compression_ratio": 1.580086588859558,
      "no_speech_prob": 0.07179155200719833
    },
    {
      "id": 431,
      "seek": 123300,
      "start": 1245.0,
      "end": 1247.0,
      "text": " benefits. And if",
      "tokens": [
        50964,
        5311,
        13,
        400,
        498,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30370181798934937,
      "compression_ratio": 1.580086588859558,
      "no_speech_prob": 0.07179155200719833
    },
    {
      "id": 432,
      "seek": 123300,
      "start": 1247.0,
      "end": 1249.0,
      "text": " costs are higher, then they are higher.",
      "tokens": [
        51064,
        5497,
        366,
        2946,
        11,
        550,
        436,
        366,
        2946,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30370181798934937,
      "compression_ratio": 1.580086588859558,
      "no_speech_prob": 0.07179155200719833
    },
    {
      "id": 433,
      "seek": 123300,
      "start": 1249.0,
      "end": 1251.0,
      "text": " Until at some point",
      "tokens": [
        51164,
        9088,
        412,
        512,
        935,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30370181798934937,
      "compression_ratio": 1.580086588859558,
      "no_speech_prob": 0.07179155200719833
    },
    {
      "id": 434,
      "seek": 123300,
      "start": 1251.0,
      "end": 1253.0,
      "text": " they are no longer bearable and then",
      "tokens": [
        51264,
        436,
        366,
        572,
        2854,
        6155,
        712,
        293,
        550,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30370181798934937,
      "compression_ratio": 1.580086588859558,
      "no_speech_prob": 0.07179155200719833
    },
    {
      "id": 435,
      "seek": 123300,
      "start": 1253.0,
      "end": 1255.0,
      "text": " a consolidation happens again.",
      "tokens": [
        51364,
        257,
        39114,
        2314,
        797,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30370181798934937,
      "compression_ratio": 1.580086588859558,
      "no_speech_prob": 0.07179155200719833
    },
    {
      "id": 436,
      "seek": 123300,
      "start": 1255.0,
      "end": 1257.0,
      "text": " But actually, it's more like",
      "tokens": [
        51464,
        583,
        767,
        11,
        309,
        311,
        544,
        411,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30370181798934937,
      "compression_ratio": 1.580086588859558,
      "no_speech_prob": 0.07179155200719833
    },
    {
      "id": 437,
      "seek": 123300,
      "start": 1257.0,
      "end": 1259.0,
      "text": " we're going to another level.",
      "tokens": [
        51564,
        321,
        434,
        516,
        281,
        1071,
        1496,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30370181798934937,
      "compression_ratio": 1.580086588859558,
      "no_speech_prob": 0.07179155200719833
    },
    {
      "id": 438,
      "seek": 123300,
      "start": 1259.0,
      "end": 1261.0,
      "text": " Exactly.",
      "tokens": [
        51664,
        7587,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30370181798934937,
      "compression_ratio": 1.580086588859558,
      "no_speech_prob": 0.07179155200719833
    },
    {
      "id": 439,
      "seek": 126100,
      "start": 1261.0,
      "end": 1263.0,
      "text": " I would like to take the data efficiency",
      "tokens": [
        50364,
        286,
        576,
        411,
        281,
        747,
        264,
        1412,
        10493,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4624914228916168,
      "compression_ratio": 1.265486717224121,
      "no_speech_prob": 0.31597357988357544
    },
    {
      "id": 440,
      "seek": 126100,
      "start": 1263.0,
      "end": 1265.0,
      "text": " with me again and also",
      "tokens": [
        50464,
        365,
        385,
        797,
        293,
        611,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4624914228916168,
      "compression_ratio": 1.265486717224121,
      "no_speech_prob": 0.31597357988357544
    },
    {
      "id": 441,
      "seek": 126100,
      "start": 1265.0,
      "end": 1267.0,
      "text": " throw in this open source question.",
      "tokens": [
        50564,
        3507,
        294,
        341,
        1269,
        4009,
        1168,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4624914228916168,
      "compression_ratio": 1.265486717224121,
      "no_speech_prob": 0.31597357988357544
    },
    {
      "id": 442,
      "seek": 126100,
      "start": 1267.0,
      "end": 1269.0,
      "text": " Because at the moment",
      "tokens": [
        50664,
        1436,
        412,
        264,
        1623,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4624914228916168,
      "compression_ratio": 1.265486717224121,
      "no_speech_prob": 0.31597357988357544
    },
    {
      "id": 443,
      "seek": 126100,
      "start": 1269.0,
      "end": 1271.0,
      "text": " the blue angel",
      "tokens": [
        50764,
        264,
        3344,
        14250,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4624914228916168,
      "compression_ratio": 1.265486717224121,
      "no_speech_prob": 0.31597357988357544
    },
    {
      "id": 444,
      "seek": 126100,
      "start": 1271.0,
      "end": 1273.0,
      "text": " is",
      "tokens": [
        50864,
        307,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4624914228916168,
      "compression_ratio": 1.265486717224121,
      "no_speech_prob": 0.31597357988357544
    },
    {
      "id": 445,
      "seek": 126100,
      "start": 1273.0,
      "end": 1275.0,
      "text": " ...",
      "tokens": [
        50964,
        1097,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4624914228916168,
      "compression_ratio": 1.265486717224121,
      "no_speech_prob": 0.31597357988357544
    },
    {
      "id": 0,
      "seek": 0,
      "start": 1288.19,
      "end": 1293.070000114441,
      "text": " It depends. On YouTube, there is a DIN norm for something like that.",
      "tokens": [
        50364,
        467,
        368,
        494,
        273,
        82,
        13,
        1282,
        3088,
        11,
        456,
        307,
        257,
        413,
        1464,
        2026,
        337,
        746,
        411,
        300,
        13,
        50608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5682968497276306,
      "compression_ratio": 1.56521737575531,
      "no_speech_prob": 0.43376240134239197
    },
    {
      "id": 1,
      "seek": 0,
      "start": 1293.070000114441,
      "end": 1296.6699995422364,
      "text": " It quoted Environment Management Systems in 14001.",
      "tokens": [
        50608,
        467,
        30047,
        35354,
        14781,
        27059,
        294,
        3499,
        628,
        16,
        13,
        50788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5682968497276306,
      "compression_ratio": 1.56521737575531,
      "no_speech_prob": 0.43376240134239197
    },
    {
      "id": 2,
      "seek": 0,
      "start": 1296.6699995422364,
      "end": 1298.5899996185303,
      "text": " You say there is a blue angel for software.",
      "tokens": [
        50788,
        509,
        584,
        456,
        307,
        257,
        3344,
        14250,
        337,
        4722,
        13,
        50884
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5682968497276306,
      "compression_ratio": 1.56521737575531,
      "no_speech_prob": 0.43376240134239197
    },
    {
      "id": 3,
      "seek": 0,
      "start": 1298.5899996185303,
      "end": 1301.5899996185303,
      "text": " That seems to be something similar.",
      "tokens": [
        50884,
        663,
        2544,
        281,
        312,
        746,
        2531,
        13,
        51034
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5682968497276306,
      "compression_ratio": 1.56521737575531,
      "no_speech_prob": 0.43376240134239197
    },
    {
      "id": 4,
      "seek": 0,
      "start": 1301.5899996185303,
      "end": 1304.6699995422364,
      "text": " It's not a norm, it's a seal.",
      "tokens": [
        51034,
        467,
        311,
        406,
        257,
        2026,
        11,
        309,
        311,
        257,
        12185,
        13,
        51188
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5682968497276306,
      "compression_ratio": 1.56521737575531,
      "no_speech_prob": 0.43376240134239197
    },
    {
      "id": 5,
      "seek": 0,
      "start": 1304.6699995422364,
      "end": 1307.19,
      "text": " So we also have a norm.",
      "tokens": [
        51188,
        407,
        321,
        611,
        362,
        257,
        2026,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5682968497276306,
      "compression_ratio": 1.56521737575531,
      "no_speech_prob": 0.43376240134239197
    },
    {
      "id": 6,
      "seek": 0,
      "start": 1307.19,
      "end": 1310.8700003051758,
      "text": " I would like to address both.",
      "tokens": [
        51314,
        286,
        576,
        411,
        281,
        2985,
        1293,
        13,
        51498
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5682968497276306,
      "compression_ratio": 1.56521737575531,
      "no_speech_prob": 0.43376240134239197
    },
    {
      "id": 7,
      "seek": 0,
      "start": 1310.8700003051758,
      "end": 1312.950000228882,
      "text": " First of all, about the seal.",
      "tokens": [
        51498,
        2386,
        295,
        439,
        11,
        466,
        264,
        12185,
        13,
        51602
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5682968497276306,
      "compression_ratio": 1.56521737575531,
      "no_speech_prob": 0.43376240134239197
    },
    {
      "id": 8,
      "seek": 0,
      "start": 1312.950000228882,
      "end": 1315.3499998474122,
      "text": " The blue angel is from the Environment Agency.",
      "tokens": [
        51602,
        440,
        3344,
        14250,
        307,
        490,
        264,
        35354,
        21649,
        13,
        51722
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5682968497276306,
      "compression_ratio": 1.56521737575531,
      "no_speech_prob": 0.43376240134239197
    },
    {
      "id": 9,
      "seek": 2716,
      "start": 1315.3499998474122,
      "end": 1319.5899996185303,
      "text": " There is an environmental seal in Germany and worldwide.",
      "tokens": [
        50364,
        821,
        307,
        364,
        8303,
        12185,
        294,
        7244,
        293,
        13485,
        13,
        50576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5716196894645691,
      "compression_ratio": 1.6403508186340332,
      "no_speech_prob": 0.10784436762332916
    },
    {
      "id": 10,
      "seek": 2716,
      "start": 1319.5899996185303,
      "end": 1322.9100012207032,
      "text": " And there is also one for software, so it just came out.",
      "tokens": [
        50576,
        400,
        456,
        307,
        611,
        472,
        337,
        4722,
        11,
        370,
        309,
        445,
        1361,
        484,
        13,
        50742
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5716196894645691,
      "compression_ratio": 1.6403508186340332,
      "no_speech_prob": 0.10784436762332916
    },
    {
      "id": 11,
      "seek": 2716,
      "start": 1322.9100012207032,
      "end": 1327.2700018310547,
      "text": " And what the blue angel does for software is",
      "tokens": [
        50742,
        400,
        437,
        264,
        3344,
        14250,
        775,
        337,
        4722,
        307,
        50960
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5716196894645691,
      "compression_ratio": 1.6403508186340332,
      "no_speech_prob": 0.10784436762332916
    },
    {
      "id": 12,
      "seek": 2716,
      "start": 1327.2700018310547,
      "end": 1331.7899984741211,
      "text": " that it specifies and requires transparency.",
      "tokens": [
        50960,
        300,
        309,
        1608,
        11221,
        293,
        7029,
        17131,
        13,
        51186
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5716196894645691,
      "compression_ratio": 1.6403508186340332,
      "no_speech_prob": 0.10784436762332916
    },
    {
      "id": 13,
      "seek": 2716,
      "start": 1331.7899984741211,
      "end": 1334.3499998474122,
      "text": " That's the most important thing.",
      "tokens": [
        51186,
        663,
        311,
        264,
        881,
        1021,
        551,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5716196894645691,
      "compression_ratio": 1.6403508186340332,
      "no_speech_prob": 0.10784436762332916
    },
    {
      "id": 14,
      "seek": 2716,
      "start": 1334.3499998474122,
      "end": 1337.6699995422364,
      "text": " It doesn't say that you have to be energy efficient,",
      "tokens": [
        51314,
        467,
        1177,
        380,
        584,
        300,
        291,
        362,
        281,
        312,
        2281,
        7148,
        11,
        51480
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5716196894645691,
      "compression_ratio": 1.6403508186340332,
      "no_speech_prob": 0.10784436762332916
    },
    {
      "id": 15,
      "seek": 2716,
      "start": 1337.6699995422364,
      "end": 1341.6699995422364,
      "text": " it just says that you have to document and show",
      "tokens": [
        51480,
        309,
        445,
        1619,
        300,
        291,
        362,
        281,
        4166,
        293,
        855,
        51680
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5716196894645691,
      "compression_ratio": 1.6403508186340332,
      "no_speech_prob": 0.10784436762332916
    },
    {
      "id": 16,
      "seek": 2716,
      "start": 1341.6699995422364,
      "end": 1344.6699995422364,
      "text": " for all scenarios of use that exist.",
      "tokens": [
        51680,
        337,
        439,
        15077,
        295,
        764,
        300,
        2514,
        13,
        51830
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5716196894645691,
      "compression_ratio": 1.6403508186340332,
      "no_speech_prob": 0.10784436762332916
    },
    {
      "id": 17,
      "seek": 5648,
      "start": 1344.6699995422364,
      "end": 1347.7899984741211,
      "text": " Plus user autonomy.",
      "tokens": [
        50364,
        7721,
        344,
        12484,
        27278,
        13,
        50520
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6536827683448792,
      "compression_ratio": 1.4929577112197876,
      "no_speech_prob": 0.006054357159882784
    },
    {
      "id": 18,
      "seek": 5648,
      "start": 1347.7899984741211,
      "end": 1349.8299993896485,
      "text": " There is open source in the game.",
      "tokens": [
        50520,
        821,
        307,
        1269,
        4009,
        294,
        264,
        1216,
        13,
        50622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6536827683448792,
      "compression_ratio": 1.4929577112197876,
      "no_speech_prob": 0.006054357159882784
    },
    {
      "id": 19,
      "seek": 5648,
      "start": 1349.8299993896485,
      "end": 1351.469998779297,
      "text": " That means you don't have a vendor log.",
      "tokens": [
        50622,
        663,
        1355,
        291,
        500,
        380,
        362,
        257,
        24321,
        3565,
        13,
        50704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6536827683448792,
      "compression_ratio": 1.4929577112197876,
      "no_speech_prob": 0.006054357159882784
    },
    {
      "id": 20,
      "seek": 5648,
      "start": 1351.469998779297,
      "end": 1353.7099966430665,
      "text": " You can get your data out of there.",
      "tokens": [
        50704,
        509,
        393,
        483,
        428,
        1412,
        484,
        295,
        456,
        13,
        50816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6536827683448792,
      "compression_ratio": 1.4929577112197876,
      "no_speech_prob": 0.006054357159882784
    },
    {
      "id": 21,
      "seek": 5648,
      "start": 1353.7099966430665,
      "end": 1360.9100012207032,
      "text": " Updates have to be made secure and tracking-free.",
      "tokens": [
        50816,
        5858,
        67,
        1024,
        362,
        281,
        312,
        1027,
        7144,
        293,
        11603,
        12,
        10792,
        13,
        51176
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6536827683448792,
      "compression_ratio": 1.4929577112197876,
      "no_speech_prob": 0.006054357159882784
    },
    {
      "id": 22,
      "seek": 5648,
      "start": 1360.9100012207032,
      "end": 1367.4299978637696,
      "text": " And the data, the data is quite a hit in the CO2.",
      "tokens": [
        51176,
        400,
        264,
        1412,
        11,
        264,
        1412,
        307,
        1596,
        257,
        2045,
        294,
        264,
        3002,
        17,
        13,
        51502
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6536827683448792,
      "compression_ratio": 1.4929577112197876,
      "no_speech_prob": 0.006054357159882784
    },
    {
      "id": 23,
      "seek": 5648,
      "start": 1367.4299978637696,
      "end": 1370.310002746582,
      "text": " Because we're talking here, it's actually not the amount of data,",
      "tokens": [
        51502,
        1436,
        321,
        434,
        1417,
        510,
        11,
        309,
        311,
        767,
        406,
        264,
        2372,
        295,
        1412,
        11,
        51646
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6536827683448792,
      "compression_ratio": 1.4929577112197876,
      "no_speech_prob": 0.006054357159882784
    },
    {
      "id": 24,
      "seek": 5648,
      "start": 1370.310002746582,
      "end": 1373.1099981689454,
      "text": " but bandwidth latency.",
      "tokens": [
        51646,
        457,
        23647,
        27043,
        13,
        51786
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6536827683448792,
      "compression_ratio": 1.4929577112197876,
      "no_speech_prob": 0.006054357159882784
    },
    {
      "id": 25,
      "seek": 8492,
      "start": 1373.1499990844727,
      "end": 1377.19,
      "text": " Because the cables, the glass fibers, they're all under power.",
      "tokens": [
        50366,
        1436,
        264,
        17555,
        11,
        264,
        4276,
        25252,
        11,
        436,
        434,
        439,
        833,
        1347,
        13,
        50568
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47297295928001404,
      "compression_ratio": 1.7210299968719482,
      "no_speech_prob": 0.028332052752375603
    },
    {
      "id": 26,
      "seek": 8492,
      "start": 1377.19,
      "end": 1380.3899969482422,
      "text": " The switches are under power, they're all running.",
      "tokens": [
        50568,
        440,
        19458,
        366,
        833,
        1347,
        11,
        436,
        434,
        439,
        2614,
        13,
        50728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47297295928001404,
      "compression_ratio": 1.7210299968719482,
      "no_speech_prob": 0.028332052752375603
    },
    {
      "id": 27,
      "seek": 8492,
      "start": 1380.3899969482422,
      "end": 1382.9100012207032,
      "text": " So it doesn't matter what we modulate in.",
      "tokens": [
        50728,
        407,
        309,
        1177,
        380,
        1871,
        437,
        321,
        1072,
        5256,
        294,
        13,
        50854
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47297295928001404,
      "compression_ratio": 1.7210299968719482,
      "no_speech_prob": 0.028332052752375603
    },
    {
      "id": 28,
      "seek": 8492,
      "start": 1382.9100012207032,
      "end": 1385.310002746582,
      "text": " But if what we're transmitting doesn't fit in,",
      "tokens": [
        50854,
        583,
        498,
        437,
        321,
        434,
        7715,
        2414,
        1177,
        380,
        3318,
        294,
        11,
        50974
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47297295928001404,
      "compression_ratio": 1.7210299968719482,
      "no_speech_prob": 0.028332052752375603
    },
    {
      "id": 29,
      "seek": 8492,
      "start": 1385.310002746582,
      "end": 1386.9900030517579,
      "text": " we have to do it again and again.",
      "tokens": [
        50974,
        321,
        362,
        281,
        360,
        309,
        797,
        293,
        797,
        13,
        51058
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47297295928001404,
      "compression_ratio": 1.7210299968719482,
      "no_speech_prob": 0.028332052752375603
    },
    {
      "id": 30,
      "seek": 8492,
      "start": 1386.9900030517579,
      "end": 1392.2300009155274,
      "text": " So we're talking a lot about availability here.",
      "tokens": [
        51058,
        407,
        321,
        434,
        1417,
        257,
        688,
        466,
        17945,
        510,
        13,
        51320
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47297295928001404,
      "compression_ratio": 1.7210299968719482,
      "no_speech_prob": 0.028332052752375603
    },
    {
      "id": 31,
      "seek": 8492,
      "start": 1392.2300009155274,
      "end": 1395.2700018310547,
      "text": " And it's about reducing availability.",
      "tokens": [
        51320,
        400,
        309,
        311,
        466,
        12245,
        17945,
        13,
        51472
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47297295928001404,
      "compression_ratio": 1.7210299968719482,
      "no_speech_prob": 0.028332052752375603
    },
    {
      "id": 32,
      "seek": 8492,
      "start": 1395.2700018310547,
      "end": 1399.8700003051758,
      "text": " And actually, we have a lot of business models",
      "tokens": [
        51472,
        400,
        767,
        11,
        321,
        362,
        257,
        688,
        295,
        1606,
        5245,
        51702
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47297295928001404,
      "compression_ratio": 1.7210299968719482,
      "no_speech_prob": 0.028332052752375603
    },
    {
      "id": 33,
      "seek": 8492,
      "start": 1399.8700003051758,
      "end": 1402.3500036621094,
      "text": " on the Internet or in our world",
      "tokens": [
        51702,
        322,
        264,
        7703,
        420,
        294,
        527,
        1002,
        51826
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47297295928001404,
      "compression_ratio": 1.7210299968719482,
      "no_speech_prob": 0.028332052752375603
    },
    {
      "id": 34,
      "seek": 11416,
      "start": 1402.3500036621094,
      "end": 1405.7899984741211,
      "text": " that are based on advertising and tracking.",
      "tokens": [
        50364,
        300,
        366,
        2361,
        322,
        13097,
        293,
        11603,
        13,
        50536
      ],
      "temperature": 0.0,
      "avg_logprob": -0.494552344083786,
      "compression_ratio": 1.6603773832321167,
      "no_speech_prob": 0.0044174473732709885
    },
    {
      "id": 35,
      "seek": 11416,
      "start": 1405.7899984741211,
      "end": 1408.9900030517579,
      "text": " So if my business model is not based on advertising and tracking,",
      "tokens": [
        50536,
        407,
        498,
        452,
        1606,
        2316,
        307,
        406,
        2361,
        322,
        13097,
        293,
        11603,
        11,
        50696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.494552344083786,
      "compression_ratio": 1.6603773832321167,
      "no_speech_prob": 0.0044174473732709885
    },
    {
      "id": 36,
      "seek": 11416,
      "start": 1408.9900030517579,
      "end": 1411.19,
      "text": " then I have a lot less data.",
      "tokens": [
        50696,
        550,
        286,
        362,
        257,
        688,
        1570,
        1412,
        13,
        50806
      ],
      "temperature": 0.0,
      "avg_logprob": -0.494552344083786,
      "compression_ratio": 1.6603773832321167,
      "no_speech_prob": 0.0044174473732709885
    },
    {
      "id": 37,
      "seek": 11416,
      "start": 1411.19,
      "end": 1412.6700033569336,
      "text": " In general.",
      "tokens": [
        50806,
        682,
        2674,
        13,
        50880
      ],
      "temperature": 0.0,
      "avg_logprob": -0.494552344083786,
      "compression_ratio": 1.6603773832321167,
      "no_speech_prob": 0.0044174473732709885
    },
    {
      "id": 38,
      "seek": 11416,
      "start": 1412.6700033569336,
      "end": 1414.7099966430665,
      "text": " Sometimes that sucks.",
      "tokens": [
        50880,
        4803,
        300,
        15846,
        13,
        50982
      ],
      "temperature": 0.0,
      "avg_logprob": -0.494552344083786,
      "compression_ratio": 1.6603773832321167,
      "no_speech_prob": 0.0044174473732709885
    },
    {
      "id": 39,
      "seek": 11416,
      "start": 1414.7099966430665,
      "end": 1417.5899938964844,
      "text": " To the other question about the norm.",
      "tokens": [
        50982,
        1407,
        264,
        661,
        1168,
        466,
        264,
        2026,
        13,
        51126
      ],
      "temperature": 0.0,
      "avg_logprob": -0.494552344083786,
      "compression_ratio": 1.6603773832321167,
      "no_speech_prob": 0.0044174473732709885
    },
    {
      "id": 40,
      "seek": 11416,
      "start": 1417.5899938964844,
      "end": 1420.6699957275391,
      "text": " The blue arrow is a seal.",
      "tokens": [
        51126,
        440,
        3344,
        594,
        340,
        86,
        307,
        257,
        12185,
        13,
        51280
      ],
      "temperature": 0.0,
      "avg_logprob": -0.494552344083786,
      "compression_ratio": 1.6603773832321167,
      "no_speech_prob": 0.0044174473732709885
    },
    {
      "id": 41,
      "seek": 11416,
      "start": 1420.6699957275391,
      "end": 1423.3899969482422,
      "text": " There are also seals regarding websites,",
      "tokens": [
        51280,
        821,
        366,
        611,
        32031,
        8595,
        12891,
        11,
        51416
      ],
      "temperature": 0.0,
      "avg_logprob": -0.494552344083786,
      "compression_ratio": 1.6603773832321167,
      "no_speech_prob": 0.0044174473732709885
    },
    {
      "id": 42,
      "seek": 11416,
      "start": 1423.3899969482422,
      "end": 1425.8699926757813,
      "text": " where you can optimize websites.",
      "tokens": [
        51416,
        689,
        291,
        393,
        19719,
        12891,
        13,
        51540
      ],
      "temperature": 0.0,
      "avg_logprob": -0.494552344083786,
      "compression_ratio": 1.6603773832321167,
      "no_speech_prob": 0.0044174473732709885
    },
    {
      "id": 43,
      "seek": 11416,
      "start": 1425.8699926757813,
      "end": 1430.2299932861329,
      "text": " I can recommend CleanerWeb, they do that.",
      "tokens": [
        51540,
        286,
        393,
        2748,
        18463,
        260,
        4360,
        65,
        11,
        436,
        360,
        300,
        13,
        51758
      ],
      "temperature": 0.0,
      "avg_logprob": -0.494552344083786,
      "compression_ratio": 1.6603773832321167,
      "no_speech_prob": 0.0044174473732709885
    },
    {
      "id": 44,
      "seek": 14204,
      "start": 1430.2299932861329,
      "end": 1433.6699957275391,
      "text": " I can open the website.",
      "tokens": [
        50364,
        286,
        393,
        1269,
        264,
        3144,
        13,
        50536
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5653799772262573,
      "compression_ratio": 1.5321637392044067,
      "no_speech_prob": 0.05393274128437042
    },
    {
      "id": 45,
      "seek": 14204,
      "start": 1433.6699957275391,
      "end": 1436.5899938964844,
      "text": " You're talking about the Green Web Foundation, I think.",
      "tokens": [
        50536,
        509,
        434,
        1417,
        466,
        264,
        6969,
        9573,
        10335,
        11,
        286,
        519,
        13,
        50682
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5653799772262573,
      "compression_ratio": 1.5321637392044067,
      "no_speech_prob": 0.05393274128437042
    },
    {
      "id": 46,
      "seek": 14204,
      "start": 1436.5899938964844,
      "end": 1438.6699957275391,
      "text": " I have the link.",
      "tokens": [
        50682,
        286,
        362,
        264,
        2113,
        13,
        50786
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5653799772262573,
      "compression_ratio": 1.5321637392044067,
      "no_speech_prob": 0.05393274128437042
    },
    {
      "id": 47,
      "seek": 14204,
      "start": 1438.6699957275391,
      "end": 1441.9900030517579,
      "text": " So CleanerWeb.",
      "tokens": [
        50786,
        407,
        18463,
        260,
        4360,
        65,
        13,
        50952
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5653799772262573,
      "compression_ratio": 1.5321637392044067,
      "no_speech_prob": 0.05393274128437042
    },
    {
      "id": 48,
      "seek": 14204,
      "start": 1441.9900030517579,
      "end": 1445.3500036621094,
      "text": " These are colleagues from Munich.",
      "tokens": [
        50952,
        1981,
        366,
        7734,
        490,
        40601,
        13,
        51120
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5653799772262573,
      "compression_ratio": 1.5321637392044067,
      "no_speech_prob": 0.05393274128437042
    },
    {
      "id": 49,
      "seek": 14204,
      "start": 1445.3500036621094,
      "end": 1446.8699926757813,
      "text": " So they help with the optimization.",
      "tokens": [
        51120,
        407,
        436,
        854,
        365,
        264,
        19618,
        13,
        51196
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5653799772262573,
      "compression_ratio": 1.5321637392044067,
      "no_speech_prob": 0.05393274128437042
    },
    {
      "id": 50,
      "seek": 14204,
      "start": 1446.8699926757813,
      "end": 1448.4300054931641,
      "text": " They also have a seal.",
      "tokens": [
        51196,
        814,
        611,
        362,
        257,
        12185,
        13,
        51274
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5653799772262573,
      "compression_ratio": 1.5321637392044067,
      "no_speech_prob": 0.05393274128437042
    },
    {
      "id": 51,
      "seek": 14204,
      "start": 1448.4300054931641,
      "end": 1453.6300024414063,
      "text": " And the Green Web Foundation,",
      "tokens": [
        51274,
        400,
        264,
        6969,
        9573,
        10335,
        11,
        51534
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5653799772262573,
      "compression_ratio": 1.5321637392044067,
      "no_speech_prob": 0.05393274128437042
    },
    {
      "id": 52,
      "seek": 14204,
      "start": 1453.6300024414063,
      "end": 1457.3899969482422,
      "text": " they take care of the topic",
      "tokens": [
        51534,
        436,
        747,
        1127,
        295,
        264,
        4829,
        51722
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5653799772262573,
      "compression_ratio": 1.5321637392044067,
      "no_speech_prob": 0.05393274128437042
    },
    {
      "id": 53,
      "seek": 16920,
      "start": 1457.3899969482422,
      "end": 1464.3500036621094,
      "text": " like web, HTTP, websites and such protocols.",
      "tokens": [
        50364,
        411,
        3670,
        11,
        33283,
        11,
        12891,
        293,
        1270,
        20618,
        13,
        50712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5324482917785645,
      "compression_ratio": 1.389937162399292,
      "no_speech_prob": 0.04543310031294823
    },
    {
      "id": 54,
      "seek": 16920,
      "start": 1464.3500036621094,
      "end": 1470.3099951171876,
      "text": " They also have a framework, a tool,",
      "tokens": [
        50712,
        814,
        611,
        362,
        257,
        8388,
        11,
        257,
        2290,
        11,
        51010
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5324482917785645,
      "compression_ratio": 1.389937162399292,
      "no_speech_prob": 0.04543310031294823
    },
    {
      "id": 55,
      "seek": 16920,
      "start": 1470.3099951171876,
      "end": 1474.3899969482422,
      "text": " CO2JS, where I can measure that.",
      "tokens": [
        51010,
        3002,
        17,
        41,
        50,
        11,
        689,
        286,
        393,
        3481,
        300,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5324482917785645,
      "compression_ratio": 1.389937162399292,
      "no_speech_prob": 0.04543310031294823
    },
    {
      "id": 56,
      "seek": 16920,
      "start": 1474.3899969482422,
      "end": 1478.9900030517579,
      "text": " And here you can create a correlation",
      "tokens": [
        51214,
        400,
        510,
        291,
        393,
        1884,
        257,
        20009,
        51444
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5324482917785645,
      "compression_ratio": 1.389937162399292,
      "no_speech_prob": 0.04543310031294823
    },
    {
      "id": 57,
      "seek": 16920,
      "start": 1478.9900030517579,
      "end": 1482.5899938964844,
      "text": " between data transmission and CO2 emissions.",
      "tokens": [
        51444,
        1296,
        1412,
        11574,
        293,
        3002,
        17,
        14607,
        13,
        51624
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5324482917785645,
      "compression_ratio": 1.389937162399292,
      "no_speech_prob": 0.04543310031294823
    },
    {
      "id": 58,
      "seek": 16920,
      "start": 1482.5899938964844,
      "end": 1485.7900061035157,
      "text": " So that's a correlation.",
      "tokens": [
        51624,
        407,
        300,
        311,
        257,
        20009,
        13,
        51784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5324482917785645,
      "compression_ratio": 1.389937162399292,
      "no_speech_prob": 0.04543310031294823
    },
    {
      "id": 59,
      "seek": 19760,
      "start": 1485.7900061035157,
      "end": 1488.0299963378907,
      "text": " You don't have much more to measure,",
      "tokens": [
        50364,
        509,
        500,
        380,
        362,
        709,
        544,
        281,
        3481,
        11,
        50476
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5528237819671631,
      "compression_ratio": 1.3855421543121338,
      "no_speech_prob": 0.012786276638507843
    },
    {
      "id": 60,
      "seek": 19760,
      "start": 1488.0299963378907,
      "end": 1492.0299963378907,
      "text": " but it works quite well.",
      "tokens": [
        50476,
        457,
        309,
        1985,
        1596,
        731,
        13,
        50676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5528237819671631,
      "compression_ratio": 1.3855421543121338,
      "no_speech_prob": 0.012786276638507843
    },
    {
      "id": 61,
      "seek": 19760,
      "start": 1492.0299963378907,
      "end": 1493.5500006103516,
      "text": " So here's another seal.",
      "tokens": [
        50676,
        407,
        510,
        311,
        1071,
        12185,
        13,
        50752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5528237819671631,
      "compression_ratio": 1.3855421543121338,
      "no_speech_prob": 0.012786276638507843
    },
    {
      "id": 62,
      "seek": 19760,
      "start": 1493.5500006103516,
      "end": 1503.710004272461,
      "text": " And then there's the Green Software Foundation.",
      "tokens": [
        50752,
        400,
        550,
        456,
        311,
        264,
        6969,
        27428,
        10335,
        13,
        51260
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5528237819671631,
      "compression_ratio": 1.3855421543121338,
      "no_speech_prob": 0.012786276638507843
    },
    {
      "id": 63,
      "seek": 19760,
      "start": 1503.710004272461,
      "end": 1509.9900030517579,
      "text": " There's the STI, the Software Carbon Intensity.",
      "tokens": [
        51260,
        821,
        311,
        264,
        4904,
        40,
        11,
        264,
        27428,
        31453,
        5681,
        6859,
        13,
        51574
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5528237819671631,
      "compression_ratio": 1.3855421543121338,
      "no_speech_prob": 0.012786276638507843
    },
    {
      "id": 64,
      "seek": 19760,
      "start": 1509.9900030517579,
      "end": 1511.6300024414063,
      "text": " We can go back to that.",
      "tokens": [
        51574,
        492,
        393,
        352,
        646,
        281,
        300,
        13,
        51656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5528237819671631,
      "compression_ratio": 1.3855421543121338,
      "no_speech_prob": 0.012786276638507843
    },
    {
      "id": 65,
      "seek": 19760,
      "start": 1511.6300024414063,
      "end": 1514.8699926757813,
      "text": " This is an ISO standard.",
      "tokens": [
        51656,
        639,
        307,
        364,
        25042,
        3832,
        13,
        51818
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5528237819671631,
      "compression_ratio": 1.3855421543121338,
      "no_speech_prob": 0.012786276638507843
    },
    {
      "id": 66,
      "seek": 22668,
      "start": 1514.8699926757813,
      "end": 1523.8699926757813,
      "text": " And that determines how I can measure the emissions of software.",
      "tokens": [
        50364,
        400,
        300,
        24799,
        577,
        286,
        393,
        3481,
        264,
        14607,
        295,
        4722,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6105555891990662,
      "compression_ratio": 1.4585987329483032,
      "no_speech_prob": 0.00398676935583353
    },
    {
      "id": 67,
      "seek": 22668,
      "start": 1523.8699926757813,
      "end": 1530.0700048828126,
      "text": " And to be complete, I would like to show that.",
      "tokens": [
        50814,
        400,
        281,
        312,
        1209,
        3498,
        11,
        286,
        576,
        411,
        281,
        855,
        300,
        13,
        51124
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6105555891990662,
      "compression_ratio": 1.4585987329483032,
      "no_speech_prob": 0.00398676935583353
    },
    {
      "id": 68,
      "seek": 22668,
      "start": 1530.0700048828126,
      "end": 1533.2700018310547,
      "text": " Because that's the question that always comes up.",
      "tokens": [
        51124,
        1436,
        300,
        311,
        264,
        1168,
        300,
        1009,
        1487,
        493,
        13,
        51284
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6105555891990662,
      "compression_ratio": 1.4585987329483032,
      "no_speech_prob": 0.00398676935583353
    },
    {
      "id": 69,
      "seek": 22668,
      "start": 1537.5500006103516,
      "end": 1543.8299993896485,
      "text": " I'll put the links in the description of the podcast and the video.",
      "tokens": [
        51498,
        286,
        603,
        829,
        264,
        6123,
        294,
        264,
        3855,
        295,
        264,
        7367,
        293,
        264,
        960,
        13,
        51812
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6105555891990662,
      "compression_ratio": 1.4585987329483032,
      "no_speech_prob": 0.00398676935583353
    },
    {
      "id": 70,
      "seek": 25564,
      "start": 1543.8299993896485,
      "end": 1548.9100012207032,
      "text": " I have a graphic here for those who only hear that.",
      "tokens": [
        50364,
        286,
        362,
        257,
        14089,
        510,
        337,
        729,
        567,
        787,
        1568,
        300,
        13,
        50618
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4500260353088379,
      "compression_ratio": 1.542553186416626,
      "no_speech_prob": 0.02503187395632267
    },
    {
      "id": 71,
      "seek": 25564,
      "start": 1548.9100012207032,
      "end": 1552.950009765625,
      "text": " The Software Carbon Intensity is a number",
      "tokens": [
        50618,
        440,
        27428,
        31453,
        5681,
        6859,
        307,
        257,
        1230,
        50820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4500260353088379,
      "compression_ratio": 1.542553186416626,
      "no_speech_prob": 0.02503187395632267
    },
    {
      "id": 72,
      "seek": 25564,
      "start": 1552.950009765625,
      "end": 1559.9100012207032,
      "text": " that describes the CO2 emissions of software.",
      "tokens": [
        50820,
        300,
        15626,
        264,
        3002,
        17,
        14607,
        295,
        4722,
        13,
        51168
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4500260353088379,
      "compression_ratio": 1.542553186416626,
      "no_speech_prob": 0.02503187395632267
    },
    {
      "id": 73,
      "seek": 25564,
      "start": 1559.9100012207032,
      "end": 1566.0700048828126,
      "text": " And what you do is you take the energy that the software uses,",
      "tokens": [
        51168,
        400,
        437,
        291,
        360,
        307,
        291,
        747,
        264,
        2281,
        300,
        264,
        4722,
        4960,
        11,
        51476
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4500260353088379,
      "compression_ratio": 1.542553186416626,
      "no_speech_prob": 0.02503187395632267
    },
    {
      "id": 74,
      "seek": 25564,
      "start": 1566.0700048828126,
      "end": 1568.230008544922,
      "text": " that is, the power consumption,",
      "tokens": [
        51476,
        300,
        307,
        11,
        264,
        1347,
        12126,
        11,
        51584
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4500260353088379,
      "compression_ratio": 1.542553186416626,
      "no_speech_prob": 0.02503187395632267
    },
    {
      "id": 75,
      "seek": 25564,
      "start": 1568.230008544922,
      "end": 1572.0299963378907,
      "text": " multiply it with the emission factor of the power grid,",
      "tokens": [
        51584,
        12972,
        309,
        365,
        264,
        29513,
        5952,
        295,
        264,
        1347,
        10748,
        11,
        51774
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4500260353088379,
      "compression_ratio": 1.542553186416626,
      "no_speech_prob": 0.02503187395632267
    },
    {
      "id": 76,
      "seek": 28384,
      "start": 1572.0299963378907,
      "end": 1574.3500036621094,
      "text": " that is, the Grid Carbon Intensity,",
      "tokens": [
        50364,
        300,
        307,
        11,
        264,
        42905,
        31453,
        5681,
        6859,
        11,
        50480
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4524872303009033,
      "compression_ratio": 1.5072463750839233,
      "no_speech_prob": 0.007128096651285887
    },
    {
      "id": 77,
      "seek": 28384,
      "start": 1574.3500036621094,
      "end": 1577.19,
      "text": " the CO2 intensity of the power grid,",
      "tokens": [
        50480,
        264,
        3002,
        17,
        13749,
        295,
        264,
        1347,
        10748,
        11,
        50622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4524872303009033,
      "compression_ratio": 1.5072463750839233,
      "no_speech_prob": 0.007128096651285887
    },
    {
      "id": 78,
      "seek": 28384,
      "start": 1577.19,
      "end": 1582.1499914550782,
      "text": " and add the binding emissions,",
      "tokens": [
        50622,
        293,
        909,
        264,
        17359,
        14607,
        11,
        50870
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4524872303009033,
      "compression_ratio": 1.5072463750839233,
      "no_speech_prob": 0.007128096651285887
    },
    {
      "id": 79,
      "seek": 28384,
      "start": 1582.1499914550782,
      "end": 1584.1499914550782,
      "text": " i.e. the hardware emissions.",
      "tokens": [
        50870,
        741,
        13,
        68,
        13,
        264,
        8837,
        14607,
        13,
        50970
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4524872303009033,
      "compression_ratio": 1.5072463750839233,
      "no_speech_prob": 0.007128096651285887
    },
    {
      "id": 80,
      "seek": 28384,
      "start": 1584.1499914550782,
      "end": 1589.3500036621094,
      "text": " And that gives me an overall amount of CO2.",
      "tokens": [
        50970,
        400,
        300,
        2709,
        385,
        364,
        4787,
        2372,
        295,
        3002,
        17,
        13,
        51230
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4524872303009033,
      "compression_ratio": 1.5072463750839233,
      "no_speech_prob": 0.007128096651285887
    },
    {
      "id": 81,
      "seek": 28384,
      "start": 1589.3500036621094,
      "end": 1591.5499853515626,
      "text": " And to evaluate that,",
      "tokens": [
        51230,
        400,
        281,
        13059,
        300,
        11,
        51340
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4524872303009033,
      "compression_ratio": 1.5072463750839233,
      "no_speech_prob": 0.007128096651285887
    },
    {
      "id": 82,
      "seek": 28384,
      "start": 1591.5499853515626,
      "end": 1593.5899938964844,
      "text": " similar to a blue angel,",
      "tokens": [
        51340,
        2531,
        281,
        257,
        3344,
        14250,
        11,
        51442
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4524872303009033,
      "compression_ratio": 1.5072463750839233,
      "no_speech_prob": 0.007128096651285887
    },
    {
      "id": 83,
      "seek": 28384,
      "start": 1593.5899938964844,
      "end": 1596.230008544922,
      "text": " I can make a functional unit for it.",
      "tokens": [
        51442,
        286,
        393,
        652,
        257,
        11745,
        4985,
        337,
        309,
        13,
        51574
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4524872303009033,
      "compression_ratio": 1.5072463750839233,
      "no_speech_prob": 0.007128096651285887
    },
    {
      "id": 84,
      "seek": 28384,
      "start": 1596.230008544922,
      "end": 1598.6700109863282,
      "text": " So I can say per order process,",
      "tokens": [
        51574,
        407,
        286,
        393,
        584,
        680,
        1668,
        1399,
        11,
        51696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4524872303009033,
      "compression_ratio": 1.5072463750839233,
      "no_speech_prob": 0.007128096651285887
    },
    {
      "id": 85,
      "seek": 28384,
      "start": 1598.6700109863282,
      "end": 1601.7900061035157,
      "text": " per logged in user,",
      "tokens": [
        51696,
        680,
        27231,
        294,
        4195,
        11,
        51852
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4524872303009033,
      "compression_ratio": 1.5072463750839233,
      "no_speech_prob": 0.007128096651285887
    },
    {
      "id": 86,
      "seek": 31360,
      "start": 1601.7900061035157,
      "end": 1604.1499914550782,
      "text": " per something,",
      "tokens": [
        50364,
        680,
        746,
        11,
        50482
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49536916613578796,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.0010794776026159525
    },
    {
      "id": 87,
      "seek": 31360,
      "start": 1604.1499914550782,
      "end": 1606.3099951171876,
      "text": " per usage scenario,",
      "tokens": [
        50482,
        680,
        14924,
        9005,
        11,
        50590
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49536916613578796,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.0010794776026159525
    },
    {
      "id": 88,
      "seek": 31360,
      "start": 1606.3099951171876,
      "end": 1607.709989013672,
      "text": " what you have there.",
      "tokens": [
        50590,
        437,
        291,
        362,
        456,
        13,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49536916613578796,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.0010794776026159525
    },
    {
      "id": 89,
      "seek": 31360,
      "start": 1607.709989013672,
      "end": 1610.0299963378907,
      "text": " And then I get a number.",
      "tokens": [
        50660,
        400,
        550,
        286,
        483,
        257,
        1230,
        13,
        50776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49536916613578796,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.0010794776026159525
    },
    {
      "id": 90,
      "seek": 31360,
      "start": 1610.0299963378907,
      "end": 1612.429990234375,
      "text": " And that's maybe an average number.",
      "tokens": [
        50776,
        400,
        300,
        311,
        1310,
        364,
        4274,
        1230,
        13,
        50896
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49536916613578796,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.0010794776026159525
    },
    {
      "id": 91,
      "seek": 31360,
      "start": 1612.429990234375,
      "end": 1616.5499853515626,
      "text": " If I want to, I can make it more detailed.",
      "tokens": [
        50896,
        759,
        286,
        528,
        281,
        11,
        286,
        393,
        652,
        309,
        544,
        9942,
        13,
        51102
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49536916613578796,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.0010794776026159525
    },
    {
      "id": 92,
      "seek": 31360,
      "start": 1616.5499853515626,
      "end": 1622.3099951171876,
      "text": " And that's relatively easy to measure",
      "tokens": [
        51102,
        400,
        300,
        311,
        7226,
        1858,
        281,
        3481,
        51390
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49536916613578796,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.0010794776026159525
    },
    {
      "id": 93,
      "seek": 31360,
      "start": 1622.3099951171876,
      "end": 1624.6700109863282,
      "text": " and relatively easy to document.",
      "tokens": [
        51390,
        293,
        7226,
        1858,
        281,
        4166,
        13,
        51508
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49536916613578796,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.0010794776026159525
    },
    {
      "id": 94,
      "seek": 31360,
      "start": 1624.6700109863282,
      "end": 1626.8699926757813,
      "text": " And a lot of people,",
      "tokens": [
        51508,
        400,
        257,
        688,
        295,
        561,
        11,
        51618
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49536916613578796,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.0010794776026159525
    },
    {
      "id": 95,
      "seek": 31360,
      "start": 1626.8699926757813,
      "end": 1629.469998779297,
      "text": " me and all other people,",
      "tokens": [
        51618,
        385,
        293,
        439,
        661,
        561,
        11,
        51748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49536916613578796,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.0010794776026159525
    },
    {
      "id": 96,
      "seek": 34128,
      "start": 1629.5100073242188,
      "end": 1630.9899877929688,
      "text": " when we produce software,",
      "tokens": [
        50366,
        562,
        321,
        5258,
        4722,
        11,
        50440
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5844825506210327,
      "compression_ratio": 1.513157844543457,
      "no_speech_prob": 0.020133865997195244
    },
    {
      "id": 97,
      "seek": 34128,
      "start": 1630.9899877929688,
      "end": 1634.3099951171876,
      "text": " that we publish this software Carbon Intensity.",
      "tokens": [
        50440,
        300,
        321,
        11374,
        341,
        4722,
        31453,
        5681,
        6859,
        13,
        50606
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5844825506210327,
      "compression_ratio": 1.513157844543457,
      "no_speech_prob": 0.020133865997195244
    },
    {
      "id": 98,
      "seek": 34128,
      "start": 1634.3099951171876,
      "end": 1636.3099951171876,
      "text": " Live, for example.",
      "tokens": [
        50606,
        10385,
        11,
        337,
        1365,
        13,
        50706
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5844825506210327,
      "compression_ratio": 1.513157844543457,
      "no_speech_prob": 0.020133865997195244
    },
    {
      "id": 99,
      "seek": 34128,
      "start": 1636.3099951171876,
      "end": 1639.7499975585938,
      "text": " Question 2 from Eddie Penz,",
      "tokens": [
        50706,
        14464,
        568,
        490,
        23911,
        10571,
        89,
        11,
        50878
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5844825506210327,
      "compression_ratio": 1.513157844543457,
      "no_speech_prob": 0.020133865997195244
    },
    {
      "id": 100,
      "seek": 34128,
      "start": 1639.7499975585938,
      "end": 1642.6700109863282,
      "text": " he asked if you can describe the R again in more detail.",
      "tokens": [
        50878,
        415,
        2351,
        498,
        291,
        393,
        6786,
        264,
        497,
        797,
        294,
        544,
        2607,
        13,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5844825506210327,
      "compression_ratio": 1.513157844543457,
      "no_speech_prob": 0.020133865997195244
    },
    {
      "id": 101,
      "seek": 34128,
      "start": 1642.6700109863282,
      "end": 1644.429990234375,
      "text": " I think you have that right now.",
      "tokens": [
        51024,
        286,
        519,
        291,
        362,
        300,
        558,
        586,
        13,
        51112
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5844825506210327,
      "compression_ratio": 1.513157844543457,
      "no_speech_prob": 0.020133865997195244
    },
    {
      "id": 102,
      "seek": 34128,
      "start": 1644.429990234375,
      "end": 1648.3500036621094,
      "text": " Is the hardware, the software per request or per order?",
      "tokens": [
        51112,
        1119,
        264,
        8837,
        11,
        264,
        4722,
        680,
        5308,
        420,
        680,
        1668,
        30,
        51308
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5844825506210327,
      "compression_ratio": 1.513157844543457,
      "no_speech_prob": 0.020133865997195244
    },
    {
      "id": 103,
      "seek": 34128,
      "start": 1648.3500036621094,
      "end": 1651.1499914550782,
      "text": " Oh, you can define that.",
      "tokens": [
        51308,
        876,
        11,
        291,
        393,
        6964,
        300,
        13,
        51448
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5844825506210327,
      "compression_ratio": 1.513157844543457,
      "no_speech_prob": 0.020133865997195244
    },
    {
      "id": 104,
      "seek": 34128,
      "start": 1651.1499914550782,
      "end": 1653.6700109863282,
      "text": " And if I now,",
      "tokens": [
        51448,
        400,
        498,
        286,
        586,
        11,
        51574
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5844825506210327,
      "compression_ratio": 1.513157844543457,
      "no_speech_prob": 0.020133865997195244
    },
    {
      "id": 105,
      "seek": 34128,
      "start": 1653.6700109863282,
      "end": 1656.6300024414063,
      "text": " that's what the blue angel wants to do,",
      "tokens": [
        51574,
        300,
        311,
        437,
        264,
        3344,
        14250,
        2738,
        281,
        360,
        11,
        51722
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5844825506210327,
      "compression_ratio": 1.513157844543457,
      "no_speech_prob": 0.020133865997195244
    },
    {
      "id": 106,
      "seek": 36844,
      "start": 1656.6300024414063,
      "end": 1659.5899938964844,
      "text": " that software may become comparable at some point.",
      "tokens": [
        50364,
        300,
        4722,
        815,
        1813,
        25323,
        412,
        512,
        935,
        13,
        50512
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4796828627586365,
      "compression_ratio": 1.623931646347046,
      "no_speech_prob": 0.052449483424425125
    },
    {
      "id": 107,
      "seek": 36844,
      "start": 1659.5899938964844,
      "end": 1663.5899938964844,
      "text": " So that's more likely to be possible in the consumer area.",
      "tokens": [
        50512,
        407,
        300,
        311,
        544,
        3700,
        281,
        312,
        1944,
        294,
        264,
        9711,
        1859,
        13,
        50712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4796828627586365,
      "compression_ratio": 1.623931646347046,
      "no_speech_prob": 0.052449483424425125
    },
    {
      "id": 108,
      "seek": 36844,
      "start": 1663.5899938964844,
      "end": 1666.1100134277344,
      "text": " Difficult, but definitely transparency.",
      "tokens": [
        50712,
        35940,
        1786,
        723,
        11,
        457,
        2138,
        17131,
        13,
        50838
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4796828627586365,
      "compression_ratio": 1.623931646347046,
      "no_speech_prob": 0.052449483424425125
    },
    {
      "id": 109,
      "seek": 36844,
      "start": 1666.1100134277344,
      "end": 1668.230008544922,
      "text": " And if I have transparency,",
      "tokens": [
        50838,
        400,
        498,
        286,
        362,
        17131,
        11,
        50944
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4796828627586365,
      "compression_ratio": 1.623931646347046,
      "no_speech_prob": 0.052449483424425125
    },
    {
      "id": 110,
      "seek": 36844,
      "start": 1668.230008544922,
      "end": 1670.1100134277344,
      "text": " then I can also make decisions.",
      "tokens": [
        50944,
        550,
        286,
        393,
        611,
        652,
        5327,
        13,
        51038
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4796828627586365,
      "compression_ratio": 1.623931646347046,
      "no_speech_prob": 0.052449483424425125
    },
    {
      "id": 111,
      "seek": 36844,
      "start": 1670.1100134277344,
      "end": 1672.3500036621094,
      "text": " I don't have transparency anymore.",
      "tokens": [
        51038,
        286,
        500,
        380,
        362,
        17131,
        3602,
        13,
        51150
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4796828627586365,
      "compression_ratio": 1.623931646347046,
      "no_speech_prob": 0.052449483424425125
    },
    {
      "id": 112,
      "seek": 36844,
      "start": 1672.3500036621094,
      "end": 1673.230008544922,
      "text": " Okay, that means,",
      "tokens": [
        51150,
        1033,
        11,
        300,
        1355,
        11,
        51194
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4796828627586365,
      "compression_ratio": 1.623931646347046,
      "no_speech_prob": 0.052449483424425125
    },
    {
      "id": 113,
      "seek": 36844,
      "start": 1673.230008544922,
      "end": 1675.230008544922,
      "text": " so I assume now, correct me,",
      "tokens": [
        51194,
        370,
        286,
        6552,
        586,
        11,
        3006,
        385,
        11,
        51294
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4796828627586365,
      "compression_ratio": 1.623931646347046,
      "no_speech_prob": 0.052449483424425125
    },
    {
      "id": 114,
      "seek": 36844,
      "start": 1675.230008544922,
      "end": 1678.950009765625,
      "text": " that I somehow sit down and see",
      "tokens": [
        51294,
        300,
        286,
        6063,
        1394,
        760,
        293,
        536,
        51480
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4796828627586365,
      "compression_ratio": 1.623931646347046,
      "no_speech_prob": 0.052449483424425125
    },
    {
      "id": 115,
      "seek": 36844,
      "start": 1678.950009765625,
      "end": 1681.19,
      "text": " how much energy I use for,",
      "tokens": [
        51480,
        577,
        709,
        2281,
        286,
        764,
        337,
        11,
        51592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4796828627586365,
      "compression_ratio": 1.623931646347046,
      "no_speech_prob": 0.052449483424425125
    },
    {
      "id": 116,
      "seek": 36844,
      "start": 1681.19,
      "end": 1683.8699926757813,
      "text": " you said order processes now,",
      "tokens": [
        51592,
        291,
        848,
        1668,
        7555,
        586,
        11,
        51726
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4796828627586365,
      "compression_ratio": 1.623931646347046,
      "no_speech_prob": 0.052449483424425125
    },
    {
      "id": 117,
      "seek": 39568,
      "start": 1683.8699926757813,
      "end": 1686.8300146484376,
      "text": " then I multiply that with the CO2 intensity.",
      "tokens": [
        50364,
        550,
        286,
        12972,
        300,
        365,
        264,
        3002,
        17,
        13749,
        13,
        50512
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38001585006713867,
      "compression_ratio": 1.6360000371932983,
      "no_speech_prob": 0.008631325326859951
    },
    {
      "id": 118,
      "seek": 39568,
      "start": 1686.8300146484376,
      "end": 1688.5899938964844,
      "text": " There was this electricity map,",
      "tokens": [
        50512,
        821,
        390,
        341,
        10356,
        4471,
        11,
        50600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38001585006713867,
      "compression_ratio": 1.6360000371932983,
      "no_speech_prob": 0.008631325326859951
    },
    {
      "id": 119,
      "seek": 39568,
      "start": 1688.5899938964844,
      "end": 1691.3099951171876,
      "text": " which you mentioned before.",
      "tokens": [
        50600,
        597,
        291,
        2835,
        949,
        13,
        50736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38001585006713867,
      "compression_ratio": 1.6360000371932983,
      "no_speech_prob": 0.008631325326859951
    },
    {
      "id": 120,
      "seek": 39568,
      "start": 1691.3099951171876,
      "end": 1693.3099951171876,
      "text": " Then I take,",
      "tokens": [
        50736,
        1396,
        286,
        747,
        11,
        50836
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38001585006713867,
      "compression_ratio": 1.6360000371932983,
      "no_speech_prob": 0.008631325326859951
    },
    {
      "id": 121,
      "seek": 39568,
      "start": 1693.3099951171876,
      "end": 1695.9899877929688,
      "text": " I look at how many servers are involved in it.",
      "tokens": [
        50836,
        286,
        574,
        412,
        577,
        867,
        15909,
        366,
        3288,
        294,
        309,
        13,
        50970
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38001585006713867,
      "compression_ratio": 1.6360000371932983,
      "no_speech_prob": 0.008631325326859951
    },
    {
      "id": 122,
      "seek": 39568,
      "start": 1695.9899877929688,
      "end": 1696.7499975585938,
      "text": " And then I say,",
      "tokens": [
        50970,
        400,
        550,
        286,
        584,
        11,
        51008
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38001585006713867,
      "compression_ratio": 1.6360000371932983,
      "no_speech_prob": 0.008631325326859951
    },
    {
      "id": 123,
      "seek": 39568,
      "start": 1696.7499975585938,
      "end": 1701.7499975585938,
      "text": " this system consumes or produces so and so much CO2.",
      "tokens": [
        51008,
        341,
        1185,
        48823,
        420,
        14725,
        370,
        293,
        370,
        709,
        3002,
        17,
        13,
        51258
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38001585006713867,
      "compression_ratio": 1.6360000371932983,
      "no_speech_prob": 0.008631325326859951
    },
    {
      "id": 124,
      "seek": 39568,
      "start": 1701.7499975585938,
      "end": 1704.6700109863282,
      "text": " And then I divide that by the number of orders that go through it.",
      "tokens": [
        51258,
        400,
        550,
        286,
        9845,
        300,
        538,
        264,
        1230,
        295,
        9470,
        300,
        352,
        807,
        309,
        13,
        51404
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38001585006713867,
      "compression_ratio": 1.6360000371932983,
      "no_speech_prob": 0.008631325326859951
    },
    {
      "id": 125,
      "seek": 39568,
      "start": 1704.6700109863282,
      "end": 1709.0299963378907,
      "text": " And then I get out what an order costs, so to speak.",
      "tokens": [
        51404,
        400,
        550,
        286,
        483,
        484,
        437,
        364,
        1668,
        5497,
        11,
        370,
        281,
        1710,
        13,
        51622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38001585006713867,
      "compression_ratio": 1.6360000371932983,
      "no_speech_prob": 0.008631325326859951
    },
    {
      "id": 126,
      "seek": 39568,
      "start": 1709.0299963378907,
      "end": 1711.7900061035157,
      "text": " And if you want to look consumer-oriented, for example,",
      "tokens": [
        51622,
        400,
        498,
        291,
        528,
        281,
        574,
        9711,
        12,
        27414,
        11,
        337,
        1365,
        11,
        51760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38001585006713867,
      "compression_ratio": 1.6360000371932983,
      "no_speech_prob": 0.008631325326859951
    },
    {
      "id": 127,
      "seek": 42360,
      "start": 1711.7900061035157,
      "end": 1712.6300024414063,
      "text": " then I can say,",
      "tokens": [
        50364,
        550,
        286,
        393,
        584,
        11,
        50406
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49198853969573975,
      "compression_ratio": 1.6106194257736206,
      "no_speech_prob": 0.012375394813716412
    },
    {
      "id": 128,
      "seek": 42360,
      "start": 1712.6300024414063,
      "end": 1718.6300024414063,
      "text": " okay, what does a minute of Zoom cost in terms of CO2?",
      "tokens": [
        50406,
        1392,
        11,
        437,
        775,
        257,
        3456,
        295,
        13453,
        2063,
        294,
        2115,
        295,
        3002,
        17,
        30,
        50706
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49198853969573975,
      "compression_ratio": 1.6106194257736206,
      "no_speech_prob": 0.012375394813716412
    },
    {
      "id": 129,
      "seek": 42360,
      "start": 1718.6300024414063,
      "end": 1720.6300024414063,
      "text": " And what does a minute of Jitsi cost?",
      "tokens": [
        50706,
        400,
        437,
        775,
        257,
        3456,
        295,
        508,
        1208,
        72,
        2063,
        30,
        50806
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49198853969573975,
      "compression_ratio": 1.6106194257736206,
      "no_speech_prob": 0.012375394813716412
    },
    {
      "id": 130,
      "seek": 42360,
      "start": 1720.6300024414063,
      "end": 1723.6300024414063,
      "text": " And what does a minute of Teams cost, for example?",
      "tokens": [
        50806,
        400,
        437,
        775,
        257,
        3456,
        295,
        24702,
        2063,
        11,
        337,
        1365,
        30,
        50956
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49198853969573975,
      "compression_ratio": 1.6106194257736206,
      "no_speech_prob": 0.012375394813716412
    },
    {
      "id": 131,
      "seek": 42360,
      "start": 1723.6300024414063,
      "end": 1724.6300024414063,
      "text": " Okay.",
      "tokens": [
        50956,
        1033,
        13,
        51006
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49198853969573975,
      "compression_ratio": 1.6106194257736206,
      "no_speech_prob": 0.012375394813716412
    },
    {
      "id": 132,
      "seek": 42360,
      "start": 1724.6300024414063,
      "end": 1725.7900061035157,
      "text": " Then you can just,",
      "tokens": [
        51006,
        1396,
        291,
        393,
        445,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49198853969573975,
      "compression_ratio": 1.6106194257736206,
      "no_speech_prob": 0.012375394813716412
    },
    {
      "id": 133,
      "seek": 42360,
      "start": 1725.7900061035157,
      "end": 1727.9100012207032,
      "text": " so that would be such a functional one,",
      "tokens": [
        51064,
        370,
        300,
        576,
        312,
        1270,
        257,
        11745,
        472,
        11,
        51170
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49198853969573975,
      "compression_ratio": 1.6106194257736206,
      "no_speech_prob": 0.012375394813716412
    },
    {
      "id": 134,
      "seek": 42360,
      "start": 1727.9100012207032,
      "end": 1731.0299963378907,
      "text": " video per second.",
      "tokens": [
        51170,
        960,
        680,
        1150,
        13,
        51326
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49198853969573975,
      "compression_ratio": 1.6106194257736206,
      "no_speech_prob": 0.012375394813716412
    },
    {
      "id": 135,
      "seek": 42360,
      "start": 1731.0299963378907,
      "end": 1731.5899938964844,
      "text": " Exactly.",
      "tokens": [
        51326,
        7587,
        13,
        51354
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49198853969573975,
      "compression_ratio": 1.6106194257736206,
      "no_speech_prob": 0.012375394813716412
    },
    {
      "id": 136,
      "seek": 42360,
      "start": 1731.5899938964844,
      "end": 1734.5499853515626,
      "text": " Perhaps the Gromio on YouTube asked",
      "tokens": [
        51354,
        10517,
        264,
        460,
        4397,
        1004,
        322,
        3088,
        2351,
        51502
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49198853969573975,
      "compression_ratio": 1.6106194257736206,
      "no_speech_prob": 0.012375394813716412
    },
    {
      "id": 137,
      "seek": 42360,
      "start": 1734.5499853515626,
      "end": 1736.5100073242188,
      "text": " which tools you would recommend",
      "tokens": [
        51502,
        597,
        3873,
        291,
        576,
        2748,
        51600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49198853969573975,
      "compression_ratio": 1.6106194257736206,
      "no_speech_prob": 0.012375394813716412
    },
    {
      "id": 138,
      "seek": 42360,
      "start": 1736.5100073242188,
      "end": 1739.1499914550782,
      "text": " to measure the individual efficiency metrics",
      "tokens": [
        51600,
        281,
        3481,
        264,
        2609,
        10493,
        16367,
        51732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49198853969573975,
      "compression_ratio": 1.6106194257736206,
      "no_speech_prob": 0.012375394813716412
    },
    {
      "id": 139,
      "seek": 45096,
      "start": 1739.1499914550782,
      "end": 1742.1100134277344,
      "text": " on your own hardware or in the cloud.",
      "tokens": [
        50364,
        322,
        428,
        1065,
        8837,
        420,
        294,
        264,
        4588,
        13,
        50512
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46106091141700745,
      "compression_ratio": 1.6926406621932983,
      "no_speech_prob": 0.11534986644983292
    },
    {
      "id": 140,
      "seek": 45096,
      "start": 1742.1100134277344,
      "end": 1744.9100012207032,
      "text": " What you already said is that somehow",
      "tokens": [
        50512,
        708,
        291,
        1217,
        848,
        307,
        300,
        6063,
        50652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46106091141700745,
      "compression_ratio": 1.6926406621932983,
      "no_speech_prob": 0.11534986644983292
    },
    {
      "id": 141,
      "seek": 45096,
      "start": 1744.9100012207032,
      "end": 1748.2699865722657,
      "text": " the data that goes in and out is a good indicator.",
      "tokens": [
        50652,
        264,
        1412,
        300,
        1709,
        294,
        293,
        484,
        307,
        257,
        665,
        16961,
        13,
        50820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46106091141700745,
      "compression_ratio": 1.6926406621932983,
      "no_speech_prob": 0.11534986644983292
    },
    {
      "id": 142,
      "seek": 45096,
      "start": 1748.2699865722657,
      "end": 1749.6700109863282,
      "text": " I found it exciting.",
      "tokens": [
        50820,
        286,
        1352,
        309,
        4670,
        13,
        50890
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46106091141700745,
      "compression_ratio": 1.6926406621932983,
      "no_speech_prob": 0.11534986644983292
    },
    {
      "id": 143,
      "seek": 45096,
      "start": 1749.6700109863282,
      "end": 1750.6700109863282,
      "text": " What else?",
      "tokens": [
        50890,
        708,
        1646,
        30,
        50940
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46106091141700745,
      "compression_ratio": 1.6926406621932983,
      "no_speech_prob": 0.11534986644983292
    },
    {
      "id": 144,
      "seek": 45096,
      "start": 1750.6700109863282,
      "end": 1753.429990234375,
      "text": " Yes, I would like to briefly pick up",
      "tokens": [
        50940,
        1079,
        11,
        286,
        576,
        411,
        281,
        10515,
        1888,
        493,
        51078
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46106091141700745,
      "compression_ratio": 1.6926406621932983,
      "no_speech_prob": 0.11534986644983292
    },
    {
      "id": 145,
      "seek": 45096,
      "start": 1753.429990234375,
      "end": 1755.3900122070313,
      "text": " first to see how you can measure it.",
      "tokens": [
        51078,
        700,
        281,
        536,
        577,
        291,
        393,
        3481,
        309,
        13,
        51176
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46106091141700745,
      "compression_ratio": 1.6926406621932983,
      "no_speech_prob": 0.11534986644983292
    },
    {
      "id": 146,
      "seek": 45096,
      "start": 1755.3900122070313,
      "end": 1756.5899938964844,
      "text": " So how can you,",
      "tokens": [
        51176,
        407,
        577,
        393,
        291,
        11,
        51236
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46106091141700745,
      "compression_ratio": 1.6926406621932983,
      "no_speech_prob": 0.11534986644983292
    },
    {
      "id": 147,
      "seek": 45096,
      "start": 1756.5899938964844,
      "end": 1757.5499853515626,
      "text": " so how can you,",
      "tokens": [
        51236,
        370,
        577,
        393,
        291,
        11,
        51284
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46106091141700745,
      "compression_ratio": 1.6926406621932983,
      "no_speech_prob": 0.11534986644983292
    },
    {
      "id": 148,
      "seek": 45096,
      "start": 1757.5499853515626,
      "end": 1760.6300024414063,
      "text": " I'll say estimate and how can you measure it?",
      "tokens": [
        51284,
        286,
        603,
        584,
        12539,
        293,
        577,
        393,
        291,
        3481,
        309,
        30,
        51438
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46106091141700745,
      "compression_ratio": 1.6926406621932983,
      "no_speech_prob": 0.11534986644983292
    },
    {
      "id": 149,
      "seek": 45096,
      "start": 1760.6300024414063,
      "end": 1765.9899877929688,
      "text": " Estimating is actually what is mostly done,",
      "tokens": [
        51438,
        4410,
        332,
        990,
        307,
        767,
        437,
        307,
        5240,
        1096,
        11,
        51706
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46106091141700745,
      "compression_ratio": 1.6926406621932983,
      "no_speech_prob": 0.11534986644983292
    },
    {
      "id": 150,
      "seek": 45096,
      "start": 1765.9899877929688,
      "end": 1767.19,
      "text": " especially when you're in the cloud,",
      "tokens": [
        51706,
        2318,
        562,
        291,
        434,
        294,
        264,
        4588,
        11,
        51766
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46106091141700745,
      "compression_ratio": 1.6926406621932983,
      "no_speech_prob": 0.11534986644983292
    },
    {
      "id": 151,
      "seek": 47900,
      "start": 1767.19,
      "end": 1769.950009765625,
      "text": " because you can't connect a measuring device to a server.",
      "tokens": [
        50364,
        570,
        291,
        393,
        380,
        1745,
        257,
        13389,
        4302,
        281,
        257,
        7154,
        13,
        50502
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4891516864299774,
      "compression_ratio": 1.54347825050354,
      "no_speech_prob": 0.019745441153645515
    },
    {
      "id": 152,
      "seek": 47900,
      "start": 1769.950009765625,
      "end": 1774.5499853515626,
      "text": " This is the so-called Etsy,",
      "tokens": [
        50502,
        639,
        307,
        264,
        370,
        12,
        11880,
        462,
        1373,
        88,
        11,
        50732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4891516864299774,
      "compression_ratio": 1.54347825050354,
      "no_speech_prob": 0.019745441153645515
    },
    {
      "id": 153,
      "seek": 47900,
      "start": 1774.5499853515626,
      "end": 1775.6700109863282,
      "text": " invented by Etsy,",
      "tokens": [
        50732,
        14479,
        538,
        47170,
        88,
        11,
        50788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4891516864299774,
      "compression_ratio": 1.54347825050354,
      "no_speech_prob": 0.019745441153645515
    },
    {
      "id": 154,
      "seek": 47900,
      "start": 1775.6700109863282,
      "end": 1778.3900122070313,
      "text": " Cloud Jewels.",
      "tokens": [
        50788,
        8061,
        5679,
        1625,
        13,
        50924
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4891516864299774,
      "compression_ratio": 1.54347825050354,
      "no_speech_prob": 0.019745441153645515
    },
    {
      "id": 155,
      "seek": 47900,
      "start": 1778.3900122070313,
      "end": 1781.0299963378907,
      "text": " And here I also show a picture.",
      "tokens": [
        50924,
        400,
        510,
        286,
        611,
        855,
        257,
        3036,
        13,
        51056
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4891516864299774,
      "compression_ratio": 1.54347825050354,
      "no_speech_prob": 0.019745441153645515
    },
    {
      "id": 156,
      "seek": 47900,
      "start": 1781.0299963378907,
      "end": 1782.0299963378907,
      "text": " So what I have,",
      "tokens": [
        51056,
        407,
        437,
        286,
        362,
        11,
        51106
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4891516864299774,
      "compression_ratio": 1.54347825050354,
      "no_speech_prob": 0.019745441153645515
    },
    {
      "id": 157,
      "seek": 47900,
      "start": 1782.0299963378907,
      "end": 1784.5499853515626,
      "text": " so a cloud or a computer always consists of",
      "tokens": [
        51106,
        370,
        257,
        4588,
        420,
        257,
        3820,
        1009,
        14689,
        295,
        51232
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4891516864299774,
      "compression_ratio": 1.54347825050354,
      "no_speech_prob": 0.019745441153645515
    },
    {
      "id": 158,
      "seek": 47900,
      "start": 1784.5499853515626,
      "end": 1788.5100073242188,
      "text": " compute, storage, network and memory,",
      "tokens": [
        51232,
        14722,
        11,
        6725,
        11,
        3209,
        293,
        4675,
        11,
        51430
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4891516864299774,
      "compression_ratio": 1.54347825050354,
      "no_speech_prob": 0.019745441153645515
    },
    {
      "id": 159,
      "seek": 47900,
      "start": 1788.5100073242188,
      "end": 1789.5100073242188,
      "text": " so memory.",
      "tokens": [
        51430,
        370,
        4675,
        13,
        51480
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4891516864299774,
      "compression_ratio": 1.54347825050354,
      "no_speech_prob": 0.019745441153645515
    },
    {
      "id": 160,
      "seek": 47900,
      "start": 1789.5100073242188,
      "end": 1790.950009765625,
      "text": " These are, so to speak,",
      "tokens": [
        51480,
        1981,
        366,
        11,
        370,
        281,
        1710,
        11,
        51552
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4891516864299774,
      "compression_ratio": 1.54347825050354,
      "no_speech_prob": 0.019745441153645515
    },
    {
      "id": 161,
      "seek": 47900,
      "start": 1790.950009765625,
      "end": 1793.7499975585938,
      "text": " the four core components of a cloud,",
      "tokens": [
        51552,
        264,
        1451,
        4965,
        6677,
        295,
        257,
        4588,
        11,
        51692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4891516864299774,
      "compression_ratio": 1.54347825050354,
      "no_speech_prob": 0.019745441153645515
    },
    {
      "id": 162,
      "seek": 47900,
      "start": 1793.7499975585938,
      "end": 1796.19,
      "text": " no matter what is put on top of it.",
      "tokens": [
        51692,
        572,
        1871,
        437,
        307,
        829,
        322,
        1192,
        295,
        309,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4891516864299774,
      "compression_ratio": 1.54347825050354,
      "no_speech_prob": 0.019745441153645515
    },
    {
      "id": 163,
      "seek": 50800,
      "start": 1796.3500036621094,
      "end": 1800.5100073242188,
      "text": " And I can count these individual core components.",
      "tokens": [
        50372,
        400,
        286,
        393,
        1207,
        613,
        2609,
        4965,
        6677,
        13,
        50580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4267294108867645,
      "compression_ratio": 1.713004469871521,
      "no_speech_prob": 0.006056090816855431
    },
    {
      "id": 164,
      "seek": 50800,
      "start": 1800.5100073242188,
      "end": 1802.7899755859376,
      "text": " So I can, I know how many CPU hours,",
      "tokens": [
        50580,
        407,
        286,
        393,
        11,
        286,
        458,
        577,
        867,
        13199,
        2496,
        11,
        50694
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4267294108867645,
      "compression_ratio": 1.713004469871521,
      "no_speech_prob": 0.006056090816855431
    },
    {
      "id": 165,
      "seek": 50800,
      "start": 1802.7899755859376,
      "end": 1804.71001953125,
      "text": " so how many core hours I have.",
      "tokens": [
        50694,
        370,
        577,
        867,
        4965,
        2496,
        286,
        362,
        13,
        50790
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4267294108867645,
      "compression_ratio": 1.713004469871521,
      "no_speech_prob": 0.006056090816855431
    },
    {
      "id": 166,
      "seek": 50800,
      "start": 1804.71001953125,
      "end": 1808.2700170898438,
      "text": " I know how many gigabytes per hour I store somewhere.",
      "tokens": [
        50790,
        286,
        458,
        577,
        867,
        42741,
        680,
        1773,
        286,
        3531,
        4079,
        13,
        50968
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4267294108867645,
      "compression_ratio": 1.713004469871521,
      "no_speech_prob": 0.006056090816855431
    },
    {
      "id": 167,
      "seek": 50800,
      "start": 1808.2700170898438,
      "end": 1811.1500219726563,
      "text": " I know how many megabytes per second,",
      "tokens": [
        50968,
        286,
        458,
        577,
        867,
        10816,
        24538,
        680,
        1150,
        11,
        51112
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4267294108867645,
      "compression_ratio": 1.713004469871521,
      "no_speech_prob": 0.006056090816855431
    },
    {
      "id": 168,
      "seek": 50800,
      "start": 1811.1500219726563,
      "end": 1813.1500219726563,
      "text": " network and so on.",
      "tokens": [
        51112,
        3209,
        293,
        370,
        322,
        13,
        51212
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4267294108867645,
      "compression_ratio": 1.713004469871521,
      "no_speech_prob": 0.006056090816855431
    },
    {
      "id": 169,
      "seek": 50800,
      "start": 1813.1500219726563,
      "end": 1816.9899877929688,
      "text": " So I can count it all, I'll say.",
      "tokens": [
        51212,
        407,
        286,
        393,
        1207,
        309,
        439,
        11,
        286,
        603,
        584,
        13,
        51404
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4267294108867645,
      "compression_ratio": 1.713004469871521,
      "no_speech_prob": 0.006056090816855431
    },
    {
      "id": 170,
      "seek": 50800,
      "start": 1816.9899877929688,
      "end": 1821.5100073242188,
      "text": " And for each of these things we have an emission factor.",
      "tokens": [
        51404,
        400,
        337,
        1184,
        295,
        613,
        721,
        321,
        362,
        364,
        29513,
        5952,
        13,
        51630
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4267294108867645,
      "compression_ratio": 1.713004469871521,
      "no_speech_prob": 0.006056090816855431
    },
    {
      "id": 171,
      "seek": 50800,
      "start": 1821.5100073242188,
      "end": 1823.429990234375,
      "text": " There are a lot of hardworking people",
      "tokens": [
        51630,
        821,
        366,
        257,
        688,
        295,
        1152,
        22475,
        561,
        51726
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4267294108867645,
      "compression_ratio": 1.713004469871521,
      "no_speech_prob": 0.006056090816855431
    },
    {
      "id": 172,
      "seek": 50800,
      "start": 1823.429990234375,
      "end": 1824.71001953125,
      "text": " who have put it together.",
      "tokens": [
        51726,
        567,
        362,
        829,
        309,
        1214,
        13,
        51790
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4267294108867645,
      "compression_ratio": 1.713004469871521,
      "no_speech_prob": 0.006056090816855431
    },
    {
      "id": 173,
      "seek": 53652,
      "start": 1824.71001953125,
      "end": 1828.2299780273438,
      "text": " The colleagues from Sourceworks have done a gigantic job.",
      "tokens": [
        50364,
        440,
        7734,
        490,
        29629,
        18357,
        362,
        1096,
        257,
        26800,
        1691,
        13,
        50540
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5075854063034058,
      "compression_ratio": 1.7142857313156128,
      "no_speech_prob": 0.0347541943192482
    },
    {
      "id": 174,
      "seek": 53652,
      "start": 1828.2299780273438,
      "end": 1832.3099951171876,
      "text": " So I then have compute hours with the emission factor,",
      "tokens": [
        50540,
        407,
        286,
        550,
        362,
        14722,
        2496,
        365,
        264,
        29513,
        5952,
        11,
        50744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5075854063034058,
      "compression_ratio": 1.7142857313156128,
      "no_speech_prob": 0.0347541943192482
    },
    {
      "id": 175,
      "seek": 53652,
      "start": 1832.3099951171876,
      "end": 1835.71001953125,
      "text": " multiply it with the energy efficiency,",
      "tokens": [
        50744,
        12972,
        309,
        365,
        264,
        2281,
        10493,
        11,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5075854063034058,
      "compression_ratio": 1.7142857313156128,
      "no_speech_prob": 0.0347541943192482
    },
    {
      "id": 176,
      "seek": 53652,
      "start": 1835.71001953125,
      "end": 1837.7899755859376,
      "text": " with the power usage effectiveness,",
      "tokens": [
        50914,
        365,
        264,
        1347,
        14924,
        21208,
        11,
        51018
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5075854063034058,
      "compression_ratio": 1.7142857313156128,
      "no_speech_prob": 0.0347541943192482
    },
    {
      "id": 177,
      "seek": 53652,
      "start": 1837.7899755859376,
      "end": 1840.66998046875,
      "text": " multiply it with, then I have an energy,",
      "tokens": [
        51018,
        12972,
        309,
        365,
        11,
        550,
        286,
        362,
        364,
        2281,
        11,
        51162
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5075854063034058,
      "compression_ratio": 1.7142857313156128,
      "no_speech_prob": 0.0347541943192482
    },
    {
      "id": 178,
      "seek": 53652,
      "start": 1840.66998046875,
      "end": 1844.7499975585938,
      "text": " then I take the energy and then calculate the CO2",
      "tokens": [
        51162,
        550,
        286,
        747,
        264,
        2281,
        293,
        550,
        8873,
        264,
        3002,
        17,
        51366
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5075854063034058,
      "compression_ratio": 1.7142857313156128,
      "no_speech_prob": 0.0347541943192482
    },
    {
      "id": 179,
      "seek": 53652,
      "start": 1844.7499975585938,
      "end": 1846.3499731445313,
      "text": " by looking at how much,",
      "tokens": [
        51366,
        538,
        1237,
        412,
        577,
        709,
        11,
        51446
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5075854063034058,
      "compression_ratio": 1.7142857313156128,
      "no_speech_prob": 0.0347541943192482
    },
    {
      "id": 180,
      "seek": 53652,
      "start": 1846.3499731445313,
      "end": 1849.0300268554688,
      "text": " what the grid intensity is and then I get it.",
      "tokens": [
        51446,
        437,
        264,
        10748,
        13749,
        307,
        293,
        550,
        286,
        483,
        309,
        13,
        51580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5075854063034058,
      "compression_ratio": 1.7142857313156128,
      "no_speech_prob": 0.0347541943192482
    },
    {
      "id": 181,
      "seek": 53652,
      "start": 1849.0300268554688,
      "end": 1852.3900122070313,
      "text": " So, and we then reduce the measurement problem",
      "tokens": [
        51580,
        407,
        11,
        293,
        321,
        550,
        5407,
        264,
        13160,
        1154,
        51748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5075854063034058,
      "compression_ratio": 1.7142857313156128,
      "no_speech_prob": 0.0347541943192482
    },
    {
      "id": 182,
      "seek": 56420,
      "start": 1852.3900122070313,
      "end": 1857.2700170898438,
      "text": " actually by looking at how many compute hours I had.",
      "tokens": [
        50364,
        767,
        538,
        1237,
        412,
        577,
        867,
        14722,
        2496,
        286,
        632,
        13,
        50608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5250449776649475,
      "compression_ratio": 1.638655424118042,
      "no_speech_prob": 0.03134273365139961
    },
    {
      "id": 183,
      "seek": 56420,
      "start": 1857.2700170898438,
      "end": 1859.8300146484376,
      "text": " And the nice thing about cloud and everywhere,",
      "tokens": [
        50608,
        400,
        264,
        1481,
        551,
        466,
        4588,
        293,
        5315,
        11,
        50736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5250449776649475,
      "compression_ratio": 1.638655424118042,
      "no_speech_prob": 0.03134273365139961
    },
    {
      "id": 184,
      "seek": 56420,
      "start": 1859.8300146484376,
      "end": 1861.66998046875,
      "text": " computing centers and so on,",
      "tokens": [
        50736,
        15866,
        10898,
        293,
        370,
        322,
        11,
        50828
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5250449776649475,
      "compression_ratio": 1.638655424118042,
      "no_speech_prob": 0.03134273365139961
    },
    {
      "id": 185,
      "seek": 56420,
      "start": 1861.66998046875,
      "end": 1864.1099829101563,
      "text": " when it's a bit managed,",
      "tokens": [
        50828,
        562,
        309,
        311,
        257,
        857,
        6453,
        11,
        50950
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5250449776649475,
      "compression_ratio": 1.638655424118042,
      "no_speech_prob": 0.03134273365139961
    },
    {
      "id": 186,
      "seek": 56420,
      "start": 1864.1099829101563,
      "end": 1866.0300268554688,
      "text": " well, it's on the account.",
      "tokens": [
        50950,
        731,
        11,
        309,
        311,
        322,
        264,
        2696,
        13,
        51046
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5250449776649475,
      "compression_ratio": 1.638655424118042,
      "no_speech_prob": 0.03134273365139961
    },
    {
      "id": 187,
      "seek": 56420,
      "start": 1866.0300268554688,
      "end": 1868.0300268554688,
      "text": " So you put it in my account,",
      "tokens": [
        51046,
        407,
        291,
        829,
        309,
        294,
        452,
        2696,
        11,
        51146
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5250449776649475,
      "compression_ratio": 1.638655424118042,
      "no_speech_prob": 0.03134273365139961
    },
    {
      "id": 188,
      "seek": 56420,
      "start": 1868.0300268554688,
      "end": 1869.7499975585938,
      "text": " so Azure puts it in my account.",
      "tokens": [
        51146,
        370,
        11969,
        8137,
        309,
        294,
        452,
        2696,
        13,
        51232
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5250449776649475,
      "compression_ratio": 1.638655424118042,
      "no_speech_prob": 0.03134273365139961
    },
    {
      "id": 189,
      "seek": 56420,
      "start": 1870.909970703125,
      "end": 1872.0700048828126,
      "text": " It's a bit complicated,",
      "tokens": [
        51290,
        467,
        311,
        257,
        857,
        6179,
        11,
        51348
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5250449776649475,
      "compression_ratio": 1.638655424118042,
      "no_speech_prob": 0.03134273365139961
    },
    {
      "id": 190,
      "seek": 56420,
      "start": 1872.0700048828126,
      "end": 1874.6300024414063,
      "text": " because the CPU utilization, for example, is not in it.",
      "tokens": [
        51348,
        570,
        264,
        13199,
        37074,
        11,
        337,
        1365,
        11,
        307,
        406,
        294,
        309,
        13,
        51476
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5250449776649475,
      "compression_ratio": 1.638655424118042,
      "no_speech_prob": 0.03134273365139961
    },
    {
      "id": 191,
      "seek": 56420,
      "start": 1874.6300024414063,
      "end": 1877.950009765625,
      "text": " I could still catch up, but good enough.",
      "tokens": [
        51476,
        286,
        727,
        920,
        3745,
        493,
        11,
        457,
        665,
        1547,
        13,
        51642
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5250449776649475,
      "compression_ratio": 1.638655424118042,
      "no_speech_prob": 0.03134273365139961
    },
    {
      "id": 192,
      "seek": 56420,
      "start": 1877.950009765625,
      "end": 1880.5499853515626,
      "text": " And then I can sort it out.",
      "tokens": [
        51642,
        400,
        550,
        286,
        393,
        1333,
        309,
        484,
        13,
        51772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5250449776649475,
      "compression_ratio": 1.638655424118042,
      "no_speech_prob": 0.03134273365139961
    },
    {
      "id": 193,
      "seek": 59236,
      "start": 1880.5499853515626,
      "end": 1884.5499853515626,
      "text": " There is a tool, the thing is called Cloud Carbon Footprint.",
      "tokens": [
        50364,
        821,
        307,
        257,
        2290,
        11,
        264,
        551,
        307,
        1219,
        8061,
        31453,
        20989,
        14030,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6225530505180359,
      "compression_ratio": 1.454545497894287,
      "no_speech_prob": 0.03637028485536575
    },
    {
      "id": 194,
      "seek": 59236,
      "start": 1886.3099951171876,
      "end": 1889.8300146484376,
      "text": " I'll show it again here.",
      "tokens": [
        50652,
        286,
        603,
        855,
        309,
        797,
        510,
        13,
        50828
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6225530505180359,
      "compression_ratio": 1.454545497894287,
      "no_speech_prob": 0.03637028485536575
    },
    {
      "id": 195,
      "seek": 59236,
      "start": 1895.1099829101563,
      "end": 1900.2700170898438,
      "text": " Cloud Carbon Footprint is open source,",
      "tokens": [
        51092,
        8061,
        31453,
        20989,
        14030,
        307,
        1269,
        4009,
        11,
        51350
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6225530505180359,
      "compression_ratio": 1.454545497894287,
      "no_speech_prob": 0.03637028485536575
    },
    {
      "id": 196,
      "seek": 59236,
      "start": 1900.2700170898438,
      "end": 1901.2700170898438,
      "text": " is on GitHub,",
      "tokens": [
        51350,
        307,
        322,
        23331,
        11,
        51400
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6225530505180359,
      "compression_ratio": 1.454545497894287,
      "no_speech_prob": 0.03637028485536575
    },
    {
      "id": 197,
      "seek": 59236,
      "start": 1901.2700170898438,
      "end": 1905.1500219726563,
      "text": " was mainly made by Sourceworks.",
      "tokens": [
        51400,
        390,
        8704,
        1027,
        538,
        29629,
        18357,
        13,
        51594
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6225530505180359,
      "compression_ratio": 1.454545497894287,
      "no_speech_prob": 0.03637028485536575
    },
    {
      "id": 198,
      "seek": 59236,
      "start": 1905.1500219726563,
      "end": 1908.19,
      "text": " And that also works for on-prem.",
      "tokens": [
        51594,
        400,
        300,
        611,
        1985,
        337,
        322,
        12,
        29403,
        13,
        51746
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6225530505180359,
      "compression_ratio": 1.454545497894287,
      "no_speech_prob": 0.03637028485536575
    },
    {
      "id": 199,
      "seek": 59236,
      "start": 1908.19,
      "end": 1909.2299780273438,
      "text": " And you can do that.",
      "tokens": [
        51746,
        400,
        291,
        393,
        360,
        300,
        13,
        51798
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6225530505180359,
      "compression_ratio": 1.454545497894287,
      "no_speech_prob": 0.03637028485536575
    },
    {
      "id": 200,
      "seek": 62104,
      "start": 1909.2299780273438,
      "end": 1911.8699926757813,
      "text": " If you want to measure correctly,",
      "tokens": [
        50364,
        759,
        291,
        528,
        281,
        3481,
        8944,
        11,
        50496
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6688715815544128,
      "compression_ratio": 1.4207316637039185,
      "no_speech_prob": 0.0178790595382452
    },
    {
      "id": 201,
      "seek": 62104,
      "start": 1911.8699926757813,
      "end": 1913.5499853515626,
      "text": " especially for blue-hanged,",
      "tokens": [
        50496,
        2318,
        337,
        3344,
        12,
        3451,
        3004,
        11,
        50580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6688715815544128,
      "compression_ratio": 1.4207316637039185,
      "no_speech_prob": 0.0178790595382452
    },
    {
      "id": 202,
      "seek": 62104,
      "start": 1913.5499853515626,
      "end": 1919.7499975585938,
      "text": " there are the Green Coding Solutions in Berlin,",
      "tokens": [
        50580,
        456,
        366,
        264,
        6969,
        383,
        8616,
        36295,
        294,
        13848,
        11,
        50890
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6688715815544128,
      "compression_ratio": 1.4207316637039185,
      "no_speech_prob": 0.0178790595382452
    },
    {
      "id": 203,
      "seek": 62104,
      "start": 1919.7499975585938,
      "end": 1920.7499975585938,
      "text": " the ARNAS.",
      "tokens": [
        50890,
        264,
        316,
        49,
        45,
        3160,
        13,
        50940
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6688715815544128,
      "compression_ratio": 1.4207316637039185,
      "no_speech_prob": 0.0178790595382452
    },
    {
      "id": 204,
      "seek": 62104,
      "start": 1922.3900122070313,
      "end": 1926.3499731445313,
      "text": " And they have the so-called Green Matrix tools.",
      "tokens": [
        51022,
        400,
        436,
        362,
        264,
        370,
        12,
        11880,
        6969,
        36274,
        3873,
        13,
        51220
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6688715815544128,
      "compression_ratio": 1.4207316637039185,
      "no_speech_prob": 0.0178790595382452
    },
    {
      "id": 205,
      "seek": 62104,
      "start": 1927.7899755859376,
      "end": 1929.3099951171876,
      "text": " There are a lot of them.",
      "tokens": [
        51292,
        821,
        366,
        257,
        688,
        295,
        552,
        13,
        51368
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6688715815544128,
      "compression_ratio": 1.4207316637039185,
      "no_speech_prob": 0.0178790595382452
    },
    {
      "id": 206,
      "seek": 62104,
      "start": 1933.7899755859376,
      "end": 1937.5100073242188,
      "text": " So, the CECD, they have a lot of tools.",
      "tokens": [
        51592,
        407,
        11,
        264,
        383,
        8140,
        35,
        11,
        436,
        362,
        257,
        688,
        295,
        3873,
        13,
        51778
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6688715815544128,
      "compression_ratio": 1.4207316637039185,
      "no_speech_prob": 0.0178790595382452
    },
    {
      "id": 207,
      "seek": 64932,
      "start": 1937.5100073242188,
      "end": 1942.9899877929688,
      "text": " And, where is it?",
      "tokens": [
        50364,
        400,
        11,
        689,
        307,
        309,
        30,
        50638
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5432771444320679,
      "compression_ratio": 1.3333333730697632,
      "no_speech_prob": 0.0022373972460627556
    },
    {
      "id": 208,
      "seek": 64932,
      "start": 1942.9899877929688,
      "end": 1945.3900122070313,
      "text": " I don't know, I can't find it right now.",
      "tokens": [
        50638,
        286,
        500,
        380,
        458,
        11,
        286,
        393,
        380,
        915,
        309,
        558,
        586,
        13,
        50758
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5432771444320679,
      "compression_ratio": 1.3333333730697632,
      "no_speech_prob": 0.0022373972460627556
    },
    {
      "id": 209,
      "seek": 64932,
      "start": 1945.3900122070313,
      "end": 1952.1099829101563,
      "text": " But they have a tool called Green Soft Matrix.",
      "tokens": [
        50758,
        583,
        436,
        362,
        257,
        2290,
        1219,
        6969,
        407,
        69,
        83,
        36274,
        13,
        51094
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5432771444320679,
      "compression_ratio": 1.3333333730697632,
      "no_speech_prob": 0.0022373972460627556
    },
    {
      "id": 210,
      "seek": 64932,
      "start": 1952.1099829101563,
      "end": 1957.470029296875,
      "text": " And that measures my software",
      "tokens": [
        51094,
        400,
        300,
        8000,
        452,
        4722,
        51362
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5432771444320679,
      "compression_ratio": 1.3333333730697632,
      "no_speech_prob": 0.0022373972460627556
    },
    {
      "id": 211,
      "seek": 64932,
      "start": 1957.470029296875,
      "end": 1959.66998046875,
      "text": " based on the actual energy consumption",
      "tokens": [
        51362,
        2361,
        322,
        264,
        3539,
        2281,
        12126,
        51472
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5432771444320679,
      "compression_ratio": 1.3333333730697632,
      "no_speech_prob": 0.0022373972460627556
    },
    {
      "id": 212,
      "seek": 64932,
      "start": 1959.66998046875,
      "end": 1962.429990234375,
      "text": " that I get from the CPU via RAPL.",
      "tokens": [
        51472,
        300,
        286,
        483,
        490,
        264,
        13199,
        5766,
        497,
        4715,
        43,
        13,
        51610
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5432771444320679,
      "compression_ratio": 1.3333333730697632,
      "no_speech_prob": 0.0022373972460627556
    },
    {
      "id": 213,
      "seek": 64932,
      "start": 1962.429990234375,
      "end": 1965.3900122070313,
      "text": " RAPL is an interface, I assume,",
      "tokens": [
        51610,
        497,
        4715,
        43,
        307,
        364,
        9226,
        11,
        286,
        6552,
        11,
        51758
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5432771444320679,
      "compression_ratio": 1.3333333730697632,
      "no_speech_prob": 0.0022373972460627556
    },
    {
      "id": 214,
      "seek": 67720,
      "start": 1965.429990234375,
      "end": 1967.5499853515626,
      "text": " which is also used for laptops or something like that.",
      "tokens": [
        50366,
        597,
        307,
        611,
        1143,
        337,
        27642,
        420,
        746,
        411,
        300,
        13,
        50472
      ],
      "temperature": 0.0,
      "avg_logprob": -0.546238899230957,
      "compression_ratio": 1.6694915294647217,
      "no_speech_prob": 0.027097780257463455
    },
    {
      "id": 215,
      "seek": 67720,
      "start": 1967.5499853515626,
      "end": 1970.66998046875,
      "text": " Exactly, as a server, that's a specification.",
      "tokens": [
        50472,
        7587,
        11,
        382,
        257,
        7154,
        11,
        300,
        311,
        257,
        31256,
        13,
        50628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.546238899230957,
      "compression_ratio": 1.6694915294647217,
      "no_speech_prob": 0.027097780257463455
    },
    {
      "id": 216,
      "seek": 67720,
      "start": 1970.66998046875,
      "end": 1972.429990234375,
      "text": " I think it's also a chip,",
      "tokens": [
        50628,
        286,
        519,
        309,
        311,
        611,
        257,
        11409,
        11,
        50716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.546238899230957,
      "compression_ratio": 1.6694915294647217,
      "no_speech_prob": 0.027097780257463455
    },
    {
      "id": 217,
      "seek": 67720,
      "start": 1972.429990234375,
      "end": 1975.9899877929688,
      "text": " where the energy consumption of all components",
      "tokens": [
        50716,
        689,
        264,
        2281,
        12126,
        295,
        439,
        6677,
        50894
      ],
      "temperature": 0.0,
      "avg_logprob": -0.546238899230957,
      "compression_ratio": 1.6694915294647217,
      "no_speech_prob": 0.027097780257463455
    },
    {
      "id": 218,
      "seek": 67720,
      "start": 1975.9899877929688,
      "end": 1979.3900122070313,
      "text": " that are on such a mine is measured.",
      "tokens": [
        50894,
        300,
        366,
        322,
        1270,
        257,
        923,
        68,
        307,
        12690,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.546238899230957,
      "compression_ratio": 1.6694915294647217,
      "no_speech_prob": 0.027097780257463455
    },
    {
      "id": 219,
      "seek": 67720,
      "start": 1979.3900122070313,
      "end": 1982.909970703125,
      "text": " That's how you can measure it.",
      "tokens": [
        51064,
        663,
        311,
        577,
        291,
        393,
        3481,
        309,
        13,
        51240
      ],
      "temperature": 0.0,
      "avg_logprob": -0.546238899230957,
      "compression_ratio": 1.6694915294647217,
      "no_speech_prob": 0.027097780257463455
    },
    {
      "id": 220,
      "seek": 67720,
      "start": 1982.909970703125,
      "end": 1984.5900244140626,
      "text": " So, I think that's the question,",
      "tokens": [
        51240,
        407,
        11,
        286,
        519,
        300,
        311,
        264,
        1168,
        11,
        51324
      ],
      "temperature": 0.0,
      "avg_logprob": -0.546238899230957,
      "compression_ratio": 1.6694915294647217,
      "no_speech_prob": 0.027097780257463455
    },
    {
      "id": 221,
      "seek": 67720,
      "start": 1984.5900244140626,
      "end": 1985.5900244140626,
      "text": " how can I measure it?",
      "tokens": [
        51324,
        577,
        393,
        286,
        3481,
        309,
        30,
        51374
      ],
      "temperature": 0.0,
      "avg_logprob": -0.546238899230957,
      "compression_ratio": 1.6694915294647217,
      "no_speech_prob": 0.027097780257463455
    },
    {
      "id": 222,
      "seek": 67720,
      "start": 1985.5900244140626,
      "end": 1987.8699926757813,
      "text": " So, I can measure it and I can download it.",
      "tokens": [
        51374,
        407,
        11,
        286,
        393,
        3481,
        309,
        293,
        286,
        393,
        5484,
        309,
        13,
        51488
      ],
      "temperature": 0.0,
      "avg_logprob": -0.546238899230957,
      "compression_ratio": 1.6694915294647217,
      "no_speech_prob": 0.027097780257463455
    },
    {
      "id": 223,
      "seek": 67720,
      "start": 1987.8699926757813,
      "end": 1991.470029296875,
      "text": " And with that, we actually have everything behind us.",
      "tokens": [
        51488,
        400,
        365,
        300,
        11,
        321,
        767,
        362,
        1203,
        2261,
        505,
        13,
        51668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.546238899230957,
      "compression_ratio": 1.6694915294647217,
      "no_speech_prob": 0.027097780257463455
    },
    {
      "id": 224,
      "seek": 70328,
      "start": 1992.429990234375,
      "end": 1997.1500219726563,
      "text": " If it's okay for you, I could ask a new topic,",
      "tokens": [
        50412,
        759,
        309,
        311,
        1392,
        337,
        291,
        11,
        286,
        727,
        1029,
        257,
        777,
        4829,
        11,
        50648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5930147171020508,
      "compression_ratio": 1.4604650735855103,
      "no_speech_prob": 0.262238472700119
    },
    {
      "id": 225,
      "seek": 70328,
      "start": 1997.1500219726563,
      "end": 2000.3900122070313,
      "text": " which I think results from a question.",
      "tokens": [
        50648,
        597,
        286,
        519,
        3542,
        490,
        257,
        1168,
        13,
        50810
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5930147171020508,
      "compression_ratio": 1.4604650735855103,
      "no_speech_prob": 0.262238472700119
    },
    {
      "id": 226,
      "seek": 70328,
      "start": 2000.3900122070313,
      "end": 2003.3900122070313,
      "text": " This is from Marco Wesselmann.",
      "tokens": [
        50810,
        639,
        307,
        490,
        26535,
        343,
        47166,
        14912,
        13,
        50960
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5930147171020508,
      "compression_ratio": 1.4604650735855103,
      "no_speech_prob": 0.262238472700119
    },
    {
      "id": 227,
      "seek": 70328,
      "start": 2003.3900122070313,
      "end": 2004.2299780273438,
      "text": " He asked,",
      "tokens": [
        50960,
        634,
        2351,
        11,
        51002
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5930147171020508,
      "compression_ratio": 1.4604650735855103,
      "no_speech_prob": 0.262238472700119
    },
    {
      "id": 228,
      "seek": 70328,
      "start": 2004.2299780273438,
      "end": 2007.9899877929688,
      "text": " what about small-scale emissions or power consumption,",
      "tokens": [
        51002,
        437,
        466,
        1359,
        12,
        20033,
        14607,
        420,
        1347,
        12126,
        11,
        51190
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5930147171020508,
      "compression_ratio": 1.4604650735855103,
      "no_speech_prob": 0.262238472700119
    },
    {
      "id": 229,
      "seek": 70328,
      "start": 2007.9899877929688,
      "end": 2008.71001953125,
      "text": " which occurs, for example,",
      "tokens": [
        51190,
        597,
        11843,
        11,
        337,
        1365,
        11,
        51226
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5930147171020508,
      "compression_ratio": 1.4604650735855103,
      "no_speech_prob": 0.262238472700119
    },
    {
      "id": 230,
      "seek": 70328,
      "start": 2008.71001953125,
      "end": 2011.950009765625,
      "text": " through computing time with JavaScript in the browser?",
      "tokens": [
        51226,
        807,
        15866,
        565,
        365,
        15778,
        294,
        264,
        11185,
        30,
        51388
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5930147171020508,
      "compression_ratio": 1.4604650735855103,
      "no_speech_prob": 0.262238472700119
    },
    {
      "id": 231,
      "seek": 70328,
      "start": 2011.950009765625,
      "end": 2014.5499853515626,
      "text": " Should apps rather do without something like that?",
      "tokens": [
        51388,
        6454,
        7733,
        2831,
        360,
        1553,
        746,
        411,
        300,
        30,
        51518
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5930147171020508,
      "compression_ratio": 1.4604650735855103,
      "no_speech_prob": 0.262238472700119
    },
    {
      "id": 232,
      "seek": 72636,
      "start": 2014.5499853515626,
      "end": 2023.5499853515626,
      "text": " I don't think it's really relevant.",
      "tokens": [
        50364,
        286,
        500,
        380,
        519,
        309,
        311,
        534,
        7340,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5539383292198181,
      "compression_ratio": 1.4720497131347656,
      "no_speech_prob": 0.012178865261375904
    },
    {
      "id": 233,
      "seek": 72636,
      "start": 2023.5499853515626,
      "end": 2034.1099829101563,
      "text": " First of all, you have to see it in its dimension.",
      "tokens": [
        50814,
        2386,
        295,
        439,
        11,
        291,
        362,
        281,
        536,
        309,
        294,
        1080,
        10139,
        13,
        51342
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5539383292198181,
      "compression_ratio": 1.4720497131347656,
      "no_speech_prob": 0.012178865261375904
    },
    {
      "id": 234,
      "seek": 72636,
      "start": 2034.1099829101563,
      "end": 2036.5499853515626,
      "text": " So, if I have a web application",
      "tokens": [
        51342,
        407,
        11,
        498,
        286,
        362,
        257,
        3670,
        3861,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5539383292198181,
      "compression_ratio": 1.4720497131347656,
      "no_speech_prob": 0.012178865261375904
    },
    {
      "id": 235,
      "seek": 72636,
      "start": 2036.5499853515626,
      "end": 2039.0300268554688,
      "text": " and a server is running,",
      "tokens": [
        51464,
        293,
        257,
        7154,
        307,
        2614,
        11,
        51588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5539383292198181,
      "compression_ratio": 1.4720497131347656,
      "no_speech_prob": 0.012178865261375904
    },
    {
      "id": 236,
      "seek": 72636,
      "start": 2039.0300268554688,
      "end": 2040.7499975585938,
      "text": " I have a back-end somewhere,",
      "tokens": [
        51588,
        286,
        362,
        257,
        646,
        12,
        521,
        4079,
        11,
        51674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5539383292198181,
      "compression_ratio": 1.4720497131347656,
      "no_speech_prob": 0.012178865261375904
    },
    {
      "id": 237,
      "seek": 72636,
      "start": 2040.7499975585938,
      "end": 2042.0700048828126,
      "text": " there are a few servers running,",
      "tokens": [
        51674,
        456,
        366,
        257,
        1326,
        15909,
        2614,
        11,
        51740
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5539383292198181,
      "compression_ratio": 1.4720497131347656,
      "no_speech_prob": 0.012178865261375904
    },
    {
      "id": 238,
      "seek": 72636,
      "start": 2042.0700048828126,
      "end": 2044.1099829101563,
      "text": " then data is being transferred.",
      "tokens": [
        51740,
        550,
        1412,
        307,
        885,
        15809,
        13,
        51842
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5539383292198181,
      "compression_ratio": 1.4720497131347656,
      "no_speech_prob": 0.012178865261375904
    },
    {
      "id": 239,
      "seek": 75592,
      "start": 2044.1099829101563,
      "end": 2047.3499731445313,
      "text": " So, the typical Angular model.",
      "tokens": [
        50364,
        407,
        11,
        264,
        7476,
        34107,
        2316,
        13,
        50526
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5231558084487915,
      "compression_ratio": 1.6060606241226196,
      "no_speech_prob": 0.006519985385239124
    },
    {
      "id": 240,
      "seek": 75592,
      "start": 2047.3499731445313,
      "end": 2048.429990234375,
      "text": " There is a database,",
      "tokens": [
        50526,
        821,
        307,
        257,
        1137,
        5509,
        405,
        11,
        50580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5231558084487915,
      "compression_ratio": 1.6060606241226196,
      "no_speech_prob": 0.006519985385239124
    },
    {
      "id": 241,
      "seek": 75592,
      "start": 2048.429990234375,
      "end": 2050.0700048828126,
      "text": " there is a back-end server,",
      "tokens": [
        50580,
        456,
        307,
        257,
        646,
        12,
        521,
        7154,
        11,
        50662
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5231558084487915,
      "compression_ratio": 1.6060606241226196,
      "no_speech_prob": 0.006519985385239124
    },
    {
      "id": 242,
      "seek": 75592,
      "start": 2050.0700048828126,
      "end": 2050.7899755859376,
      "text": " a few services,",
      "tokens": [
        50662,
        257,
        1326,
        3328,
        11,
        50698
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5231558084487915,
      "compression_ratio": 1.6060606241226196,
      "no_speech_prob": 0.006519985385239124
    },
    {
      "id": 243,
      "seek": 75592,
      "start": 2050.7899755859376,
      "end": 2052.1500219726563,
      "text": " and then I have front-end.",
      "tokens": [
        50698,
        293,
        550,
        286,
        362,
        1868,
        12,
        521,
        13,
        50766
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5231558084487915,
      "compression_ratio": 1.6060606241226196,
      "no_speech_prob": 0.006519985385239124
    },
    {
      "id": 244,
      "seek": 75592,
      "start": 2052.1500219726563,
      "end": 2054.19,
      "text": " The question is,",
      "tokens": [
        50766,
        440,
        1168,
        307,
        11,
        50868
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5231558084487915,
      "compression_ratio": 1.6060606241226196,
      "no_speech_prob": 0.006519985385239124
    },
    {
      "id": 245,
      "seek": 75592,
      "start": 2054.19,
      "end": 2055.5499853515626,
      "text": " do I do server-side generated",
      "tokens": [
        50868,
        360,
        286,
        360,
        7154,
        12,
        1812,
        10833,
        50936
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5231558084487915,
      "compression_ratio": 1.6060606241226196,
      "no_speech_prob": 0.006519985385239124
    },
    {
      "id": 246,
      "seek": 75592,
      "start": 2055.5499853515626,
      "end": 2059.510007324219,
      "text": " or client-side generated applications?",
      "tokens": [
        50936,
        420,
        6423,
        12,
        1812,
        10833,
        5821,
        30,
        51134
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5231558084487915,
      "compression_ratio": 1.6060606241226196,
      "no_speech_prob": 0.006519985385239124
    },
    {
      "id": 247,
      "seek": 75592,
      "start": 2059.510007324219,
      "end": 2063.3900122070313,
      "text": " In the overall system,",
      "tokens": [
        51134,
        682,
        264,
        4787,
        1185,
        11,
        51328
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5231558084487915,
      "compression_ratio": 1.6060606241226196,
      "no_speech_prob": 0.006519985385239124
    },
    {
      "id": 248,
      "seek": 75592,
      "start": 2063.3900122070313,
      "end": 2066.909970703125,
      "text": " the back-end is the deciding factor.",
      "tokens": [
        51328,
        264,
        646,
        12,
        521,
        307,
        264,
        17990,
        5952,
        13,
        51504
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5231558084487915,
      "compression_ratio": 1.6060606241226196,
      "no_speech_prob": 0.006519985385239124
    },
    {
      "id": 249,
      "seek": 75592,
      "start": 2066.909970703125,
      "end": 2069.989987792969,
      "text": " And on the end device,",
      "tokens": [
        51504,
        400,
        322,
        264,
        917,
        4302,
        11,
        51658
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5231558084487915,
      "compression_ratio": 1.6060606241226196,
      "no_speech_prob": 0.006519985385239124
    },
    {
      "id": 250,
      "seek": 75592,
      "start": 2069.989987792969,
      "end": 2073.5499853515626,
      "text": " we have the data transfer.",
      "tokens": [
        51658,
        321,
        362,
        264,
        1412,
        5003,
        13,
        51836
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5231558084487915,
      "compression_ratio": 1.6060606241226196,
      "no_speech_prob": 0.006519985385239124
    },
    {
      "id": 251,
      "seek": 78536,
      "start": 2073.5499853515626,
      "end": 2076.8699926757813,
      "text": " I guess it's probably similar.",
      "tokens": [
        50364,
        286,
        2041,
        309,
        311,
        1391,
        2531,
        13,
        50530
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6030389070510864,
      "compression_ratio": 1.6243094205856323,
      "no_speech_prob": 0.05558532103896141
    },
    {
      "id": 252,
      "seek": 78536,
      "start": 2076.8699926757813,
      "end": 2078.1500219726563,
      "text": " And then I have the end device.",
      "tokens": [
        50530,
        400,
        550,
        286,
        362,
        264,
        917,
        4302,
        13,
        50594
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6030389070510864,
      "compression_ratio": 1.6243094205856323,
      "no_speech_prob": 0.05558532103896141
    },
    {
      "id": 253,
      "seek": 78536,
      "start": 2078.1500219726563,
      "end": 2079.429990234375,
      "text": " And now I'm talking about",
      "tokens": [
        50594,
        400,
        586,
        286,
        478,
        1417,
        466,
        50658
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6030389070510864,
      "compression_ratio": 1.6243094205856323,
      "no_speech_prob": 0.05558532103896141
    },
    {
      "id": 254,
      "seek": 78536,
      "start": 2079.429990234375,
      "end": 2082.3099951171876,
      "text": " how many emissions I have on the end device.",
      "tokens": [
        50658,
        577,
        867,
        14607,
        286,
        362,
        322,
        264,
        917,
        4302,
        13,
        50802
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6030389070510864,
      "compression_ratio": 1.6243094205856323,
      "no_speech_prob": 0.05558532103896141
    },
    {
      "id": 255,
      "seek": 78536,
      "start": 2082.3099951171876,
      "end": 2089.5900244140626,
      "text": " And there it is actually the monitor that is the topic.",
      "tokens": [
        50802,
        400,
        456,
        309,
        307,
        767,
        264,
        6002,
        300,
        307,
        264,
        4829,
        13,
        51166
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6030389070510864,
      "compression_ratio": 1.6243094205856323,
      "no_speech_prob": 0.05558532103896141
    },
    {
      "id": 256,
      "seek": 78536,
      "start": 2089.5900244140626,
      "end": 2091.1099829101563,
      "text": " Or runtime,",
      "tokens": [
        51166,
        1610,
        34474,
        11,
        51242
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6030389070510864,
      "compression_ratio": 1.6243094205856323,
      "no_speech_prob": 0.05558532103896141
    },
    {
      "id": 257,
      "seek": 78536,
      "start": 2091.1099829101563,
      "end": 2094.950009765625,
      "text": " because the laptop doesn't do anything.",
      "tokens": [
        51242,
        570,
        264,
        10732,
        1177,
        380,
        360,
        1340,
        13,
        51434
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6030389070510864,
      "compression_ratio": 1.6243094205856323,
      "no_speech_prob": 0.05558532103896141
    },
    {
      "id": 258,
      "seek": 78536,
      "start": 2094.950009765625,
      "end": 2100.1500219726563,
      "text": " And then I'm talking about micro-optimization again.",
      "tokens": [
        51434,
        400,
        550,
        286,
        478,
        1417,
        466,
        4532,
        12,
        5747,
        332,
        2144,
        797,
        13,
        51694
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6030389070510864,
      "compression_ratio": 1.6243094205856323,
      "no_speech_prob": 0.05558532103896141
    },
    {
      "id": 259,
      "seek": 81196,
      "start": 2100.1500219726563,
      "end": 2105.3099951171876,
      "text": " And if I can do my database queries better,",
      "tokens": [
        50364,
        400,
        498,
        286,
        393,
        360,
        452,
        8149,
        24109,
        1101,
        11,
        50622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4980272054672241,
      "compression_ratio": 1.548717975616455,
      "no_speech_prob": 0.011825182475149632
    },
    {
      "id": 260,
      "seek": 81196,
      "start": 2105.3099951171876,
      "end": 2107.429990234375,
      "text": " maybe I can cache them,",
      "tokens": [
        50622,
        1310,
        286,
        393,
        19459,
        552,
        11,
        50728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4980272054672241,
      "compression_ratio": 1.548717975616455,
      "no_speech_prob": 0.011825182475149632
    },
    {
      "id": 261,
      "seek": 81196,
      "start": 2107.429990234375,
      "end": 2109.8699926757813,
      "text": " then I get more out of it.",
      "tokens": [
        50728,
        550,
        286,
        483,
        544,
        484,
        295,
        309,
        13,
        50850
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4980272054672241,
      "compression_ratio": 1.548717975616455,
      "no_speech_prob": 0.011825182475149632
    },
    {
      "id": 262,
      "seek": 81196,
      "start": 2109.8699926757813,
      "end": 2112.749997558594,
      "text": " But that's not a free ride,",
      "tokens": [
        50850,
        583,
        300,
        311,
        406,
        257,
        1737,
        5077,
        11,
        50994
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4980272054672241,
      "compression_ratio": 1.548717975616455,
      "no_speech_prob": 0.011825182475149632
    },
    {
      "id": 263,
      "seek": 81196,
      "start": 2112.749997558594,
      "end": 2116.1500219726563,
      "text": " because it's all a matter of scale.",
      "tokens": [
        50994,
        570,
        309,
        311,
        439,
        257,
        1871,
        295,
        4373,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4980272054672241,
      "compression_ratio": 1.548717975616455,
      "no_speech_prob": 0.011825182475149632
    },
    {
      "id": 264,
      "seek": 81196,
      "start": 2116.1500219726563,
      "end": 2118.5900244140626,
      "text": " So, if I have applications now,",
      "tokens": [
        51164,
        407,
        11,
        498,
        286,
        362,
        5821,
        586,
        11,
        51286
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4980272054672241,
      "compression_ratio": 1.548717975616455,
      "no_speech_prob": 0.011825182475149632
    },
    {
      "id": 265,
      "seek": 81196,
      "start": 2118.5900244140626,
      "end": 2120.5900244140626,
      "text": " especially websites or web applications",
      "tokens": [
        51286,
        2318,
        12891,
        420,
        3670,
        5821,
        51386
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4980272054672241,
      "compression_ratio": 1.548717975616455,
      "no_speech_prob": 0.011825182475149632
    },
    {
      "id": 266,
      "seek": 81196,
      "start": 2120.5900244140626,
      "end": 2122.8699926757813,
      "text": " that have an incredibly high scale,",
      "tokens": [
        51386,
        300,
        362,
        364,
        6252,
        1090,
        4373,
        11,
        51500
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4980272054672241,
      "compression_ratio": 1.548717975616455,
      "no_speech_prob": 0.011825182475149632
    },
    {
      "id": 267,
      "seek": 81196,
      "start": 2122.8699926757813,
      "end": 2127.5499853515626,
      "text": " then it is of course very efficient",
      "tokens": [
        51500,
        550,
        309,
        307,
        295,
        1164,
        588,
        7148,
        51734
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4980272054672241,
      "compression_ratio": 1.548717975616455,
      "no_speech_prob": 0.011825182475149632
    },
    {
      "id": 268,
      "seek": 83936,
      "start": 2127.5499853515626,
      "end": 2129.1099829101563,
      "text": " when I, for example,",
      "tokens": [
        50364,
        562,
        286,
        11,
        337,
        1365,
        11,
        50442
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4778004288673401,
      "compression_ratio": 1.4649122953414917,
      "no_speech_prob": 0.13594144582748413
    },
    {
      "id": 269,
      "seek": 83936,
      "start": 2129.1099829101563,
      "end": 2132.5900244140626,
      "text": " reduce the amount of data transfer.",
      "tokens": [
        50442,
        5407,
        264,
        2372,
        295,
        1412,
        5003,
        13,
        50616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4778004288673401,
      "compression_ratio": 1.4649122953414917,
      "no_speech_prob": 0.13594144582748413
    },
    {
      "id": 270,
      "seek": 83936,
      "start": 2132.5900244140626,
      "end": 2135.8699926757813,
      "text": " So maybe I make my JSON smarter,",
      "tokens": [
        50616,
        407,
        1310,
        286,
        652,
        452,
        31828,
        20294,
        11,
        50780
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4778004288673401,
      "compression_ratio": 1.4649122953414917,
      "no_speech_prob": 0.13594144582748413
    },
    {
      "id": 271,
      "seek": 83936,
      "start": 2135.8699926757813,
      "end": 2138.8699926757813,
      "text": " make my bundle smarter,",
      "tokens": [
        50780,
        652,
        452,
        24438,
        20294,
        11,
        50930
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4778004288673401,
      "compression_ratio": 1.4649122953414917,
      "no_speech_prob": 0.13594144582748413
    },
    {
      "id": 272,
      "seek": 83936,
      "start": 2138.8699926757813,
      "end": 2140.909970703125,
      "text": " maybe I don't have to get everything and so on.",
      "tokens": [
        50930,
        1310,
        286,
        500,
        380,
        362,
        281,
        483,
        1203,
        293,
        370,
        322,
        13,
        51032
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4778004288673401,
      "compression_ratio": 1.4649122953414917,
      "no_speech_prob": 0.13594144582748413
    },
    {
      "id": 273,
      "seek": 83936,
      "start": 2140.909970703125,
      "end": 2143.3099951171876,
      "text": " So there's a lot going on.",
      "tokens": [
        51032,
        407,
        456,
        311,
        257,
        688,
        516,
        322,
        13,
        51152
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4778004288673401,
      "compression_ratio": 1.4649122953414917,
      "no_speech_prob": 0.13594144582748413
    },
    {
      "id": 274,
      "seek": 83936,
      "start": 2143.3099951171876,
      "end": 2145.3499731445313,
      "text": " Which might even mean",
      "tokens": [
        51152,
        3013,
        1062,
        754,
        914,
        51254
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4778004288673401,
      "compression_ratio": 1.4649122953414917,
      "no_speech_prob": 0.13594144582748413
    },
    {
      "id": 275,
      "seek": 83936,
      "start": 2145.3499731445313,
      "end": 2150.270017089844,
      "text": " that you look even better with an intelligent back-end.",
      "tokens": [
        51254,
        300,
        291,
        574,
        754,
        1101,
        365,
        364,
        13232,
        646,
        12,
        521,
        13,
        51500
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4778004288673401,
      "compression_ratio": 1.4649122953414917,
      "no_speech_prob": 0.13594144582748413
    },
    {
      "id": 276,
      "seek": 83936,
      "start": 2150.270017089844,
      "end": 2152.909970703125,
      "text": " Exactly, could be even worse, yes.",
      "tokens": [
        51500,
        7587,
        11,
        727,
        312,
        754,
        5324,
        11,
        2086,
        13,
        51632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4778004288673401,
      "compression_ratio": 1.4649122953414917,
      "no_speech_prob": 0.13594144582748413
    },
    {
      "id": 277,
      "seek": 83936,
      "start": 2152.909970703125,
      "end": 2156.3099951171876,
      "text": " Then HappyTree asked on YouTube,",
      "tokens": [
        51632,
        1396,
        8277,
        51,
        701,
        2351,
        322,
        3088,
        11,
        51802
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4778004288673401,
      "compression_ratio": 1.4649122953414917,
      "no_speech_prob": 0.13594144582748413
    },
    {
      "id": 278,
      "seek": 86812,
      "start": 2156.3099951171876,
      "end": 2158.229978027344,
      "text": " also a question that, I think,",
      "tokens": [
        50364,
        611,
        257,
        1168,
        300,
        11,
        286,
        519,
        11,
        50460
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5450146198272705,
      "compression_ratio": 1.5251141786575317,
      "no_speech_prob": 0.016480419784784317
    },
    {
      "id": 279,
      "seek": 86812,
      "start": 2158.229978027344,
      "end": 2161.19,
      "text": " goes a little bit in the other direction.",
      "tokens": [
        50460,
        1709,
        257,
        707,
        857,
        294,
        264,
        661,
        3513,
        13,
        50608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5450146198272705,
      "compression_ratio": 1.5251141786575317,
      "no_speech_prob": 0.016480419784784317
    },
    {
      "id": 280,
      "seek": 86812,
      "start": 2161.19,
      "end": 2164.950009765625,
      "text": " He asked, he or she asked,",
      "tokens": [
        50608,
        634,
        2351,
        11,
        415,
        420,
        750,
        2351,
        11,
        50796
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5450146198272705,
      "compression_ratio": 1.5251141786575317,
      "no_speech_prob": 0.016480419784784317
    },
    {
      "id": 281,
      "seek": 86812,
      "start": 2164.950009765625,
      "end": 2170.950009765625,
      "text": " if you now press the energy through any measure,",
      "tokens": [
        50796,
        498,
        291,
        586,
        1886,
        264,
        2281,
        807,
        604,
        3481,
        11,
        51096
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5450146198272705,
      "compression_ratio": 1.5251141786575317,
      "no_speech_prob": 0.016480419784784317
    },
    {
      "id": 282,
      "seek": 86812,
      "start": 2170.950009765625,
      "end": 2173.5900244140626,
      "text": " don't you get directly into the rebound effect,",
      "tokens": [
        51096,
        500,
        380,
        291,
        483,
        3838,
        666,
        264,
        31850,
        1802,
        11,
        51228
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5450146198272705,
      "compression_ratio": 1.5251141786575317,
      "no_speech_prob": 0.016480419784784317
    },
    {
      "id": 283,
      "seek": 86812,
      "start": 2173.5900244140626,
      "end": 2175.5900244140626,
      "text": " that then the input is simply used",
      "tokens": [
        51228,
        300,
        550,
        264,
        4846,
        307,
        2935,
        1143,
        51328
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5450146198272705,
      "compression_ratio": 1.5251141786575317,
      "no_speech_prob": 0.016480419784784317
    },
    {
      "id": 284,
      "seek": 86812,
      "start": 2175.5900244140626,
      "end": 2177.510007324219,
      "text": " to let something else run?",
      "tokens": [
        51328,
        281,
        718,
        746,
        1646,
        1190,
        30,
        51424
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5450146198272705,
      "compression_ratio": 1.5251141786575317,
      "no_speech_prob": 0.016480419784784317
    },
    {
      "id": 285,
      "seek": 86812,
      "start": 2177.510007324219,
      "end": 2179.749997558594,
      "text": " That's very much like this story.",
      "tokens": [
        51424,
        663,
        311,
        588,
        709,
        411,
        341,
        1657,
        13,
        51536
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5450146198272705,
      "compression_ratio": 1.5251141786575317,
      "no_speech_prob": 0.016480419784784317
    },
    {
      "id": 286,
      "seek": 86812,
      "start": 2179.749997558594,
      "end": 2181.229978027344,
      "text": " Always the same.",
      "tokens": [
        51536,
        11270,
        264,
        912,
        13,
        51610
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5450146198272705,
      "compression_ratio": 1.5251141786575317,
      "no_speech_prob": 0.016480419784784317
    },
    {
      "id": 287,
      "seek": 86812,
      "start": 2181.229978027344,
      "end": 2185.1500219726563,
      "text": " Yes, I agree, of course.",
      "tokens": [
        51610,
        1079,
        11,
        286,
        3986,
        11,
        295,
        1164,
        13,
        51806
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5450146198272705,
      "compression_ratio": 1.5251141786575317,
      "no_speech_prob": 0.016480419784784317
    },
    {
      "id": 288,
      "seek": 89696,
      "start": 2185.1500219726563,
      "end": 2187.71001953125,
      "text": " Rebound is always...",
      "tokens": [
        50364,
        1300,
        18767,
        307,
        1009,
        485,
        50492
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5919913649559021,
      "compression_ratio": 1.3743590116500854,
      "no_speech_prob": 0.002896595746278763
    },
    {
      "id": 289,
      "seek": 89696,
      "start": 2187.71001953125,
      "end": 2191.3099951171876,
      "text": " That's why it's like this,",
      "tokens": [
        50492,
        663,
        311,
        983,
        309,
        311,
        411,
        341,
        11,
        50672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5919913649559021,
      "compression_ratio": 1.3743590116500854,
      "no_speech_prob": 0.002896595746278763
    },
    {
      "id": 290,
      "seek": 89696,
      "start": 2191.3099951171876,
      "end": 2193.3099951171876,
      "text": " if you...",
      "tokens": [
        50672,
        498,
        291,
        485,
        50772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5919913649559021,
      "compression_ratio": 1.3743590116500854,
      "no_speech_prob": 0.002896595746278763
    },
    {
      "id": 291,
      "seek": 89696,
      "start": 2193.3099951171876,
      "end": 2195.749997558594,
      "text": " So even bigger, right?",
      "tokens": [
        50772,
        407,
        754,
        3801,
        11,
        558,
        30,
        50894
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5919913649559021,
      "compression_ratio": 1.3743590116500854,
      "no_speech_prob": 0.002896595746278763
    },
    {
      "id": 292,
      "seek": 89696,
      "start": 2195.749997558594,
      "end": 2198.3099951171876,
      "text": " So we're talking about social politics now.",
      "tokens": [
        50894,
        407,
        321,
        434,
        1417,
        466,
        2093,
        7341,
        586,
        13,
        51022
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5919913649559021,
      "compression_ratio": 1.3743590116500854,
      "no_speech_prob": 0.002896595746278763
    },
    {
      "id": 293,
      "seek": 89696,
      "start": 2198.3099951171876,
      "end": 2200.6300024414063,
      "text": " So I'm just in my profession.",
      "tokens": [
        51022,
        407,
        286,
        478,
        445,
        294,
        452,
        7032,
        13,
        51138
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5919913649559021,
      "compression_ratio": 1.3743590116500854,
      "no_speech_prob": 0.002896595746278763
    },
    {
      "id": 294,
      "seek": 89696,
      "start": 2200.6300024414063,
      "end": 2202.1500219726563,
      "text": " What can I, as a software developer,",
      "tokens": [
        51138,
        708,
        393,
        286,
        11,
        382,
        257,
        4722,
        10754,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5919913649559021,
      "compression_ratio": 1.3743590116500854,
      "no_speech_prob": 0.002896595746278763
    },
    {
      "id": 295,
      "seek": 89696,
      "start": 2202.1500219726563,
      "end": 2204.470029296875,
      "text": " as an architect, do?",
      "tokens": [
        51214,
        382,
        364,
        6331,
        11,
        360,
        30,
        51330
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5919913649559021,
      "compression_ratio": 1.3743590116500854,
      "no_speech_prob": 0.002896595746278763
    },
    {
      "id": 296,
      "seek": 89696,
      "start": 2204.470029296875,
      "end": 2211.1500219726563,
      "text": " And that is, reduce the CO2 emissions of your software.",
      "tokens": [
        51330,
        400,
        300,
        307,
        11,
        5407,
        264,
        3002,
        17,
        14607,
        295,
        428,
        4722,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5919913649559021,
      "compression_ratio": 1.3743590116500854,
      "no_speech_prob": 0.002896595746278763
    },
    {
      "id": 297,
      "seek": 92296,
      "start": 2211.19,
      "end": 2215.989987792969,
      "text": " From coding to operation.",
      "tokens": [
        50366,
        3358,
        17720,
        281,
        6916,
        13,
        50606
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4555586874485016,
      "compression_ratio": 1.420454502105713,
      "no_speech_prob": 0.004732098896056414
    },
    {
      "id": 298,
      "seek": 92296,
      "start": 2215.989987792969,
      "end": 2221.229978027344,
      "text": " But yes, then you just have more rebound again.",
      "tokens": [
        50606,
        583,
        2086,
        11,
        550,
        291,
        445,
        362,
        544,
        31850,
        797,
        13,
        50868
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4555586874485016,
      "compression_ratio": 1.420454502105713,
      "no_speech_prob": 0.004732098896056414
    },
    {
      "id": 299,
      "seek": 92296,
      "start": 2221.229978027344,
      "end": 2226.0700048828126,
      "text": " And that is, for example, a criticism of this norm,",
      "tokens": [
        50868,
        400,
        300,
        307,
        11,
        337,
        1365,
        11,
        257,
        15835,
        295,
        341,
        2026,
        11,
        51110
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4555586874485016,
      "compression_ratio": 1.420454502105713,
      "no_speech_prob": 0.004732098896056414
    },
    {
      "id": 300,
      "seek": 92296,
      "start": 2226.0700048828126,
      "end": 2228.8300146484376,
      "text": " that there is a functional unit here",
      "tokens": [
        51110,
        300,
        456,
        307,
        257,
        11745,
        4985,
        510,
        51248
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4555586874485016,
      "compression_ratio": 1.420454502105713,
      "no_speech_prob": 0.004732098896056414
    },
    {
      "id": 301,
      "seek": 92296,
      "start": 2228.8300146484376,
      "end": 2231.030026855469,
      "text": " in the Carbon Intensity software.",
      "tokens": [
        51248,
        294,
        264,
        31453,
        5681,
        6859,
        4722,
        13,
        51358
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4555586874485016,
      "compression_ratio": 1.420454502105713,
      "no_speech_prob": 0.004732098896056414
    },
    {
      "id": 302,
      "seek": 92296,
      "start": 2231.030026855469,
      "end": 2238.19,
      "text": " So where I say, I have an emission per order process.",
      "tokens": [
        51358,
        407,
        689,
        286,
        584,
        11,
        286,
        362,
        364,
        29513,
        680,
        1668,
        1399,
        13,
        51716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4555586874485016,
      "compression_ratio": 1.420454502105713,
      "no_speech_prob": 0.004732098896056414
    },
    {
      "id": 303,
      "seek": 95000,
      "start": 2238.229978027344,
      "end": 2242.5900244140626,
      "text": " If now the number of orders goes up,",
      "tokens": [
        50366,
        759,
        586,
        264,
        1230,
        295,
        9470,
        1709,
        493,
        11,
        50584
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39124253392219543,
      "compression_ratio": 1.534482717514038,
      "no_speech_prob": 0.0029205307364463806
    },
    {
      "id": 304,
      "seek": 95000,
      "start": 2242.5900244140626,
      "end": 2246.429990234375,
      "text": " then the CO2 emission actually goes up in my entire system.",
      "tokens": [
        50584,
        550,
        264,
        3002,
        17,
        29513,
        767,
        1709,
        493,
        294,
        452,
        2302,
        1185,
        13,
        50776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39124253392219543,
      "compression_ratio": 1.534482717514038,
      "no_speech_prob": 0.0029205307364463806
    },
    {
      "id": 305,
      "seek": 95000,
      "start": 2246.429990234375,
      "end": 2249.1099829101563,
      "text": " But my Carbon Intensity software",
      "tokens": [
        50776,
        583,
        452,
        31453,
        5681,
        6859,
        4722,
        50910
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39124253392219543,
      "compression_ratio": 1.534482717514038,
      "no_speech_prob": 0.0029205307364463806
    },
    {
      "id": 306,
      "seek": 95000,
      "start": 2249.1099829101563,
      "end": 2253.3900122070313,
      "text": " could stay constant or even go down a bit.",
      "tokens": [
        50910,
        727,
        1754,
        5754,
        420,
        754,
        352,
        760,
        257,
        857,
        13,
        51124
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39124253392219543,
      "compression_ratio": 1.534482717514038,
      "no_speech_prob": 0.0029205307364463806
    },
    {
      "id": 307,
      "seek": 95000,
      "start": 2253.3900122070313,
      "end": 2255.270017089844,
      "text": " And now the rebound comes here.",
      "tokens": [
        51124,
        400,
        586,
        264,
        31850,
        1487,
        510,
        13,
        51218
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39124253392219543,
      "compression_ratio": 1.534482717514038,
      "no_speech_prob": 0.0029205307364463806
    },
    {
      "id": 308,
      "seek": 95000,
      "start": 2255.270017089844,
      "end": 2257.030026855469,
      "text": " So it all looks good.",
      "tokens": [
        51218,
        407,
        309,
        439,
        1542,
        665,
        13,
        51306
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39124253392219543,
      "compression_ratio": 1.534482717514038,
      "no_speech_prob": 0.0029205307364463806
    },
    {
      "id": 309,
      "seek": 95000,
      "start": 2257.030026855469,
      "end": 2260.030026855469,
      "text": " So the energy consumption is great,",
      "tokens": [
        51306,
        407,
        264,
        2281,
        12126,
        307,
        869,
        11,
        51456
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39124253392219543,
      "compression_ratio": 1.534482717514038,
      "no_speech_prob": 0.0029205307364463806
    },
    {
      "id": 310,
      "seek": 95000,
      "start": 2260.030026855469,
      "end": 2262.19,
      "text": " but overall it is higher.",
      "tokens": [
        51456,
        457,
        4787,
        309,
        307,
        2946,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39124253392219543,
      "compression_ratio": 1.534482717514038,
      "no_speech_prob": 0.0029205307364463806
    },
    {
      "id": 311,
      "seek": 95000,
      "start": 2262.19,
      "end": 2264.8300146484376,
      "text": " That means the efficiency that I had in it,",
      "tokens": [
        51564,
        663,
        1355,
        264,
        10493,
        300,
        286,
        632,
        294,
        309,
        11,
        51696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39124253392219543,
      "compression_ratio": 1.534482717514038,
      "no_speech_prob": 0.0029205307364463806
    },
    {
      "id": 312,
      "seek": 95000,
      "start": 2264.8300146484376,
      "end": 2267.470029296875,
      "text": " it was eaten by growth.",
      "tokens": [
        51696,
        309,
        390,
        12158,
        538,
        4599,
        13,
        51828
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39124253392219543,
      "compression_ratio": 1.534482717514038,
      "no_speech_prob": 0.0029205307364463806
    },
    {
      "id": 313,
      "seek": 97928,
      "start": 2267.470029296875,
      "end": 2268.71001953125,
      "text": " And I actually have to,",
      "tokens": [
        50364,
        400,
        286,
        767,
        362,
        281,
        11,
        50426
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41247376799583435,
      "compression_ratio": 1.6608695983886719,
      "no_speech_prob": 0.0011316640302538872
    },
    {
      "id": 314,
      "seek": 97928,
      "start": 2268.71001953125,
      "end": 2271.8699926757813,
      "text": " to maintain a constant CO2 emission,",
      "tokens": [
        50426,
        281,
        6909,
        257,
        5754,
        3002,
        17,
        29513,
        11,
        50584
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41247376799583435,
      "compression_ratio": 1.6608695983886719,
      "no_speech_prob": 0.0011316640302538872
    },
    {
      "id": 315,
      "seek": 97928,
      "start": 2271.8699926757813,
      "end": 2278.270017089844,
      "text": " I have to increase my efficiency more than my growth.",
      "tokens": [
        50584,
        286,
        362,
        281,
        3488,
        452,
        10493,
        544,
        813,
        452,
        4599,
        13,
        50904
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41247376799583435,
      "compression_ratio": 1.6608695983886719,
      "no_speech_prob": 0.0011316640302538872
    },
    {
      "id": 316,
      "seek": 97928,
      "start": 2278.270017089844,
      "end": 2280.5499853515626,
      "text": " This is an effect that we had with lamps,",
      "tokens": [
        50904,
        639,
        307,
        364,
        1802,
        300,
        321,
        632,
        365,
        34887,
        11,
        51018
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41247376799583435,
      "compression_ratio": 1.6608695983886719,
      "no_speech_prob": 0.0011316640302538872
    },
    {
      "id": 317,
      "seek": 97928,
      "start": 2280.5499853515626,
      "end": 2283.3499731445313,
      "text": " which used to have these light bulbs.",
      "tokens": [
        51018,
        597,
        1143,
        281,
        362,
        613,
        1442,
        32871,
        13,
        51158
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41247376799583435,
      "compression_ratio": 1.6608695983886719,
      "no_speech_prob": 0.0011316640302538872
    },
    {
      "id": 318,
      "seek": 97928,
      "start": 2283.3499731445313,
      "end": 2285.8699926757813,
      "text": " And then we exchanged them for LEDs,",
      "tokens": [
        51158,
        400,
        550,
        321,
        38378,
        552,
        337,
        33366,
        11,
        51284
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41247376799583435,
      "compression_ratio": 1.6608695983886719,
      "no_speech_prob": 0.0011316640302538872
    },
    {
      "id": 319,
      "seek": 97928,
      "start": 2285.8699926757813,
      "end": 2288.270017089844,
      "text": " in the hope that the energy consumption",
      "tokens": [
        51284,
        294,
        264,
        1454,
        300,
        264,
        2281,
        12126,
        51404
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41247376799583435,
      "compression_ratio": 1.6608695983886719,
      "no_speech_prob": 0.0011316640302538872
    },
    {
      "id": 320,
      "seek": 97928,
      "start": 2288.270017089844,
      "end": 2290.5499853515626,
      "text": " for the lighting goes down.",
      "tokens": [
        51404,
        337,
        264,
        9577,
        1709,
        760,
        13,
        51518
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41247376799583435,
      "compression_ratio": 1.6608695983886719,
      "no_speech_prob": 0.0011316640302538872
    },
    {
      "id": 321,
      "seek": 97928,
      "start": 2290.5499853515626,
      "end": 2292.470029296875,
      "text": " Exactly the other way around.",
      "tokens": [
        51518,
        7587,
        264,
        661,
        636,
        926,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41247376799583435,
      "compression_ratio": 1.6608695983886719,
      "no_speech_prob": 0.0011316640302538872
    },
    {
      "id": 322,
      "seek": 97928,
      "start": 2292.470029296875,
      "end": 2295.0700048828126,
      "text": " The energy consumption for the lighting goes higher,",
      "tokens": [
        51614,
        440,
        2281,
        12126,
        337,
        264,
        9577,
        1709,
        2946,
        11,
        51744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41247376799583435,
      "compression_ratio": 1.6608695983886719,
      "no_speech_prob": 0.0011316640302538872
    },
    {
      "id": 323,
      "seek": 100688,
      "start": 2295.0700048828126,
      "end": 2297.5499853515626,
      "text": " because now you have LEDs everywhere.",
      "tokens": [
        50364,
        570,
        586,
        291,
        362,
        33366,
        5315,
        13,
        50488
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45814815163612366,
      "compression_ratio": 1.5566037893295288,
      "no_speech_prob": 0.054489243775606155
    },
    {
      "id": 324,
      "seek": 100688,
      "start": 2297.5499853515626,
      "end": 2302.229978027344,
      "text": " Then, of course, the consumption per lamp has become lower,",
      "tokens": [
        50488,
        1396,
        11,
        295,
        1164,
        11,
        264,
        12126,
        680,
        12684,
        575,
        1813,
        3126,
        11,
        50722
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45814815163612366,
      "compression_ratio": 1.5566037893295288,
      "no_speech_prob": 0.054489243775606155
    },
    {
      "id": 325,
      "seek": 100688,
      "start": 2302.229978027344,
      "end": 2304.1099829101563,
      "text": " but much more.",
      "tokens": [
        50722,
        457,
        709,
        544,
        13,
        50816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45814815163612366,
      "compression_ratio": 1.5566037893295288,
      "no_speech_prob": 0.054489243775606155
    },
    {
      "id": 326,
      "seek": 100688,
      "start": 2304.1099829101563,
      "end": 2307.270017089844,
      "text": " But that's actually the rebound effect.",
      "tokens": [
        50816,
        583,
        300,
        311,
        767,
        264,
        31850,
        1802,
        13,
        50974
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45814815163612366,
      "compression_ratio": 1.5566037893295288,
      "no_speech_prob": 0.054489243775606155
    },
    {
      "id": 327,
      "seek": 100688,
      "start": 2307.270017089844,
      "end": 2309.229978027344,
      "text": " So what you just said,",
      "tokens": [
        50974,
        407,
        437,
        291,
        445,
        848,
        11,
        51072
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45814815163612366,
      "compression_ratio": 1.5566037893295288,
      "no_speech_prob": 0.054489243775606155
    },
    {
      "id": 328,
      "seek": 100688,
      "start": 2309.229978027344,
      "end": 2311.030026855469,
      "text": " that I somehow say,",
      "tokens": [
        51072,
        300,
        286,
        6063,
        584,
        11,
        51162
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45814815163612366,
      "compression_ratio": 1.5566037893295288,
      "no_speech_prob": 0.054489243775606155
    },
    {
      "id": 329,
      "seek": 100688,
      "start": 2311.030026855469,
      "end": 2313.62994140625,
      "text": " I have less consumption per lamp now,",
      "tokens": [
        51162,
        286,
        362,
        1570,
        12126,
        680,
        12684,
        586,
        11,
        51292
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45814815163612366,
      "compression_ratio": 1.5566037893295288,
      "no_speech_prob": 0.054489243775606155
    },
    {
      "id": 330,
      "seek": 100688,
      "start": 2313.62994140625,
      "end": 2315.75005859375,
      "text": " but I now illuminate things",
      "tokens": [
        51292,
        457,
        286,
        586,
        28593,
        473,
        721,
        51398
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45814815163612366,
      "compression_ratio": 1.5566037893295288,
      "no_speech_prob": 0.054489243775606155
    },
    {
      "id": 331,
      "seek": 100688,
      "start": 2315.75005859375,
      "end": 2317.3099951171876,
      "text": " that I didn't illuminate before,",
      "tokens": [
        51398,
        300,
        286,
        994,
        380,
        28593,
        473,
        949,
        11,
        51476
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45814815163612366,
      "compression_ratio": 1.5566037893295288,
      "no_speech_prob": 0.054489243775606155
    },
    {
      "id": 332,
      "seek": 100688,
      "start": 2317.3099951171876,
      "end": 2322.2300390625,
      "text": " because I can suddenly afford that.",
      "tokens": [
        51476,
        570,
        286,
        393,
        5800,
        6157,
        300,
        13,
        51722
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45814815163612366,
      "compression_ratio": 1.5566037893295288,
      "no_speech_prob": 0.054489243775606155
    },
    {
      "id": 333,
      "seek": 103404,
      "start": 2323.2300390625,
      "end": 2329.389951171875,
      "text": " And that with the order is actually this rebound effect.",
      "tokens": [
        50414,
        400,
        300,
        365,
        264,
        1668,
        307,
        767,
        341,
        31850,
        1802,
        13,
        50722
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5634182095527649,
      "compression_ratio": 1.5868544578552246,
      "no_speech_prob": 0.009716326370835304
    },
    {
      "id": 334,
      "seek": 103404,
      "start": 2329.389951171875,
      "end": 2333.66998046875,
      "text": " So it just means that I am economically successful",
      "tokens": [
        50722,
        407,
        309,
        445,
        1355,
        300,
        286,
        669,
        26811,
        4406,
        50936
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5634182095527649,
      "compression_ratio": 1.5868544578552246,
      "no_speech_prob": 0.009716326370835304
    },
    {
      "id": 335,
      "seek": 103404,
      "start": 2333.66998046875,
      "end": 2336.19,
      "text": " and have more orders.",
      "tokens": [
        50936,
        293,
        362,
        544,
        9470,
        13,
        51062
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5634182095527649,
      "compression_ratio": 1.5868544578552246,
      "no_speech_prob": 0.009716326370835304
    },
    {
      "id": 336,
      "seek": 103404,
      "start": 2336.19,
      "end": 2338.1100439453126,
      "text": " Rebound would be if I now say,",
      "tokens": [
        51062,
        1300,
        18767,
        576,
        312,
        498,
        286,
        586,
        584,
        11,
        51158
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5634182095527649,
      "compression_ratio": 1.5868544578552246,
      "no_speech_prob": 0.009716326370835304
    },
    {
      "id": 337,
      "seek": 103404,
      "start": 2338.1100439453126,
      "end": 2341.0299658203126,
      "text": " okay, I now have an increase in efficiency",
      "tokens": [
        51158,
        1392,
        11,
        286,
        586,
        362,
        364,
        3488,
        294,
        10493,
        51304
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5634182095527649,
      "compression_ratio": 1.5868544578552246,
      "no_speech_prob": 0.009716326370835304
    },
    {
      "id": 338,
      "seek": 103404,
      "start": 2341.0299658203126,
      "end": 2343.909970703125,
      "text": " in relation to, for example, order processes.",
      "tokens": [
        51304,
        294,
        9721,
        281,
        11,
        337,
        1365,
        11,
        1668,
        7555,
        13,
        51448
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5634182095527649,
      "compression_ratio": 1.5868544578552246,
      "no_speech_prob": 0.009716326370835304
    },
    {
      "id": 339,
      "seek": 103404,
      "start": 2343.909970703125,
      "end": 2347.0299658203126,
      "text": " And now I'm just starting and digitizing the rest too,",
      "tokens": [
        51448,
        400,
        586,
        286,
        478,
        445,
        2891,
        293,
        14293,
        3319,
        264,
        1472,
        886,
        11,
        51604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5634182095527649,
      "compression_ratio": 1.5868544578552246,
      "no_speech_prob": 0.009716326370835304
    },
    {
      "id": 340,
      "seek": 103404,
      "start": 2347.0299658203126,
      "end": 2350.2300390625,
      "text": " because I now have free resources",
      "tokens": [
        51604,
        570,
        286,
        586,
        362,
        1737,
        3593,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5634182095527649,
      "compression_ratio": 1.5868544578552246,
      "no_speech_prob": 0.009716326370835304
    },
    {
      "id": 341,
      "seek": 106204,
      "start": 2350.2300390625,
      "end": 2352.71001953125,
      "text": " that I can use for other things.",
      "tokens": [
        50364,
        300,
        286,
        393,
        764,
        337,
        661,
        721,
        13,
        50488
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43662840127944946,
      "compression_ratio": 1.5416666269302368,
      "no_speech_prob": 0.015644775703549385
    },
    {
      "id": 342,
      "seek": 106204,
      "start": 2352.71001953125,
      "end": 2356.8300146484376,
      "text": " And I can't really imagine that, can I?",
      "tokens": [
        50488,
        400,
        286,
        393,
        380,
        534,
        3811,
        300,
        11,
        393,
        286,
        30,
        50694
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43662840127944946,
      "compression_ratio": 1.5416666269302368,
      "no_speech_prob": 0.015644775703549385
    },
    {
      "id": 343,
      "seek": 106204,
      "start": 2356.8300146484376,
      "end": 2359.75005859375,
      "text": " Misunderstood, sorry.",
      "tokens": [
        50694,
        23240,
        6617,
        6431,
        11,
        2597,
        13,
        50840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43662840127944946,
      "compression_ratio": 1.5416666269302368,
      "no_speech_prob": 0.015644775703549385
    },
    {
      "id": 344,
      "seek": 106204,
      "start": 2359.75005859375,
      "end": 2362.5499853515626,
      "text": " The rebound actually comes from the fact",
      "tokens": [
        50840,
        440,
        31850,
        767,
        1487,
        490,
        264,
        1186,
        50980
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43662840127944946,
      "compression_ratio": 1.5416666269302368,
      "no_speech_prob": 0.015644775703549385
    },
    {
      "id": 345,
      "seek": 106204,
      "start": 2362.5499853515626,
      "end": 2365.909970703125,
      "text": " that you think you're good.",
      "tokens": [
        50980,
        300,
        291,
        519,
        291,
        434,
        665,
        13,
        51148
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43662840127944946,
      "compression_ratio": 1.5416666269302368,
      "no_speech_prob": 0.015644775703549385
    },
    {
      "id": 346,
      "seek": 106204,
      "start": 2365.909970703125,
      "end": 2368.1499609375,
      "text": " So that's...",
      "tokens": [
        51148,
        407,
        300,
        311,
        485,
        51260
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43662840127944946,
      "compression_ratio": 1.5416666269302368,
      "no_speech_prob": 0.015644775703549385
    },
    {
      "id": 347,
      "seek": 106204,
      "start": 2368.1499609375,
      "end": 2370.66998046875,
      "text": " So I can now...",
      "tokens": [
        51260,
        407,
        286,
        393,
        586,
        485,
        51386
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43662840127944946,
      "compression_ratio": 1.5416666269302368,
      "no_speech_prob": 0.015644775703549385
    },
    {
      "id": 348,
      "seek": 106204,
      "start": 2370.66998046875,
      "end": 2373.19,
      "text": " So the LED lamp doesn't cost anything now,",
      "tokens": [
        51386,
        407,
        264,
        11261,
        12684,
        1177,
        380,
        2063,
        1340,
        586,
        11,
        51512
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43662840127944946,
      "compression_ratio": 1.5416666269302368,
      "no_speech_prob": 0.015644775703549385
    },
    {
      "id": 349,
      "seek": 106204,
      "start": 2373.19,
      "end": 2374.3099951171876,
      "text": " so to speak, energy.",
      "tokens": [
        51512,
        370,
        281,
        1710,
        11,
        2281,
        13,
        51568
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43662840127944946,
      "compression_ratio": 1.5416666269302368,
      "no_speech_prob": 0.015644775703549385
    },
    {
      "id": 350,
      "seek": 106204,
      "start": 2374.3099951171876,
      "end": 2376.3099951171876,
      "text": " Then I just make it a little nicer",
      "tokens": [
        51568,
        1396,
        286,
        445,
        652,
        309,
        257,
        707,
        22842,
        51668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43662840127944946,
      "compression_ratio": 1.5416666269302368,
      "no_speech_prob": 0.015644775703549385
    },
    {
      "id": 351,
      "seek": 106204,
      "start": 2376.3099951171876,
      "end": 2379.470029296875,
      "text": " or let it run, because it doesn't matter.",
      "tokens": [
        51668,
        420,
        718,
        309,
        1190,
        11,
        570,
        309,
        1177,
        380,
        1871,
        13,
        51826
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43662840127944946,
      "compression_ratio": 1.5416666269302368,
      "no_speech_prob": 0.015644775703549385
    },
    {
      "id": 352,
      "seek": 109128,
      "start": 2379.470029296875,
      "end": 2381.470029296875,
      "text": " And then it happens.",
      "tokens": [
        50364,
        400,
        550,
        309,
        2314,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3570390045642853,
      "compression_ratio": 1.565445065498352,
      "no_speech_prob": 0.0017163591692224145
    },
    {
      "id": 353,
      "seek": 109128,
      "start": 2381.470029296875,
      "end": 2383.75005859375,
      "text": " Then it kicks me off, so to speak,",
      "tokens": [
        50464,
        1396,
        309,
        21293,
        385,
        766,
        11,
        370,
        281,
        1710,
        11,
        50578
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3570390045642853,
      "compression_ratio": 1.565445065498352,
      "no_speech_prob": 0.0017163591692224145
    },
    {
      "id": 354,
      "seek": 109128,
      "start": 2383.75005859375,
      "end": 2387.1499609375,
      "text": " because I don't even notice it.",
      "tokens": [
        50578,
        570,
        286,
        500,
        380,
        754,
        3449,
        309,
        13,
        50748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3570390045642853,
      "compression_ratio": 1.565445065498352,
      "no_speech_prob": 0.0017163591692224145
    },
    {
      "id": 355,
      "seek": 109128,
      "start": 2387.1499609375,
      "end": 2389.5099462890626,
      "text": " And if I now have my emissions",
      "tokens": [
        50748,
        400,
        498,
        286,
        586,
        362,
        452,
        14607,
        50866
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3570390045642853,
      "compression_ratio": 1.565445065498352,
      "no_speech_prob": 0.0017163591692224145
    },
    {
      "id": 356,
      "seek": 109128,
      "start": 2389.5099462890626,
      "end": 2392.2300390625,
      "text": " in such a factor,",
      "tokens": [
        50866,
        294,
        1270,
        257,
        5952,
        11,
        51002
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3570390045642853,
      "compression_ratio": 1.565445065498352,
      "no_speech_prob": 0.0017163591692224145
    },
    {
      "id": 357,
      "seek": 109128,
      "start": 2392.2300390625,
      "end": 2394.1499609375,
      "text": " then I don't notice it.",
      "tokens": [
        51002,
        550,
        286,
        500,
        380,
        3449,
        309,
        13,
        51098
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3570390045642853,
      "compression_ratio": 1.565445065498352,
      "no_speech_prob": 0.0017163591692224145
    },
    {
      "id": 358,
      "seek": 109128,
      "start": 2394.1499609375,
      "end": 2397.5499853515626,
      "text": " And that's why many say",
      "tokens": [
        51098,
        400,
        300,
        311,
        983,
        867,
        584,
        51268
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3570390045642853,
      "compression_ratio": 1.565445065498352,
      "no_speech_prob": 0.0017163591692224145
    },
    {
      "id": 359,
      "seek": 109128,
      "start": 2397.5499853515626,
      "end": 2402.2699560546876,
      "text": " that you always have to monitor the entire system",
      "tokens": [
        51268,
        300,
        291,
        1009,
        362,
        281,
        6002,
        264,
        2302,
        1185,
        51504
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3570390045642853,
      "compression_ratio": 1.565445065498352,
      "no_speech_prob": 0.0017163591692224145
    },
    {
      "id": 360,
      "seek": 109128,
      "start": 2402.2699560546876,
      "end": 2406.2699560546876,
      "text": " to avoid exactly this rebound effect,",
      "tokens": [
        51504,
        281,
        5042,
        2293,
        341,
        31850,
        1802,
        11,
        51704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3570390045642853,
      "compression_ratio": 1.565445065498352,
      "no_speech_prob": 0.0017163591692224145
    },
    {
      "id": 361,
      "seek": 109128,
      "start": 2406.2699560546876,
      "end": 2408.3099951171876,
      "text": " because it's out of sight.",
      "tokens": [
        51704,
        570,
        309,
        311,
        484,
        295,
        7860,
        13,
        51806
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3570390045642853,
      "compression_ratio": 1.565445065498352,
      "no_speech_prob": 0.0017163591692224145
    },
    {
      "id": 362,
      "seek": 112012,
      "start": 2408.3099951171876,
      "end": 2409.429990234375,
      "text": " Okay, that means you're telling me",
      "tokens": [
        50364,
        1033,
        11,
        300,
        1355,
        291,
        434,
        3585,
        385,
        50420
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4597212076187134,
      "compression_ratio": 1.6423076391220093,
      "no_speech_prob": 0.014927295967936516
    },
    {
      "id": 363,
      "seek": 112012,
      "start": 2409.429990234375,
      "end": 2412.1100439453126,
      "text": " this number per unit is somehow deceitful,",
      "tokens": [
        50420,
        341,
        1230,
        680,
        4985,
        307,
        6063,
        14088,
        270,
        906,
        11,
        50554
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4597212076187134,
      "compression_ratio": 1.6423076391220093,
      "no_speech_prob": 0.014927295967936516
    },
    {
      "id": 364,
      "seek": 112012,
      "start": 2412.1100439453126,
      "end": 2413.7899755859376,
      "text": " because when the units grow,",
      "tokens": [
        50554,
        570,
        562,
        264,
        6815,
        1852,
        11,
        50638
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4597212076187134,
      "compression_ratio": 1.6423076391220093,
      "no_speech_prob": 0.014927295967936516
    },
    {
      "id": 365,
      "seek": 112012,
      "start": 2413.7899755859376,
      "end": 2415.0700048828126,
      "text": " then I have an overall problem",
      "tokens": [
        50638,
        550,
        286,
        362,
        364,
        4787,
        1154,
        50702
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4597212076187134,
      "compression_ratio": 1.6423076391220093,
      "no_speech_prob": 0.014927295967936516
    },
    {
      "id": 366,
      "seek": 112012,
      "start": 2415.0700048828126,
      "end": 2420.3500341796876,
      "text": " and have to work harder, so to speak.",
      "tokens": [
        50702,
        293,
        362,
        281,
        589,
        6081,
        11,
        370,
        281,
        1710,
        13,
        50966
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4597212076187134,
      "compression_ratio": 1.6423076391220093,
      "no_speech_prob": 0.014927295967936516
    },
    {
      "id": 367,
      "seek": 112012,
      "start": 2420.3500341796876,
      "end": 2422.2699560546876,
      "text": " There are still several questions.",
      "tokens": [
        50966,
        821,
        366,
        920,
        2940,
        1651,
        13,
        51062
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4597212076187134,
      "compression_ratio": 1.6423076391220093,
      "no_speech_prob": 0.014927295967936516
    },
    {
      "id": 368,
      "seek": 112012,
      "start": 2422.2699560546876,
      "end": 2425.62994140625,
      "text": " So one has...",
      "tokens": [
        51062,
        407,
        472,
        575,
        485,
        51230
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4597212076187134,
      "compression_ratio": 1.6423076391220093,
      "no_speech_prob": 0.014927295967936516
    },
    {
      "id": 369,
      "seek": 112012,
      "start": 2425.62994140625,
      "end": 2427.0299658203126,
      "text": " So here's the question again.",
      "tokens": [
        51230,
        407,
        510,
        311,
        264,
        1168,
        797,
        13,
        51300
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4597212076187134,
      "compression_ratio": 1.6423076391220093,
      "no_speech_prob": 0.014927295967936516
    },
    {
      "id": 370,
      "seek": 112012,
      "start": 2427.0299658203126,
      "end": 2429.5900244140626,
      "text": " Can you name your definition of a functional unit again?",
      "tokens": [
        51300,
        1664,
        291,
        1315,
        428,
        7123,
        295,
        257,
        11745,
        4985,
        797,
        30,
        51428
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4597212076187134,
      "compression_ratio": 1.6423076391220093,
      "no_speech_prob": 0.014927295967936516
    },
    {
      "id": 371,
      "seek": 112012,
      "start": 2429.5900244140626,
      "end": 2431.7899755859376,
      "text": " Is a computer or a service a functional unit?",
      "tokens": [
        51428,
        1119,
        257,
        3820,
        420,
        257,
        2643,
        257,
        11745,
        4985,
        30,
        51538
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4597212076187134,
      "compression_ratio": 1.6423076391220093,
      "no_speech_prob": 0.014927295967936516
    },
    {
      "id": 372,
      "seek": 112012,
      "start": 2431.7899755859376,
      "end": 2433.71001953125,
      "text": " I think we actually cleared that with the order.",
      "tokens": [
        51538,
        286,
        519,
        321,
        767,
        19725,
        300,
        365,
        264,
        1668,
        13,
        51634
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4597212076187134,
      "compression_ratio": 1.6423076391220093,
      "no_speech_prob": 0.014927295967936516
    },
    {
      "id": 373,
      "seek": 112012,
      "start": 2433.71001953125,
      "end": 2435.66998046875,
      "text": " So an order could...",
      "tokens": [
        51634,
        407,
        364,
        1668,
        727,
        485,
        51732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4597212076187134,
      "compression_ratio": 1.6423076391220093,
      "no_speech_prob": 0.014927295967936516
    },
    {
      "id": 374,
      "seek": 114748,
      "start": 2435.66998046875,
      "end": 2438.5900244140626,
      "text": " So you usually try to run it professionally.",
      "tokens": [
        50364,
        407,
        291,
        2673,
        853,
        281,
        1190,
        309,
        27941,
        13,
        50510
      ],
      "temperature": 0.0,
      "avg_logprob": -0.549021303653717,
      "compression_ratio": 1.6163792610168457,
      "no_speech_prob": 0.05873596668243408
    },
    {
      "id": 375,
      "seek": 114748,
      "start": 2438.5900244140626,
      "end": 2440.990048828125,
      "text": " You can of course also say per request or something,",
      "tokens": [
        50510,
        509,
        393,
        295,
        1164,
        611,
        584,
        680,
        5308,
        420,
        746,
        11,
        50630
      ],
      "temperature": 0.0,
      "avg_logprob": -0.549021303653717,
      "compression_ratio": 1.6163792610168457,
      "no_speech_prob": 0.05873596668243408
    },
    {
      "id": 376,
      "seek": 114748,
      "start": 2440.990048828125,
      "end": 2442.990048828125,
      "text": " but on a technical level,",
      "tokens": [
        50630,
        457,
        322,
        257,
        6191,
        1496,
        11,
        50730
      ],
      "temperature": 0.0,
      "avg_logprob": -0.549021303653717,
      "compression_ratio": 1.6163792610168457,
      "no_speech_prob": 0.05873596668243408
    },
    {
      "id": 377,
      "seek": 114748,
      "start": 2442.990048828125,
      "end": 2444.5099462890626,
      "text": " you try to run it professionally.",
      "tokens": [
        50730,
        291,
        853,
        281,
        1190,
        309,
        27941,
        13,
        50806
      ],
      "temperature": 0.0,
      "avg_logprob": -0.549021303653717,
      "compression_ratio": 1.6163792610168457,
      "no_speech_prob": 0.05873596668243408
    },
    {
      "id": 378,
      "seek": 114748,
      "start": 2444.5099462890626,
      "end": 2447.470029296875,
      "text": " So per order, per tax,",
      "tokens": [
        50806,
        407,
        680,
        1668,
        11,
        680,
        3366,
        11,
        50954
      ],
      "temperature": 0.0,
      "avg_logprob": -0.549021303653717,
      "compression_ratio": 1.6163792610168457,
      "no_speech_prob": 0.05873596668243408
    },
    {
      "id": 379,
      "seek": 114748,
      "start": 2447.470029296875,
      "end": 2448.5499853515626,
      "text": " that I somehow have,",
      "tokens": [
        50954,
        300,
        286,
        6063,
        362,
        11,
        51008
      ],
      "temperature": 0.0,
      "avg_logprob": -0.549021303653717,
      "compression_ratio": 1.6163792610168457,
      "no_speech_prob": 0.05873596668243408
    },
    {
      "id": 380,
      "seek": 114748,
      "start": 2448.5499853515626,
      "end": 2449.5499853515626,
      "text": " tax notice that I have,",
      "tokens": [
        51008,
        3366,
        3449,
        300,
        286,
        362,
        11,
        51058
      ],
      "temperature": 0.0,
      "avg_logprob": -0.549021303653717,
      "compression_ratio": 1.6163792610168457,
      "no_speech_prob": 0.05873596668243408
    },
    {
      "id": 381,
      "seek": 114748,
      "start": 2449.5499853515626,
      "end": 2452.5499853515626,
      "text": " or whatever.",
      "tokens": [
        51058,
        420,
        2035,
        13,
        51208
      ],
      "temperature": 0.0,
      "avg_logprob": -0.549021303653717,
      "compression_ratio": 1.6163792610168457,
      "no_speech_prob": 0.05873596668243408
    },
    {
      "id": 382,
      "seek": 114748,
      "start": 2452.5499853515626,
      "end": 2456.75005859375,
      "text": " Then the question from Twilight Depends asked,",
      "tokens": [
        51208,
        1396,
        264,
        1168,
        490,
        38525,
        4056,
        2581,
        2351,
        11,
        51418
      ],
      "temperature": 0.0,
      "avg_logprob": -0.549021303653717,
      "compression_ratio": 1.6163792610168457,
      "no_speech_prob": 0.05873596668243408
    },
    {
      "id": 383,
      "seek": 114748,
      "start": 2456.75005859375,
      "end": 2458.5099462890626,
      "text": " does the blue angel bring me a market advantage",
      "tokens": [
        51418,
        775,
        264,
        3344,
        14250,
        1565,
        385,
        257,
        2142,
        5002,
        51506
      ],
      "temperature": 0.0,
      "avg_logprob": -0.549021303653717,
      "compression_ratio": 1.6163792610168457,
      "no_speech_prob": 0.05873596668243408
    },
    {
      "id": 384,
      "seek": 114748,
      "start": 2458.5099462890626,
      "end": 2462.19,
      "text": " for my software or my network?",
      "tokens": [
        51506,
        337,
        452,
        4722,
        420,
        452,
        3209,
        30,
        51690
      ],
      "temperature": 0.0,
      "avg_logprob": -0.549021303653717,
      "compression_ratio": 1.6163792610168457,
      "no_speech_prob": 0.05873596668243408
    },
    {
      "id": 385,
      "seek": 114748,
      "start": 2462.19,
      "end": 2464.2300390625,
      "text": " Hopefully.",
      "tokens": [
        51690,
        10429,
        13,
        51792
      ],
      "temperature": 0.0,
      "avg_logprob": -0.549021303653717,
      "compression_ratio": 1.6163792610168457,
      "no_speech_prob": 0.05873596668243408
    },
    {
      "id": 386,
      "seek": 117604,
      "start": 2464.2699560546876,
      "end": 2466.470029296875,
      "text": " You just said that it's kind of insanely fresh, right?",
      "tokens": [
        50366,
        509,
        445,
        848,
        300,
        309,
        311,
        733,
        295,
        40965,
        4451,
        11,
        558,
        30,
        50476
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6430470943450928,
      "compression_ratio": 1.4247788190841675,
      "no_speech_prob": 0.6026617884635925
    },
    {
      "id": 387,
      "seek": 117604,
      "start": 2466.470029296875,
      "end": 2471.0299658203126,
      "text": " So for toilet paper, for printers...",
      "tokens": [
        50476,
        407,
        337,
        11137,
        3035,
        11,
        337,
        40007,
        485,
        50704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6430470943450928,
      "compression_ratio": 1.4247788190841675,
      "no_speech_prob": 0.6026617884635925
    },
    {
      "id": 388,
      "seek": 117604,
      "start": 2471.0299658203126,
      "end": 2473.429990234375,
      "text": " So with printers it's quite a lot.",
      "tokens": [
        50704,
        407,
        365,
        40007,
        309,
        311,
        1596,
        257,
        688,
        13,
        50824
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6430470943450928,
      "compression_ratio": 1.4247788190841675,
      "no_speech_prob": 0.6026617884635925
    },
    {
      "id": 389,
      "seek": 117604,
      "start": 2473.429990234375,
      "end": 2474.429990234375,
      "text": " Or paper.",
      "tokens": [
        50824,
        1610,
        3035,
        13,
        50874
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6430470943450928,
      "compression_ratio": 1.4247788190841675,
      "no_speech_prob": 0.6026617884635925
    },
    {
      "id": 390,
      "seek": 117604,
      "start": 2474.429990234375,
      "end": 2475.62994140625,
      "text": " So with printers it's...",
      "tokens": [
        50874,
        407,
        365,
        40007,
        309,
        311,
        485,
        50934
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6430470943450928,
      "compression_ratio": 1.4247788190841675,
      "no_speech_prob": 0.6026617884635925
    },
    {
      "id": 0,
      "seek": 0,
      "start": 2490.61,
      "end": 2493.61,
      "text": " You go there and say, I'll make a blue angel.",
      "tokens": [
        50364,
        509,
        352,
        456,
        293,
        584,
        11,
        286,
        603,
        652,
        257,
        3344,
        14250,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48238635063171387,
      "compression_ratio": 1.6982758045196533,
      "no_speech_prob": 0.8643338680267334
    },
    {
      "id": 1,
      "seek": 0,
      "start": 2493.61,
      "end": 2500.61,
      "text": " I mean, I'm aware of it, I know, I'm part of the problem, but I'm also part of the solution.",
      "tokens": [
        50514,
        286,
        914,
        11,
        286,
        478,
        3650,
        295,
        309,
        11,
        286,
        458,
        11,
        286,
        478,
        644,
        295,
        264,
        1154,
        11,
        457,
        286,
        478,
        611,
        644,
        295,
        264,
        3827,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48238635063171387,
      "compression_ratio": 1.6982758045196533,
      "no_speech_prob": 0.8643338680267334
    },
    {
      "id": 2,
      "seek": 0,
      "start": 2500.61,
      "end": 2506.61,
      "text": " And then he also wrote, there will be something like this, I assume that this blue angel will be audited.",
      "tokens": [
        50864,
        400,
        550,
        415,
        611,
        4114,
        11,
        456,
        486,
        312,
        746,
        411,
        341,
        11,
        286,
        6552,
        300,
        341,
        3344,
        14250,
        486,
        312,
        2379,
        1226,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48238635063171387,
      "compression_ratio": 1.6982758045196533,
      "no_speech_prob": 0.8643338680267334
    },
    {
      "id": 3,
      "seek": 0,
      "start": 2506.61,
      "end": 2512.61,
      "text": " Yes, so that's actually not the case that anyone gives it away,",
      "tokens": [
        51164,
        1079,
        11,
        370,
        300,
        311,
        767,
        406,
        264,
        1389,
        300,
        2878,
        2709,
        309,
        1314,
        11,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48238635063171387,
      "compression_ratio": 1.6982758045196533,
      "no_speech_prob": 0.8643338680267334
    },
    {
      "id": 4,
      "seek": 0,
      "start": 2512.61,
      "end": 2519.61,
      "text": " but there are auditors, they have to be accredited at the Federal Environment Office,",
      "tokens": [
        51464,
        457,
        456,
        366,
        2379,
        9862,
        11,
        436,
        362,
        281,
        312,
        33877,
        1226,
        412,
        264,
        12380,
        35354,
        8935,
        11,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48238635063171387,
      "compression_ratio": 1.6982758045196533,
      "no_speech_prob": 0.8643338680267334
    },
    {
      "id": 5,
      "seek": 2900,
      "start": 2519.61,
      "end": 2526.61,
      "text": " there is also an exam, so not just say what I want, but above all there are criteria.",
      "tokens": [
        50364,
        456,
        307,
        611,
        364,
        1139,
        11,
        370,
        406,
        445,
        584,
        437,
        286,
        528,
        11,
        457,
        3673,
        439,
        456,
        366,
        11101,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5079997181892395,
      "compression_ratio": 1.4923076629638672,
      "no_speech_prob": 0.004253944847732782
    },
    {
      "id": 6,
      "seek": 2900,
      "start": 2526.61,
      "end": 2531.61,
      "text": " So it's just like an authority in Siebel does.",
      "tokens": [
        50714,
        407,
        309,
        311,
        445,
        411,
        364,
        8281,
        294,
        3559,
        5390,
        775,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5079997181892395,
      "compression_ratio": 1.4923076629638672,
      "no_speech_prob": 0.004253944847732782
    },
    {
      "id": 7,
      "seek": 2900,
      "start": 2531.61,
      "end": 2536.61,
      "text": " Exactly, just as we imagine it here in this country.",
      "tokens": [
        50964,
        7587,
        11,
        445,
        382,
        321,
        3811,
        309,
        510,
        294,
        341,
        1941,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5079997181892395,
      "compression_ratio": 1.4923076629638672,
      "no_speech_prob": 0.004253944847732782
    },
    {
      "id": 8,
      "seek": 2900,
      "start": 2536.61,
      "end": 2539.61,
      "text": " Exactly.",
      "tokens": [
        51214,
        7587,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5079997181892395,
      "compression_ratio": 1.4923076629638672,
      "no_speech_prob": 0.004253944847732782
    },
    {
      "id": 9,
      "seek": 2900,
      "start": 2539.61,
      "end": 2542.61,
      "text": " I would really like to get rid of one more topic.",
      "tokens": [
        51364,
        286,
        576,
        534,
        411,
        281,
        483,
        3973,
        295,
        472,
        544,
        4829,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5079997181892395,
      "compression_ratio": 1.4923076629638672,
      "no_speech_prob": 0.004253944847732782
    },
    {
      "id": 10,
      "seek": 2900,
      "start": 2542.61,
      "end": 2546.61,
      "text": " No, I think we've actually worked it up a bit,",
      "tokens": [
        51514,
        883,
        11,
        286,
        519,
        321,
        600,
        767,
        2732,
        309,
        493,
        257,
        857,
        11,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5079997181892395,
      "compression_ratio": 1.4923076629638672,
      "no_speech_prob": 0.004253944847732782
    },
    {
      "id": 11,
      "seek": 5600,
      "start": 2546.61,
      "end": 2549.61,
      "text": " these few things have come up.",
      "tokens": [
        50364,
        613,
        1326,
        721,
        362,
        808,
        493,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4643692374229431,
      "compression_ratio": 1.4390244483947754,
      "no_speech_prob": 0.16798628866672516
    },
    {
      "id": 12,
      "seek": 5600,
      "start": 2549.61,
      "end": 2552.61,
      "text": " But yes, exactly, then I would say, go ahead.",
      "tokens": [
        50514,
        583,
        2086,
        11,
        2293,
        11,
        550,
        286,
        576,
        584,
        11,
        352,
        2286,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4643692374229431,
      "compression_ratio": 1.4390244483947754,
      "no_speech_prob": 0.16798628866672516
    },
    {
      "id": 13,
      "seek": 5600,
      "start": 2552.61,
      "end": 2563.61,
      "text": " So we had this efficiency, these action areas, and I would like to tease two things.",
      "tokens": [
        50664,
        407,
        321,
        632,
        341,
        10493,
        11,
        613,
        3069,
        3179,
        11,
        293,
        286,
        576,
        411,
        281,
        30444,
        732,
        721,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4643692374229431,
      "compression_ratio": 1.4390244483947754,
      "no_speech_prob": 0.16798628866672516
    },
    {
      "id": 14,
      "seek": 5600,
      "start": 2563.61,
      "end": 2569.61,
      "text": " One is, when I'm in the cloud at some point,",
      "tokens": [
        51214,
        1485,
        307,
        11,
        562,
        286,
        478,
        294,
        264,
        4588,
        412,
        512,
        935,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4643692374229431,
      "compression_ratio": 1.4390244483947754,
      "no_speech_prob": 0.16798628866672516
    },
    {
      "id": 15,
      "seek": 5600,
      "start": 2569.61,
      "end": 2573.61,
      "text": " what helps a lot is shutdown.",
      "tokens": [
        51514,
        437,
        3665,
        257,
        688,
        307,
        34927,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4643692374229431,
      "compression_ratio": 1.4390244483947754,
      "no_speech_prob": 0.16798628866672516
    },
    {
      "id": 16,
      "seek": 8300,
      "start": 2573.61,
      "end": 2579.61,
      "text": " So strategy number one, turn off the stuff.",
      "tokens": [
        50364,
        407,
        5206,
        1230,
        472,
        11,
        1261,
        766,
        264,
        1507,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46984946727752686,
      "compression_ratio": 1.4478527307510376,
      "no_speech_prob": 0.01954834535717964
    },
    {
      "id": 17,
      "seek": 8300,
      "start": 2579.61,
      "end": 2583.61,
      "text": " We have, according to experience, a lot of test systems,",
      "tokens": [
        50664,
        492,
        362,
        11,
        4650,
        281,
        1752,
        11,
        257,
        688,
        295,
        1500,
        3652,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46984946727752686,
      "compression_ratio": 1.4478527307510376,
      "no_speech_prob": 0.01954834535717964
    },
    {
      "id": 18,
      "seek": 8300,
      "start": 2583.61,
      "end": 2589.61,
      "text": " CICD systems, customer imaging systems, and these things run.",
      "tokens": [
        50864,
        383,
        2532,
        35,
        3652,
        11,
        5474,
        25036,
        3652,
        11,
        293,
        613,
        721,
        1190,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46984946727752686,
      "compression_ratio": 1.4478527307510376,
      "no_speech_prob": 0.01954834535717964
    },
    {
      "id": 19,
      "seek": 8300,
      "start": 2589.61,
      "end": 2592.61,
      "text": " Run and run, even though you don't need them.",
      "tokens": [
        51164,
        8950,
        293,
        1190,
        11,
        754,
        1673,
        291,
        500,
        380,
        643,
        552,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46984946727752686,
      "compression_ratio": 1.4478527307510376,
      "no_speech_prob": 0.01954834535717964
    },
    {
      "id": 20,
      "seek": 8300,
      "start": 2592.61,
      "end": 2595.61,
      "text": " So you can turn it all off.",
      "tokens": [
        51314,
        407,
        291,
        393,
        1261,
        309,
        439,
        766,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46984946727752686,
      "compression_ratio": 1.4478527307510376,
      "no_speech_prob": 0.01954834535717964
    },
    {
      "id": 21,
      "seek": 10500,
      "start": 2595.61,
      "end": 2601.61,
      "text": " Yes, it's a bit placid.",
      "tokens": [
        50364,
        1079,
        11,
        309,
        311,
        257,
        857,
        499,
        326,
        327,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49672001600265503,
      "compression_ratio": 1.545851469039917,
      "no_speech_prob": 0.08703922480344772
    },
    {
      "id": 22,
      "seek": 10500,
      "start": 2601.61,
      "end": 2604.61,
      "text": " The shutdown is the problem, but it's turning it on.",
      "tokens": [
        50664,
        440,
        34927,
        307,
        264,
        1154,
        11,
        457,
        309,
        311,
        1261,
        278,
        309,
        322,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49672001600265503,
      "compression_ratio": 1.545851469039917,
      "no_speech_prob": 0.08703922480344772
    },
    {
      "id": 23,
      "seek": 10500,
      "start": 2604.61,
      "end": 2606.61,
      "text": " And there's a lot going on.",
      "tokens": [
        50814,
        400,
        456,
        311,
        257,
        688,
        516,
        322,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49672001600265503,
      "compression_ratio": 1.545851469039917,
      "no_speech_prob": 0.08703922480344772
    },
    {
      "id": 24,
      "seek": 10500,
      "start": 2606.61,
      "end": 2610.61,
      "text": " So you could build some kind of system where you drive the things up again.",
      "tokens": [
        50914,
        407,
        291,
        727,
        1322,
        512,
        733,
        295,
        1185,
        689,
        291,
        3332,
        264,
        721,
        493,
        797,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49672001600265503,
      "compression_ratio": 1.545851469039917,
      "no_speech_prob": 0.08703922480344772
    },
    {
      "id": 25,
      "seek": 10500,
      "start": 2610.61,
      "end": 2613.61,
      "text": " You send an email and then it just drives up a thousand things.",
      "tokens": [
        51114,
        509,
        2845,
        364,
        3796,
        293,
        550,
        309,
        445,
        11754,
        493,
        257,
        4714,
        721,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49672001600265503,
      "compression_ratio": 1.545851469039917,
      "no_speech_prob": 0.08703922480344772
    },
    {
      "id": 26,
      "seek": 10500,
      "start": 2613.61,
      "end": 2615.61,
      "text": " So we've tried a lot.",
      "tokens": [
        51264,
        407,
        321,
        600,
        3031,
        257,
        688,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49672001600265503,
      "compression_ratio": 1.545851469039917,
      "no_speech_prob": 0.08703922480344772
    },
    {
      "id": 27,
      "seek": 10500,
      "start": 2615.61,
      "end": 2620.61,
      "text": " What also works very well are such on-demand,",
      "tokens": [
        51364,
        708,
        611,
        1985,
        588,
        731,
        366,
        1270,
        322,
        12,
        10730,
        474,
        11,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49672001600265503,
      "compression_ratio": 1.545851469039917,
      "no_speech_prob": 0.08703922480344772
    },
    {
      "id": 28,
      "seek": 10500,
      "start": 2620.61,
      "end": 2623.61,
      "text": " so if I'm in container apps, for example,",
      "tokens": [
        51614,
        370,
        498,
        286,
        478,
        294,
        10129,
        7733,
        11,
        337,
        1365,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49672001600265503,
      "compression_ratio": 1.545851469039917,
      "no_speech_prob": 0.08703922480344772
    },
    {
      "id": 29,
      "seek": 13300,
      "start": 2623.61,
      "end": 2626.61,
      "text": " then I can just put a request on it and then the system drives itself up",
      "tokens": [
        50364,
        550,
        286,
        393,
        445,
        829,
        257,
        5308,
        322,
        309,
        293,
        550,
        264,
        1185,
        11754,
        2564,
        493,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40476930141448975,
      "compression_ratio": 1.588932752609253,
      "no_speech_prob": 0.01375111285597086
    },
    {
      "id": 30,
      "seek": 13300,
      "start": 2626.61,
      "end": 2628.61,
      "text": " because there's a load balancer on it.",
      "tokens": [
        50514,
        570,
        456,
        311,
        257,
        3677,
        3119,
        28347,
        322,
        309,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40476930141448975,
      "compression_ratio": 1.588932752609253,
      "no_speech_prob": 0.01375111285597086
    },
    {
      "id": 31,
      "seek": 13300,
      "start": 2628.61,
      "end": 2629.61,
      "text": " So there's a lot going on.",
      "tokens": [
        50614,
        407,
        456,
        311,
        257,
        688,
        516,
        322,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40476930141448975,
      "compression_ratio": 1.588932752609253,
      "no_speech_prob": 0.01375111285597086
    },
    {
      "id": 32,
      "seek": 13300,
      "start": 2629.61,
      "end": 2632.61,
      "text": " Turn off stuff.",
      "tokens": [
        50664,
        7956,
        766,
        1507,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40476930141448975,
      "compression_ratio": 1.588932752609253,
      "no_speech_prob": 0.01375111285597086
    },
    {
      "id": 33,
      "seek": 13300,
      "start": 2632.61,
      "end": 2634.61,
      "text": " You can also avoid something.",
      "tokens": [
        50814,
        509,
        393,
        611,
        5042,
        746,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40476930141448975,
      "compression_ratio": 1.588932752609253,
      "no_speech_prob": 0.01375111285597086
    },
    {
      "id": 34,
      "seek": 13300,
      "start": 2634.61,
      "end": 2636.61,
      "text": " So produce some reports that no one reads.",
      "tokens": [
        50914,
        407,
        5258,
        512,
        7122,
        300,
        572,
        472,
        15700,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40476930141448975,
      "compression_ratio": 1.588932752609253,
      "no_speech_prob": 0.01375111285597086
    },
    {
      "id": 35,
      "seek": 13300,
      "start": 2636.61,
      "end": 2638.61,
      "text": " I don't need that anyway.",
      "tokens": [
        51014,
        286,
        500,
        380,
        643,
        300,
        4033,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40476930141448975,
      "compression_ratio": 1.588932752609253,
      "no_speech_prob": 0.01375111285597086
    },
    {
      "id": 36,
      "seek": 13300,
      "start": 2638.61,
      "end": 2641.61,
      "text": " And on some things you can also do without.",
      "tokens": [
        51114,
        400,
        322,
        512,
        721,
        291,
        393,
        611,
        360,
        1553,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40476930141448975,
      "compression_ratio": 1.588932752609253,
      "no_speech_prob": 0.01375111285597086
    },
    {
      "id": 37,
      "seek": 13300,
      "start": 2641.61,
      "end": 2648.61,
      "text": " Does every weather app have a high availability of 9.9999%?",
      "tokens": [
        51264,
        4402,
        633,
        5503,
        724,
        362,
        257,
        1090,
        17945,
        295,
        1722,
        13,
        8494,
        8494,
        4,
        30,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40476930141448975,
      "compression_ratio": 1.588932752609253,
      "no_speech_prob": 0.01375111285597086
    },
    {
      "id": 38,
      "seek": 13300,
      "start": 2648.61,
      "end": 2651.61,
      "text": " Do I have to look at the weather everywhere?",
      "tokens": [
        51614,
        1144,
        286,
        362,
        281,
        574,
        412,
        264,
        5503,
        633,
        86,
        6703,
        30,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40476930141448975,
      "compression_ratio": 1.588932752609253,
      "no_speech_prob": 0.01375111285597086
    },
    {
      "id": 39,
      "seek": 16100,
      "start": 2651.61,
      "end": 2653.61,
      "text": " You can avoid things.",
      "tokens": [
        50364,
        509,
        393,
        5042,
        721,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42291921377182007,
      "compression_ratio": 1.5858585834503174,
      "no_speech_prob": 0.09593557566404343
    },
    {
      "id": 40,
      "seek": 16100,
      "start": 2653.61,
      "end": 2654.61,
      "text": " You can do without it.",
      "tokens": [
        50464,
        509,
        393,
        360,
        1553,
        309,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42291921377182007,
      "compression_ratio": 1.5858585834503174,
      "no_speech_prob": 0.09593557566404343
    },
    {
      "id": 41,
      "seek": 16100,
      "start": 2654.61,
      "end": 2656.61,
      "text": " You can question things.",
      "tokens": [
        50514,
        509,
        393,
        1168,
        721,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42291921377182007,
      "compression_ratio": 1.5858585834503174,
      "no_speech_prob": 0.09593557566404343
    },
    {
      "id": 42,
      "seek": 16100,
      "start": 2656.61,
      "end": 2657.61,
      "text": " You can turn it on and off.",
      "tokens": [
        50614,
        509,
        393,
        1261,
        309,
        322,
        293,
        766,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42291921377182007,
      "compression_ratio": 1.5858585834503174,
      "no_speech_prob": 0.09593557566404343
    },
    {
      "id": 43,
      "seek": 16100,
      "start": 2657.61,
      "end": 2659.61,
      "text": " There are massive low-hanging fruits.",
      "tokens": [
        50664,
        821,
        366,
        5994,
        2295,
        12,
        71,
        9741,
        12148,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42291921377182007,
      "compression_ratio": 1.5858585834503174,
      "no_speech_prob": 0.09593557566404343
    },
    {
      "id": 44,
      "seek": 16100,
      "start": 2659.61,
      "end": 2662.61,
      "text": " You can't even imagine that.",
      "tokens": [
        50764,
        509,
        393,
        380,
        754,
        3811,
        300,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42291921377182007,
      "compression_ratio": 1.5858585834503174,
      "no_speech_prob": 0.09593557566404343
    },
    {
      "id": 45,
      "seek": 16100,
      "start": 2662.61,
      "end": 2664.61,
      "text": " We don't even have to start coding yet.",
      "tokens": [
        50914,
        492,
        500,
        380,
        754,
        362,
        281,
        722,
        17720,
        1939,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42291921377182007,
      "compression_ratio": 1.5858585834503174,
      "no_speech_prob": 0.09593557566404343
    },
    {
      "id": 46,
      "seek": 16100,
      "start": 2664.61,
      "end": 2672.61,
      "text": " But if we do, of course, everything plays into this maximum server utilization.",
      "tokens": [
        51014,
        583,
        498,
        321,
        360,
        11,
        295,
        1164,
        11,
        1203,
        5749,
        666,
        341,
        6674,
        7154,
        37074,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42291921377182007,
      "compression_ratio": 1.5858585834503174,
      "no_speech_prob": 0.09593557566404343
    },
    {
      "id": 47,
      "seek": 16100,
      "start": 2672.61,
      "end": 2675.61,
      "text": " So container, path and so on.",
      "tokens": [
        51414,
        407,
        10129,
        11,
        3100,
        293,
        370,
        322,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42291921377182007,
      "compression_ratio": 1.5858585834503174,
      "no_speech_prob": 0.09593557566404343
    },
    {
      "id": 48,
      "seek": 18500,
      "start": 2676.61,
      "end": 2683.61,
      "text": " And this...",
      "tokens": [
        50414,
        400,
        341,
        485,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5900297164916992,
      "compression_ratio": 1.232758641242981,
      "no_speech_prob": 0.11061577498912811
    },
    {
      "id": 49,
      "seek": 18500,
      "start": 2683.61,
      "end": 2686.61,
      "text": " Sorry.",
      "tokens": [
        50764,
        4919,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5900297164916992,
      "compression_ratio": 1.232758641242981,
      "no_speech_prob": 0.11061577498912811
    },
    {
      "id": 50,
      "seek": 18500,
      "start": 2686.61,
      "end": 2689.61,
      "text": " What...",
      "tokens": [
        50914,
        708,
        485,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5900297164916992,
      "compression_ratio": 1.232758641242981,
      "no_speech_prob": 0.11061577498912811
    },
    {
      "id": 51,
      "seek": 18500,
      "start": 2689.61,
      "end": 2694.61,
      "text": " Where there's a lot going on and it's dynamic scaling.",
      "tokens": [
        51064,
        2305,
        456,
        311,
        257,
        688,
        516,
        322,
        293,
        309,
        311,
        8546,
        21589,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5900297164916992,
      "compression_ratio": 1.232758641242981,
      "no_speech_prob": 0.11061577498912811
    },
    {
      "id": 52,
      "seek": 18500,
      "start": 2694.61,
      "end": 2697.61,
      "text": " So here, architecture stream.",
      "tokens": [
        51314,
        407,
        510,
        11,
        9482,
        4309,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5900297164916992,
      "compression_ratio": 1.232758641242981,
      "no_speech_prob": 0.11061577498912811
    },
    {
      "id": 53,
      "seek": 18500,
      "start": 2697.61,
      "end": 2700.61,
      "text": " So everyone knows how it works.",
      "tokens": [
        51464,
        407,
        1518,
        3255,
        577,
        309,
        1985,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5900297164916992,
      "compression_ratio": 1.232758641242981,
      "no_speech_prob": 0.11061577498912811
    },
    {
      "id": 54,
      "seek": 21000,
      "start": 2700.61,
      "end": 2708.61,
      "text": " Typically, our software systems have a time-dependent load.",
      "tokens": [
        50364,
        23129,
        11,
        527,
        4722,
        3652,
        362,
        257,
        565,
        12,
        36763,
        317,
        3677,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36536428332328796,
      "compression_ratio": 1.6588234901428223,
      "no_speech_prob": 0.24298226833343506
    },
    {
      "id": 55,
      "seek": 21000,
      "start": 2708.61,
      "end": 2711.61,
      "text": " And I have a graphic here.",
      "tokens": [
        50764,
        400,
        286,
        362,
        257,
        14089,
        510,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36536428332328796,
      "compression_ratio": 1.6588234901428223,
      "no_speech_prob": 0.24298226833343506
    },
    {
      "id": 56,
      "seek": 21000,
      "start": 2711.61,
      "end": 2713.61,
      "text": " So the load depends on the time.",
      "tokens": [
        50914,
        407,
        264,
        3677,
        5946,
        322,
        264,
        565,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36536428332328796,
      "compression_ratio": 1.6588234901428223,
      "no_speech_prob": 0.24298226833343506
    },
    {
      "id": 57,
      "seek": 21000,
      "start": 2713.61,
      "end": 2716.61,
      "text": " It goes up and down.",
      "tokens": [
        51014,
        467,
        1709,
        493,
        293,
        760,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36536428332328796,
      "compression_ratio": 1.6588234901428223,
      "no_speech_prob": 0.24298226833343506
    },
    {
      "id": 58,
      "seek": 21000,
      "start": 2716.61,
      "end": 2720.61,
      "text": " And then I need several computer units to represent this load.",
      "tokens": [
        51164,
        400,
        550,
        286,
        643,
        2940,
        3820,
        6815,
        281,
        2906,
        341,
        3677,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36536428332328796,
      "compression_ratio": 1.6588234901428223,
      "no_speech_prob": 0.24298226833343506
    },
    {
      "id": 59,
      "seek": 21000,
      "start": 2720.61,
      "end": 2725.61,
      "text": " So maybe three computer units at the top.",
      "tokens": [
        51364,
        407,
        1310,
        1045,
        3820,
        6815,
        412,
        264,
        1192,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36536428332328796,
      "compression_ratio": 1.6588234901428223,
      "no_speech_prob": 0.24298226833343506
    },
    {
      "id": 60,
      "seek": 21000,
      "start": 2725.61,
      "end": 2728.61,
      "text": " And one computer unit at the bottom.",
      "tokens": [
        51614,
        400,
        472,
        3820,
        4985,
        412,
        264,
        2767,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36536428332328796,
      "compression_ratio": 1.6588234901428223,
      "no_speech_prob": 0.24298226833343506
    },
    {
      "id": 61,
      "seek": 23800,
      "start": 2728.61,
      "end": 2735.61,
      "text": " And the industrial standard is essentially that we provide maximum load.",
      "tokens": [
        50364,
        400,
        264,
        9987,
        3832,
        307,
        4476,
        300,
        321,
        2893,
        6674,
        3677,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36963963508605957,
      "compression_ratio": 1.6774193048477173,
      "no_speech_prob": 0.007976834662258625
    },
    {
      "id": 62,
      "seek": 23800,
      "start": 2735.61,
      "end": 2738.61,
      "text": " And then there are always three servers running all the time.",
      "tokens": [
        50714,
        400,
        550,
        456,
        366,
        1009,
        1045,
        15909,
        2614,
        439,
        264,
        565,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36963963508605957,
      "compression_ratio": 1.6774193048477173,
      "no_speech_prob": 0.007976834662258625
    },
    {
      "id": 63,
      "seek": 23800,
      "start": 2738.61,
      "end": 2740.61,
      "text": " But I could scale dynamically.",
      "tokens": [
        50864,
        583,
        286,
        727,
        4373,
        43492,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36963963508605957,
      "compression_ratio": 1.6774193048477173,
      "no_speech_prob": 0.007976834662258625
    },
    {
      "id": 64,
      "seek": 23800,
      "start": 2740.61,
      "end": 2745.61,
      "text": " That is, when my load increases, I add computer units and then switch them off again.",
      "tokens": [
        50964,
        663,
        307,
        11,
        562,
        452,
        3677,
        8637,
        11,
        286,
        909,
        3820,
        6815,
        293,
        550,
        3679,
        552,
        766,
        797,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36963963508605957,
      "compression_ratio": 1.6774193048477173,
      "no_speech_prob": 0.007976834662258625
    },
    {
      "id": 65,
      "seek": 23800,
      "start": 2745.61,
      "end": 2748.61,
      "text": " And actually turn off the computer when possible.",
      "tokens": [
        51214,
        400,
        767,
        1261,
        766,
        264,
        3820,
        562,
        1944,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36963963508605957,
      "compression_ratio": 1.6774193048477173,
      "no_speech_prob": 0.007976834662258625
    },
    {
      "id": 66,
      "seek": 23800,
      "start": 2748.61,
      "end": 2752.61,
      "text": " In on-prem or in the cloud, I can release the resource.",
      "tokens": [
        51364,
        682,
        322,
        12,
        29403,
        420,
        294,
        264,
        4588,
        11,
        286,
        393,
        4374,
        264,
        7684,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36963963508605957,
      "compression_ratio": 1.6774193048477173,
      "no_speech_prob": 0.007976834662258625
    },
    {
      "id": 67,
      "seek": 23800,
      "start": 2752.61,
      "end": 2755.61,
      "text": " And then the emission is actually gone from this hardware.",
      "tokens": [
        51564,
        400,
        550,
        264,
        29513,
        307,
        767,
        2780,
        490,
        341,
        8837,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36963963508605957,
      "compression_ratio": 1.6774193048477173,
      "no_speech_prob": 0.007976834662258625
    },
    {
      "id": 68,
      "seek": 26500,
      "start": 2755.61,
      "end": 2758.61,
      "text": " Both energy and bound emissions.",
      "tokens": [
        50364,
        6767,
        2281,
        293,
        5472,
        14607,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34409722685813904,
      "compression_ratio": 1.484375,
      "no_speech_prob": 0.18961869180202484
    },
    {
      "id": 69,
      "seek": 26500,
      "start": 2758.61,
      "end": 2769.61,
      "text": " And if you think about the savings, then there are easily 30, 40, 50 percent CO2 emissions.",
      "tokens": [
        50514,
        400,
        498,
        291,
        519,
        466,
        264,
        13454,
        11,
        550,
        456,
        366,
        3612,
        2217,
        11,
        3356,
        11,
        2625,
        3043,
        3002,
        17,
        14607,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34409722685813904,
      "compression_ratio": 1.484375,
      "no_speech_prob": 0.18961869180202484
    },
    {
      "id": 70,
      "seek": 26500,
      "start": 2769.61,
      "end": 2774.61,
      "text": " Just because you turned on a horizontal scaler in Kubernetes.",
      "tokens": [
        51064,
        1449,
        570,
        291,
        3574,
        322,
        257,
        12750,
        15664,
        260,
        294,
        23145,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34409722685813904,
      "compression_ratio": 1.484375,
      "no_speech_prob": 0.18961869180202484
    },
    {
      "id": 71,
      "seek": 26500,
      "start": 2774.61,
      "end": 2778.61,
      "text": " Just because you release the load at the end.",
      "tokens": [
        51314,
        1449,
        570,
        291,
        4374,
        264,
        3677,
        412,
        264,
        917,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34409722685813904,
      "compression_ratio": 1.484375,
      "no_speech_prob": 0.18961869180202484
    },
    {
      "id": 72,
      "seek": 26500,
      "start": 2778.61,
      "end": 2783.61,
      "text": " This is a no-brainer from a technical point of view.",
      "tokens": [
        51514,
        639,
        307,
        257,
        572,
        12,
        6198,
        4564,
        490,
        257,
        6191,
        935,
        295,
        1910,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34409722685813904,
      "compression_ratio": 1.484375,
      "no_speech_prob": 0.18961869180202484
    },
    {
      "id": 73,
      "seek": 29300,
      "start": 2783.61,
      "end": 2786.61,
      "text": " Go read a book, if you don't know it.",
      "tokens": [
        50364,
        1037,
        1401,
        257,
        1446,
        11,
        498,
        291,
        500,
        380,
        458,
        309,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4558198153972626,
      "compression_ratio": 1.585365891456604,
      "no_speech_prob": 0.09202632308006287
    },
    {
      "id": 74,
      "seek": 29300,
      "start": 2786.61,
      "end": 2789.61,
      "text": " And that really hits the spot.",
      "tokens": [
        50514,
        400,
        300,
        534,
        8664,
        264,
        4008,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4558198153972626,
      "compression_ratio": 1.585365891456604,
      "no_speech_prob": 0.09202632308006287
    },
    {
      "id": 75,
      "seek": 29300,
      "start": 2789.61,
      "end": 2792.61,
      "text": " I would really like to share that with you.",
      "tokens": [
        50664,
        286,
        576,
        534,
        411,
        281,
        2073,
        300,
        365,
        291,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4558198153972626,
      "compression_ratio": 1.585365891456604,
      "no_speech_prob": 0.09202632308006287
    },
    {
      "id": 76,
      "seek": 29300,
      "start": 2792.61,
      "end": 2794.61,
      "text": " Because I see a lot of systems.",
      "tokens": [
        50814,
        1436,
        286,
        536,
        257,
        688,
        295,
        3652,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4558198153972626,
      "compression_ratio": 1.585365891456604,
      "no_speech_prob": 0.09202632308006287
    },
    {
      "id": 77,
      "seek": 29300,
      "start": 2794.61,
      "end": 2797.61,
      "text": " It is really an industrial standard to provide maximum load.",
      "tokens": [
        50914,
        467,
        307,
        534,
        364,
        9987,
        3832,
        281,
        2893,
        6674,
        3677,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4558198153972626,
      "compression_ratio": 1.585365891456604,
      "no_speech_prob": 0.09202632308006287
    },
    {
      "id": 78,
      "seek": 29300,
      "start": 2797.61,
      "end": 2802.61,
      "text": " Because of reasons, so to speak.",
      "tokens": [
        51064,
        1436,
        295,
        4112,
        11,
        370,
        281,
        1710,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4558198153972626,
      "compression_ratio": 1.585365891456604,
      "no_speech_prob": 0.09202632308006287
    },
    {
      "id": 79,
      "seek": 29300,
      "start": 2802.61,
      "end": 2804.61,
      "text": " There are always reasons.",
      "tokens": [
        51314,
        821,
        366,
        1009,
        4112,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4558198153972626,
      "compression_ratio": 1.585365891456604,
      "no_speech_prob": 0.09202632308006287
    },
    {
      "id": 80,
      "seek": 29300,
      "start": 2804.61,
      "end": 2810.61,
      "text": " And our job as a techie is actually to change these reasons.",
      "tokens": [
        51414,
        400,
        527,
        1691,
        382,
        257,
        7553,
        414,
        307,
        767,
        281,
        1319,
        613,
        4112,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4558198153972626,
      "compression_ratio": 1.585365891456604,
      "no_speech_prob": 0.09202632308006287
    },
    {
      "id": 81,
      "seek": 32000,
      "start": 2811.61,
      "end": 2814.61,
      "text": " Of course, a system is as it is.",
      "tokens": [
        50414,
        2720,
        1164,
        11,
        257,
        1185,
        307,
        382,
        309,
        307,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3522586226463318,
      "compression_ratio": 1.4814814329147339,
      "no_speech_prob": 0.017939100041985512
    },
    {
      "id": 82,
      "seek": 32000,
      "start": 2814.61,
      "end": 2817.61,
      "text": " The system also has a quality problem, because it is so.",
      "tokens": [
        50564,
        440,
        1185,
        611,
        575,
        257,
        3125,
        1154,
        11,
        570,
        309,
        307,
        370,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3522586226463318,
      "compression_ratio": 1.4814814329147339,
      "no_speech_prob": 0.017939100041985512
    },
    {
      "id": 83,
      "seek": 32000,
      "start": 2817.61,
      "end": 2819.61,
      "text": " It doesn't fall from the sky either.",
      "tokens": [
        50714,
        467,
        1177,
        380,
        2100,
        490,
        264,
        5443,
        2139,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3522586226463318,
      "compression_ratio": 1.4814814329147339,
      "no_speech_prob": 0.017939100041985512
    },
    {
      "id": 84,
      "seek": 32000,
      "start": 2819.61,
      "end": 2823.61,
      "text": " And the other thing is the CO2 intensity.",
      "tokens": [
        50814,
        400,
        264,
        661,
        551,
        307,
        264,
        3002,
        17,
        13749,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3522586226463318,
      "compression_ratio": 1.4814814329147339,
      "no_speech_prob": 0.017939100041985512
    },
    {
      "id": 85,
      "seek": 32000,
      "start": 2823.61,
      "end": 2827.61,
      "text": " This is something that we don't have in mind.",
      "tokens": [
        51014,
        639,
        307,
        746,
        300,
        321,
        500,
        380,
        362,
        294,
        1575,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3522586226463318,
      "compression_ratio": 1.4814814329147339,
      "no_speech_prob": 0.017939100041985512
    },
    {
      "id": 86,
      "seek": 32000,
      "start": 2827.61,
      "end": 2836.61,
      "text": " This is the connection between energy, i.e. electricity, and CO2.",
      "tokens": [
        51214,
        639,
        307,
        264,
        4984,
        1296,
        2281,
        11,
        741,
        13,
        68,
        13,
        10356,
        11,
        293,
        3002,
        17,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3522586226463318,
      "compression_ratio": 1.4814814329147339,
      "no_speech_prob": 0.017939100041985512
    },
    {
      "id": 87,
      "seek": 34600,
      "start": 2836.61,
      "end": 2842.61,
      "text": " The CO2 intensity, i.e. the CO2 generation from electricity,",
      "tokens": [
        50364,
        440,
        3002,
        17,
        13749,
        11,
        741,
        13,
        68,
        13,
        264,
        3002,
        17,
        5125,
        490,
        10356,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30868276953697205,
      "compression_ratio": 1.4352331161499023,
      "no_speech_prob": 0.005961332004517317
    },
    {
      "id": 88,
      "seek": 34600,
      "start": 2842.61,
      "end": 2847.61,
      "text": " depends on how much renewable energy I have at the moment.",
      "tokens": [
        50664,
        5946,
        322,
        577,
        709,
        20938,
        2281,
        286,
        362,
        412,
        264,
        1623,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30868276953697205,
      "compression_ratio": 1.4352331161499023,
      "no_speech_prob": 0.005961332004517317
    },
    {
      "id": 89,
      "seek": 34600,
      "start": 2847.61,
      "end": 2850.61,
      "text": " Germany now has an average of about 60 percent.",
      "tokens": [
        50914,
        7244,
        586,
        575,
        364,
        4274,
        295,
        466,
        4060,
        3043,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30868276953697205,
      "compression_ratio": 1.4352331161499023,
      "no_speech_prob": 0.005961332004517317
    },
    {
      "id": 90,
      "seek": 34600,
      "start": 2850.61,
      "end": 2852.61,
      "text": " But that changes over time.",
      "tokens": [
        51064,
        583,
        300,
        2962,
        670,
        565,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30868276953697205,
      "compression_ratio": 1.4352331161499023,
      "no_speech_prob": 0.005961332004517317
    },
    {
      "id": 91,
      "seek": 34600,
      "start": 2852.61,
      "end": 2855.61,
      "text": " I have a website here called Electricity Maps.",
      "tokens": [
        51164,
        286,
        362,
        257,
        3144,
        510,
        1219,
        24677,
        507,
        28978,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30868276953697205,
      "compression_ratio": 1.4352331161499023,
      "no_speech_prob": 0.005961332004517317
    },
    {
      "id": 92,
      "seek": 34600,
      "start": 2855.61,
      "end": 2858.61,
      "text": " For all those who can only listen.",
      "tokens": [
        51314,
        1171,
        439,
        729,
        567,
        393,
        787,
        2140,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30868276953697205,
      "compression_ratio": 1.4352331161499023,
      "no_speech_prob": 0.005961332004517317
    },
    {
      "id": 93,
      "seek": 36800,
      "start": 2858.61,
      "end": 2864.61,
      "text": " There you can see at the moment how high the CO2 intensity is in the individual networks.",
      "tokens": [
        50364,
        821,
        291,
        393,
        536,
        412,
        264,
        1623,
        577,
        1090,
        264,
        3002,
        17,
        13749,
        307,
        294,
        264,
        2609,
        9590,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3185425400733948,
      "compression_ratio": 1.5545023679733276,
      "no_speech_prob": 0.329387366771698
    },
    {
      "id": 94,
      "seek": 36800,
      "start": 2864.61,
      "end": 2866.61,
      "text": " Germany, Luxembourg, for example.",
      "tokens": [
        50664,
        7244,
        11,
        25767,
        443,
        43638,
        11,
        337,
        1365,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3185425400733948,
      "compression_ratio": 1.5545023679733276,
      "no_speech_prob": 0.329387366771698
    },
    {
      "id": 95,
      "seek": 36800,
      "start": 2866.61,
      "end": 2869.61,
      "text": " Or Norway, France.",
      "tokens": [
        50764,
        1610,
        24354,
        11,
        6190,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3185425400733948,
      "compression_ratio": 1.5545023679733276,
      "no_speech_prob": 0.329387366771698
    },
    {
      "id": 96,
      "seek": 36800,
      "start": 2869.61,
      "end": 2871.61,
      "text": " How high the CO2 intensity is there.",
      "tokens": [
        50914,
        1012,
        1090,
        264,
        3002,
        17,
        13749,
        307,
        456,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3185425400733948,
      "compression_ratio": 1.5545023679733276,
      "no_speech_prob": 0.329387366771698
    },
    {
      "id": 97,
      "seek": 36800,
      "start": 2871.61,
      "end": 2873.61,
      "text": " We are now at 10 o'clock.",
      "tokens": [
        51014,
        492,
        366,
        586,
        412,
        1266,
        277,
        6,
        9023,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3185425400733948,
      "compression_ratio": 1.5545023679733276,
      "no_speech_prob": 0.329387366771698
    },
    {
      "id": 98,
      "seek": 36800,
      "start": 2873.61,
      "end": 2875.61,
      "text": " We are a bit delayed.",
      "tokens": [
        51114,
        492,
        366,
        257,
        857,
        20268,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3185425400733948,
      "compression_ratio": 1.5545023679733276,
      "no_speech_prob": 0.329387366771698
    },
    {
      "id": 99,
      "seek": 36800,
      "start": 2875.61,
      "end": 2879.61,
      "text": " In Germany, 436 grams of CO2 per kilowatt hour.",
      "tokens": [
        51214,
        682,
        7244,
        11,
        1017,
        11309,
        11899,
        295,
        3002,
        17,
        680,
        41295,
        1591,
        1773,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3185425400733948,
      "compression_ratio": 1.5545023679733276,
      "no_speech_prob": 0.329387366771698
    },
    {
      "id": 100,
      "seek": 36800,
      "start": 2879.61,
      "end": 2885.61,
      "text": " In Norway, we have 30 grams of CO2 at the same time.",
      "tokens": [
        51414,
        682,
        24354,
        11,
        321,
        362,
        2217,
        11899,
        295,
        3002,
        17,
        412,
        264,
        912,
        565,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3185425400733948,
      "compression_ratio": 1.5545023679733276,
      "no_speech_prob": 0.329387366771698
    },
    {
      "id": 101,
      "seek": 39500,
      "start": 2886.61,
      "end": 2889.61,
      "text": " Because Norway has a lot of hydropower.",
      "tokens": [
        50414,
        1436,
        24354,
        575,
        257,
        688,
        295,
        5796,
        81,
        404,
        968,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37779590487480164,
      "compression_ratio": 1.529953956604004,
      "no_speech_prob": 0.04530353471636772
    },
    {
      "id": 102,
      "seek": 39500,
      "start": 2889.61,
      "end": 2891.61,
      "text": " Poland has a lot of coal.",
      "tokens": [
        50564,
        15950,
        575,
        257,
        688,
        295,
        10209,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37779590487480164,
      "compression_ratio": 1.529953956604004,
      "no_speech_prob": 0.04530353471636772
    },
    {
      "id": 103,
      "seek": 39500,
      "start": 2891.61,
      "end": 2894.61,
      "text": " There it is now 558 grams.",
      "tokens": [
        50664,
        821,
        309,
        307,
        586,
        12330,
        23,
        11899,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37779590487480164,
      "compression_ratio": 1.529953956604004,
      "no_speech_prob": 0.04530353471636772
    },
    {
      "id": 104,
      "seek": 39500,
      "start": 2894.61,
      "end": 2897.61,
      "text": " In France, you can now weigh it as you like.",
      "tokens": [
        50814,
        682,
        6190,
        11,
        291,
        393,
        586,
        13843,
        309,
        382,
        291,
        411,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37779590487480164,
      "compression_ratio": 1.529953956604004,
      "no_speech_prob": 0.04530353471636772
    },
    {
      "id": 105,
      "seek": 39500,
      "start": 2897.61,
      "end": 2899.61,
      "text": " Also 40 grams.",
      "tokens": [
        50964,
        2743,
        3356,
        11899,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37779590487480164,
      "compression_ratio": 1.529953956604004,
      "no_speech_prob": 0.04530353471636772
    },
    {
      "id": 106,
      "seek": 39500,
      "start": 2899.61,
      "end": 2902.61,
      "text": " But they have a lot of atoms.",
      "tokens": [
        51064,
        583,
        436,
        362,
        257,
        688,
        295,
        16871,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37779590487480164,
      "compression_ratio": 1.529953956604004,
      "no_speech_prob": 0.04530353471636772
    },
    {
      "id": 107,
      "seek": 39500,
      "start": 2902.61,
      "end": 2904.61,
      "text": " They have 30 percent regenerative.",
      "tokens": [
        51214,
        814,
        362,
        2217,
        3043,
        26358,
        1166,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37779590487480164,
      "compression_ratio": 1.529953956604004,
      "no_speech_prob": 0.04530353471636772
    },
    {
      "id": 108,
      "seek": 39500,
      "start": 2904.61,
      "end": 2907.61,
      "text": " The rest is basically atoms.",
      "tokens": [
        51314,
        440,
        1472,
        307,
        1936,
        16871,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37779590487480164,
      "compression_ratio": 1.529953956604004,
      "no_speech_prob": 0.04530353471636772
    },
    {
      "id": 109,
      "seek": 39500,
      "start": 2907.61,
      "end": 2911.61,
      "text": " When I have static things, I can think about it.",
      "tokens": [
        51464,
        1133,
        286,
        362,
        13437,
        721,
        11,
        286,
        393,
        519,
        466,
        309,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37779590487480164,
      "compression_ratio": 1.529953956604004,
      "no_speech_prob": 0.04530353471636772
    },
    {
      "id": 110,
      "seek": 39500,
      "start": 2911.61,
      "end": 2913.61,
      "text": " Okay, so number crunch or something.",
      "tokens": [
        51664,
        1033,
        11,
        370,
        1230,
        13386,
        420,
        746,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37779590487480164,
      "compression_ratio": 1.529953956604004,
      "no_speech_prob": 0.04530353471636772
    },
    {
      "id": 111,
      "seek": 42300,
      "start": 2913.61,
      "end": 2916.61,
      "text": " I do it in a region that always has green electricity.",
      "tokens": [
        50364,
        286,
        360,
        309,
        294,
        257,
        4458,
        300,
        1009,
        575,
        3092,
        10356,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4424999952316284,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.27286550402641296
    },
    {
      "id": 112,
      "seek": 42300,
      "start": 2916.61,
      "end": 2926.61,
      "text": " Or because the electricity, over time, the share of renewable energies fluctuates.",
      "tokens": [
        50514,
        1610,
        570,
        264,
        10356,
        11,
        670,
        565,
        11,
        264,
        2073,
        295,
        20938,
        25737,
        23448,
        27710,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4424999952316284,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.27286550402641296
    },
    {
      "id": 113,
      "seek": 42300,
      "start": 2926.61,
      "end": 2931.61,
      "text": " Now I have a website from the Fraunhofer Institute.",
      "tokens": [
        51014,
        823,
        286,
        362,
        257,
        3144,
        490,
        264,
        5849,
        409,
        1289,
        612,
        9446,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4424999952316284,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.27286550402641296
    },
    {
      "id": 114,
      "seek": 42300,
      "start": 2931.61,
      "end": 2934.61,
      "text": " This is the power station.",
      "tokens": [
        51264,
        639,
        307,
        264,
        1347,
        5214,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4424999952316284,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.27286550402641296
    },
    {
      "id": 115,
      "seek": 42300,
      "start": 2934.61,
      "end": 2942.61,
      "text": " There you can see that the share of renewables fluctuates over the day.",
      "tokens": [
        51414,
        821,
        291,
        393,
        536,
        300,
        264,
        2073,
        295,
        10162,
        2965,
        23448,
        27710,
        670,
        264,
        786,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4424999952316284,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.27286550402641296
    },
    {
      "id": 116,
      "seek": 45200,
      "start": 2943.61,
      "end": 2948.61,
      "text": " Typically, we have a good afternoon.",
      "tokens": [
        50414,
        23129,
        11,
        321,
        362,
        257,
        665,
        6499,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3897939622402191,
      "compression_ratio": 1.4458599090576172,
      "no_speech_prob": 0.00572283985093236
    },
    {
      "id": 117,
      "seek": 45200,
      "start": 2948.61,
      "end": 2950.61,
      "text": " There is no wind today.",
      "tokens": [
        50664,
        821,
        307,
        572,
        2468,
        965,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3897939622402191,
      "compression_ratio": 1.4458599090576172,
      "no_speech_prob": 0.00572283985093236
    },
    {
      "id": 118,
      "seek": 45200,
      "start": 2950.61,
      "end": 2956.61,
      "text": " That's why it's bad this afternoon at 5 p.m.",
      "tokens": [
        50764,
        663,
        311,
        983,
        309,
        311,
        1578,
        341,
        6499,
        412,
        1025,
        280,
        13,
        76,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3897939622402191,
      "compression_ratio": 1.4458599090576172,
      "no_speech_prob": 0.00572283985093236
    },
    {
      "id": 119,
      "seek": 45200,
      "start": 2956.61,
      "end": 2958.61,
      "text": " And then it gets better again.",
      "tokens": [
        51064,
        400,
        550,
        309,
        2170,
        1101,
        797,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3897939622402191,
      "compression_ratio": 1.4458599090576172,
      "no_speech_prob": 0.00572283985093236
    },
    {
      "id": 120,
      "seek": 45200,
      "start": 2958.61,
      "end": 2960.61,
      "text": " There are predictions.",
      "tokens": [
        51164,
        821,
        366,
        21264,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3897939622402191,
      "compression_ratio": 1.4458599090576172,
      "no_speech_prob": 0.00572283985093236
    },
    {
      "id": 121,
      "seek": 45200,
      "start": 2960.61,
      "end": 2966.61,
      "text": " The idea is that, similar to electric car charging or other things,",
      "tokens": [
        51264,
        440,
        1558,
        307,
        300,
        11,
        2531,
        281,
        5210,
        1032,
        11379,
        420,
        661,
        721,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3897939622402191,
      "compression_ratio": 1.4458599090576172,
      "no_speech_prob": 0.00572283985093236
    },
    {
      "id": 122,
      "seek": 47600,
      "start": 2966.61,
      "end": 2972.61,
      "text": " it always consumes electricity when it is generated by renewable energies.",
      "tokens": [
        50364,
        309,
        1009,
        48823,
        10356,
        562,
        309,
        307,
        10833,
        538,
        20938,
        25737,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4249040186405182,
      "compression_ratio": 1.502732276916504,
      "no_speech_prob": 0.030149420723319054
    },
    {
      "id": 123,
      "seek": 47600,
      "start": 2972.61,
      "end": 2984.61,
      "text": " So I push the load of my software to times where I have little CO2 in the electricity.",
      "tokens": [
        50664,
        407,
        286,
        2944,
        264,
        3677,
        295,
        452,
        4722,
        281,
        1413,
        689,
        286,
        362,
        707,
        3002,
        17,
        294,
        264,
        10356,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4249040186405182,
      "compression_ratio": 1.502732276916504,
      "no_speech_prob": 0.030149420723319054
    },
    {
      "id": 124,
      "seek": 47600,
      "start": 2984.61,
      "end": 2986.61,
      "text": " There are a lot of tools for this.",
      "tokens": [
        51264,
        821,
        366,
        257,
        688,
        295,
        3873,
        337,
        341,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4249040186405182,
      "compression_ratio": 1.502732276916504,
      "no_speech_prob": 0.030149420723319054
    },
    {
      "id": 125,
      "seek": 47600,
      "start": 2986.61,
      "end": 2990.61,
      "text": " The basis is again the Green Software Foundation.",
      "tokens": [
        51364,
        440,
        5143,
        307,
        797,
        264,
        6969,
        27428,
        10335,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4249040186405182,
      "compression_ratio": 1.502732276916504,
      "no_speech_prob": 0.030149420723319054
    },
    {
      "id": 126,
      "seek": 47600,
      "start": 2990.61,
      "end": 2993.61,
      "text": " There is a Carbon Aware SDK.",
      "tokens": [
        51564,
        821,
        307,
        257,
        31453,
        43949,
        37135,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4249040186405182,
      "compression_ratio": 1.502732276916504,
      "no_speech_prob": 0.030149420723319054
    },
    {
      "id": 127,
      "seek": 50300,
      "start": 2994.61,
      "end": 3001.61,
      "text": " I took that and built it into tooling and did a project with the Fraunhofer Institute",
      "tokens": [
        50414,
        286,
        1890,
        300,
        293,
        3094,
        309,
        666,
        46593,
        293,
        630,
        257,
        1716,
        365,
        264,
        5849,
        409,
        1289,
        612,
        9446,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3966177999973297,
      "compression_ratio": 1.3023256063461304,
      "no_speech_prob": 0.008569504134356976
    },
    {
      "id": 128,
      "seek": 50300,
      "start": 3001.61,
      "end": 3009.61,
      "text": " to get predictions about the CO2 intensity of the power grid in the next 24 hours.",
      "tokens": [
        50764,
        281,
        483,
        21264,
        466,
        264,
        3002,
        17,
        13749,
        295,
        264,
        1347,
        10748,
        294,
        264,
        958,
        4022,
        2496,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3966177999973297,
      "compression_ratio": 1.3023256063461304,
      "no_speech_prob": 0.008569504134356976
    },
    {
      "id": 129,
      "seek": 51900,
      "start": 3010.61,
      "end": 3012.61,
      "text": " Question 2.",
      "tokens": [
        50414,
        14464,
        568,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.466301828622818,
      "compression_ratio": 1.350318431854248,
      "no_speech_prob": 0.0725049301981926
    },
    {
      "id": 130,
      "seek": 51900,
      "start": 3012.61,
      "end": 3023.61,
      "text": " Can I choose this as the first approach to optimize what we are seeing right now?",
      "tokens": [
        50514,
        1664,
        286,
        2826,
        341,
        382,
        264,
        700,
        3109,
        281,
        19719,
        437,
        321,
        366,
        2577,
        558,
        586,
        30,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.466301828622818,
      "compression_ratio": 1.350318431854248,
      "no_speech_prob": 0.0725049301981926
    },
    {
      "id": 131,
      "seek": 51900,
      "start": 3023.61,
      "end": 3024.61,
      "text": " Yes.",
      "tokens": [
        51064,
        1079,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.466301828622818,
      "compression_ratio": 1.350318431854248,
      "no_speech_prob": 0.0725049301981926
    },
    {
      "id": 132,
      "seek": 51900,
      "start": 3024.61,
      "end": 3027.61,
      "text": " We are in the software.",
      "tokens": [
        51114,
        492,
        366,
        294,
        264,
        4722,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.466301828622818,
      "compression_ratio": 1.350318431854248,
      "no_speech_prob": 0.0725049301981926
    },
    {
      "id": 133,
      "seek": 51900,
      "start": 3027.61,
      "end": 3029.61,
      "text": " It always starts from there.",
      "tokens": [
        51264,
        467,
        1009,
        3719,
        490,
        456,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.466301828622818,
      "compression_ratio": 1.350318431854248,
      "no_speech_prob": 0.0725049301981926
    },
    {
      "id": 134,
      "seek": 51900,
      "start": 3029.61,
      "end": 3032.61,
      "text": " If I may give you points.",
      "tokens": [
        51364,
        759,
        286,
        815,
        976,
        291,
        2793,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.466301828622818,
      "compression_ratio": 1.350318431854248,
      "no_speech_prob": 0.0725049301981926
    },
    {
      "id": 135,
      "seek": 51900,
      "start": 3032.61,
      "end": 3035.61,
      "text": " Turn off the stuff you don't need.",
      "tokens": [
        51514,
        7956,
        766,
        264,
        1507,
        291,
        500,
        380,
        643,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.466301828622818,
      "compression_ratio": 1.350318431854248,
      "no_speech_prob": 0.0725049301981926
    },
    {
      "id": 136,
      "seek": 54500,
      "start": 3035.61,
      "end": 3040.61,
      "text": " All these test systems, CECD, all the machinery has to run on each comet.",
      "tokens": [
        50364,
        1057,
        613,
        1500,
        3652,
        11,
        383,
        8140,
        35,
        11,
        439,
        264,
        27302,
        575,
        281,
        1190,
        322,
        1184,
        33696,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4349059760570526,
      "compression_ratio": 1.4976303577423096,
      "no_speech_prob": 0.2190374881029129
    },
    {
      "id": 137,
      "seek": 54500,
      "start": 3040.61,
      "end": 3042.61,
      "text": " I only do that with Merge Request.",
      "tokens": [
        50614,
        286,
        787,
        360,
        300,
        365,
        6124,
        432,
        1300,
        20343,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4349059760570526,
      "compression_ratio": 1.4976303577423096,
      "no_speech_prob": 0.2190374881029129
    },
    {
      "id": 138,
      "seek": 54500,
      "start": 3042.61,
      "end": 3044.61,
      "text": " Can I turn off any systems?",
      "tokens": [
        50714,
        1664,
        286,
        1261,
        766,
        604,
        3652,
        30,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4349059760570526,
      "compression_ratio": 1.4976303577423096,
      "no_speech_prob": 0.2190374881029129
    },
    {
      "id": 139,
      "seek": 54500,
      "start": 3044.61,
      "end": 3045.61,
      "text": " Really turn it off.",
      "tokens": [
        50814,
        4083,
        1261,
        309,
        766,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4349059760570526,
      "compression_ratio": 1.4976303577423096,
      "no_speech_prob": 0.2190374881029129
    },
    {
      "id": 140,
      "seek": 54500,
      "start": 3045.61,
      "end": 3047.61,
      "text": " Do my things have to run at night?",
      "tokens": [
        50864,
        1144,
        452,
        721,
        362,
        281,
        1190,
        412,
        1818,
        30,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4349059760570526,
      "compression_ratio": 1.4976303577423096,
      "no_speech_prob": 0.2190374881029129
    },
    {
      "id": 141,
      "seek": 54500,
      "start": 3047.61,
      "end": 3049.61,
      "text": " Turning it off helps.",
      "tokens": [
        50964,
        39660,
        309,
        766,
        3665,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4349059760570526,
      "compression_ratio": 1.4976303577423096,
      "no_speech_prob": 0.2190374881029129
    },
    {
      "id": 142,
      "seek": 54500,
      "start": 3049.61,
      "end": 3055.61,
      "text": " Number 2, which is going really well, is dynamic scaling.",
      "tokens": [
        51064,
        5118,
        568,
        11,
        597,
        307,
        516,
        534,
        731,
        11,
        307,
        8546,
        21589,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4349059760570526,
      "compression_ratio": 1.4976303577423096,
      "no_speech_prob": 0.2190374881029129
    },
    {
      "id": 143,
      "seek": 54500,
      "start": 3055.61,
      "end": 3059.61,
      "text": " A totally low-hanging, incredibly efficient.",
      "tokens": [
        51364,
        316,
        3879,
        2295,
        12,
        71,
        9741,
        11,
        6252,
        7148,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4349059760570526,
      "compression_ratio": 1.4976303577423096,
      "no_speech_prob": 0.2190374881029129
    },
    {
      "id": 144,
      "seek": 56900,
      "start": 3060.61,
      "end": 3064.61,
      "text": " Number 3 is Carbon Aware Computing.",
      "tokens": [
        50414,
        5118,
        805,
        307,
        31453,
        43949,
        37804,
        278,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3852929174900055,
      "compression_ratio": 1.5789474248886108,
      "no_speech_prob": 0.07342979311943054
    },
    {
      "id": 145,
      "seek": 56900,
      "start": 3064.61,
      "end": 3068.61,
      "text": " This time-shifting, where you say, okay, I'll push it there.",
      "tokens": [
        50614,
        639,
        565,
        12,
        2716,
        10106,
        11,
        689,
        291,
        584,
        11,
        1392,
        11,
        286,
        603,
        2944,
        309,
        456,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3852929174900055,
      "compression_ratio": 1.5789474248886108,
      "no_speech_prob": 0.07342979311943054
    },
    {
      "id": 146,
      "seek": 56900,
      "start": 3068.61,
      "end": 3071.61,
      "text": " The more batch jobs you have, the better it is to shield.",
      "tokens": [
        50814,
        440,
        544,
        7362,
        339,
        4782,
        291,
        362,
        11,
        264,
        1101,
        309,
        307,
        281,
        402,
        72,
        5957,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3852929174900055,
      "compression_ratio": 1.5789474248886108,
      "no_speech_prob": 0.07342979311943054
    },
    {
      "id": 147,
      "seek": 56900,
      "start": 3071.61,
      "end": 3078.61,
      "text": " This is the beginning, of course, because we also have to take other resources with us.",
      "tokens": [
        50964,
        639,
        307,
        264,
        2863,
        11,
        295,
        1164,
        11,
        570,
        321,
        611,
        362,
        281,
        747,
        661,
        3593,
        365,
        505,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3852929174900055,
      "compression_ratio": 1.5789474248886108,
      "no_speech_prob": 0.07342979311943054
    },
    {
      "id": 148,
      "seek": 56900,
      "start": 3078.61,
      "end": 3084.61,
      "text": " We are actually optimizing resources here, namely compute resources and CO2.",
      "tokens": [
        51314,
        492,
        366,
        767,
        40425,
        3593,
        510,
        11,
        20926,
        14722,
        3593,
        293,
        3002,
        17,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3852929174900055,
      "compression_ratio": 1.5789474248886108,
      "no_speech_prob": 0.07342979311943054
    },
    {
      "id": 149,
      "seek": 56900,
      "start": 3084.61,
      "end": 3087.61,
      "text": " The number we have at the moment is CO2.",
      "tokens": [
        51614,
        440,
        1230,
        321,
        362,
        412,
        264,
        1623,
        307,
        3002,
        17,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3852929174900055,
      "compression_ratio": 1.5789474248886108,
      "no_speech_prob": 0.07342979311943054
    },
    {
      "id": 150,
      "seek": 59700,
      "start": 3087.61,
      "end": 3090.61,
      "text": " But if I'm in the cloud, for example, and I have batch jobs,",
      "tokens": [
        50364,
        583,
        498,
        286,
        478,
        294,
        264,
        4588,
        11,
        337,
        1365,
        11,
        293,
        286,
        362,
        15245,
        4782,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3953598737716675,
      "compression_ratio": 1.478468894958496,
      "no_speech_prob": 0.02554681897163391
    },
    {
      "id": 151,
      "seek": 59700,
      "start": 3090.61,
      "end": 3093.61,
      "text": " then I can combine that with Spot VMs.",
      "tokens": [
        50514,
        550,
        286,
        393,
        10432,
        300,
        365,
        19102,
        18038,
        82,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3953598737716675,
      "compression_ratio": 1.478468894958496,
      "no_speech_prob": 0.02554681897163391
    },
    {
      "id": 152,
      "seek": 59700,
      "start": 3093.61,
      "end": 3099.61,
      "text": " These are basically the VMs from our data center.",
      "tokens": [
        50664,
        1981,
        366,
        1936,
        264,
        18038,
        82,
        490,
        527,
        1412,
        3056,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3953598737716675,
      "compression_ratio": 1.478468894958496,
      "no_speech_prob": 0.02554681897163391
    },
    {
      "id": 153,
      "seek": 59700,
      "start": 3099.61,
      "end": 3101.61,
      "text": " I combine them.",
      "tokens": [
        50964,
        286,
        10432,
        552,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3953598737716675,
      "compression_ratio": 1.478468894958496,
      "no_speech_prob": 0.02554681897163391
    },
    {
      "id": 154,
      "seek": 59700,
      "start": 3101.61,
      "end": 3107.61,
      "text": " And with that, I have a maximum without effort.",
      "tokens": [
        51064,
        400,
        365,
        300,
        11,
        286,
        362,
        257,
        6674,
        1553,
        4630,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3953598737716675,
      "compression_ratio": 1.478468894958496,
      "no_speech_prob": 0.02554681897163391
    },
    {
      "id": 155,
      "seek": 59700,
      "start": 3107.61,
      "end": 3110.61,
      "text": " Would you like to briefly explain what Spot VMs are?",
      "tokens": [
        51364,
        6068,
        291,
        411,
        281,
        10515,
        2903,
        437,
        19102,
        18038,
        82,
        366,
        30,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3953598737716675,
      "compression_ratio": 1.478468894958496,
      "no_speech_prob": 0.02554681897163391
    },
    {
      "id": 156,
      "seek": 59700,
      "start": 3110.61,
      "end": 3112.61,
      "text": " I'm not sure if everyone understands that.",
      "tokens": [
        51514,
        286,
        478,
        406,
        988,
        498,
        1518,
        15146,
        300,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3953598737716675,
      "compression_ratio": 1.478468894958496,
      "no_speech_prob": 0.02554681897163391
    },
    {
      "id": 157,
      "seek": 62200,
      "start": 3113.61,
      "end": 3120.61,
      "text": " The big hyperscalers, if they have too many free compute resources,",
      "tokens": [
        50414,
        440,
        955,
        7420,
        433,
        9895,
        433,
        11,
        498,
        436,
        362,
        886,
        867,
        1737,
        14722,
        3593,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35637176036834717,
      "compression_ratio": 1.47398841381073,
      "no_speech_prob": 0.062421273440122604
    },
    {
      "id": 158,
      "seek": 62200,
      "start": 3120.61,
      "end": 3125.61,
      "text": " then you can order a kind of VM.",
      "tokens": [
        50764,
        550,
        291,
        393,
        1668,
        257,
        733,
        295,
        18038,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35637176036834717,
      "compression_ratio": 1.47398841381073,
      "no_speech_prob": 0.062421273440122604
    },
    {
      "id": 159,
      "seek": 62200,
      "start": 3125.61,
      "end": 3127.61,
      "text": " You get it at some point.",
      "tokens": [
        51014,
        509,
        483,
        309,
        412,
        512,
        935,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35637176036834717,
      "compression_ratio": 1.47398841381073,
      "no_speech_prob": 0.062421273440122604
    },
    {
      "id": 160,
      "seek": 62200,
      "start": 3127.61,
      "end": 3130.61,
      "text": " And it's taken away from you again when you need the resources.",
      "tokens": [
        51114,
        400,
        309,
        311,
        2726,
        1314,
        490,
        291,
        797,
        562,
        291,
        643,
        264,
        3593,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35637176036834717,
      "compression_ratio": 1.47398841381073,
      "no_speech_prob": 0.062421273440122604
    },
    {
      "id": 161,
      "seek": 62200,
      "start": 3130.61,
      "end": 3132.61,
      "text": " But I have a free time.",
      "tokens": [
        51264,
        583,
        286,
        362,
        257,
        1737,
        565,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35637176036834717,
      "compression_ratio": 1.47398841381073,
      "no_speech_prob": 0.062421273440122604
    },
    {
      "id": 162,
      "seek": 62200,
      "start": 3132.61,
      "end": 3134.61,
      "text": " I can use the VM.",
      "tokens": [
        51364,
        286,
        393,
        764,
        264,
        18038,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35637176036834717,
      "compression_ratio": 1.47398841381073,
      "no_speech_prob": 0.062421273440122604
    },
    {
      "id": 163,
      "seek": 62200,
      "start": 3134.61,
      "end": 3137.61,
      "text": " And it's much cheaper.",
      "tokens": [
        51464,
        400,
        309,
        311,
        709,
        12284,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35637176036834717,
      "compression_ratio": 1.47398841381073,
      "no_speech_prob": 0.062421273440122604
    },
    {
      "id": 164,
      "seek": 64700,
      "start": 3138.61,
      "end": 3142.61,
      "text": " I take the rest of the compute.",
      "tokens": [
        50414,
        286,
        747,
        264,
        1472,
        295,
        264,
        14722,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4073413014411926,
      "compression_ratio": 1.5794392824172974,
      "no_speech_prob": 0.07653988897800446
    },
    {
      "id": 165,
      "seek": 64700,
      "start": 3142.61,
      "end": 3149.61,
      "text": " If I understand that correctly, I pay so and so many euros for this thing.",
      "tokens": [
        50614,
        759,
        286,
        1223,
        300,
        8944,
        11,
        286,
        1689,
        370,
        293,
        370,
        867,
        14160,
        337,
        341,
        551,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4073413014411926,
      "compression_ratio": 1.5794392824172974,
      "no_speech_prob": 0.07653988897800446
    },
    {
      "id": 166,
      "seek": 64700,
      "start": 3149.61,
      "end": 3154.61,
      "text": " And if the price is below that, then this resource is given to me.",
      "tokens": [
        50964,
        400,
        498,
        264,
        3218,
        307,
        2507,
        300,
        11,
        550,
        341,
        7684,
        307,
        2212,
        281,
        385,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4073413014411926,
      "compression_ratio": 1.5794392824172974,
      "no_speech_prob": 0.07653988897800446
    },
    {
      "id": 167,
      "seek": 64700,
      "start": 3154.61,
      "end": 3157.61,
      "text": " And then it runs for a while and at some point it will be withdrawn again.",
      "tokens": [
        51214,
        400,
        550,
        309,
        6676,
        337,
        257,
        1339,
        293,
        412,
        512,
        935,
        309,
        486,
        312,
        48151,
        797,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4073413014411926,
      "compression_ratio": 1.5794392824172974,
      "no_speech_prob": 0.07653988897800446
    },
    {
      "id": 168,
      "seek": 64700,
      "start": 3157.61,
      "end": 3159.61,
      "text": " This is the beta model.",
      "tokens": [
        51364,
        639,
        307,
        264,
        9861,
        2316,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4073413014411926,
      "compression_ratio": 1.5794392824172974,
      "no_speech_prob": 0.07653988897800446
    },
    {
      "id": 169,
      "seek": 64700,
      "start": 3159.61,
      "end": 3164.61,
      "text": " At Microsoft, for example, there is the Azure Batch as a service.",
      "tokens": [
        51464,
        1711,
        8116,
        11,
        337,
        1365,
        11,
        456,
        307,
        264,
        11969,
        363,
        852,
        382,
        257,
        2643,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4073413014411926,
      "compression_ratio": 1.5794392824172974,
      "no_speech_prob": 0.07653988897800446
    },
    {
      "id": 170,
      "seek": 67400,
      "start": 3164.61,
      "end": 3167.61,
      "text": " Then you can say, I would like Spot VMs.",
      "tokens": [
        50364,
        1396,
        291,
        393,
        584,
        11,
        286,
        576,
        411,
        19102,
        18038,
        82,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42733144760131836,
      "compression_ratio": 1.6375000476837158,
      "no_speech_prob": 0.10614971816539764
    },
    {
      "id": 171,
      "seek": 67400,
      "start": 3167.61,
      "end": 3169.61,
      "text": " Then you just get them at some point.",
      "tokens": [
        50514,
        1396,
        291,
        445,
        483,
        552,
        412,
        512,
        935,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42733144760131836,
      "compression_ratio": 1.6375000476837158,
      "no_speech_prob": 0.10614971816539764
    },
    {
      "id": 172,
      "seek": 67400,
      "start": 3169.61,
      "end": 3171.61,
      "text": " And they are 30-40% cheaper.",
      "tokens": [
        50614,
        400,
        436,
        366,
        2217,
        12,
        5254,
        4,
        12284,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42733144760131836,
      "compression_ratio": 1.6375000476837158,
      "no_speech_prob": 0.10614971816539764
    },
    {
      "id": 173,
      "seek": 67400,
      "start": 3171.61,
      "end": 3174.61,
      "text": " And I think you can also offer them somewhere else.",
      "tokens": [
        50714,
        400,
        286,
        519,
        291,
        393,
        611,
        2626,
        552,
        4079,
        1646,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42733144760131836,
      "compression_ratio": 1.6375000476837158,
      "no_speech_prob": 0.10614971816539764
    },
    {
      "id": 174,
      "seek": 67400,
      "start": 3174.61,
      "end": 3176.61,
      "text": " Yes, that was AWS.",
      "tokens": [
        50864,
        1079,
        11,
        300,
        390,
        17650,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42733144760131836,
      "compression_ratio": 1.6375000476837158,
      "no_speech_prob": 0.10614971816539764
    },
    {
      "id": 175,
      "seek": 67400,
      "start": 3176.61,
      "end": 3178.61,
      "text": " But that's ten years ago or so.",
      "tokens": [
        50964,
        583,
        300,
        311,
        2064,
        924,
        2057,
        420,
        370,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42733144760131836,
      "compression_ratio": 1.6375000476837158,
      "no_speech_prob": 0.10614971816539764
    },
    {
      "id": 176,
      "seek": 67400,
      "start": 3178.61,
      "end": 3180.61,
      "text": " I did exactly that.",
      "tokens": [
        51064,
        286,
        630,
        2293,
        300,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42733144760131836,
      "compression_ratio": 1.6375000476837158,
      "no_speech_prob": 0.10614971816539764
    },
    {
      "id": 177,
      "seek": 67400,
      "start": 3180.61,
      "end": 3184.61,
      "text": " And I also found that the things are just gone at some point.",
      "tokens": [
        51164,
        400,
        286,
        611,
        1352,
        300,
        264,
        721,
        366,
        445,
        2780,
        412,
        512,
        935,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42733144760131836,
      "compression_ratio": 1.6375000476837158,
      "no_speech_prob": 0.10614971816539764
    },
    {
      "id": 178,
      "seek": 67400,
      "start": 3184.61,
      "end": 3185.61,
      "text": " Just like that.",
      "tokens": [
        51364,
        1449,
        411,
        300,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42733144760131836,
      "compression_ratio": 1.6375000476837158,
      "no_speech_prob": 0.10614971816539764
    },
    {
      "id": 179,
      "seek": 67400,
      "start": 3185.61,
      "end": 3187.61,
      "text": " It's behind the scenes, so to speak.",
      "tokens": [
        51414,
        467,
        311,
        2261,
        264,
        8026,
        11,
        370,
        281,
        1710,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42733144760131836,
      "compression_ratio": 1.6375000476837158,
      "no_speech_prob": 0.10614971816539764
    },
    {
      "id": 180,
      "seek": 67400,
      "start": 3187.61,
      "end": 3188.61,
      "text": " Yes, exactly.",
      "tokens": [
        51514,
        1079,
        11,
        2293,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42733144760131836,
      "compression_ratio": 1.6375000476837158,
      "no_speech_prob": 0.10614971816539764
    },
    {
      "id": 181,
      "seek": 67400,
      "start": 3188.61,
      "end": 3191.61,
      "text": " You have to respect the software.",
      "tokens": [
        51564,
        509,
        362,
        281,
        3104,
        264,
        4722,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42733144760131836,
      "compression_ratio": 1.6375000476837158,
      "no_speech_prob": 0.10614971816539764
    },
    {
      "id": 182,
      "seek": 70100,
      "start": 3192.61,
      "end": 3198.61,
      "text": " Yes, it is definitely very valid.",
      "tokens": [
        50414,
        1079,
        11,
        309,
        307,
        2138,
        588,
        7363,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41716817021369934,
      "compression_ratio": 1.4111111164093018,
      "no_speech_prob": 0.05245595425367355
    },
    {
      "id": 183,
      "seek": 70100,
      "start": 3198.61,
      "end": 3201.61,
      "text": " And especially if you look at the CO2 intensity,",
      "tokens": [
        50714,
        400,
        2318,
        498,
        291,
        574,
        412,
        264,
        3002,
        17,
        13749,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41716817021369934,
      "compression_ratio": 1.4111111164093018,
      "no_speech_prob": 0.05245595425367355
    },
    {
      "id": 184,
      "seek": 70100,
      "start": 3201.61,
      "end": 3209.61,
      "text": " it fluctuates from 600 or 700 grams of CO2 per kilowatt hour to 50.",
      "tokens": [
        50864,
        309,
        23448,
        27710,
        490,
        11849,
        420,
        15204,
        11899,
        295,
        3002,
        17,
        680,
        41295,
        1591,
        1773,
        281,
        2625,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41716817021369934,
      "compression_ratio": 1.4111111164093018,
      "no_speech_prob": 0.05245595425367355
    },
    {
      "id": 185,
      "seek": 70100,
      "start": 3209.61,
      "end": 3211.61,
      "text": " So that's good.",
      "tokens": [
        51264,
        407,
        300,
        311,
        665,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41716817021369934,
      "compression_ratio": 1.4111111164093018,
      "no_speech_prob": 0.05245595425367355
    },
    {
      "id": 186,
      "seek": 70100,
      "start": 3211.61,
      "end": 3215.61,
      "text": " If you calculate an hour, then it's good.",
      "tokens": [
        51364,
        759,
        291,
        8873,
        364,
        1773,
        11,
        550,
        309,
        311,
        665,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41716817021369934,
      "compression_ratio": 1.4111111164093018,
      "no_speech_prob": 0.05245595425367355
    },
    {
      "id": 187,
      "seek": 70100,
      "start": 3215.61,
      "end": 3217.61,
      "text": " Exactly, that's a factor of 10.",
      "tokens": [
        51564,
        7587,
        11,
        300,
        311,
        257,
        5952,
        295,
        1266,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41716817021369934,
      "compression_ratio": 1.4111111164093018,
      "no_speech_prob": 0.05245595425367355
    },
    {
      "id": 188,
      "seek": 70100,
      "start": 3217.61,
      "end": 3219.61,
      "text": " So it's good.",
      "tokens": [
        51664,
        407,
        309,
        311,
        665,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41716817021369934,
      "compression_ratio": 1.4111111164093018,
      "no_speech_prob": 0.05245595425367355
    },
    {
      "id": 189,
      "seek": 72900,
      "start": 3219.61,
      "end": 3221.61,
      "text": " And there is tooling.",
      "tokens": [
        50364,
        400,
        456,
        307,
        46593,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41110357642173767,
      "compression_ratio": 1.4659091234207153,
      "no_speech_prob": 0.18409810960292816
    },
    {
      "id": 190,
      "seek": 72900,
      "start": 3221.61,
      "end": 3224.61,
      "text": " So that's also very easy.",
      "tokens": [
        50464,
        407,
        300,
        311,
        611,
        588,
        1858,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41110357642173767,
      "compression_ratio": 1.4659091234207153,
      "no_speech_prob": 0.18409810960292816
    },
    {
      "id": 191,
      "seek": 72900,
      "start": 3224.61,
      "end": 3231.61,
      "text": " Here on the website there are jobs and PowerShell and web and APs and everything.",
      "tokens": [
        50614,
        1692,
        322,
        264,
        3144,
        456,
        366,
        4782,
        293,
        7086,
        9526,
        285,
        293,
        3670,
        293,
        5372,
        82,
        293,
        1203,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41110357642173767,
      "compression_ratio": 1.4659091234207153,
      "no_speech_prob": 0.18409810960292816
    },
    {
      "id": 192,
      "seek": 72900,
      "start": 3231.61,
      "end": 3233.61,
      "text": " Exactly.",
      "tokens": [
        50964,
        7587,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41110357642173767,
      "compression_ratio": 1.4659091234207153,
      "no_speech_prob": 0.18409810960292816
    },
    {
      "id": 193,
      "seek": 72900,
      "start": 3233.61,
      "end": 3236.61,
      "text": " So I would really like to include that,",
      "tokens": [
        51064,
        407,
        286,
        576,
        534,
        411,
        281,
        4090,
        300,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41110357642173767,
      "compression_ratio": 1.4659091234207153,
      "no_speech_prob": 0.18409810960292816
    },
    {
      "id": 194,
      "seek": 72900,
      "start": 3236.61,
      "end": 3242.61,
      "text": " because these are actually all low-hanging fruits.",
      "tokens": [
        51214,
        570,
        613,
        366,
        767,
        439,
        2295,
        12,
        71,
        9741,
        12148,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41110357642173767,
      "compression_ratio": 1.4659091234207153,
      "no_speech_prob": 0.18409810960292816
    },
    {
      "id": 195,
      "seek": 72900,
      "start": 3242.61,
      "end": 3245.61,
      "text": " And when I go there and say,",
      "tokens": [
        51514,
        400,
        562,
        286,
        352,
        456,
        293,
        584,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41110357642173767,
      "compression_ratio": 1.4659091234207153,
      "no_speech_prob": 0.18409810960292816
    },
    {
      "id": 196,
      "seek": 75500,
      "start": 3245.61,
      "end": 3249.61,
      "text": " okay, I have harvested my low-hanging,",
      "tokens": [
        50364,
        1392,
        11,
        286,
        362,
        40994,
        452,
        2295,
        12,
        71,
        9741,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33788156509399414,
      "compression_ratio": 1.637130856513977,
      "no_speech_prob": 0.05167049542069435
    },
    {
      "id": 197,
      "seek": 75500,
      "start": 3249.61,
      "end": 3251.61,
      "text": " then I can go back to the software,",
      "tokens": [
        50564,
        550,
        286,
        393,
        352,
        646,
        281,
        264,
        4722,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33788156509399414,
      "compression_ratio": 1.637130856513977,
      "no_speech_prob": 0.05167049542069435
    },
    {
      "id": 198,
      "seek": 75500,
      "start": 3251.61,
      "end": 3253.61,
      "text": " can continue to optimize,",
      "tokens": [
        50664,
        393,
        2354,
        281,
        19719,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33788156509399414,
      "compression_ratio": 1.637130856513977,
      "no_speech_prob": 0.05167049542069435
    },
    {
      "id": 199,
      "seek": 75500,
      "start": 3253.61,
      "end": 3257.61,
      "text": " to pay for these individual fields of action.",
      "tokens": [
        50764,
        281,
        1689,
        337,
        613,
        2609,
        7909,
        295,
        3069,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33788156509399414,
      "compression_ratio": 1.637130856513977,
      "no_speech_prob": 0.05167049542069435
    },
    {
      "id": 200,
      "seek": 75500,
      "start": 3257.61,
      "end": 3259.61,
      "text": " Then you can think about what's going on.",
      "tokens": [
        50964,
        1396,
        291,
        393,
        519,
        466,
        437,
        311,
        516,
        322,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33788156509399414,
      "compression_ratio": 1.637130856513977,
      "no_speech_prob": 0.05167049542069435
    },
    {
      "id": 201,
      "seek": 75500,
      "start": 3259.61,
      "end": 3261.61,
      "text": " Exactly, that's actually a very good point.",
      "tokens": [
        51064,
        7587,
        11,
        300,
        311,
        767,
        257,
        588,
        665,
        935,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33788156509399414,
      "compression_ratio": 1.637130856513977,
      "no_speech_prob": 0.05167049542069435
    },
    {
      "id": 202,
      "seek": 75500,
      "start": 3261.61,
      "end": 3263.61,
      "text": " I don't think you said it explicitly,",
      "tokens": [
        51164,
        286,
        500,
        380,
        519,
        291,
        848,
        309,
        20803,
        11,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33788156509399414,
      "compression_ratio": 1.637130856513977,
      "no_speech_prob": 0.05167049542069435
    },
    {
      "id": 203,
      "seek": 75500,
      "start": 3263.61,
      "end": 3265.61,
      "text": " but it comes out implicitly.",
      "tokens": [
        51264,
        457,
        309,
        1487,
        484,
        26947,
        356,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33788156509399414,
      "compression_ratio": 1.637130856513977,
      "no_speech_prob": 0.05167049542069435
    },
    {
      "id": 204,
      "seek": 75500,
      "start": 3265.61,
      "end": 3269.61,
      "text": " It's actually just about how I run the software.",
      "tokens": [
        51364,
        467,
        311,
        767,
        445,
        466,
        577,
        286,
        1190,
        264,
        4722,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33788156509399414,
      "compression_ratio": 1.637130856513977,
      "no_speech_prob": 0.05167049542069435
    },
    {
      "id": 205,
      "seek": 75500,
      "start": 3269.61,
      "end": 3273.61,
      "text": " So we haven't even talked about it yet.",
      "tokens": [
        51564,
        407,
        321,
        2378,
        380,
        754,
        2825,
        466,
        309,
        1939,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33788156509399414,
      "compression_ratio": 1.637130856513977,
      "no_speech_prob": 0.05167049542069435
    },
    {
      "id": 206,
      "seek": 78300,
      "start": 3273.61,
      "end": 3275.61,
      "text": " I don't know, wasn't there a question?",
      "tokens": [
        50364,
        286,
        500,
        380,
        458,
        11,
        2067,
        380,
        456,
        257,
        1168,
        30,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4466911256313324,
      "compression_ratio": 1.514285683631897,
      "no_speech_prob": 0.0348055474460125
    },
    {
      "id": 207,
      "seek": 78300,
      "start": 3275.61,
      "end": 3277.61,
      "text": " Let me take a quick look.",
      "tokens": [
        50464,
        961,
        385,
        747,
        257,
        1702,
        574,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4466911256313324,
      "compression_ratio": 1.514285683631897,
      "no_speech_prob": 0.0348055474460125
    },
    {
      "id": 208,
      "seek": 78300,
      "start": 3277.61,
      "end": 3279.61,
      "text": " Or rather, this is one of the topics",
      "tokens": [
        50564,
        1610,
        2831,
        11,
        341,
        307,
        472,
        295,
        264,
        8378,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4466911256313324,
      "compression_ratio": 1.514285683631897,
      "no_speech_prob": 0.0348055474460125
    },
    {
      "id": 209,
      "seek": 78300,
      "start": 3279.61,
      "end": 3281.61,
      "text": " that is always going around the area.",
      "tokens": [
        50664,
        300,
        307,
        1009,
        516,
        926,
        264,
        1859,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4466911256313324,
      "compression_ratio": 1.514285683631897,
      "no_speech_prob": 0.0348055474460125
    },
    {
      "id": 210,
      "seek": 78300,
      "start": 3281.61,
      "end": 3284.61,
      "text": " Which programming language should I use?",
      "tokens": [
        50764,
        3013,
        9410,
        2856,
        820,
        286,
        764,
        30,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4466911256313324,
      "compression_ratio": 1.514285683631897,
      "no_speech_prob": 0.0348055474460125
    },
    {
      "id": 211,
      "seek": 78300,
      "start": 3284.61,
      "end": 3287.61,
      "text": " And we haven't really discussed that.",
      "tokens": [
        50914,
        400,
        321,
        2378,
        380,
        534,
        7152,
        300,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4466911256313324,
      "compression_ratio": 1.514285683631897,
      "no_speech_prob": 0.0348055474460125
    },
    {
      "id": 212,
      "seek": 78300,
      "start": 3287.61,
      "end": 3290.61,
      "text": " It would be a bit of a question.",
      "tokens": [
        51064,
        467,
        576,
        312,
        257,
        857,
        295,
        257,
        1168,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4466911256313324,
      "compression_ratio": 1.514285683631897,
      "no_speech_prob": 0.0348055474460125
    },
    {
      "id": 213,
      "seek": 78300,
      "start": 3290.61,
      "end": 3295.61,
      "text": " So is that even a topic?",
      "tokens": [
        51214,
        407,
        307,
        300,
        754,
        257,
        4829,
        30,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4466911256313324,
      "compression_ratio": 1.514285683631897,
      "no_speech_prob": 0.0348055474460125
    },
    {
      "id": 214,
      "seek": 78300,
      "start": 3295.61,
      "end": 3298.61,
      "text": " So yes, no.",
      "tokens": [
        51464,
        407,
        2086,
        11,
        572,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4466911256313324,
      "compression_ratio": 1.514285683631897,
      "no_speech_prob": 0.0348055474460125
    },
    {
      "id": 215,
      "seek": 78300,
      "start": 3298.61,
      "end": 3300.61,
      "text": " So academically, I would say.",
      "tokens": [
        51614,
        407,
        48944,
        11,
        286,
        576,
        584,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4466911256313324,
      "compression_ratio": 1.514285683631897,
      "no_speech_prob": 0.0348055474460125
    },
    {
      "id": 216,
      "seek": 81000,
      "start": 3300.61,
      "end": 3302.61,
      "text": " First of all, the programming language",
      "tokens": [
        50364,
        2386,
        295,
        439,
        11,
        264,
        9410,
        2856,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32307249307632446,
      "compression_ratio": 1.5019919872283936,
      "no_speech_prob": 0.13298314809799194
    },
    {
      "id": 217,
      "seek": 81000,
      "start": 3302.61,
      "end": 3304.61,
      "text": " that is suitable for us.",
      "tokens": [
        50464,
        300,
        307,
        12873,
        337,
        505,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32307249307632446,
      "compression_ratio": 1.5019919872283936,
      "no_speech_prob": 0.13298314809799194
    },
    {
      "id": 218,
      "seek": 81000,
      "start": 3304.61,
      "end": 3306.61,
      "text": " So what should I tell people?",
      "tokens": [
        50564,
        407,
        437,
        820,
        286,
        980,
        561,
        30,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32307249307632446,
      "compression_ratio": 1.5019919872283936,
      "no_speech_prob": 0.13298314809799194
    },
    {
      "id": 219,
      "seek": 81000,
      "start": 3306.61,
      "end": 3308.61,
      "text": " Don't do Python, do Rust.",
      "tokens": [
        50664,
        1468,
        380,
        360,
        15329,
        11,
        360,
        34952,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32307249307632446,
      "compression_ratio": 1.5019919872283936,
      "no_speech_prob": 0.13298314809799194
    },
    {
      "id": 220,
      "seek": 81000,
      "start": 3308.61,
      "end": 3310.61,
      "text": " But it's not that bad,",
      "tokens": [
        50764,
        583,
        309,
        311,
        406,
        300,
        1578,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32307249307632446,
      "compression_ratio": 1.5019919872283936,
      "no_speech_prob": 0.13298314809799194
    },
    {
      "id": 221,
      "seek": 81000,
      "start": 3310.61,
      "end": 3314.61,
      "text": " because Python of course uses the C libraries at the end.",
      "tokens": [
        50864,
        570,
        15329,
        295,
        1164,
        4960,
        264,
        383,
        15148,
        412,
        264,
        917,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32307249307632446,
      "compression_ratio": 1.5019919872283936,
      "no_speech_prob": 0.13298314809799194
    },
    {
      "id": 222,
      "seek": 81000,
      "start": 3314.61,
      "end": 3318.61,
      "text": " Or Java or .NET or something.",
      "tokens": [
        51064,
        1610,
        10745,
        420,
        2411,
        35554,
        420,
        746,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32307249307632446,
      "compression_ratio": 1.5019919872283936,
      "no_speech_prob": 0.13298314809799194
    },
    {
      "id": 223,
      "seek": 81000,
      "start": 3318.61,
      "end": 3321.61,
      "text": " Well, it also depends on the runtime environment.",
      "tokens": [
        51264,
        1042,
        11,
        309,
        611,
        5946,
        322,
        264,
        34474,
        2823,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32307249307632446,
      "compression_ratio": 1.5019919872283936,
      "no_speech_prob": 0.13298314809799194
    },
    {
      "id": 224,
      "seek": 81000,
      "start": 3321.61,
      "end": 3323.61,
      "text": " So do I do .NET Core, do I do .NET Framework,",
      "tokens": [
        51414,
        407,
        360,
        286,
        360,
        2411,
        35554,
        14798,
        11,
        360,
        286,
        360,
        2411,
        35554,
        31628,
        1902,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32307249307632446,
      "compression_ratio": 1.5019919872283936,
      "no_speech_prob": 0.13298314809799194
    },
    {
      "id": 225,
      "seek": 81000,
      "start": 3323.61,
      "end": 3327.61,
      "text": " do I do Java with any Enterprise Beans or Schlank?",
      "tokens": [
        51514,
        360,
        286,
        360,
        10745,
        365,
        604,
        26696,
        879,
        599,
        420,
        318,
        11439,
        657,
        30,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32307249307632446,
      "compression_ratio": 1.5019919872283936,
      "no_speech_prob": 0.13298314809799194
    },
    {
      "id": 226,
      "seek": 83700,
      "start": 3328.61,
      "end": 3333.61,
      "text": " Do I have Spring with me or not?",
      "tokens": [
        50414,
        1144,
        286,
        362,
        14013,
        365,
        385,
        420,
        406,
        30,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3502334654331207,
      "compression_ratio": 1.565445065498352,
      "no_speech_prob": 0.017999902367591858
    },
    {
      "id": 227,
      "seek": 83700,
      "start": 3333.61,
      "end": 3336.61,
      "text": " So in my opinion, it's not the programming language.",
      "tokens": [
        50664,
        407,
        294,
        452,
        4800,
        11,
        309,
        311,
        406,
        264,
        9410,
        2856,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3502334654331207,
      "compression_ratio": 1.565445065498352,
      "no_speech_prob": 0.017999902367591858
    },
    {
      "id": 228,
      "seek": 83700,
      "start": 3336.61,
      "end": 3338.61,
      "text": " If so, it's the runtime environment",
      "tokens": [
        50814,
        759,
        370,
        11,
        309,
        311,
        264,
        34474,
        2823,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3502334654331207,
      "compression_ratio": 1.565445065498352,
      "no_speech_prob": 0.017999902367591858
    },
    {
      "id": 229,
      "seek": 83700,
      "start": 3338.61,
      "end": 3340.61,
      "text": " and the Frameworks that we make.",
      "tokens": [
        50914,
        293,
        264,
        31628,
        18357,
        300,
        321,
        652,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3502334654331207,
      "compression_ratio": 1.565445065498352,
      "no_speech_prob": 0.017999902367591858
    },
    {
      "id": 230,
      "seek": 83700,
      "start": 3342.61,
      "end": 3346.61,
      "text": " But I think it's mainly the mindset.",
      "tokens": [
        51114,
        583,
        286,
        519,
        309,
        311,
        8704,
        264,
        12543,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3502334654331207,
      "compression_ratio": 1.565445065498352,
      "no_speech_prob": 0.017999902367591858
    },
    {
      "id": 231,
      "seek": 83700,
      "start": 3349.61,
      "end": 3351.61,
      "text": " It's software engineering.",
      "tokens": [
        51464,
        467,
        311,
        4722,
        7043,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3502334654331207,
      "compression_ratio": 1.565445065498352,
      "no_speech_prob": 0.017999902367591858
    },
    {
      "id": 232,
      "seek": 83700,
      "start": 3351.61,
      "end": 3353.61,
      "text": " It's just normal software engineering.",
      "tokens": [
        51564,
        467,
        311,
        445,
        2710,
        4722,
        7043,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3502334654331207,
      "compression_ratio": 1.565445065498352,
      "no_speech_prob": 0.017999902367591858
    },
    {
      "id": 233,
      "seek": 83700,
      "start": 3353.61,
      "end": 3355.61,
      "text": " We can all do that.",
      "tokens": [
        51664,
        492,
        393,
        439,
        360,
        300,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3502334654331207,
      "compression_ratio": 1.565445065498352,
      "no_speech_prob": 0.017999902367591858
    },
    {
      "id": 234,
      "seek": 83700,
      "start": 3355.61,
      "end": 3356.61,
      "text": " We know how it works.",
      "tokens": [
        51764,
        492,
        458,
        577,
        309,
        1985,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3502334654331207,
      "compression_ratio": 1.565445065498352,
      "no_speech_prob": 0.017999902367591858
    },
    {
      "id": 235,
      "seek": 86600,
      "start": 3356.61,
      "end": 3358.61,
      "text": " If we don't know it, we'll learn it right away.",
      "tokens": [
        50364,
        759,
        321,
        500,
        380,
        458,
        309,
        11,
        321,
        603,
        1466,
        309,
        558,
        1314,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3002147674560547,
      "compression_ratio": 1.6872427463531494,
      "no_speech_prob": 0.016522418707609177
    },
    {
      "id": 236,
      "seek": 86600,
      "start": 3358.61,
      "end": 3360.61,
      "text": " These are similar practices.",
      "tokens": [
        50464,
        1981,
        366,
        2531,
        7525,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3002147674560547,
      "compression_ratio": 1.6872427463531494,
      "no_speech_prob": 0.016522418707609177
    },
    {
      "id": 237,
      "seek": 86600,
      "start": 3360.61,
      "end": 3362.61,
      "text": " And in software engineering,",
      "tokens": [
        50564,
        400,
        294,
        4722,
        7043,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3002147674560547,
      "compression_ratio": 1.6872427463531494,
      "no_speech_prob": 0.016522418707609177
    },
    {
      "id": 238,
      "seek": 86600,
      "start": 3362.61,
      "end": 3365.61,
      "text": " we have our focus on evolvability.",
      "tokens": [
        50664,
        321,
        362,
        527,
        1879,
        322,
        7117,
        85,
        2310,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3002147674560547,
      "compression_ratio": 1.6872427463531494,
      "no_speech_prob": 0.016522418707609177
    },
    {
      "id": 239,
      "seek": 86600,
      "start": 3365.61,
      "end": 3368.61,
      "text": " And in green software, in green coding,",
      "tokens": [
        50814,
        400,
        294,
        3092,
        4722,
        11,
        294,
        3092,
        17720,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3002147674560547,
      "compression_ratio": 1.6872427463531494,
      "no_speech_prob": 0.016522418707609177
    },
    {
      "id": 240,
      "seek": 86600,
      "start": 3368.61,
      "end": 3371.61,
      "text": " we use the same tools",
      "tokens": [
        50964,
        321,
        764,
        264,
        912,
        3873,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3002147674560547,
      "compression_ratio": 1.6872427463531494,
      "no_speech_prob": 0.016522418707609177
    },
    {
      "id": 241,
      "seek": 86600,
      "start": 3371.61,
      "end": 3374.61,
      "text": " with a focus on climate-friendly.",
      "tokens": [
        51114,
        365,
        257,
        1879,
        322,
        5659,
        12,
        22864,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3002147674560547,
      "compression_ratio": 1.6872427463531494,
      "no_speech_prob": 0.016522418707609177
    },
    {
      "id": 242,
      "seek": 86600,
      "start": 3374.61,
      "end": 3376.61,
      "text": " And in doing so, we somehow also save money in advance.",
      "tokens": [
        51264,
        400,
        294,
        884,
        370,
        11,
        321,
        6063,
        611,
        3155,
        1460,
        294,
        7295,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3002147674560547,
      "compression_ratio": 1.6872427463531494,
      "no_speech_prob": 0.016522418707609177
    },
    {
      "id": 243,
      "seek": 86600,
      "start": 3376.61,
      "end": 3378.61,
      "text": " And that's actually something",
      "tokens": [
        51364,
        400,
        300,
        311,
        767,
        746,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3002147674560547,
      "compression_ratio": 1.6872427463531494,
      "no_speech_prob": 0.016522418707609177
    },
    {
      "id": 244,
      "seek": 86600,
      "start": 3378.61,
      "end": 3380.61,
      "text": " where you can get active right away,",
      "tokens": [
        51464,
        689,
        291,
        393,
        483,
        4967,
        558,
        1314,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3002147674560547,
      "compression_ratio": 1.6872427463531494,
      "no_speech_prob": 0.016522418707609177
    },
    {
      "id": 245,
      "seek": 86600,
      "start": 3380.61,
      "end": 3382.61,
      "text": " as you said very clearly.",
      "tokens": [
        51564,
        382,
        291,
        848,
        588,
        4448,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3002147674560547,
      "compression_ratio": 1.6872427463531494,
      "no_speech_prob": 0.016522418707609177
    },
    {
      "id": 246,
      "seek": 86600,
      "start": 3382.61,
      "end": 3384.61,
      "text": " One thing, I have to see",
      "tokens": [
        51664,
        1485,
        551,
        11,
        286,
        362,
        281,
        536,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3002147674560547,
      "compression_ratio": 1.6872427463531494,
      "no_speech_prob": 0.016522418707609177
    },
    {
      "id": 247,
      "seek": 89400,
      "start": 3384.61,
      "end": 3386.61,
      "text": " if I can find it out.",
      "tokens": [
        50364,
        498,
        286,
        393,
        915,
        309,
        484,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4277801811695099,
      "compression_ratio": 1.7027027606964111,
      "no_speech_prob": 0.2512245774269104
    },
    {
      "id": 248,
      "seek": 89400,
      "start": 3386.61,
      "end": 3388.61,
      "text": " I don't know if you're also keen on it,",
      "tokens": [
        50464,
        286,
        500,
        380,
        458,
        498,
        291,
        434,
        611,
        20297,
        322,
        309,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4277801811695099,
      "compression_ratio": 1.7027027606964111,
      "no_speech_prob": 0.2512245774269104
    },
    {
      "id": 249,
      "seek": 89400,
      "start": 3388.61,
      "end": 3390.61,
      "text": " because we were just talking about programming languages.",
      "tokens": [
        50564,
        570,
        321,
        645,
        445,
        1417,
        466,
        9410,
        8650,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4277801811695099,
      "compression_ratio": 1.7027027606964111,
      "no_speech_prob": 0.2512245774269104
    },
    {
      "id": 250,
      "seek": 89400,
      "start": 3390.61,
      "end": 3392.61,
      "text": " There's a new paper that says",
      "tokens": [
        50664,
        821,
        311,
        257,
        777,
        3035,
        300,
        1619,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4277801811695099,
      "compression_ratio": 1.7027027606964111,
      "no_speech_prob": 0.2512245774269104
    },
    {
      "id": 251,
      "seek": 89400,
      "start": 3392.61,
      "end": 3394.61,
      "text": " the previous view",
      "tokens": [
        50764,
        264,
        3894,
        1910,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4277801811695099,
      "compression_ratio": 1.7027027606964111,
      "no_speech_prob": 0.2512245774269104
    },
    {
      "id": 252,
      "seek": 89400,
      "start": 3394.61,
      "end": 3396.61,
      "text": " that programming languages",
      "tokens": [
        50864,
        300,
        9410,
        8650,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4277801811695099,
      "compression_ratio": 1.7027027606964111,
      "no_speech_prob": 0.2512245774269104
    },
    {
      "id": 253,
      "seek": 89400,
      "start": 3396.61,
      "end": 3398.61,
      "text": " bring a lot of things",
      "tokens": [
        50964,
        1565,
        257,
        688,
        295,
        721,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4277801811695099,
      "compression_ratio": 1.7027027606964111,
      "no_speech_prob": 0.2512245774269104
    },
    {
      "id": 254,
      "seek": 89400,
      "start": 3398.61,
      "end": 3400.61,
      "text": " is falsified because",
      "tokens": [
        51064,
        307,
        16720,
        2587,
        570,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4277801811695099,
      "compression_ratio": 1.7027027606964111,
      "no_speech_prob": 0.2512245774269104
    },
    {
      "id": 255,
      "seek": 89400,
      "start": 3400.61,
      "end": 3402.61,
      "text": " programming languages are typically used",
      "tokens": [
        51164,
        9410,
        8650,
        366,
        5850,
        1143,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4277801811695099,
      "compression_ratio": 1.7027027606964111,
      "no_speech_prob": 0.2512245774269104
    },
    {
      "id": 256,
      "seek": 89400,
      "start": 3402.61,
      "end": 3404.61,
      "text": " for certain problem areas.",
      "tokens": [
        51264,
        337,
        1629,
        1154,
        3179,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4277801811695099,
      "compression_ratio": 1.7027027606964111,
      "no_speech_prob": 0.2512245774269104
    },
    {
      "id": 257,
      "seek": 89400,
      "start": 3404.61,
      "end": 3406.61,
      "text": " And in reality,",
      "tokens": [
        51364,
        400,
        294,
        4103,
        11,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4277801811695099,
      "compression_ratio": 1.7027027606964111,
      "no_speech_prob": 0.2512245774269104
    },
    {
      "id": 258,
      "seek": 89400,
      "start": 3406.61,
      "end": 3408.61,
      "text": " the problem areas are what",
      "tokens": [
        51464,
        264,
        1154,
        3179,
        366,
        437,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4277801811695099,
      "compression_ratio": 1.7027027606964111,
      "no_speech_prob": 0.2512245774269104
    },
    {
      "id": 259,
      "seek": 89400,
      "start": 3408.61,
      "end": 3410.61,
      "text": " creates different efficiency.",
      "tokens": [
        51564,
        7829,
        819,
        10493,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4277801811695099,
      "compression_ratio": 1.7027027606964111,
      "no_speech_prob": 0.2512245774269104
    },
    {
      "id": 260,
      "seek": 92000,
      "start": 3411.61,
      "end": 3413.61,
      "text": " I don't know the paper,",
      "tokens": [
        50414,
        286,
        500,
        380,
        458,
        264,
        3035,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4575865566730499,
      "compression_ratio": 1.4879517555236816,
      "no_speech_prob": 0.4056611657142639
    },
    {
      "id": 261,
      "seek": 92000,
      "start": 3413.61,
      "end": 3416.61,
      "text": " but I would confirm it.",
      "tokens": [
        50514,
        457,
        286,
        576,
        9064,
        309,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4575865566730499,
      "compression_ratio": 1.4879517555236816,
      "no_speech_prob": 0.4056611657142639
    },
    {
      "id": 262,
      "seek": 92000,
      "start": 3422.61,
      "end": 3424.61,
      "text": " What I don't know yet,",
      "tokens": [
        50964,
        708,
        286,
        500,
        380,
        458,
        1939,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4575865566730499,
      "compression_ratio": 1.4879517555236816,
      "no_speech_prob": 0.4056611657142639
    },
    {
      "id": 263,
      "seek": 92000,
      "start": 3424.61,
      "end": 3426.61,
      "text": " for example,",
      "tokens": [
        51064,
        337,
        1365,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4575865566730499,
      "compression_ratio": 1.4879517555236816,
      "no_speech_prob": 0.4056611657142639
    },
    {
      "id": 264,
      "seek": 92000,
      "start": 3426.61,
      "end": 3428.61,
      "text": " whether I can continue with static code analysis.",
      "tokens": [
        51164,
        1968,
        286,
        393,
        2354,
        365,
        13437,
        3089,
        5215,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4575865566730499,
      "compression_ratio": 1.4879517555236816,
      "no_speech_prob": 0.4056611657142639
    },
    {
      "id": 265,
      "seek": 92000,
      "start": 3428.61,
      "end": 3432.61,
      "text": " There is the Environment Campus Trier",
      "tokens": [
        51264,
        821,
        307,
        264,
        2193,
        85,
        2088,
        518,
        28095,
        314,
        7326,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4575865566730499,
      "compression_ratio": 1.4879517555236816,
      "no_speech_prob": 0.4056611657142639
    },
    {
      "id": 266,
      "seek": 92000,
      "start": 3432.61,
      "end": 3434.61,
      "text": " and in the environment,",
      "tokens": [
        51464,
        293,
        294,
        264,
        2823,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4575865566730499,
      "compression_ratio": 1.4879517555236816,
      "no_speech_prob": 0.4056611657142639
    },
    {
      "id": 267,
      "seek": 92000,
      "start": 3434.61,
      "end": 3436.61,
      "text": " it's called Birkenfeld.",
      "tokens": [
        51564,
        309,
        311,
        1219,
        7145,
        2653,
        25115,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4575865566730499,
      "compression_ratio": 1.4879517555236816,
      "no_speech_prob": 0.4056611657142639
    },
    {
      "id": 268,
      "seek": 92000,
      "start": 3436.61,
      "end": 3438.61,
      "text": " And there was, for example,",
      "tokens": [
        51664,
        400,
        456,
        390,
        11,
        337,
        1365,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4575865566730499,
      "compression_ratio": 1.4879517555236816,
      "no_speech_prob": 0.4056611657142639
    },
    {
      "id": 269,
      "seek": 94800,
      "start": 3438.61,
      "end": 3440.61,
      "text": " a master's thesis that examined this.",
      "tokens": [
        50364,
        257,
        4505,
        311,
        22288,
        300,
        30972,
        341,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3949728310108185,
      "compression_ratio": 1.7180850505828857,
      "no_speech_prob": 0.023032747209072113
    },
    {
      "id": 270,
      "seek": 94800,
      "start": 3440.61,
      "end": 3442.61,
      "text": " And in fact,",
      "tokens": [
        50464,
        400,
        294,
        1186,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3949728310108185,
      "compression_ratio": 1.7180850505828857,
      "no_speech_prob": 0.023032747209072113
    },
    {
      "id": 271,
      "seek": 94800,
      "start": 3442.61,
      "end": 3444.61,
      "text": " we get performance problems",
      "tokens": [
        50564,
        321,
        483,
        3389,
        2740,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3949728310108185,
      "compression_ratio": 1.7180850505828857,
      "no_speech_prob": 0.023032747209072113
    },
    {
      "id": 272,
      "seek": 94800,
      "start": 3444.61,
      "end": 3446.61,
      "text": " through static code analysis,",
      "tokens": [
        50664,
        807,
        13437,
        3089,
        5215,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3949728310108185,
      "compression_ratio": 1.7180850505828857,
      "no_speech_prob": 0.023032747209072113
    },
    {
      "id": 273,
      "seek": 94800,
      "start": 3446.61,
      "end": 3448.61,
      "text": " but more than",
      "tokens": [
        50764,
        457,
        544,
        813,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3949728310108185,
      "compression_ratio": 1.7180850505828857,
      "no_speech_prob": 0.023032747209072113
    },
    {
      "id": 274,
      "seek": 94800,
      "start": 3448.61,
      "end": 3450.61,
      "text": " we can do performance analysis.",
      "tokens": [
        50864,
        321,
        393,
        360,
        3389,
        5215,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3949728310108185,
      "compression_ratio": 1.7180850505828857,
      "no_speech_prob": 0.023032747209072113
    },
    {
      "id": 275,
      "seek": 94800,
      "start": 3450.61,
      "end": 3452.61,
      "text": " What we can do through static code analysis.",
      "tokens": [
        50964,
        708,
        321,
        393,
        360,
        807,
        13437,
        3089,
        5215,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3949728310108185,
      "compression_ratio": 1.7180850505828857,
      "no_speech_prob": 0.023032747209072113
    },
    {
      "id": 276,
      "seek": 94800,
      "start": 3452.61,
      "end": 3454.61,
      "text": " But really,",
      "tokens": [
        51064,
        583,
        534,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3949728310108185,
      "compression_ratio": 1.7180850505828857,
      "no_speech_prob": 0.023032747209072113
    },
    {
      "id": 277,
      "seek": 94800,
      "start": 3454.61,
      "end": 3456.61,
      "text": " that doesn't make the code any better.",
      "tokens": [
        51164,
        300,
        1177,
        380,
        652,
        264,
        3089,
        604,
        1101,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3949728310108185,
      "compression_ratio": 1.7180850505828857,
      "no_speech_prob": 0.023032747209072113
    },
    {
      "id": 278,
      "seek": 94800,
      "start": 3456.61,
      "end": 3458.61,
      "text": " So we don't get",
      "tokens": [
        51264,
        407,
        321,
        500,
        380,
        483,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3949728310108185,
      "compression_ratio": 1.7180850505828857,
      "no_speech_prob": 0.023032747209072113
    },
    {
      "id": 279,
      "seek": 94800,
      "start": 3458.61,
      "end": 3460.61,
      "text": " better",
      "tokens": [
        51364,
        1101,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3949728310108185,
      "compression_ratio": 1.7180850505828857,
      "no_speech_prob": 0.023032747209072113
    },
    {
      "id": 280,
      "seek": 94800,
      "start": 3460.61,
      "end": 3462.61,
      "text": " programming paradigms",
      "tokens": [
        51464,
        9410,
        13480,
        328,
        2592,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3949728310108185,
      "compression_ratio": 1.7180850505828857,
      "no_speech_prob": 0.023032747209072113
    },
    {
      "id": 281,
      "seek": 94800,
      "start": 3462.61,
      "end": 3466.61,
      "text": " that go beyond performance.",
      "tokens": [
        51564,
        300,
        352,
        4399,
        3389,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3949728310108185,
      "compression_ratio": 1.7180850505828857,
      "no_speech_prob": 0.023032747209072113
    },
    {
      "id": 282,
      "seek": 97600,
      "start": 3466.61,
      "end": 3468.61,
      "text": " So profiler land.",
      "tokens": [
        50364,
        407,
        1740,
        5441,
        2117,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4321386516094208,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.07849818468093872
    },
    {
      "id": 283,
      "seek": 97600,
      "start": 3470.61,
      "end": 3472.61,
      "text": " I think you said that very nicely.",
      "tokens": [
        50564,
        286,
        519,
        291,
        848,
        300,
        588,
        9594,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4321386516094208,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.07849818468093872
    },
    {
      "id": 284,
      "seek": 97600,
      "start": 3472.61,
      "end": 3474.61,
      "text": " Once this very nice graphic",
      "tokens": [
        50664,
        3443,
        341,
        588,
        1481,
        14089,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4321386516094208,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.07849818468093872
    },
    {
      "id": 285,
      "seek": 97600,
      "start": 3474.61,
      "end": 3476.61,
      "text": " where you showed that",
      "tokens": [
        50764,
        689,
        291,
        4712,
        300,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4321386516094208,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.07849818468093872
    },
    {
      "id": 286,
      "seek": 97600,
      "start": 3476.61,
      "end": 3478.61,
      "text": " if I dynamically scale,",
      "tokens": [
        50864,
        498,
        286,
        43492,
        4373,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4321386516094208,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.07849818468093872
    },
    {
      "id": 287,
      "seek": 97600,
      "start": 3478.61,
      "end": 3480.61,
      "text": " then it saves a lot.",
      "tokens": [
        50964,
        550,
        309,
        19155,
        257,
        688,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4321386516094208,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.07849818468093872
    },
    {
      "id": 288,
      "seek": 97600,
      "start": 3480.61,
      "end": 3482.61,
      "text": " That the server load is",
      "tokens": [
        51064,
        663,
        264,
        7154,
        3677,
        307,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4321386516094208,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.07849818468093872
    },
    {
      "id": 289,
      "seek": 97600,
      "start": 3482.61,
      "end": 3484.61,
      "text": " actually very important.",
      "tokens": [
        51164,
        767,
        588,
        1021,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4321386516094208,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.07849818468093872
    },
    {
      "id": 290,
      "seek": 97600,
      "start": 3484.61,
      "end": 3486.61,
      "text": " That the run-time is so expensive.",
      "tokens": [
        51264,
        663,
        264,
        1190,
        12,
        3766,
        307,
        370,
        5124,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4321386516094208,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.07849818468093872
    },
    {
      "id": 291,
      "seek": 97600,
      "start": 3486.61,
      "end": 3488.61,
      "text": " And also this story",
      "tokens": [
        51364,
        400,
        611,
        341,
        1657,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4321386516094208,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.07849818468093872
    },
    {
      "id": 292,
      "seek": 97600,
      "start": 3488.61,
      "end": 3490.61,
      "text": " that depending on where I",
      "tokens": [
        51464,
        300,
        5413,
        322,
        689,
        286,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4321386516094208,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.07849818468093872
    },
    {
      "id": 293,
      "seek": 97600,
      "start": 3490.61,
      "end": 3492.61,
      "text": " generate the CO2",
      "tokens": [
        51564,
        8460,
        264,
        3002,
        17,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4321386516094208,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.07849818468093872
    },
    {
      "id": 294,
      "seek": 97600,
      "start": 3492.61,
      "end": 3494.61,
      "text": " or where I get the power,",
      "tokens": [
        51664,
        420,
        689,
        286,
        483,
        264,
        1347,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4321386516094208,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.07849818468093872
    },
    {
      "id": 295,
      "seek": 100400,
      "start": 3494.61,
      "end": 3496.61,
      "text": " that's obviously the big factors.",
      "tokens": [
        50364,
        300,
        311,
        2745,
        264,
        955,
        6771,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3753282427787781,
      "compression_ratio": 1.3095238208770752,
      "no_speech_prob": 0.20964723825454712
    },
    {
      "id": 296,
      "seek": 100400,
      "start": 3498.61,
      "end": 3500.61,
      "text": " You also have this CO2 challenge",
      "tokens": [
        50564,
        509,
        611,
        362,
        341,
        3002,
        17,
        3430,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3753282427787781,
      "compression_ratio": 1.3095238208770752,
      "no_speech_prob": 0.20964723825454712
    },
    {
      "id": 297,
      "seek": 100400,
      "start": 3500.61,
      "end": 3502.61,
      "text": " in Karlsruhe, right?",
      "tokens": [
        50664,
        294,
        20405,
        82,
        894,
        675,
        11,
        558,
        30,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3753282427787781,
      "compression_ratio": 1.3095238208770752,
      "no_speech_prob": 0.20964723825454712
    },
    {
      "id": 298,
      "seek": 100400,
      "start": 3502.61,
      "end": 3504.61,
      "text": " Yes, thank you.",
      "tokens": [
        50764,
        1079,
        11,
        1309,
        291,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3753282427787781,
      "compression_ratio": 1.3095238208770752,
      "no_speech_prob": 0.20964723825454712
    },
    {
      "id": 299,
      "seek": 100400,
      "start": 3508.61,
      "end": 3510.61,
      "text": " The question is, what can I do?",
      "tokens": [
        51064,
        440,
        1168,
        307,
        11,
        437,
        393,
        286,
        360,
        30,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3753282427787781,
      "compression_ratio": 1.3095238208770752,
      "no_speech_prob": 0.20964723825454712
    },
    {
      "id": 300,
      "seek": 100400,
      "start": 3512.61,
      "end": 3514.61,
      "text": " A, I can stay in my profession.",
      "tokens": [
        51264,
        316,
        11,
        286,
        393,
        1754,
        294,
        452,
        7032,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3753282427787781,
      "compression_ratio": 1.3095238208770752,
      "no_speech_prob": 0.20964723825454712
    },
    {
      "id": 301,
      "seek": 100400,
      "start": 3516.61,
      "end": 3518.61,
      "text": " And I always say smuggle in.",
      "tokens": [
        51464,
        400,
        286,
        1009,
        584,
        899,
        31726,
        294,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3753282427787781,
      "compression_ratio": 1.3095238208770752,
      "no_speech_prob": 0.20964723825454712
    },
    {
      "id": 302,
      "seek": 100400,
      "start": 3520.61,
      "end": 3522.61,
      "text": " And as an entrepreneur,",
      "tokens": [
        51664,
        400,
        382,
        364,
        14307,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3753282427787781,
      "compression_ratio": 1.3095238208770752,
      "no_speech_prob": 0.20964723825454712
    },
    {
      "id": 303,
      "seek": 103200,
      "start": 3522.61,
      "end": 3524.61,
      "text": " we have a large corporate network",
      "tokens": [
        50364,
        321,
        362,
        257,
        2416,
        10896,
        3209,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520950675010681,
      "compression_ratio": 1.4879226684570312,
      "no_speech_prob": 0.027206161990761757
    },
    {
      "id": 304,
      "seek": 103200,
      "start": 3524.61,
      "end": 3526.61,
      "text": " in Karlsruhe, one of the largest in Europe.",
      "tokens": [
        50464,
        294,
        20405,
        82,
        894,
        675,
        11,
        472,
        295,
        264,
        6443,
        294,
        3315,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520950675010681,
      "compression_ratio": 1.4879226684570312,
      "no_speech_prob": 0.027206161990761757
    },
    {
      "id": 305,
      "seek": 103200,
      "start": 3528.61,
      "end": 3530.61,
      "text": " We have now launched a campaign",
      "tokens": [
        50664,
        492,
        362,
        586,
        8730,
        257,
        5129,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520950675010681,
      "compression_ratio": 1.4879226684570312,
      "no_speech_prob": 0.027206161990761757
    },
    {
      "id": 306,
      "seek": 103200,
      "start": 3530.61,
      "end": 3532.61,
      "text": " where companies commit",
      "tokens": [
        50764,
        689,
        3431,
        5599,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520950675010681,
      "compression_ratio": 1.4879226684570312,
      "no_speech_prob": 0.027206161990761757
    },
    {
      "id": 307,
      "seek": 103200,
      "start": 3532.61,
      "end": 3534.61,
      "text": " to reducing their",
      "tokens": [
        50864,
        281,
        12245,
        641,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520950675010681,
      "compression_ratio": 1.4879226684570312,
      "no_speech_prob": 0.027206161990761757
    },
    {
      "id": 308,
      "seek": 103200,
      "start": 3534.61,
      "end": 3536.61,
      "text": " software products by 40%",
      "tokens": [
        50964,
        4722,
        3383,
        538,
        3356,
        4,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520950675010681,
      "compression_ratio": 1.4879226684570312,
      "no_speech_prob": 0.027206161990761757
    },
    {
      "id": 309,
      "seek": 103200,
      "start": 3536.61,
      "end": 3538.61,
      "text": " within a year.",
      "tokens": [
        51064,
        1951,
        257,
        1064,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520950675010681,
      "compression_ratio": 1.4879226684570312,
      "no_speech_prob": 0.027206161990761757
    },
    {
      "id": 310,
      "seek": 103200,
      "start": 3540.61,
      "end": 3542.61,
      "text": " There is mentoring for this.",
      "tokens": [
        51264,
        821,
        307,
        30257,
        337,
        341,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520950675010681,
      "compression_ratio": 1.4879226684570312,
      "no_speech_prob": 0.027206161990761757
    },
    {
      "id": 311,
      "seek": 103200,
      "start": 3544.61,
      "end": 3546.61,
      "text": " People, experts from the network",
      "tokens": [
        51464,
        3432,
        11,
        8572,
        490,
        264,
        3209,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520950675010681,
      "compression_ratio": 1.4879226684570312,
      "no_speech_prob": 0.027206161990761757
    },
    {
      "id": 312,
      "seek": 103200,
      "start": 3546.61,
      "end": 3548.61,
      "text": " are honored to be there.",
      "tokens": [
        51564,
        366,
        14556,
        281,
        312,
        456,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520950675010681,
      "compression_ratio": 1.4879226684570312,
      "no_speech_prob": 0.027206161990761757
    },
    {
      "id": 313,
      "seek": 103200,
      "start": 3548.61,
      "end": 3550.61,
      "text": " So if someone is in the stream",
      "tokens": [
        51664,
        407,
        498,
        1580,
        307,
        294,
        264,
        4309,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520950675010681,
      "compression_ratio": 1.4879226684570312,
      "no_speech_prob": 0.027206161990761757
    },
    {
      "id": 314,
      "seek": 106000,
      "start": 3550.61,
      "end": 3552.61,
      "text": " and is an expert, please report it.",
      "tokens": [
        50364,
        293,
        307,
        364,
        5844,
        11,
        1767,
        2275,
        309,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4392615854740143,
      "compression_ratio": 1.43478262424469,
      "no_speech_prob": 0.004509277176111937
    },
    {
      "id": 315,
      "seek": 106000,
      "start": 3554.61,
      "end": 3556.61,
      "text": " Or people in Karlsruhe",
      "tokens": [
        50564,
        1610,
        561,
        294,
        20405,
        82,
        894,
        675,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4392615854740143,
      "compression_ratio": 1.43478262424469,
      "no_speech_prob": 0.004509277176111937
    },
    {
      "id": 316,
      "seek": 106000,
      "start": 3556.61,
      "end": 3558.61,
      "text": " are against it.",
      "tokens": [
        50664,
        366,
        1970,
        309,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4392615854740143,
      "compression_ratio": 1.43478262424469,
      "no_speech_prob": 0.004509277176111937
    },
    {
      "id": 317,
      "seek": 106000,
      "start": 3558.61,
      "end": 3560.61,
      "text": " The big ones are still there.",
      "tokens": [
        50764,
        440,
        955,
        2306,
        366,
        920,
        456,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4392615854740143,
      "compression_ratio": 1.43478262424469,
      "no_speech_prob": 0.004509277176111937
    },
    {
      "id": 318,
      "seek": 106000,
      "start": 3560.61,
      "end": 3562.61,
      "text": " For example, Teamviewer,",
      "tokens": [
        50864,
        1171,
        1365,
        11,
        7606,
        13457,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4392615854740143,
      "compression_ratio": 1.43478262424469,
      "no_speech_prob": 0.004509277176111937
    },
    {
      "id": 319,
      "seek": 106000,
      "start": 3562.61,
      "end": 3564.61,
      "text": " NBW.",
      "tokens": [
        50964,
        426,
        33,
        54,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4392615854740143,
      "compression_ratio": 1.43478262424469,
      "no_speech_prob": 0.004509277176111937
    },
    {
      "id": 320,
      "seek": 106000,
      "start": 3566.61,
      "end": 3568.61,
      "text": " I don't know.",
      "tokens": [
        51164,
        286,
        500,
        380,
        458,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4392615854740143,
      "compression_ratio": 1.43478262424469,
      "no_speech_prob": 0.004509277176111937
    },
    {
      "id": 321,
      "seek": 106000,
      "start": 3568.61,
      "end": 3570.61,
      "text": " February you might know.",
      "tokens": [
        51264,
        3697,
        65,
        894,
        822,
        291,
        1062,
        458,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4392615854740143,
      "compression_ratio": 1.43478262424469,
      "no_speech_prob": 0.004509277176111937
    },
    {
      "id": 322,
      "seek": 106000,
      "start": 3570.61,
      "end": 3572.61,
      "text": " And a few small ones.",
      "tokens": [
        51364,
        400,
        257,
        1326,
        1359,
        2306,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4392615854740143,
      "compression_ratio": 1.43478262424469,
      "no_speech_prob": 0.004509277176111937
    },
    {
      "id": 323,
      "seek": 106000,
      "start": 3572.61,
      "end": 3574.61,
      "text": " There are still a few missing",
      "tokens": [
        51464,
        821,
        366,
        920,
        257,
        1326,
        5361,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4392615854740143,
      "compression_ratio": 1.43478262424469,
      "no_speech_prob": 0.004509277176111937
    },
    {
      "id": 324,
      "seek": 106000,
      "start": 3574.61,
      "end": 3576.61,
      "text": " as I can see.",
      "tokens": [
        51564,
        382,
        286,
        393,
        536,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4392615854740143,
      "compression_ratio": 1.43478262424469,
      "no_speech_prob": 0.004509277176111937
    },
    {
      "id": 325,
      "seek": 106000,
      "start": 3576.61,
      "end": 3578.61,
      "text": " They all do it together.",
      "tokens": [
        51664,
        814,
        439,
        360,
        309,
        1214,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4392615854740143,
      "compression_ratio": 1.43478262424469,
      "no_speech_prob": 0.004509277176111937
    },
    {
      "id": 326,
      "seek": 109000,
      "start": 3580.61,
      "end": 3582.61,
      "text": " In principle,",
      "tokens": [
        50364,
        682,
        8665,
        11,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43542709946632385,
      "compression_ratio": 1.3855421543121338,
      "no_speech_prob": 0.016634967178106308
    },
    {
      "id": 327,
      "seek": 109000,
      "start": 3582.61,
      "end": 3584.61,
      "text": " you take responsibility",
      "tokens": [
        50464,
        291,
        747,
        6357,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43542709946632385,
      "compression_ratio": 1.3855421543121338,
      "no_speech_prob": 0.016634967178106308
    },
    {
      "id": 328,
      "seek": 109000,
      "start": 3584.61,
      "end": 3586.61,
      "text": " for your products.",
      "tokens": [
        50564,
        337,
        428,
        3383,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43542709946632385,
      "compression_ratio": 1.3855421543121338,
      "no_speech_prob": 0.016634967178106308
    },
    {
      "id": 329,
      "seek": 109000,
      "start": 3586.61,
      "end": 3588.61,
      "text": " That's what I like about this campaign.",
      "tokens": [
        50664,
        663,
        311,
        437,
        286,
        411,
        466,
        341,
        5129,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43542709946632385,
      "compression_ratio": 1.3855421543121338,
      "no_speech_prob": 0.016634967178106308
    },
    {
      "id": 330,
      "seek": 109000,
      "start": 3592.61,
      "end": 3594.61,
      "text": " Anything else you",
      "tokens": [
        50964,
        11998,
        1646,
        291,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43542709946632385,
      "compression_ratio": 1.3855421543121338,
      "no_speech_prob": 0.016634967178106308
    },
    {
      "id": 331,
      "seek": 109000,
      "start": 3594.61,
      "end": 3596.61,
      "text": " would like to say?",
      "tokens": [
        51064,
        576,
        411,
        281,
        584,
        30,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43542709946632385,
      "compression_ratio": 1.3855421543121338,
      "no_speech_prob": 0.016634967178106308
    },
    {
      "id": 332,
      "seek": 109000,
      "start": 3598.61,
      "end": 3600.61,
      "text": " We are here",
      "tokens": [
        51264,
        492,
        366,
        510,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43542709946632385,
      "compression_ratio": 1.3855421543121338,
      "no_speech_prob": 0.016634967178106308
    },
    {
      "id": 333,
      "seek": 109000,
      "start": 3600.61,
      "end": 3602.61,
      "text": " from the community.",
      "tokens": [
        51364,
        490,
        264,
        1768,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43542709946632385,
      "compression_ratio": 1.3855421543121338,
      "no_speech_prob": 0.016634967178106308
    },
    {
      "id": 334,
      "seek": 109000,
      "start": 3602.61,
      "end": 3604.61,
      "text": " There are",
      "tokens": [
        51464,
        821,
        366,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43542709946632385,
      "compression_ratio": 1.3855421543121338,
      "no_speech_prob": 0.016634967178106308
    },
    {
      "id": 335,
      "seek": 109000,
      "start": 3604.61,
      "end": 3606.61,
      "text": " some renters worldwide",
      "tokens": [
        51564,
        512,
        8124,
        1559,
        13485,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43542709946632385,
      "compression_ratio": 1.3855421543121338,
      "no_speech_prob": 0.016634967178106308
    },
    {
      "id": 336,
      "seek": 109000,
      "start": 3606.61,
      "end": 3608.61,
      "text": " on the topic of green software.",
      "tokens": [
        51664,
        322,
        264,
        4829,
        295,
        3092,
        4722,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43542709946632385,
      "compression_ratio": 1.3855421543121338,
      "no_speech_prob": 0.016634967178106308
    },
    {
      "id": 337,
      "seek": 112000,
      "start": 3610.61,
      "end": 3612.61,
      "text": " Karlsruhe, of course.",
      "tokens": [
        50364,
        20405,
        82,
        894,
        675,
        11,
        295,
        1164,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3355109691619873,
      "compression_ratio": 1.2921348810195923,
      "no_speech_prob": 0.005529299844056368
    },
    {
      "id": 338,
      "seek": 112000,
      "start": 3612.61,
      "end": 3614.61,
      "text": " Munich,",
      "tokens": [
        50464,
        40601,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3355109691619873,
      "compression_ratio": 1.2921348810195923,
      "no_speech_prob": 0.005529299844056368
    },
    {
      "id": 339,
      "seek": 112000,
      "start": 3614.61,
      "end": 3616.61,
      "text": " Düsseldorf, Stuttgart,",
      "tokens": [
        50564,
        413,
        37838,
        67,
        28030,
        11,
        745,
        13478,
        49330,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3355109691619873,
      "compression_ratio": 1.2921348810195923,
      "no_speech_prob": 0.005529299844056368
    },
    {
      "id": 340,
      "seek": 112000,
      "start": 3616.61,
      "end": 3618.61,
      "text": " Frankfurt,",
      "tokens": [
        50664,
        36530,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3355109691619873,
      "compression_ratio": 1.2921348810195923,
      "no_speech_prob": 0.005529299844056368
    },
    {
      "id": 341,
      "seek": 112000,
      "start": 3618.61,
      "end": 3620.61,
      "text": " Hamburg and Berlin",
      "tokens": [
        50764,
        34118,
        293,
        13848,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3355109691619873,
      "compression_ratio": 1.2921348810195923,
      "no_speech_prob": 0.005529299844056368
    },
    {
      "id": 342,
      "seek": 112000,
      "start": 3620.61,
      "end": 3622.61,
      "text": " from time to time.",
      "tokens": [
        50864,
        490,
        565,
        281,
        565,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3355109691619873,
      "compression_ratio": 1.2921348810195923,
      "no_speech_prob": 0.005529299844056368
    },
    {
      "id": 343,
      "seek": 112000,
      "start": 3622.61,
      "end": 3624.61,
      "text": " Also in Nuremberg.",
      "tokens": [
        50964,
        2743,
        294,
        426,
        540,
        4508,
        70,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3355109691619873,
      "compression_ratio": 1.2921348810195923,
      "no_speech_prob": 0.005529299844056368
    },
    {
      "id": 344,
      "seek": 112000,
      "start": 3624.61,
      "end": 3626.61,
      "text": " We have people from everywhere.",
      "tokens": [
        51064,
        492,
        362,
        561,
        490,
        5315,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3355109691619873,
      "compression_ratio": 1.2921348810195923,
      "no_speech_prob": 0.005529299844056368
    },
    {
      "id": 345,
      "seek": 112000,
      "start": 3628.61,
      "end": 3630.61,
      "text": " In Karlsruhe,",
      "tokens": [
        51264,
        682,
        20405,
        82,
        894,
        675,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3355109691619873,
      "compression_ratio": 1.2921348810195923,
      "no_speech_prob": 0.005529299844056368
    },
    {
      "id": 346,
      "seek": 112000,
      "start": 3630.61,
      "end": 3632.61,
      "text": " you can do it hybrid.",
      "tokens": [
        51364,
        291,
        393,
        360,
        309,
        13051,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3355109691619873,
      "compression_ratio": 1.2921348810195923,
      "no_speech_prob": 0.005529299844056368
    },
    {
      "id": 347,
      "seek": 112000,
      "start": 3632.61,
      "end": 3634.61,
      "text": " There is also",
      "tokens": [
        51464,
        821,
        307,
        611,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3355109691619873,
      "compression_ratio": 1.2921348810195923,
      "no_speech_prob": 0.005529299844056368
    },
    {
      "id": 348,
      "seek": 112000,
      "start": 3634.61,
      "end": 3636.61,
      "text": " Green Software Foundation.",
      "tokens": [
        51564,
        6969,
        27428,
        10335,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3355109691619873,
      "compression_ratio": 1.2921348810195923,
      "no_speech_prob": 0.005529299844056368
    },
    {
      "id": 349,
      "seek": 114600,
      "start": 3636.61,
      "end": 3638.61,
      "text": " What we started",
      "tokens": [
        50364,
        708,
        321,
        1409,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3585664927959442,
      "compression_ratio": 1.505050539970398,
      "no_speech_prob": 0.017393747344613075
    },
    {
      "id": 350,
      "seek": 114600,
      "start": 3638.61,
      "end": 3640.61,
      "text": " 15 years ago,",
      "tokens": [
        50464,
        2119,
        924,
        2057,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3585664927959442,
      "compression_ratio": 1.505050539970398,
      "no_speech_prob": 0.017393747344613075
    },
    {
      "id": 351,
      "seek": 114600,
      "start": 3640.61,
      "end": 3642.61,
      "text": " 20 years ago, with agility,",
      "tokens": [
        50564,
        945,
        924,
        2057,
        11,
        365,
        39794,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3585664927959442,
      "compression_ratio": 1.505050539970398,
      "no_speech_prob": 0.017393747344613075
    },
    {
      "id": 352,
      "seek": 114600,
      "start": 3642.61,
      "end": 3644.61,
      "text": " with software craftsmanship,",
      "tokens": [
        50664,
        365,
        4722,
        8448,
        10817,
        27140,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3585664927959442,
      "compression_ratio": 1.505050539970398,
      "no_speech_prob": 0.017393747344613075
    },
    {
      "id": 353,
      "seek": 114600,
      "start": 3644.61,
      "end": 3646.61,
      "text": " the same movement",
      "tokens": [
        50764,
        264,
        912,
        3963,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3585664927959442,
      "compression_ratio": 1.505050539970398,
      "no_speech_prob": 0.017393747344613075
    },
    {
      "id": 354,
      "seek": 114600,
      "start": 3646.61,
      "end": 3648.61,
      "text": " starts now with green software.",
      "tokens": [
        50864,
        3719,
        586,
        365,
        3092,
        4722,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3585664927959442,
      "compression_ratio": 1.505050539970398,
      "no_speech_prob": 0.017393747344613075
    },
    {
      "id": 355,
      "seek": 114600,
      "start": 3648.61,
      "end": 3650.61,
      "text": " So in the sense of a",
      "tokens": [
        50964,
        407,
        294,
        264,
        2020,
        295,
        257,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3585664927959442,
      "compression_ratio": 1.505050539970398,
      "no_speech_prob": 0.017393747344613075
    },
    {
      "id": 356,
      "seek": 114600,
      "start": 3650.61,
      "end": 3652.61,
      "text": " roots movement, you mean.",
      "tokens": [
        51064,
        10669,
        3963,
        11,
        291,
        914,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3585664927959442,
      "compression_ratio": 1.505050539970398,
      "no_speech_prob": 0.017393747344613075
    },
    {
      "id": 357,
      "seek": 114600,
      "start": 3652.61,
      "end": 3654.61,
      "text": " Exactly.",
      "tokens": [
        51164,
        7587,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3585664927959442,
      "compression_ratio": 1.505050539970398,
      "no_speech_prob": 0.017393747344613075
    },
    {
      "id": 358,
      "seek": 114600,
      "start": 3654.61,
      "end": 3656.61,
      "text": " Maybe one more thing.",
      "tokens": [
        51264,
        2704,
        472,
        544,
        551,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3585664927959442,
      "compression_ratio": 1.505050539970398,
      "no_speech_prob": 0.017393747344613075
    },
    {
      "id": 359,
      "seek": 114600,
      "start": 3656.61,
      "end": 3658.61,
      "text": " I don't know if that's obvious.",
      "tokens": [
        51364,
        286,
        500,
        380,
        458,
        498,
        300,
        311,
        6322,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3585664927959442,
      "compression_ratio": 1.505050539970398,
      "no_speech_prob": 0.017393747344613075
    },
    {
      "id": 360,
      "seek": 114600,
      "start": 3660.61,
      "end": 3662.61,
      "text": " You also save operating costs",
      "tokens": [
        51564,
        509,
        611,
        3155,
        7447,
        5497,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3585664927959442,
      "compression_ratio": 1.505050539970398,
      "no_speech_prob": 0.017393747344613075
    },
    {
      "id": 361,
      "seek": 114600,
      "start": 3662.61,
      "end": 3664.61,
      "text": " relatively obviously.",
      "tokens": [
        51664,
        7226,
        2745,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3585664927959442,
      "compression_ratio": 1.505050539970398,
      "no_speech_prob": 0.017393747344613075
    },
    {
      "id": 362,
      "seek": 117400,
      "start": 3664.61,
      "end": 3666.61,
      "text": " We can discuss the",
      "tokens": [
        50364,
        492,
        393,
        2248,
        264,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36866357922554016,
      "compression_ratio": 1.4269006252288818,
      "no_speech_prob": 0.02922331914305687
    },
    {
      "id": 363,
      "seek": 117400,
      "start": 3666.61,
      "end": 3668.61,
      "text": " quantities now.",
      "tokens": [
        50464,
        22927,
        586,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36866357922554016,
      "compression_ratio": 1.4269006252288818,
      "no_speech_prob": 0.02922331914305687
    },
    {
      "id": 364,
      "seek": 117400,
      "start": 3668.61,
      "end": 3670.61,
      "text": " But it's not like",
      "tokens": [
        50564,
        583,
        309,
        311,
        406,
        411,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36866357922554016,
      "compression_ratio": 1.4269006252288818,
      "no_speech_prob": 0.02922331914305687
    },
    {
      "id": 365,
      "seek": 117400,
      "start": 3670.61,
      "end": 3672.61,
      "text": " you invest and only",
      "tokens": [
        50664,
        291,
        1963,
        293,
        787,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36866357922554016,
      "compression_ratio": 1.4269006252288818,
      "no_speech_prob": 0.02922331914305687
    },
    {
      "id": 366,
      "seek": 117400,
      "start": 3672.61,
      "end": 3674.61,
      "text": " CO2 is saved.",
      "tokens": [
        50764,
        3002,
        17,
        307,
        6624,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36866357922554016,
      "compression_ratio": 1.4269006252288818,
      "no_speech_prob": 0.02922331914305687
    },
    {
      "id": 367,
      "seek": 117400,
      "start": 3674.61,
      "end": 3676.61,
      "text": " It gets better.",
      "tokens": [
        50864,
        467,
        2170,
        1101,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36866357922554016,
      "compression_ratio": 1.4269006252288818,
      "no_speech_prob": 0.02922331914305687
    },
    {
      "id": 368,
      "seek": 117400,
      "start": 3678.61,
      "end": 3680.61,
      "text": " We are",
      "tokens": [
        51064,
        492,
        366,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36866357922554016,
      "compression_ratio": 1.4269006252288818,
      "no_speech_prob": 0.02922331914305687
    },
    {
      "id": 369,
      "seek": 117400,
      "start": 3680.61,
      "end": 3682.61,
      "text": " in an optimized system",
      "tokens": [
        51164,
        294,
        364,
        26941,
        1185,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36866357922554016,
      "compression_ratio": 1.4269006252288818,
      "no_speech_prob": 0.02922331914305687
    },
    {
      "id": 370,
      "seek": 117400,
      "start": 3682.61,
      "end": 3684.61,
      "text": " at the moment.",
      "tokens": [
        51264,
        412,
        264,
        1623,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36866357922554016,
      "compression_ratio": 1.4269006252288818,
      "no_speech_prob": 0.02922331914305687
    },
    {
      "id": 371,
      "seek": 117400,
      "start": 3684.61,
      "end": 3686.61,
      "text": " We are always looking for",
      "tokens": [
        51364,
        492,
        366,
        1009,
        1237,
        337,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36866357922554016,
      "compression_ratio": 1.4269006252288818,
      "no_speech_prob": 0.02922331914305687
    },
    {
      "id": 372,
      "seek": 117400,
      "start": 3686.61,
      "end": 3688.61,
      "text": " optimum. It's our job.",
      "tokens": [
        51464,
        39326,
        13,
        467,
        311,
        527,
        1691,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36866357922554016,
      "compression_ratio": 1.4269006252288818,
      "no_speech_prob": 0.02922331914305687
    },
    {
      "id": 373,
      "seek": 117400,
      "start": 3688.61,
      "end": 3690.61,
      "text": " Do it better, do it well.",
      "tokens": [
        51564,
        1144,
        309,
        1101,
        11,
        360,
        309,
        731,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36866357922554016,
      "compression_ratio": 1.4269006252288818,
      "no_speech_prob": 0.02922331914305687
    },
    {
      "id": 374,
      "seek": 117400,
      "start": 3690.61,
      "end": 3692.61,
      "text": " What we are doing now",
      "tokens": [
        51664,
        708,
        321,
        366,
        884,
        586,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36866357922554016,
      "compression_ratio": 1.4269006252288818,
      "no_speech_prob": 0.02922331914305687
    },
    {
      "id": 375,
      "seek": 120200,
      "start": 3692.61,
      "end": 3694.61,
      "text": " is that we",
      "tokens": [
        50364,
        307,
        300,
        321,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33885496854782104,
      "compression_ratio": 1.491891860961914,
      "no_speech_prob": 0.01738397777080536
    },
    {
      "id": 376,
      "seek": 120200,
      "start": 3694.61,
      "end": 3696.61,
      "text": " add another aspect to our",
      "tokens": [
        50464,
        909,
        1071,
        4171,
        281,
        527,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33885496854782104,
      "compression_ratio": 1.491891860961914,
      "no_speech_prob": 0.01738397777080536
    },
    {
      "id": 377,
      "seek": 120200,
      "start": 3696.61,
      "end": 3698.61,
      "text": " profession.",
      "tokens": [
        50564,
        7032,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33885496854782104,
      "compression_ratio": 1.491891860961914,
      "no_speech_prob": 0.01738397777080536
    },
    {
      "id": 378,
      "seek": 120200,
      "start": 3698.61,
      "end": 3700.61,
      "text": " What we used to do",
      "tokens": [
        50664,
        708,
        321,
        1143,
        281,
        360,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33885496854782104,
      "compression_ratio": 1.491891860961914,
      "no_speech_prob": 0.01738397777080536
    },
    {
      "id": 379,
      "seek": 120200,
      "start": 3700.61,
      "end": 3702.61,
      "text": " with agility,",
      "tokens": [
        50764,
        365,
        39794,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33885496854782104,
      "compression_ratio": 1.491891860961914,
      "no_speech_prob": 0.01738397777080536
    },
    {
      "id": 380,
      "seek": 120200,
      "start": 3702.61,
      "end": 3704.61,
      "text": " we had software craftsmanship",
      "tokens": [
        50864,
        321,
        632,
        4722,
        8448,
        10817,
        27140,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33885496854782104,
      "compression_ratio": 1.491891860961914,
      "no_speech_prob": 0.01738397777080536
    },
    {
      "id": 381,
      "seek": 120200,
      "start": 3704.61,
      "end": 3706.61,
      "text": " and now the climate",
      "tokens": [
        50964,
        293,
        586,
        264,
        5659,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33885496854782104,
      "compression_ratio": 1.491891860961914,
      "no_speech_prob": 0.01738397777080536
    },
    {
      "id": 382,
      "seek": 120200,
      "start": 3706.61,
      "end": 3708.61,
      "text": " is added.",
      "tokens": [
        51064,
        307,
        3869,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33885496854782104,
      "compression_ratio": 1.491891860961914,
      "no_speech_prob": 0.01738397777080536
    },
    {
      "id": 383,
      "seek": 120200,
      "start": 3708.61,
      "end": 3710.61,
      "text": " It needs a kind of activation energy.",
      "tokens": [
        51164,
        467,
        2203,
        257,
        733,
        295,
        24433,
        2281,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33885496854782104,
      "compression_ratio": 1.491891860961914,
      "no_speech_prob": 0.01738397777080536
    },
    {
      "id": 384,
      "seek": 120200,
      "start": 3710.61,
      "end": 3712.61,
      "text": " But the next optimum",
      "tokens": [
        51264,
        583,
        264,
        958,
        39326,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33885496854782104,
      "compression_ratio": 1.491891860961914,
      "no_speech_prob": 0.01738397777080536
    },
    {
      "id": 385,
      "seek": 120200,
      "start": 3712.61,
      "end": 3714.61,
      "text": " we produce is better",
      "tokens": [
        51364,
        321,
        5258,
        307,
        1101,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33885496854782104,
      "compression_ratio": 1.491891860961914,
      "no_speech_prob": 0.01738397777080536
    },
    {
      "id": 386,
      "seek": 120200,
      "start": 3714.61,
      "end": 3716.61,
      "text": " than what we had.",
      "tokens": [
        51464,
        813,
        437,
        321,
        632,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33885496854782104,
      "compression_ratio": 1.491891860961914,
      "no_speech_prob": 0.01738397777080536
    },
    {
      "id": 387,
      "seek": 120200,
      "start": 3716.61,
      "end": 3718.61,
      "text": " It's cheaper.",
      "tokens": [
        51564,
        467,
        311,
        12284,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33885496854782104,
      "compression_ratio": 1.491891860961914,
      "no_speech_prob": 0.01738397777080536
    },
    {
      "id": 388,
      "seek": 120200,
      "start": 3718.61,
      "end": 3720.61,
      "text": " We just have to do it.",
      "tokens": [
        51664,
        492,
        445,
        362,
        281,
        360,
        309,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33885496854782104,
      "compression_ratio": 1.491891860961914,
      "no_speech_prob": 0.01738397777080536
    },
    {
      "id": 389,
      "seek": 123200,
      "start": 3722.61,
      "end": 3724.61,
      "text": " We are a bit at the end of time.",
      "tokens": [
        50364,
        492,
        366,
        257,
        857,
        412,
        264,
        917,
        295,
        565,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3841199576854706,
      "compression_ratio": 1.4224598407745361,
      "no_speech_prob": 0.2057887464761734
    },
    {
      "id": 390,
      "seek": 123200,
      "start": 3724.61,
      "end": 3726.61,
      "text": " I don't know if you still have topics.",
      "tokens": [
        50464,
        286,
        500,
        380,
        458,
        498,
        291,
        920,
        362,
        8378,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3841199576854706,
      "compression_ratio": 1.4224598407745361,
      "no_speech_prob": 0.2057887464761734
    },
    {
      "id": 391,
      "seek": 123200,
      "start": 3726.61,
      "end": 3728.61,
      "text": " I could talk for hours.",
      "tokens": [
        50564,
        286,
        727,
        751,
        337,
        2496,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3841199576854706,
      "compression_ratio": 1.4224598407745361,
      "no_speech_prob": 0.2057887464761734
    },
    {
      "id": 392,
      "seek": 123200,
      "start": 3728.61,
      "end": 3730.61,
      "text": " But I think",
      "tokens": [
        50664,
        583,
        286,
        519,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3841199576854706,
      "compression_ratio": 1.4224598407745361,
      "no_speech_prob": 0.2057887464761734
    },
    {
      "id": 393,
      "seek": 123200,
      "start": 3730.61,
      "end": 3732.61,
      "text": " it's good.",
      "tokens": [
        50764,
        309,
        311,
        665,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3841199576854706,
      "compression_ratio": 1.4224598407745361,
      "no_speech_prob": 0.2057887464761734
    },
    {
      "id": 394,
      "seek": 123200,
      "start": 3732.61,
      "end": 3734.61,
      "text": " If there are questions,",
      "tokens": [
        50864,
        759,
        456,
        366,
        1651,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3841199576854706,
      "compression_ratio": 1.4224598407745361,
      "no_speech_prob": 0.2057887464761734
    },
    {
      "id": 395,
      "seek": 123200,
      "start": 3734.61,
      "end": 3736.61,
      "text": " just ping",
      "tokens": [
        50964,
        445,
        26151,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3841199576854706,
      "compression_ratio": 1.4224598407745361,
      "no_speech_prob": 0.2057887464761734
    },
    {
      "id": 396,
      "seek": 123200,
      "start": 3736.61,
      "end": 3738.61,
      "text": " on LinkedIn, connect.",
      "tokens": [
        51064,
        322,
        20657,
        11,
        1745,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3841199576854706,
      "compression_ratio": 1.4224598407745361,
      "no_speech_prob": 0.2057887464761734
    },
    {
      "id": 397,
      "seek": 123200,
      "start": 3742.61,
      "end": 3744.61,
      "text": " I'll link your profile again.",
      "tokens": [
        51364,
        286,
        603,
        2113,
        428,
        7964,
        797,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3841199576854706,
      "compression_ratio": 1.4224598407745361,
      "no_speech_prob": 0.2057887464761734
    },
    {
      "id": 398,
      "seek": 123200,
      "start": 3744.61,
      "end": 3746.61,
      "text": " We'll have",
      "tokens": [
        51464,
        492,
        603,
        362,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3841199576854706,
      "compression_ratio": 1.4224598407745361,
      "no_speech_prob": 0.2057887464761734
    },
    {
      "id": 399,
      "seek": 123200,
      "start": 3746.61,
      "end": 3748.61,
      "text": " a lot of things anyway.",
      "tokens": [
        51564,
        257,
        688,
        295,
        721,
        4033,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3841199576854706,
      "compression_ratio": 1.4224598407745361,
      "no_speech_prob": 0.2057887464761734
    },
    {
      "id": 400,
      "seek": 123200,
      "start": 3748.61,
      "end": 3750.61,
      "text": " Then I would say thank you",
      "tokens": [
        51664,
        1396,
        286,
        576,
        584,
        1309,
        291,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3841199576854706,
      "compression_ratio": 1.4224598407745361,
      "no_speech_prob": 0.2057887464761734
    },
    {
      "id": 401,
      "seek": 126000,
      "start": 3750.61,
      "end": 3752.61,
      "text": " to you.",
      "tokens": [
        50364,
        281,
        291,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34072449803352356,
      "compression_ratio": 1.677725076675415,
      "no_speech_prob": 0.13685201108455658
    },
    {
      "id": 402,
      "seek": 126000,
      "start": 3752.61,
      "end": 3754.61,
      "text": " Nice that you took the time.",
      "tokens": [
        50464,
        5490,
        300,
        291,
        1890,
        264,
        565,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34072449803352356,
      "compression_ratio": 1.677725076675415,
      "no_speech_prob": 0.13685201108455658
    },
    {
      "id": 403,
      "seek": 126000,
      "start": 3754.61,
      "end": 3756.61,
      "text": " I found it very exciting and I think it's a very important topic.",
      "tokens": [
        50564,
        286,
        1352,
        309,
        588,
        4670,
        293,
        286,
        519,
        309,
        311,
        257,
        588,
        1021,
        4829,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34072449803352356,
      "compression_ratio": 1.677725076675415,
      "no_speech_prob": 0.13685201108455658
    },
    {
      "id": 404,
      "seek": 126000,
      "start": 3756.61,
      "end": 3758.61,
      "text": " Short preview",
      "tokens": [
        50664,
        16881,
        14281,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34072449803352356,
      "compression_ratio": 1.677725076675415,
      "no_speech_prob": 0.13685201108455658
    },
    {
      "id": 405,
      "seek": 126000,
      "start": 3758.61,
      "end": 3760.61,
      "text": " for the next time.",
      "tokens": [
        50764,
        337,
        264,
        958,
        565,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34072449803352356,
      "compression_ratio": 1.677725076675415,
      "no_speech_prob": 0.13685201108455658
    },
    {
      "id": 406,
      "seek": 126000,
      "start": 3760.61,
      "end": 3762.61,
      "text": " The next time is again next Friday.",
      "tokens": [
        50864,
        440,
        958,
        565,
        307,
        797,
        958,
        6984,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34072449803352356,
      "compression_ratio": 1.677725076675415,
      "no_speech_prob": 0.13685201108455658
    },
    {
      "id": 407,
      "seek": 126000,
      "start": 3762.61,
      "end": 3764.61,
      "text": " That's the topic",
      "tokens": [
        50964,
        663,
        311,
        264,
        4829,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34072449803352356,
      "compression_ratio": 1.677725076675415,
      "no_speech_prob": 0.13685201108455658
    },
    {
      "id": 408,
      "seek": 126000,
      "start": 3764.61,
      "end": 3766.61,
      "text": " Code Retreat.",
      "tokens": [
        51064,
        15549,
        11495,
        620,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34072449803352356,
      "compression_ratio": 1.677725076675415,
      "no_speech_prob": 0.13685201108455658
    },
    {
      "id": 409,
      "seek": 126000,
      "start": 3766.61,
      "end": 3768.61,
      "text": " Marco Emmerich and I will",
      "tokens": [
        51164,
        26535,
        3968,
        936,
        480,
        293,
        286,
        486,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34072449803352356,
      "compression_ratio": 1.677725076675415,
      "no_speech_prob": 0.13685201108455658
    },
    {
      "id": 410,
      "seek": 126000,
      "start": 3768.61,
      "end": 3770.61,
      "text": " sit at the computer together.",
      "tokens": [
        51264,
        1394,
        412,
        264,
        3820,
        1214,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34072449803352356,
      "compression_ratio": 1.677725076675415,
      "no_speech_prob": 0.13685201108455658
    },
    {
      "id": 411,
      "seek": 126000,
      "start": 3770.61,
      "end": 3772.61,
      "text": " Marco can actually",
      "tokens": [
        51364,
        26535,
        393,
        767,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34072449803352356,
      "compression_ratio": 1.677725076675415,
      "no_speech_prob": 0.13685201108455658
    },
    {
      "id": 412,
      "seek": 126000,
      "start": 3772.61,
      "end": 3774.61,
      "text": " encode on the computer.",
      "tokens": [
        51464,
        2058,
        1429,
        322,
        264,
        3820,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34072449803352356,
      "compression_ratio": 1.677725076675415,
      "no_speech_prob": 0.13685201108455658
    },
    {
      "id": 413,
      "seek": 126000,
      "start": 3774.61,
      "end": 3776.61,
      "text": " We will show together",
      "tokens": [
        51564,
        492,
        486,
        855,
        1214,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34072449803352356,
      "compression_ratio": 1.677725076675415,
      "no_speech_prob": 0.13685201108455658
    },
    {
      "id": 414,
      "seek": 126000,
      "start": 3776.61,
      "end": 3778.61,
      "text": " how such a Code Retreat works.",
      "tokens": [
        51664,
        577,
        1270,
        257,
        15549,
        11495,
        620,
        1985,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34072449803352356,
      "compression_ratio": 1.677725076675415,
      "no_speech_prob": 0.13685201108455658
    },
    {
      "id": 415,
      "seek": 128800,
      "start": 3778.61,
      "end": 3780.61,
      "text": " This is a story from the software craftsmanship area.",
      "tokens": [
        50364,
        639,
        307,
        257,
        1657,
        490,
        264,
        4722,
        8448,
        10817,
        27140,
        1859,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3579975962638855,
      "compression_ratio": 1.5118483304977417,
      "no_speech_prob": 0.3023679554462433
    },
    {
      "id": 416,
      "seek": 128800,
      "start": 3780.61,
      "end": 3782.61,
      "text": " It's about things like",
      "tokens": [
        50464,
        467,
        311,
        466,
        721,
        411,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3579975962638855,
      "compression_ratio": 1.5118483304977417,
      "no_speech_prob": 0.3023679554462433
    },
    {
      "id": 417,
      "seek": 128800,
      "start": 3782.61,
      "end": 3784.61,
      "text": " system development, refactoring",
      "tokens": [
        50564,
        1185,
        3250,
        11,
        1895,
        578,
        3662,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3579975962638855,
      "compression_ratio": 1.5118483304977417,
      "no_speech_prob": 0.3023679554462433
    },
    {
      "id": 418,
      "seek": 128800,
      "start": 3784.61,
      "end": 3786.61,
      "text": " and all these things",
      "tokens": [
        50664,
        293,
        439,
        613,
        721,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3579975962638855,
      "compression_ratio": 1.5118483304977417,
      "no_speech_prob": 0.3023679554462433
    },
    {
      "id": 419,
      "seek": 128800,
      "start": 3786.61,
      "end": 3788.61,
      "text": " to practice.",
      "tokens": [
        50764,
        281,
        3124,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3579975962638855,
      "compression_ratio": 1.5118483304977417,
      "no_speech_prob": 0.3023679554462433
    },
    {
      "id": 420,
      "seek": 128800,
      "start": 3788.61,
      "end": 3790.61,
      "text": " This is a bit of a preview",
      "tokens": [
        50864,
        639,
        307,
        257,
        857,
        295,
        257,
        14281,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3579975962638855,
      "compression_ratio": 1.5118483304977417,
      "no_speech_prob": 0.3023679554462433
    },
    {
      "id": 421,
      "seek": 128800,
      "start": 3790.61,
      "end": 3792.61,
      "text": " of the Global Day of Code Retreat,",
      "tokens": [
        50964,
        295,
        264,
        14465,
        5226,
        295,
        15549,
        11495,
        620,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3579975962638855,
      "compression_ratio": 1.5118483304977417,
      "no_speech_prob": 0.3023679554462433
    },
    {
      "id": 422,
      "seek": 128800,
      "start": 3792.61,
      "end": 3794.61,
      "text": " which is on the 8th and 11th.",
      "tokens": [
        51064,
        597,
        307,
        322,
        264,
        1649,
        392,
        293,
        2975,
        392,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3579975962638855,
      "compression_ratio": 1.5118483304977417,
      "no_speech_prob": 0.3023679554462433
    },
    {
      "id": 423,
      "seek": 128800,
      "start": 3794.61,
      "end": 3796.61,
      "text": " That means it's a bit of an appetizer",
      "tokens": [
        51164,
        663,
        1355,
        309,
        311,
        257,
        857,
        295,
        364,
        16159,
        6545,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3579975962638855,
      "compression_ratio": 1.5118483304977417,
      "no_speech_prob": 0.3023679554462433
    },
    {
      "id": 424,
      "seek": 128800,
      "start": 3796.61,
      "end": 3798.61,
      "text": " for it.",
      "tokens": [
        51264,
        337,
        309,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3579975962638855,
      "compression_ratio": 1.5118483304977417,
      "no_speech_prob": 0.3023679554462433
    },
    {
      "id": 425,
      "seek": 128800,
      "start": 3798.61,
      "end": 3800.61,
      "text": " Thank you very much and see you there.",
      "tokens": [
        51364,
        1044,
        291,
        588,
        709,
        293,
        536,
        291,
        456,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3579975962638855,
      "compression_ratio": 1.5118483304977417,
      "no_speech_prob": 0.3023679554462433
    }
  ],
  "language": "english"
}