{
  "text": "Netflix keine bauenden Kontexte mehr benutzt und da will ich mich bedanken halt einmal bei dem Nico Stotz, der beim Software-Architektur im Stream Slack das Thema aufgebracht hat und außerdem hatte ich eine Person, mit der ich gesprochen hatte nach meinem Talk beim VR Developers World Congress, die mich auch noch meine Einschätzung von diesem Paper gefragt hat und beide haben, glaube ich, da den Eindruck, dass dieses Paper einen Widerspruch erzeugt zu eben unabhängigen Microservices und sowas wie Bauen und Kontexten, also unabhängiger Datenmodellierung und das ist so ein bisschen die Richtung, in die das Ganze halt geht und das ist insbesondere deswegen halt interessant, weil eben Netflix einer der Pioniere ist in diesem Bereich von den Microservices und natürlich an der Stelle, wo jetzt einer von den Pionieren sagt, das passt halt irgendwie nicht mehr, ist das halt etwas, was natürlich auf Interesse stößt. Ich werde kurz sozusagen so ein bisschen so eine Motivation geben, also warum ist das mit dem Bauen und Kontext ein Thema, warum ist das mit dem Modell ein Thema, was sind so Alternativen, wie orte man das halt insgesamt ein. Dann werde ich den Blogpost von Netflix tatsächlich diskutieren und dann das Ganze noch mal bewerten und ich freue mich natürlich irgendwie auf eure Fragen und Kommentare, die ihr sehr gerne in dem Chat oder in dem Formular auf der Homepage hinterlasten könnt. Also legen wir los. Was ist die Geschichte mit diesen Bauen und Kontexten und den Modellen? Also das ist etwas, was sich so ein bisschen durch die, mittlerweile seit glaube ich einem Jahr, durch den Stream zieht. Es gab halt einmal diese Episode, die gesagt hat, naja, Bauen und Kontext bedeutet eben, hat eigentlich so drei Dinge, die das halt irgendwie repräsentiert. Das ist zum einen so ein Modell, also irgendetwas, wo ich halt hingehe und ich sage, ich habe eine Funktionalität, also zum Beispiel irgendetwas, was halt sagt, wie kriege ich halt eine Bestellung zum Kunden geliefert, sowas in dem Dreh. Dafür brauche ich ja ein Modell. Das heißt also, ich muss jetzt wissen, welche logistischen Möglichkeiten habe ich, Sachen halt zum Kunden zu bekommen. Ich muss wissen, welche Waren habe ich, wie kann ich die verschicken, sollen die versichert verschickt werden oder nicht, sind die teuer oder billig, wenn sie teuer sind, sollen sie versichert verschickt werden und so weiter und so weiter. So und das ist eben dieser Modellcharakter von den Bauen und Kontexten. Dann gibt es noch diese Sprache. Das heißt also, in unterschiedlichen Kontexten können Dinge unterschiedlich definiert sein. Und mein Beispiel dafür, was ich in letzter Zeit öfter benutze, ist halt der Hotelkunde. Also wer ist der Kunde eines Hotels? Und ich würde behaupten, wenn ich über den Check-in spreche, dann ist das natürlich eine Person, so wie ich, Eberhard. Und wenn ich halt über sowas wie die Rechnungslegung spreche, dann ist das vielleicht mein Arbeitgeber, nicht die SwagClub GmbH. Und die kann definitiv niemals in einem Hotel einchecken, weil es ist eben keine natürliche Person. Und dann habe ich halt irgendwie noch, wer auch immer das bezahlt. Also ich bezahle das vielleicht selber, bezahle vielleicht für meinen Kollegen mit und dann habe ich eben drei verschiedene Modelle. Also ich habe den Check-in, da bin ich und mein Kollege sind dort der Kunde, dann gibt es halt die Bezahlung, da bin ich vielleicht die Person, die es bezahlt mit meiner Kreditkarte, auch für meinen Kollegen. Und dann haben wir eben noch das Modell für die Rechnungslegung, wo wir sagen, die SwagClub GmbH ist der Kunde. Das heißt also, abhängig davon, über welchen Kontext wir reden, über welches Modell wir reden, sind bestimmte Sachen unterschiedlich definiert. Also Kunde kann eben unterschiedliche Dinge sein. Und da ist auch noch wichtig, wir reden halt dort über Logik. Also wir haben ein Modell, was es mir erlaubt, dass sich irgendjemand eincheckt oder dass jemand in eine Rechnung geschickt wird. Das ist Logik. Da ist nämlich Logik drin. Vielleicht darf ich nicht einchecken, weil ich bin minderjährig oder was auch immer. Und das ist eigentlich der Kern. Wir wollen also Logik aufteilen in verschiedene Modelle. Dafür brauchen wir halt unterschiedliche Daten. Davon getrennt ist so ein bisschen die Geschichte mit der Sprache. Man kann eben manchmal beobachten, dass wenn Menschen über verschiedene Dinge reden, also in diesem Fall über den Kunden, unterschiedliche Dinge meinen. Der Kunde ist halt vielleicht die SwagClub GmbH. Vielleicht ist es halt auch eben eine natürliche Person. Das ist so der andere Aspekt. Also dass sprachliche Definitionen unterschiedlich sind. Die Modelle sind ein Aspekt. Und dann ist der dritte Aspekt diese Geschichte, dass sich eben ein Bauen im Kontext einem Team geben kann. Also auch über Teams ist das letztendlich eine Aussage, dass es ein Team bekommt, das typischerweise mit einem Bauen im Kontext zu tun. Und damit ist das eben auch dort relevant. Also habe ich diese drei Ebenen Modelle, Sprache und Teams. Darüber hatte ich eben in dieser einen Episode gesprochen, wo es darum geht, was ist eigentlich Bauen im Kontext. Und ich habe dann noch eine Episode nachgeschoben, wo ich gesagt habe, eigentlich ist es mit den Modellen spannend und diese Modelle zu finden. Das ist so ein bisschen die Kernerausforderung von Softwarearchitektur. Und ich habe versucht ein paar Röstling anzugeben, wie man so etwas auf die Reihe bekommen kann. Der Urs Enzler bei LinkedIn hatte vorher auch schon gesagt, dass eben Modelle für ihn sozusagen das Wichtigste sind bei dieser Aufteilung. Das würde ich auch so sehen. Aus einer Softwarearchitektur-Frage ist das eben tatsächlich das Wichtigste. Und da kommen wir jetzt her. Das heißt also, wir wollen heute diskutieren, ob Netflix tatsächlich nur ein Modell nutzt. Und das ist eigentlich erstaunlich, weil es wäre erstaunlich, wenn das so wäre. Weil wenn man an dem Hotelbeispiel sieht, mehrere kleine Modelle sind eigentlich das, worauf es halt typischerweise hinausläuft und was eben typischerweise sozusagen der sinnvolle Ansatz ist. Weil wir jetzt in so eine Situation kommen, wo wir halt über potenziell ein Datenmodell reden, das halt sozusagen universell ist. Da gibt es halt von dem leider verstorbenen Stefan Tilkoff diesen Blogpost, den ich auch nochmal verlinke, wo er über diese kanonischen Datenmodelle spricht. Das ist so ein Thema aus SOA, was eben ein Architekturansatz ist, der so vor 20 Jahren ein relevanter Architekturansatz war. Und dort sagt er, ich kann jetzt versuchen, zum Beispiel eben den Kunden zu modellieren. Einmal für alle. Da sagt er, das ist halt schwierig. Einmal deswegen aus diesen konzeptionellen Unterschiedlichkeiten, die er in unterschiedlichen Situationen haben kann für einen Kunden. Beim Check-In ist es eben immer anders als bei der Rechnungslegung. Er macht noch den Punkt, dass es halt die Teamautonomie einschränkt, weil die Teams eben nicht unabhängig voneinander die Modellierung durchführen können. Und er spricht auch noch darüber, das sind die beiden Punkte, die er irgendwie sieht als Schwierigkeiten. Und er gibt dann als Tipp zu sagen, dass man unabhängige Teile von verschiedenen Teams definieren lassen sollte, weil die dann eben jeweils unabhängig voneinander die Sachen für diese Art relevant sind, selber modellieren kann. Ich kann, wenn, dann vielleicht nur Fragmente standardisieren, wo das sinnvoll ist. Ich sollte insbesondere nicht das zentrale Modell in die Teams runterpushen. Und er sagt insbesondere auch noch, dass so ein zentrales Modell, dass man da sozusagen versuchen kann, Aufwand zu sparen, dass das eine mögliche Motivation ist und dass das eben auch kontraproduktiv ist. Das heißt also, er sagt halt, diese Motivation mit dem Aufwand sparen, das wird man typischerweise halt nicht hinbekommen, weil eben dieses universelle Modell zu bauen schwierig oder kaum möglich ist. Das heißt also, aus der Perspektive würden wir jetzt erwarten, wenn wir halt ein Datenmodell haben, das übergreifend ist, haben wir Einschränkungen von Autonomie, hohen Aufwand, Probleme, weil es konzeptionell schwierig ist und es sollte insgesamt schief gehen. Ich bin da mit Stefan einer Meinung und das ist halt auch einer der Gründe, weswegen das sich erst mal so ein bisschen komisch anhört. Jetzt gibt es halt im Bereich Domain-Driven Design durchaus Patterns, die ein bisschen in so eine Modellierung von einem gemeinsamen Modell gehen. Ein Beispiel ist die Published Language. Published Language bedeutet, dass ich irgendwo einen wohl definierten, publizierten Datendarstellung habe und zwar ist das eine gemeinsame Sprache, mit der ich dann dafür sorgen kann, dass wir uns für die Kommunikation zwischen zwei Bauenden Kontexten auf irgendeine gemeinsame Sprache einigen. Der ist halt getrennt von den internen Modellen. Das heißt also, potenziell könnten wir jetzt sagen, wir bauen eine Schnittstelle. Nehmen wir mein internes Modell? Nein. Nehmen wir dein internes Modell? Nein. Wir bauen also ein gemeinsames Modell. Das wäre dann die Published Language und das könnten wir auch höher skalieren. Das heißt, wir könnten jetzt auch sagen, wir bauen halt so eine Published Language, die für mehrere Parteien relevant ist. Das heißt also, da hätte ich jetzt ein Datenmodell. Das wäre etwas, was sich mehrere teilen. Ein Realist schreibt schon, man braucht ein anständiges und wirksames Ontology-Management. Bei Netflix läuft das tatsächlich ein bisschen in diese Richtung, dass ich dort Begriffe definiere und versuche, die hin und her zu mappen. Das ist also etwas, was ich dann brauche für diese Übersetzung. Ein anderer Bereich, was für mich nicht ganz in so ein gemeinsames Datenmodell geht, aber schon etwas ist, was man diskutieren muss, sind diese Data Products bzw. Data Meshes, wo ich jetzt sage, ich habe irgendwelche Informationen, also zum Beispiel Informationen aus dem Check-in von einem Hotel und ich sage jetzt, diese Information von dem Check-in biete ich jetzt an zur Analyse. Vielleicht ist es so, dass ich glaube, dass der exakte Check-in-Zeitpunkt relevant ist oder das Geschlecht oder das Alter oder was weiß ich. Dann baue ich so einen Datenexport zusammen, mit dem ich dann diese Daten zur Analyse bereitstellen kann, sodass ein anderes Team oder irgendwelche Business Intelligence Leute diese Daten analysieren können. Das ist typischerweise eher so auf der Schnittstellen-Ebene. Vielleicht exportiere ich die Daten in einen S3-Bucket und dadurch vermeide ich, dass Leute jetzt hinter meinem Rücken in meiner Datenbank meine Daten auslesen, sondern ich ziehe das auf eine Schnittstellen-Ebene. Sprich, wenn ich jetzt mein internes Datenmodell ändere, kann ich ja trotzdem das Datenmodell für den Export konstant halten und gleichzeitig ist es so, dass die Leute, die die Daten analysieren, die Möglichkeit haben, Dinge zu analysieren, an die ich vorher vielleicht noch nicht gedacht habe, weil sie eben diese Datenprodukte kombinieren können, sich anschauen können und dort dann eben entsprechend Möglichkeiten haben, das zu tun, was sie tun wollen, was vielleicht vorher gar nicht planbar ist. Wenn ich vorher sagen kann, okay, exakt diese Daten will ich analysieren, das ist ja einfach, wird dann schwierig, wenn ich sage, ich weiß nicht so genau, welche Daten ich analysieren will, gibt mir sozusagen alles und sowas könnte ich jetzt hier so ein bisschen umsetzen. Das also so ein bisschen zum Einschwingen. Wir haben jetzt eigentlich folgende Aussagen. Wir erwarten, dass wir typischerweise in Softwareentwicklung eine Vielzahl an Modellen haben das ist vorteilhaft. Wenn wir das nicht haben, werden wir hohe Aufwände haben, die Dinge zu koordinieren. Wir werden Schwierigkeiten haben, vernünftige Datenmodelle zu erzeugen, den Kunden für das Hotel einmal zu modellieren, dass er eben alle drei Benutzungen irgendwie abdeckt, ist schwierig, würde ich auch nicht wollen, macht auch konzeptionell wenig Sinn. Ich hätte dort ein Problem, Autonomie, die Konzepte, dass die nicht funktionieren. Und ich kann aber durchaus für Kommunikation und für Datenanalyse dazu kommen, dass ich ein Datenmodell habe, das so eine Art globalen Standard möglicherweise darstellt. Published Language und ein Data Product können in diese Richtung gehen. Das ist so ein bisschen das, wo wir herkommen. Der Netflix Blog hat eben diesen schönen Titel, Model once represent everywhere, also nicht, modelliere einmal und die Repräsentationen sind überall und nennt halt die Unified Data Architecture dort als das Schlagwort. Netflix, mittlerweile breit bekannt, ist ein Online-Videodienst, wo ich also nicht Online-Videos gucken kann. Die sind deswegen interessant, weil sie ein Microservices-Pionier waren und zwar schon so lange, dass ich am Anfang, als ich über Netflix gesprochen habe, noch immer erwähnen musste, was das überhaupt ist, weil sie gar nicht in Deutschland präsent sind. Mittlerweile ist es ja deutlich anders. Ein sehr erfolgreiches Unternehmen unter dem Fortune 500 und ist eben dort, also aus diesem Grund glaube ich, interessant, weil es eben dieses Microservices und dieses unabhängige Zeug, unabhängige Teams, autonome Teams und so weiter gepredigt hat, zumindest zu dem Zeitpunkt und weil hier jetzt zumindest wahrgenommen Widerspruch ist. Was hier also letztendlich passiert ist, sowas wie, ich habe mir aufgeschrieben, eine Änderung an der Architektur. Ich bin mir gar nicht sicher, ob das stimmt. Eigentlich ist es eine Architekturentscheidung. Also wir haben eine Architekturentscheidung, die irgendwie sagt, wir wollen ein gemeinsames Datenmodell haben. Und um das sozusagen zu bewerten, ist es halt, finde ich, wichtig, erstmal herauszufinden, was sind eigentlich die Gründe. Also wenn ich eine Architekturentscheidung treffe, dann sollte ich die halt irgendwie begründen und ich sollte sie anhand der Begründung auch bewerten. Also nur, weil ich mich jetzt irgendwie hinstelle oder sich jemand hinstellt und sagt, wir bestreiten die Autonomie der Teams. Das sollten wir nicht machen. Es kann ja Gründe geben, warum ich das doch machen möchte. Und vielleicht ist in diesem spezifischen Fall die Autonomie der Teams gar nicht so schlimm, wird nicht so stark eingeschränkt. Das heißt also, ich muss mir die Frage stellen, was ist denn eigentlich das Ziel? Warum treffe ich diese Entscheidung? Und anhand dieser Kriterien sollte ich es anschließend bewerten. So das Paper fängt halt auch tatsächlich damit an und sagt halt, das Problem, das wir haben, ist, dass sowas wie ein Actor, also ein Schauspieler oder ein Movie, also ein Film mehrfach modelliert ist. Und zwar in einer GraphQL-Gateway für die internen Anwendungen, im Asset Management, im Media Computing, wo also Sachen irgendwie encoded werden. Und die modellieren das leicht unterschiedlich, mit wenig Koordination oder gemeinsamen Verständnis. Oft haben sie dieselben Konzepte, aber sie wissen es nicht. Ich würde jetzt erstmal behaupten, das ist keine vernünftige Begründung, weil das ist sicher irgendwie, wie soll ich sagen, suboptimal. Das wünscht man sich vielleicht anders, gerade wenn man so ingenieursmäßig vorgeht. Aber bis jetzt habe ich noch nicht verstanden, was sozusagen für BenutzerInnen oder irgendwelche anderen Stakeholder konkrete Nachteile sind. Es ist im Gegenteil so, wenn ich Sachen mehrfach modelliere, aus dem, was ich vorher gesagt habe, kann es eben sein, dass es einen guten Grund dafür gibt, nämlich höhere Autonomie und dass es in Wirklichkeit unterschiedliche Konzepte sind. Das heißt also, auf dieser Ebene ist es jetzt erstmal so, dass ich noch nicht so richtig sehen kann, was eigentlich das Problem ist. Also doppelte und inkonsistente Modelle sind, glaube ich, nicht das Problem. Dann haben sie als weiteres Thema halt inkonsistente Terminologie dargestellt. Das finde ich auch schwierig, denn wir haben es gerade eben bei dem Kunden von dem Hotel diskutiert. Der Kunde des Hotels ist eben unterschiedlich, je nachdem, in welchem Kontext ich ihn betrachte. Das erwarte ich halt. Das heißt also, diese inkonsistente Terminologie ist nicht etwas, was ich einfach abschalten kann, wenn ich mich auf etwas einige. Sondern es ist eben so, dass der Kunde, der eincheckt, was anderes ist als der Kunde, der hat die Rechnung bezahlt oder die Rechnung bekommt. Das bedeutet, diese inkonsistente Terminologie ist eben ein Teil, eine Auszeichnung der Modellierung meines Systems. Das ist also auch ein schwieriges Thema und dem könnte ich jetzt auch zum Beispiel begegnen, indem ich beispielsweise im Kloß H schreibe, indem ich sage, das ist der Begriff und so sind die Synonyme oder dieser Begriff in den verschiedenen Bauern und Kontexten hat unterschiedliche Bedeutungen. Das ist nichts, wo ich jetzt erstmal unbedingt Architekturmaßnahmen brauche. Zwei Punkte, die ich interessant finde und nachvollziehbar sind. Einmal Datenqualität. Also, dass diese Sachen auseinanderlaufen und Referenzen manchmal kaputt sind. Also, dass Systeme auf Daten in anderen Systemen verweisen, die nicht mehr dort sind. Das kann ein Thema sein. Es ist aber immer noch nicht so, dass ich jetzt… Also, idealerweise würde ich mir wünschen, dass man sagt, an genau dieser Stelle hat irgendein Benutzer, irgendein Stakeholder ein echtes Problem gehabt und das können wir jetzt lösen. Datenqualität an sich ist erst dann ein Problem, wenn daraus irgendwelche Dinge hervorgehen, die wirklich Benutzer oder Stakeholder vor irgendwelche Schwierigkeiten stellen. Hier ist es für mich eher nachvollziehbar und das würde ich vielleicht abstellen. Es fehlt vielleicht nur die Information, die sagt, an dieser Stelle ist das ein Problem. Und dann haben sie noch aufgeschrieben, dass es wenig Verbindungen über Systeme hinweg gibt. Das könnte eventuell auch ein Thema sein, dass ich Schwierigkeiten habe, von einem System zu einem anderen zu kommen und dort mehr Details zu finden. Interessant ist hier, dass diese Themen, die eigentlich relevant sind, also Autonomie, Aufwand und so weiter, hier gar nicht diskutiert worden sind. Das heißt, es steht nirgendwo, ja, und dafür nehmen wir in Kauf, dass die Teams weniger autonom sind. Das steht da nicht drin. Es ist für mich schwer nachvollziehbar, wie gravierend diese Probleme sind. Ist da irgendwo etwas, wo wir jetzt einen Umsatzverlust haben oder irgendein Ansehensverlust oder irgendwelche Schwierigkeiten in dieser Richtung? Das steht da nicht drin. Kann man aber auch nicht erwarten, weil es ist ein Blogpost und der Blogpost wird ja jetzt nicht sagen, wir haben übrigens massive Schwierigkeiten. Und weil wir diese massiven Schwierigkeiten haben, haben wir folgende Entscheidung getroffen. Also es wird kein Mensch sozusagen öffentlich zuzugeben, logischerweise. Die Lösung ist jetzt zu sagen, wir definieren einmal ein Modell und verwenden es überall wieder. Und das wollen wir machen mit mehr als Dokumentation, nicht nur als Dokumentation, sondern wir wollen tatsächlich Schemata generieren, Konsistenz erzwingen und so weiter. Das erste Interessante ist, dass genau genommen diese Sache halt nur genutzt wird für Content Engineering. Content Engineering ist ein Bereich, den Netflix seit 2020 hat, damit deutlich nach den Netflix Microservices Bedeutet das, dass wir nur ein Modell haben sollen? Es könnte halt sein, dass wir halt ein bauenden Kontext haben mit einem Modell, nämlich Content Engineering und das halt aus diesem Grund dieses eine Modell sozusagen funktioniert und das bedeutet auch, dass sie vielleicht gar nicht so viel Legacy-Themen haben. Also seit 2020, gut, sind immerhin fünf Jahre, aber es ist ein relativ neues Thema und es ist halt auch deswegen ein neues Thema, weil eben Netflix noch nicht so lange, so jedenfalls meine Wahrnehmung selber, Content tatsächlich produziert. Die haben ja früher halt nur Dinge vertrieben. So und der Geschäftsprozess, der dort irgendwie abgebildet wird, ist halt sowas wie ein Pitch, wo man also sagt, das ist halt eine tolle Serie, dann halt eine Business Negotiation, wo man also darüber diskutiert, wie man die halt irgendwie produzieren kann, nehme ich an, dann Pre-Production, Production, Post- Production und schließlich Launch. Das heißt also, wir nehmen nur dieses Thema aus dem gesamten Netflix-Universum raus. Das heißt also, an der Stelle, wo das Ding live gegangen ist, ist da Schluss. Was also bedeutet, dass wir wahrscheinlich, vielleicht nicht über ein unternehmenswertes Modell sprechen. Ich bin mir auch nicht sicher, wie sehr wir über Legacy-Transformation sprechen, also ob wir darüber reden, dass wir alte Systeme modernisieren wollen. Das wäre ja etwas, was sozusagen echten Umschwung wäre, oder nicht? Wo man jetzt sagen würde, okay, wir haben halt Microservices gemacht, wir haben halt dezentral irgendwelche Sachen modelliert, das war eine blöde Idee, wir machen jetzt dieses zentrale Modell. Das ist eigentlich nicht erkennbar, weil das eben ein relativ neuer oder anderer Bereich ist, als der den Netflix zumindest 2015 hatte. Mir ist noch nicht ganz, also ich habe immer noch so ein Problem damit zu verstehen, was eigentlich genau das Problem ist, das gelöst werden soll. Und ich kann es so ein bisschen spoilern. Ich würde behaupten, dass das Problem, das eigentlich gelöst wird, ein ganz anderes ist. Aber das sollten wir dann noch mal diskutieren. So, jetzt ist halt die Frage, was macht dieses UDA-Ding? Und ich muss mal kurz schauen. Genau, das wollte ich zeigen. Da kann man sich halt ein bisschen an der ersten Grafik orientieren, die die halt gebaut haben. Und da ist es halt letztendlich so, dass man sagt, okay, wir haben ein Domainmodell in der Mitte, das mappen wir auf verschiedene Repräsentationen. Da gibt es zum einen eine Repräsentation in Apache Iceberg, das ist so eine Big-Data-Lösung, wo man also offensichtlich Analyse mit betreiben kann, GraphQL-Repräsentation für irgendwelche Datencontainer. Und unten haben wir dann halt auch eine Mapping-Richtung Data Mesh. Das fand ich besonders interessant. Also das heißt, eine Lösung, Data Mesh-Lösung für Datenprodukte ist eigentlich schon in Benutzung und ist eben eines der Mapping- Ziele. Und man will jetzt mit diesem System Content-Domain-Modelle registrieren können und umsetzen können. Und die halt entsprechend auch die Schemata übertragen können in Richtung von GraphQL Afro. Afro ist dieses Format, was zum Beispiel im Apache Kafka-Kontext genutzt wird. Was halt so rückwärtskompatible Möglichkeiten hat. Also wo ich halt dann tatsächlich dafür sorgen kann, dass ich halt Daten in einem alten Format bekomme, obwohl sie in einem neuen Format vorliegen. Also mit einem integrierten Converter. Dann sowas wie SQL, was bei Iceberg bei sich eine Rolle spielt, sowas wie RDF. Dazu kommen wir später nochmal. Oder auch eine Java-Repräsentation. Das ist halt das, was wir jetzt irgendwie bauen wollen. Oder was die halt gebaut haben. Dann wollen sie halt Daten transportieren vom GraphQL in Richtung zu dem Data Mesh zum Beispiel. Dann, dass sie halt irgendwie die Möglichkeit haben, über Change Data Capture, also wenn irgendwie Daten geändert werden, das halt in die Iceberg-Datenprodukte reinzubekommen. Solche Geschichten. Und sie wollen dann eine Möglichkeit anbieten, um Domain-Konzepte zu finden und zu untersuchen durch Queries oder andere und Grafen. Und auch programmatisch halt diesen Grafen sozusagen untersuchen. So und damit ist eigentlich das Ziel, was sie jetzt da tatsächlich verfolgen, eine Daten-Integration. Wo sie also im Prinzip sagen, wir wollen halt Daten aus verschiedenen Bereichen vernetzen, in einen großen Datengrafen reinbekommen. Diese ganzen Daten darüber eine gemeinsame Sicht anbieten und dafür sorgen, dass wir darüber halt arbeiten können. Was für mich da hinweist, dass das eigentliche Thema, was sie da haben, ein Datenanalyse-Thema ist. Also sie wollen, glaube ich, irgendwie eine Oberfläche irgendwelchen Menschen anbieten, die ja Domain-Expertinnen sind und dafür sorgen, dass die dann einheitlich auf diese verschiedenen Datenquellen zugreifen können. Und das ist die Richtung, in die sie halt erstmal, glaube ich, marschieren wollen. Und das ist was anderes. Also das Problemsetting war ja nicht, wir haben ganz viele Datencontainer und wir können die Daten nicht analysieren, sondern die Aussage war, naja, unsere Datenqualität und diese Sachen sind halt ein bisschen schwierig. Und damit ist das nach meinem Empfinden eben eigentlich ein Daten-Integrationsthema, ein Analyse-Thema und halt auch etwas, wo diese Data-Products wieder eine Rolle spielen. Und ohne jetzt sozusagen der endgültigen Diskussion vorgreifen zu wollen, bedeutet das, dass halt diese Aussage, ich habe einzelne Systeme, die getrennte Modelle haben, das steht da, glaube ich, gar nicht so im Kern dahinter, dass man jetzt davon eine Abkehr irgendwie haben wird. Und genau, das heißt, sie wollen jetzt so Knowledge-Graphen bauen, wo sie eben diese ganzen Sachen gemeinsam miteinander vernetzen. Dafür benutzen sie RDF, dieses Resource Description Framework. Das ist etwas, was ist bei B3 schon lange gibt, also beim B3C, so für dieses Semantic Web Zeug, was ich glaube sogar schon in den 90ern ein Thema war, wo ich also so Aussagen formalisiert treffen kann über Ressourcen, Subjekte, Prädikate und Objekte. Sowas, also das Beispiel, was wir im Text nennen, ist ECMI produziert Batterien. Das heißt also, das Subjekt ist ECMI und das Prädikat ist produziert und das Objekt ist Batterien, nicht? Also grammatikalisch falsch, aber das stellt einen Zusammenhang hin hier zwischen Batterien und ECMI und zwar, wie wir diesen Zusammenhang produzieren. Und das ist jetzt eben etwas, also das Wikipedia-Beispiel für RDF und das ist jetzt etwas, was ich natürlich nutzen kann, um irgendwie so Anthropologien und solche Sachen aufzubauen, wo ich Begriffe in Verbindung miteinander setze. Und sie haben dann diese Shape Constraint Language, SHACL heißt die, die jetzt irgendwie noch weiter auf diesen RDF-Grafen Constraints einführen kann. Und das ist jetzt etwas, was vielleicht, wo ich mir nicht sicher bin, ob es für die Architekturdiskussion relevant ist. Aber es ist halt etwas, wo wir jetzt Semantik von Daten sozusagen einfangen können. Und ich hatte es vorhin schon gesagt, ein Realist hat es eben auch schon kurz gesagt, ich brauche halt irgendwie solche semantischen Dinge, um jetzt Anthropologien zu haben und um unsere Mapping halt irgendwie auf die Reihe zu bekommen. So und sie haben jetzt verschiedene Bestandteile des Systems. Da gibt es einmal das Primary Data Management, PDM. Da gibt es diese Referenzdaten und diese Taxonomien drin. Das heißt, da steht jetzt irgendwie drin, was halt semantisch wie rot modelliert ist. Und das generiert eine UI für Business-Anwender in. So und da ist wieder die Geschichte. Also wenn ich sozusagen nur das Problem anschaue. In dem Problem steht nichts von Analyse. Hier ist aber eine Lösung, die hat offensichtlich auf Analyse abzielt. Das heißt also wahrscheinlich ist das Problem eher, ich will irgendwie Daten analysieren, will halt irgendwelchen Business-ExpertInnen die Möglichkeit geben, diese ganzen Daten anzuschauen. Und das kann im Moment Afro und GraphQL, also eben nur zwei Plattformen. Das heißt also, die sind halt auch noch in der Implementierung. Dann haben sie als weiteres Produkt Sphere. Das ist also nicht die Kugel. Das ist ein System, mit dem Sie, mit dem Business-ExpertInnen sich selbst Reports zusammenbauen können. Und das katalogisiert uns als Business-Konzepte wie im Actor oder Movie sozusagen zueinander in Beziehung. Traversiert dann halt diesen Knowledge-Graphen, der da ist. Das heißt also, da habe ich jetzt irgendwie diese gesamte Oberfläche mit den verschiedenen Daten. Da habe ich diesen Knowledge-Graphen, den kann ich jetzt über das Sphere benutzen, um halt irgendwelche Reports zu machen. Und daraus generiert das System dann SQL Queries. Und das ist halt wieder eine Geschichte, die halt irgendwie eher Datenanalyse bedeutet. Wo dann für mich wieder die Frage ist, also warum nicht Data Meshes und Datenprodukte dort haben? Also warum brauche ich nicht ein System, wo ich halt diese ganzen Daten einfach rein exportiere und dann irgendwie anschließend Reports drüber fahren lassen kann? Keine Ahnung. So, dann haben Sie eine eigene Sprache, um Domänen zu modellieren. Die nennt sich APPA. Da haben Sie Schlüsselattribute und die Beziehungen dazwischen, in Beziehung zu anderen Entitäten. Die sind dann in Taxonomien organisiert. Und da gibt es halt ein Beispiel. Das ist das hier. Mal kurz schauen, dass ich das richtig hinbekomme. Genau, also da ist es halt so, dass wir jetzt sehen, einen One Piece Charakter. One Piece ist so ein Manga, war mir vorher irgendwie auch nicht bekannt. Und da gibt es einen Devil Fruit. Das ist also eine bestimmte Frucht, die so einen Charakter typischerweise hat oder den repräsentiert. Und da habe ich diese Beziehung Devil Fruit dazwischen. Und dann gibt es halt darunter noch den Devil Fruit Type. Das ist, glaube ich, ein artifizielles Beispiel. Wir werden nachher noch sehen, dass Netflix tatsächlich mit den echten Beispielen aus dem echten Leben eher vorsichtig ist. Und so kann jetzt also eine Modellierung aussehen. Das bedeutet, ich habe dort jetzt eine Taxonomie und ein Datenmodell gebaut. Das kann ich anschließend auch in eine Sprache übersetzen. Ich erspare uns, da sind Listings drin, aber ich erspare uns, das im Listing sozusagen anzugucken. Es geht darum, das konzeptionell zu verstehen. Und das kann ich dann transpellieren, also übersetzen in Richtung zu GraphQL, Afro, Iceberg oder Java. Und das ist also letztendlich eben so eine generelle universelle Datenrepräsentationssprache, die ich jetzt übersetzen kann auf diese verschiedenen Systeme. Was ich dabei noch interessant finde, ist, dass dieses System die Möglichkeit bietet, diese Domainmodelle zu erweitern, was möglicherweise darauf hindeutet, dass sie eben sozusagen ein gemeinsames Ding definieren und dann einzelnen Teams oder einzelnen Bereichen die Möglichkeit geben, es zu erweitern. Was ja wiederum bedeutet, es gibt nicht das eine übergreifende Modell, sondern eben einen gemeinsamen Kern, den man dann eben entsprechend erweitern kann. Also auch da, das wäre jetzt auch so ein Hinweis. Wir bauen nicht das eine Modell, sondern unterschiedliche Dinge, nur einen gemeinsamen Kern. Und das Nächste, worüber sie dann noch diskutieren, ist das hier. Das ist also so eine Data Container Representation für dieses Data Mesh. Und hier sieht man jetzt also nicht dieser One Piece Charakter. Also One Piece Devil Fruit is a Record. Da gibt es einen Namen und noch einen Namen und die sind nicht nullable. Also dort eben eine Datenbeschreibung, die da dann umgesetzt werden kann. In beispielsweise Afro, wie man hier sieht. So und das kann ich jetzt eben tatsächlich visuell sozusagen mappen. Das heißt also, ich kann jetzt im nächsten Schritt dann sagen, dass ich halt dort irgendwas übersetzen möchte von diesem UDA Properties auf irgendwelchen konkreten Data Assets und habe da die entsprechende Übersetzung. Und hier ist eins der Features, dass die auch haben, dass man die Daten automatisch irgendwo anders hinbewegen kann. Dass ich jetzt sage, okay, ich habe die Daten in GraphQL und ich schmeiße sie jetzt mal irgendwie in Iceberg, damit ich sie da halt dann analysieren kann mit meinem SQL, was vielleicht irgendwie performance mäßig besser ist. So, was eben bedeutet, dass ich durch Transpellieren nicht nur diese verschiedenen Schema-Teile erzeugen kann, sondern dass ich eben auch die Daten hin und her kopieren kann. Und das ist so die wesentliche Idee, die sie dort offensichtlich haben. Beispiele, die sie dann nennen, wo dieses System sozusagen genutzt wird, ist halt einmal dieses Primary Data Management. Da sprechen sie tatsächlich davon, dass sie eben ein kontrolliertes Vokabular umsetzen und zentral definieren. Also was ist wo, wie erlaubt, mit welchen Werten? Und zwar durch irgendwelche Business User In, also nicht durch Techniker In. Und das nutzt auch ein W3C-Standard, nämlich S-Core Simple Knowledge Organization System, worüber jetzt einzelne Nutzer in ihr eigenes Modell mit ihrer eigenen Sprache sozusagen drunter benutzen können. Und offensichtlich diesen S-Core Layer, keine Ahnung wie genau, aber von dem müssen sie noch nicht mal wissen, dass das existiert. Was also auch wieder bedeutet, dass es vielleicht nicht das eine Modell ist, sondern eher so ein Übersetzungs-Ding. Und dann haben sie schönerweise ein Screenshot zu diesem Sphere. Da ist halt bedauerlicherweise alles mögliche irgendwie geschwärzt, sodass man im Prinzip nur Production hier sieht. Das bedeutet, irgendwie kann man da Reports machen, aber was genau wie, das sagt uns Netflix hier halt irgendwie nicht. Und als Ausgangsperspektive oder als weitere Perspektive sagen sie dann, naja, es kann mehr Projections geben, also wir werden mehr Datenformate unterstützen, um da mehr Möglichkeiten zu haben. Zum Beispiel auch sowas wie Protobuf, also dieses binäre, eher effiziente Protokoll oder sowas wie gRPC als weitere Kommunikationsmöglichkeit. Wir werden den Logistik-Graphen materialisieren. Also ich denke mal, dass der dann nicht nur, dass der dann halt als konkrete Datenstruktur vorstellt und weitere Probleme in Bezug auf die Suche über diesen Graphen lösen. So weit Schnelldurchlauf sozusagen dieses Paper. Jetzt ist halt die Frage und damit komme ich sozusagen zu dem dritten Teil. Also was bedeutet das jetzt für uns und was ist eigentlich so das Ergebnis und wie bewerten wir das? Also zurück zu dem Problem. Wenn wir halt tatsächlich diese Lösung bauen, um Datenqualität zu erhöhen, also das Gebanzene aufzulösen, kaputte Referenzen aufzulösen und diese Verbindung zwischen dem System hinzubekommen, dann kann ich mir nicht vorstellen, dass der Aufwand, den man dafür treibt, in einem vernünftigen Verhältnis zu den Nutzen steht. Das heißt also, ich würde behaupten, dieses Problem, was wir ursprünglich genannt haben, ist nicht das Problem. Ich glaube, dass Sie eigentlich eine Analyseplattform bauen wollen und insbesondere Sphere läuft ja auch in diese Richtung. Also ich mache solche Geschichten. Dann haben wir aber eigentlich was anderes gebaut. Wir haben ein System gebaut, mit dem wir Datenanalyse betreiben können. Hier wieder die Beziehung Richtung Data Meshes, Data Products, wo ich also irgendwelche Daten, die ich in dem System habe, so darstellen kann, dass ich sie anschließend analysieren kann. Ich habe jetzt hier eigentlich einen Architekturansatz, der sagt, ich habe verschiedene natürliche Datenrepräsentationen, GraphQL, Afro, whatever. Ich versuche das zu vereinheitlichen mit einer Plattform und eine gemeinsame Sicht darauf anzubieten. Das ist etwas anderes, als wenn ich jetzt jedem Team sagen würde, die Daten, die du hast, da sind Menschen, die sich vielleicht für diese Daten interessieren. Stell denen die doch zur Verfügung und mach das irgendwie. Was der Data Mesh bzw. Data Product Ansatz wäre, so wie ich ihn verstehe. Das heißt, ich habe hier eine Integrationsplattform, die versucht, das alles unter den Hut zu bekommen. In dem anderen Fall hätte ich einen Marktplatz von Daten. Mir gefällt dieser Marktplatz von Daten besser, weil ich dadurch den Teams im Prinzip die Freiheit gebe, die Daten eigenständig in irgendeinem vernünftigen Format zu exportieren und jedem Team übertrage, das irgendwie zu machen. Ich habe auch das Gefühl, dass das wahrscheinlich technisch weniger aufwendig ist. Aber wie dem auch sei. Man kann jetzt wahrscheinlich eine Architekturdiskussion führen und schauen, welche Vorteile das andere System hat. Ich finde es ehrlich gesagt ein bisschen schwierig, das so ad hoc zu sehen, was da die Vorteile wären. Er könnte dann diese Ansage auch normal hinterfragen. Genau, der Marco Wesselmann schreibt, was das eigentlich der Karl Schmolke gerade geschrieben hat, ich auch nicht und noch sehe ich auch noch kein wirtschaftlich rechtfertigbares zugrundeliegendes Problem. Was hat er weiter geschrieben? Den wirklichen Grund beziehungsweise Ziel, wo sie darauf hinaus steuern, werden sie nicht öffentlich kundtun. Naja, also nichts zu sagen, wir bauen halt eben eine Datenplattform und Daten zu analysieren, finde ich, können sie halt schon sagen. Aber das ist der nächste Punkt, den ich sozusagen diskutieren wollen würde. Ich habe mir hier aufgeschrieben, overengineering. Also was das bedeutet ist, dass wir halt jetzt einen massiven Aufwand betreiben, um eine Infrastruktur zu schaffen mit in der Menge Zeug, das nicht Netflix spezifisch ist, in dem Sinne, dass es jetzt speziell abgestimmt ist auf Filme. Das ist im Prinzip ein Datenanalyse Problem mit verschiedenen Datenquellen und das ist halt kein Netflix Problem, sondern das ist was anderes. Das führt natürlich dazu, dass es jetzt ganz viele spannende Engineering Probleme gibt. Also man kann sich vorstellen, dass da Sachen sind, die Techniker gerne lösen wollen, wobei ich eigentlich lieber Geschäftslogik bauen würde, aber sei es drum nicht. Also es gibt eben Leute, die gerne technisch komplizierte Sachen lösen und das ist hier sicher ein schönes Spielfeld dafür. Und das ganze Paper ist halt voll mit ganz viel Technik. Ich habe es ja erzählt, es gibt APA und es gibt Sphere und es gibt PDM und was weiß ich und das ist ganz viel in dieser Richtung, aber wenig über konkrete Probleme. Genau, Kaschmolka hat auch noch mal geschrieben, was ist eigentlich der geschäftliche Zweck? Genau, das fehlt halt so ein bisschen und das ist ein bisschen etwas, was Netflix hat auch bei dem Microservices Zeug bereits gemacht hat. Die haben eben auch eine eigene Microservices Stack gebaut mit einer Menge an Open Source Projekten und dabei zum Beispiel auch diese Resilience Lösung gebaut, das Hystrix, was ja mittlerweile eingestellt worden ist und das ist glaube ich da im Prinzip dasselbe. Also wir investieren viel Aufwand, um eine Infrastruktur zu schaffen für irgendein Problem und also bei dem Microservices Stack kann man noch diskutieren, ob es keinen am Markt gab. Hier ist halt mein Gefühl, also zumindest eine oberflächliche Recherche ergibt halt, dass es halt Integrationsplattformen gibt, die sowas wie eine Ontologie und so etwas unterstützen. Das bedeutet für mich, Kunden, die ich typischerweise berate, dem würde ich halt nicht dazu raten, dieses zu tun, weil das massiver, tinscher Aufwand ist und es ist nicht so klar, was der Vorteil ist und ich würde mich fragen, ob ich nichts kaufen kann. Ich investiere da irgendwie in Infrastruktur, nicht in meine spezifische Geschäftslogik und das ist halt selten eine gute Idee. Cashmoney hat nochmal geschrieben, das werden sie erst auflösen, wenn sie damit erfolgreich waren. Mitbewerbervorteil, ja sicher werden sie wahrscheinlich nicht darüber öffentlich reden, aber es ist trotzdem irgendwie komisch, dass sie dort so wenig, also ich kann ja auch abstrakt über Geschäftsprobleme reden, also dass ich sage, ich will Sachen analysieren und das tun sie halt wenig bis gar nichts. Ich habe das Gefühl, dass diese starke technische Motivation, dieses Over-Engineering und die Ablehnung von Kaufsoftware, dass das bei diesem Blogartikel irgendwie durchschreitet. Es ist ja auch nicht so, dass sie schreiben, hey und das ist übrigens so, dass es da zwar Lösungen am Markt gibt, aber die passen auf uns nicht, weil folgende Gründe, sondern es steht einfach da, wir haben es dann irgendwie gelöst. Warum veröffentlichen sie das ganze? Das hatte ich mir noch aufgeschrieben. Das ist ja auch so eine Frage. Wollen die uns irgendwas mitteilen? Ist das irgendwie eine Motivation? Sie schreiben, dass sie sich mit anderen Leuten vernetzen wollen, die Ähnliches bauen und ich glaube insgesamt ist das ein Versuch, um Engineers zu gewinnen, die gute Engineers sind, weswegen das vielleicht auch eine technische Diskussion ist. Solche Blogs macht man jedenfalls nicht, um mehr Zuschauer zu gewinnen, sondern ich glaube, dass es letztendlich Personalmarketing ist, wenn es einen Grund gibt. Jetzt ist die Frage, ist es denn nun tatsächlich so ein Widerspruch zu dieser Idee, mehrere Modelle zu haben? Ich glaube, das ist kein solcher Widerspruch. Der erste Punkt ist, vielleicht ist das, worüber wir reden, tatsächlich nur einbauende Kontexte. Es ist Content Engineering und Content Engineering nicht von dem Pitch bis es zum Launch geht. Da kann es sehr gut sein, dass ein Modell und eine Art, Daten zu repräsentieren, ausreichend ist. Vielleicht ist das eine Erklärung, um diese beiden Sachen miteinander zu vereinbaren. Das Ziel ist nicht, Aufwand zu sparen. Stefan hat in seinem Artikel damals geschrieben, wenn ich es einmal modelliere, dann habe ich es einmal modelliert, kann es wiederverwenden, das ist einfacher. Das ist nicht das, was Sie schreiben, das schreiben Sie ganz deutlich nicht, sondern es geht eben um Analyse. Es gibt Möglichkeiten, das allgemeine Modell zu erweitern. Das hatte ich bei AppA genannt, bei dieser Sprache, mit der man diese Schemata definieren kann. Ich hatte auch gesagt, dass dieses S-Kurs in dem PDM sogar ermöglicht, dass Teams ihre eigene Sprache nutzen, ohne jetzt mit dem PDM in Kontakt zu sein. Das kann bedeuten, dass es tatsächlich mehrere Modelle gibt, aber das steht nur am Rande da. Jetzt hat Karl Schmeuke geschrieben, in einem möglichen Grund den Ansatz vom Sparen zu challengen. Dafür ist es zu spät. Die sind sehr lange in diese Richtung marschiert, haben offensichtlich ganz viele Systeme gebaut. Das ist weit über eine Idee hinweg. Ich glaube, dass man das nicht mehr ernsthaft ohne Gesichtsverlust kassieren kann. Dann hat Tobias Böschel geschrieben, das kann eigentlich nur KI getrieben sein. Singuläre Datenhaltung über die gesamte Geschäftsdomäne bedeutet Verfügbarkeit für allwissende Agenten. Das könnte auch sein. Da muss man vielleicht auch hinzufügen, dass vom Business-Usern tatsächlich die Sprache ist. In dem gesamten Artikel erinnere ich zumindest nicht, dass AI oder KI angesprochen worden ist. Aber Tobias, du hast recht. Das ist etwas, was in so eine Motivation gehen könnte. Ich habe diese Daten bestimmt und die sollen durch AI analysiert werden. Ich hatte es am Anfang gesagt, so etwas wie eine Published Language oder Datenprodukte sind okay und sinnvoll. Datenprodukte sind sicherlich eine ganz hervorragende Ergänzung zu so etwas wie Domain-Driven Design. Das kann durchaus sein, dass wir gerade so einen Fall hier eigentlich sehen. Vielleicht ist das eben genau so etwas, was konzeptionell einer Published Language oder solchen Datenprodukten aus dem Data Mesh ähnelt und dann dafür sorgt, dass man sagt, hier gibt es eine Repräsentation, die ich nach außen entgebe für die Analyse. Ich habe eine interne Repräsentation. Das sind zwei getrennte Sachen. Diese interne Repräsentation ist für mich speziell und die nach draußen ist eine, die ich für die Analyse anbiete. Dann hätte ich da eben auch keinen Widerspruch. Der Daniel Pützinger hatte bei LinkedIn noch gesagt, im Domain-Driven Design gibt es ja ein paar Patterns, die er zumindest in diesem Text wiederfindet. Er nannte da zum Beispiel Shared Kernel. Shared Kernel ist etwas, wo ich ihm sage, zwei unterschiedliche Modelle haben einen gemeinsamen Kern. Das ist das, was Shared Kernel sagt. Ich sehe hier kein Shared Kernel, weil Shared Kernel Modelle sind für mich Logik. Wir teilen hier keine Logik, sondern wir reden hier nur über den Austausch von Daten. Sonst könnte das sein, dass man sowas per einen gemeinsamen Datenkern definiert. Dann schrieb er noch sowas wie ein Open-Host-Service. Das könnte das sein. Open-Host-Service ist nach meinem Empfinden eine Schnittstelle, die viele andere Teams konsumieren. Was auch wiederum bedeutet, Zugriff auf Logik. Das sehe ich hier auch nicht. Das ist meiner Ansicht nach ein Datenformat, keine Schnittstelle. Es ist auch ein Datenformat, das sozusagen aufgepoppt wird. Man sagt allen, bitte konvertiere deine Daten in dieses Datenformat oder ziehe dieses Datenformat vielleicht sogar in deine Systeme mit rein. Dann hat er noch genannt als Pattern Conformist. Conformist ist ein Pattern, wo jemand ein Modell vorgibt und die anderen müssen das nutzen und haben kein Mitspracherecht, also kein Veto-Recht oder keine Möglichkeit, das weiterzuentwickeln. Zum Beispiel, weil es vielleicht ein Legacy-System ist und das Legacy-System nicht anpassbar ist, sodass man mit dem leben muss, was dort ist. Es wäre eine ähnliche Geschichte. Es ist für mich eher eine Sache, die etwas mit Logik zu tun hat. Conformist hat eher etwas mit Logik zu tun. Es hat insbesondere eine bilaterale Beziehung, wo ich also zwei Teams habe, die miteinander reden. Das sehe ich hier auch nicht. Insgesamt ist es halt eher etwas, was für mich in die Datenintegration geht. Es ist tatsächlich so, dass in den gesamten Blogposts, in meiner Erinnerung, keine Funktionalitäten besprochen werden. Es wird nirgendwo gesagt, auch nicht bei diesem One-Piece-Beispiel, was man jetzt eigentlich mit diesen Daten anfangen will, sondern es wird nur gesagt, die Daten sind da und ich kann sie mir angucken und analysieren. Das ist meiner Ansicht nach nicht das, was DDD-Modelle, die speziell darauf ausgerichtet sind, komplexe Logik zu implementieren, wo das hingeht. Mutex.ab bei den Heise-Foren hat dann noch geschrieben, das könnte ich auch mit Datenbanken und Datenbank-Links umsetzen. Eine gemeinsame Sicht mit Views und darüber kriege ich das hin. Ja, aber hier kann ich mit mehr Heterogenität umgehen. Ich habe sowas wie GraphQL, was ja nicht eine Datenrepräsentation ist, sondern da ist es so, dass ich über HTTP REST stelle und mich Daten zur Verfügung stelle. Dann habe ich sowas wie dieses Apache Iceberg. Dann habe ich halt Dataproducts aus dem Data Mesh und die können andere Persistenztechnologien benutzen. Das heißt, ich habe hier tatsächlich eine flexiblere Möglichkeit und ich muss auch gestehen, solche Systeme, die versuchen, sich über die Datenbank zu integrieren, das ist eine von den Sachen, wo ich in meiner Beratungspraxis zu oft gesehen habe, dass das dazu führt, dass man ein großes kompliziertes Modell hat, was de facto dann eben von vielen Systemen genutzt wird und schwer änderbar ist. Davon würde ich generell eher Abstand nehmen. Ich halte Integration über die Datenbank, über sowas wie Datenbankviews und so weiter eher für schwierig. Auch da kann man im Einzelfall wahrscheinlich diskutieren, aber ich würde davon eher Abstand nehmen, weil ich Angst davor hätte, dass man dann am Ende bei einem großen komplizierten Datenbankmodell rauskommt, das irgendwie schwerwertig ist. Was mich noch insbesondere gewundert hat, ist, ich hatte es vor allem bei Stefans Artikel nochmal gesagt, es gibt also jetzt ein paar, also warum legen wir, ich, so viel Wert darauf, dass wir getrennte Modelle haben und Systeme aufteilen mehrere Modelle. Einmal deswegen, weil wir sonst in konzeptionelle Schwierigkeiten kommen. Ein Kunde, der eincheckt, ist eben nicht der Kunde, der die Rechnung bekommt. Und dann, weil diese umfangreichen großen zentralen Modelle super schwierig zu ändern sind. Es passiert zu häufig, dass man sagt, ich habe hier eine große Datenbank, da ist ein großes kompliziertes Modell drin. Dann habe ich lauter Systeme drumherum und dann versuche ich, die Systeme aufzuteilen. Aber das klappt nicht, weil ich diese Datenbank im Kern habe. Die Datenbank kann ich nicht aufteilen, weil niemand weiß, welche Daten welches System nutzt. Und dann habe ich letztendlich ein ganz schwieriges Problem, jemals dieses System aufzuteilen. Und zu diesem Thema, dass ein gemeinsames Modell auf der Datenebene zu einer starken Kopplung und zu einer Schwierigkeit führt, das System vernünftig zu modularisieren, findet man halt auch nichts in dem Blogbeitrag. Und das ist so ein bisschen die Meta-Ebene. So ein Papier zu schreiben und zu lesen ist eine Form von Kommunikation. Die haben gesagt, wir schreiben einen Blogbeitrag und wir sitzen jetzt hier nicht und reden drüber, sondern ich habe den Blogbeitrag gelesen, glaube ihn irgendwie verstanden zu haben. Und das ist eine indirekte Art von Kommunikation. Ich habe nie mit diesen Menschen direkt gesprochen. Und das führt dazu, dass es jetzt so eine Menge an Fragen gibt, die man jetzt stellen müsste. Also was ist denn nun wirklich das Problem? Ist es eigentlich ein Integrationsproblem? Dann wäre für mich die Frage, was ist mit der Autonomie der Teams? Wie stark ist die Modellierung tatsächlich unabhängig? Habt ihr da Schwierigkeiten? Habt ihr einen hohen Koordinationsaufwand? Lauft ihr an so ein Problem, dass ihr ein großes Datenmodell habt, was niemand mehr versteht und auseinandernehmen kann? Das wäre so etwas, wo man sich wahrscheinlich mal fünf, zehn Minuten oder vielleicht eine halbe Stunde zusammensetzen könnte und dann deutlich mehr wüsste. Ich finde das nochmal wichtig, weil es mir zu häufig passiert, dass Leute sagen, hey, neue Menschen sollen bei uns irgendwas machen und da sind Schwierigkeiten und deswegen brauchen wir mehr Dokumentation. Das hilft halt irgendwie nicht. Das sieht man hier relativ gut. Also man sieht irgendwie nicht, das ist gut geschrieben, das ist verständlich. Trotzdem ist es so, dass da ein massiver Informationsverlust ist, weil wir eben nicht miteinander direkt gesprochen haben. Da wäre jetzt für mich auch die Frage, was Sie sagen würden zu diesen verschiedenen kleinen Modellen, die wir ja eigentlich predigen. Ich bin mir nicht sicher, ob Sie sagen würden, das ist ein Fehlansatz. Das weiß ich nicht, weil Sie auf einer anderen Ebene sind bei dieser Datenanalyse in erster Linie. Mich würde interessieren, warum Ihr Datamash, was Sie haben, nicht ausreichend ist. Das wäre da so der Punkt. Mich erinnert das auch ein bisschen zu diesem Paper, was ich vor einiger Zeit mal diskutiert habe. Ich packe den Link dazu auch nochmal in die Shownotes, wo in der öffentlichen Wahrnehmung stecken übrig geblieben ist. Amazon macht jetzt Monolithen statt Microservices und das stand halt in dem Paper einfach nicht drin. Ich glaube, das ist hier was Ähnliches. Es steht hier nicht drin, Bau einen Kontext und mehrere Modelle sind eine blöde Idee, sondern es steht irgendwie was anderes drin. Ich glaube, es steht was drin in der Datenanalyse. Lass uns nochmal durch die Fragen gehen. Also Asmir Abdi hat gefragt, geht Netflix zu der Daten-Centric-Architecture? Nein, glaube ich nicht. Ich glaube, die bauen einfach eine Daten-Integration da am Ende. Und man sieht es unten, softverbinden-architektur.tv findest du die Episode dann auch nochmal komplett und kannst sie nachhören oder dir angucken. Karl Schmolka hat geschrieben, mögliche Gründe. In der Vergangenheit haben sie viele autonome Teams dem Part, wenn dann immer nachrängig behandelt. Darüber steht dann nichts drin und das ist halt tatsächlich komplette Mutmaßung, dass irgendwie eine zu große Autonomie dort zu einem Problem geführt hätte. Und selbst wenn, dann kann ich halt Makroarchitektur-Regeln definieren, die halt sagen nicht, also Bau halt ein Datenprodukt, bietet das an und macht das vernünftig. Was steht hier noch? Karl Schmolka schrieb, der Aufruf, doch bitte Daten zu bedienen und zu befüllen, wurde nicht ausreichend und zufriedenstellend bedient. Also zwingt man jetzt die Entwicklungsteams. Also wie gesagt, es ist eine komplette Mutmaßung. Und selbst wenn dem so wäre, fände ich, ist das ein Antipattern, weil das ist ein soziales Problem. Die Teams machen nicht das, was sie eigentlich tun sollten und was sinnvoll wäre. Und ich baue dann halt eine technische Lösung dafür, halte ich nicht für eine gute Idee. Kann man machen, schrieb halt dazu. Ich warte noch eine Sekunde, ob noch weitere Teams sind. Sonst wäre das sozusagen meine kurze Zusammenfassung dazu. Und vielen Dank nochmal für den Hinweis auf das Paper. Nächste Woche wird es aller Voraussicht nach keine Episode geben. Das hängt damit zusammen, dass ich so ein bisschen Zeitschwierigkeiten da gerade habe. Die übernächste Woche ist was geplant. Und zwar am 5.9. kommt dann das Thema Webperformance mit Lukas Domen und Lisa. Das wird also auf jeden Fall die nächste Episode sein. Vielleicht gibt es vorher nochmal was. Aber da könnt ihr dann auf die Webseite gucken. Vielen Dank für die vielen Fragen. Vielen Dank für die Inspiration, für die Diskussion. Und ich wünsche dann schon mal ein schönes Wochenende und bis dahin.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 12.079999923706055,
      "text": " Netflix keine bauenden Kontexte mehr benutzt und da will ich mich bedanken",
      "tokens": [
        50364,
        12778,
        9252,
        43787,
        1556,
        20629,
        3828,
        68,
        5417,
        38424,
        2682,
        674,
        1120,
        486,
        1893,
        6031,
        2901,
        18493,
        50968
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39804312586784363,
      "compression_ratio": 1.4186046123504639,
      "no_speech_prob": 0.8871558904647827
    },
    {
      "id": 1,
      "seek": 0,
      "start": 12.079999923706055,
      "end": 23.239999771118164,
      "text": " halt einmal bei dem Nico Stotz, der beim Software-Architektur im Stream Slack das",
      "tokens": [
        50968,
        12479,
        11078,
        4643,
        1371,
        15115,
        745,
        18530,
        11,
        1163,
        13922,
        27428,
        12,
        10683,
        339,
        642,
        2320,
        374,
        566,
        24904,
        37211,
        1482,
        51526
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39804312586784363,
      "compression_ratio": 1.4186046123504639,
      "no_speech_prob": 0.8871558904647827
    },
    {
      "id": 2,
      "seek": 0,
      "start": 23.239999771118164,
      "end": 25.799999237060547,
      "text": " Thema aufgebracht hat und außerdem hatte ich eine Person, mit der ich",
      "tokens": [
        51526,
        16306,
        2501,
        432,
        23404,
        2385,
        674,
        1609,
        35957,
        13299,
        1893,
        3018,
        8443,
        11,
        2194,
        1163,
        1893,
        51654
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39804312586784363,
      "compression_ratio": 1.4186046123504639,
      "no_speech_prob": 0.8871558904647827
    },
    {
      "id": 3,
      "seek": 0,
      "start": 25.799999237060547,
      "end": 28.920000076293945,
      "text": " gesprochen hatte nach meinem Talk beim VR Developers World Congress, die mich",
      "tokens": [
        51654,
        42714,
        13299,
        5168,
        24171,
        8780,
        13922,
        13722,
        11442,
        433,
        3937,
        6426,
        11,
        978,
        6031,
        51810
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39804312586784363,
      "compression_ratio": 1.4186046123504639,
      "no_speech_prob": 0.8871558904647827
    },
    {
      "id": 4,
      "seek": 2892,
      "start": 28.920000076293945,
      "end": 35.79999923706055,
      "text": " auch noch meine Einschätzung von diesem Paper gefragt hat und beide haben,",
      "tokens": [
        50364,
        2168,
        3514,
        10946,
        22790,
        339,
        3628,
        27667,
        2957,
        10975,
        24990,
        42638,
        2385,
        674,
        35831,
        3084,
        11,
        50708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3239583671092987,
      "compression_ratio": 1.6654545068740845,
      "no_speech_prob": 0.020931748673319817
    },
    {
      "id": 5,
      "seek": 2892,
      "start": 35.79999923706055,
      "end": 38.68000030517578,
      "text": " glaube ich, da den Eindruck, dass dieses Paper einen Widerspruch erzeugt zu",
      "tokens": [
        50708,
        13756,
        1893,
        11,
        1120,
        1441,
        462,
        41824,
        11,
        2658,
        12113,
        24990,
        4891,
        343,
        6936,
        45788,
        1189,
        19303,
        83,
        2164,
        50852
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3239583671092987,
      "compression_ratio": 1.6654545068740845,
      "no_speech_prob": 0.020931748673319817
    },
    {
      "id": 6,
      "seek": 2892,
      "start": 38.68000030517578,
      "end": 41.91999816894531,
      "text": " eben unabhängigen Microservices und sowas wie Bauen und Kontexten, also",
      "tokens": [
        50852,
        11375,
        517,
        455,
        34591,
        3213,
        5818,
        2635,
        47480,
        674,
        19766,
        296,
        3355,
        363,
        11715,
        674,
        20629,
        3828,
        268,
        11,
        611,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3239583671092987,
      "compression_ratio": 1.6654545068740845,
      "no_speech_prob": 0.020931748673319817
    },
    {
      "id": 7,
      "seek": 2892,
      "start": 41.91999816894531,
      "end": 46.279998779296875,
      "text": " unabhängiger Datenmodellierung und das ist so ein bisschen die Richtung, in die",
      "tokens": [
        51014,
        517,
        455,
        34591,
        4810,
        31126,
        8014,
        898,
        11651,
        674,
        1482,
        1418,
        370,
        1343,
        10763,
        978,
        33023,
        11,
        294,
        978,
        51232
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3239583671092987,
      "compression_ratio": 1.6654545068740845,
      "no_speech_prob": 0.020931748673319817
    },
    {
      "id": 8,
      "seek": 2892,
      "start": 46.279998779296875,
      "end": 50.91999816894531,
      "text": " das Ganze halt geht und das ist insbesondere deswegen halt interessant,",
      "tokens": [
        51232,
        1482,
        35206,
        12479,
        7095,
        674,
        1482,
        1418,
        48694,
        26482,
        12479,
        37748,
        11,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3239583671092987,
      "compression_ratio": 1.6654545068740845,
      "no_speech_prob": 0.020931748673319817
    },
    {
      "id": 9,
      "seek": 2892,
      "start": 50.91999816894531,
      "end": 55.2400016784668,
      "text": " weil eben Netflix einer der Pioniere ist in diesem Bereich von den Microservices",
      "tokens": [
        51464,
        7689,
        11375,
        12778,
        6850,
        1163,
        430,
        313,
        14412,
        1418,
        294,
        10975,
        26489,
        2957,
        1441,
        5818,
        2635,
        47480,
        51680
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3239583671092987,
      "compression_ratio": 1.6654545068740845,
      "no_speech_prob": 0.020931748673319817
    },
    {
      "id": 10,
      "seek": 5524,
      "start": 55.36000061035156,
      "end": 59.91999816894531,
      "text": " und natürlich an der Stelle, wo jetzt einer von den Pionieren sagt, das passt",
      "tokens": [
        50370,
        674,
        8762,
        364,
        1163,
        26629,
        11,
        6020,
        4354,
        6850,
        2957,
        1441,
        430,
        313,
        5695,
        15764,
        11,
        1482,
        37154,
        50598
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3229633867740631,
      "compression_ratio": 1.5714285373687744,
      "no_speech_prob": 0.04881315305829048
    },
    {
      "id": 11,
      "seek": 5524,
      "start": 59.91999816894531,
      "end": 65.0,
      "text": " halt irgendwie nicht mehr, ist das halt etwas, was natürlich auf Interesse stößt.",
      "tokens": [
        50598,
        12479,
        20759,
        1979,
        5417,
        11,
        1418,
        1482,
        12479,
        9569,
        11,
        390,
        8762,
        2501,
        5751,
        7357,
        342,
        18595,
        83,
        13,
        50852
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3229633867740631,
      "compression_ratio": 1.5714285373687744,
      "no_speech_prob": 0.04881315305829048
    },
    {
      "id": 12,
      "seek": 5524,
      "start": 65.0,
      "end": 74.4000015258789,
      "text": " Ich werde kurz sozusagen so ein bisschen so eine Motivation geben, also warum ist das mit dem",
      "tokens": [
        50852,
        3141,
        24866,
        20465,
        33762,
        370,
        1343,
        10763,
        370,
        3018,
        8956,
        592,
        399,
        17191,
        11,
        611,
        24331,
        1418,
        1482,
        2194,
        1371,
        51322
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3229633867740631,
      "compression_ratio": 1.5714285373687744,
      "no_speech_prob": 0.04881315305829048
    },
    {
      "id": 13,
      "seek": 5524,
      "start": 74.4000015258789,
      "end": 79.04000091552734,
      "text": " Bauen und Kontext ein Thema, warum ist das mit dem Modell ein Thema, was sind so Alternativen,",
      "tokens": [
        51322,
        363,
        11715,
        674,
        20629,
        3828,
        1343,
        16306,
        11,
        24331,
        1418,
        1482,
        2194,
        1371,
        6583,
        898,
        1343,
        16306,
        11,
        390,
        3290,
        370,
        23830,
        267,
        5709,
        11,
        51554
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3229633867740631,
      "compression_ratio": 1.5714285373687744,
      "no_speech_prob": 0.04881315305829048
    },
    {
      "id": 14,
      "seek": 7904,
      "start": 79.04000091552734,
      "end": 85.16000366210938,
      "text": " wie orte man das halt insgesamt ein. Dann werde ich den Blogpost von Netflix tatsächlich",
      "tokens": [
        50364,
        3355,
        420,
        975,
        587,
        1482,
        12479,
        41438,
        1343,
        13,
        7455,
        24866,
        1893,
        1441,
        46693,
        23744,
        2957,
        12778,
        20796,
        50670
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35779061913490295,
      "compression_ratio": 1.457983136177063,
      "no_speech_prob": 0.09523437917232513
    },
    {
      "id": 15,
      "seek": 7904,
      "start": 85.16000366210938,
      "end": 89.5999984741211,
      "text": " diskutieren und dann das Ganze noch mal bewerten und ich freue mich natürlich",
      "tokens": [
        50670,
        36760,
        5695,
        674,
        3594,
        1482,
        35206,
        3514,
        2806,
        17897,
        39990,
        674,
        1893,
        43195,
        6031,
        8762,
        50892
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35779061913490295,
      "compression_ratio": 1.457983136177063,
      "no_speech_prob": 0.09523437917232513
    },
    {
      "id": 16,
      "seek": 7904,
      "start": 89.5999984741211,
      "end": 94.5999984741211,
      "text": " irgendwie auf eure Fragen und Kommentare, die ihr sehr gerne in dem Chat oder in dem",
      "tokens": [
        50892,
        20759,
        2501,
        32845,
        25588,
        674,
        46203,
        11,
        978,
        5553,
        5499,
        15689,
        294,
        1371,
        27503,
        4513,
        294,
        1371,
        51142
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35779061913490295,
      "compression_ratio": 1.457983136177063,
      "no_speech_prob": 0.09523437917232513
    },
    {
      "id": 17,
      "seek": 7904,
      "start": 94.5999984741211,
      "end": 101.80000305175781,
      "text": " Formular auf der Homepage hinterlasten könnt. Also legen wir los. Was ist die Geschichte mit",
      "tokens": [
        51142,
        10126,
        1040,
        2501,
        1163,
        8719,
        15161,
        23219,
        7743,
        1147,
        22541,
        13,
        2743,
        48315,
        1987,
        1750,
        13,
        3027,
        1418,
        978,
        28896,
        2194,
        51502
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35779061913490295,
      "compression_ratio": 1.457983136177063,
      "no_speech_prob": 0.09523437917232513
    },
    {
      "id": 18,
      "seek": 10180,
      "start": 101.83999633789062,
      "end": 108.5999984741211,
      "text": " diesen Bauen und Kontexten und den Modellen? Also das ist etwas, was sich so ein bisschen",
      "tokens": [
        50366,
        12862,
        363,
        11715,
        674,
        20629,
        3828,
        268,
        674,
        1441,
        6583,
        8581,
        30,
        2743,
        1482,
        1418,
        9569,
        11,
        390,
        3041,
        370,
        1343,
        10763,
        50704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34325000643730164,
      "compression_ratio": 1.721611738204956,
      "no_speech_prob": 0.6234825253486633
    },
    {
      "id": 19,
      "seek": 10180,
      "start": 108.5999984741211,
      "end": 114.23999786376953,
      "text": " durch die, mittlerweile seit glaube ich einem Jahr, durch den Stream zieht. Es gab halt einmal",
      "tokens": [
        50704,
        7131,
        978,
        11,
        41999,
        16452,
        13756,
        1893,
        6827,
        11674,
        11,
        7131,
        1441,
        24904,
        16503,
        357,
        13,
        2313,
        17964,
        12479,
        11078,
        50986
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34325000643730164,
      "compression_ratio": 1.721611738204956,
      "no_speech_prob": 0.6234825253486633
    },
    {
      "id": 20,
      "seek": 10180,
      "start": 114.23999786376953,
      "end": 119.12000274658203,
      "text": " diese Episode, die gesagt hat, naja, Bauen und Kontext bedeutet eben, hat eigentlich so drei",
      "tokens": [
        50986,
        6705,
        19882,
        11,
        978,
        12260,
        2385,
        11,
        1667,
        2938,
        11,
        363,
        11715,
        674,
        20629,
        3828,
        27018,
        11375,
        11,
        2385,
        10926,
        370,
        16809,
        51230
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34325000643730164,
      "compression_ratio": 1.721611738204956,
      "no_speech_prob": 0.6234825253486633
    },
    {
      "id": 21,
      "seek": 10180,
      "start": 119.12000274658203,
      "end": 125.5199966430664,
      "text": " Dinge, die das halt irgendwie repräsentiert. Das ist zum einen so ein Modell, also irgendetwas,",
      "tokens": [
        51230,
        25102,
        11,
        978,
        1482,
        12479,
        20759,
        1085,
        11397,
        49315,
        4859,
        13,
        2846,
        1418,
        5919,
        4891,
        370,
        1343,
        6583,
        898,
        11,
        611,
        11093,
        302,
        6569,
        11,
        51550
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34325000643730164,
      "compression_ratio": 1.721611738204956,
      "no_speech_prob": 0.6234825253486633
    },
    {
      "id": 22,
      "seek": 10180,
      "start": 125.5199966430664,
      "end": 129.63999938964844,
      "text": " wo ich halt hingehe und ich sage, ich habe eine Funktionalität, also zum Beispiel irgendetwas,",
      "tokens": [
        51550,
        6020,
        1893,
        12479,
        28822,
        675,
        674,
        1893,
        19721,
        11,
        1893,
        6015,
        3018,
        11166,
        2320,
        1966,
        14053,
        11,
        611,
        5919,
        13772,
        11093,
        302,
        6569,
        11,
        51756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34325000643730164,
      "compression_ratio": 1.721611738204956,
      "no_speech_prob": 0.6234825253486633
    },
    {
      "id": 23,
      "seek": 12964,
      "start": 129.67999267578125,
      "end": 135.36000061035156,
      "text": " was halt sagt, wie kriege ich halt eine Bestellung zum Kunden geliefert, sowas in dem Dreh. Dafür",
      "tokens": [
        50366,
        390,
        12479,
        15764,
        11,
        3355,
        25766,
        432,
        1893,
        12479,
        3018,
        9752,
        898,
        1063,
        5919,
        38192,
        4087,
        414,
        34784,
        11,
        19766,
        296,
        294,
        1371,
        413,
        9017,
        13,
        35865,
        50650
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29271990060806274,
      "compression_ratio": 1.8580645322799683,
      "no_speech_prob": 0.009406781755387783
    },
    {
      "id": 24,
      "seek": 12964,
      "start": 135.36000061035156,
      "end": 139.32000732421875,
      "text": " brauche ich ja ein Modell. Das heißt also, ich muss jetzt wissen, welche logistischen Möglichkeiten",
      "tokens": [
        50650,
        1548,
        17545,
        1893,
        2784,
        1343,
        6583,
        898,
        13,
        2846,
        13139,
        611,
        11,
        1893,
        6425,
        4354,
        16331,
        11,
        24311,
        3565,
        468,
        6282,
        42627,
        50848
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29271990060806274,
      "compression_ratio": 1.8580645322799683,
      "no_speech_prob": 0.009406781755387783
    },
    {
      "id": 25,
      "seek": 12964,
      "start": 139.32000732421875,
      "end": 143.32000732421875,
      "text": " habe ich, Sachen halt zum Kunden zu bekommen. Ich muss wissen, welche Waren habe ich, wie kann ich",
      "tokens": [
        50848,
        6015,
        1893,
        11,
        26074,
        12479,
        5919,
        38192,
        2164,
        19256,
        13,
        3141,
        6425,
        16331,
        11,
        24311,
        343,
        4484,
        6015,
        1893,
        11,
        3355,
        4028,
        1893,
        51048
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29271990060806274,
      "compression_ratio": 1.8580645322799683,
      "no_speech_prob": 0.009406781755387783
    },
    {
      "id": 26,
      "seek": 12964,
      "start": 143.32000732421875,
      "end": 147.0399932861328,
      "text": " die verschicken, sollen die versichert verschickt werden oder nicht, sind die teuer oder billig,",
      "tokens": [
        51048,
        978,
        20563,
        3830,
        11,
        24713,
        978,
        1774,
        480,
        911,
        20563,
        40522,
        4604,
        4513,
        1979,
        11,
        3290,
        978,
        535,
        5486,
        4513,
        2961,
        328,
        11,
        51234
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29271990060806274,
      "compression_ratio": 1.8580645322799683,
      "no_speech_prob": 0.009406781755387783
    },
    {
      "id": 27,
      "seek": 12964,
      "start": 147.0399932861328,
      "end": 150.1199951171875,
      "text": " wenn sie teuer sind, sollen sie versichert verschickt werden und so weiter und so weiter.",
      "tokens": [
        51234,
        4797,
        2804,
        535,
        5486,
        3290,
        11,
        24713,
        2804,
        1774,
        480,
        911,
        20563,
        40522,
        4604,
        674,
        370,
        8988,
        674,
        370,
        8988,
        13,
        51388
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29271990060806274,
      "compression_ratio": 1.8580645322799683,
      "no_speech_prob": 0.009406781755387783
    },
    {
      "id": 28,
      "seek": 12964,
      "start": 150.1199951171875,
      "end": 154.44000244140625,
      "text": " So und das ist eben dieser Modellcharakter von den Bauen und Kontexten. Dann gibt es noch",
      "tokens": [
        51388,
        407,
        674,
        1482,
        1418,
        11375,
        9053,
        6583,
        898,
        7374,
        33557,
        2957,
        1441,
        363,
        11715,
        674,
        20629,
        3828,
        268,
        13,
        7455,
        6089,
        785,
        3514,
        51604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29271990060806274,
      "compression_ratio": 1.8580645322799683,
      "no_speech_prob": 0.009406781755387783
    },
    {
      "id": 29,
      "seek": 15444,
      "start": 154.60000610351562,
      "end": 162.0399932861328,
      "text": " diese Sprache. Das heißt also, in unterschiedlichen Kontexten können Dinge unterschiedlich definiert",
      "tokens": [
        50372,
        6705,
        7702,
        6000,
        13,
        2846,
        13139,
        611,
        11,
        294,
        30058,
        10193,
        20629,
        3828,
        268,
        6310,
        25102,
        30058,
        1739,
        1561,
        4859,
        50744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29891934990882874,
      "compression_ratio": 1.546875,
      "no_speech_prob": 0.1498323231935501
    },
    {
      "id": 30,
      "seek": 15444,
      "start": 162.0399932861328,
      "end": 169.8000030517578,
      "text": " sein. Und mein Beispiel dafür, was ich in letzter Zeit öfter benutze, ist halt der Hotelkunde. Also",
      "tokens": [
        50744,
        6195,
        13,
        2719,
        10777,
        13772,
        13747,
        11,
        390,
        1893,
        294,
        14027,
        391,
        9394,
        4044,
        828,
        38424,
        1381,
        11,
        1418,
        12479,
        1163,
        20354,
        74,
        13271,
        13,
        2743,
        51132
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29891934990882874,
      "compression_ratio": 1.546875,
      "no_speech_prob": 0.1498323231935501
    },
    {
      "id": 31,
      "seek": 15444,
      "start": 169.8000030517578,
      "end": 174.9199981689453,
      "text": " wer ist der Kunde eines Hotels? Und ich würde behaupten, wenn ich über den Check-in spreche,",
      "tokens": [
        51132,
        2612,
        1418,
        1163,
        591,
        13271,
        18599,
        9423,
        1625,
        30,
        2719,
        1893,
        11942,
        1540,
        13343,
        268,
        11,
        4797,
        1893,
        4502,
        1441,
        6881,
        12,
        259,
        22269,
        1876,
        11,
        51388
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29891934990882874,
      "compression_ratio": 1.546875,
      "no_speech_prob": 0.1498323231935501
    },
    {
      "id": 32,
      "seek": 15444,
      "start": 174.9199981689453,
      "end": 179.9600067138672,
      "text": " dann ist das natürlich eine Person, so wie ich, Eberhard. Und wenn ich halt über sowas wie die",
      "tokens": [
        51388,
        3594,
        1418,
        1482,
        8762,
        3018,
        8443,
        11,
        370,
        3355,
        1893,
        11,
        462,
        607,
        21491,
        13,
        2719,
        4797,
        1893,
        12479,
        4502,
        19766,
        296,
        3355,
        978,
        51640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29891934990882874,
      "compression_ratio": 1.546875,
      "no_speech_prob": 0.1498323231935501
    },
    {
      "id": 33,
      "seek": 17996,
      "start": 179.9600067138672,
      "end": 187.36000061035156,
      "text": " Rechnungslegung spreche, dann ist das vielleicht mein Arbeitgeber, nicht die SwagClub GmbH. Und",
      "tokens": [
        50364,
        1300,
        1377,
        5846,
        6363,
        1063,
        22269,
        1876,
        11,
        3594,
        1418,
        1482,
        12547,
        10777,
        18604,
        432,
        607,
        11,
        1979,
        978,
        3926,
        559,
        9966,
        836,
        460,
        2504,
        39,
        13,
        2719,
        50734
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28427812457084656,
      "compression_ratio": 1.7153284549713135,
      "no_speech_prob": 0.06749198585748672
    },
    {
      "id": 34,
      "seek": 17996,
      "start": 187.36000061035156,
      "end": 192.0399932861328,
      "text": " die kann definitiv niemals in einem Hotel einchecken, weil es ist eben keine natürliche",
      "tokens": [
        50734,
        978,
        4028,
        28781,
        592,
        2838,
        34978,
        294,
        6827,
        20354,
        1343,
        1876,
        13029,
        11,
        7689,
        785,
        1418,
        11375,
        9252,
        8762,
        68,
        50968
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28427812457084656,
      "compression_ratio": 1.7153284549713135,
      "no_speech_prob": 0.06749198585748672
    },
    {
      "id": 35,
      "seek": 17996,
      "start": 192.0399932861328,
      "end": 197.1199951171875,
      "text": " Person. Und dann habe ich halt irgendwie noch, wer auch immer das bezahlt. Also ich bezahle das",
      "tokens": [
        50968,
        8443,
        13,
        2719,
        3594,
        6015,
        1893,
        12479,
        20759,
        3514,
        11,
        2612,
        2168,
        5578,
        1482,
        10782,
        44950,
        13,
        2743,
        1893,
        10782,
        545,
        306,
        1482,
        51222
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28427812457084656,
      "compression_ratio": 1.7153284549713135,
      "no_speech_prob": 0.06749198585748672
    },
    {
      "id": 36,
      "seek": 17996,
      "start": 197.1199951171875,
      "end": 200.83999633789062,
      "text": " vielleicht selber, bezahle vielleicht für meinen Kollegen mit und dann habe ich eben drei",
      "tokens": [
        51222,
        12547,
        23888,
        11,
        10782,
        545,
        306,
        12547,
        2959,
        22738,
        23713,
        2194,
        674,
        3594,
        6015,
        1893,
        11375,
        16809,
        51408
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28427812457084656,
      "compression_ratio": 1.7153284549713135,
      "no_speech_prob": 0.06749198585748672
    },
    {
      "id": 37,
      "seek": 17996,
      "start": 200.83999633789062,
      "end": 206.39999389648438,
      "text": " verschiedene Modelle. Also ich habe den Check-in, da bin ich und mein Kollege sind dort der Kunde,",
      "tokens": [
        51408,
        35411,
        6583,
        4434,
        13,
        2743,
        1893,
        6015,
        1441,
        6881,
        12,
        259,
        11,
        1120,
        5171,
        1893,
        674,
        10777,
        28505,
        3290,
        15775,
        1163,
        591,
        13271,
        11,
        51686
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28427812457084656,
      "compression_ratio": 1.7153284549713135,
      "no_speech_prob": 0.06749198585748672
    },
    {
      "id": 38,
      "seek": 20640,
      "start": 206.52000427246094,
      "end": 211.16000366210938,
      "text": " dann gibt es halt die Bezahlung, da bin ich vielleicht die Person, die es bezahlt mit meiner",
      "tokens": [
        50370,
        3594,
        6089,
        785,
        12479,
        978,
        879,
        39670,
        1063,
        11,
        1120,
        5171,
        1893,
        12547,
        978,
        8443,
        11,
        978,
        785,
        10782,
        44950,
        2194,
        20529,
        50602
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2674935758113861,
      "compression_ratio": 1.6571428775787354,
      "no_speech_prob": 0.003272067056968808
    },
    {
      "id": 39,
      "seek": 20640,
      "start": 211.16000366210938,
      "end": 216.36000061035156,
      "text": " Kreditkarte, auch für meinen Kollegen. Und dann haben wir eben noch das Modell für die",
      "tokens": [
        50602,
        591,
        20046,
        74,
        11026,
        11,
        2168,
        2959,
        22738,
        23713,
        13,
        2719,
        3594,
        3084,
        1987,
        11375,
        3514,
        1482,
        6583,
        898,
        2959,
        978,
        50862
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2674935758113861,
      "compression_ratio": 1.6571428775787354,
      "no_speech_prob": 0.003272067056968808
    },
    {
      "id": 40,
      "seek": 20640,
      "start": 216.36000061035156,
      "end": 220.9199981689453,
      "text": " Rechnungslegung, wo wir sagen, die SwagClub GmbH ist der Kunde. Das heißt also, abhängig davon,",
      "tokens": [
        50862,
        1300,
        1377,
        5846,
        6363,
        1063,
        11,
        6020,
        1987,
        8360,
        11,
        978,
        3926,
        559,
        9966,
        836,
        460,
        2504,
        39,
        1418,
        1163,
        591,
        13271,
        13,
        2846,
        13139,
        611,
        11,
        410,
        34591,
        328,
        18574,
        11,
        51090
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2674935758113861,
      "compression_ratio": 1.6571428775787354,
      "no_speech_prob": 0.003272067056968808
    },
    {
      "id": 41,
      "seek": 20640,
      "start": 220.9199981689453,
      "end": 226.32000732421875,
      "text": " über welchen Kontext wir reden, über welches Modell wir reden, sind bestimmte Sachen",
      "tokens": [
        51090,
        4502,
        2214,
        2470,
        20629,
        3828,
        1987,
        26447,
        11,
        4502,
        2214,
        3781,
        6583,
        898,
        1987,
        26447,
        11,
        3290,
        35180,
        975,
        26074,
        51360
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2674935758113861,
      "compression_ratio": 1.6571428775787354,
      "no_speech_prob": 0.003272067056968808
    },
    {
      "id": 42,
      "seek": 20640,
      "start": 226.32000732421875,
      "end": 232.36000061035156,
      "text": " unterschiedlich definiert. Also Kunde kann eben unterschiedliche Dinge sein. Und da ist auch noch",
      "tokens": [
        51360,
        30058,
        1739,
        1561,
        4859,
        13,
        2743,
        591,
        13271,
        4028,
        11375,
        30058,
        10185,
        25102,
        6195,
        13,
        2719,
        1120,
        1418,
        2168,
        3514,
        51662
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2674935758113861,
      "compression_ratio": 1.6571428775787354,
      "no_speech_prob": 0.003272067056968808
    },
    {
      "id": 43,
      "seek": 23236,
      "start": 232.36000061035156,
      "end": 237.55999755859375,
      "text": " wichtig, wir reden halt dort über Logik. Also wir haben ein Modell, was es mir erlaubt, dass sich",
      "tokens": [
        50364,
        13621,
        11,
        1987,
        26447,
        12479,
        15775,
        4502,
        10824,
        1035,
        13,
        2743,
        1987,
        3084,
        1343,
        6583,
        898,
        11,
        390,
        785,
        3149,
        1189,
        20798,
        83,
        11,
        2658,
        3041,
        50624
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24801956117153168,
      "compression_ratio": 1.6713286638259888,
      "no_speech_prob": 0.08380705863237381
    },
    {
      "id": 44,
      "seek": 23236,
      "start": 237.55999755859375,
      "end": 243.27999877929688,
      "text": " irgendjemand eincheckt oder dass jemand in eine Rechnung geschickt wird. Das ist Logik. Da ist",
      "tokens": [
        50624,
        11093,
        73,
        18941,
        1343,
        1876,
        19951,
        4513,
        2658,
        21717,
        294,
        3018,
        1300,
        1377,
        1063,
        13511,
        40522,
        4578,
        13,
        2846,
        1418,
        10824,
        1035,
        13,
        3933,
        1418,
        50910
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24801956117153168,
      "compression_ratio": 1.6713286638259888,
      "no_speech_prob": 0.08380705863237381
    },
    {
      "id": 45,
      "seek": 23236,
      "start": 243.27999877929688,
      "end": 246.9600067138672,
      "text": " nämlich Logik drin. Vielleicht darf ich nicht einchecken, weil ich bin minderjährig oder was",
      "tokens": [
        50910,
        21219,
        10824,
        1035,
        24534,
        13,
        29838,
        19374,
        1893,
        1979,
        1343,
        1876,
        13029,
        11,
        7689,
        1893,
        5171,
        44146,
        49418,
        328,
        4513,
        390,
        51094
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24801956117153168,
      "compression_ratio": 1.6713286638259888,
      "no_speech_prob": 0.08380705863237381
    },
    {
      "id": 46,
      "seek": 23236,
      "start": 246.9600067138672,
      "end": 253.44000244140625,
      "text": " auch immer. Und das ist eigentlich der Kern. Wir wollen also Logik aufteilen in verschiedene",
      "tokens": [
        51094,
        2168,
        5578,
        13,
        2719,
        1482,
        1418,
        10926,
        1163,
        40224,
        13,
        4347,
        11253,
        611,
        10824,
        1035,
        1609,
        16268,
        17471,
        294,
        35411,
        51418
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24801956117153168,
      "compression_ratio": 1.6713286638259888,
      "no_speech_prob": 0.08380705863237381
    },
    {
      "id": 47,
      "seek": 23236,
      "start": 253.44000244140625,
      "end": 259.8399963378906,
      "text": " Modelle. Dafür brauchen wir halt unterschiedliche Daten. Davon getrennt ist so ein bisschen die",
      "tokens": [
        51418,
        6583,
        4434,
        13,
        35865,
        19543,
        1987,
        12479,
        30058,
        10185,
        31126,
        13,
        3724,
        266,
        483,
        1095,
        580,
        1418,
        370,
        1343,
        10763,
        978,
        51738
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24801956117153168,
      "compression_ratio": 1.6713286638259888,
      "no_speech_prob": 0.08380705863237381
    },
    {
      "id": 48,
      "seek": 25984,
      "start": 259.8399963378906,
      "end": 270.1600036621094,
      "text": " Geschichte mit der Sprache. Man kann eben manchmal beobachten, dass wenn Menschen über",
      "tokens": [
        50364,
        28896,
        2194,
        1163,
        7702,
        6000,
        13,
        2458,
        4028,
        11375,
        32092,
        312,
        996,
        20806,
        11,
        2658,
        4797,
        8397,
        4502,
        50880
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2866847813129425,
      "compression_ratio": 1.763157844543457,
      "no_speech_prob": 0.009857909753918648
    },
    {
      "id": 49,
      "seek": 25984,
      "start": 270.1600036621094,
      "end": 273.8399963378906,
      "text": " verschiedene Dinge reden, also in diesem Fall über den Kunden, unterschiedliche Dinge meinen. Der",
      "tokens": [
        50880,
        35411,
        25102,
        26447,
        11,
        611,
        294,
        10975,
        7465,
        4502,
        1441,
        38192,
        11,
        30058,
        10185,
        25102,
        22738,
        13,
        5618,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2866847813129425,
      "compression_ratio": 1.763157844543457,
      "no_speech_prob": 0.009857909753918648
    },
    {
      "id": 50,
      "seek": 25984,
      "start": 273.8399963378906,
      "end": 278.2799987792969,
      "text": " Kunde ist halt vielleicht die SwagClub GmbH. Vielleicht ist es halt auch eben eine natürliche",
      "tokens": [
        51064,
        591,
        13271,
        1418,
        12479,
        12547,
        978,
        3926,
        559,
        9966,
        836,
        460,
        2504,
        39,
        13,
        29838,
        1418,
        785,
        12479,
        2168,
        11375,
        3018,
        8762,
        68,
        51286
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2866847813129425,
      "compression_ratio": 1.763157844543457,
      "no_speech_prob": 0.009857909753918648
    },
    {
      "id": 51,
      "seek": 25984,
      "start": 278.2799987792969,
      "end": 283.6000061035156,
      "text": " Person. Das ist so der andere Aspekt. Also dass sprachliche Definitionen unterschiedlich sind.",
      "tokens": [
        51286,
        8443,
        13,
        2846,
        1418,
        370,
        1163,
        10490,
        1018,
        23533,
        13,
        2743,
        2658,
        6103,
        608,
        10185,
        46245,
        849,
        268,
        30058,
        1739,
        3290,
        13,
        51552
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2866847813129425,
      "compression_ratio": 1.763157844543457,
      "no_speech_prob": 0.009857909753918648
    },
    {
      "id": 52,
      "seek": 25984,
      "start": 283.6000061035156,
      "end": 288.44000244140625,
      "text": " Die Modelle sind ein Aspekt. Und dann ist der dritte Aspekt diese Geschichte, dass sich eben",
      "tokens": [
        51552,
        3229,
        6583,
        4434,
        3290,
        1343,
        1018,
        23533,
        13,
        2719,
        3594,
        1418,
        1163,
        1224,
        9786,
        1018,
        23533,
        6705,
        28896,
        11,
        2658,
        3041,
        11375,
        51794
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2866847813129425,
      "compression_ratio": 1.763157844543457,
      "no_speech_prob": 0.009857909753918648
    },
    {
      "id": 53,
      "seek": 28844,
      "start": 288.4800109863281,
      "end": 293.67999267578125,
      "text": " ein Bauen im Kontext einem Team geben kann. Also auch über Teams ist das letztendlich eine Aussage,",
      "tokens": [
        50366,
        1343,
        363,
        11715,
        566,
        20629,
        3828,
        6827,
        7606,
        17191,
        4028,
        13,
        2743,
        2168,
        4502,
        24702,
        1418,
        1482,
        35262,
        521,
        1739,
        3018,
        21286,
        609,
        11,
        50626
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3703247904777527,
      "compression_ratio": 1.8065693378448486,
      "no_speech_prob": 0.043345898389816284
    },
    {
      "id": 54,
      "seek": 28844,
      "start": 293.67999267578125,
      "end": 298.55999755859375,
      "text": " dass es ein Team bekommt, das typischerweise mit einem Bauen im Kontext zu tun. Und damit ist das",
      "tokens": [
        50626,
        2658,
        785,
        1343,
        7606,
        33429,
        11,
        1482,
        2125,
        5494,
        44071,
        2194,
        6827,
        363,
        11715,
        566,
        20629,
        3828,
        2164,
        4267,
        13,
        2719,
        9479,
        1418,
        1482,
        50870
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3703247904777527,
      "compression_ratio": 1.8065693378448486,
      "no_speech_prob": 0.043345898389816284
    },
    {
      "id": 55,
      "seek": 28844,
      "start": 298.55999755859375,
      "end": 307.6000061035156,
      "text": " eben auch dort relevant. Also habe ich diese drei Ebenen Modelle, Sprache und Teams. Darüber hatte",
      "tokens": [
        50870,
        11375,
        2168,
        15775,
        7340,
        13,
        2743,
        6015,
        1893,
        6705,
        16809,
        462,
        1799,
        268,
        6583,
        4434,
        11,
        7702,
        6000,
        674,
        24702,
        13,
        7803,
        12670,
        13299,
        51322
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3703247904777527,
      "compression_ratio": 1.8065693378448486,
      "no_speech_prob": 0.043345898389816284
    },
    {
      "id": 56,
      "seek": 28844,
      "start": 307.6000061035156,
      "end": 312.6400146484375,
      "text": " ich eben in dieser einen Episode gesprochen, wo es darum geht, was ist eigentlich Bauen im Kontext.",
      "tokens": [
        51322,
        1893,
        11375,
        294,
        9053,
        4891,
        19882,
        42714,
        11,
        6020,
        785,
        27313,
        7095,
        11,
        390,
        1418,
        10926,
        363,
        11715,
        566,
        20629,
        3828,
        13,
        51574
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3703247904777527,
      "compression_ratio": 1.8065693378448486,
      "no_speech_prob": 0.043345898389816284
    },
    {
      "id": 57,
      "seek": 28844,
      "start": 312.6400146484375,
      "end": 317.55999755859375,
      "text": " Und ich habe dann noch eine Episode nachgeschoben, wo ich gesagt habe, eigentlich ist es mit den",
      "tokens": [
        51574,
        2719,
        1893,
        6015,
        3594,
        3514,
        3018,
        19882,
        5168,
        23378,
        46213,
        11,
        6020,
        1893,
        12260,
        6015,
        11,
        10926,
        1418,
        785,
        2194,
        1441,
        51820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3703247904777527,
      "compression_ratio": 1.8065693378448486,
      "no_speech_prob": 0.043345898389816284
    },
    {
      "id": 58,
      "seek": 31756,
      "start": 317.7200012207031,
      "end": 322.0400085449219,
      "text": " Modellen spannend und diese Modelle zu finden. Das ist so ein bisschen die Kernerausforderung von",
      "tokens": [
        50372,
        6583,
        8581,
        49027,
        674,
        6705,
        6583,
        4434,
        2164,
        20734,
        13,
        2846,
        1418,
        370,
        1343,
        10763,
        978,
        20706,
        1193,
        8463,
        30943,
        1063,
        2957,
        50588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34328868985176086,
      "compression_ratio": 1.6013288497924805,
      "no_speech_prob": 0.016399765387177467
    },
    {
      "id": 59,
      "seek": 31756,
      "start": 322.0400085449219,
      "end": 325.7200012207031,
      "text": " Softwarearchitektur. Und ich habe versucht ein paar Röstling anzugeben, wie man so etwas auf die",
      "tokens": [
        50588,
        27428,
        1178,
        642,
        2320,
        374,
        13,
        2719,
        1893,
        6015,
        36064,
        1343,
        16509,
        497,
        973,
        372,
        1688,
        364,
        46285,
        1799,
        11,
        3355,
        587,
        370,
        9569,
        2501,
        978,
        50772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34328868985176086,
      "compression_ratio": 1.6013288497924805,
      "no_speech_prob": 0.016399765387177467
    },
    {
      "id": 60,
      "seek": 31756,
      "start": 325.7200012207031,
      "end": 330.9200134277344,
      "text": " Reihe bekommen kann. Der Urs Enzler bei LinkedIn hatte vorher auch schon gesagt, dass eben Modelle",
      "tokens": [
        50772,
        34549,
        675,
        19256,
        4028,
        13,
        5618,
        41303,
        2193,
        89,
        1918,
        4643,
        20657,
        13299,
        29195,
        2168,
        4981,
        12260,
        11,
        2658,
        11375,
        6583,
        4434,
        51032
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34328868985176086,
      "compression_ratio": 1.6013288497924805,
      "no_speech_prob": 0.016399765387177467
    },
    {
      "id": 61,
      "seek": 31756,
      "start": 330.9200134277344,
      "end": 335.8399963378906,
      "text": " für ihn sozusagen das Wichtigste sind bei dieser Aufteilung. Das würde ich auch so sehen. Aus",
      "tokens": [
        51032,
        2959,
        14534,
        33762,
        1482,
        343,
        7334,
        2941,
        3290,
        4643,
        9053,
        12160,
        16268,
        388,
        1063,
        13,
        2846,
        11942,
        1893,
        2168,
        370,
        11333,
        13,
        9039,
        51278
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34328868985176086,
      "compression_ratio": 1.6013288497924805,
      "no_speech_prob": 0.016399765387177467
    },
    {
      "id": 62,
      "seek": 31756,
      "start": 335.8399963378906,
      "end": 341.55999755859375,
      "text": " einer Softwarearchitektur-Frage ist das eben tatsächlich das Wichtigste. Und da kommen wir",
      "tokens": [
        51278,
        6850,
        27428,
        1178,
        642,
        2320,
        374,
        12,
        37,
        16223,
        1418,
        1482,
        11375,
        20796,
        1482,
        343,
        7334,
        2941,
        13,
        2719,
        1120,
        11729,
        1987,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34328868985176086,
      "compression_ratio": 1.6013288497924805,
      "no_speech_prob": 0.016399765387177467
    },
    {
      "id": 63,
      "seek": 34156,
      "start": 341.6400146484375,
      "end": 349.79998779296875,
      "text": " jetzt her. Das heißt also, wir wollen heute diskutieren, ob Netflix tatsächlich nur ein",
      "tokens": [
        50368,
        4354,
        720,
        13,
        2846,
        13139,
        611,
        11,
        1987,
        11253,
        9801,
        36760,
        5695,
        11,
        1111,
        12778,
        20796,
        4343,
        1343,
        50776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3012228310108185,
      "compression_ratio": 1.5708154439926147,
      "no_speech_prob": 0.17766423523426056
    },
    {
      "id": 64,
      "seek": 34156,
      "start": 349.79998779296875,
      "end": 356.7200012207031,
      "text": " Modell nutzt. Und das ist eigentlich erstaunlich, weil es wäre erstaunlich, wenn das so wäre.",
      "tokens": [
        50776,
        6583,
        898,
        5393,
        2682,
        13,
        2719,
        1482,
        1418,
        10926,
        1189,
        9140,
        409,
        1739,
        11,
        7689,
        785,
        14558,
        1189,
        9140,
        409,
        1739,
        11,
        4797,
        1482,
        370,
        14558,
        13,
        51122
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3012228310108185,
      "compression_ratio": 1.5708154439926147,
      "no_speech_prob": 0.17766423523426056
    },
    {
      "id": 65,
      "seek": 34156,
      "start": 356.7200012207031,
      "end": 361.44000244140625,
      "text": " Weil wenn man an dem Hotelbeispiel sieht, mehrere kleine Modelle sind eigentlich das,",
      "tokens": [
        51122,
        18665,
        4797,
        587,
        364,
        1371,
        20354,
        650,
        11935,
        14289,
        11,
        44677,
        22278,
        6583,
        4434,
        3290,
        10926,
        1482,
        11,
        51358
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3012228310108185,
      "compression_ratio": 1.5708154439926147,
      "no_speech_prob": 0.17766423523426056
    },
    {
      "id": 66,
      "seek": 34156,
      "start": 361.44000244140625,
      "end": 366.0799865722656,
      "text": " worauf es halt typischerweise hinausläuft und was eben typischerweise sozusagen der sinnvolle",
      "tokens": [
        51358,
        469,
        9507,
        785,
        12479,
        2125,
        19674,
        13109,
        46056,
        22882,
        25005,
        674,
        390,
        11375,
        2125,
        19674,
        13109,
        33762,
        1163,
        47066,
        20654,
        68,
        51590
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3012228310108185,
      "compression_ratio": 1.5708154439926147,
      "no_speech_prob": 0.17766423523426056
    },
    {
      "id": 67,
      "seek": 36608,
      "start": 366.1199951171875,
      "end": 375.6400146484375,
      "text": " Ansatz ist. Weil wir jetzt in so eine Situation kommen, wo wir halt über potenziell ein Datenmodell",
      "tokens": [
        50366,
        14590,
        10300,
        1418,
        13,
        18665,
        1987,
        4354,
        294,
        370,
        3018,
        22247,
        11729,
        11,
        6020,
        1987,
        12479,
        4502,
        1847,
        32203,
        285,
        1343,
        31126,
        8014,
        898,
        50842
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28515422344207764,
      "compression_ratio": 1.4900989532470703,
      "no_speech_prob": 0.0182592011988163
    },
    {
      "id": 68,
      "seek": 36608,
      "start": 375.6400146484375,
      "end": 382.4800109863281,
      "text": " reden, das halt sozusagen universell ist. Da gibt es halt von dem leider verstorbenen Stefan Tilkoff",
      "tokens": [
        50842,
        26447,
        11,
        1482,
        12479,
        33762,
        6445,
        285,
        1418,
        13,
        3933,
        6089,
        785,
        12479,
        2957,
        1371,
        29115,
        48960,
        284,
        1799,
        268,
        32158,
        45141,
        4093,
        602,
        51184
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28515422344207764,
      "compression_ratio": 1.4900989532470703,
      "no_speech_prob": 0.0182592011988163
    },
    {
      "id": 69,
      "seek": 36608,
      "start": 382.4800109863281,
      "end": 389.67999267578125,
      "text": " diesen Blogpost, den ich auch nochmal verlinke, wo er über diese kanonischen Datenmodelle spricht.",
      "tokens": [
        51184,
        12862,
        46693,
        23744,
        11,
        1441,
        1893,
        2168,
        26509,
        1306,
        5045,
        330,
        11,
        6020,
        1189,
        4502,
        6705,
        4608,
        266,
        6282,
        31126,
        8014,
        4434,
        42088,
        13,
        51544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28515422344207764,
      "compression_ratio": 1.4900989532470703,
      "no_speech_prob": 0.0182592011988163
    },
    {
      "id": 70,
      "seek": 38968,
      "start": 389.67999267578125,
      "end": 394.8399963378906,
      "text": " Das ist so ein Thema aus SOA, was eben ein Architekturansatz ist, der so vor 20 Jahren",
      "tokens": [
        50364,
        2846,
        1418,
        370,
        1343,
        16306,
        3437,
        10621,
        32,
        11,
        390,
        11375,
        1343,
        10984,
        642,
        2320,
        374,
        599,
        10300,
        1418,
        11,
        1163,
        370,
        4245,
        945,
        13080,
        50622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3381221890449524,
      "compression_ratio": 1.6067415475845337,
      "no_speech_prob": 0.3435195982456207
    },
    {
      "id": 71,
      "seek": 38968,
      "start": 394.8399963378906,
      "end": 400.8800048828125,
      "text": " ein relevanter Architekturansatz war. Und dort sagt er, ich kann jetzt versuchen,",
      "tokens": [
        50622,
        1343,
        2951,
        9768,
        391,
        10984,
        642,
        2320,
        374,
        599,
        10300,
        1516,
        13,
        2719,
        15775,
        15764,
        1189,
        11,
        1893,
        4028,
        4354,
        34749,
        11,
        50924
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3381221890449524,
      "compression_ratio": 1.6067415475845337,
      "no_speech_prob": 0.3435195982456207
    },
    {
      "id": 72,
      "seek": 38968,
      "start": 400.8800048828125,
      "end": 408.239990234375,
      "text": " zum Beispiel eben den Kunden zu modellieren. Einmal für alle. Da sagt er, das ist halt",
      "tokens": [
        50924,
        5919,
        13772,
        11375,
        1441,
        38192,
        2164,
        1072,
        898,
        5695,
        13,
        6391,
        5579,
        2959,
        5430,
        13,
        3933,
        15764,
        1189,
        11,
        1482,
        1418,
        12479,
        51292
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3381221890449524,
      "compression_ratio": 1.6067415475845337,
      "no_speech_prob": 0.3435195982456207
    },
    {
      "id": 73,
      "seek": 38968,
      "start": 408.239990234375,
      "end": 412.1600036621094,
      "text": " schwierig. Einmal deswegen aus diesen konzeptionellen Unterschiedlichkeiten,",
      "tokens": [
        51292,
        37845,
        13,
        6391,
        5579,
        26482,
        3437,
        12862,
        5897,
        32082,
        313,
        8581,
        41414,
        1739,
        21049,
        11,
        51488
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3381221890449524,
      "compression_ratio": 1.6067415475845337,
      "no_speech_prob": 0.3435195982456207
    },
    {
      "id": 74,
      "seek": 38968,
      "start": 412.1600036621094,
      "end": 416.79998779296875,
      "text": " die er in unterschiedlichen Situationen haben kann für einen Kunden. Beim Check-In ist es eben",
      "tokens": [
        51488,
        978,
        1189,
        294,
        30058,
        10193,
        22247,
        268,
        3084,
        4028,
        2959,
        4891,
        38192,
        13,
        45113,
        6881,
        12,
        4575,
        1418,
        785,
        11375,
        51720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3381221890449524,
      "compression_ratio": 1.6067415475845337,
      "no_speech_prob": 0.3435195982456207
    },
    {
      "id": 75,
      "seek": 41680,
      "start": 416.8399963378906,
      "end": 421.3599853515625,
      "text": " immer anders als bei der Rechnungslegung. Er macht noch den Punkt, dass es halt die",
      "tokens": [
        50366,
        5578,
        17999,
        3907,
        4643,
        1163,
        1300,
        1377,
        5846,
        6363,
        1063,
        13,
        3300,
        10857,
        3514,
        1441,
        25487,
        11,
        2658,
        785,
        12479,
        978,
        50592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29871004819869995,
      "compression_ratio": 1.5304347276687622,
      "no_speech_prob": 0.04022223502397537
    },
    {
      "id": 76,
      "seek": 41680,
      "start": 421.3599853515625,
      "end": 429.9200134277344,
      "text": " Teamautonomie einschränkt, weil die Teams eben nicht unabhängig voneinander die Modellierung",
      "tokens": [
        50592,
        7606,
        1375,
        12481,
        414,
        21889,
        339,
        33766,
        2320,
        11,
        7689,
        978,
        24702,
        11375,
        1979,
        517,
        455,
        34591,
        328,
        371,
        546,
        20553,
        978,
        6583,
        898,
        11651,
        51020
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29871004819869995,
      "compression_ratio": 1.5304347276687622,
      "no_speech_prob": 0.04022223502397537
    },
    {
      "id": 77,
      "seek": 41680,
      "start": 429.9200134277344,
      "end": 436.79998779296875,
      "text": " durchführen können. Und er spricht auch noch darüber, das sind die beiden Punkte,",
      "tokens": [
        51020,
        7131,
        69,
        29540,
        6310,
        13,
        2719,
        1189,
        42088,
        2168,
        3514,
        21737,
        11,
        1482,
        3290,
        978,
        23446,
        47352,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29871004819869995,
      "compression_ratio": 1.5304347276687622,
      "no_speech_prob": 0.04022223502397537
    },
    {
      "id": 78,
      "seek": 41680,
      "start": 436.79998779296875,
      "end": 443.0400085449219,
      "text": " die er irgendwie sieht als Schwierigkeiten. Und er gibt dann als Tipp zu sagen, dass man",
      "tokens": [
        51364,
        978,
        1189,
        20759,
        14289,
        3907,
        17576,
        811,
        37545,
        13,
        2719,
        1189,
        6089,
        3594,
        3907,
        42102,
        2164,
        8360,
        11,
        2658,
        587,
        51676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29871004819869995,
      "compression_ratio": 1.5304347276687622,
      "no_speech_prob": 0.04022223502397537
    },
    {
      "id": 79,
      "seek": 44304,
      "start": 443.20001220703125,
      "end": 449.0,
      "text": " unabhängige Teile von verschiedenen Teams definieren lassen sollte, weil die dann eben",
      "tokens": [
        50372,
        517,
        455,
        34591,
        3969,
        1989,
        794,
        2957,
        41043,
        24702,
        1561,
        5695,
        16168,
        18042,
        11,
        7689,
        978,
        3594,
        11375,
        50662
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28588369488716125,
      "compression_ratio": 1.578723430633545,
      "no_speech_prob": 0.05336860194802284
    },
    {
      "id": 80,
      "seek": 44304,
      "start": 449.0,
      "end": 453.4800109863281,
      "text": " jeweils unabhängig voneinander die Sachen für diese Art relevant sind, selber modellieren kann.",
      "tokens": [
        50662,
        46534,
        4174,
        517,
        455,
        34591,
        328,
        371,
        546,
        20553,
        978,
        26074,
        2959,
        6705,
        5735,
        7340,
        3290,
        11,
        23888,
        1072,
        898,
        5695,
        4028,
        13,
        50886
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28588369488716125,
      "compression_ratio": 1.578723430633545,
      "no_speech_prob": 0.05336860194802284
    },
    {
      "id": 81,
      "seek": 44304,
      "start": 453.4800109863281,
      "end": 460.3999938964844,
      "text": " Ich kann, wenn, dann vielleicht nur Fragmente standardisieren, wo das sinnvoll ist. Ich",
      "tokens": [
        50886,
        3141,
        4028,
        11,
        4797,
        11,
        3594,
        12547,
        4343,
        479,
        3731,
        4082,
        3832,
        271,
        5695,
        11,
        6020,
        1482,
        47066,
        20654,
        1418,
        13,
        3141,
        51232
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28588369488716125,
      "compression_ratio": 1.578723430633545,
      "no_speech_prob": 0.05336860194802284
    },
    {
      "id": 82,
      "seek": 44304,
      "start": 460.3999938964844,
      "end": 466.760009765625,
      "text": " sollte insbesondere nicht das zentrale Modell in die Teams runterpushen. Und er sagt insbesondere",
      "tokens": [
        51232,
        18042,
        48694,
        1979,
        1482,
        710,
        317,
        47282,
        6583,
        898,
        294,
        978,
        24702,
        33295,
        79,
        1498,
        268,
        13,
        2719,
        1189,
        15764,
        1028,
        6446,
        78,
        273,
        323,
        51550
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28588369488716125,
      "compression_ratio": 1.578723430633545,
      "no_speech_prob": 0.05336860194802284
    },
    {
      "id": 83,
      "seek": 46676,
      "start": 466.760009765625,
      "end": 475.5199890136719,
      "text": " auch noch, dass so ein zentrales Modell, dass man da sozusagen versuchen kann, Aufwand zu sparen,",
      "tokens": [
        50364,
        2168,
        3514,
        11,
        2658,
        370,
        1343,
        710,
        317,
        2155,
        279,
        6583,
        898,
        11,
        2658,
        587,
        1120,
        33762,
        34749,
        4028,
        11,
        9462,
        33114,
        2164,
        637,
        4484,
        11,
        50802
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29990309476852417,
      "compression_ratio": 1.7383512258529663,
      "no_speech_prob": 0.10513495653867722
    },
    {
      "id": 84,
      "seek": 46676,
      "start": 475.5199890136719,
      "end": 479.79998779296875,
      "text": " dass das eine mögliche Motivation ist und dass das eben auch kontraproduktiv ist. Das heißt also,",
      "tokens": [
        50802,
        2658,
        1482,
        3018,
        16294,
        68,
        8956,
        592,
        399,
        1418,
        674,
        2658,
        1482,
        11375,
        2168,
        14373,
        4007,
        2323,
        2320,
        592,
        1418,
        13,
        2846,
        13139,
        611,
        11,
        51016
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29990309476852417,
      "compression_ratio": 1.7383512258529663,
      "no_speech_prob": 0.10513495653867722
    },
    {
      "id": 85,
      "seek": 46676,
      "start": 479.79998779296875,
      "end": 483.6000061035156,
      "text": " er sagt halt, diese Motivation mit dem Aufwand sparen, das wird man typischerweise halt nicht",
      "tokens": [
        51016,
        1189,
        15764,
        12479,
        11,
        6705,
        8956,
        592,
        399,
        2194,
        1371,
        9462,
        33114,
        637,
        4484,
        11,
        1482,
        4578,
        587,
        2125,
        19674,
        13109,
        12479,
        1979,
        51206
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29990309476852417,
      "compression_ratio": 1.7383512258529663,
      "no_speech_prob": 0.10513495653867722
    },
    {
      "id": 86,
      "seek": 46676,
      "start": 483.6000061035156,
      "end": 491.4800109863281,
      "text": " hinbekommen, weil eben dieses universelle Modell zu bauen schwierig oder kaum möglich ist. Das",
      "tokens": [
        51206,
        14102,
        650,
        13675,
        11,
        7689,
        11375,
        12113,
        6445,
        2447,
        6583,
        898,
        2164,
        43787,
        37845,
        4513,
        36443,
        16294,
        1418,
        13,
        2846,
        51600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29990309476852417,
      "compression_ratio": 1.7383512258529663,
      "no_speech_prob": 0.10513495653867722
    },
    {
      "id": 87,
      "seek": 46676,
      "start": 491.4800109863281,
      "end": 496.44000244140625,
      "text": " heißt also, aus der Perspektive würden wir jetzt erwarten, wenn wir halt ein Datenmodell haben,",
      "tokens": [
        51600,
        13139,
        611,
        11,
        3437,
        1163,
        14006,
        23533,
        488,
        27621,
        1987,
        4354,
        21715,
        11719,
        11,
        4797,
        1987,
        12479,
        1343,
        31126,
        8014,
        898,
        3084,
        11,
        51848
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29990309476852417,
      "compression_ratio": 1.7383512258529663,
      "no_speech_prob": 0.10513495653867722
    },
    {
      "id": 88,
      "seek": 49644,
      "start": 496.6000061035156,
      "end": 501.79998779296875,
      "text": " das übergreifend ist, haben wir Einschränkungen von Autonomie, hohen Aufwand, Probleme, weil es",
      "tokens": [
        50372,
        1482,
        4502,
        33248,
        351,
        521,
        1418,
        11,
        3084,
        1987,
        22790,
        339,
        33766,
        74,
        5084,
        2957,
        6049,
        12481,
        414,
        11,
        1106,
        2932,
        9462,
        33114,
        11,
        32891,
        11,
        7689,
        785,
        50632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39035165309906006,
      "compression_ratio": 1.4396886825561523,
      "no_speech_prob": 0.0006361346459016204
    },
    {
      "id": 89,
      "seek": 49644,
      "start": 501.79998779296875,
      "end": 508.3599853515625,
      "text": " konzeptionell schwierig ist und es sollte insgesamt schief gehen. Ich bin da mit",
      "tokens": [
        50632,
        5897,
        32082,
        313,
        898,
        37845,
        1418,
        674,
        785,
        18042,
        41438,
        956,
        2521,
        13230,
        13,
        3141,
        5171,
        1120,
        2194,
        50960
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39035165309906006,
      "compression_ratio": 1.4396886825561523,
      "no_speech_prob": 0.0006361346459016204
    },
    {
      "id": 90,
      "seek": 49644,
      "start": 508.3599853515625,
      "end": 513.5599975585938,
      "text": " Stefan einer Meinung und das ist halt auch einer der Gründe, weswegen das sich erst mal so ein",
      "tokens": [
        50960,
        32158,
        6850,
        36519,
        674,
        1482,
        1418,
        12479,
        2168,
        6850,
        1163,
        2606,
        25596,
        11,
        38384,
        13683,
        1482,
        3041,
        11301,
        2806,
        370,
        1343,
        51220
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39035165309906006,
      "compression_ratio": 1.4396886825561523,
      "no_speech_prob": 0.0006361346459016204
    },
    {
      "id": 91,
      "seek": 49644,
      "start": 513.5599975585938,
      "end": 521.760009765625,
      "text": " bisschen komisch anhört. Jetzt gibt es halt im Bereich Domain-Driven Design durchaus Patterns,",
      "tokens": [
        51220,
        10763,
        5207,
        5494,
        18931,
        11454,
        13,
        12592,
        6089,
        785,
        12479,
        566,
        26489,
        16674,
        491,
        12,
        35,
        470,
        553,
        12748,
        42840,
        34367,
        3695,
        11,
        51630
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39035165309906006,
      "compression_ratio": 1.4396886825561523,
      "no_speech_prob": 0.0006361346459016204
    },
    {
      "id": 92,
      "seek": 52176,
      "start": 521.760009765625,
      "end": 528.0,
      "text": " die ein bisschen in so eine Modellierung von einem gemeinsamen Modell gehen. Ein Beispiel ist",
      "tokens": [
        50364,
        978,
        1343,
        10763,
        294,
        370,
        3018,
        6583,
        898,
        11651,
        2957,
        6827,
        22971,
        22403,
        6583,
        898,
        13230,
        13,
        6391,
        13772,
        1418,
        50676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2865767180919647,
      "compression_ratio": 1.5854700803756714,
      "no_speech_prob": 0.01940304785966873
    },
    {
      "id": 93,
      "seek": 52176,
      "start": 528.0,
      "end": 533.7999877929688,
      "text": " die Published Language. Published Language bedeutet, dass ich irgendwo einen wohl definierten,",
      "tokens": [
        50676,
        978,
        21808,
        4173,
        24445,
        13,
        21808,
        4173,
        24445,
        27018,
        11,
        2658,
        1893,
        40865,
        4891,
        24531,
        1561,
        29632,
        11,
        50966
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2865767180919647,
      "compression_ratio": 1.5854700803756714,
      "no_speech_prob": 0.01940304785966873
    },
    {
      "id": 94,
      "seek": 52176,
      "start": 533.7999877929688,
      "end": 546.6400146484375,
      "text": " publizierten Datendarstellung habe und zwar ist das eine gemeinsame Sprache, mit der ich dann",
      "tokens": [
        50966,
        11227,
        590,
        29632,
        9315,
        10292,
        30016,
        6015,
        674,
        19054,
        1418,
        1482,
        3018,
        22971,
        529,
        7702,
        6000,
        11,
        2194,
        1163,
        1893,
        3594,
        51608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2865767180919647,
      "compression_ratio": 1.5854700803756714,
      "no_speech_prob": 0.01940304785966873
    },
    {
      "id": 95,
      "seek": 52176,
      "start": 546.6400146484375,
      "end": 551.0,
      "text": " dafür sorgen kann, dass wir uns für die Kommunikation zwischen zwei Bauenden Kontexten",
      "tokens": [
        51608,
        13747,
        47972,
        4028,
        11,
        2658,
        1987,
        2693,
        2959,
        978,
        28832,
        1035,
        399,
        19875,
        12002,
        28772,
        8896,
        20629,
        3828,
        268,
        51826
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2865767180919647,
      "compression_ratio": 1.5854700803756714,
      "no_speech_prob": 0.01940304785966873
    },
    {
      "id": 96,
      "seek": 55100,
      "start": 551.0399780273438,
      "end": 556.8800048828125,
      "text": " auf irgendeine gemeinsame Sprache einigen. Der ist halt getrennt von den internen Modellen. Das heißt",
      "tokens": [
        50366,
        2501,
        3418,
        27429,
        533,
        22971,
        529,
        7702,
        6000,
        1343,
        3213,
        13,
        5618,
        1418,
        12479,
        483,
        1095,
        580,
        2957,
        1441,
        2154,
        268,
        6583,
        8581,
        13,
        2846,
        13139,
        50658
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3319859802722931,
      "compression_ratio": 1.8984375,
      "no_speech_prob": 0.0015976930735632777
    },
    {
      "id": 97,
      "seek": 55100,
      "start": 556.8800048828125,
      "end": 561.1199951171875,
      "text": " also, potenziell könnten wir jetzt sagen, wir bauen eine Schnittstelle. Nehmen wir mein internes",
      "tokens": [
        50658,
        611,
        11,
        1847,
        32203,
        285,
        37411,
        1987,
        4354,
        8360,
        11,
        1987,
        43787,
        3018,
        318,
        32064,
        372,
        4434,
        13,
        1734,
        9547,
        1987,
        10777,
        2154,
        279,
        50870
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3319859802722931,
      "compression_ratio": 1.8984375,
      "no_speech_prob": 0.0015976930735632777
    },
    {
      "id": 98,
      "seek": 55100,
      "start": 561.1199951171875,
      "end": 566.47998046875,
      "text": " Modell? Nein. Nehmen wir dein internes Modell? Nein. Wir bauen also ein gemeinsames Modell. Das",
      "tokens": [
        50870,
        6583,
        898,
        30,
        18878,
        13,
        1734,
        9547,
        1987,
        25641,
        2154,
        279,
        6583,
        898,
        30,
        18878,
        13,
        4347,
        43787,
        611,
        1343,
        22971,
        1632,
        6583,
        898,
        13,
        2846,
        51138
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3319859802722931,
      "compression_ratio": 1.8984375,
      "no_speech_prob": 0.0015976930735632777
    },
    {
      "id": 99,
      "seek": 55100,
      "start": 566.47998046875,
      "end": 569.719970703125,
      "text": " wäre dann die Published Language und das könnten wir auch höher skalieren. Das heißt, wir könnten",
      "tokens": [
        51138,
        14558,
        3594,
        978,
        21808,
        4173,
        24445,
        674,
        1482,
        37411,
        1987,
        2168,
        48045,
        16890,
        5695,
        13,
        2846,
        13139,
        11,
        1987,
        37411,
        51300
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3319859802722931,
      "compression_ratio": 1.8984375,
      "no_speech_prob": 0.0015976930735632777
    },
    {
      "id": 100,
      "seek": 55100,
      "start": 569.719970703125,
      "end": 576.6400146484375,
      "text": " jetzt auch sagen, wir bauen halt so eine Published Language, die für mehrere Parteien",
      "tokens": [
        51300,
        4354,
        2168,
        8360,
        11,
        1987,
        43787,
        12479,
        370,
        3018,
        21808,
        4173,
        24445,
        11,
        978,
        2959,
        44677,
        47689,
        1053,
        51646
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3319859802722931,
      "compression_ratio": 1.8984375,
      "no_speech_prob": 0.0015976930735632777
    },
    {
      "id": 101,
      "seek": 57664,
      "start": 577.0,
      "end": 584.1199951171875,
      "text": " relevant ist. Das heißt also, da hätte ich jetzt ein Datenmodell. Das wäre etwas,",
      "tokens": [
        50382,
        7340,
        1418,
        13,
        2846,
        13139,
        611,
        11,
        1120,
        20041,
        1893,
        4354,
        1343,
        31126,
        8014,
        898,
        13,
        2846,
        14558,
        9569,
        11,
        50738
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3459470570087433,
      "compression_ratio": 1.4816327095031738,
      "no_speech_prob": 0.11743146926164627
    },
    {
      "id": 102,
      "seek": 57664,
      "start": 584.1199951171875,
      "end": 591.4000244140625,
      "text": " was sich mehrere teilen. Ein Realist schreibt schon, man braucht ein anständiges und wirksames",
      "tokens": [
        50738,
        390,
        3041,
        44677,
        535,
        17471,
        13,
        6391,
        8467,
        468,
        956,
        31174,
        4981,
        11,
        587,
        22623,
        1343,
        364,
        16913,
        20609,
        674,
        1987,
        1694,
        1632,
        51102
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3459470570087433,
      "compression_ratio": 1.4816327095031738,
      "no_speech_prob": 0.11743146926164627
    },
    {
      "id": 103,
      "seek": 57664,
      "start": 591.4000244140625,
      "end": 596.719970703125,
      "text": " Ontology-Management. Bei Netflix läuft das tatsächlich ein bisschen in diese Richtung,",
      "tokens": [
        51102,
        16980,
        1793,
        12,
        6652,
        11129,
        13,
        16188,
        12778,
        31807,
        1482,
        20796,
        1343,
        10763,
        294,
        6705,
        33023,
        11,
        51368
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3459470570087433,
      "compression_ratio": 1.4816327095031738,
      "no_speech_prob": 0.11743146926164627
    },
    {
      "id": 104,
      "seek": 57664,
      "start": 596.719970703125,
      "end": 601.4400024414062,
      "text": " dass ich dort Begriffe definiere und versuche, die hin und her zu mappen. Das ist also etwas,",
      "tokens": [
        51368,
        2658,
        1893,
        15775,
        879,
        861,
        31387,
        1561,
        14412,
        674,
        1774,
        17545,
        11,
        978,
        14102,
        674,
        720,
        2164,
        463,
        21278,
        13,
        2846,
        1418,
        611,
        9569,
        11,
        51604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3459470570087433,
      "compression_ratio": 1.4816327095031738,
      "no_speech_prob": 0.11743146926164627
    },
    {
      "id": 105,
      "seek": 60144,
      "start": 601.4400024414062,
      "end": 611.52001953125,
      "text": " was ich dann brauche für diese Übersetzung. Ein anderer Bereich, was für mich nicht ganz in",
      "tokens": [
        50364,
        390,
        1893,
        3594,
        1548,
        17545,
        2959,
        6705,
        10713,
        1616,
        38584,
        13,
        6391,
        48108,
        26489,
        11,
        390,
        2959,
        6031,
        1979,
        6312,
        294,
        50868
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3541775047779083,
      "compression_ratio": 1.5188285112380981,
      "no_speech_prob": 0.0980004146695137
    },
    {
      "id": 106,
      "seek": 60144,
      "start": 611.52001953125,
      "end": 618.1599731445312,
      "text": " so ein gemeinsames Datenmodell geht, aber schon etwas ist, was man diskutieren muss, sind diese",
      "tokens": [
        50868,
        370,
        1343,
        22971,
        1632,
        31126,
        8014,
        898,
        7095,
        11,
        4340,
        4981,
        9569,
        1418,
        11,
        390,
        587,
        36760,
        5695,
        6425,
        11,
        3290,
        6705,
        51200
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3541775047779083,
      "compression_ratio": 1.5188285112380981,
      "no_speech_prob": 0.0980004146695137
    },
    {
      "id": 107,
      "seek": 60144,
      "start": 618.1599731445312,
      "end": 624.239990234375,
      "text": " Data Products bzw. Data Meshes, wo ich jetzt sage, ich habe irgendwelche Informationen,",
      "tokens": [
        51200,
        11888,
        47699,
        39998,
        13,
        11888,
        17485,
        8076,
        11,
        6020,
        1893,
        4354,
        19721,
        11,
        1893,
        6015,
        26455,
        338,
        1876,
        46753,
        11,
        51504
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3541775047779083,
      "compression_ratio": 1.5188285112380981,
      "no_speech_prob": 0.0980004146695137
    },
    {
      "id": 108,
      "seek": 60144,
      "start": 624.239990234375,
      "end": 628.8800048828125,
      "text": " also zum Beispiel Informationen aus dem Check-in von einem Hotel und ich sage jetzt,",
      "tokens": [
        51504,
        611,
        5919,
        13772,
        46753,
        3437,
        1371,
        6881,
        12,
        259,
        2957,
        6827,
        20354,
        674,
        1893,
        19721,
        4354,
        11,
        51736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3541775047779083,
      "compression_ratio": 1.5188285112380981,
      "no_speech_prob": 0.0980004146695137
    },
    {
      "id": 109,
      "seek": 62888,
      "start": 628.8800048828125,
      "end": 634.239990234375,
      "text": " diese Information von dem Check-in biete ich jetzt an zur Analyse. Vielleicht ist es so,",
      "tokens": [
        50364,
        6705,
        15357,
        2957,
        1371,
        6881,
        12,
        259,
        272,
        40462,
        1893,
        4354,
        364,
        7147,
        1107,
        5222,
        405,
        13,
        29838,
        1418,
        785,
        370,
        11,
        50632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2922952473163605,
      "compression_ratio": 1.6200716495513916,
      "no_speech_prob": 0.01743771694600582
    },
    {
      "id": 110,
      "seek": 62888,
      "start": 634.239990234375,
      "end": 640.1199951171875,
      "text": " dass ich glaube, dass der exakte Check-in-Zeitpunkt relevant ist oder das Geschlecht oder das Alter",
      "tokens": [
        50632,
        2658,
        1893,
        13756,
        11,
        2658,
        1163,
        454,
        48036,
        6881,
        12,
        259,
        12,
        44571,
        270,
        31744,
        7340,
        1418,
        4513,
        1482,
        14241,
        306,
        4701,
        4513,
        1482,
        32608,
        50926
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2922952473163605,
      "compression_ratio": 1.6200716495513916,
      "no_speech_prob": 0.01743771694600582
    },
    {
      "id": 111,
      "seek": 62888,
      "start": 640.1199951171875,
      "end": 646.52001953125,
      "text": " oder was weiß ich. Dann baue ich so einen Datenexport zusammen, mit dem ich dann diese",
      "tokens": [
        50926,
        4513,
        390,
        13385,
        1893,
        13,
        7455,
        4773,
        622,
        1893,
        370,
        4891,
        9315,
        1450,
        87,
        2707,
        14311,
        11,
        2194,
        1371,
        1893,
        3594,
        6705,
        51246
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2922952473163605,
      "compression_ratio": 1.6200716495513916,
      "no_speech_prob": 0.01743771694600582
    },
    {
      "id": 112,
      "seek": 62888,
      "start": 646.52001953125,
      "end": 651.8800048828125,
      "text": " Daten zur Analyse bereitstellen kann, sodass ein anderes Team oder irgendwelche Business",
      "tokens": [
        51246,
        31126,
        7147,
        1107,
        5222,
        405,
        38758,
        17538,
        4028,
        11,
        15047,
        640,
        1343,
        31426,
        7606,
        4513,
        26455,
        338,
        1876,
        10715,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2922952473163605,
      "compression_ratio": 1.6200716495513916,
      "no_speech_prob": 0.01743771694600582
    },
    {
      "id": 113,
      "seek": 62888,
      "start": 651.8800048828125,
      "end": 658.8400268554688,
      "text": " Intelligence Leute diese Daten analysieren können. Das ist typischerweise eher so auf",
      "tokens": [
        51514,
        27274,
        13495,
        6705,
        31126,
        23014,
        5695,
        6310,
        13,
        2846,
        1418,
        2125,
        19674,
        13109,
        24332,
        370,
        2501,
        51862
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2922952473163605,
      "compression_ratio": 1.6200716495513916,
      "no_speech_prob": 0.01743771694600582
    },
    {
      "id": 114,
      "seek": 65884,
      "start": 658.8400268554688,
      "end": 666.47998046875,
      "text": " der Schnittstellen-Ebene. Vielleicht exportiere ich die Daten in einen S3-Bucket und dadurch",
      "tokens": [
        50364,
        1163,
        318,
        32064,
        17538,
        12,
        36,
        41605,
        13,
        29838,
        10725,
        14412,
        1893,
        978,
        31126,
        294,
        4891,
        318,
        18,
        12,
        33,
        1134,
        302,
        674,
        35472,
        50746
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30509448051452637,
      "compression_ratio": 1.6343612670898438,
      "no_speech_prob": 0.0013458005851134658
    },
    {
      "id": 115,
      "seek": 65884,
      "start": 666.47998046875,
      "end": 670.9600219726562,
      "text": " vermeide ich, dass Leute jetzt hinter meinem Rücken in meiner Datenbank meine Daten auslesen,",
      "tokens": [
        50746,
        40064,
        482,
        1893,
        11,
        2658,
        13495,
        4354,
        23219,
        24171,
        497,
        26037,
        294,
        20529,
        31126,
        25423,
        10946,
        31126,
        3437,
        904,
        268,
        11,
        50970
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30509448051452637,
      "compression_ratio": 1.6343612670898438,
      "no_speech_prob": 0.0013458005851134658
    },
    {
      "id": 116,
      "seek": 65884,
      "start": 670.9600219726562,
      "end": 677.1199951171875,
      "text": " sondern ich ziehe das auf eine Schnittstellen-Ebene. Sprich, wenn ich jetzt mein internes",
      "tokens": [
        50970,
        11465,
        1893,
        16503,
        675,
        1482,
        2501,
        3018,
        318,
        32064,
        17538,
        12,
        36,
        41605,
        13,
        7702,
        480,
        11,
        4797,
        1893,
        4354,
        10777,
        2154,
        279,
        51278
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30509448051452637,
      "compression_ratio": 1.6343612670898438,
      "no_speech_prob": 0.0013458005851134658
    },
    {
      "id": 117,
      "seek": 65884,
      "start": 677.1199951171875,
      "end": 681.9199829101562,
      "text": " Datenmodell ändere, kann ich ja trotzdem das Datenmodell für den Export konstant halten und",
      "tokens": [
        51278,
        31126,
        8014,
        898,
        24981,
        323,
        11,
        4028,
        1893,
        2784,
        28325,
        1482,
        31126,
        8014,
        898,
        2959,
        1441,
        50130,
        34208,
        394,
        27184,
        674,
        51518
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30509448051452637,
      "compression_ratio": 1.6343612670898438,
      "no_speech_prob": 0.0013458005851134658
    },
    {
      "id": 118,
      "seek": 68192,
      "start": 681.9199829101562,
      "end": 688.9199829101562,
      "text": " gleichzeitig ist es so, dass die Leute, die die Daten analysieren, die Möglichkeit haben,",
      "tokens": [
        50364,
        44242,
        1418,
        785,
        370,
        11,
        2658,
        978,
        13495,
        11,
        978,
        978,
        31126,
        23014,
        5695,
        11,
        978,
        30662,
        3084,
        11,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3590225577354431,
      "compression_ratio": 1.912162184715271,
      "no_speech_prob": 0.08743105828762054
    },
    {
      "id": 119,
      "seek": 68192,
      "start": 688.9199829101562,
      "end": 692.8800048828125,
      "text": " Dinge zu analysieren, an die ich vorher vielleicht noch nicht gedacht habe, weil sie eben diese",
      "tokens": [
        50714,
        25102,
        2164,
        23014,
        5695,
        11,
        364,
        978,
        1893,
        29195,
        12547,
        3514,
        1979,
        33296,
        6015,
        11,
        7689,
        2804,
        11375,
        6705,
        50912
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3590225577354431,
      "compression_ratio": 1.912162184715271,
      "no_speech_prob": 0.08743105828762054
    },
    {
      "id": 120,
      "seek": 68192,
      "start": 692.8800048828125,
      "end": 698.3200073242188,
      "text": " Datenprodukte kombinieren können, sich anschauen können und dort dann eben entsprechend Möglichkeiten",
      "tokens": [
        50912,
        31126,
        14314,
        18844,
        42925,
        259,
        5695,
        6310,
        11,
        3041,
        31508,
        11715,
        6310,
        674,
        15775,
        3594,
        11375,
        47823,
        42627,
        51184
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3590225577354431,
      "compression_ratio": 1.912162184715271,
      "no_speech_prob": 0.08743105828762054
    },
    {
      "id": 121,
      "seek": 68192,
      "start": 698.3200073242188,
      "end": 702.5599975585938,
      "text": " haben, das zu tun, was sie tun wollen, was vielleicht vorher gar nicht planbar ist.",
      "tokens": [
        51184,
        3084,
        11,
        1482,
        2164,
        4267,
        11,
        390,
        2804,
        4267,
        11253,
        11,
        390,
        12547,
        29195,
        3691,
        1979,
        1393,
        5356,
        1418,
        13,
        51396
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3590225577354431,
      "compression_ratio": 1.912162184715271,
      "no_speech_prob": 0.08743105828762054
    },
    {
      "id": 122,
      "seek": 68192,
      "start": 702.5599975585938,
      "end": 706.3599853515625,
      "text": " Wenn ich vorher sagen kann, okay, exakt diese Daten will ich analysieren, das ist ja einfach,",
      "tokens": [
        51396,
        7899,
        1893,
        29195,
        8360,
        4028,
        11,
        1392,
        11,
        454,
        5886,
        6705,
        31126,
        486,
        1893,
        23014,
        5695,
        11,
        1482,
        1418,
        2784,
        7281,
        11,
        51586
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3590225577354431,
      "compression_ratio": 1.912162184715271,
      "no_speech_prob": 0.08743105828762054
    },
    {
      "id": 123,
      "seek": 68192,
      "start": 706.3599853515625,
      "end": 711.0,
      "text": " wird dann schwierig, wenn ich sage, ich weiß nicht so genau, welche Daten ich analysieren will,",
      "tokens": [
        51586,
        4578,
        3594,
        37845,
        11,
        4797,
        1893,
        19721,
        11,
        1893,
        13385,
        1979,
        370,
        12535,
        11,
        24311,
        31126,
        1893,
        23014,
        5695,
        486,
        11,
        51818
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3590225577354431,
      "compression_ratio": 1.912162184715271,
      "no_speech_prob": 0.08743105828762054
    },
    {
      "id": 124,
      "seek": 71100,
      "start": 711.0800170898438,
      "end": 716.719970703125,
      "text": " gibt mir sozusagen alles und sowas könnte ich jetzt hier so ein bisschen umsetzen.",
      "tokens": [
        50368,
        6089,
        3149,
        33762,
        7874,
        674,
        19766,
        296,
        17646,
        1893,
        4354,
        3296,
        370,
        1343,
        10763,
        1105,
        3854,
        2904,
        13,
        50650
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35264843702316284,
      "compression_ratio": 1.4640884399414062,
      "no_speech_prob": 0.0060968282632529736
    },
    {
      "id": 125,
      "seek": 71100,
      "start": 716.719970703125,
      "end": 732.47998046875,
      "text": " Das also so ein bisschen zum Einschwingen. Wir haben jetzt eigentlich folgende Aussagen. Wir",
      "tokens": [
        50650,
        2846,
        611,
        370,
        1343,
        10763,
        5919,
        22790,
        339,
        7904,
        268,
        13,
        4347,
        3084,
        4354,
        10926,
        3339,
        27429,
        21286,
        4698,
        13,
        4347,
        51438
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35264843702316284,
      "compression_ratio": 1.4640884399414062,
      "no_speech_prob": 0.0060968282632529736
    },
    {
      "id": 126,
      "seek": 71100,
      "start": 732.47998046875,
      "end": 735.9600219726562,
      "text": " erwarten, dass wir typischerweise in Softwareentwicklung eine Vielzahl an Modellen haben",
      "tokens": [
        51438,
        21715,
        11719,
        11,
        2658,
        1987,
        2125,
        19674,
        13109,
        294,
        27428,
        317,
        16038,
        17850,
        3018,
        35931,
        39670,
        364,
        6583,
        8581,
        3084,
        51612
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35264843702316284,
      "compression_ratio": 1.4640884399414062,
      "no_speech_prob": 0.0060968282632529736
    },
    {
      "id": 127,
      "seek": 73596,
      "start": 736.3599853515625,
      "end": 744.5999755859375,
      "text": " das ist vorteilhaft. Wenn wir das nicht haben, werden wir hohe Aufwände haben,",
      "tokens": [
        50384,
        1482,
        1418,
        371,
        12752,
        388,
        25127,
        13,
        7899,
        1987,
        1482,
        1979,
        3084,
        11,
        4604,
        1987,
        1106,
        675,
        9462,
        86,
        26973,
        3084,
        11,
        50796
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30792444944381714,
      "compression_ratio": 1.548936128616333,
      "no_speech_prob": 0.17295296490192413
    },
    {
      "id": 128,
      "seek": 73596,
      "start": 744.5999755859375,
      "end": 748.0800170898438,
      "text": " die Dinge zu koordinieren. Wir werden Schwierigkeiten haben, vernünftige Datenmodelle",
      "tokens": [
        50796,
        978,
        25102,
        2164,
        8384,
        6241,
        5695,
        13,
        4347,
        4604,
        17576,
        811,
        37545,
        3084,
        11,
        35793,
        3412,
        844,
        3969,
        31126,
        8014,
        4434,
        50970
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30792444944381714,
      "compression_ratio": 1.548936128616333,
      "no_speech_prob": 0.17295296490192413
    },
    {
      "id": 129,
      "seek": 73596,
      "start": 748.0800170898438,
      "end": 753.760009765625,
      "text": " zu erzeugen, den Kunden für das Hotel einmal zu modellieren, dass er eben alle drei Benutzungen",
      "tokens": [
        50970,
        2164,
        1189,
        19303,
        268,
        11,
        1441,
        38192,
        2959,
        1482,
        20354,
        11078,
        2164,
        1072,
        898,
        5695,
        11,
        2658,
        1189,
        11375,
        5430,
        16809,
        3964,
        12950,
        5084,
        51254
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30792444944381714,
      "compression_ratio": 1.548936128616333,
      "no_speech_prob": 0.17295296490192413
    },
    {
      "id": 130,
      "seek": 73596,
      "start": 753.760009765625,
      "end": 761.280029296875,
      "text": " irgendwie abdeckt, ist schwierig, würde ich auch nicht wollen, macht auch konzeptionell wenig Sinn.",
      "tokens": [
        51254,
        20759,
        410,
        1479,
        19951,
        11,
        1418,
        37845,
        11,
        11942,
        1893,
        2168,
        1979,
        11253,
        11,
        10857,
        2168,
        5897,
        32082,
        313,
        898,
        20911,
        37962,
        13,
        51630
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30792444944381714,
      "compression_ratio": 1.548936128616333,
      "no_speech_prob": 0.17295296490192413
    },
    {
      "id": 131,
      "seek": 76128,
      "start": 761.47998046875,
      "end": 766.47998046875,
      "text": " Ich hätte dort ein Problem, Autonomie, die Konzepte, dass die nicht funktionieren.",
      "tokens": [
        50374,
        3141,
        20041,
        15775,
        1343,
        11676,
        11,
        6049,
        12481,
        414,
        11,
        978,
        12718,
        46342,
        975,
        11,
        2658,
        978,
        1979,
        20454,
        5695,
        13,
        50624
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35826218128204346,
      "compression_ratio": 1.4793388843536377,
      "no_speech_prob": 0.11886689066886902
    },
    {
      "id": 132,
      "seek": 76128,
      "start": 766.47998046875,
      "end": 773.3200073242188,
      "text": " Und ich kann aber durchaus für Kommunikation und für Datenanalyse dazu kommen, dass ich ein",
      "tokens": [
        50624,
        2719,
        1893,
        4028,
        4340,
        42840,
        2959,
        28832,
        1035,
        399,
        674,
        2959,
        31126,
        282,
        5222,
        405,
        13034,
        11729,
        11,
        2658,
        1893,
        1343,
        50966
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35826218128204346,
      "compression_ratio": 1.4793388843536377,
      "no_speech_prob": 0.11886689066886902
    },
    {
      "id": 133,
      "seek": 76128,
      "start": 773.3200073242188,
      "end": 780.0,
      "text": " Datenmodell habe, das so eine Art globalen Standard möglicherweise darstellt. Published",
      "tokens": [
        50966,
        31126,
        8014,
        898,
        6015,
        11,
        1482,
        370,
        3018,
        5735,
        4338,
        268,
        21298,
        16294,
        44071,
        4072,
        372,
        12783,
        13,
        21808,
        4173,
        51300
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35826218128204346,
      "compression_ratio": 1.4793388843536377,
      "no_speech_prob": 0.11886689066886902
    },
    {
      "id": 134,
      "seek": 76128,
      "start": 780.0,
      "end": 783.6400146484375,
      "text": " Language und ein Data Product können in diese Richtung gehen. Das ist so ein bisschen das,",
      "tokens": [
        51300,
        24445,
        674,
        1343,
        11888,
        22005,
        6310,
        294,
        6705,
        33023,
        13230,
        13,
        2846,
        1418,
        370,
        1343,
        10763,
        1482,
        11,
        51482
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35826218128204346,
      "compression_ratio": 1.4793388843536377,
      "no_speech_prob": 0.11886689066886902
    },
    {
      "id": 135,
      "seek": 78364,
      "start": 783.6400146484375,
      "end": 791.7999877929688,
      "text": " wo wir herkommen. Der Netflix Blog hat eben diesen schönen Titel, Model once represent",
      "tokens": [
        50364,
        6020,
        1987,
        720,
        13675,
        13,
        5618,
        12778,
        46693,
        2385,
        11375,
        12862,
        25032,
        2866,
        14489,
        338,
        11,
        17105,
        1564,
        2906,
        50772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4367396831512451,
      "compression_ratio": 1.3731343746185303,
      "no_speech_prob": 0.3873019516468048
    },
    {
      "id": 136,
      "seek": 78364,
      "start": 791.7999877929688,
      "end": 797.52001953125,
      "text": " everywhere, also nicht, modelliere einmal und die Repräsentationen sind überall und nennt",
      "tokens": [
        50772,
        5315,
        11,
        611,
        1979,
        11,
        1072,
        898,
        14412,
        11078,
        674,
        978,
        3696,
        11397,
        49315,
        399,
        268,
        3290,
        38035,
        674,
        16399,
        580,
        51058
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4367396831512451,
      "compression_ratio": 1.3731343746185303,
      "no_speech_prob": 0.3873019516468048
    },
    {
      "id": 137,
      "seek": 78364,
      "start": 797.52001953125,
      "end": 808.5999755859375,
      "text": " halt die Unified Data Architecture dort als das Schlagwort. Netflix, mittlerweile breit bekannt,",
      "tokens": [
        51058,
        12479,
        978,
        1156,
        2587,
        11888,
        43049,
        15775,
        3907,
        1482,
        16420,
        559,
        13802,
        13,
        12778,
        11,
        41999,
        1403,
        270,
        39167,
        11,
        51612
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4367396831512451,
      "compression_ratio": 1.3731343746185303,
      "no_speech_prob": 0.3873019516468048
    },
    {
      "id": 138,
      "seek": 80860,
      "start": 808.6400146484375,
      "end": 815.5599975585938,
      "text": " ist ein Online-Videodienst, wo ich also nicht Online-Videos gucken kann. Die sind deswegen",
      "tokens": [
        50366,
        1418,
        1343,
        16930,
        12,
        53,
        482,
        378,
        27366,
        11,
        6020,
        1893,
        611,
        1979,
        16930,
        12,
        53,
        482,
        329,
        33135,
        4028,
        13,
        3229,
        3290,
        26482,
        50712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32772162556648254,
      "compression_ratio": 1.5714285373687744,
      "no_speech_prob": 0.22752735018730164
    },
    {
      "id": 139,
      "seek": 80860,
      "start": 815.5599975585938,
      "end": 821.0800170898438,
      "text": " interessant, weil sie ein Microservices-Pionier waren und zwar schon so lange, dass ich am Anfang,",
      "tokens": [
        50712,
        37748,
        11,
        7689,
        2804,
        1343,
        5818,
        2635,
        47480,
        12,
        47,
        313,
        811,
        11931,
        674,
        19054,
        4981,
        370,
        18131,
        11,
        2658,
        1893,
        669,
        25856,
        11,
        50988
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32772162556648254,
      "compression_ratio": 1.5714285373687744,
      "no_speech_prob": 0.22752735018730164
    },
    {
      "id": 140,
      "seek": 80860,
      "start": 821.0800170898438,
      "end": 824.719970703125,
      "text": " als ich über Netflix gesprochen habe, noch immer erwähnen musste, was das überhaupt ist,",
      "tokens": [
        50988,
        3907,
        1893,
        4502,
        12778,
        42714,
        6015,
        11,
        3514,
        5578,
        21715,
        6860,
        2866,
        34497,
        11,
        390,
        1482,
        20023,
        1418,
        11,
        51170
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32772162556648254,
      "compression_ratio": 1.5714285373687744,
      "no_speech_prob": 0.22752735018730164
    },
    {
      "id": 141,
      "seek": 80860,
      "start": 824.719970703125,
      "end": 828.1599731445312,
      "text": " weil sie gar nicht in Deutschland präsent sind. Mittlerweile ist es ja deutlich anders.",
      "tokens": [
        51170,
        7689,
        2804,
        3691,
        1979,
        294,
        14802,
        582,
        13555,
        317,
        3290,
        13,
        18784,
        36055,
        1418,
        785,
        2784,
        24344,
        17999,
        13,
        51342
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32772162556648254,
      "compression_ratio": 1.5714285373687744,
      "no_speech_prob": 0.22752735018730164
    },
    {
      "id": 142,
      "seek": 80860,
      "start": 828.1599731445312,
      "end": 835.8800048828125,
      "text": " Ein sehr erfolgreiches Unternehmen unter dem Fortune 500 und ist eben dort, also aus diesem",
      "tokens": [
        51342,
        6391,
        5499,
        48270,
        279,
        27577,
        8662,
        1371,
        38508,
        5923,
        674,
        1418,
        11375,
        15775,
        11,
        611,
        3437,
        10975,
        51728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32772162556648254,
      "compression_ratio": 1.5714285373687744,
      "no_speech_prob": 0.22752735018730164
    },
    {
      "id": 143,
      "seek": 83588,
      "start": 835.8800048828125,
      "end": 840.760009765625,
      "text": " Grund glaube ich, interessant, weil es eben dieses Microservices und dieses unabhängige Zeug,",
      "tokens": [
        50364,
        13941,
        13756,
        1893,
        11,
        37748,
        11,
        7689,
        785,
        11375,
        12113,
        5818,
        2635,
        47480,
        674,
        12113,
        517,
        455,
        34591,
        3969,
        4853,
        697,
        11,
        50608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3110795319080353,
      "compression_ratio": 1.7121212482452393,
      "no_speech_prob": 0.0188286155462265
    },
    {
      "id": 144,
      "seek": 83588,
      "start": 840.760009765625,
      "end": 846.52001953125,
      "text": " unabhängige Teams, autonome Teams und so weiter gepredigt hat, zumindest zu dem Zeitpunkt und",
      "tokens": [
        50608,
        517,
        455,
        34591,
        3969,
        24702,
        11,
        1476,
        266,
        423,
        24702,
        674,
        370,
        8988,
        30979,
        986,
        5828,
        2385,
        11,
        38082,
        2164,
        1371,
        9394,
        31744,
        674,
        50896
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3110795319080353,
      "compression_ratio": 1.7121212482452393,
      "no_speech_prob": 0.0188286155462265
    },
    {
      "id": 145,
      "seek": 83588,
      "start": 846.52001953125,
      "end": 852.5599975585938,
      "text": " weil hier jetzt zumindest wahrgenommen Widerspruch ist. Was hier also letztendlich passiert ist,",
      "tokens": [
        50896,
        7689,
        3296,
        4354,
        38082,
        21628,
        29270,
        343,
        6936,
        45788,
        1418,
        13,
        3027,
        3296,
        611,
        35262,
        521,
        1739,
        21671,
        1418,
        11,
        51198
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3110795319080353,
      "compression_ratio": 1.7121212482452393,
      "no_speech_prob": 0.0188286155462265
    },
    {
      "id": 146,
      "seek": 83588,
      "start": 852.5599975585938,
      "end": 858.5599975585938,
      "text": " sowas wie, ich habe mir aufgeschrieben, eine Änderung an der Architektur. Ich bin mir gar",
      "tokens": [
        51198,
        19766,
        296,
        3355,
        11,
        1893,
        6015,
        3149,
        2501,
        23378,
        24027,
        11,
        3018,
        13700,
        20535,
        1063,
        364,
        1163,
        10984,
        642,
        2320,
        374,
        13,
        3141,
        5171,
        3149,
        3691,
        51498
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3110795319080353,
      "compression_ratio": 1.7121212482452393,
      "no_speech_prob": 0.0188286155462265
    },
    {
      "id": 147,
      "seek": 83588,
      "start": 858.5599975585938,
      "end": 861.5599975585938,
      "text": " nicht sicher, ob das stimmt. Eigentlich ist es eine Architekturentscheidung. Also wir haben",
      "tokens": [
        51498,
        1979,
        18623,
        11,
        1111,
        1482,
        37799,
        13,
        40561,
        7698,
        1418,
        785,
        3018,
        10984,
        642,
        2320,
        374,
        791,
        1876,
        327,
        1063,
        13,
        2743,
        1987,
        3084,
        51648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3110795319080353,
      "compression_ratio": 1.7121212482452393,
      "no_speech_prob": 0.0188286155462265
    },
    {
      "id": 148,
      "seek": 83588,
      "start": 861.5599975585938,
      "end": 865.239990234375,
      "text": " eine Architekturentscheidung, die irgendwie sagt, wir wollen ein gemeinsames Datenmodell haben.",
      "tokens": [
        51648,
        3018,
        10984,
        642,
        2320,
        374,
        791,
        1876,
        327,
        1063,
        11,
        978,
        20759,
        15764,
        11,
        1987,
        11253,
        1343,
        22971,
        1632,
        31126,
        8014,
        898,
        3084,
        13,
        51832
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3110795319080353,
      "compression_ratio": 1.7121212482452393,
      "no_speech_prob": 0.0188286155462265
    },
    {
      "id": 149,
      "seek": 86524,
      "start": 865.3599853515625,
      "end": 873.6799926757812,
      "text": " Und um das sozusagen zu bewerten, ist es halt, finde ich, wichtig, erstmal herauszufinden,",
      "tokens": [
        50370,
        2719,
        1105,
        1482,
        33762,
        2164,
        17897,
        39990,
        11,
        1418,
        785,
        12479,
        11,
        17841,
        1893,
        11,
        13621,
        11,
        38607,
        25089,
        39467,
        10291,
        11,
        50786
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33404162526130676,
      "compression_ratio": 1.6322870254516602,
      "no_speech_prob": 0.00044420998892746866
    },
    {
      "id": 150,
      "seek": 86524,
      "start": 873.6799926757812,
      "end": 877.719970703125,
      "text": " was sind eigentlich die Gründe. Also wenn ich eine Architekturentscheidung treffe,",
      "tokens": [
        50786,
        390,
        3290,
        10926,
        978,
        2606,
        25596,
        13,
        2743,
        4797,
        1893,
        3018,
        10984,
        642,
        2320,
        374,
        791,
        1876,
        327,
        1063,
        2192,
        16349,
        11,
        50988
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33404162526130676,
      "compression_ratio": 1.6322870254516602,
      "no_speech_prob": 0.00044420998892746866
    },
    {
      "id": 151,
      "seek": 86524,
      "start": 877.719970703125,
      "end": 885.8400268554688,
      "text": " dann sollte ich die halt irgendwie begründen und ich sollte sie anhand der Begründung auch",
      "tokens": [
        50988,
        3594,
        18042,
        1893,
        978,
        12479,
        20759,
        38972,
        27687,
        674,
        1893,
        18042,
        2804,
        364,
        5543,
        1163,
        879,
        861,
        9541,
        1063,
        2168,
        51394
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33404162526130676,
      "compression_ratio": 1.6322870254516602,
      "no_speech_prob": 0.00044420998892746866
    },
    {
      "id": 152,
      "seek": 86524,
      "start": 885.8400268554688,
      "end": 889.8400268554688,
      "text": " bewerten. Also nur, weil ich mich jetzt irgendwie hinstelle oder sich jemand hinstellt und sagt,",
      "tokens": [
        51394,
        17897,
        39990,
        13,
        2743,
        4343,
        11,
        7689,
        1893,
        6031,
        4354,
        20759,
        276,
        13911,
        4434,
        4513,
        3041,
        21717,
        276,
        13911,
        12783,
        674,
        15764,
        11,
        51594
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33404162526130676,
      "compression_ratio": 1.6322870254516602,
      "no_speech_prob": 0.00044420998892746866
    },
    {
      "id": 153,
      "seek": 88984,
      "start": 889.9600219726562,
      "end": 895.3599853515625,
      "text": " wir bestreiten die Autonomie der Teams. Das sollten wir nicht machen. Es kann ja Gründe",
      "tokens": [
        50370,
        1987,
        1151,
        265,
        6009,
        978,
        6049,
        12481,
        414,
        1163,
        24702,
        13,
        2846,
        29096,
        1987,
        1979,
        7069,
        13,
        2313,
        4028,
        2784,
        2606,
        25596,
        50640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2788906693458557,
      "compression_ratio": 1.6145833730697632,
      "no_speech_prob": 0.06001397594809532
    },
    {
      "id": 154,
      "seek": 88984,
      "start": 895.3599853515625,
      "end": 899.760009765625,
      "text": " geben, warum ich das doch machen möchte. Und vielleicht ist in diesem spezifischen Fall die",
      "tokens": [
        50640,
        17191,
        11,
        24331,
        1893,
        1482,
        9243,
        7069,
        14570,
        13,
        2719,
        12547,
        1418,
        294,
        10975,
        768,
        89,
        351,
        6282,
        7465,
        978,
        50860
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2788906693458557,
      "compression_ratio": 1.6145833730697632,
      "no_speech_prob": 0.06001397594809532
    },
    {
      "id": 155,
      "seek": 88984,
      "start": 899.760009765625,
      "end": 906.3200073242188,
      "text": " Autonomie der Teams gar nicht so schlimm, wird nicht so stark eingeschränkt. Das heißt also,",
      "tokens": [
        50860,
        6049,
        12481,
        414,
        1163,
        24702,
        3691,
        1979,
        370,
        48821,
        11,
        4578,
        1979,
        370,
        17417,
        17002,
        22320,
        33766,
        2320,
        13,
        2846,
        13139,
        611,
        11,
        51188
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2788906693458557,
      "compression_ratio": 1.6145833730697632,
      "no_speech_prob": 0.06001397594809532
    },
    {
      "id": 156,
      "seek": 88984,
      "start": 906.3200073242188,
      "end": 911.8800048828125,
      "text": " ich muss mir die Frage stellen, was ist denn eigentlich das Ziel? Warum treffe ich diese",
      "tokens": [
        51188,
        1893,
        6425,
        3149,
        978,
        13685,
        24407,
        11,
        390,
        1418,
        10471,
        10926,
        1482,
        25391,
        30,
        25541,
        2192,
        16349,
        1893,
        6705,
        51466
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2788906693458557,
      "compression_ratio": 1.6145833730697632,
      "no_speech_prob": 0.06001397594809532
    },
    {
      "id": 157,
      "seek": 88984,
      "start": 911.8800048828125,
      "end": 916.3200073242188,
      "text": " Entscheidung? Und anhand dieser Kriterien sollte ich es anschließend bewerten. So das Paper fängt",
      "tokens": [
        51466,
        44667,
        30,
        2719,
        364,
        5543,
        9053,
        6332,
        1681,
        1053,
        18042,
        1893,
        785,
        31508,
        24476,
        521,
        17897,
        39990,
        13,
        407,
        1482,
        24990,
        283,
        29670,
        51688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2788906693458557,
      "compression_ratio": 1.6145833730697632,
      "no_speech_prob": 0.06001397594809532
    },
    {
      "id": 158,
      "seek": 91632,
      "start": 916.3200073242188,
      "end": 921.0399780273438,
      "text": " halt auch tatsächlich damit an und sagt halt, das Problem, das wir haben, ist, dass sowas wie",
      "tokens": [
        50364,
        12479,
        2168,
        20796,
        9479,
        364,
        674,
        15764,
        12479,
        11,
        1482,
        11676,
        11,
        1482,
        1987,
        3084,
        11,
        1418,
        11,
        2658,
        19766,
        296,
        3355,
        50600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28931450843811035,
      "compression_ratio": 1.5604026317596436,
      "no_speech_prob": 0.14179028570652008
    },
    {
      "id": 159,
      "seek": 91632,
      "start": 921.0399780273438,
      "end": 927.3599853515625,
      "text": " ein Actor, also ein Schauspieler oder ein Movie, also ein Film mehrfach modelliert ist. Und zwar",
      "tokens": [
        50600,
        1343,
        45457,
        11,
        611,
        1343,
        2065,
        8463,
        36037,
        260,
        4513,
        1343,
        28766,
        11,
        611,
        1343,
        13801,
        5417,
        6749,
        1072,
        898,
        4859,
        1418,
        13,
        2719,
        19054,
        50916
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28931450843811035,
      "compression_ratio": 1.5604026317596436,
      "no_speech_prob": 0.14179028570652008
    },
    {
      "id": 160,
      "seek": 91632,
      "start": 927.3599853515625,
      "end": 936.47998046875,
      "text": " in einer GraphQL-Gateway für die internen Anwendungen, im Asset Management, im Media",
      "tokens": [
        50916,
        294,
        6850,
        21884,
        13695,
        12,
        38,
        473,
        676,
        2959,
        978,
        2154,
        268,
        1107,
        20128,
        5084,
        11,
        566,
        1018,
        3854,
        14781,
        11,
        566,
        14741,
        51372
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28931450843811035,
      "compression_ratio": 1.5604026317596436,
      "no_speech_prob": 0.14179028570652008
    },
    {
      "id": 161,
      "seek": 91632,
      "start": 936.47998046875,
      "end": 941.4000244140625,
      "text": " Computing, wo also Sachen irgendwie encoded werden. Und die modellieren das leicht unterschiedlich,",
      "tokens": [
        51372,
        37804,
        278,
        11,
        6020,
        611,
        26074,
        20759,
        2058,
        12340,
        4604,
        13,
        2719,
        978,
        1072,
        898,
        5695,
        1482,
        28333,
        30058,
        1739,
        11,
        51618
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28931450843811035,
      "compression_ratio": 1.5604026317596436,
      "no_speech_prob": 0.14179028570652008
    },
    {
      "id": 162,
      "seek": 91632,
      "start": 941.4000244140625,
      "end": 945.719970703125,
      "text": " mit wenig Koordination oder gemeinsamen Verständnis. Oft haben sie dieselben Konzepte,",
      "tokens": [
        51618,
        2194,
        20911,
        10509,
        765,
        2486,
        4513,
        22971,
        22403,
        4281,
        16913,
        10661,
        13,
        37112,
        3084,
        2804,
        21258,
        1799,
        12718,
        46342,
        975,
        11,
        51834
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28931450843811035,
      "compression_ratio": 1.5604026317596436,
      "no_speech_prob": 0.14179028570652008
    },
    {
      "id": 163,
      "seek": 94572,
      "start": 945.8400268554688,
      "end": 951.5999755859375,
      "text": " aber sie wissen es nicht. Ich würde jetzt erstmal behaupten, das ist keine vernünftige Begründung,",
      "tokens": [
        50370,
        4340,
        2804,
        16331,
        785,
        1979,
        13,
        3141,
        11942,
        4354,
        38607,
        1540,
        13343,
        268,
        11,
        1482,
        1418,
        9252,
        35793,
        3412,
        844,
        3969,
        879,
        861,
        9541,
        1063,
        11,
        50658
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2763153910636902,
      "compression_ratio": 1.5622895956039429,
      "no_speech_prob": 0.00679559214040637
    },
    {
      "id": 164,
      "seek": 94572,
      "start": 951.5999755859375,
      "end": 958.760009765625,
      "text": " weil das ist sicher irgendwie, wie soll ich sagen, suboptimal. Das wünscht man sich vielleicht anders,",
      "tokens": [
        50658,
        7689,
        1482,
        1418,
        18623,
        20759,
        11,
        3355,
        7114,
        1893,
        8360,
        11,
        1422,
        5747,
        10650,
        13,
        2846,
        30841,
        82,
        4701,
        587,
        3041,
        12547,
        17999,
        11,
        51016
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2763153910636902,
      "compression_ratio": 1.5622895956039429,
      "no_speech_prob": 0.00679559214040637
    },
    {
      "id": 165,
      "seek": 94572,
      "start": 958.760009765625,
      "end": 963.4400024414062,
      "text": " gerade wenn man so ingenieursmäßig vorgeht. Aber bis jetzt habe ich noch nicht verstanden,",
      "tokens": [
        51016,
        12117,
        4797,
        587,
        370,
        21600,
        17743,
        43132,
        4245,
        46227,
        13,
        5992,
        7393,
        4354,
        6015,
        1893,
        3514,
        1979,
        1306,
        33946,
        11,
        51250
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2763153910636902,
      "compression_ratio": 1.5622895956039429,
      "no_speech_prob": 0.00679559214040637
    },
    {
      "id": 166,
      "seek": 94572,
      "start": 963.4400024414062,
      "end": 967.0800170898438,
      "text": " was sozusagen für BenutzerInnen oder irgendwelche anderen Stakeholder konkrete",
      "tokens": [
        51250,
        390,
        33762,
        2959,
        3964,
        325,
        4527,
        4575,
        2866,
        4513,
        26455,
        338,
        1876,
        11122,
        745,
        619,
        20480,
        21428,
        7600,
        51432
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2763153910636902,
      "compression_ratio": 1.5622895956039429,
      "no_speech_prob": 0.00679559214040637
    },
    {
      "id": 167,
      "seek": 94572,
      "start": 967.0800170898438,
      "end": 972.2000122070312,
      "text": " Nachteile sind. Es ist im Gegenteil so, wenn ich Sachen mehrfach modelliere, aus dem,",
      "tokens": [
        51432,
        426,
        26136,
        794,
        3290,
        13,
        2313,
        1418,
        566,
        27826,
        1576,
        388,
        370,
        11,
        4797,
        1893,
        26074,
        5417,
        6749,
        1072,
        898,
        14412,
        11,
        3437,
        1371,
        11,
        51688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2763153910636902,
      "compression_ratio": 1.5622895956039429,
      "no_speech_prob": 0.00679559214040637
    },
    {
      "id": 168,
      "seek": 97220,
      "start": 972.2000122070312,
      "end": 975.5999755859375,
      "text": " was ich vorher gesagt habe, kann es eben sein, dass es einen guten Grund dafür gibt,",
      "tokens": [
        50364,
        390,
        1893,
        29195,
        12260,
        6015,
        11,
        4028,
        785,
        11375,
        6195,
        11,
        2658,
        785,
        4891,
        31277,
        13941,
        13747,
        6089,
        11,
        50534
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23700104653835297,
      "compression_ratio": 1.590443730354309,
      "no_speech_prob": 0.04334059730172157
    },
    {
      "id": 169,
      "seek": 97220,
      "start": 975.5999755859375,
      "end": 981.0800170898438,
      "text": " nämlich höhere Autonomie und dass es in Wirklichkeit unterschiedliche Konzepte sind.",
      "tokens": [
        50534,
        21219,
        13531,
        6703,
        6049,
        12481,
        414,
        674,
        2658,
        785,
        294,
        4347,
        9056,
        9238,
        30058,
        10185,
        12718,
        46342,
        975,
        3290,
        13,
        50808
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23700104653835297,
      "compression_ratio": 1.590443730354309,
      "no_speech_prob": 0.04334059730172157
    },
    {
      "id": 170,
      "seek": 97220,
      "start": 981.0800170898438,
      "end": 986.52001953125,
      "text": " Das heißt also, auf dieser Ebene ist es jetzt erstmal so, dass ich noch nicht so richtig sehen",
      "tokens": [
        50808,
        2846,
        13139,
        611,
        11,
        2501,
        9053,
        20418,
        1450,
        1418,
        785,
        4354,
        38607,
        370,
        11,
        2658,
        1893,
        3514,
        1979,
        370,
        13129,
        11333,
        51080
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23700104653835297,
      "compression_ratio": 1.590443730354309,
      "no_speech_prob": 0.04334059730172157
    },
    {
      "id": 171,
      "seek": 97220,
      "start": 986.52001953125,
      "end": 992.1599731445312,
      "text": " kann, was eigentlich das Problem ist. Also doppelte und inkonsistente Modelle sind, glaube ich,",
      "tokens": [
        51080,
        4028,
        11,
        390,
        10926,
        1482,
        11676,
        1418,
        13,
        2743,
        44862,
        338,
        975,
        674,
        11276,
        892,
        468,
        1576,
        6583,
        4434,
        3290,
        11,
        13756,
        1893,
        11,
        51362
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23700104653835297,
      "compression_ratio": 1.590443730354309,
      "no_speech_prob": 0.04334059730172157
    },
    {
      "id": 172,
      "seek": 97220,
      "start": 992.1599731445312,
      "end": 1001.3200073242188,
      "text": " nicht das Problem. Dann haben sie als weiteres Thema halt inkonsistente Terminologie dargestellt. Das",
      "tokens": [
        51362,
        1979,
        1482,
        11676,
        13,
        7455,
        3084,
        2804,
        3907,
        8988,
        279,
        16306,
        12479,
        11276,
        892,
        468,
        1576,
        19835,
        259,
        20121,
        4072,
        26293,
        13,
        2846,
        51820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23700104653835297,
      "compression_ratio": 1.590443730354309,
      "no_speech_prob": 0.04334059730172157
    },
    {
      "id": 173,
      "seek": 100132,
      "start": 1001.3599853515625,
      "end": 1007.9600219726562,
      "text": " finde ich auch schwierig, denn wir haben es gerade eben bei dem Kunden von dem Hotel diskutiert.",
      "tokens": [
        50366,
        17841,
        1893,
        2168,
        37845,
        11,
        10471,
        1987,
        3084,
        785,
        12117,
        11375,
        4643,
        1371,
        38192,
        2957,
        1371,
        20354,
        36760,
        4859,
        13,
        50696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2956768274307251,
      "compression_ratio": 1.7360594272613525,
      "no_speech_prob": 0.008444787003099918
    },
    {
      "id": 174,
      "seek": 100132,
      "start": 1007.9600219726562,
      "end": 1014.0,
      "text": " Der Kunde des Hotels ist eben unterschiedlich, je nachdem, in welchem Kontext ich ihn betrachte.",
      "tokens": [
        50696,
        5618,
        591,
        13271,
        730,
        9423,
        1625,
        1418,
        11375,
        30058,
        1739,
        11,
        1506,
        5168,
        10730,
        11,
        294,
        2214,
        17345,
        20629,
        3828,
        1893,
        14534,
        778,
        81,
        26136,
        13,
        50998
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2956768274307251,
      "compression_ratio": 1.7360594272613525,
      "no_speech_prob": 0.008444787003099918
    },
    {
      "id": 175,
      "seek": 100132,
      "start": 1014.0,
      "end": 1019.2000122070312,
      "text": " Das erwarte ich halt. Das heißt also, diese inkonsistente Terminologie ist nicht etwas,",
      "tokens": [
        50998,
        2846,
        21715,
        11026,
        1893,
        12479,
        13,
        2846,
        13139,
        611,
        11,
        6705,
        11276,
        892,
        468,
        1576,
        19835,
        259,
        20121,
        1418,
        1979,
        9569,
        11,
        51258
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2956768274307251,
      "compression_ratio": 1.7360594272613525,
      "no_speech_prob": 0.008444787003099918
    },
    {
      "id": 176,
      "seek": 100132,
      "start": 1019.2000122070312,
      "end": 1024.8399658203125,
      "text": " was ich einfach abschalten kann, wenn ich mich auf etwas einige. Sondern es ist eben so,",
      "tokens": [
        51258,
        390,
        1893,
        7281,
        1950,
        339,
        23276,
        4028,
        11,
        4797,
        1893,
        6031,
        2501,
        9569,
        1343,
        3969,
        13,
        318,
        10881,
        785,
        1418,
        11375,
        370,
        11,
        51540
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2956768274307251,
      "compression_ratio": 1.7360594272613525,
      "no_speech_prob": 0.008444787003099918
    },
    {
      "id": 177,
      "seek": 100132,
      "start": 1024.8399658203125,
      "end": 1029.43994140625,
      "text": " dass der Kunde, der eincheckt, was anderes ist als der Kunde, der hat die Rechnung bezahlt oder",
      "tokens": [
        51540,
        2658,
        1163,
        591,
        13271,
        11,
        1163,
        1343,
        1876,
        19951,
        11,
        390,
        31426,
        1418,
        3907,
        1163,
        591,
        13271,
        11,
        1163,
        2385,
        978,
        1300,
        1377,
        1063,
        10782,
        44950,
        4513,
        51770
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2956768274307251,
      "compression_ratio": 1.7360594272613525,
      "no_speech_prob": 0.008444787003099918
    },
    {
      "id": 178,
      "seek": 102944,
      "start": 1029.47998046875,
      "end": 1033.9200439453125,
      "text": " die Rechnung bekommt. Das bedeutet, diese inkonsistente Terminologie ist eben ein Teil,",
      "tokens": [
        50366,
        978,
        1300,
        1377,
        1063,
        33429,
        13,
        2846,
        27018,
        11,
        6705,
        11276,
        892,
        468,
        1576,
        19835,
        259,
        20121,
        1418,
        11375,
        1343,
        16357,
        11,
        50588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3172268867492676,
      "compression_ratio": 1.6223021745681763,
      "no_speech_prob": 0.002934848191216588
    },
    {
      "id": 179,
      "seek": 102944,
      "start": 1033.9200439453125,
      "end": 1042.5999755859375,
      "text": " eine Auszeichnung der Modellierung meines Systems. Das ist also auch ein schwieriges",
      "tokens": [
        50588,
        3018,
        9039,
        32338,
        15539,
        1163,
        6583,
        898,
        11651,
        385,
        1652,
        27059,
        13,
        2846,
        1418,
        611,
        2168,
        1343,
        27546,
        20609,
        51022
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3172268867492676,
      "compression_ratio": 1.6223021745681763,
      "no_speech_prob": 0.002934848191216588
    },
    {
      "id": 180,
      "seek": 102944,
      "start": 1042.5999755859375,
      "end": 1046.719970703125,
      "text": " Thema und dem könnte ich jetzt auch zum Beispiel begegnen, indem ich beispielsweise im Kloß H",
      "tokens": [
        51022,
        16306,
        674,
        1371,
        17646,
        1893,
        4354,
        2168,
        5919,
        13772,
        41832,
        70,
        2866,
        11,
        37185,
        1893,
        40152,
        566,
        591,
        752,
        2536,
        389,
        51228
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3172268867492676,
      "compression_ratio": 1.6223021745681763,
      "no_speech_prob": 0.002934848191216588
    },
    {
      "id": 181,
      "seek": 102944,
      "start": 1046.719970703125,
      "end": 1053.9200439453125,
      "text": " schreibe, indem ich sage, das ist der Begriff und so sind die Synonyme oder dieser Begriff in",
      "tokens": [
        51228,
        956,
        10271,
        650,
        11,
        37185,
        1893,
        19721,
        11,
        1482,
        1418,
        1163,
        879,
        32783,
        674,
        370,
        3290,
        978,
        26155,
        2526,
        1398,
        4513,
        9053,
        879,
        32783,
        294,
        51588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3172268867492676,
      "compression_ratio": 1.6223021745681763,
      "no_speech_prob": 0.002934848191216588
    },
    {
      "id": 182,
      "seek": 102944,
      "start": 1053.9200439453125,
      "end": 1057.280029296875,
      "text": " den verschiedenen Bauern und Kontexten hat unterschiedliche Bedeutungen. Das ist nichts,",
      "tokens": [
        51588,
        1441,
        41043,
        28772,
        1248,
        674,
        20629,
        3828,
        268,
        2385,
        30058,
        10185,
        363,
        4858,
        325,
        5084,
        13,
        2846,
        1418,
        13004,
        11,
        51756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3172268867492676,
      "compression_ratio": 1.6223021745681763,
      "no_speech_prob": 0.002934848191216588
    },
    {
      "id": 183,
      "seek": 105728,
      "start": 1057.3199462890625,
      "end": 1064.199951171875,
      "text": " wo ich jetzt erstmal unbedingt Architekturmaßnahmen brauche. Zwei Punkte, die ich interessant finde",
      "tokens": [
        50366,
        6020,
        1893,
        4354,
        38607,
        41211,
        10984,
        642,
        2320,
        374,
        1696,
        2536,
        24221,
        1548,
        17545,
        13,
        1176,
        17849,
        47352,
        11,
        978,
        1893,
        37748,
        17841,
        50710
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31961384415626526,
      "compression_ratio": 1.5183672904968262,
      "no_speech_prob": 0.031608860939741135
    },
    {
      "id": 184,
      "seek": 105728,
      "start": 1064.199951171875,
      "end": 1070.9200439453125,
      "text": " und nachvollziehbar sind. Einmal Datenqualität. Also, dass diese Sachen auseinanderlaufen und",
      "tokens": [
        50710,
        674,
        5168,
        20654,
        28213,
        5356,
        3290,
        13,
        6391,
        5579,
        31126,
        22345,
        14053,
        13,
        2743,
        11,
        2658,
        6705,
        26074,
        257,
        438,
        20553,
        875,
        19890,
        674,
        51046
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31961384415626526,
      "compression_ratio": 1.5183672904968262,
      "no_speech_prob": 0.031608860939741135
    },
    {
      "id": 185,
      "seek": 105728,
      "start": 1070.9200439453125,
      "end": 1075.719970703125,
      "text": " Referenzen manchmal kaputt sind. Also, dass Systeme auf Daten in anderen Systemen verweisen,",
      "tokens": [
        51046,
        36889,
        268,
        2904,
        32092,
        13816,
        13478,
        3290,
        13,
        2743,
        11,
        2658,
        8910,
        68,
        2501,
        31126,
        294,
        11122,
        8910,
        268,
        1306,
        40196,
        11,
        51286
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31961384415626526,
      "compression_ratio": 1.5183672904968262,
      "no_speech_prob": 0.031608860939741135
    },
    {
      "id": 186,
      "seek": 105728,
      "start": 1075.719970703125,
      "end": 1080.56005859375,
      "text": " die nicht mehr dort sind. Das kann ein Thema sein. Es ist aber immer noch nicht so,",
      "tokens": [
        51286,
        978,
        1979,
        5417,
        15775,
        3290,
        13,
        2846,
        4028,
        1343,
        16306,
        6195,
        13,
        2313,
        1418,
        4340,
        5578,
        3514,
        1979,
        370,
        11,
        51528
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31961384415626526,
      "compression_ratio": 1.5183672904968262,
      "no_speech_prob": 0.031608860939741135
    },
    {
      "id": 187,
      "seek": 108056,
      "start": 1080.6800537109375,
      "end": 1085.47998046875,
      "text": " dass ich jetzt… Also, idealerweise würde ich mir wünschen, dass man sagt, an genau dieser",
      "tokens": [
        50370,
        2658,
        1893,
        4354,
        1260,
        2743,
        11,
        7157,
        44071,
        11942,
        1893,
        3149,
        30841,
        82,
        2470,
        11,
        2658,
        587,
        15764,
        11,
        364,
        12535,
        9053,
        50610
      ],
      "temperature": 0.0,
      "avg_logprob": -0.323313444852829,
      "compression_ratio": 1.6156584024429321,
      "no_speech_prob": 0.38382700085639954
    },
    {
      "id": 188,
      "seek": 108056,
      "start": 1085.47998046875,
      "end": 1090.3599853515625,
      "text": " Stelle hat irgendein Benutzer, irgendein Stakeholder ein echtes Problem gehabt und",
      "tokens": [
        50610,
        26629,
        2385,
        3418,
        27429,
        259,
        3964,
        325,
        4527,
        11,
        3418,
        27429,
        259,
        745,
        619,
        20480,
        1343,
        13972,
        279,
        11676,
        37092,
        674,
        50854
      ],
      "temperature": 0.0,
      "avg_logprob": -0.323313444852829,
      "compression_ratio": 1.6156584024429321,
      "no_speech_prob": 0.38382700085639954
    },
    {
      "id": 189,
      "seek": 108056,
      "start": 1090.3599853515625,
      "end": 1096.9599609375,
      "text": " das können wir jetzt lösen. Datenqualität an sich ist erst dann ein Problem, wenn daraus",
      "tokens": [
        50854,
        1482,
        6310,
        1987,
        4354,
        25209,
        6748,
        13,
        31126,
        22345,
        14053,
        364,
        3041,
        1418,
        11301,
        3594,
        1343,
        11676,
        11,
        4797,
        274,
        46483,
        51184
      ],
      "temperature": 0.0,
      "avg_logprob": -0.323313444852829,
      "compression_ratio": 1.6156584024429321,
      "no_speech_prob": 0.38382700085639954
    },
    {
      "id": 190,
      "seek": 108056,
      "start": 1096.9599609375,
      "end": 1102.0799560546875,
      "text": " irgendwelche Dinge hervorgehen, die wirklich Benutzer oder Stakeholder vor irgendwelche",
      "tokens": [
        51184,
        26455,
        338,
        1876,
        25102,
        720,
        85,
        4685,
        2932,
        11,
        978,
        9696,
        3964,
        325,
        4527,
        4513,
        745,
        619,
        20480,
        4245,
        26455,
        338,
        1876,
        51440
      ],
      "temperature": 0.0,
      "avg_logprob": -0.323313444852829,
      "compression_ratio": 1.6156584024429321,
      "no_speech_prob": 0.38382700085639954
    },
    {
      "id": 191,
      "seek": 108056,
      "start": 1102.0799560546875,
      "end": 1106.5999755859375,
      "text": " Schwierigkeiten stellen. Hier ist es für mich eher nachvollziehbar und das würde ich vielleicht",
      "tokens": [
        51440,
        17576,
        811,
        37545,
        24407,
        13,
        10886,
        1418,
        785,
        2959,
        6031,
        24332,
        5168,
        20654,
        28213,
        5356,
        674,
        1482,
        11942,
        1893,
        12547,
        51666
      ],
      "temperature": 0.0,
      "avg_logprob": -0.323313444852829,
      "compression_ratio": 1.6156584024429321,
      "no_speech_prob": 0.38382700085639954
    },
    {
      "id": 192,
      "seek": 110660,
      "start": 1106.8800048828125,
      "end": 1111.4000244140625,
      "text": " abstellen. Es fehlt vielleicht nur die Information, die sagt, an dieser Stelle ist das ein Problem.",
      "tokens": [
        50378,
        10823,
        8581,
        13,
        2313,
        47994,
        12547,
        4343,
        978,
        15357,
        11,
        978,
        15764,
        11,
        364,
        9053,
        26629,
        1418,
        1482,
        1343,
        11676,
        13,
        50604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33415839076042175,
      "compression_ratio": 1.5399999618530273,
      "no_speech_prob": 0.040826551616191864
    },
    {
      "id": 193,
      "seek": 110660,
      "start": 1111.4000244140625,
      "end": 1118.239990234375,
      "text": " Und dann haben sie noch aufgeschrieben, dass es wenig Verbindungen über Systeme hinweg gibt. Das",
      "tokens": [
        50604,
        2719,
        3594,
        3084,
        2804,
        3514,
        2501,
        23378,
        24027,
        11,
        2658,
        785,
        20911,
        27034,
        471,
        5084,
        4502,
        8910,
        68,
        14102,
        12517,
        6089,
        13,
        2846,
        50946
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33415839076042175,
      "compression_ratio": 1.5399999618530273,
      "no_speech_prob": 0.040826551616191864
    },
    {
      "id": 194,
      "seek": 110660,
      "start": 1118.239990234375,
      "end": 1122.5999755859375,
      "text": " könnte eventuell auch ein Thema sein, dass ich Schwierigkeiten habe, von einem System zu einem",
      "tokens": [
        50946,
        17646,
        2280,
        13789,
        2168,
        1343,
        16306,
        6195,
        11,
        2658,
        1893,
        17576,
        811,
        37545,
        6015,
        11,
        2957,
        6827,
        8910,
        2164,
        6827,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33415839076042175,
      "compression_ratio": 1.5399999618530273,
      "no_speech_prob": 0.040826551616191864
    },
    {
      "id": 195,
      "seek": 110660,
      "start": 1122.5999755859375,
      "end": 1129.1600341796875,
      "text": " anderen zu kommen und dort mehr Details zu finden. Interessant ist hier, dass diese Themen,",
      "tokens": [
        51164,
        11122,
        2164,
        11729,
        674,
        15775,
        5417,
        42811,
        2164,
        20734,
        13,
        5751,
        442,
        394,
        1418,
        3296,
        11,
        2658,
        6705,
        39229,
        11,
        51492
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33415839076042175,
      "compression_ratio": 1.5399999618530273,
      "no_speech_prob": 0.040826551616191864
    },
    {
      "id": 196,
      "seek": 112916,
      "start": 1129.760009765625,
      "end": 1137.800048828125,
      "text": " die eigentlich relevant sind, also Autonomie, Aufwand und so weiter, hier gar nicht diskutiert",
      "tokens": [
        50394,
        978,
        10926,
        7340,
        3290,
        11,
        611,
        6049,
        12481,
        414,
        11,
        9462,
        33114,
        674,
        370,
        8988,
        11,
        3296,
        3691,
        1979,
        36760,
        4859,
        50796
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3595377504825592,
      "compression_ratio": 1.5120967626571655,
      "no_speech_prob": 0.16639502346515656
    },
    {
      "id": 197,
      "seek": 112916,
      "start": 1137.800048828125,
      "end": 1142.199951171875,
      "text": " worden sind. Das heißt, es steht nirgendwo, ja, und dafür nehmen wir in Kauf, dass die Teams",
      "tokens": [
        50796,
        14054,
        3290,
        13,
        2846,
        13139,
        11,
        785,
        16361,
        297,
        347,
        9395,
        6120,
        11,
        2784,
        11,
        674,
        13747,
        19905,
        1987,
        294,
        44590,
        11,
        2658,
        978,
        24702,
        51016
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3595377504825592,
      "compression_ratio": 1.5120967626571655,
      "no_speech_prob": 0.16639502346515656
    },
    {
      "id": 198,
      "seek": 112916,
      "start": 1142.199951171875,
      "end": 1150.719970703125,
      "text": " weniger autonom sind. Das steht da nicht drin. Es ist für mich schwer nachvollziehbar, wie",
      "tokens": [
        51016,
        23224,
        18203,
        3290,
        13,
        2846,
        16361,
        1120,
        1979,
        24534,
        13,
        2313,
        1418,
        2959,
        6031,
        23809,
        5168,
        20654,
        28213,
        5356,
        11,
        3355,
        51442
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3595377504825592,
      "compression_ratio": 1.5120967626571655,
      "no_speech_prob": 0.16639502346515656
    },
    {
      "id": 199,
      "seek": 112916,
      "start": 1150.719970703125,
      "end": 1157.199951171875,
      "text": " gravierend diese Probleme sind. Ist da irgendwo etwas, wo wir jetzt einen Umsatzverlust haben",
      "tokens": [
        51442,
        7427,
        811,
        521,
        6705,
        32891,
        3290,
        13,
        12810,
        1120,
        40865,
        9569,
        11,
        6020,
        1987,
        4354,
        4891,
        46963,
        10300,
        331,
        75,
        381,
        3084,
        51766
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3595377504825592,
      "compression_ratio": 1.5120967626571655,
      "no_speech_prob": 0.16639502346515656
    },
    {
      "id": 200,
      "seek": 115720,
      "start": 1157.199951171875,
      "end": 1165.199951171875,
      "text": " oder irgendein Ansehensverlust oder irgendwelche Schwierigkeiten in dieser Richtung? Das steht",
      "tokens": [
        50364,
        4513,
        3418,
        27429,
        259,
        1107,
        405,
        71,
        694,
        331,
        75,
        381,
        4513,
        26455,
        338,
        1876,
        17576,
        811,
        37545,
        294,
        9053,
        33023,
        30,
        2846,
        16361,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3556034564971924,
      "compression_ratio": 1.7137681245803833,
      "no_speech_prob": 0.01032630167901516
    },
    {
      "id": 201,
      "seek": 115720,
      "start": 1165.199951171875,
      "end": 1168.52001953125,
      "text": " da nicht drin. Kann man aber auch nicht erwarten, weil es ist ein Blogpost und der Blogpost wird",
      "tokens": [
        50764,
        1120,
        1979,
        24534,
        13,
        29074,
        587,
        4340,
        2168,
        1979,
        21715,
        11719,
        11,
        7689,
        785,
        1418,
        1343,
        46693,
        23744,
        674,
        1163,
        46693,
        23744,
        4578,
        50930
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3556034564971924,
      "compression_ratio": 1.7137681245803833,
      "no_speech_prob": 0.01032630167901516
    },
    {
      "id": 202,
      "seek": 115720,
      "start": 1168.52001953125,
      "end": 1172.43994140625,
      "text": " ja jetzt nicht sagen, wir haben übrigens massive Schwierigkeiten. Und weil wir diese massiven",
      "tokens": [
        50930,
        2784,
        4354,
        1979,
        8360,
        11,
        1987,
        3084,
        38215,
        5994,
        17576,
        811,
        37545,
        13,
        2719,
        7689,
        1987,
        6705,
        2758,
        5709,
        51126
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3556034564971924,
      "compression_ratio": 1.7137681245803833,
      "no_speech_prob": 0.01032630167901516
    },
    {
      "id": 203,
      "seek": 115720,
      "start": 1172.43994140625,
      "end": 1177.4000244140625,
      "text": " Schwierigkeiten haben, haben wir folgende Entscheidung getroffen. Also es wird kein Mensch",
      "tokens": [
        51126,
        17576,
        811,
        37545,
        3084,
        11,
        3084,
        1987,
        3339,
        27429,
        44667,
        483,
        30594,
        13,
        2743,
        785,
        4578,
        13424,
        27773,
        51374
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3556034564971924,
      "compression_ratio": 1.7137681245803833,
      "no_speech_prob": 0.01032630167901516
    },
    {
      "id": 204,
      "seek": 115720,
      "start": 1177.4000244140625,
      "end": 1185.760009765625,
      "text": " sozusagen öffentlich zuzugeben, logischerweise. Die Lösung ist jetzt zu sagen, wir definieren",
      "tokens": [
        51374,
        33762,
        34603,
        2164,
        46285,
        1799,
        11,
        3565,
        19674,
        13109,
        13,
        3229,
        46934,
        1418,
        4354,
        2164,
        8360,
        11,
        1987,
        1561,
        5695,
        51792
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3556034564971924,
      "compression_ratio": 1.7137681245803833,
      "no_speech_prob": 0.01032630167901516
    },
    {
      "id": 205,
      "seek": 118576,
      "start": 1185.8800048828125,
      "end": 1191.0799560546875,
      "text": " einmal ein Modell und verwenden es überall wieder. Und das wollen wir machen mit mehr als",
      "tokens": [
        50370,
        11078,
        1343,
        6583,
        898,
        674,
        24615,
        8896,
        785,
        38035,
        6216,
        13,
        2719,
        1482,
        11253,
        1987,
        7069,
        2194,
        5417,
        3907,
        50630
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3083861172199249,
      "compression_ratio": 1.5955555438995361,
      "no_speech_prob": 0.003592690685763955
    },
    {
      "id": 206,
      "seek": 118576,
      "start": 1191.0799560546875,
      "end": 1195.47998046875,
      "text": " Dokumentation, nicht nur als Dokumentation, sondern wir wollen tatsächlich Schemata generieren,",
      "tokens": [
        50630,
        29768,
        2206,
        399,
        11,
        1979,
        4343,
        3907,
        29768,
        2206,
        399,
        11,
        11465,
        1987,
        11253,
        20796,
        2065,
        443,
        3274,
        1337,
        5695,
        11,
        50850
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3083861172199249,
      "compression_ratio": 1.5955555438995361,
      "no_speech_prob": 0.003592690685763955
    },
    {
      "id": 207,
      "seek": 118576,
      "start": 1195.47998046875,
      "end": 1206.0,
      "text": " Konsistenz erzwingen und so weiter. Das erste Interessante ist, dass genau genommen diese",
      "tokens": [
        50850,
        48163,
        4821,
        89,
        1189,
        89,
        7904,
        268,
        674,
        370,
        8988,
        13,
        2846,
        20951,
        5751,
        442,
        2879,
        1418,
        11,
        2658,
        12535,
        38715,
        6705,
        51376
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3083861172199249,
      "compression_ratio": 1.5955555438995361,
      "no_speech_prob": 0.003592690685763955
    },
    {
      "id": 208,
      "seek": 118576,
      "start": 1206.0,
      "end": 1212.3199462890625,
      "text": " Sache halt nur genutzt wird für Content Engineering. Content Engineering ist ein",
      "tokens": [
        51376,
        31452,
        12479,
        4343,
        1049,
        325,
        2682,
        4578,
        2959,
        30078,
        16215,
        13,
        30078,
        16215,
        1418,
        1343,
        51692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3083861172199249,
      "compression_ratio": 1.5955555438995361,
      "no_speech_prob": 0.003592690685763955
    },
    {
      "id": 209,
      "seek": 121232,
      "start": 1212.3199462890625,
      "end": 1218.760009765625,
      "text": " Bereich, den Netflix seit 2020 hat, damit deutlich nach den Netflix Microservices",
      "tokens": [
        50364,
        26489,
        11,
        1441,
        12778,
        16452,
        4808,
        2385,
        11,
        9479,
        24344,
        5168,
        1441,
        12778,
        5818,
        2635,
        47480,
        50686
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4520227015018463,
      "compression_ratio": 1.0945945978164673,
      "no_speech_prob": 0.8633546829223633
    },
    {
      "id": 0,
      "seek": 0,
      "start": 1233.78,
      "end": 1236.859999923706,
      "text": " Bedeutet das, dass wir nur ein Modell haben sollen?",
      "tokens": [
        50364,
        363,
        4858,
        20364,
        1482,
        11,
        2658,
        1987,
        4343,
        1343,
        6583,
        898,
        3084,
        24713,
        30,
        50518
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4191110134124756,
      "compression_ratio": 1.6402877569198608,
      "no_speech_prob": 0.8394168019294739
    },
    {
      "id": 1,
      "seek": 0,
      "start": 1236.859999923706,
      "end": 1242.6200001525879,
      "text": " Es könnte halt sein, dass wir halt ein bauenden Kontext haben mit einem Modell,",
      "tokens": [
        50518,
        2313,
        17646,
        12479,
        6195,
        11,
        2658,
        1987,
        12479,
        1343,
        272,
        1459,
        8896,
        20629,
        3828,
        3084,
        2194,
        6827,
        6583,
        898,
        11,
        50806
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4191110134124756,
      "compression_ratio": 1.6402877569198608,
      "no_speech_prob": 0.8394168019294739
    },
    {
      "id": 2,
      "seek": 0,
      "start": 1242.6200001525879,
      "end": 1247.2599995422363,
      "text": " nämlich Content Engineering und das halt aus diesem Grund dieses eine Modell",
      "tokens": [
        50806,
        21219,
        30078,
        16215,
        674,
        1482,
        12479,
        3437,
        10975,
        13941,
        12113,
        3018,
        6583,
        898,
        51038
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4191110134124756,
      "compression_ratio": 1.6402877569198608,
      "no_speech_prob": 0.8394168019294739
    },
    {
      "id": 3,
      "seek": 0,
      "start": 1247.2599995422363,
      "end": 1252.4199993896484,
      "text": " sozusagen funktioniert und das bedeutet auch, dass sie vielleicht gar nicht so",
      "tokens": [
        51038,
        33762,
        26160,
        674,
        1482,
        27018,
        2168,
        11,
        2658,
        2804,
        12547,
        3691,
        1979,
        370,
        51296
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4191110134124756,
      "compression_ratio": 1.6402877569198608,
      "no_speech_prob": 0.8394168019294739
    },
    {
      "id": 4,
      "seek": 0,
      "start": 1252.4199993896484,
      "end": 1257.2200005340576,
      "text": " viel Legacy-Themen haben. Also seit 2020, gut, sind immerhin fünf Jahre, aber es ist ein",
      "tokens": [
        51296,
        5891,
        42838,
        12,
        2434,
        14071,
        3084,
        13,
        2743,
        16452,
        4808,
        11,
        5228,
        11,
        3290,
        5578,
        10876,
        28723,
        15557,
        11,
        4340,
        785,
        1418,
        1343,
        51536
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4191110134124756,
      "compression_ratio": 1.6402877569198608,
      "no_speech_prob": 0.8394168019294739
    },
    {
      "id": 5,
      "seek": 0,
      "start": 1257.2200005340576,
      "end": 1260.78,
      "text": " relativ neues Thema und es ist halt auch deswegen ein neues Thema, weil eben",
      "tokens": [
        51536,
        21960,
        43979,
        16306,
        674,
        785,
        1418,
        12479,
        2168,
        26482,
        1343,
        43979,
        16306,
        11,
        7689,
        11375,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4191110134124756,
      "compression_ratio": 1.6402877569198608,
      "no_speech_prob": 0.8394168019294739
    },
    {
      "id": 6,
      "seek": 2700,
      "start": 1260.78,
      "end": 1265.78,
      "text": " Netflix noch nicht so lange, so jedenfalls meine Wahrnehmung selber, Content",
      "tokens": [
        50364,
        12778,
        3514,
        1979,
        370,
        18131,
        11,
        370,
        12906,
        18542,
        10946,
        36357,
        716,
        8587,
        1063,
        23888,
        11,
        30078,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2964220941066742,
      "compression_ratio": 1.6863354444503784,
      "no_speech_prob": 0.3301410973072052
    },
    {
      "id": 7,
      "seek": 2700,
      "start": 1265.78,
      "end": 1269.939999847412,
      "text": " tatsächlich produziert. Die haben ja früher halt nur Dinge vertrieben.",
      "tokens": [
        50614,
        20796,
        28093,
        4859,
        13,
        3229,
        3084,
        2784,
        32349,
        12479,
        4343,
        25102,
        6509,
        24027,
        13,
        50822
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2964220941066742,
      "compression_ratio": 1.6863354444503784,
      "no_speech_prob": 0.3301410973072052
    },
    {
      "id": 8,
      "seek": 2700,
      "start": 1269.939999847412,
      "end": 1273.379998474121,
      "text": " So und der Geschäftsprozess, der dort irgendwie abgebildet wird, ist halt sowas",
      "tokens": [
        50822,
        407,
        674,
        1163,
        40440,
        82,
        4318,
        37575,
        11,
        1163,
        15775,
        20759,
        410,
        10848,
        793,
        302,
        4578,
        11,
        1418,
        12479,
        19766,
        296,
        50994
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2964220941066742,
      "compression_ratio": 1.6863354444503784,
      "no_speech_prob": 0.3301410973072052
    },
    {
      "id": 9,
      "seek": 2700,
      "start": 1273.379998474121,
      "end": 1278.5399983215332,
      "text": " wie ein Pitch, wo man also sagt, das ist halt eine tolle Serie, dann halt eine",
      "tokens": [
        50994,
        3355,
        1343,
        430,
        1549,
        11,
        6020,
        587,
        611,
        15764,
        11,
        1482,
        1418,
        12479,
        3018,
        281,
        2447,
        49135,
        11,
        3594,
        12479,
        3018,
        51252
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2964220941066742,
      "compression_ratio": 1.6863354444503784,
      "no_speech_prob": 0.3301410973072052
    },
    {
      "id": 10,
      "seek": 2700,
      "start": 1278.5399983215332,
      "end": 1281.5399983215332,
      "text": " Business Negotiation, wo man also darüber diskutiert, wie man die halt",
      "tokens": [
        51252,
        10715,
        19103,
        26618,
        11,
        6020,
        587,
        611,
        21737,
        36760,
        4859,
        11,
        3355,
        587,
        978,
        12479,
        51402
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2964220941066742,
      "compression_ratio": 1.6863354444503784,
      "no_speech_prob": 0.3301410973072052
    },
    {
      "id": 11,
      "seek": 2700,
      "start": 1281.5399983215332,
      "end": 1285.2599995422363,
      "text": " irgendwie produzieren kann, nehme ich an, dann Pre-Production, Production, Post-",
      "tokens": [
        51402,
        20759,
        28093,
        5695,
        4028,
        11,
        48276,
        1893,
        364,
        11,
        3594,
        6001,
        12,
        42370,
        882,
        11,
        30088,
        11,
        10223,
        12,
        51588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2964220941066742,
      "compression_ratio": 1.6863354444503784,
      "no_speech_prob": 0.3301410973072052
    },
    {
      "id": 12,
      "seek": 2700,
      "start": 1285.2599995422363,
      "end": 1290.0599987792968,
      "text": " Production und schließlich Launch. Das heißt also, wir nehmen nur dieses Thema",
      "tokens": [
        51588,
        30088,
        674,
        956,
        44697,
        28119,
        13,
        2846,
        13139,
        611,
        11,
        1987,
        19905,
        4343,
        12113,
        16306,
        51828
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2964220941066742,
      "compression_ratio": 1.6863354444503784,
      "no_speech_prob": 0.3301410973072052
    },
    {
      "id": 13,
      "seek": 5628,
      "start": 1290.0599987792968,
      "end": 1294.3000004577636,
      "text": " aus dem gesamten Netflix-Universum raus. Das heißt also, an der Stelle, wo",
      "tokens": [
        50364,
        3437,
        1371,
        39746,
        1147,
        12778,
        12,
        12405,
        1762,
        449,
        17202,
        13,
        2846,
        13139,
        611,
        11,
        364,
        1163,
        26629,
        11,
        6020,
        50576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3406357765197754,
      "compression_ratio": 1.5536912679672241,
      "no_speech_prob": 0.009699685499072075
    },
    {
      "id": 14,
      "seek": 5628,
      "start": 1294.3000004577636,
      "end": 1299.659997253418,
      "text": " das Ding live gegangen ist, ist da Schluss. Was also bedeutet, dass wir",
      "tokens": [
        50576,
        1482,
        20558,
        1621,
        44415,
        1418,
        11,
        1418,
        1120,
        36573,
        13,
        3027,
        611,
        27018,
        11,
        2658,
        1987,
        50844
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3406357765197754,
      "compression_ratio": 1.5536912679672241,
      "no_speech_prob": 0.009699685499072075
    },
    {
      "id": 15,
      "seek": 5628,
      "start": 1299.659997253418,
      "end": 1305.0199978637695,
      "text": " wahrscheinlich, vielleicht nicht über ein unternehmenswertes Modell sprechen.",
      "tokens": [
        50844,
        30957,
        11,
        12547,
        1979,
        4502,
        1343,
        8662,
        716,
        8587,
        694,
        26521,
        279,
        6583,
        898,
        27853,
        13,
        51112
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3406357765197754,
      "compression_ratio": 1.5536912679672241,
      "no_speech_prob": 0.009699685499072075
    },
    {
      "id": 16,
      "seek": 5628,
      "start": 1305.0199978637695,
      "end": 1308.4199993896484,
      "text": " Ich bin mir auch nicht sicher, wie sehr wir über Legacy-Transformation",
      "tokens": [
        51112,
        3141,
        5171,
        3149,
        2168,
        1979,
        18623,
        11,
        3355,
        5499,
        1987,
        4502,
        42838,
        12,
        33339,
        8663,
        51282
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3406357765197754,
      "compression_ratio": 1.5536912679672241,
      "no_speech_prob": 0.009699685499072075
    },
    {
      "id": 17,
      "seek": 5628,
      "start": 1308.4199993896484,
      "end": 1312.4199993896484,
      "text": " sprechen, also ob wir darüber reden, dass wir alte Systeme modernisieren wollen.",
      "tokens": [
        51282,
        27853,
        11,
        611,
        1111,
        1987,
        21737,
        26447,
        11,
        2658,
        1987,
        38973,
        8910,
        68,
        4363,
        271,
        5695,
        11253,
        13,
        51482
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3406357765197754,
      "compression_ratio": 1.5536912679672241,
      "no_speech_prob": 0.009699685499072075
    },
    {
      "id": 18,
      "seek": 5628,
      "start": 1312.4199993896484,
      "end": 1318.5800030517578,
      "text": " Das wäre ja etwas, was sozusagen echten Umschwung wäre, oder nicht? Wo man jetzt",
      "tokens": [
        51482,
        2846,
        14558,
        2784,
        9569,
        11,
        390,
        33762,
        308,
        21043,
        46963,
        34655,
        1063,
        14558,
        11,
        4513,
        1979,
        30,
        6622,
        587,
        4354,
        51790
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3406357765197754,
      "compression_ratio": 1.5536912679672241,
      "no_speech_prob": 0.009699685499072075
    },
    {
      "id": 19,
      "seek": 8480,
      "start": 1318.6199963378906,
      "end": 1320.6999981689453,
      "text": " sagen würde, okay, wir haben halt Microservices gemacht, wir haben halt",
      "tokens": [
        50366,
        8360,
        11942,
        11,
        1392,
        11,
        1987,
        3084,
        12479,
        5818,
        2635,
        47480,
        12293,
        11,
        1987,
        3084,
        12479,
        50470
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31827297806739807,
      "compression_ratio": 1.656862735748291,
      "no_speech_prob": 0.03565531596541405
    },
    {
      "id": 20,
      "seek": 8480,
      "start": 1320.6999981689453,
      "end": 1323.7399990844726,
      "text": " dezentral irgendwelche Sachen modelliert, das war eine blöde Idee, wir machen jetzt",
      "tokens": [
        50470,
        368,
        14185,
        2155,
        26455,
        338,
        1876,
        26074,
        1072,
        898,
        4859,
        11,
        1482,
        1516,
        3018,
        888,
        973,
        1479,
        32651,
        11,
        1987,
        7069,
        4354,
        50622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31827297806739807,
      "compression_ratio": 1.656862735748291,
      "no_speech_prob": 0.03565531596541405
    },
    {
      "id": 21,
      "seek": 8480,
      "start": 1323.7399990844726,
      "end": 1327.6199963378906,
      "text": " dieses zentrale Modell. Das ist eigentlich nicht erkennbar, weil das",
      "tokens": [
        50622,
        12113,
        710,
        317,
        47282,
        6583,
        898,
        13,
        2846,
        1418,
        10926,
        1979,
        31879,
        1857,
        5356,
        11,
        7689,
        1482,
        50816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31827297806739807,
      "compression_ratio": 1.656862735748291,
      "no_speech_prob": 0.03565531596541405
    },
    {
      "id": 22,
      "seek": 8480,
      "start": 1327.6199963378906,
      "end": 1332.9799969482422,
      "text": " eben ein relativ neuer oder anderer Bereich ist, als der den Netflix",
      "tokens": [
        50816,
        11375,
        1343,
        21960,
        408,
        5486,
        4513,
        48108,
        26489,
        1418,
        11,
        3907,
        1163,
        1441,
        12778,
        51084
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31827297806739807,
      "compression_ratio": 1.656862735748291,
      "no_speech_prob": 0.03565531596541405
    },
    {
      "id": 23,
      "seek": 8480,
      "start": 1332.9799969482422,
      "end": 1339.3399975585937,
      "text": " zumindest 2015 hatte. Mir ist noch nicht ganz, also ich habe immer noch so ein",
      "tokens": [
        51084,
        38082,
        7546,
        13299,
        13,
        9421,
        1418,
        3514,
        1979,
        6312,
        11,
        611,
        1893,
        6015,
        5578,
        3514,
        370,
        1343,
        51402
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31827297806739807,
      "compression_ratio": 1.656862735748291,
      "no_speech_prob": 0.03565531596541405
    },
    {
      "id": 24,
      "seek": 8480,
      "start": 1339.3399975585937,
      "end": 1342.0599987792968,
      "text": " Problem damit zu verstehen, was eigentlich genau das Problem ist, das",
      "tokens": [
        51402,
        11676,
        9479,
        2164,
        37352,
        11,
        390,
        10926,
        12535,
        1482,
        11676,
        1418,
        11,
        1482,
        51538
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31827297806739807,
      "compression_ratio": 1.656862735748291,
      "no_speech_prob": 0.03565531596541405
    },
    {
      "id": 25,
      "seek": 8480,
      "start": 1342.0599987792968,
      "end": 1346.659997253418,
      "text": " gelöst werden soll. Und ich kann es so ein bisschen spoilern.",
      "tokens": [
        51538,
        4087,
        36995,
        4604,
        7114,
        13,
        2719,
        1893,
        4028,
        785,
        370,
        1343,
        10763,
        18630,
        1248,
        13,
        51768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31827297806739807,
      "compression_ratio": 1.656862735748291,
      "no_speech_prob": 0.03565531596541405
    },
    {
      "id": 26,
      "seek": 11288,
      "start": 1346.659997253418,
      "end": 1353.2600033569336,
      "text": " Ich würde behaupten, dass das Problem, das eigentlich gelöst wird, ein ganz",
      "tokens": [
        50364,
        3141,
        11942,
        1540,
        13343,
        268,
        11,
        2658,
        1482,
        11676,
        11,
        1482,
        10926,
        4087,
        36995,
        4578,
        11,
        1343,
        6312,
        50694
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38709262013435364,
      "compression_ratio": 1.3689839839935303,
      "no_speech_prob": 0.0017819649074226618
    },
    {
      "id": 27,
      "seek": 11288,
      "start": 1353.2600033569336,
      "end": 1357.3399975585937,
      "text": " anderes ist. Aber das sollten wir dann noch mal diskutieren.",
      "tokens": [
        50694,
        31426,
        1418,
        13,
        5992,
        1482,
        29096,
        1987,
        3594,
        3514,
        2806,
        36760,
        5695,
        13,
        50898
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38709262013435364,
      "compression_ratio": 1.3689839839935303,
      "no_speech_prob": 0.0017819649074226618
    },
    {
      "id": 28,
      "seek": 11288,
      "start": 1357.3399975585937,
      "end": 1367.4199993896484,
      "text": " So, jetzt ist halt die Frage, was macht dieses UDA-Ding? Und ich muss mal",
      "tokens": [
        50898,
        407,
        11,
        4354,
        1418,
        12479,
        978,
        13685,
        11,
        390,
        10857,
        12113,
        624,
        7509,
        12,
        35,
        278,
        30,
        2719,
        1893,
        6425,
        2806,
        51402
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38709262013435364,
      "compression_ratio": 1.3689839839935303,
      "no_speech_prob": 0.0017819649074226618
    },
    {
      "id": 29,
      "seek": 11288,
      "start": 1367.4199993896484,
      "end": 1373.3800061035156,
      "text": " kurz schauen. Genau, das wollte ich zeigen.",
      "tokens": [
        51402,
        20465,
        25672,
        13,
        22340,
        11,
        1482,
        24509,
        1893,
        24687,
        13,
        51700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38709262013435364,
      "compression_ratio": 1.3689839839935303,
      "no_speech_prob": 0.0017819649074226618
    },
    {
      "id": 30,
      "seek": 13960,
      "start": 1373.4199993896484,
      "end": 1377.6999981689453,
      "text": " Da kann man sich halt ein bisschen an der ersten Grafik orientieren, die die",
      "tokens": [
        50366,
        3933,
        4028,
        587,
        3041,
        12479,
        1343,
        10763,
        364,
        1163,
        17324,
        8985,
        31230,
        8579,
        5695,
        11,
        978,
        978,
        50580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2691304087638855,
      "compression_ratio": 1.6097561120986938,
      "no_speech_prob": 0.0054647186771035194
    },
    {
      "id": 31,
      "seek": 13960,
      "start": 1377.6999981689453,
      "end": 1381.539994506836,
      "text": " halt gebaut haben. Und da ist es halt letztendlich so, dass man sagt, okay, wir",
      "tokens": [
        50580,
        12479,
        49203,
        3084,
        13,
        2719,
        1120,
        1418,
        785,
        12479,
        35262,
        521,
        1739,
        370,
        11,
        2658,
        587,
        15764,
        11,
        1392,
        11,
        1987,
        50772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2691304087638855,
      "compression_ratio": 1.6097561120986938,
      "no_speech_prob": 0.0054647186771035194
    },
    {
      "id": 32,
      "seek": 13960,
      "start": 1381.539994506836,
      "end": 1384.6999981689453,
      "text": " haben ein Domainmodell in der Mitte, das mappen wir auf verschiedene",
      "tokens": [
        50772,
        3084,
        1343,
        16674,
        491,
        8014,
        898,
        294,
        1163,
        41526,
        11,
        1482,
        463,
        21278,
        1987,
        2501,
        35411,
        50930
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2691304087638855,
      "compression_ratio": 1.6097561120986938,
      "no_speech_prob": 0.0054647186771035194
    },
    {
      "id": 33,
      "seek": 13960,
      "start": 1384.6999981689453,
      "end": 1389.9400036621093,
      "text": " Repräsentationen. Da gibt es zum einen eine Repräsentation in Apache Iceberg, das",
      "tokens": [
        50930,
        3696,
        11397,
        49315,
        399,
        268,
        13,
        3933,
        6089,
        785,
        5919,
        4891,
        3018,
        3696,
        11397,
        49315,
        399,
        294,
        46597,
        15332,
        6873,
        11,
        1482,
        51192
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2691304087638855,
      "compression_ratio": 1.6097561120986938,
      "no_speech_prob": 0.0054647186771035194
    },
    {
      "id": 34,
      "seek": 13960,
      "start": 1389.9400036621093,
      "end": 1394.8999951171875,
      "text": " ist so eine Big-Data-Lösung, wo man also offensichtlich Analyse mit betreiben",
      "tokens": [
        51192,
        1418,
        370,
        3018,
        5429,
        12,
        35,
        3274,
        12,
        43,
        11310,
        1063,
        11,
        6020,
        587,
        611,
        766,
        694,
        41971,
        1107,
        5222,
        405,
        2194,
        778,
        25946,
        51440
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2691304087638855,
      "compression_ratio": 1.6097561120986938,
      "no_speech_prob": 0.0054647186771035194
    },
    {
      "id": 35,
      "seek": 13960,
      "start": 1394.8999951171875,
      "end": 1402.1000073242187,
      "text": " kann, GraphQL-Repräsentation für irgendwelche Datencontainer. Und unten",
      "tokens": [
        51440,
        4028,
        11,
        21884,
        13695,
        12,
        25554,
        11397,
        49315,
        399,
        2959,
        26455,
        338,
        1876,
        31126,
        9000,
        491,
        260,
        13,
        2719,
        25693,
        51800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2691304087638855,
      "compression_ratio": 1.6097561120986938,
      "no_speech_prob": 0.0054647186771035194
    },
    {
      "id": 36,
      "seek": 16832,
      "start": 1402.1000073242187,
      "end": 1405.4599926757812,
      "text": " haben wir dann halt auch eine Mapping-Richtung Data Mesh. Das fand ich",
      "tokens": [
        50364,
        3084,
        1987,
        3594,
        12479,
        2168,
        3018,
        376,
        10534,
        12,
        49,
        1405,
        1063,
        11888,
        376,
        14935,
        13,
        2846,
        38138,
        1893,
        50532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34439563751220703,
      "compression_ratio": 1.512195110321045,
      "no_speech_prob": 0.016911106184124947
    },
    {
      "id": 37,
      "seek": 16832,
      "start": 1405.4599926757812,
      "end": 1409.1400006103515,
      "text": " besonders interessant. Also das heißt, eine Lösung, Data Mesh-Lösung für",
      "tokens": [
        50532,
        25258,
        37748,
        13,
        2743,
        1482,
        13139,
        11,
        3018,
        441,
        11310,
        1063,
        11,
        11888,
        376,
        14935,
        12,
        43,
        11310,
        1063,
        2959,
        50716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34439563751220703,
      "compression_ratio": 1.512195110321045,
      "no_speech_prob": 0.016911106184124947
    },
    {
      "id": 38,
      "seek": 16832,
      "start": 1409.1400006103515,
      "end": 1415.300004272461,
      "text": " Datenprodukte ist eigentlich schon in Benutzung und ist eben eines der Mapping-",
      "tokens": [
        50716,
        31126,
        14314,
        18844,
        1418,
        10926,
        4981,
        294,
        3964,
        12950,
        1063,
        674,
        1418,
        11375,
        18599,
        1163,
        376,
        10534,
        12,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34439563751220703,
      "compression_ratio": 1.512195110321045,
      "no_speech_prob": 0.016911106184124947
    },
    {
      "id": 39,
      "seek": 16832,
      "start": 1415.300004272461,
      "end": 1421.0599987792968,
      "text": " Ziele. Und man will jetzt mit diesem System Content-Domain-Modelle",
      "tokens": [
        51024,
        1176,
        15949,
        13,
        2719,
        587,
        486,
        4354,
        2194,
        10975,
        8910,
        30078,
        12,
        35,
        298,
        491,
        12,
        44,
        378,
        4434,
        51312
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34439563751220703,
      "compression_ratio": 1.512195110321045,
      "no_speech_prob": 0.016911106184124947
    },
    {
      "id": 40,
      "seek": 16832,
      "start": 1421.0599987792968,
      "end": 1426.500001220703,
      "text": " registrieren können und umsetzen können. Und die halt entsprechend auch die",
      "tokens": [
        51312,
        11376,
        470,
        5170,
        6310,
        674,
        1105,
        3854,
        2904,
        6310,
        13,
        2719,
        978,
        12479,
        47823,
        2168,
        978,
        51584
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34439563751220703,
      "compression_ratio": 1.512195110321045,
      "no_speech_prob": 0.016911106184124947
    },
    {
      "id": 41,
      "seek": 19272,
      "start": 1426.500001220703,
      "end": 1432.6999981689453,
      "text": " Schemata übertragen können in Richtung von GraphQL Afro. Afro ist dieses",
      "tokens": [
        50364,
        2065,
        8615,
        64,
        3304,
        4290,
        20663,
        6310,
        294,
        33023,
        2957,
        21884,
        13695,
        3325,
        340,
        13,
        3325,
        340,
        1418,
        12113,
        50674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3005484640598297,
      "compression_ratio": 1.4814814329147339,
      "no_speech_prob": 0.5138058066368103
    },
    {
      "id": 42,
      "seek": 19272,
      "start": 1432.6999981689453,
      "end": 1437.6999981689453,
      "text": " Format, was zum Beispiel im Apache Kafka-Kontext genutzt wird. Was halt so",
      "tokens": [
        50674,
        10126,
        267,
        11,
        390,
        5919,
        13772,
        566,
        46597,
        47064,
        12,
        42,
        896,
        3828,
        1049,
        325,
        2682,
        4578,
        13,
        3027,
        12479,
        370,
        50924
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3005484640598297,
      "compression_ratio": 1.4814814329147339,
      "no_speech_prob": 0.5138058066368103
    },
    {
      "id": 43,
      "seek": 19272,
      "start": 1437.6999981689453,
      "end": 1442.7400067138672,
      "text": " rückwärtskompatible Möglichkeiten hat. Also wo ich halt dann tatsächlich dafür",
      "tokens": [
        50924,
        367,
        6536,
        86,
        2713,
        1373,
        74,
        8586,
        267,
        964,
        42627,
        2385,
        13,
        2743,
        6020,
        1893,
        12479,
        3594,
        20796,
        13747,
        51176
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3005484640598297,
      "compression_ratio": 1.4814814329147339,
      "no_speech_prob": 0.5138058066368103
    },
    {
      "id": 44,
      "seek": 19272,
      "start": 1442.7400067138672,
      "end": 1446.8600018310547,
      "text": " sorgen kann, dass ich halt Daten in einem alten Format bekomme, obwohl sie in einem",
      "tokens": [
        51176,
        47972,
        4028,
        11,
        2658,
        1893,
        12479,
        31126,
        294,
        6827,
        41217,
        10126,
        267,
        9393,
        15117,
        11,
        48428,
        2804,
        294,
        6827,
        51382
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3005484640598297,
      "compression_ratio": 1.4814814329147339,
      "no_speech_prob": 0.5138058066368103
    },
    {
      "id": 45,
      "seek": 19272,
      "start": 1446.8600018310547,
      "end": 1452.8999951171875,
      "text": " neuen Format vorliegen. Also mit einem integrierten Converter. Dann sowas wie SQL,",
      "tokens": [
        51382,
        21387,
        10126,
        267,
        4245,
        6302,
        1766,
        13,
        2743,
        2194,
        6827,
        16200,
        470,
        39990,
        2656,
        331,
        391,
        13,
        7455,
        19766,
        296,
        3355,
        19200,
        11,
        51684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3005484640598297,
      "compression_ratio": 1.4814814329147339,
      "no_speech_prob": 0.5138058066368103
    },
    {
      "id": 46,
      "seek": 21912,
      "start": 1452.8999951171875,
      "end": 1457.8999951171875,
      "text": " was bei Iceberg bei sich eine Rolle spielt, sowas wie RDF. Dazu kommen wir",
      "tokens": [
        50364,
        390,
        4643,
        15332,
        6873,
        220,
        21845,
        3041,
        3018,
        35376,
        39778,
        11,
        19766,
        296,
        3355,
        49488,
        37,
        13,
        34667,
        11729,
        1987,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42791855335235596,
      "compression_ratio": 1.6330934762954712,
      "no_speech_prob": 0.0027143999468535185
    },
    {
      "id": 47,
      "seek": 21912,
      "start": 1457.8999951171875,
      "end": 1462.259995727539,
      "text": " später nochmal. Oder auch eine Java-Repräsentation. Das ist halt das, was",
      "tokens": [
        50614,
        24196,
        26509,
        13,
        20988,
        2168,
        3018,
        10745,
        12,
        25554,
        11397,
        49315,
        399,
        13,
        2846,
        1418,
        12479,
        1482,
        11,
        390,
        50832
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42791855335235596,
      "compression_ratio": 1.6330934762954712,
      "no_speech_prob": 0.0027143999468535185
    },
    {
      "id": 48,
      "seek": 21912,
      "start": 1462.259995727539,
      "end": 1466.0599987792968,
      "text": " wir jetzt irgendwie bauen wollen. Oder was die halt gebaut haben. Dann wollen sie",
      "tokens": [
        50832,
        1987,
        4354,
        20759,
        43787,
        11253,
        13,
        20988,
        390,
        978,
        12479,
        49203,
        3084,
        13,
        7455,
        11253,
        2804,
        51022
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42791855335235596,
      "compression_ratio": 1.6330934762954712,
      "no_speech_prob": 0.0027143999468535185
    },
    {
      "id": 49,
      "seek": 21912,
      "start": 1466.0599987792968,
      "end": 1470.8199932861328,
      "text": " halt Daten transportieren vom GraphQL in Richtung zu dem Data Mesh",
      "tokens": [
        51022,
        12479,
        31126,
        5495,
        5695,
        10135,
        21884,
        13695,
        294,
        33023,
        2164,
        1371,
        11888,
        376,
        14935,
        51260
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42791855335235596,
      "compression_ratio": 1.6330934762954712,
      "no_speech_prob": 0.0027143999468535185
    },
    {
      "id": 50,
      "seek": 21912,
      "start": 1470.8199932861328,
      "end": 1475.9400036621093,
      "text": " zum Beispiel. Dann, dass sie halt irgendwie die Möglichkeit haben, über",
      "tokens": [
        51260,
        5919,
        13772,
        13,
        7455,
        11,
        2658,
        2804,
        12479,
        20759,
        978,
        30662,
        3084,
        11,
        4502,
        51516
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42791855335235596,
      "compression_ratio": 1.6330934762954712,
      "no_speech_prob": 0.0027143999468535185
    },
    {
      "id": 51,
      "seek": 21912,
      "start": 1475.9400036621093,
      "end": 1480.2200024414062,
      "text": " Change Data Capture, also wenn irgendwie Daten geändert werden, das halt in die",
      "tokens": [
        51516,
        15060,
        11888,
        9480,
        540,
        11,
        611,
        4797,
        20759,
        31126,
        1519,
        34945,
        4604,
        11,
        1482,
        12479,
        294,
        978,
        51730
      ],
      "temperature": 0.0,
      "avg_logprob": -0.42791855335235596,
      "compression_ratio": 1.6330934762954712,
      "no_speech_prob": 0.0027143999468535185
    },
    {
      "id": 52,
      "seek": 24644,
      "start": 1480.259995727539,
      "end": 1486.1000073242187,
      "text": " Iceberg-Datenprodukte reinzubekommen. Solche Geschichten. Und sie wollen dann",
      "tokens": [
        50366,
        15332,
        6873,
        12,
        35,
        7186,
        14314,
        18844,
        6561,
        89,
        1977,
        13675,
        13,
        7026,
        1876,
        14241,
        24681,
        13,
        2719,
        2804,
        11253,
        3594,
        50658
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3493097722530365,
      "compression_ratio": 1.4428571462631226,
      "no_speech_prob": 0.05497026816010475
    },
    {
      "id": 53,
      "seek": 24644,
      "start": 1486.1000073242187,
      "end": 1489.300004272461,
      "text": " eine Möglichkeit anbieten, um Domain-Konzepte zu finden und zu untersuchen",
      "tokens": [
        50658,
        3018,
        30662,
        364,
        65,
        25868,
        11,
        1105,
        16674,
        491,
        12,
        42,
        21972,
        595,
        975,
        2164,
        20734,
        674,
        2164,
        20983,
        11285,
        50818
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3493097722530365,
      "compression_ratio": 1.4428571462631226,
      "no_speech_prob": 0.05497026816010475
    },
    {
      "id": 54,
      "seek": 24644,
      "start": 1489.300004272461,
      "end": 1499.8999951171875,
      "text": " durch Queries oder andere und Grafen. Und auch programmatisch halt diesen",
      "tokens": [
        50818,
        7131,
        2326,
        21659,
        4513,
        10490,
        674,
        8985,
        6570,
        13,
        2719,
        2168,
        1461,
        15677,
        5494,
        12479,
        12862,
        51348
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3493097722530365,
      "compression_ratio": 1.4428571462631226,
      "no_speech_prob": 0.05497026816010475
    },
    {
      "id": 55,
      "seek": 24644,
      "start": 1499.8999951171875,
      "end": 1506.9400036621093,
      "text": " Grafen sozusagen untersuchen. So und damit ist eigentlich das Ziel, was sie",
      "tokens": [
        51348,
        8985,
        6570,
        33762,
        20983,
        11285,
        13,
        407,
        674,
        9479,
        1418,
        10926,
        1482,
        25391,
        11,
        390,
        2804,
        51700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3493097722530365,
      "compression_ratio": 1.4428571462631226,
      "no_speech_prob": 0.05497026816010475
    },
    {
      "id": 56,
      "seek": 27316,
      "start": 1506.9400036621093,
      "end": 1512.6199963378906,
      "text": " jetzt da tatsächlich verfolgen, eine Daten-Integration. Wo sie also im Prinzip",
      "tokens": [
        50364,
        4354,
        1120,
        20796,
        1306,
        7082,
        1766,
        11,
        3018,
        31126,
        12,
        40,
        9358,
        861,
        399,
        13,
        6622,
        2804,
        611,
        566,
        47572,
        50648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32111185789108276,
      "compression_ratio": 1.513157844543457,
      "no_speech_prob": 0.025944944471120834
    },
    {
      "id": 57,
      "seek": 27316,
      "start": 1512.6199963378906,
      "end": 1516.6199963378906,
      "text": " sagen, wir wollen halt Daten aus verschiedenen Bereichen vernetzen, in einen",
      "tokens": [
        50648,
        8360,
        11,
        1987,
        11253,
        12479,
        31126,
        3437,
        41043,
        17684,
        18613,
        1306,
        7129,
        2904,
        11,
        294,
        4891,
        50848
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32111185789108276,
      "compression_ratio": 1.513157844543457,
      "no_speech_prob": 0.025944944471120834
    },
    {
      "id": 58,
      "seek": 27316,
      "start": 1516.6199963378906,
      "end": 1520.1399853515625,
      "text": " großen Datengrafen reinbekommen. Diese ganzen Daten darüber eine",
      "tokens": [
        50848,
        23076,
        31126,
        20735,
        6570,
        6561,
        650,
        13675,
        13,
        18993,
        23966,
        31126,
        21737,
        3018,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32111185789108276,
      "compression_ratio": 1.513157844543457,
      "no_speech_prob": 0.025944944471120834
    },
    {
      "id": 59,
      "seek": 27316,
      "start": 1520.1399853515625,
      "end": 1525.4200146484375,
      "text": " gemeinsame Sicht anbieten und dafür sorgen, dass wir darüber halt arbeiten",
      "tokens": [
        51024,
        22971,
        529,
        36615,
        364,
        65,
        25868,
        674,
        13747,
        47972,
        11,
        2658,
        1987,
        21737,
        12479,
        23162,
        51288
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32111185789108276,
      "compression_ratio": 1.513157844543457,
      "no_speech_prob": 0.025944944471120834
    },
    {
      "id": 60,
      "seek": 27316,
      "start": 1525.4200146484375,
      "end": 1533.540009765625,
      "text": " können. Was für mich da hinweist, dass das",
      "tokens": [
        51288,
        6310,
        13,
        3027,
        2959,
        6031,
        1120,
        14102,
        826,
        468,
        11,
        2658,
        1482,
        51694
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32111185789108276,
      "compression_ratio": 1.513157844543457,
      "no_speech_prob": 0.025944944471120834
    },
    {
      "id": 61,
      "seek": 29976,
      "start": 1533.540009765625,
      "end": 1539.1399853515625,
      "text": " eigentliche Thema, was sie da haben, ein Datenanalyse-Thema ist. Also sie wollen,",
      "tokens": [
        50364,
        10926,
        68,
        16306,
        11,
        390,
        2804,
        1120,
        3084,
        11,
        1343,
        31126,
        282,
        5222,
        405,
        12,
        2434,
        5619,
        1418,
        13,
        2743,
        2804,
        11253,
        11,
        50644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2962217330932617,
      "compression_ratio": 1.6735395193099976,
      "no_speech_prob": 0.10951651632785797
    },
    {
      "id": 62,
      "seek": 29976,
      "start": 1539.1399853515625,
      "end": 1542.9800122070312,
      "text": " glaube ich, irgendwie eine Oberfläche irgendwelchen Menschen anbieten, die ja",
      "tokens": [
        50644,
        13756,
        1893,
        11,
        20759,
        3018,
        27664,
        3423,
        32664,
        26455,
        338,
        2470,
        8397,
        364,
        65,
        25868,
        11,
        978,
        2784,
        50836
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2962217330932617,
      "compression_ratio": 1.6735395193099976,
      "no_speech_prob": 0.10951651632785797
    },
    {
      "id": 63,
      "seek": 29976,
      "start": 1542.9800122070312,
      "end": 1548.739991455078,
      "text": " Domain-Expertinnen sind und dafür sorgen, dass die dann einheitlich auf diese",
      "tokens": [
        50836,
        16674,
        491,
        12,
        11149,
        15346,
        11399,
        3290,
        674,
        13747,
        47972,
        11,
        2658,
        978,
        3594,
        1343,
        8480,
        1739,
        2501,
        6705,
        51124
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2962217330932617,
      "compression_ratio": 1.6735395193099976,
      "no_speech_prob": 0.10951651632785797
    },
    {
      "id": 64,
      "seek": 29976,
      "start": 1548.739991455078,
      "end": 1552.3800061035156,
      "text": " verschiedenen Datenquellen zugreifen können. Und das ist die Richtung, in die",
      "tokens": [
        51124,
        41043,
        31126,
        358,
        8581,
        33507,
        265,
        25076,
        6310,
        13,
        2719,
        1482,
        1418,
        978,
        33023,
        11,
        294,
        978,
        51306
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2962217330932617,
      "compression_ratio": 1.6735395193099976,
      "no_speech_prob": 0.10951651632785797
    },
    {
      "id": 65,
      "seek": 29976,
      "start": 1552.3800061035156,
      "end": 1557.8200085449218,
      "text": " sie halt erstmal, glaube ich, marschieren wollen. Und das ist was anderes. Also das",
      "tokens": [
        51306,
        2804,
        12479,
        38607,
        11,
        13756,
        1893,
        11,
        30517,
        339,
        5695,
        11253,
        13,
        2719,
        1482,
        1418,
        390,
        31426,
        13,
        2743,
        1482,
        51578
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2962217330932617,
      "compression_ratio": 1.6735395193099976,
      "no_speech_prob": 0.10951651632785797
    },
    {
      "id": 66,
      "seek": 29976,
      "start": 1557.8200085449218,
      "end": 1561.1000073242187,
      "text": " Problemsetting war ja nicht, wir haben ganz viele Datencontainer und wir können die",
      "tokens": [
        51578,
        11676,
        3854,
        783,
        1516,
        2784,
        1979,
        11,
        1987,
        3084,
        6312,
        9693,
        31126,
        9000,
        491,
        260,
        674,
        1987,
        6310,
        978,
        51742
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2962217330932617,
      "compression_ratio": 1.6735395193099976,
      "no_speech_prob": 0.10951651632785797
    },
    {
      "id": 67,
      "seek": 32732,
      "start": 1561.1000073242187,
      "end": 1566.2200024414062,
      "text": " Daten nicht analysieren, sondern die Aussage war, naja, unsere Datenqualität",
      "tokens": [
        50364,
        31126,
        1979,
        23014,
        5695,
        11,
        11465,
        978,
        21286,
        609,
        1516,
        11,
        1667,
        2938,
        11,
        14339,
        31126,
        22345,
        14053,
        50620
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3122953772544861,
      "compression_ratio": 1.5597269535064697,
      "no_speech_prob": 0.030660631135106087
    },
    {
      "id": 68,
      "seek": 32732,
      "start": 1566.2200024414062,
      "end": 1572.3800061035156,
      "text": " und diese Sachen sind halt ein bisschen schwierig. Und damit ist das nach meinem",
      "tokens": [
        50620,
        674,
        6705,
        26074,
        3290,
        12479,
        1343,
        10763,
        37845,
        13,
        2719,
        9479,
        1418,
        1482,
        5168,
        24171,
        50928
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3122953772544861,
      "compression_ratio": 1.5597269535064697,
      "no_speech_prob": 0.030660631135106087
    },
    {
      "id": 69,
      "seek": 32732,
      "start": 1572.3800061035156,
      "end": 1575.7000134277343,
      "text": " Empfinden eben eigentlich ein Daten-Integrationsthema, ein Analyse-Thema und",
      "tokens": [
        50928,
        8599,
        43270,
        11375,
        10926,
        1343,
        31126,
        12,
        40,
        9358,
        861,
        399,
        372,
        71,
        5619,
        11,
        1343,
        1107,
        5222,
        405,
        12,
        2434,
        5619,
        674,
        51094
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3122953772544861,
      "compression_ratio": 1.5597269535064697,
      "no_speech_prob": 0.030660631135106087
    },
    {
      "id": 70,
      "seek": 32732,
      "start": 1575.7000134277343,
      "end": 1580.8999951171875,
      "text": " halt auch etwas, wo diese Data-Products wieder eine Rolle spielen. Und ohne",
      "tokens": [
        51094,
        12479,
        2168,
        9569,
        11,
        6020,
        6705,
        11888,
        12,
        42370,
        349,
        82,
        6216,
        3018,
        35376,
        30950,
        13,
        2719,
        15716,
        51354
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3122953772544861,
      "compression_ratio": 1.5597269535064697,
      "no_speech_prob": 0.030660631135106087
    },
    {
      "id": 71,
      "seek": 32732,
      "start": 1580.8999951171875,
      "end": 1584.739991455078,
      "text": " jetzt sozusagen der endgültigen Diskussion vorgreifen zu wollen, bedeutet",
      "tokens": [
        51354,
        4354,
        33762,
        1163,
        917,
        70,
        774,
        2282,
        3213,
        45963,
        313,
        4245,
        33248,
        25076,
        2164,
        11253,
        11,
        27018,
        51546
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3122953772544861,
      "compression_ratio": 1.5597269535064697,
      "no_speech_prob": 0.030660631135106087
    },
    {
      "id": 72,
      "seek": 32732,
      "start": 1584.739991455078,
      "end": 1588.1799938964843,
      "text": " das, dass halt diese Aussage, ich habe einzelne Systeme, die getrennte",
      "tokens": [
        51546,
        1482,
        11,
        2658,
        12479,
        6705,
        21286,
        609,
        11,
        1893,
        6015,
        36731,
        716,
        8910,
        68,
        11,
        978,
        483,
        1095,
        9358,
        51718
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3122953772544861,
      "compression_ratio": 1.5597269535064697,
      "no_speech_prob": 0.030660631135106087
    },
    {
      "id": 73,
      "seek": 35440,
      "start": 1588.1799938964843,
      "end": 1594.1399853515625,
      "text": " Modelle haben, das steht da, glaube ich, gar nicht so im Kern dahinter, dass man",
      "tokens": [
        50364,
        6583,
        4434,
        3084,
        11,
        1482,
        16361,
        1120,
        11,
        13756,
        1893,
        11,
        3691,
        1979,
        370,
        566,
        40224,
        16800,
        5106,
        11,
        2658,
        587,
        50662
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35726234316825867,
      "compression_ratio": 1.4553191661834717,
      "no_speech_prob": 0.06183716282248497
    },
    {
      "id": 74,
      "seek": 35440,
      "start": 1594.1399853515625,
      "end": 1598.2999890136718,
      "text": " jetzt davon eine Abkehr irgendwie haben wird.",
      "tokens": [
        50662,
        4354,
        18574,
        3018,
        2847,
        22833,
        20759,
        3084,
        4578,
        13,
        50870
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35726234316825867,
      "compression_ratio": 1.4553191661834717,
      "no_speech_prob": 0.06183716282248497
    },
    {
      "id": 75,
      "seek": 35440,
      "start": 1598.8599865722656,
      "end": 1604.5799877929687,
      "text": " Und genau, das heißt, sie wollen jetzt so Knowledge-Graphen bauen, wo sie eben",
      "tokens": [
        50898,
        2719,
        12535,
        11,
        1482,
        13139,
        11,
        2804,
        11253,
        4354,
        370,
        32906,
        12,
        38,
        2662,
        268,
        43787,
        11,
        6020,
        2804,
        11375,
        51184
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35726234316825867,
      "compression_ratio": 1.4553191661834717,
      "no_speech_prob": 0.06183716282248497
    },
    {
      "id": 76,
      "seek": 35440,
      "start": 1604.5799877929687,
      "end": 1607.4200146484375,
      "text": " diese ganzen Sachen gemeinsam miteinander vernetzen.",
      "tokens": [
        51184,
        6705,
        23966,
        26074,
        29701,
        43127,
        1306,
        7129,
        2904,
        13,
        51326
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35726234316825867,
      "compression_ratio": 1.4553191661834717,
      "no_speech_prob": 0.06183716282248497
    },
    {
      "id": 77,
      "seek": 35440,
      "start": 1607.4200146484375,
      "end": 1612.3800061035156,
      "text": " Dafür benutzen sie RDF, dieses Resource Description Framework. Das ist etwas, was",
      "tokens": [
        51326,
        35865,
        38424,
        2904,
        2804,
        49488,
        37,
        11,
        12113,
        35200,
        3885,
        12432,
        31628,
        1902,
        13,
        2846,
        1418,
        9569,
        11,
        390,
        51574
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35726234316825867,
      "compression_ratio": 1.4553191661834717,
      "no_speech_prob": 0.06183716282248497
    },
    {
      "id": 78,
      "seek": 37860,
      "start": 1612.500001220703,
      "end": 1619.6199963378906,
      "text": " ist bei B3 schon lange gibt, also beim B3C, so für dieses Semantic Web Zeug, was",
      "tokens": [
        50370,
        1418,
        4643,
        363,
        18,
        4981,
        18131,
        6089,
        11,
        611,
        13922,
        363,
        18,
        34,
        11,
        370,
        2959,
        12113,
        14421,
        7128,
        9573,
        4853,
        697,
        11,
        390,
        50726
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3859214782714844,
      "compression_ratio": 1.3719007968902588,
      "no_speech_prob": 0.34426456689834595
    },
    {
      "id": 79,
      "seek": 37860,
      "start": 1619.6199963378906,
      "end": 1627.019990234375,
      "text": " ich glaube sogar schon in den 90ern ein Thema war, wo ich also so Aussagen formalisiert",
      "tokens": [
        50726,
        1893,
        13756,
        19485,
        4981,
        294,
        1441,
        4289,
        1248,
        1343,
        16306,
        1516,
        11,
        6020,
        1893,
        611,
        370,
        21286,
        4698,
        9860,
        42266,
        51096
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3859214782714844,
      "compression_ratio": 1.3719007968902588,
      "no_speech_prob": 0.34426456689834595
    },
    {
      "id": 80,
      "seek": 37860,
      "start": 1627.019990234375,
      "end": 1632.0599987792968,
      "text": " treffen kann über Ressourcen, Subjekte, Prädikate und Objekte. Sowas, also das",
      "tokens": [
        51096,
        37620,
        4028,
        4502,
        497,
        442,
        396,
        13037,
        11,
        8511,
        27023,
        975,
        11,
        2114,
        16837,
        1035,
        473,
        674,
        4075,
        27023,
        975,
        13,
        48644,
        296,
        11,
        611,
        1482,
        51348
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3859214782714844,
      "compression_ratio": 1.3719007968902588,
      "no_speech_prob": 0.34426456689834595
    },
    {
      "id": 81,
      "seek": 37860,
      "start": 1632.0599987792968,
      "end": 1637.0599987792968,
      "text": " Beispiel, was wir im Text nennen, ist ECMI produziert Batterien. Das heißt also,",
      "tokens": [
        51348,
        13772,
        11,
        390,
        1987,
        566,
        18643,
        297,
        16043,
        11,
        1418,
        19081,
        13808,
        28093,
        4859,
        33066,
        1053,
        13,
        2846,
        13139,
        611,
        11,
        51598
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3859214782714844,
      "compression_ratio": 1.3719007968902588,
      "no_speech_prob": 0.34426456689834595
    },
    {
      "id": 82,
      "seek": 40328,
      "start": 1638.0599987792968,
      "end": 1644.6600048828125,
      "text": " das Subjekt ist ECMI und das Prädikat ist produziert und das Objekt ist Batterien,",
      "tokens": [
        50414,
        1482,
        8511,
        14930,
        1418,
        19081,
        13808,
        674,
        1482,
        2114,
        16837,
        36300,
        1418,
        28093,
        4859,
        674,
        1482,
        4075,
        14930,
        1418,
        33066,
        1053,
        11,
        50744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3690827488899231,
      "compression_ratio": 1.61044180393219,
      "no_speech_prob": 0.03960476815700531
    },
    {
      "id": 83,
      "seek": 40328,
      "start": 1644.6600048828125,
      "end": 1649.78,
      "text": " nicht? Also grammatikalisch falsch, aber das stellt einen Zusammenhang hin hier",
      "tokens": [
        50744,
        1979,
        30,
        2743,
        17570,
        267,
        41216,
        5494,
        43340,
        11,
        4340,
        1482,
        38582,
        4891,
        29442,
        23850,
        14102,
        3296,
        51000
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3690827488899231,
      "compression_ratio": 1.61044180393219,
      "no_speech_prob": 0.03960476815700531
    },
    {
      "id": 84,
      "seek": 40328,
      "start": 1649.78,
      "end": 1654.4200146484375,
      "text": " zwischen Batterien und ECMI und zwar, wie wir diesen Zusammenhang produzieren.",
      "tokens": [
        51000,
        19875,
        33066,
        1053,
        674,
        19081,
        13808,
        674,
        19054,
        11,
        3355,
        1987,
        12862,
        29442,
        23850,
        28093,
        5695,
        13,
        51232
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3690827488899231,
      "compression_ratio": 1.61044180393219,
      "no_speech_prob": 0.03960476815700531
    },
    {
      "id": 85,
      "seek": 40328,
      "start": 1654.4200146484375,
      "end": 1660.8200085449218,
      "text": " Und das ist jetzt eben etwas, also das Wikipedia-Beispiel für RDF und das ist",
      "tokens": [
        51232,
        2719,
        1482,
        1418,
        4354,
        11375,
        9569,
        11,
        611,
        1482,
        28999,
        12,
        6524,
        11935,
        2959,
        49488,
        37,
        674,
        1482,
        1418,
        51552
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3690827488899231,
      "compression_ratio": 1.61044180393219,
      "no_speech_prob": 0.03960476815700531
    },
    {
      "id": 86,
      "seek": 40328,
      "start": 1660.8200085449218,
      "end": 1664.0599987792968,
      "text": " jetzt etwas, was ich natürlich nutzen kann, um irgendwie so Anthropologien und",
      "tokens": [
        51552,
        4354,
        9569,
        11,
        390,
        1893,
        8762,
        36905,
        4028,
        11,
        1105,
        20759,
        370,
        12727,
        1513,
        1132,
        1053,
        674,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3690827488899231,
      "compression_ratio": 1.61044180393219,
      "no_speech_prob": 0.03960476815700531
    },
    {
      "id": 87,
      "seek": 43028,
      "start": 1664.0599987792968,
      "end": 1669.3800061035156,
      "text": " solche Sachen aufzubauen, wo ich Begriffe in Verbindung miteinander setze. Und sie",
      "tokens": [
        50364,
        29813,
        26074,
        2501,
        40566,
        11715,
        11,
        6020,
        1893,
        879,
        861,
        31387,
        294,
        27034,
        41442,
        43127,
        992,
        1381,
        13,
        2719,
        2804,
        50630
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3041362762451172,
      "compression_ratio": 1.4533898830413818,
      "no_speech_prob": 0.2533320188522339
    },
    {
      "id": 88,
      "seek": 43028,
      "start": 1669.3800061035156,
      "end": 1678.540009765625,
      "text": " haben dann diese Shape Constraint Language, SHACL heißt die, die jetzt irgendwie noch",
      "tokens": [
        50630,
        3084,
        3594,
        6705,
        49148,
        8574,
        424,
        686,
        24445,
        11,
        7405,
        4378,
        43,
        13139,
        978,
        11,
        978,
        4354,
        20759,
        3514,
        51088
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3041362762451172,
      "compression_ratio": 1.4533898830413818,
      "no_speech_prob": 0.2533320188522339
    },
    {
      "id": 89,
      "seek": 43028,
      "start": 1678.540009765625,
      "end": 1687.4599926757812,
      "text": " weiter auf diesen RDF-Grafen Constraints einführen kann. Und das ist jetzt etwas,",
      "tokens": [
        51088,
        8988,
        2501,
        12862,
        49488,
        37,
        12,
        38,
        10437,
        268,
        8574,
        424,
        8654,
        38627,
        29540,
        4028,
        13,
        2719,
        1482,
        1418,
        4354,
        9569,
        11,
        51534
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3041362762451172,
      "compression_ratio": 1.4533898830413818,
      "no_speech_prob": 0.2533320188522339
    },
    {
      "id": 90,
      "seek": 43028,
      "start": 1687.4599926757812,
      "end": 1690.9800122070312,
      "text": " was vielleicht, wo ich mir nicht sicher bin, ob es für die Architekturdiskussion relevant",
      "tokens": [
        51534,
        390,
        12547,
        11,
        6020,
        1893,
        3149,
        1979,
        18623,
        5171,
        11,
        1111,
        785,
        2959,
        978,
        10984,
        642,
        2320,
        10752,
        7797,
        2023,
        313,
        7340,
        51710
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3041362762451172,
      "compression_ratio": 1.4533898830413818,
      "no_speech_prob": 0.2533320188522339
    },
    {
      "id": 91,
      "seek": 45720,
      "start": 1691.1399853515625,
      "end": 1697.9400036621093,
      "text": " ist. Aber es ist halt etwas, wo wir jetzt Semantik von Daten sozusagen einfangen können.",
      "tokens": [
        50372,
        1418,
        13,
        5992,
        785,
        1418,
        12479,
        9569,
        11,
        6020,
        1987,
        4354,
        14421,
        394,
        1035,
        2957,
        31126,
        33762,
        38627,
        10784,
        6310,
        13,
        50712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3174342215061188,
      "compression_ratio": 1.6281588077545166,
      "no_speech_prob": 0.03510603681206703
    },
    {
      "id": 92,
      "seek": 45720,
      "start": 1697.9400036621093,
      "end": 1703.5799877929687,
      "text": " Und ich hatte es vorhin schon gesagt, ein Realist hat es eben auch schon kurz gesagt,",
      "tokens": [
        50712,
        2719,
        1893,
        13299,
        785,
        4245,
        10876,
        4981,
        12260,
        11,
        1343,
        8467,
        468,
        2385,
        785,
        11375,
        2168,
        4981,
        20465,
        12260,
        11,
        50994
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3174342215061188,
      "compression_ratio": 1.6281588077545166,
      "no_speech_prob": 0.03510603681206703
    },
    {
      "id": 93,
      "seek": 45720,
      "start": 1703.5799877929687,
      "end": 1708.3800061035156,
      "text": " ich brauche halt irgendwie solche semantischen Dinge, um jetzt Anthropologien zu haben und um",
      "tokens": [
        50994,
        1893,
        1548,
        17545,
        12479,
        20759,
        29813,
        4361,
        394,
        6282,
        25102,
        11,
        1105,
        4354,
        12727,
        1513,
        1132,
        1053,
        2164,
        3084,
        674,
        1105,
        51234
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3174342215061188,
      "compression_ratio": 1.6281588077545166,
      "no_speech_prob": 0.03510603681206703
    },
    {
      "id": 94,
      "seek": 45720,
      "start": 1708.3800061035156,
      "end": 1713.4200146484375,
      "text": " unsere Mapping halt irgendwie auf die Reihe zu bekommen. So und sie haben jetzt verschiedene",
      "tokens": [
        51234,
        14339,
        376,
        10534,
        12479,
        20759,
        2501,
        978,
        34549,
        675,
        2164,
        19256,
        13,
        407,
        674,
        2804,
        3084,
        4354,
        35411,
        51486
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3174342215061188,
      "compression_ratio": 1.6281588077545166,
      "no_speech_prob": 0.03510603681206703
    },
    {
      "id": 95,
      "seek": 45720,
      "start": 1713.4200146484375,
      "end": 1720.4200146484375,
      "text": " Bestandteile des Systems. Da gibt es einmal das Primary Data Management, PDM. Da gibt es",
      "tokens": [
        51486,
        9752,
        474,
        975,
        794,
        730,
        27059,
        13,
        3933,
        6089,
        785,
        11078,
        1482,
        42576,
        11888,
        14781,
        11,
        10464,
        44,
        13,
        3933,
        6089,
        785,
        51836
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3174342215061188,
      "compression_ratio": 1.6281588077545166,
      "no_speech_prob": 0.03510603681206703
    },
    {
      "id": 96,
      "seek": 48664,
      "start": 1720.5799877929687,
      "end": 1724.4599926757812,
      "text": " diese Referenzdaten und diese Taxonomien drin. Das heißt, da steht jetzt irgendwie drin,",
      "tokens": [
        50372,
        6705,
        36889,
        11368,
        67,
        7186,
        674,
        6705,
        23263,
        12481,
        1053,
        24534,
        13,
        2846,
        13139,
        11,
        1120,
        16361,
        4354,
        20759,
        24534,
        11,
        50566
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33211714029312134,
      "compression_ratio": 1.6395759582519531,
      "no_speech_prob": 0.024409016594290733
    },
    {
      "id": 97,
      "seek": 48664,
      "start": 1724.4599926757812,
      "end": 1732.4200146484375,
      "text": " was halt semantisch wie rot modelliert ist. Und das generiert eine UI für Business-Anwender in.",
      "tokens": [
        50566,
        390,
        12479,
        4361,
        394,
        5494,
        3355,
        4297,
        1072,
        898,
        4859,
        1418,
        13,
        2719,
        1482,
        1337,
        4859,
        3018,
        15682,
        2959,
        10715,
        12,
        7828,
        86,
        3216,
        294,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33211714029312134,
      "compression_ratio": 1.6395759582519531,
      "no_speech_prob": 0.024409016594290733
    },
    {
      "id": 98,
      "seek": 48664,
      "start": 1732.4200146484375,
      "end": 1738.260010986328,
      "text": " So und da ist wieder die Geschichte. Also wenn ich sozusagen nur das Problem anschaue. In dem",
      "tokens": [
        50964,
        407,
        674,
        1120,
        1418,
        6216,
        978,
        28896,
        13,
        2743,
        4797,
        1893,
        33762,
        4343,
        1482,
        11676,
        1567,
        4413,
        622,
        13,
        682,
        1371,
        51256
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33211714029312134,
      "compression_ratio": 1.6395759582519531,
      "no_speech_prob": 0.024409016594290733
    },
    {
      "id": 99,
      "seek": 48664,
      "start": 1738.260010986328,
      "end": 1742.9400036621093,
      "text": " Problem steht nichts von Analyse. Hier ist aber eine Lösung, die hat offensichtlich auf Analyse",
      "tokens": [
        51256,
        11676,
        16361,
        13004,
        2957,
        1107,
        5222,
        405,
        13,
        10886,
        1418,
        4340,
        3018,
        46934,
        11,
        978,
        2385,
        766,
        694,
        41971,
        2501,
        1107,
        5222,
        405,
        51490
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33211714029312134,
      "compression_ratio": 1.6395759582519531,
      "no_speech_prob": 0.024409016594290733
    },
    {
      "id": 100,
      "seek": 48664,
      "start": 1742.9400036621093,
      "end": 1746.9800122070312,
      "text": " abzielt. Das heißt also wahrscheinlich ist das Problem eher, ich will irgendwie Daten",
      "tokens": [
        51490,
        410,
        89,
        18940,
        13,
        2846,
        13139,
        611,
        30957,
        1418,
        1482,
        11676,
        24332,
        11,
        1893,
        486,
        20759,
        31126,
        51692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33211714029312134,
      "compression_ratio": 1.6395759582519531,
      "no_speech_prob": 0.024409016594290733
    },
    {
      "id": 101,
      "seek": 51320,
      "start": 1746.9800122070312,
      "end": 1750.499970703125,
      "text": " analysieren, will halt irgendwelchen Business-ExpertInnen die Möglichkeit geben,",
      "tokens": [
        50364,
        23014,
        5695,
        11,
        486,
        12479,
        11093,
        45512,
        2470,
        10715,
        12,
        11149,
        15346,
        4575,
        2866,
        978,
        30662,
        17191,
        11,
        50540
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32780611515045166,
      "compression_ratio": 1.437751054763794,
      "no_speech_prob": 0.009556732140481472
    },
    {
      "id": 102,
      "seek": 51320,
      "start": 1750.499970703125,
      "end": 1760.019990234375,
      "text": " diese ganzen Daten anzuschauen. Und das kann im Moment Afro und GraphQL, also eben nur zwei",
      "tokens": [
        50540,
        6705,
        23966,
        31126,
        364,
        16236,
        339,
        11715,
        13,
        2719,
        1482,
        4028,
        566,
        19093,
        3325,
        340,
        674,
        21884,
        13695,
        11,
        611,
        11375,
        4343,
        12002,
        51016
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32780611515045166,
      "compression_ratio": 1.437751054763794,
      "no_speech_prob": 0.009556732140481472
    },
    {
      "id": 103,
      "seek": 51320,
      "start": 1760.019990234375,
      "end": 1765.5799877929687,
      "text": " Plattformen. Das heißt also, die sind halt auch noch in der Implementierung. Dann haben sie als",
      "tokens": [
        51016,
        2149,
        49952,
        268,
        13,
        2846,
        13139,
        611,
        11,
        978,
        3290,
        12479,
        2168,
        3514,
        294,
        1163,
        4331,
        43704,
        11651,
        13,
        7455,
        3084,
        2804,
        3907,
        51294
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32780611515045166,
      "compression_ratio": 1.437751054763794,
      "no_speech_prob": 0.009556732140481472
    },
    {
      "id": 104,
      "seek": 51320,
      "start": 1765.5799877929687,
      "end": 1774.4599926757812,
      "text": " weiteres Produkt Sphere. Das ist also nicht die Kugel. Das ist ein System, mit dem Sie,",
      "tokens": [
        51294,
        8988,
        279,
        44599,
        318,
        6605,
        13,
        2846,
        1418,
        611,
        1979,
        978,
        591,
        697,
        338,
        13,
        2846,
        1418,
        1343,
        8910,
        11,
        2194,
        1371,
        3559,
        11,
        51738
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32780611515045166,
      "compression_ratio": 1.437751054763794,
      "no_speech_prob": 0.009556732140481472
    },
    {
      "id": 105,
      "seek": 54068,
      "start": 1774.5799877929687,
      "end": 1782.78,
      "text": " mit dem Business-ExpertInnen sich selbst Reports zusammenbauen können. Und das",
      "tokens": [
        50370,
        2194,
        1371,
        10715,
        12,
        11149,
        15346,
        4575,
        2866,
        3041,
        13053,
        45910,
        14311,
        65,
        11715,
        6310,
        13,
        2719,
        1482,
        50780
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3304905891418457,
      "compression_ratio": 1.5985915660858154,
      "no_speech_prob": 0.024788748472929
    },
    {
      "id": 106,
      "seek": 54068,
      "start": 1782.78,
      "end": 1787.8999951171875,
      "text": " katalogisiert uns als Business-Konzepte wie im Actor oder Movie sozusagen zueinander in Beziehung.",
      "tokens": [
        50780,
        16536,
        44434,
        42266,
        2693,
        3907,
        10715,
        12,
        42,
        21972,
        595,
        975,
        3355,
        566,
        45457,
        4513,
        28766,
        370,
        16236,
        64,
        1766,
        710,
        622,
        20553,
        294,
        879,
        28213,
        1063,
        13,
        51036
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3304905891418457,
      "compression_ratio": 1.5985915660858154,
      "no_speech_prob": 0.024788748472929
    },
    {
      "id": 107,
      "seek": 54068,
      "start": 1787.8999951171875,
      "end": 1792.060029296875,
      "text": " Traversiert dann halt diesen Knowledge-Graphen, der da ist. Das heißt also, da habe ich jetzt",
      "tokens": [
        51036,
        5403,
        840,
        4859,
        3594,
        12479,
        12862,
        32906,
        12,
        38,
        2662,
        268,
        11,
        1163,
        1120,
        1418,
        13,
        2846,
        13139,
        611,
        11,
        1120,
        6015,
        1893,
        4354,
        51244
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3304905891418457,
      "compression_ratio": 1.5985915660858154,
      "no_speech_prob": 0.024788748472929
    },
    {
      "id": 108,
      "seek": 54068,
      "start": 1792.060029296875,
      "end": 1796.3399975585937,
      "text": " irgendwie diese gesamte Oberfläche mit den verschiedenen Daten. Da habe ich diesen",
      "tokens": [
        51244,
        20759,
        6705,
        39746,
        975,
        27664,
        3423,
        32664,
        2194,
        1441,
        41043,
        31126,
        13,
        3933,
        6015,
        1893,
        12862,
        51458
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3304905891418457,
      "compression_ratio": 1.5985915660858154,
      "no_speech_prob": 0.024788748472929
    },
    {
      "id": 109,
      "seek": 54068,
      "start": 1796.3399975585937,
      "end": 1799.9800122070312,
      "text": " Knowledge-Graphen, den kann ich jetzt über das Sphere benutzen, um halt irgendwelche Reports zu",
      "tokens": [
        51458,
        32906,
        12,
        38,
        2662,
        268,
        11,
        1441,
        4028,
        1893,
        4354,
        4502,
        1482,
        318,
        6605,
        38424,
        2904,
        11,
        1105,
        12479,
        26455,
        338,
        1876,
        45910,
        2164,
        51640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3304905891418457,
      "compression_ratio": 1.5985915660858154,
      "no_speech_prob": 0.024788748472929
    },
    {
      "id": 110,
      "seek": 56620,
      "start": 1799.9800122070312,
      "end": 1810.30001953125,
      "text": " machen. Und daraus generiert das System dann SQL Queries. Und das ist halt wieder eine Geschichte,",
      "tokens": [
        50364,
        7069,
        13,
        2719,
        274,
        46483,
        1337,
        4859,
        1482,
        8910,
        3594,
        19200,
        2326,
        21659,
        13,
        2719,
        1482,
        1418,
        12479,
        6216,
        3018,
        28896,
        11,
        50880
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32150134444236755,
      "compression_ratio": 1.6008230447769165,
      "no_speech_prob": 0.028857460245490074
    },
    {
      "id": 111,
      "seek": 56620,
      "start": 1810.30001953125,
      "end": 1817.540009765625,
      "text": " die halt irgendwie eher Datenanalyse bedeutet. Wo dann für mich wieder die Frage ist, also warum",
      "tokens": [
        50880,
        978,
        12479,
        20759,
        24332,
        31126,
        282,
        5222,
        405,
        27018,
        13,
        6622,
        3594,
        2959,
        6031,
        6216,
        978,
        13685,
        1418,
        11,
        611,
        24331,
        51242
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32150134444236755,
      "compression_ratio": 1.6008230447769165,
      "no_speech_prob": 0.028857460245490074
    },
    {
      "id": 112,
      "seek": 56620,
      "start": 1817.540009765625,
      "end": 1823.6600048828125,
      "text": " nicht Data Meshes und Datenprodukte dort haben? Also warum brauche ich nicht ein System, wo ich",
      "tokens": [
        51242,
        1979,
        11888,
        17485,
        8076,
        674,
        31126,
        14314,
        18844,
        15775,
        3084,
        30,
        2743,
        24331,
        1548,
        17545,
        1893,
        1979,
        1343,
        8910,
        11,
        6020,
        1893,
        51548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32150134444236755,
      "compression_ratio": 1.6008230447769165,
      "no_speech_prob": 0.028857460245490074
    },
    {
      "id": 113,
      "seek": 56620,
      "start": 1823.6600048828125,
      "end": 1828.8600170898437,
      "text": " halt diese ganzen Daten einfach rein exportiere und dann irgendwie anschließend Reports drüber",
      "tokens": [
        51548,
        12479,
        6705,
        23966,
        31126,
        7281,
        6561,
        10725,
        14412,
        674,
        3594,
        20759,
        31508,
        24476,
        521,
        45910,
        1224,
        12670,
        51808
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32150134444236755,
      "compression_ratio": 1.6008230447769165,
      "no_speech_prob": 0.028857460245490074
    },
    {
      "id": 114,
      "seek": 59508,
      "start": 1828.9399731445312,
      "end": 1835.5799877929687,
      "text": " fahren lassen kann? Keine Ahnung. So, dann haben Sie eine eigene Sprache, um Domänen zu modellieren.",
      "tokens": [
        50368,
        25593,
        16168,
        4028,
        30,
        3189,
        533,
        2438,
        15539,
        13,
        407,
        11,
        3594,
        3084,
        3559,
        3018,
        38549,
        7702,
        6000,
        11,
        1105,
        16674,
        737,
        2866,
        2164,
        1072,
        898,
        5695,
        13,
        50700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3264106512069702,
      "compression_ratio": 1.4258372783660889,
      "no_speech_prob": 0.008845076896250248
    },
    {
      "id": 115,
      "seek": 59508,
      "start": 1835.5799877929687,
      "end": 1846.019990234375,
      "text": " Die nennt sich APPA. Da haben Sie Schlüsselattribute und die Beziehungen dazwischen, in Beziehung zu",
      "tokens": [
        50700,
        3229,
        16399,
        580,
        3041,
        5372,
        10297,
        13,
        3933,
        3084,
        3559,
        16420,
        37838,
        1591,
        2024,
        1169,
        674,
        978,
        879,
        28213,
        5084,
        274,
        921,
        86,
        6282,
        11,
        294,
        879,
        28213,
        1063,
        2164,
        51222
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3264106512069702,
      "compression_ratio": 1.4258372783660889,
      "no_speech_prob": 0.008845076896250248
    },
    {
      "id": 116,
      "seek": 59508,
      "start": 1846.019990234375,
      "end": 1854.499970703125,
      "text": " anderen Entitäten. Die sind dann in Taxonomien organisiert. Und da gibt es halt ein Beispiel.",
      "tokens": [
        51222,
        11122,
        3951,
        49289,
        13,
        3229,
        3290,
        3594,
        294,
        23263,
        12481,
        1053,
        15223,
        4859,
        13,
        2719,
        1120,
        6089,
        785,
        12479,
        1343,
        13772,
        13,
        51646
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3264106512069702,
      "compression_ratio": 1.4258372783660889,
      "no_speech_prob": 0.008845076896250248
    },
    {
      "id": 117,
      "seek": 62072,
      "start": 1854.8199780273437,
      "end": 1866.1000073242187,
      "text": " Das ist das hier. Mal kurz schauen, dass ich das richtig hinbekomme. Genau, also da ist es halt so,",
      "tokens": [
        50380,
        2846,
        1418,
        1482,
        3296,
        13,
        5746,
        20465,
        25672,
        11,
        2658,
        1893,
        1482,
        13129,
        14102,
        25714,
        15117,
        13,
        22340,
        11,
        611,
        1120,
        1418,
        785,
        12479,
        370,
        11,
        50944
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4275968670845032,
      "compression_ratio": 1.374100685119629,
      "no_speech_prob": 0.04398598149418831
    },
    {
      "id": 118,
      "seek": 62072,
      "start": 1866.1000073242187,
      "end": 1876.3399975585937,
      "text": " dass wir jetzt sehen, einen One Piece Charakter. One Piece ist so ein Manga, war mir vorher",
      "tokens": [
        50944,
        2658,
        1987,
        4354,
        11333,
        11,
        4891,
        1485,
        42868,
        4327,
        33557,
        13,
        1485,
        42868,
        1418,
        370,
        1343,
        376,
        26005,
        11,
        1516,
        3149,
        29195,
        51456
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4275968670845032,
      "compression_ratio": 1.374100685119629,
      "no_speech_prob": 0.04398598149418831
    },
    {
      "id": 119,
      "seek": 64256,
      "start": 1876.3399975585937,
      "end": 1883.9399731445312,
      "text": " irgendwie auch nicht bekannt. Und da gibt es einen Devil Fruit. Das ist also eine bestimmte",
      "tokens": [
        50364,
        20759,
        2168,
        1979,
        39167,
        13,
        2719,
        1120,
        6089,
        785,
        4891,
        25221,
        39989,
        13,
        2846,
        1418,
        611,
        3018,
        35180,
        975,
        50744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31238171458244324,
      "compression_ratio": 1.621739149093628,
      "no_speech_prob": 0.3003394603729248
    },
    {
      "id": 120,
      "seek": 64256,
      "start": 1883.9399731445312,
      "end": 1888.1800244140625,
      "text": " Frucht, die so einen Charakter typischerweise hat oder den repräsentiert. Und da habe ich",
      "tokens": [
        50744,
        1526,
        10084,
        11,
        978,
        370,
        4891,
        4327,
        33557,
        2125,
        19674,
        13109,
        2385,
        4513,
        1441,
        1085,
        11397,
        49315,
        4859,
        13,
        2719,
        1120,
        6015,
        1893,
        50956
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31238171458244324,
      "compression_ratio": 1.621739149093628,
      "no_speech_prob": 0.3003394603729248
    },
    {
      "id": 121,
      "seek": 64256,
      "start": 1888.1800244140625,
      "end": 1893.5799877929687,
      "text": " diese Beziehung Devil Fruit dazwischen. Und dann gibt es halt darunter noch den Devil Fruit Type.",
      "tokens": [
        50956,
        6705,
        879,
        28213,
        1063,
        25221,
        39989,
        274,
        921,
        86,
        6282,
        13,
        2719,
        3594,
        6089,
        785,
        12479,
        4072,
        21777,
        3514,
        1441,
        25221,
        39989,
        15576,
        13,
        51226
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31238171458244324,
      "compression_ratio": 1.621739149093628,
      "no_speech_prob": 0.3003394603729248
    },
    {
      "id": 122,
      "seek": 64256,
      "start": 1893.5799877929687,
      "end": 1901.2200024414062,
      "text": " Das ist, glaube ich, ein artifizielles Beispiel. Wir werden nachher noch sehen, dass Netflix",
      "tokens": [
        51226,
        2846,
        1418,
        11,
        13756,
        1893,
        11,
        1343,
        1523,
        351,
        590,
        414,
        19126,
        13772,
        13,
        4347,
        4604,
        5168,
        511,
        3514,
        11333,
        11,
        2658,
        12778,
        51608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31238171458244324,
      "compression_ratio": 1.621739149093628,
      "no_speech_prob": 0.3003394603729248
    },
    {
      "id": 123,
      "seek": 66744,
      "start": 1901.3799755859375,
      "end": 1911.499970703125,
      "text": " tatsächlich mit den echten Beispielen aus dem echten Leben eher vorsichtig ist. Und so kann",
      "tokens": [
        50372,
        20796,
        2194,
        1441,
        308,
        21043,
        13772,
        268,
        3437,
        1371,
        308,
        21043,
        15399,
        24332,
        48432,
        7334,
        1418,
        13,
        2719,
        370,
        4028,
        50878
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3533959686756134,
      "compression_ratio": 1.4157894849777222,
      "no_speech_prob": 0.04334663599729538
    },
    {
      "id": 124,
      "seek": 66744,
      "start": 1911.499970703125,
      "end": 1922.6200268554687,
      "text": " jetzt also eine Modellierung aussehen. Das bedeutet, ich habe dort jetzt eine Taxonomie",
      "tokens": [
        50878,
        4354,
        611,
        3018,
        6583,
        898,
        11651,
        3437,
        27750,
        13,
        2846,
        27018,
        11,
        1893,
        6015,
        15775,
        4354,
        3018,
        23263,
        12481,
        414,
        51434
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3533959686756134,
      "compression_ratio": 1.4157894849777222,
      "no_speech_prob": 0.04334663599729538
    },
    {
      "id": 125,
      "seek": 66744,
      "start": 1922.6200268554687,
      "end": 1928.2200024414062,
      "text": " und ein Datenmodell gebaut. Das kann ich anschließend auch in eine Sprache übersetzen.",
      "tokens": [
        51434,
        674,
        1343,
        31126,
        8014,
        898,
        49203,
        13,
        2846,
        4028,
        1893,
        31508,
        24476,
        521,
        2168,
        294,
        3018,
        7702,
        6000,
        45022,
        24797,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3533959686756134,
      "compression_ratio": 1.4157894849777222,
      "no_speech_prob": 0.04334663599729538
    },
    {
      "id": 126,
      "seek": 69444,
      "start": 1928.3399975585937,
      "end": 1934.30001953125,
      "text": " Ich erspare uns, da sind Listings drin, aber ich erspare uns, das im Listing sozusagen anzugucken.",
      "tokens": [
        50370,
        3141,
        33743,
        79,
        543,
        2693,
        11,
        1120,
        3290,
        17668,
        1109,
        24534,
        11,
        4340,
        1893,
        33743,
        79,
        543,
        2693,
        11,
        1482,
        566,
        17668,
        278,
        33762,
        364,
        29742,
        49720,
        13,
        50668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3443011939525604,
      "compression_ratio": 1.5497835874557495,
      "no_speech_prob": 0.037308916449546814
    },
    {
      "id": 127,
      "seek": 69444,
      "start": 1934.30001953125,
      "end": 1938.060029296875,
      "text": " Es geht darum, das konzeptionell zu verstehen. Und das kann ich dann transpellieren,",
      "tokens": [
        50668,
        2313,
        7095,
        27313,
        11,
        1482,
        5897,
        32082,
        313,
        898,
        2164,
        37352,
        13,
        2719,
        1482,
        4028,
        1893,
        3594,
        1145,
        49241,
        5695,
        11,
        50856
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3443011939525604,
      "compression_ratio": 1.5497835874557495,
      "no_speech_prob": 0.037308916449546814
    },
    {
      "id": 128,
      "seek": 69444,
      "start": 1938.060029296875,
      "end": 1947.019990234375,
      "text": " also übersetzen in Richtung zu GraphQL, Afro, Iceberg oder Java. Und das ist also letztendlich",
      "tokens": [
        50856,
        611,
        45022,
        24797,
        294,
        33023,
        2164,
        21884,
        13695,
        11,
        3325,
        340,
        11,
        15332,
        6873,
        4513,
        10745,
        13,
        2719,
        1482,
        1418,
        611,
        35262,
        521,
        1739,
        51304
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3443011939525604,
      "compression_ratio": 1.5497835874557495,
      "no_speech_prob": 0.037308916449546814
    },
    {
      "id": 129,
      "seek": 69444,
      "start": 1947.019990234375,
      "end": 1951.6999829101562,
      "text": " eben so eine generelle universelle Datenrepräsentationssprache, die ich jetzt",
      "tokens": [
        51304,
        11375,
        370,
        3018,
        41553,
        2447,
        6445,
        2447,
        31126,
        265,
        1424,
        13555,
        317,
        763,
        18193,
        6000,
        11,
        978,
        1893,
        4354,
        51538
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3443011939525604,
      "compression_ratio": 1.5497835874557495,
      "no_speech_prob": 0.037308916449546814
    },
    {
      "id": 130,
      "seek": 71792,
      "start": 1951.9800122070312,
      "end": 1958.6200268554687,
      "text": " übersetzen kann auf diese verschiedenen Systeme. Was ich dabei noch interessant finde, ist,",
      "tokens": [
        50378,
        45022,
        24797,
        4028,
        2501,
        6705,
        41043,
        8910,
        68,
        13,
        3027,
        1893,
        14967,
        3514,
        37748,
        17841,
        11,
        1418,
        11,
        50710
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28333333134651184,
      "compression_ratio": 1.649350643157959,
      "no_speech_prob": 0.2624114155769348
    },
    {
      "id": 131,
      "seek": 71792,
      "start": 1958.6200268554687,
      "end": 1966.6999829101562,
      "text": " dass dieses System die Möglichkeit bietet, diese Domainmodelle zu erweitern, was möglicherweise",
      "tokens": [
        50710,
        2658,
        12113,
        8910,
        978,
        30662,
        272,
        45531,
        11,
        6705,
        16674,
        491,
        8014,
        4434,
        2164,
        1189,
        28019,
        1248,
        11,
        390,
        16294,
        44071,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28333333134651184,
      "compression_ratio": 1.649350643157959,
      "no_speech_prob": 0.2624114155769348
    },
    {
      "id": 132,
      "seek": 71792,
      "start": 1966.6999829101562,
      "end": 1975.8600170898437,
      "text": " darauf hindeutet, dass sie eben sozusagen ein gemeinsames Ding definieren und dann einzelnen",
      "tokens": [
        51114,
        18654,
        276,
        8274,
        20364,
        11,
        2658,
        2804,
        11375,
        33762,
        1343,
        22971,
        1632,
        20558,
        1561,
        5695,
        674,
        3594,
        36731,
        2866,
        51572
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28333333134651184,
      "compression_ratio": 1.649350643157959,
      "no_speech_prob": 0.2624114155769348
    },
    {
      "id": 133,
      "seek": 71792,
      "start": 1975.8600170898437,
      "end": 1979.6600048828125,
      "text": " Teams oder einzelnen Bereichen die Möglichkeit geben, es zu erweitern. Was ja wiederum bedeutet,",
      "tokens": [
        51572,
        24702,
        4513,
        36731,
        2866,
        17684,
        18613,
        978,
        30662,
        17191,
        11,
        785,
        2164,
        1189,
        28019,
        1248,
        13,
        3027,
        2784,
        6216,
        449,
        27018,
        11,
        51762
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28333333134651184,
      "compression_ratio": 1.649350643157959,
      "no_speech_prob": 0.2624114155769348
    },
    {
      "id": 134,
      "seek": 74588,
      "start": 1979.6600048828125,
      "end": 1985.3799755859375,
      "text": " es gibt nicht das eine übergreifende Modell, sondern eben einen gemeinsamen Kern, den man",
      "tokens": [
        50364,
        785,
        6089,
        1979,
        1482,
        3018,
        4502,
        33248,
        351,
        5445,
        6583,
        898,
        11,
        11465,
        11375,
        4891,
        22971,
        22403,
        40224,
        11,
        1441,
        587,
        50650
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29401299357414246,
      "compression_ratio": 1.5645161867141724,
      "no_speech_prob": 0.015419664792716503
    },
    {
      "id": 135,
      "seek": 74588,
      "start": 1985.3799755859375,
      "end": 1990.540009765625,
      "text": " dann eben entsprechend erweitern kann. Also auch da, das wäre jetzt auch so ein Hinweis. Wir bauen",
      "tokens": [
        50650,
        3594,
        11375,
        47823,
        1189,
        28019,
        1248,
        4028,
        13,
        2743,
        2168,
        1120,
        11,
        1482,
        14558,
        4354,
        2168,
        370,
        1343,
        29571,
        35033,
        13,
        4347,
        43787,
        50908
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29401299357414246,
      "compression_ratio": 1.5645161867141724,
      "no_speech_prob": 0.015419664792716503
    },
    {
      "id": 136,
      "seek": 74588,
      "start": 1990.540009765625,
      "end": 2000.30001953125,
      "text": " nicht das eine Modell, sondern unterschiedliche Dinge, nur einen gemeinsamen Kern. Und das Nächste,",
      "tokens": [
        50908,
        1979,
        1482,
        3018,
        6583,
        898,
        11,
        11465,
        30058,
        10185,
        25102,
        11,
        4343,
        4891,
        22971,
        22403,
        40224,
        13,
        2719,
        1482,
        426,
        10168,
        2941,
        11,
        51396
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29401299357414246,
      "compression_ratio": 1.5645161867141724,
      "no_speech_prob": 0.015419664792716503
    },
    {
      "id": 137,
      "seek": 76652,
      "start": 2000.30001953125,
      "end": 2011.1800244140625,
      "text": " worüber sie dann noch diskutieren, ist das hier. Das ist also so eine Data Container",
      "tokens": [
        50364,
        469,
        12670,
        2804,
        3594,
        3514,
        36760,
        5695,
        11,
        1418,
        1482,
        3296,
        13,
        2846,
        1418,
        611,
        370,
        3018,
        11888,
        43732,
        260,
        50908
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40717557072639465,
      "compression_ratio": 1.3134328126907349,
      "no_speech_prob": 0.19652535021305084
    },
    {
      "id": 138,
      "seek": 76652,
      "start": 2011.1800244140625,
      "end": 2022.6200268554687,
      "text": " Representation für dieses Data Mesh. Und hier sieht man jetzt also nicht dieser One Piece",
      "tokens": [
        50908,
        19945,
        399,
        2959,
        12113,
        11888,
        376,
        14935,
        13,
        2719,
        3296,
        14289,
        587,
        4354,
        611,
        1979,
        9053,
        1485,
        42868,
        51480
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40717557072639465,
      "compression_ratio": 1.3134328126907349,
      "no_speech_prob": 0.19652535021305084
    },
    {
      "id": 139,
      "seek": 78884,
      "start": 2022.7400219726562,
      "end": 2029.7400219726562,
      "text": " Charakter. Also One Piece Devil Fruit is a Record. Da gibt es einen Namen und noch einen Namen und",
      "tokens": [
        50370,
        4327,
        33557,
        13,
        2743,
        1485,
        42868,
        25221,
        39989,
        307,
        257,
        27401,
        13,
        3933,
        6089,
        785,
        4891,
        38771,
        674,
        3514,
        4891,
        38771,
        674,
        50720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4622395932674408,
      "compression_ratio": 1.4467004537582397,
      "no_speech_prob": 0.3101150095462799
    },
    {
      "id": 140,
      "seek": 78884,
      "start": 2029.7400219726562,
      "end": 2040.3799755859375,
      "text": " die sind nicht nullable. Also dort eben eine Datenbeschreibung, die da dann umgesetzt werden",
      "tokens": [
        50720,
        978,
        3290,
        1979,
        18184,
        712,
        13,
        2743,
        15775,
        11375,
        3018,
        31126,
        6446,
        339,
        38606,
        1063,
        11,
        978,
        1120,
        3594,
        1105,
        42283,
        4604,
        51252
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4622395932674408,
      "compression_ratio": 1.4467004537582397,
      "no_speech_prob": 0.3101150095462799
    },
    {
      "id": 141,
      "seek": 78884,
      "start": 2040.3799755859375,
      "end": 2049.1000073242185,
      "text": " kann. In beispielsweise Afro, wie man hier sieht. So und das kann ich jetzt eben tatsächlich",
      "tokens": [
        51252,
        4028,
        13,
        682,
        40152,
        3325,
        340,
        11,
        3355,
        587,
        3296,
        14289,
        13,
        407,
        674,
        1482,
        4028,
        1893,
        4354,
        11375,
        20796,
        51688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4622395932674408,
      "compression_ratio": 1.4467004537582397,
      "no_speech_prob": 0.3101150095462799
    },
    {
      "id": 142,
      "seek": 81532,
      "start": 2049.5799877929685,
      "end": 2055.8999951171872,
      "text": " visuell sozusagen mappen. Das heißt also, ich kann jetzt im nächsten Schritt",
      "tokens": [
        50388,
        1452,
        13789,
        33762,
        463,
        21278,
        13,
        2846,
        13139,
        611,
        11,
        1893,
        4028,
        4354,
        566,
        19101,
        33062,
        50704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3625991940498352,
      "compression_ratio": 1.3645833730697632,
      "no_speech_prob": 0.004829182755202055
    },
    {
      "id": 143,
      "seek": 81532,
      "start": 2061.5799877929685,
      "end": 2068.1000073242185,
      "text": " dann sagen, dass ich halt dort irgendwas übersetzen möchte von diesem UDA Properties",
      "tokens": [
        50988,
        3594,
        8360,
        11,
        2658,
        1893,
        12479,
        15775,
        47090,
        45022,
        24797,
        14570,
        2957,
        10975,
        624,
        7509,
        27627,
        6097,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3625991940498352,
      "compression_ratio": 1.3645833730697632,
      "no_speech_prob": 0.004829182755202055
    },
    {
      "id": 144,
      "seek": 81532,
      "start": 2068.1000073242185,
      "end": 2076.1000073242185,
      "text": " auf irgendwelchen konkreten Data Assets und habe da die entsprechende Übersetzung. Und hier ist",
      "tokens": [
        51314,
        2501,
        26455,
        338,
        2470,
        21428,
        35383,
        11888,
        6281,
        1385,
        674,
        6015,
        1120,
        978,
        29967,
        5445,
        10713,
        1616,
        38584,
        13,
        2719,
        3296,
        1418,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3625991940498352,
      "compression_ratio": 1.3645833730697632,
      "no_speech_prob": 0.004829182755202055
    },
    {
      "id": 145,
      "seek": 84232,
      "start": 2076.1399853515622,
      "end": 2081.980012207031,
      "text": " eins der Features, dass die auch haben, dass man die Daten automatisch irgendwo anders hinbewegen",
      "tokens": [
        50366,
        21889,
        1163,
        3697,
        3377,
        11,
        2658,
        978,
        2168,
        3084,
        11,
        2658,
        587,
        978,
        31126,
        28034,
        5494,
        3418,
        432,
        273,
        6120,
        17999,
        14102,
        650,
        13683,
        50658
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43207645416259766,
      "compression_ratio": 1.688811182975769,
      "no_speech_prob": 0.025950061157345772
    },
    {
      "id": 146,
      "seek": 84232,
      "start": 2081.980012207031,
      "end": 2087.2599804687497,
      "text": " kann. Dass ich jetzt sage, okay, ich habe die Daten in GraphQL und ich schmeiße sie jetzt mal",
      "tokens": [
        50658,
        4028,
        13,
        22306,
        1893,
        4354,
        19721,
        11,
        1392,
        11,
        1893,
        6015,
        978,
        31126,
        294,
        21884,
        13695,
        674,
        1893,
        46459,
        47828,
        2804,
        4354,
        2806,
        50922
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43207645416259766,
      "compression_ratio": 1.688811182975769,
      "no_speech_prob": 0.025950061157345772
    },
    {
      "id": 147,
      "seek": 84232,
      "start": 2087.2599804687497,
      "end": 2093.8600170898435,
      "text": " irgendwie in Iceberg, damit ich sie da halt dann analysieren kann mit meinem SQL, was vielleicht",
      "tokens": [
        50922,
        20759,
        294,
        15332,
        6873,
        11,
        9479,
        1893,
        2804,
        1120,
        12479,
        3594,
        23014,
        5695,
        4028,
        2194,
        24171,
        19200,
        11,
        390,
        12547,
        51252
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43207645416259766,
      "compression_ratio": 1.688811182975769,
      "no_speech_prob": 0.025950061157345772
    },
    {
      "id": 148,
      "seek": 84232,
      "start": 2093.8600170898435,
      "end": 2102.1399853515622,
      "text": " irgendwie performance mäßig besser ist. So, was eben bedeutet, dass ich durch Transpellieren nicht",
      "tokens": [
        51252,
        20759,
        3389,
        25117,
        2536,
        328,
        18021,
        1418,
        13,
        407,
        11,
        390,
        11375,
        27018,
        11,
        2658,
        1893,
        7131,
        6531,
        49241,
        5695,
        1979,
        51666
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43207645416259766,
      "compression_ratio": 1.688811182975769,
      "no_speech_prob": 0.025950061157345772
    },
    {
      "id": 149,
      "seek": 84232,
      "start": 2102.1399853515622,
      "end": 2105.1399853515622,
      "text": " nur diese verschiedenen Schema-Teile erzeugen kann, sondern dass ich eben auch die Daten hin",
      "tokens": [
        51666,
        4343,
        6705,
        41043,
        2065,
        5619,
        12,
        14233,
        794,
        1189,
        19303,
        268,
        4028,
        11,
        11465,
        2658,
        1893,
        11375,
        2168,
        978,
        31126,
        14102,
        51816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43207645416259766,
      "compression_ratio": 1.688811182975769,
      "no_speech_prob": 0.025950061157345772
    },
    {
      "id": 150,
      "seek": 87136,
      "start": 2105.1399853515622,
      "end": 2113.8199780273435,
      "text": " und her kopieren kann. Und das ist so die wesentliche Idee, die sie dort offensichtlich",
      "tokens": [
        50364,
        674,
        720,
        28920,
        5695,
        4028,
        13,
        2719,
        1482,
        1418,
        370,
        978,
        38384,
        7698,
        68,
        32651,
        11,
        978,
        2804,
        15775,
        766,
        694,
        41971,
        50798
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24673210084438324,
      "compression_ratio": 1.45641028881073,
      "no_speech_prob": 0.020631013438105583
    },
    {
      "id": 151,
      "seek": 87136,
      "start": 2113.8199780273435,
      "end": 2121.5400097656247,
      "text": " haben. Beispiele, die sie dann nennen, wo dieses System sozusagen genutzt wird, ist halt einmal",
      "tokens": [
        50798,
        3084,
        13,
        879,
        7631,
        15949,
        11,
        978,
        2804,
        3594,
        297,
        16043,
        11,
        6020,
        12113,
        8910,
        33762,
        1049,
        325,
        2682,
        4578,
        11,
        1418,
        12479,
        11078,
        51184
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24673210084438324,
      "compression_ratio": 1.45641028881073,
      "no_speech_prob": 0.020631013438105583
    },
    {
      "id": 152,
      "seek": 87136,
      "start": 2121.5400097656247,
      "end": 2127.8199780273435,
      "text": " dieses Primary Data Management. Da sprechen sie tatsächlich davon, dass sie eben ein kontrolliertes",
      "tokens": [
        51184,
        12113,
        42576,
        11888,
        14781,
        13,
        3933,
        27853,
        2804,
        20796,
        18574,
        11,
        2658,
        2804,
        11375,
        1343,
        47107,
        4859,
        279,
        51498
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24673210084438324,
      "compression_ratio": 1.45641028881073,
      "no_speech_prob": 0.020631013438105583
    },
    {
      "id": 153,
      "seek": 89404,
      "start": 2127.8199780273435,
      "end": 2137.1000073242185,
      "text": " Vokabular umsetzen und zentral definieren. Also was ist wo, wie erlaubt, mit welchen Werten? Und",
      "tokens": [
        50364,
        691,
        453,
        455,
        1040,
        1105,
        3854,
        2904,
        674,
        710,
        317,
        2155,
        1561,
        5695,
        13,
        2743,
        390,
        1418,
        6020,
        11,
        3355,
        1189,
        20798,
        83,
        11,
        2194,
        2214,
        2470,
        37205,
        268,
        30,
        2719,
        50828
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29943183064460754,
      "compression_ratio": 1.4538745880126953,
      "no_speech_prob": 0.23305323719978333
    },
    {
      "id": 154,
      "seek": 89404,
      "start": 2137.1000073242185,
      "end": 2141.1399853515622,
      "text": " zwar durch irgendwelche Business User In, also nicht durch Techniker In. Und das nutzt auch",
      "tokens": [
        50828,
        19054,
        7131,
        26455,
        338,
        1876,
        10715,
        32127,
        682,
        11,
        611,
        1979,
        7131,
        8337,
        17314,
        682,
        13,
        2719,
        1482,
        5393,
        2682,
        2168,
        51030
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29943183064460754,
      "compression_ratio": 1.4538745880126953,
      "no_speech_prob": 0.23305323719978333
    },
    {
      "id": 155,
      "seek": 89404,
      "start": 2141.1399853515622,
      "end": 2147.980012207031,
      "text": " ein W3C-Standard, nämlich S-Core Simple Knowledge Organization System, worüber jetzt einzelne Nutzer",
      "tokens": [
        51030,
        1343,
        343,
        18,
        34,
        12,
        4520,
        474,
        515,
        11,
        21219,
        318,
        12,
        34,
        418,
        21532,
        32906,
        23979,
        8910,
        11,
        469,
        12670,
        4354,
        36731,
        716,
        19861,
        4527,
        51372
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29943183064460754,
      "compression_ratio": 1.4538745880126953,
      "no_speech_prob": 0.23305323719978333
    },
    {
      "id": 156,
      "seek": 89404,
      "start": 2147.980012207031,
      "end": 2154.8600170898435,
      "text": " in ihr eigenes Modell mit ihrer eigenen Sprache sozusagen drunter benutzen können. Und offensichtlich",
      "tokens": [
        51372,
        294,
        5553,
        10446,
        279,
        6583,
        898,
        2194,
        23990,
        28702,
        7702,
        6000,
        33762,
        1224,
        21777,
        38424,
        2904,
        6310,
        13,
        2719,
        766,
        694,
        41971,
        51716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29943183064460754,
      "compression_ratio": 1.4538745880126953,
      "no_speech_prob": 0.23305323719978333
    },
    {
      "id": 157,
      "seek": 92108,
      "start": 2154.8600170898435,
      "end": 2160.459992675781,
      "text": " diesen S-Core Layer, keine Ahnung wie genau, aber von dem müssen sie noch nicht mal wissen,",
      "tokens": [
        50364,
        12862,
        318,
        12,
        34,
        418,
        35166,
        11,
        9252,
        2438,
        15539,
        3355,
        12535,
        11,
        4340,
        2957,
        1371,
        9013,
        2804,
        3514,
        1979,
        2806,
        16331,
        11,
        50644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3554017245769501,
      "compression_ratio": 1.5099601745605469,
      "no_speech_prob": 0.022966526448726654
    },
    {
      "id": 158,
      "seek": 92108,
      "start": 2160.459992675781,
      "end": 2164.6600048828122,
      "text": " dass das existiert. Was also auch wieder bedeutet, dass es vielleicht nicht das eine Modell ist,",
      "tokens": [
        50644,
        2658,
        1482,
        2514,
        4859,
        13,
        3027,
        611,
        2168,
        6216,
        27018,
        11,
        2658,
        785,
        12547,
        1979,
        1482,
        3018,
        6583,
        898,
        1418,
        11,
        50854
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3554017245769501,
      "compression_ratio": 1.5099601745605469,
      "no_speech_prob": 0.022966526448726654
    },
    {
      "id": 159,
      "seek": 92108,
      "start": 2164.6600048828122,
      "end": 2175.459992675781,
      "text": " sondern eher so ein Übersetzungs-Ding. Und dann haben sie schönerweise ein Screenshot zu diesem",
      "tokens": [
        50854,
        11465,
        24332,
        370,
        1343,
        10713,
        1616,
        10074,
        5846,
        12,
        35,
        278,
        13,
        2719,
        3594,
        3084,
        2804,
        25032,
        1193,
        13109,
        1343,
        2747,
        9098,
        12194,
        2164,
        10975,
        51394
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3554017245769501,
      "compression_ratio": 1.5099601745605469,
      "no_speech_prob": 0.022966526448726654
    },
    {
      "id": 160,
      "seek": 92108,
      "start": 2175.459992675781,
      "end": 2180.5400097656247,
      "text": " Sphere. Da ist halt bedauerlicherweise alles mögliche irgendwie geschwärzt, sodass man im",
      "tokens": [
        51394,
        318,
        6605,
        13,
        3933,
        1418,
        12479,
        2901,
        18120,
        25215,
        13109,
        7874,
        16294,
        68,
        20759,
        13511,
        86,
        2713,
        2682,
        11,
        15047,
        640,
        587,
        566,
        51648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3554017245769501,
      "compression_ratio": 1.5099601745605469,
      "no_speech_prob": 0.022966526448726654
    },
    {
      "id": 161,
      "seek": 94676,
      "start": 2180.5400097656247,
      "end": 2189.2599804687497,
      "text": " Prinzip nur Production hier sieht. Das bedeutet, irgendwie kann man da Reports machen, aber was",
      "tokens": [
        50364,
        47572,
        4343,
        30088,
        3296,
        14289,
        13,
        2846,
        27018,
        11,
        20759,
        4028,
        587,
        1120,
        45910,
        7069,
        11,
        4340,
        390,
        50800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3319232761859894,
      "compression_ratio": 1.5255101919174194,
      "no_speech_prob": 0.06274254620075226
    },
    {
      "id": 162,
      "seek": 94676,
      "start": 2189.2599804687497,
      "end": 2197.980012207031,
      "text": " genau wie, das sagt uns Netflix hier halt irgendwie nicht. Und als Ausgangsperspektive oder als weitere",
      "tokens": [
        50800,
        12535,
        3355,
        11,
        1482,
        15764,
        2693,
        12778,
        3296,
        12479,
        20759,
        1979,
        13,
        2719,
        3907,
        9039,
        19619,
        4952,
        433,
        23533,
        488,
        4513,
        3907,
        30020,
        51236
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3319232761859894,
      "compression_ratio": 1.5255101919174194,
      "no_speech_prob": 0.06274254620075226
    },
    {
      "id": 163,
      "seek": 94676,
      "start": 2197.980012207031,
      "end": 2203.6600048828122,
      "text": " Perspektive sagen sie dann, naja, es kann mehr Projections geben, also wir werden mehr Datenformate",
      "tokens": [
        51236,
        14006,
        23533,
        488,
        8360,
        2804,
        3594,
        11,
        1667,
        2938,
        11,
        785,
        4028,
        5417,
        9849,
        626,
        17191,
        11,
        611,
        1987,
        4604,
        5417,
        31126,
        837,
        473,
        51520
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3319232761859894,
      "compression_ratio": 1.5255101919174194,
      "no_speech_prob": 0.06274254620075226
    },
    {
      "id": 164,
      "seek": 96988,
      "start": 2203.7799999999997,
      "end": 2210.8999951171872,
      "text": " unterstützen, um da mehr Möglichkeiten zu haben. Zum Beispiel auch sowas wie Protobuf, also dieses",
      "tokens": [
        50370,
        43081,
        11,
        1105,
        1120,
        5417,
        42627,
        2164,
        3084,
        13,
        23906,
        13772,
        2168,
        19766,
        296,
        3355,
        10019,
        996,
        2947,
        11,
        611,
        12113,
        50726
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39199504256248474,
      "compression_ratio": 1.48046875,
      "no_speech_prob": 0.10511447489261627
    },
    {
      "id": 165,
      "seek": 96988,
      "start": 2210.8999951171872,
      "end": 2218.220002441406,
      "text": " binäre, eher effiziente Protokoll oder sowas wie gRPC als weitere Kommunikationsmöglichkeit. Wir",
      "tokens": [
        50726,
        5171,
        12277,
        11,
        24332,
        1244,
        590,
        8413,
        10019,
        453,
        1833,
        4513,
        19766,
        296,
        3355,
        290,
        49,
        12986,
        3907,
        30020,
        28832,
        1035,
        763,
        76,
        16277,
        9238,
        13,
        4347,
        51092
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39199504256248474,
      "compression_ratio": 1.48046875,
      "no_speech_prob": 0.10511447489261627
    },
    {
      "id": 166,
      "seek": 96988,
      "start": 2218.220002441406,
      "end": 2222.3799755859372,
      "text": " werden den Logistik-Graphen materialisieren. Also ich denke mal, dass der dann nicht nur,",
      "tokens": [
        51092,
        4604,
        1441,
        10824,
        468,
        1035,
        12,
        38,
        2662,
        268,
        2527,
        271,
        5695,
        13,
        2743,
        1893,
        27245,
        2806,
        11,
        2658,
        1163,
        3594,
        1979,
        4343,
        11,
        51300
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39199504256248474,
      "compression_ratio": 1.48046875,
      "no_speech_prob": 0.10511447489261627
    },
    {
      "id": 167,
      "seek": 96988,
      "start": 2222.3799755859372,
      "end": 2227.8600170898435,
      "text": " dass der dann halt als konkrete Datenstruktur vorstellt und weitere Probleme in Bezug auf",
      "tokens": [
        51300,
        2658,
        1163,
        3594,
        12479,
        3907,
        21428,
        7600,
        9315,
        268,
        372,
        31543,
        4245,
        372,
        12783,
        674,
        30020,
        32891,
        294,
        879,
        29742,
        2501,
        51574
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39199504256248474,
      "compression_ratio": 1.48046875,
      "no_speech_prob": 0.10511447489261627
    },
    {
      "id": 168,
      "seek": 99408,
      "start": 2227.8600170898435,
      "end": 2237.939973144531,
      "text": " die Suche über diesen Graphen lösen. So weit Schnelldurchlauf sozusagen dieses Paper. Jetzt",
      "tokens": [
        50364,
        978,
        9653,
        68,
        4502,
        12862,
        21884,
        268,
        25209,
        6748,
        13,
        407,
        15306,
        2065,
        8903,
        67,
        2476,
        36488,
        33762,
        12113,
        24990,
        13,
        12592,
        50868
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3132748007774353,
      "compression_ratio": 1.5742573738098145,
      "no_speech_prob": 0.19407646358013153
    },
    {
      "id": 169,
      "seek": 99408,
      "start": 2237.939973144531,
      "end": 2242.3799755859372,
      "text": " ist halt die Frage und damit komme ich sozusagen zu dem dritten Teil. Also was bedeutet das jetzt",
      "tokens": [
        50868,
        1418,
        12479,
        978,
        13685,
        674,
        9479,
        31194,
        1893,
        33762,
        2164,
        1371,
        1224,
        2987,
        16357,
        13,
        2743,
        390,
        27018,
        1482,
        4354,
        51090
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3132748007774353,
      "compression_ratio": 1.5742573738098145,
      "no_speech_prob": 0.19407646358013153
    },
    {
      "id": 170,
      "seek": 99408,
      "start": 2242.3799755859372,
      "end": 2246.699982910156,
      "text": " für uns und was ist eigentlich so das Ergebnis und wie bewerten wir das? Also zurück zu dem",
      "tokens": [
        51090,
        2959,
        2693,
        674,
        390,
        1418,
        10926,
        370,
        1482,
        46229,
        674,
        3355,
        17897,
        39990,
        1987,
        1482,
        30,
        2743,
        15089,
        2164,
        1371,
        51306
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3132748007774353,
      "compression_ratio": 1.5742573738098145,
      "no_speech_prob": 0.19407646358013153
    },
    {
      "id": 171,
      "seek": 99408,
      "start": 2246.699982910156,
      "end": 2251.8600170898435,
      "text": " Problem. Wenn wir halt tatsächlich diese Lösung bauen, um Datenqualität zu erhöhen, also das",
      "tokens": [
        51306,
        11676,
        13,
        7899,
        1987,
        12479,
        20796,
        6705,
        46934,
        43787,
        11,
        1105,
        31126,
        22345,
        14053,
        2164,
        49058,
        2932,
        11,
        611,
        1482,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3132748007774353,
      "compression_ratio": 1.5742573738098145,
      "no_speech_prob": 0.19407646358013153
    },
    {
      "id": 172,
      "seek": 99408,
      "start": 2251.8600170898435,
      "end": 2257.6200268554685,
      "text": " Gebanzene aufzulösen, kaputte Referenzen aufzulösen und diese Verbindung zwischen dem System",
      "tokens": [
        51564,
        24984,
        3910,
        1450,
        2501,
        89,
        425,
        973,
        6748,
        11,
        13816,
        325,
        975,
        36889,
        268,
        2904,
        2501,
        89,
        425,
        973,
        6748,
        674,
        6705,
        27034,
        41442,
        19875,
        1371,
        8910,
        51852
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3132748007774353,
      "compression_ratio": 1.5742573738098145,
      "no_speech_prob": 0.19407646358013153
    },
    {
      "id": 173,
      "seek": 102384,
      "start": 2257.9400341796872,
      "end": 2266.4200146484372,
      "text": " hinzubekommen, dann kann ich mir nicht vorstellen, dass der Aufwand, den man dafür treibt, in einem",
      "tokens": [
        50380,
        14102,
        89,
        1977,
        13675,
        11,
        3594,
        4028,
        1893,
        3149,
        1979,
        34346,
        11,
        2658,
        1163,
        9462,
        33114,
        11,
        1441,
        587,
        13747,
        2192,
        13651,
        11,
        294,
        6827,
        50804
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2571583390235901,
      "compression_ratio": 1.483146071434021,
      "no_speech_prob": 0.001956712221726775
    },
    {
      "id": 174,
      "seek": 102384,
      "start": 2266.4200146484372,
      "end": 2273.6600048828122,
      "text": " vernünftigen Verhältnis zu den Nutzen steht. Das heißt also, ich würde behaupten, dieses Problem,",
      "tokens": [
        50804,
        35793,
        3412,
        844,
        3213,
        4281,
        28068,
        10661,
        2164,
        1441,
        19861,
        2904,
        16361,
        13,
        2846,
        13139,
        611,
        11,
        1893,
        11942,
        1540,
        13343,
        268,
        11,
        12113,
        11676,
        11,
        51166
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2571583390235901,
      "compression_ratio": 1.483146071434021,
      "no_speech_prob": 0.001956712221726775
    },
    {
      "id": 175,
      "seek": 102384,
      "start": 2273.6600048828122,
      "end": 2277.7399609374997,
      "text": " was wir ursprünglich genannt haben, ist nicht das Problem. Ich glaube, dass Sie eigentlich eine",
      "tokens": [
        51166,
        390,
        1987,
        4038,
        18193,
        36216,
        1739,
        1049,
        39878,
        3084,
        11,
        1418,
        1979,
        1482,
        11676,
        13,
        3141,
        13756,
        11,
        2658,
        3559,
        10926,
        3018,
        51370
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2571583390235901,
      "compression_ratio": 1.483146071434021,
      "no_speech_prob": 0.001956712221726775
    },
    {
      "id": 176,
      "seek": 102384,
      "start": 2277.7399609374997,
      "end": 2282.5800488281247,
      "text": " Analyseplattform bauen wollen und insbesondere Sphere läuft ja auch in diese Richtung. Also ich",
      "tokens": [
        51370,
        1107,
        5222,
        405,
        564,
        49952,
        43787,
        11253,
        674,
        48694,
        318,
        6605,
        31807,
        2784,
        2168,
        294,
        6705,
        33023,
        13,
        2743,
        1893,
        51612
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2571583390235901,
      "compression_ratio": 1.483146071434021,
      "no_speech_prob": 0.001956712221726775
    },
    {
      "id": 177,
      "seek": 104880,
      "start": 2282.6199658203122,
      "end": 2291.4999707031247,
      "text": " mache solche Geschichten. Dann haben wir aber eigentlich was anderes gebaut. Wir haben ein",
      "tokens": [
        50366,
        28289,
        29813,
        14241,
        24681,
        13,
        7455,
        3084,
        1987,
        4340,
        10926,
        390,
        31426,
        49203,
        13,
        4347,
        3084,
        1343,
        50810
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36476263403892517,
      "compression_ratio": 1.4666666984558105,
      "no_speech_prob": 0.21702513098716736
    },
    {
      "id": 178,
      "seek": 104880,
      "start": 2291.4999707031247,
      "end": 2297.4600537109372,
      "text": " System gebaut, mit dem wir Datenanalyse betreiben können. Hier wieder die Beziehung Richtung Data",
      "tokens": [
        50810,
        8910,
        49203,
        11,
        2194,
        1371,
        1987,
        31126,
        282,
        5222,
        405,
        778,
        25946,
        6310,
        13,
        10886,
        6216,
        978,
        879,
        28213,
        1063,
        33023,
        11888,
        51108
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36476263403892517,
      "compression_ratio": 1.4666666984558105,
      "no_speech_prob": 0.21702513098716736
    },
    {
      "id": 179,
      "seek": 104880,
      "start": 2297.4600537109372,
      "end": 2303.0600292968747,
      "text": " Meshes, Data Products, wo ich also irgendwelche Daten, die ich in dem System habe, so darstellen",
      "tokens": [
        51108,
        17485,
        8076,
        11,
        11888,
        47699,
        11,
        6020,
        1893,
        611,
        26455,
        338,
        1876,
        31126,
        11,
        978,
        1893,
        294,
        1371,
        8910,
        6015,
        11,
        370,
        4072,
        17538,
        51388
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36476263403892517,
      "compression_ratio": 1.4666666984558105,
      "no_speech_prob": 0.21702513098716736
    },
    {
      "id": 180,
      "seek": 106928,
      "start": 2303.0600292968747,
      "end": 2316.6600048828122,
      "text": " kann, dass ich sie anschließend analysieren kann. Ich habe jetzt hier eigentlich einen",
      "tokens": [
        50364,
        4028,
        11,
        2658,
        1893,
        2804,
        31508,
        24476,
        521,
        23014,
        5695,
        4028,
        13,
        3141,
        6015,
        4354,
        3296,
        10926,
        4891,
        51044
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33298802375793457,
      "compression_ratio": 1.396039605140686,
      "no_speech_prob": 0.1345447450876236
    },
    {
      "id": 181,
      "seek": 106928,
      "start": 2316.6600048828122,
      "end": 2323.8599560546872,
      "text": " Architekturansatz, der sagt, ich habe verschiedene natürliche Datenrepräsentationen, GraphQL,",
      "tokens": [
        51044,
        10984,
        642,
        2320,
        374,
        599,
        10300,
        11,
        1163,
        15764,
        11,
        1893,
        6015,
        35411,
        8762,
        68,
        31126,
        265,
        1424,
        13555,
        317,
        399,
        268,
        11,
        21884,
        13695,
        11,
        51404
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33298802375793457,
      "compression_ratio": 1.396039605140686,
      "no_speech_prob": 0.1345447450876236
    },
    {
      "id": 182,
      "seek": 106928,
      "start": 2323.8599560546872,
      "end": 2329.6199658203122,
      "text": " Afro, whatever. Ich versuche das zu vereinheitlichen mit einer Plattform und eine gemeinsame Sicht",
      "tokens": [
        51404,
        3325,
        340,
        11,
        2035,
        13,
        3141,
        1774,
        17545,
        1482,
        2164,
        49162,
        8480,
        10193,
        2194,
        6850,
        2149,
        49952,
        674,
        3018,
        22971,
        529,
        36615,
        51692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33298802375793457,
      "compression_ratio": 1.396039605140686,
      "no_speech_prob": 0.1345447450876236
    },
    {
      "id": 183,
      "seek": 109584,
      "start": 2329.6199658203122,
      "end": 2337.3400585937497,
      "text": " darauf anzubieten. Das ist etwas anderes, als wenn ich jetzt jedem Team sagen würde,",
      "tokens": [
        50364,
        18654,
        364,
        40566,
        25868,
        13,
        2846,
        1418,
        9569,
        31426,
        11,
        3907,
        4797,
        1893,
        4354,
        36538,
        7606,
        8360,
        11942,
        11,
        50750
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36514946818351746,
      "compression_ratio": 1.489878535270691,
      "no_speech_prob": 0.033572908490896225
    },
    {
      "id": 184,
      "seek": 109584,
      "start": 2337.3400585937497,
      "end": 2344.2199414062497,
      "text": " die Daten, die du hast, da sind Menschen, die sich vielleicht für diese Daten interessieren.",
      "tokens": [
        50750,
        978,
        31126,
        11,
        978,
        1581,
        6581,
        11,
        1120,
        3290,
        8397,
        11,
        978,
        3041,
        12547,
        2959,
        6705,
        31126,
        12478,
        5695,
        13,
        51094
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36514946818351746,
      "compression_ratio": 1.489878535270691,
      "no_speech_prob": 0.033572908490896225
    },
    {
      "id": 185,
      "seek": 109584,
      "start": 2344.2199414062497,
      "end": 2354.7799999999997,
      "text": " Stell denen die doch zur Verfügung und mach das irgendwie. Was der Data Mesh bzw. Data Product",
      "tokens": [
        51094,
        37364,
        19998,
        978,
        9243,
        7147,
        43026,
        674,
        2246,
        1482,
        20759,
        13,
        3027,
        1163,
        11888,
        376,
        14935,
        39998,
        13,
        11888,
        22005,
        51622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36514946818351746,
      "compression_ratio": 1.489878535270691,
      "no_speech_prob": 0.033572908490896225
    },
    {
      "id": 186,
      "seek": 109584,
      "start": 2354.7799999999997,
      "end": 2358.8599560546872,
      "text": " Ansatz wäre, so wie ich ihn verstehe. Das heißt, ich habe hier eine Integrationsplattform,",
      "tokens": [
        51622,
        14590,
        10300,
        14558,
        11,
        370,
        3355,
        1893,
        14534,
        22442,
        675,
        13,
        2846,
        13139,
        11,
        1893,
        6015,
        3296,
        3018,
        23894,
        763,
        564,
        49952,
        11,
        51826
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36514946818351746,
      "compression_ratio": 1.489878535270691,
      "no_speech_prob": 0.033572908490896225
    },
    {
      "id": 187,
      "seek": 112508,
      "start": 2358.9400341796872,
      "end": 2363.2199414062497,
      "text": " die versucht, das alles unter den Hut zu bekommen. In dem anderen Fall hätte ich einen",
      "tokens": [
        50368,
        978,
        36064,
        11,
        1482,
        7874,
        8662,
        1441,
        39012,
        2164,
        19256,
        13,
        682,
        1371,
        11122,
        7465,
        20041,
        1893,
        4891,
        50582
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28798601031303406,
      "compression_ratio": 1.537500023841858,
      "no_speech_prob": 0.0005274640861898661
    },
    {
      "id": 188,
      "seek": 112508,
      "start": 2363.2199414062497,
      "end": 2370.4600537109372,
      "text": " Marktplatz von Daten. Mir gefällt dieser Marktplatz von Daten besser, weil ich dadurch",
      "tokens": [
        50582,
        39774,
        34755,
        2957,
        31126,
        13,
        9421,
        11271,
        25333,
        9053,
        39774,
        34755,
        2957,
        31126,
        18021,
        11,
        7689,
        1893,
        35472,
        50944
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28798601031303406,
      "compression_ratio": 1.537500023841858,
      "no_speech_prob": 0.0005274640861898661
    },
    {
      "id": 189,
      "seek": 112508,
      "start": 2370.4600537109372,
      "end": 2379.5400097656247,
      "text": " den Teams im Prinzip die Freiheit gebe, die Daten eigenständig in irgendeinem vernünftigen Format zu",
      "tokens": [
        50944,
        1441,
        24702,
        566,
        47572,
        978,
        47825,
        29073,
        11,
        978,
        31126,
        10446,
        16913,
        328,
        294,
        3418,
        27429,
        259,
        443,
        35793,
        3412,
        844,
        3213,
        10126,
        267,
        2164,
        51398
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28798601031303406,
      "compression_ratio": 1.537500023841858,
      "no_speech_prob": 0.0005274640861898661
    },
    {
      "id": 190,
      "seek": 112508,
      "start": 2379.5400097656247,
      "end": 2385.0199902343747,
      "text": " exportieren und jedem Team übertrage, das irgendwie zu machen. Ich habe auch das Gefühl,",
      "tokens": [
        51398,
        10725,
        5695,
        674,
        36538,
        7606,
        3304,
        4290,
        16223,
        11,
        1482,
        20759,
        2164,
        7069,
        13,
        3141,
        6015,
        2168,
        1482,
        29715,
        11,
        51672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28798601031303406,
      "compression_ratio": 1.537500023841858,
      "no_speech_prob": 0.0005274640861898661
    },
    {
      "id": 191,
      "seek": 115124,
      "start": 2385.2199414062497,
      "end": 2391.1399853515622,
      "text": " dass das wahrscheinlich technisch weniger aufwendig ist. Aber wie dem auch sei. Man kann",
      "tokens": [
        50374,
        2658,
        1482,
        30957,
        1537,
        5494,
        23224,
        2501,
        20128,
        328,
        1418,
        13,
        5992,
        3355,
        1371,
        2168,
        10842,
        13,
        2458,
        4028,
        50670
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3482045531272888,
      "compression_ratio": 1.5106383562088013,
      "no_speech_prob": 0.09799641370773315
    },
    {
      "id": 192,
      "seek": 115124,
      "start": 2391.1399853515622,
      "end": 2396.9799511718747,
      "text": " jetzt wahrscheinlich eine Architekturdiskussion führen und schauen, welche Vorteile das andere",
      "tokens": [
        50670,
        4354,
        30957,
        3018,
        10984,
        642,
        2320,
        10752,
        7797,
        2023,
        313,
        35498,
        674,
        25672,
        11,
        24311,
        46968,
        794,
        1482,
        10490,
        50962
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3482045531272888,
      "compression_ratio": 1.5106383562088013,
      "no_speech_prob": 0.09799641370773315
    },
    {
      "id": 193,
      "seek": 115124,
      "start": 2396.9799511718747,
      "end": 2400.9400341796872,
      "text": " System hat. Ich finde es ehrlich gesagt ein bisschen schwierig, das so ad hoc zu sehen,",
      "tokens": [
        50962,
        8910,
        2385,
        13,
        3141,
        17841,
        785,
        40872,
        12260,
        1343,
        10763,
        37845,
        11,
        1482,
        370,
        614,
        16708,
        2164,
        11333,
        11,
        51160
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3482045531272888,
      "compression_ratio": 1.5106383562088013,
      "no_speech_prob": 0.09799641370773315
    },
    {
      "id": 194,
      "seek": 115124,
      "start": 2400.9400341796872,
      "end": 2408.0600292968747,
      "text": " was da die Vorteile wären. Er könnte dann diese Ansage auch normal hinterfragen.",
      "tokens": [
        51160,
        390,
        1120,
        978,
        46968,
        794,
        43933,
        13,
        3300,
        17646,
        3594,
        6705,
        14590,
        609,
        2168,
        2710,
        23219,
        69,
        20663,
        13,
        51516
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3482045531272888,
      "compression_ratio": 1.5106383562088013,
      "no_speech_prob": 0.09799641370773315
    },
    {
      "id": 195,
      "seek": 117428,
      "start": 2408.0600292968747,
      "end": 2423.0999462890622,
      "text": " Genau, der Marco Wesselmann schreibt, was das eigentlich",
      "tokens": [
        50364,
        22340,
        11,
        1163,
        26535,
        343,
        47166,
        14912,
        956,
        31174,
        11,
        390,
        1482,
        10926,
        51116
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6883379220962524,
      "compression_ratio": 0.9032257795333862,
      "no_speech_prob": 0.5986936688423157
    },
    {
      "id": 0,
      "seek": 0,
      "start": 2438.13,
      "end": 2442.8499997901918,
      "text": " der Karl Schmolke gerade geschrieben hat, ich auch nicht und noch sehe ich auch noch kein",
      "tokens": [
        50364,
        1163,
        20405,
        2065,
        76,
        401,
        330,
        12117,
        47397,
        2385,
        11,
        1893,
        2168,
        1979,
        674,
        3514,
        35995,
        1893,
        2168,
        3514,
        13424,
        50600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3857581913471222,
      "compression_ratio": 1.5796610116958618,
      "no_speech_prob": 0.6742501854896545
    },
    {
      "id": 1,
      "seek": 0,
      "start": 2442.8499997901918,
      "end": 2448.209999923706,
      "text": " wirtschaftlich rechtfertigbares zugrundeliegendes Problem. Was hat er weiter geschrieben? Den",
      "tokens": [
        50600,
        1987,
        22165,
        1739,
        24261,
        34784,
        328,
        5356,
        279,
        33507,
        894,
        273,
        338,
        414,
        9395,
        279,
        11676,
        13,
        3027,
        2385,
        1189,
        8988,
        47397,
        30,
        6458,
        50868
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3857581913471222,
      "compression_ratio": 1.5796610116958618,
      "no_speech_prob": 0.6742501854896545
    },
    {
      "id": 2,
      "seek": 0,
      "start": 2448.209999923706,
      "end": 2451.850000267029,
      "text": " wirklichen Grund beziehungsweise Ziel, wo sie darauf hinaus steuern, werden sie nicht öffentlich",
      "tokens": [
        50868,
        9696,
        268,
        13941,
        312,
        28213,
        5846,
        13109,
        25391,
        11,
        6020,
        2804,
        18654,
        46056,
        2126,
        84,
        1248,
        11,
        4604,
        2804,
        1979,
        34603,
        51050
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3857581913471222,
      "compression_ratio": 1.5796610116958618,
      "no_speech_prob": 0.6742501854896545
    },
    {
      "id": 3,
      "seek": 0,
      "start": 2451.850000267029,
      "end": 2457.6099995422364,
      "text": " kundtun. Naja, also nichts zu sagen, wir bauen halt eben eine Datenplattform und Daten zu",
      "tokens": [
        51050,
        350,
        997,
        83,
        409,
        13,
        426,
        12908,
        11,
        611,
        13004,
        2164,
        8360,
        11,
        1987,
        43787,
        12479,
        11375,
        3018,
        31126,
        564,
        49952,
        674,
        31126,
        2164,
        51338
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3857581913471222,
      "compression_ratio": 1.5796610116958618,
      "no_speech_prob": 0.6742501854896545
    },
    {
      "id": 4,
      "seek": 0,
      "start": 2457.6099995422364,
      "end": 2466.050000076294,
      "text": " analysieren, finde ich, können sie halt schon sagen. Aber das ist der nächste Punkt, den ich",
      "tokens": [
        51338,
        23014,
        5695,
        11,
        17841,
        1893,
        11,
        6310,
        2804,
        12479,
        4981,
        8360,
        13,
        5992,
        1482,
        1418,
        1163,
        30661,
        25487,
        11,
        1441,
        1893,
        51760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3857581913471222,
      "compression_ratio": 1.5796610116958618,
      "no_speech_prob": 0.6742501854896545
    },
    {
      "id": 5,
      "seek": 2792,
      "start": 2466.209999923706,
      "end": 2472.289999847412,
      "text": " sozusagen diskutieren wollen würde. Ich habe mir hier aufgeschrieben, overengineering. Also was",
      "tokens": [
        50372,
        33762,
        36760,
        5695,
        11253,
        11942,
        13,
        3141,
        6015,
        3149,
        3296,
        2501,
        23378,
        24027,
        11,
        670,
        25609,
        1794,
        13,
        2743,
        390,
        50676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3592345118522644,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.009556006640195847
    },
    {
      "id": 6,
      "seek": 2792,
      "start": 2472.289999847412,
      "end": 2477.249998931885,
      "text": " das bedeutet ist, dass wir halt jetzt einen massiven Aufwand betreiben, um eine Infrastruktur",
      "tokens": [
        50676,
        1482,
        27018,
        1418,
        11,
        2658,
        1987,
        12479,
        4354,
        4891,
        2758,
        5709,
        9462,
        33114,
        778,
        25946,
        11,
        1105,
        3018,
        38425,
        31543,
        50924
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3592345118522644,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.009556006640195847
    },
    {
      "id": 7,
      "seek": 2792,
      "start": 2477.249998931885,
      "end": 2484.0499981689454,
      "text": " zu schaffen mit in der Menge Zeug, das nicht Netflix spezifisch ist, in dem Sinne, dass es",
      "tokens": [
        50924,
        2164,
        30888,
        2194,
        294,
        1163,
        40723,
        4853,
        697,
        11,
        1482,
        1979,
        12778,
        768,
        89,
        351,
        5494,
        1418,
        11,
        294,
        1371,
        47041,
        11,
        2658,
        785,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3592345118522644,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.009556006640195847
    },
    {
      "id": 8,
      "seek": 2792,
      "start": 2484.0499981689454,
      "end": 2490.13,
      "text": " jetzt speziell abgestimmt ist auf Filme. Das ist im Prinzip ein Datenanalyse Problem mit verschiedenen",
      "tokens": [
        51264,
        4354,
        48682,
        285,
        410,
        2629,
        15314,
        1418,
        2501,
        7905,
        1398,
        13,
        2846,
        1418,
        566,
        47572,
        1343,
        31126,
        282,
        5222,
        405,
        11676,
        2194,
        41043,
        51568
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3592345118522644,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.009556006640195847
    },
    {
      "id": 9,
      "seek": 5200,
      "start": 2490.249998931885,
      "end": 2496.810000305176,
      "text": " Datenquellen und das ist halt kein Netflix Problem, sondern das ist was anderes. Das führt",
      "tokens": [
        50370,
        31126,
        358,
        8581,
        674,
        1482,
        1418,
        12479,
        13424,
        12778,
        11676,
        11,
        11465,
        1482,
        1418,
        390,
        31426,
        13,
        2846,
        39671,
        50698
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3276529312133789,
      "compression_ratio": 1.523809552192688,
      "no_speech_prob": 0.1021774485707283
    },
    {
      "id": 10,
      "seek": 5200,
      "start": 2496.810000305176,
      "end": 2502.0100010681153,
      "text": " natürlich dazu, dass es jetzt ganz viele spannende Engineering Probleme gibt. Also man kann sich",
      "tokens": [
        50698,
        8762,
        13034,
        11,
        2658,
        785,
        4354,
        6312,
        9693,
        33360,
        5445,
        16215,
        32891,
        6089,
        13,
        2743,
        587,
        4028,
        3041,
        50958
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3276529312133789,
      "compression_ratio": 1.523809552192688,
      "no_speech_prob": 0.1021774485707283
    },
    {
      "id": 11,
      "seek": 5200,
      "start": 2502.0100010681153,
      "end": 2507.9699963378907,
      "text": " vorstellen, dass da Sachen sind, die Techniker gerne lösen wollen, wobei ich eigentlich lieber",
      "tokens": [
        50958,
        34346,
        11,
        2658,
        1120,
        26074,
        3290,
        11,
        978,
        8337,
        17314,
        15689,
        25209,
        6748,
        11253,
        11,
        6020,
        21845,
        1893,
        10926,
        38252,
        51256
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3276529312133789,
      "compression_ratio": 1.523809552192688,
      "no_speech_prob": 0.1021774485707283
    },
    {
      "id": 12,
      "seek": 5200,
      "start": 2507.9699963378907,
      "end": 2511.8900021362306,
      "text": " Geschäftslogik bauen würde, aber sei es drum nicht. Also es gibt eben Leute, die gerne technisch",
      "tokens": [
        51256,
        40440,
        82,
        4987,
        1035,
        43787,
        11942,
        11,
        4340,
        10842,
        785,
        10206,
        1979,
        13,
        2743,
        785,
        6089,
        11375,
        13495,
        11,
        978,
        15689,
        1537,
        5494,
        51452
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3276529312133789,
      "compression_ratio": 1.523809552192688,
      "no_speech_prob": 0.1021774485707283
    },
    {
      "id": 13,
      "seek": 7376,
      "start": 2511.8900021362306,
      "end": 2522.3699978637696,
      "text": " komplizierte Sachen lösen und das ist hier sicher ein schönes Spielfeld dafür. Und das ganze Paper",
      "tokens": [
        50364,
        24526,
        590,
        23123,
        26074,
        25209,
        6748,
        674,
        1482,
        1418,
        3296,
        18623,
        1343,
        13527,
        279,
        14266,
        25115,
        13747,
        13,
        2719,
        1482,
        18898,
        24990,
        50888
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41522759199142456,
      "compression_ratio": 1.5115385055541992,
      "no_speech_prob": 0.3270713984966278
    },
    {
      "id": 14,
      "seek": 7376,
      "start": 2522.3699978637696,
      "end": 2528.409998779297,
      "text": " ist halt voll mit ganz viel Technik. Ich habe es ja erzählt, es gibt APA und es gibt Sphere und",
      "tokens": [
        50888,
        1418,
        12479,
        15593,
        2194,
        6312,
        5891,
        8337,
        1035,
        13,
        3141,
        6015,
        785,
        2784,
        47110,
        11,
        785,
        6089,
        5372,
        32,
        674,
        785,
        6089,
        318,
        6605,
        674,
        51190
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41522759199142456,
      "compression_ratio": 1.5115385055541992,
      "no_speech_prob": 0.3270713984966278
    },
    {
      "id": 15,
      "seek": 7376,
      "start": 2528.409998779297,
      "end": 2533.6100033569337,
      "text": " es gibt PDM und was weiß ich und das ist ganz viel in dieser Richtung, aber wenig über konkrete",
      "tokens": [
        51190,
        785,
        6089,
        10464,
        44,
        674,
        390,
        13385,
        1893,
        674,
        1482,
        1418,
        6312,
        5891,
        294,
        9053,
        33023,
        11,
        4340,
        20911,
        4502,
        21428,
        7600,
        51450
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41522759199142456,
      "compression_ratio": 1.5115385055541992,
      "no_speech_prob": 0.3270713984966278
    },
    {
      "id": 16,
      "seek": 7376,
      "start": 2533.6100033569337,
      "end": 2538.6100033569337,
      "text": " Probleme. Genau, Kaschmolka hat auch noch mal geschrieben, was ist eigentlich der geschäftliche",
      "tokens": [
        51450,
        32891,
        13,
        22340,
        11,
        28059,
        339,
        76,
        401,
        2330,
        2385,
        2168,
        3514,
        2806,
        47397,
        11,
        390,
        1418,
        10926,
        1163,
        13511,
        19210,
        10185,
        51700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41522759199142456,
      "compression_ratio": 1.5115385055541992,
      "no_speech_prob": 0.3270713984966278
    },
    {
      "id": 17,
      "seek": 10048,
      "start": 2538.6499966430665,
      "end": 2545.3699978637696,
      "text": " Zweck? Genau, das fehlt halt so ein bisschen und das ist ein bisschen etwas, was Netflix hat auch",
      "tokens": [
        50366,
        32475,
        547,
        30,
        22340,
        11,
        1482,
        47994,
        12479,
        370,
        1343,
        10763,
        674,
        1482,
        1418,
        1343,
        10763,
        9569,
        11,
        390,
        12778,
        2385,
        2168,
        50702
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3464912176132202,
      "compression_ratio": 1.5958904027938843,
      "no_speech_prob": 0.03902973607182503
    },
    {
      "id": 18,
      "seek": 10048,
      "start": 2545.3699978637696,
      "end": 2549.2900036621095,
      "text": " bei dem Microservices Zeug bereits gemacht hat. Die haben eben auch eine eigene Microservices",
      "tokens": [
        50702,
        4643,
        1371,
        5818,
        2635,
        47480,
        4853,
        697,
        23703,
        12293,
        2385,
        13,
        3229,
        3084,
        11375,
        2168,
        3018,
        38549,
        5818,
        2635,
        47480,
        50898
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3464912176132202,
      "compression_ratio": 1.5958904027938843,
      "no_speech_prob": 0.03902973607182503
    },
    {
      "id": 19,
      "seek": 10048,
      "start": 2549.2900036621095,
      "end": 2554.729998474121,
      "text": " Stack gebaut mit einer Menge an Open Source Projekten und dabei zum Beispiel auch diese",
      "tokens": [
        50898,
        37649,
        49203,
        2194,
        6850,
        40723,
        364,
        7238,
        29629,
        1705,
        27023,
        1147,
        674,
        14967,
        5919,
        13772,
        2168,
        6705,
        51170
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3464912176132202,
      "compression_ratio": 1.5958904027938843,
      "no_speech_prob": 0.03902973607182503
    },
    {
      "id": 20,
      "seek": 10048,
      "start": 2554.729998474121,
      "end": 2559.689997558594,
      "text": " Resilience Lösung gebaut, das Hystrix, was ja mittlerweile eingestellt worden ist und das ist",
      "tokens": [
        51170,
        5015,
        388,
        1182,
        46934,
        49203,
        11,
        1482,
        5701,
        372,
        6579,
        11,
        390,
        2784,
        41999,
        17002,
        377,
        12783,
        14054,
        1418,
        674,
        1482,
        1418,
        51418
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3464912176132202,
      "compression_ratio": 1.5958904027938843,
      "no_speech_prob": 0.03902973607182503
    },
    {
      "id": 21,
      "seek": 10048,
      "start": 2559.689997558594,
      "end": 2564.689997558594,
      "text": " glaube ich da im Prinzip dasselbe. Also wir investieren viel Aufwand, um eine Infrastruktur",
      "tokens": [
        51418,
        13756,
        1893,
        1120,
        566,
        47572,
        2658,
        338,
        650,
        13,
        2743,
        1987,
        1963,
        5695,
        5891,
        9462,
        33114,
        11,
        1105,
        3018,
        38425,
        31543,
        51668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3464912176132202,
      "compression_ratio": 1.5958904027938843,
      "no_speech_prob": 0.03902973607182503
    },
    {
      "id": 22,
      "seek": 12656,
      "start": 2564.7699993896485,
      "end": 2572.450007324219,
      "text": " zu schaffen für irgendein Problem und also bei dem Microservices Stack kann man noch diskutieren,",
      "tokens": [
        50368,
        2164,
        30888,
        2959,
        3418,
        27429,
        259,
        11676,
        674,
        611,
        4643,
        1371,
        5818,
        2635,
        47480,
        37649,
        4028,
        587,
        3514,
        36760,
        5695,
        11,
        50752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32128265500068665,
      "compression_ratio": 1.3908629417419434,
      "no_speech_prob": 0.03619685396552086
    },
    {
      "id": 23,
      "seek": 12656,
      "start": 2572.450007324219,
      "end": 2579.8500012207032,
      "text": " ob es keinen am Markt gab. Hier ist halt mein Gefühl, also zumindest eine oberflächliche",
      "tokens": [
        50752,
        1111,
        785,
        20624,
        669,
        39774,
        17964,
        13,
        10886,
        1418,
        12479,
        10777,
        29715,
        11,
        611,
        38082,
        3018,
        277,
        607,
        3423,
        10168,
        10185,
        51122
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32128265500068665,
      "compression_ratio": 1.3908629417419434,
      "no_speech_prob": 0.03619685396552086
    },
    {
      "id": 24,
      "seek": 12656,
      "start": 2579.8500012207032,
      "end": 2585.450007324219,
      "text": " Recherche ergibt halt, dass es halt Integrationsplattformen gibt, die sowas wie eine",
      "tokens": [
        51122,
        1300,
        6759,
        1876,
        26585,
        13651,
        12479,
        11,
        2658,
        785,
        12479,
        23894,
        763,
        564,
        49952,
        268,
        6089,
        11,
        978,
        19766,
        296,
        3355,
        3018,
        51402
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32128265500068665,
      "compression_ratio": 1.3908629417419434,
      "no_speech_prob": 0.03619685396552086
    },
    {
      "id": 25,
      "seek": 14732,
      "start": 2585.450007324219,
      "end": 2601.0499981689454,
      "text": " Ontologie und so etwas unterstützen. Das bedeutet für mich, Kunden, die ich typischerweise berate,",
      "tokens": [
        50364,
        16980,
        20121,
        674,
        370,
        9569,
        43081,
        13,
        2846,
        27018,
        2959,
        6031,
        11,
        38192,
        11,
        978,
        1893,
        2125,
        5494,
        44071,
        5948,
        473,
        11,
        51144
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43089738488197327,
      "compression_ratio": 1.5126903057098389,
      "no_speech_prob": 0.4333944022655487
    },
    {
      "id": 26,
      "seek": 14732,
      "start": 2601.0499981689454,
      "end": 2605.8099926757814,
      "text": " dem würde ich halt nicht dazu raten, dieses zu tun, weil das massiver, tinscher Aufwand ist und",
      "tokens": [
        51144,
        1371,
        11942,
        1893,
        12479,
        1979,
        13034,
        5937,
        268,
        11,
        978,
        405,
        82,
        2164,
        4267,
        11,
        7689,
        1482,
        2758,
        1837,
        11,
        256,
        1292,
        6759,
        9462,
        33114,
        1418,
        674,
        51382
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43089738488197327,
      "compression_ratio": 1.5126903057098389,
      "no_speech_prob": 0.4333944022655487
    },
    {
      "id": 27,
      "seek": 14732,
      "start": 2605.8099926757814,
      "end": 2611.7699993896485,
      "text": " es ist nicht so klar, was der Vorteil ist und ich würde mich fragen, ob ich nichts kaufen kann. Ich",
      "tokens": [
        51382,
        785,
        1418,
        1979,
        370,
        14743,
        11,
        390,
        1163,
        46968,
        388,
        1418,
        674,
        1893,
        11942,
        6031,
        39129,
        11,
        1111,
        1893,
        13004,
        42083,
        4028,
        13,
        3141,
        51680
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43089738488197327,
      "compression_ratio": 1.5126903057098389,
      "no_speech_prob": 0.4333944022655487
    },
    {
      "id": 28,
      "seek": 17364,
      "start": 2611.7699993896485,
      "end": 2615.650004272461,
      "text": " investiere da irgendwie in Infrastruktur, nicht in meine spezifische Geschäftslogik und das ist",
      "tokens": [
        50364,
        1963,
        14412,
        1120,
        20759,
        294,
        38425,
        31543,
        11,
        1979,
        294,
        10946,
        768,
        89,
        351,
        7864,
        40440,
        82,
        4987,
        1035,
        674,
        1482,
        1418,
        50558
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31836462020874023,
      "compression_ratio": 1.567460298538208,
      "no_speech_prob": 0.11426614969968796
    },
    {
      "id": 29,
      "seek": 17364,
      "start": 2615.650004272461,
      "end": 2622.7300061035157,
      "text": " halt selten eine gute Idee. Cashmoney hat nochmal geschrieben, das werden sie erst auflösen, wenn",
      "tokens": [
        50558,
        12479,
        5851,
        1147,
        3018,
        21476,
        32651,
        13,
        27016,
        76,
        1308,
        2385,
        26509,
        47397,
        11,
        1482,
        4604,
        2804,
        11301,
        2501,
        75,
        973,
        6748,
        11,
        4797,
        50912
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31836462020874023,
      "compression_ratio": 1.567460298538208,
      "no_speech_prob": 0.11426614969968796
    },
    {
      "id": 30,
      "seek": 17364,
      "start": 2622.7300061035157,
      "end": 2629.0100048828126,
      "text": " sie damit erfolgreich waren. Mitbewerbervorteil, ja sicher werden sie wahrscheinlich nicht darüber",
      "tokens": [
        50912,
        2804,
        9479,
        48270,
        11931,
        13,
        10821,
        650,
        1554,
        607,
        85,
        12752,
        388,
        11,
        2784,
        18623,
        4604,
        2804,
        30957,
        1979,
        21737,
        51226
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31836462020874023,
      "compression_ratio": 1.567460298538208,
      "no_speech_prob": 0.11426614969968796
    },
    {
      "id": 31,
      "seek": 17364,
      "start": 2629.0100048828126,
      "end": 2638.370005493164,
      "text": " öffentlich reden, aber es ist trotzdem irgendwie komisch, dass sie dort so wenig, also ich kann ja",
      "tokens": [
        51226,
        34603,
        26447,
        11,
        4340,
        785,
        1418,
        28325,
        20759,
        5207,
        5494,
        11,
        2658,
        2804,
        15775,
        370,
        20911,
        11,
        611,
        1893,
        4028,
        2784,
        51694
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31836462020874023,
      "compression_ratio": 1.567460298538208,
      "no_speech_prob": 0.11426614969968796
    },
    {
      "id": 32,
      "seek": 20024,
      "start": 2638.370005493164,
      "end": 2644.3299969482423,
      "text": " auch abstrakt über Geschäftsprobleme reden, also dass ich sage, ich will Sachen analysieren und das",
      "tokens": [
        50364,
        2168,
        10823,
        32249,
        4502,
        40440,
        82,
        47419,
        68,
        26447,
        11,
        611,
        2658,
        1893,
        19721,
        11,
        1893,
        486,
        26074,
        23014,
        5695,
        674,
        1482,
        50662
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3949317932128906,
      "compression_ratio": 1.53125,
      "no_speech_prob": 0.20154650509357452
    },
    {
      "id": 33,
      "seek": 20024,
      "start": 2644.3299969482423,
      "end": 2650.2499951171876,
      "text": " tun sie halt wenig bis gar nichts. Ich habe das Gefühl, dass diese starke technische Motivation,",
      "tokens": [
        50662,
        4267,
        2804,
        12479,
        20911,
        7393,
        3691,
        13004,
        13,
        3141,
        6015,
        1482,
        29715,
        11,
        2658,
        6705,
        3543,
        330,
        1537,
        7864,
        8956,
        592,
        399,
        11,
        50958
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3949317932128906,
      "compression_ratio": 1.53125,
      "no_speech_prob": 0.20154650509357452
    },
    {
      "id": 34,
      "seek": 20024,
      "start": 2650.2499951171876,
      "end": 2659.5299938964845,
      "text": " dieses Over-Engineering und die Ablehnung von Kaufsoftware, dass das bei diesem Blogartikel",
      "tokens": [
        50958,
        12113,
        422,
        303,
        81,
        12,
        31254,
        533,
        1794,
        674,
        978,
        316,
        638,
        12071,
        1063,
        2957,
        44590,
        13908,
        3039,
        11,
        2658,
        1482,
        4643,
        10975,
        46693,
        446,
        41486,
        51422
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3949317932128906,
      "compression_ratio": 1.53125,
      "no_speech_prob": 0.20154650509357452
    },
    {
      "id": 35,
      "seek": 20024,
      "start": 2659.5299938964845,
      "end": 2664.3299969482423,
      "text": " irgendwie durchschreitet. Es ist ja auch nicht so, dass sie schreiben, hey und das ist übrigens so,",
      "tokens": [
        51422,
        20759,
        7131,
        6145,
        265,
        16341,
        13,
        2313,
        1418,
        2784,
        2168,
        1979,
        370,
        11,
        2658,
        2804,
        48546,
        11,
        4177,
        674,
        1482,
        1418,
        38215,
        370,
        11,
        51662
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3949317932128906,
      "compression_ratio": 1.53125,
      "no_speech_prob": 0.20154650509357452
    },
    {
      "id": 36,
      "seek": 22620,
      "start": 2664.370005493164,
      "end": 2669.0900067138673,
      "text": " dass es da zwar Lösungen am Markt gibt, aber die passen auf uns nicht, weil folgende Gründe,",
      "tokens": [
        50366,
        2658,
        785,
        1120,
        19054,
        34642,
        5084,
        669,
        39774,
        6089,
        11,
        4340,
        978,
        1320,
        268,
        2501,
        2693,
        1979,
        11,
        7689,
        3339,
        27429,
        2606,
        25596,
        11,
        50602
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36672478914260864,
      "compression_ratio": 1.5910652875900269,
      "no_speech_prob": 0.05497705936431885
    },
    {
      "id": 37,
      "seek": 22620,
      "start": 2669.0900067138673,
      "end": 2675.0900067138673,
      "text": " sondern es steht einfach da, wir haben es dann irgendwie gelöst. Warum veröffentlichen sie das",
      "tokens": [
        50602,
        11465,
        785,
        16361,
        7281,
        1120,
        11,
        1987,
        3084,
        785,
        3594,
        20759,
        4087,
        36995,
        13,
        25541,
        1306,
        973,
        22805,
        268,
        2804,
        1482,
        50902
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36672478914260864,
      "compression_ratio": 1.5910652875900269,
      "no_speech_prob": 0.05497705936431885
    },
    {
      "id": 38,
      "seek": 22620,
      "start": 2675.0900067138673,
      "end": 2678.0100048828126,
      "text": " ganze? Das hatte ich mir noch aufgeschrieben. Das ist ja auch so eine Frage. Wollen die uns",
      "tokens": [
        50902,
        18898,
        30,
        2846,
        13299,
        1893,
        3149,
        3514,
        2501,
        23378,
        24027,
        13,
        2846,
        1418,
        2784,
        2168,
        370,
        3018,
        13685,
        13,
        343,
        26669,
        978,
        2693,
        51048
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36672478914260864,
      "compression_ratio": 1.5910652875900269,
      "no_speech_prob": 0.05497705936431885
    },
    {
      "id": 39,
      "seek": 22620,
      "start": 2678.0100048828126,
      "end": 2685.409998779297,
      "text": " irgendwas mitteilen? Ist das irgendwie eine Motivation? Sie schreiben, dass sie sich mit",
      "tokens": [
        51048,
        47090,
        275,
        9786,
        17471,
        30,
        12810,
        1482,
        20759,
        3018,
        8956,
        592,
        399,
        30,
        3559,
        48546,
        11,
        2658,
        2804,
        3041,
        2194,
        51418
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36672478914260864,
      "compression_ratio": 1.5910652875900269,
      "no_speech_prob": 0.05497705936431885
    },
    {
      "id": 40,
      "seek": 22620,
      "start": 2685.409998779297,
      "end": 2689.2900036621095,
      "text": " anderen Leuten vernetzen wollen, die Ähnliches bauen und ich glaube insgesamt ist das ein",
      "tokens": [
        51418,
        11122,
        42301,
        1306,
        7129,
        2904,
        11253,
        11,
        978,
        13700,
        35646,
        279,
        43787,
        674,
        1893,
        13756,
        41438,
        1418,
        1482,
        1343,
        51612
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36672478914260864,
      "compression_ratio": 1.5910652875900269,
      "no_speech_prob": 0.05497705936431885
    },
    {
      "id": 41,
      "seek": 25116,
      "start": 2689.2900036621095,
      "end": 2695.5299938964845,
      "text": " Versuch, um Engineers zu gewinnen, die gute Engineers sind, weswegen das vielleicht auch eine",
      "tokens": [
        50364,
        12226,
        625,
        11,
        1105,
        43950,
        2164,
        6906,
        11399,
        11,
        978,
        21476,
        43950,
        3290,
        11,
        38384,
        13683,
        1482,
        12547,
        2168,
        3018,
        50676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3297627866268158,
      "compression_ratio": 1.5506073236465454,
      "no_speech_prob": 0.23599210381507874
    },
    {
      "id": 42,
      "seek": 25116,
      "start": 2695.5299938964845,
      "end": 2702.4899853515626,
      "text": " technische Diskussion ist. Solche Blogs macht man jedenfalls nicht, um mehr Zuschauer zu gewinnen,",
      "tokens": [
        50676,
        1537,
        7864,
        45963,
        313,
        1418,
        13,
        7026,
        1876,
        46693,
        82,
        10857,
        587,
        12906,
        18542,
        1979,
        11,
        1105,
        5417,
        48333,
        18120,
        2164,
        6906,
        11399,
        11,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3297627866268158,
      "compression_ratio": 1.5506073236465454,
      "no_speech_prob": 0.23599210381507874
    },
    {
      "id": 43,
      "seek": 25116,
      "start": 2702.4899853515626,
      "end": 2707.8500012207032,
      "text": " sondern ich glaube, dass es letztendlich Personalmarketing ist, wenn es einen Grund gibt.",
      "tokens": [
        51024,
        11465,
        1893,
        13756,
        11,
        2658,
        785,
        35262,
        521,
        1739,
        25317,
        5638,
        9880,
        1418,
        11,
        4797,
        785,
        4891,
        13941,
        6089,
        13,
        51292
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3297627866268158,
      "compression_ratio": 1.5506073236465454,
      "no_speech_prob": 0.23599210381507874
    },
    {
      "id": 44,
      "seek": 25116,
      "start": 2707.8500012207032,
      "end": 2715.2900036621095,
      "text": " Jetzt ist die Frage, ist es denn nun tatsächlich so ein Widerspruch zu dieser Idee, mehrere Modelle",
      "tokens": [
        51292,
        12592,
        1418,
        978,
        13685,
        11,
        1418,
        785,
        10471,
        8905,
        20796,
        370,
        1343,
        343,
        6936,
        45788,
        2164,
        9053,
        32651,
        11,
        44677,
        6583,
        4434,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3297627866268158,
      "compression_ratio": 1.5506073236465454,
      "no_speech_prob": 0.23599210381507874
    },
    {
      "id": 45,
      "seek": 27716,
      "start": 2715.369990234375,
      "end": 2727.0100048828126,
      "text": " zu haben? Ich glaube, das ist kein solcher Widerspruch. Der erste Punkt ist, vielleicht",
      "tokens": [
        50368,
        2164,
        3084,
        30,
        3141,
        13756,
        11,
        1482,
        1418,
        13424,
        1404,
        6759,
        343,
        6936,
        45788,
        13,
        5618,
        20951,
        25487,
        1418,
        11,
        12547,
        50950
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3880208432674408,
      "compression_ratio": 1.4175257682800293,
      "no_speech_prob": 0.07471789419651031
    },
    {
      "id": 46,
      "seek": 27716,
      "start": 2727.0100048828126,
      "end": 2733.3300122070314,
      "text": " ist das, worüber wir reden, tatsächlich nur einbauende Kontexte. Es ist Content Engineering",
      "tokens": [
        50950,
        1418,
        1482,
        11,
        469,
        12670,
        1987,
        26447,
        11,
        20796,
        4343,
        1343,
        4231,
        622,
        16404,
        20629,
        3828,
        68,
        13,
        2313,
        1418,
        30078,
        16215,
        51266
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3880208432674408,
      "compression_ratio": 1.4175257682800293,
      "no_speech_prob": 0.07471789419651031
    },
    {
      "id": 47,
      "seek": 27716,
      "start": 2733.3300122070314,
      "end": 2742.2900036621095,
      "text": " und Content Engineering nicht von dem Pitch bis es zum Launch geht. Da kann es sehr gut sein,",
      "tokens": [
        51266,
        674,
        30078,
        16215,
        1979,
        2957,
        1371,
        430,
        1549,
        7393,
        785,
        5919,
        28119,
        7095,
        13,
        3933,
        4028,
        785,
        5499,
        5228,
        6195,
        11,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3880208432674408,
      "compression_ratio": 1.4175257682800293,
      "no_speech_prob": 0.07471789419651031
    },
    {
      "id": 48,
      "seek": 30416,
      "start": 2742.4899853515626,
      "end": 2747.9699963378907,
      "text": " dass ein Modell und eine Art, Daten zu repräsentieren, ausreichend ist. Vielleicht",
      "tokens": [
        50374,
        2658,
        1343,
        6583,
        898,
        674,
        3018,
        5735,
        11,
        31126,
        2164,
        1085,
        11397,
        49315,
        5695,
        11,
        3437,
        12594,
        521,
        1418,
        13,
        29838,
        50648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34704843163490295,
      "compression_ratio": 1.5767441987991333,
      "no_speech_prob": 0.04270350933074951
    },
    {
      "id": 49,
      "seek": 30416,
      "start": 2747.9699963378907,
      "end": 2757.5700024414064,
      "text": " ist das eine Erklärung, um diese beiden Sachen miteinander zu vereinbaren.",
      "tokens": [
        50648,
        1418,
        1482,
        3018,
        3300,
        45988,
        1063,
        11,
        1105,
        6705,
        23446,
        26074,
        43127,
        2164,
        1306,
        68,
        259,
        43552,
        13,
        51128
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34704843163490295,
      "compression_ratio": 1.5767441987991333,
      "no_speech_prob": 0.04270350933074951
    },
    {
      "id": 50,
      "seek": 30416,
      "start": 2757.5700024414064,
      "end": 2764.689997558594,
      "text": " Das Ziel ist nicht, Aufwand zu sparen. Stefan hat in seinem Artikel damals geschrieben,",
      "tokens": [
        51128,
        2846,
        25391,
        1418,
        1979,
        11,
        9462,
        33114,
        2164,
        637,
        4484,
        13,
        32158,
        2385,
        294,
        29187,
        5735,
        41486,
        26067,
        47397,
        11,
        51484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34704843163490295,
      "compression_ratio": 1.5767441987991333,
      "no_speech_prob": 0.04270350933074951
    },
    {
      "id": 51,
      "seek": 30416,
      "start": 2764.689997558594,
      "end": 2767.9699963378907,
      "text": " wenn ich es einmal modelliere, dann habe ich es einmal modelliert, kann es wiederverwenden,",
      "tokens": [
        51484,
        4797,
        1893,
        785,
        11078,
        1072,
        898,
        14412,
        11,
        3594,
        6015,
        1893,
        785,
        11078,
        1072,
        898,
        4859,
        11,
        4028,
        785,
        6216,
        331,
        86,
        8896,
        11,
        51648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34704843163490295,
      "compression_ratio": 1.5767441987991333,
      "no_speech_prob": 0.04270350933074951
    },
    {
      "id": 52,
      "seek": 32984,
      "start": 2767.9699963378907,
      "end": 2773.170008544922,
      "text": " das ist einfacher. Das ist nicht das, was Sie schreiben, das schreiben Sie ganz deutlich nicht,",
      "tokens": [
        50364,
        1482,
        1418,
        38627,
        4062,
        13,
        2846,
        1418,
        1979,
        1482,
        11,
        390,
        3559,
        48546,
        11,
        1482,
        48546,
        3559,
        6312,
        24344,
        1979,
        11,
        50624
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3334815502166748,
      "compression_ratio": 1.5545850992202759,
      "no_speech_prob": 0.03844982013106346
    },
    {
      "id": 53,
      "seek": 32984,
      "start": 2773.170008544922,
      "end": 2780.0500134277345,
      "text": " sondern es geht eben um Analyse. Es gibt Möglichkeiten, das allgemeine Modell zu",
      "tokens": [
        50624,
        11465,
        785,
        7095,
        11375,
        1105,
        1107,
        5222,
        405,
        13,
        2313,
        6089,
        42627,
        11,
        1482,
        439,
        31964,
        533,
        6583,
        898,
        2164,
        50968
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3334815502166748,
      "compression_ratio": 1.5545850992202759,
      "no_speech_prob": 0.03844982013106346
    },
    {
      "id": 54,
      "seek": 32984,
      "start": 2780.0500134277345,
      "end": 2784.649989013672,
      "text": " erweitern. Das hatte ich bei AppA genannt, bei dieser Sprache, mit der man diese Schemata",
      "tokens": [
        50968,
        1189,
        28019,
        1248,
        13,
        2846,
        13299,
        1893,
        4643,
        3132,
        32,
        1049,
        39878,
        11,
        4643,
        9053,
        7702,
        6000,
        11,
        2194,
        1163,
        587,
        6705,
        2065,
        443,
        3274,
        51198
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3334815502166748,
      "compression_ratio": 1.5545850992202759,
      "no_speech_prob": 0.03844982013106346
    },
    {
      "id": 55,
      "seek": 32984,
      "start": 2784.649989013672,
      "end": 2790.9699963378907,
      "text": " definieren kann. Ich hatte auch gesagt, dass dieses S-Kurs in dem PDM sogar ermöglicht,",
      "tokens": [
        51198,
        1561,
        5695,
        4028,
        13,
        3141,
        13299,
        2168,
        12260,
        11,
        2658,
        12113,
        318,
        12,
        42,
        2156,
        294,
        1371,
        10464,
        44,
        19485,
        25253,
        50023,
        20238,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3334815502166748,
      "compression_ratio": 1.5545850992202759,
      "no_speech_prob": 0.03844982013106346
    },
    {
      "id": 56,
      "seek": 35284,
      "start": 2790.9699963378907,
      "end": 2801.369990234375,
      "text": " dass Teams ihre eigene Sprache nutzen, ohne jetzt mit dem PDM in Kontakt zu sein.",
      "tokens": [
        50364,
        2658,
        24702,
        14280,
        38549,
        7702,
        6000,
        36905,
        11,
        15716,
        4354,
        2194,
        1371,
        10464,
        44,
        294,
        43396,
        2164,
        6195,
        13,
        50884
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45681363344192505,
      "compression_ratio": 1.3315508365631104,
      "no_speech_prob": 0.2807607650756836
    },
    {
      "id": 57,
      "seek": 35284,
      "start": 2801.369990234375,
      "end": 2807.5700024414064,
      "text": " Das kann bedeuten, dass es tatsächlich mehrere Modelle gibt, aber das steht nur am Rande da.",
      "tokens": [
        50884,
        2846,
        4028,
        22466,
        7886,
        11,
        2658,
        785,
        20796,
        44677,
        6583,
        4434,
        6089,
        11,
        4340,
        1482,
        16361,
        4343,
        669,
        497,
        11123,
        1120,
        13,
        51194
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45681363344192505,
      "compression_ratio": 1.3315508365631104,
      "no_speech_prob": 0.2807607650756836
    },
    {
      "id": 58,
      "seek": 35284,
      "start": 2812.9699963378907,
      "end": 2817.4899853515626,
      "text": " Jetzt hat Karl Schmeuke geschrieben, in einem möglichen Grund den Ansatz",
      "tokens": [
        51464,
        12592,
        2385,
        20405,
        2065,
        1398,
        15420,
        47397,
        11,
        294,
        6827,
        16294,
        268,
        13941,
        1441,
        14590,
        10300,
        51690
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45681363344192505,
      "compression_ratio": 1.3315508365631104,
      "no_speech_prob": 0.2807607650756836
    },
    {
      "id": 59,
      "seek": 37936,
      "start": 2818.0899914550782,
      "end": 2824.890009765625,
      "text": " vom Sparen zu challengen. Dafür ist es zu spät. Die sind sehr lange in diese Richtung marschiert,",
      "tokens": [
        50394,
        10135,
        1738,
        4484,
        2164,
        2076,
        268,
        1766,
        13,
        35865,
        1418,
        785,
        2164,
        637,
        3628,
        13,
        3229,
        3290,
        5499,
        18131,
        294,
        6705,
        33023,
        30517,
        339,
        4859,
        11,
        50734
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30771562457084656,
      "compression_ratio": 1.5165562629699707,
      "no_speech_prob": 0.0600469708442688
    },
    {
      "id": 60,
      "seek": 37936,
      "start": 2824.890009765625,
      "end": 2832.3300122070314,
      "text": " haben offensichtlich ganz viele Systeme gebaut. Das ist weit über eine Idee hinweg. Ich glaube,",
      "tokens": [
        50734,
        3084,
        766,
        694,
        41971,
        6312,
        9693,
        8910,
        68,
        49203,
        13,
        2846,
        1418,
        15306,
        4502,
        3018,
        32651,
        14102,
        12517,
        13,
        3141,
        13756,
        11,
        51106
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30771562457084656,
      "compression_ratio": 1.5165562629699707,
      "no_speech_prob": 0.0600469708442688
    },
    {
      "id": 61,
      "seek": 37936,
      "start": 2832.3300122070314,
      "end": 2835.5700024414064,
      "text": " dass man das nicht mehr ernsthaft ohne Gesichtsverlust kassieren kann.",
      "tokens": [
        51106,
        2658,
        587,
        1482,
        1979,
        5417,
        43412,
        25127,
        15716,
        47777,
        82,
        331,
        75,
        381,
        350,
        640,
        5695,
        4028,
        13,
        51268
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30771562457084656,
      "compression_ratio": 1.5165562629699707,
      "no_speech_prob": 0.0600469708442688
    },
    {
      "id": 62,
      "seek": 37936,
      "start": 2835.5700024414064,
      "end": 2841.3300122070314,
      "text": " Dann hat Tobias Böschel geschrieben, das kann eigentlich nur KI getrieben sein. Singuläre",
      "tokens": [
        51268,
        7455,
        2385,
        26350,
        4609,
        363,
        973,
        6145,
        338,
        47397,
        11,
        1482,
        4028,
        10926,
        4343,
        47261,
        483,
        24027,
        6195,
        13,
        7474,
        425,
        12277,
        51556
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30771562457084656,
      "compression_ratio": 1.5165562629699707,
      "no_speech_prob": 0.0600469708442688
    },
    {
      "id": 63,
      "seek": 37936,
      "start": 2841.3300122070314,
      "end": 2846.170008544922,
      "text": " Datenhaltung über die gesamte Geschäftsdomäne bedeutet Verfügbarkeit für allwissende Agenten.",
      "tokens": [
        51556,
        31126,
        20731,
        1063,
        4502,
        978,
        39746,
        975,
        40440,
        82,
        4121,
        737,
        716,
        27018,
        41611,
        5356,
        9238,
        2959,
        439,
        86,
        891,
        5445,
        27174,
        268,
        13,
        51798
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30771562457084656,
      "compression_ratio": 1.5165562629699707,
      "no_speech_prob": 0.0600469708442688
    },
    {
      "id": 64,
      "seek": 40804,
      "start": 2846.689997558594,
      "end": 2858.0500134277345,
      "text": " Das könnte auch sein. Da muss man vielleicht auch hinzufügen, dass vom Business-Usern",
      "tokens": [
        50390,
        2846,
        17646,
        2168,
        6195,
        13,
        3933,
        6425,
        587,
        12547,
        2168,
        14102,
        39467,
        45336,
        11,
        2658,
        10135,
        10715,
        12,
        29211,
        1248,
        50958
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35620996356010437,
      "compression_ratio": 1.335078477859497,
      "no_speech_prob": 0.027578063309192657
    },
    {
      "id": 65,
      "seek": 40804,
      "start": 2858.0500134277345,
      "end": 2865.0100048828126,
      "text": " tatsächlich die Sprache ist. In dem gesamten Artikel erinnere ich zumindest nicht,",
      "tokens": [
        50958,
        20796,
        978,
        7702,
        6000,
        1418,
        13,
        682,
        1371,
        39746,
        1147,
        5735,
        41486,
        1189,
        7729,
        323,
        1893,
        38082,
        1979,
        11,
        51306
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35620996356010437,
      "compression_ratio": 1.335078477859497,
      "no_speech_prob": 0.027578063309192657
    },
    {
      "id": 66,
      "seek": 40804,
      "start": 2865.0100048828126,
      "end": 2872.0899914550782,
      "text": " dass AI oder KI angesprochen worden ist. Aber Tobias, du hast recht. Das ist etwas,",
      "tokens": [
        51306,
        2658,
        7318,
        4513,
        47261,
        31138,
        23902,
        14054,
        1418,
        13,
        5992,
        26350,
        4609,
        11,
        1581,
        6581,
        24261,
        13,
        2846,
        1418,
        9569,
        11,
        51660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35620996356010437,
      "compression_ratio": 1.335078477859497,
      "no_speech_prob": 0.027578063309192657
    },
    {
      "id": 67,
      "seek": 43396,
      "start": 2872.2099865722657,
      "end": 2878.8500012207032,
      "text": " was in so eine Motivation gehen könnte. Ich habe diese Daten bestimmt und die sollen durch",
      "tokens": [
        50370,
        390,
        294,
        370,
        3018,
        8956,
        592,
        399,
        13230,
        17646,
        13,
        3141,
        6015,
        6705,
        31126,
        1151,
        332,
        42744,
        674,
        978,
        24713,
        7131,
        50702
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38618361949920654,
      "compression_ratio": 1.5260869264602661,
      "no_speech_prob": 0.08382588624954224
    },
    {
      "id": 68,
      "seek": 43396,
      "start": 2878.8500012207032,
      "end": 2887.3300122070314,
      "text": " AI analysiert werden. Ich hatte es am Anfang gesagt, so etwas wie eine Published Language",
      "tokens": [
        50702,
        7318,
        23014,
        4859,
        4604,
        13,
        3141,
        13299,
        785,
        669,
        25856,
        12260,
        11,
        370,
        9569,
        3355,
        3018,
        21808,
        4173,
        24445,
        51126
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38618361949920654,
      "compression_ratio": 1.5260869264602661,
      "no_speech_prob": 0.08382588624954224
    },
    {
      "id": 69,
      "seek": 43396,
      "start": 2887.3300122070314,
      "end": 2893.0899914550782,
      "text": " oder Datenprodukte sind okay und sinnvoll. Datenprodukte sind sicherlich eine ganz",
      "tokens": [
        51126,
        4513,
        31126,
        14314,
        18844,
        3290,
        1392,
        674,
        47066,
        20654,
        13,
        31126,
        14314,
        18844,
        3290,
        18623,
        1739,
        3018,
        6312,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38618361949920654,
      "compression_ratio": 1.5260869264602661,
      "no_speech_prob": 0.08382588624954224
    },
    {
      "id": 70,
      "seek": 43396,
      "start": 2893.0899914550782,
      "end": 2898.0899914550782,
      "text": " hervorragende Ergänzung zu so etwas wie Domain-Driven Design. Das kann durchaus sein,",
      "tokens": [
        51414,
        720,
        8453,
        3731,
        5445,
        3300,
        70,
        4029,
        27667,
        2164,
        370,
        9569,
        3355,
        16674,
        491,
        12,
        35,
        470,
        553,
        12748,
        13,
        2846,
        4028,
        42840,
        6195,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38618361949920654,
      "compression_ratio": 1.5260869264602661,
      "no_speech_prob": 0.08382588624954224
    },
    {
      "id": 71,
      "seek": 45996,
      "start": 2898.2099865722657,
      "end": 2905.5700024414064,
      "text": " dass wir gerade so einen Fall hier eigentlich sehen. Vielleicht ist das eben genau so etwas,",
      "tokens": [
        50370,
        2658,
        1987,
        12117,
        370,
        4891,
        7465,
        3296,
        10926,
        11333,
        13,
        29838,
        1418,
        1482,
        11375,
        12535,
        370,
        9569,
        11,
        50738
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36586323380470276,
      "compression_ratio": 1.5344129800796509,
      "no_speech_prob": 0.15796910226345062
    },
    {
      "id": 72,
      "seek": 45996,
      "start": 2905.5700024414064,
      "end": 2912.13,
      "text": " was konzeptionell einer Published Language oder solchen Datenprodukten aus dem Data Mesh ähnelt",
      "tokens": [
        50738,
        390,
        5897,
        32082,
        313,
        898,
        6850,
        21808,
        4173,
        24445,
        4513,
        46281,
        31126,
        14314,
        47120,
        3437,
        1371,
        11888,
        376,
        14935,
        3078,
        12071,
        2018,
        51066
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36586323380470276,
      "compression_ratio": 1.5344129800796509,
      "no_speech_prob": 0.15796910226345062
    },
    {
      "id": 73,
      "seek": 45996,
      "start": 2912.13,
      "end": 2917.170008544922,
      "text": " und dann dafür sorgt, dass man sagt, hier gibt es eine Repräsentation, die ich nach außen",
      "tokens": [
        51066,
        674,
        3594,
        13747,
        262,
        36698,
        11,
        2658,
        587,
        15764,
        11,
        3296,
        6089,
        785,
        3018,
        3696,
        11397,
        49315,
        399,
        11,
        978,
        1893,
        5168,
        1609,
        8989,
        51318
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36586323380470276,
      "compression_ratio": 1.5344129800796509,
      "no_speech_prob": 0.15796910226345062
    },
    {
      "id": 74,
      "seek": 45996,
      "start": 2917.170008544922,
      "end": 2922.0899914550782,
      "text": " entgebe für die Analyse. Ich habe eine interne Repräsentation. Das sind zwei getrennte Sachen.",
      "tokens": [
        51318,
        948,
        432,
        650,
        2959,
        978,
        1107,
        5222,
        405,
        13,
        3141,
        6015,
        3018,
        728,
        716,
        3696,
        11397,
        49315,
        399,
        13,
        2846,
        3290,
        12002,
        483,
        1095,
        9358,
        26074,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36586323380470276,
      "compression_ratio": 1.5344129800796509,
      "no_speech_prob": 0.15796910226345062
    },
    {
      "id": 75,
      "seek": 48396,
      "start": 2922.2099865722657,
      "end": 2926.689997558594,
      "text": " Diese interne Repräsentation ist für mich speziell und die nach draußen ist eine,",
      "tokens": [
        50370,
        18993,
        728,
        716,
        3696,
        11397,
        49315,
        399,
        1418,
        2959,
        6031,
        48682,
        285,
        674,
        978,
        5168,
        44602,
        1418,
        3018,
        11,
        50594
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3279891312122345,
      "compression_ratio": 1.450819730758667,
      "no_speech_prob": 0.0467011034488678
    },
    {
      "id": 76,
      "seek": 48396,
      "start": 2926.689997558594,
      "end": 2931.5700024414064,
      "text": " die ich für die Analyse anbiete. Dann hätte ich da eben auch keinen Widerspruch.",
      "tokens": [
        50594,
        978,
        1893,
        2959,
        978,
        1107,
        5222,
        405,
        364,
        65,
        40462,
        13,
        7455,
        20041,
        1893,
        1120,
        11375,
        2168,
        20624,
        343,
        6936,
        45788,
        13,
        50838
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3279891312122345,
      "compression_ratio": 1.450819730758667,
      "no_speech_prob": 0.0467011034488678
    },
    {
      "id": 77,
      "seek": 48396,
      "start": 2931.5700024414064,
      "end": 2939.9699963378907,
      "text": " Der Daniel Pützinger hatte bei LinkedIn noch gesagt, im Domain-Driven Design gibt es ja ein",
      "tokens": [
        50838,
        5618,
        8033,
        430,
        7695,
        89,
        6911,
        13299,
        4643,
        20657,
        3514,
        12260,
        11,
        566,
        16674,
        491,
        12,
        35,
        470,
        553,
        12748,
        6089,
        785,
        2784,
        1343,
        51258
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3279891312122345,
      "compression_ratio": 1.450819730758667,
      "no_speech_prob": 0.0467011034488678
    },
    {
      "id": 78,
      "seek": 48396,
      "start": 2939.9699963378907,
      "end": 2947.929987792969,
      "text": " paar Patterns, die er zumindest in diesem Text wiederfindet. Er nannte da zum Beispiel Shared",
      "tokens": [
        51258,
        16509,
        34367,
        3695,
        11,
        978,
        1189,
        38082,
        294,
        10975,
        18643,
        6216,
        35072,
        302,
        13,
        3300,
        14067,
        9358,
        1120,
        5919,
        13772,
        1160,
        1642,
        51656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3279891312122345,
      "compression_ratio": 1.450819730758667,
      "no_speech_prob": 0.0467011034488678
    },
    {
      "id": 79,
      "seek": 50980,
      "start": 2947.929987792969,
      "end": 2954.65001953125,
      "text": " Kernel. Shared Kernel ist etwas, wo ich ihm sage, zwei unterschiedliche Modelle haben einen",
      "tokens": [
        50364,
        40224,
        338,
        13,
        1160,
        1642,
        40224,
        338,
        1418,
        9569,
        11,
        6020,
        1893,
        16021,
        19721,
        11,
        12002,
        30058,
        10185,
        6583,
        4434,
        3084,
        4891,
        50700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24649807810783386,
      "compression_ratio": 1.6755555868148804,
      "no_speech_prob": 0.15799924731254578
    },
    {
      "id": 80,
      "seek": 50980,
      "start": 2954.65001953125,
      "end": 2960.5300244140626,
      "text": " gemeinsamen Kern. Das ist das, was Shared Kernel sagt. Ich sehe hier kein Shared Kernel, weil",
      "tokens": [
        50700,
        22971,
        22403,
        40224,
        13,
        2846,
        1418,
        1482,
        11,
        390,
        1160,
        1642,
        40224,
        338,
        15764,
        13,
        3141,
        35995,
        3296,
        13424,
        1160,
        1642,
        40224,
        338,
        11,
        7689,
        50994
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24649807810783386,
      "compression_ratio": 1.6755555868148804,
      "no_speech_prob": 0.15799924731254578
    },
    {
      "id": 81,
      "seek": 50980,
      "start": 2960.5300244140626,
      "end": 2966.0100048828126,
      "text": " Shared Kernel Modelle sind für mich Logik. Wir teilen hier keine Logik, sondern wir reden hier",
      "tokens": [
        50994,
        1160,
        1642,
        40224,
        338,
        6583,
        4434,
        3290,
        2959,
        6031,
        10824,
        1035,
        13,
        4347,
        535,
        17471,
        3296,
        9252,
        10824,
        1035,
        11,
        11465,
        1987,
        26447,
        3296,
        51268
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24649807810783386,
      "compression_ratio": 1.6755555868148804,
      "no_speech_prob": 0.15799924731254578
    },
    {
      "id": 82,
      "seek": 50980,
      "start": 2966.0100048828126,
      "end": 2973.410029296875,
      "text": " nur über den Austausch von Daten. Sonst könnte das sein, dass man sowas per einen gemeinsamen",
      "tokens": [
        51268,
        4343,
        4502,
        1441,
        4126,
        8463,
        339,
        2957,
        31126,
        13,
        318,
        4068,
        17646,
        1482,
        6195,
        11,
        2658,
        587,
        19766,
        296,
        680,
        4891,
        22971,
        22403,
        51638
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24649807810783386,
      "compression_ratio": 1.6755555868148804,
      "no_speech_prob": 0.15799924731254578
    },
    {
      "id": 83,
      "seek": 53528,
      "start": 2973.410029296875,
      "end": 2980.970026855469,
      "text": " Datenkern definiert. Dann schrieb er noch sowas wie ein Open-Host-Service. Das könnte",
      "tokens": [
        50364,
        31126,
        74,
        1248,
        1561,
        4859,
        13,
        7455,
        956,
        31775,
        1189,
        3514,
        19766,
        296,
        3355,
        1343,
        7238,
        12,
        39,
        329,
        83,
        12,
        50,
        25006,
        13,
        2846,
        17646,
        50742
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31347760558128357,
      "compression_ratio": 1.4293193817138672,
      "no_speech_prob": 0.11913635581731796
    },
    {
      "id": 84,
      "seek": 53528,
      "start": 2980.970026855469,
      "end": 2987.169978027344,
      "text": " das sein. Open-Host-Service ist nach meinem Empfinden eine Schnittstelle, die viele andere",
      "tokens": [
        50742,
        1482,
        6195,
        13,
        7238,
        12,
        29644,
        12,
        50,
        25006,
        1418,
        5168,
        24171,
        8599,
        43270,
        3018,
        318,
        32064,
        372,
        4434,
        11,
        978,
        9693,
        10490,
        51052
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31347760558128357,
      "compression_ratio": 1.4293193817138672,
      "no_speech_prob": 0.11913635581731796
    },
    {
      "id": 85,
      "seek": 53528,
      "start": 2987.169978027344,
      "end": 2997.929987792969,
      "text": " Teams konsumieren. Was auch wiederum bedeutet, Zugriff auf Logik. Das sehe ich hier auch nicht.",
      "tokens": [
        51052,
        24702,
        27896,
        449,
        5695,
        13,
        3027,
        2168,
        6216,
        449,
        27018,
        11,
        34722,
        81,
        3661,
        2501,
        10824,
        1035,
        13,
        2846,
        35995,
        1893,
        3296,
        2168,
        1979,
        13,
        51590
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31347760558128357,
      "compression_ratio": 1.4293193817138672,
      "no_speech_prob": 0.11913635581731796
    },
    {
      "id": 86,
      "seek": 55980,
      "start": 2998.450007324219,
      "end": 3003.970026855469,
      "text": " Das ist meiner Ansicht nach ein Datenformat, keine Schnittstelle. Es ist auch ein Datenformat,",
      "tokens": [
        50390,
        2846,
        1418,
        20529,
        14590,
        1405,
        5168,
        1343,
        31126,
        837,
        267,
        11,
        9252,
        318,
        32064,
        372,
        4434,
        13,
        2313,
        1418,
        2168,
        1343,
        31126,
        837,
        267,
        11,
        50666
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3575814962387085,
      "compression_ratio": 1.7162162065505981,
      "no_speech_prob": 0.019415762275457382
    },
    {
      "id": 87,
      "seek": 55980,
      "start": 3003.970026855469,
      "end": 3010.450007324219,
      "text": " das sozusagen aufgepoppt wird. Man sagt allen, bitte konvertiere deine Daten in dieses Datenformat",
      "tokens": [
        50666,
        1482,
        33762,
        35031,
        13872,
        662,
        4578,
        13,
        2458,
        15764,
        18440,
        11,
        23231,
        5897,
        3281,
        14412,
        28395,
        31126,
        294,
        12113,
        31126,
        837,
        267,
        50990
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3575814962387085,
      "compression_ratio": 1.7162162065505981,
      "no_speech_prob": 0.019415762275457382
    },
    {
      "id": 88,
      "seek": 55980,
      "start": 3010.450007324219,
      "end": 3016.890009765625,
      "text": " oder ziehe dieses Datenformat vielleicht sogar in deine Systeme mit rein. Dann hat er noch",
      "tokens": [
        50990,
        4513,
        16503,
        675,
        12113,
        31126,
        837,
        267,
        12547,
        19485,
        294,
        28395,
        8910,
        68,
        2194,
        6561,
        13,
        7455,
        2385,
        1189,
        3514,
        51312
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3575814962387085,
      "compression_ratio": 1.7162162065505981,
      "no_speech_prob": 0.019415762275457382
    },
    {
      "id": 89,
      "seek": 55980,
      "start": 3016.890009765625,
      "end": 3024.3300122070314,
      "text": " genannt als Pattern Conformist. Conformist ist ein Pattern, wo jemand ein Modell vorgibt und die",
      "tokens": [
        51312,
        1049,
        39878,
        3907,
        34367,
        77,
        2656,
        837,
        468,
        13,
        2656,
        837,
        468,
        1418,
        1343,
        34367,
        77,
        11,
        6020,
        21717,
        1343,
        6583,
        898,
        4245,
        70,
        13651,
        674,
        978,
        51684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3575814962387085,
      "compression_ratio": 1.7162162065505981,
      "no_speech_prob": 0.019415762275457382
    },
    {
      "id": 90,
      "seek": 58620,
      "start": 3024.3300122070314,
      "end": 3029.13,
      "text": " anderen müssen das nutzen und haben kein Mitspracherecht, also kein Veto-Recht oder",
      "tokens": [
        50364,
        11122,
        9013,
        1482,
        36905,
        674,
        3084,
        13424,
        40897,
        1424,
        608,
        48561,
        11,
        611,
        13424,
        691,
        19515,
        12,
        8524,
        4701,
        4513,
        50604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3169720470905304,
      "compression_ratio": 1.622377634048462,
      "no_speech_prob": 0.05337429419159889
    },
    {
      "id": 91,
      "seek": 58620,
      "start": 3029.13,
      "end": 3033.7299755859376,
      "text": " keine Möglichkeit, das weiterzuentwickeln. Zum Beispiel, weil es vielleicht ein Legacy-System ist",
      "tokens": [
        50604,
        9252,
        30662,
        11,
        1482,
        8988,
        11728,
        317,
        22295,
        32099,
        13,
        23906,
        13772,
        11,
        7689,
        785,
        12547,
        1343,
        42838,
        12,
        50,
        9321,
        1418,
        50834
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3169720470905304,
      "compression_ratio": 1.622377634048462,
      "no_speech_prob": 0.05337429419159889
    },
    {
      "id": 92,
      "seek": 58620,
      "start": 3033.7299755859376,
      "end": 3040.0900219726564,
      "text": " und das Legacy-System nicht anpassbar ist, sodass man mit dem leben muss, was dort ist.",
      "tokens": [
        50834,
        674,
        1482,
        42838,
        12,
        50,
        9321,
        1979,
        364,
        9216,
        5356,
        1418,
        11,
        15047,
        640,
        587,
        2194,
        1371,
        26392,
        6425,
        11,
        390,
        15775,
        1418,
        13,
        51152
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3169720470905304,
      "compression_ratio": 1.622377634048462,
      "no_speech_prob": 0.05337429419159889
    },
    {
      "id": 93,
      "seek": 58620,
      "start": 3040.0900219726564,
      "end": 3046.2499951171876,
      "text": " Es wäre eine ähnliche Geschichte. Es ist für mich eher eine Sache, die etwas mit Logik zu tun hat.",
      "tokens": [
        51152,
        2313,
        14558,
        3018,
        3078,
        12071,
        10185,
        28896,
        13,
        2313,
        1418,
        2959,
        6031,
        24332,
        3018,
        31452,
        11,
        978,
        9569,
        2194,
        10824,
        1035,
        2164,
        4267,
        2385,
        13,
        51460
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3169720470905304,
      "compression_ratio": 1.622377634048462,
      "no_speech_prob": 0.05337429419159889
    },
    {
      "id": 94,
      "seek": 58620,
      "start": 3046.2499951171876,
      "end": 3051.210017089844,
      "text": " Conformist hat eher etwas mit Logik zu tun. Es hat insbesondere eine bilaterale Beziehung,",
      "tokens": [
        51460,
        2656,
        837,
        468,
        2385,
        24332,
        9569,
        2194,
        10824,
        1035,
        2164,
        4267,
        13,
        2313,
        2385,
        48694,
        3018,
        8588,
        771,
        1220,
        879,
        28213,
        1063,
        11,
        51708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3169720470905304,
      "compression_ratio": 1.622377634048462,
      "no_speech_prob": 0.05337429419159889
    },
    {
      "id": 95,
      "seek": 61308,
      "start": 3051.3300122070314,
      "end": 3057.169978027344,
      "text": " wo ich also zwei Teams habe, die miteinander reden. Das sehe ich hier auch nicht. Insgesamt ist es",
      "tokens": [
        50370,
        6020,
        1893,
        611,
        12002,
        24702,
        6015,
        11,
        978,
        43127,
        26447,
        13,
        2846,
        35995,
        1893,
        3296,
        2168,
        1979,
        13,
        9442,
        34818,
        1418,
        785,
        50662
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3017544150352478,
      "compression_ratio": 1.6280701160430908,
      "no_speech_prob": 0.026748737320303917
    },
    {
      "id": 96,
      "seek": 61308,
      "start": 3057.169978027344,
      "end": 3064.450007324219,
      "text": " halt eher etwas, was für mich in die Datenintegration geht. Es ist tatsächlich so,",
      "tokens": [
        50662,
        12479,
        24332,
        9569,
        11,
        390,
        2959,
        6031,
        294,
        978,
        31126,
        31131,
        399,
        7095,
        13,
        2313,
        1418,
        20796,
        370,
        11,
        51026
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3017544150352478,
      "compression_ratio": 1.6280701160430908,
      "no_speech_prob": 0.026748737320303917
    },
    {
      "id": 97,
      "seek": 61308,
      "start": 3064.450007324219,
      "end": 3070.369990234375,
      "text": " dass in den gesamten Blogposts, in meiner Erinnerung, keine Funktionalitäten besprochen",
      "tokens": [
        51026,
        2658,
        294,
        1441,
        39746,
        1147,
        46693,
        23744,
        82,
        11,
        294,
        20529,
        3300,
        19166,
        1063,
        11,
        9252,
        11166,
        2320,
        1966,
        49289,
        4097,
        23902,
        51322
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3017544150352478,
      "compression_ratio": 1.6280701160430908,
      "no_speech_prob": 0.026748737320303917
    },
    {
      "id": 98,
      "seek": 61308,
      "start": 3070.369990234375,
      "end": 3075.369990234375,
      "text": " werden. Es wird nirgendwo gesagt, auch nicht bei diesem One-Piece-Beispiel, was man jetzt",
      "tokens": [
        51322,
        4604,
        13,
        2313,
        4578,
        297,
        347,
        9395,
        6120,
        12260,
        11,
        2168,
        1979,
        4643,
        10975,
        1485,
        12,
        47,
        46566,
        12,
        6524,
        11935,
        11,
        390,
        587,
        4354,
        51572
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3017544150352478,
      "compression_ratio": 1.6280701160430908,
      "no_speech_prob": 0.026748737320303917
    },
    {
      "id": 99,
      "seek": 61308,
      "start": 3075.369990234375,
      "end": 3079.4899853515626,
      "text": " eigentlich mit diesen Daten anfangen will, sondern es wird nur gesagt, die Daten sind da und ich kann",
      "tokens": [
        51572,
        10926,
        2194,
        12862,
        31126,
        33709,
        10784,
        486,
        11,
        11465,
        785,
        4578,
        4343,
        12260,
        11,
        978,
        31126,
        3290,
        1120,
        674,
        1893,
        4028,
        51778
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3017544150352478,
      "compression_ratio": 1.6280701160430908,
      "no_speech_prob": 0.026748737320303917
    },
    {
      "id": 100,
      "seek": 64136,
      "start": 3079.4899853515626,
      "end": 3086.3300122070314,
      "text": " sie mir angucken und analysieren. Das ist meiner Ansicht nach nicht das, was DDD-Modelle, die",
      "tokens": [
        50364,
        2804,
        3149,
        2562,
        49720,
        674,
        23014,
        5695,
        13,
        2846,
        1418,
        20529,
        14590,
        1405,
        5168,
        1979,
        1482,
        11,
        390,
        413,
        20818,
        12,
        44,
        378,
        4434,
        11,
        978,
        50706
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36328125,
      "compression_ratio": 1.4586776494979858,
      "no_speech_prob": 0.029751112684607506
    },
    {
      "id": 101,
      "seek": 64136,
      "start": 3086.3300122070314,
      "end": 3092.8099926757814,
      "text": " speziell darauf ausgerichtet sind, komplexe Logik zu implementieren, wo das hingeht.",
      "tokens": [
        50706,
        48682,
        285,
        18654,
        3437,
        1321,
        40387,
        3290,
        11,
        5207,
        18945,
        68,
        10824,
        1035,
        2164,
        4445,
        5695,
        11,
        6020,
        1482,
        28822,
        357,
        13,
        51030
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36328125,
      "compression_ratio": 1.4586776494979858,
      "no_speech_prob": 0.029751112684607506
    },
    {
      "id": 102,
      "seek": 64136,
      "start": 3092.8099926757814,
      "end": 3103.13,
      "text": " Mutex.ab bei den Heise-Foren hat dann noch geschrieben, das könnte ich auch mit",
      "tokens": [
        51030,
        376,
        1169,
        87,
        13,
        455,
        4643,
        1441,
        634,
        908,
        12,
        37,
        10948,
        2385,
        3594,
        3514,
        47397,
        11,
        1482,
        17646,
        1893,
        2168,
        2194,
        51546
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36328125,
      "compression_ratio": 1.4586776494979858,
      "no_speech_prob": 0.029751112684607506
    },
    {
      "id": 103,
      "seek": 64136,
      "start": 3103.13,
      "end": 3109.0100048828126,
      "text": " Datenbanken und Datenbank-Links umsetzen. Eine gemeinsame Sicht mit Views und darüber kriege",
      "tokens": [
        51546,
        31126,
        65,
        18493,
        674,
        31126,
        25423,
        12,
        43,
        16431,
        1105,
        3854,
        2904,
        13,
        17664,
        22971,
        529,
        36615,
        2194,
        13909,
        82,
        674,
        21737,
        25766,
        432,
        51840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36328125,
      "compression_ratio": 1.4586776494979858,
      "no_speech_prob": 0.029751112684607506
    },
    {
      "id": 104,
      "seek": 67088,
      "start": 3109.0100048828126,
      "end": 3117.849970703125,
      "text": " ich das hin. Ja, aber hier kann ich mit mehr Heterogenität umgehen. Ich habe sowas wie",
      "tokens": [
        50364,
        1893,
        1482,
        14102,
        13,
        3530,
        11,
        4340,
        3296,
        4028,
        1893,
        2194,
        5417,
        389,
        2398,
        8799,
        14053,
        1105,
        24985,
        13,
        3141,
        6015,
        19766,
        296,
        3355,
        50806
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3579046130180359,
      "compression_ratio": 1.4940239191055298,
      "no_speech_prob": 0.005060012452304363
    },
    {
      "id": 105,
      "seek": 67088,
      "start": 3117.849970703125,
      "end": 3122.60998046875,
      "text": " GraphQL, was ja nicht eine Datenrepräsentation ist, sondern da ist es so, dass ich über HTTP",
      "tokens": [
        50806,
        21884,
        13695,
        11,
        390,
        2784,
        1979,
        3018,
        31126,
        265,
        1424,
        13555,
        317,
        399,
        1418,
        11,
        11465,
        1120,
        1418,
        785,
        370,
        11,
        2658,
        1893,
        4502,
        33283,
        51044
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3579046130180359,
      "compression_ratio": 1.4940239191055298,
      "no_speech_prob": 0.005060012452304363
    },
    {
      "id": 106,
      "seek": 67088,
      "start": 3122.60998046875,
      "end": 3128.4899853515626,
      "text": " REST stelle und mich Daten zur Verfügung stelle. Dann habe ich sowas wie dieses Apache Iceberg.",
      "tokens": [
        51044,
        497,
        14497,
        342,
        4434,
        674,
        6031,
        31126,
        7147,
        43026,
        342,
        4434,
        13,
        7455,
        6015,
        1893,
        19766,
        296,
        3355,
        12113,
        46597,
        15332,
        6873,
        13,
        51338
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3579046130180359,
      "compression_ratio": 1.4940239191055298,
      "no_speech_prob": 0.005060012452304363
    },
    {
      "id": 107,
      "seek": 67088,
      "start": 3128.4899853515626,
      "end": 3133.4899853515626,
      "text": " Dann habe ich halt Dataproducts aus dem Data Mesh und die können andere Persistenztechnologien",
      "tokens": [
        51338,
        7455,
        6015,
        1893,
        12479,
        9315,
        569,
        2323,
        349,
        82,
        3437,
        1371,
        11888,
        376,
        14935,
        674,
        978,
        6310,
        10490,
        14006,
        4821,
        89,
        29113,
        1132,
        1053,
        51588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3579046130180359,
      "compression_ratio": 1.4940239191055298,
      "no_speech_prob": 0.005060012452304363
    },
    {
      "id": 108,
      "seek": 69536,
      "start": 3133.4899853515626,
      "end": 3140.60998046875,
      "text": " benutzen. Das heißt, ich habe hier tatsächlich eine flexiblere Möglichkeit und ich muss auch",
      "tokens": [
        50364,
        38424,
        2904,
        13,
        2846,
        13139,
        11,
        1893,
        6015,
        3296,
        20796,
        3018,
        5896,
        11476,
        323,
        30662,
        674,
        1893,
        6425,
        2168,
        50720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2893090844154358,
      "compression_ratio": 1.52173912525177,
      "no_speech_prob": 0.21181295812129974
    },
    {
      "id": 109,
      "seek": 69536,
      "start": 3140.60998046875,
      "end": 3147.0499829101564,
      "text": " gestehen, solche Systeme, die versuchen, sich über die Datenbank zu integrieren, das ist eine",
      "tokens": [
        50720,
        7219,
        68,
        2932,
        11,
        29813,
        8910,
        68,
        11,
        978,
        34749,
        11,
        3041,
        4502,
        978,
        31126,
        25423,
        2164,
        16200,
        470,
        5170,
        11,
        1482,
        1418,
        3018,
        51042
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2893090844154358,
      "compression_ratio": 1.52173912525177,
      "no_speech_prob": 0.21181295812129974
    },
    {
      "id": 110,
      "seek": 69536,
      "start": 3147.0499829101564,
      "end": 3152.689997558594,
      "text": " von den Sachen, wo ich in meiner Beratungspraxis zu oft gesehen habe, dass das dazu führt, dass",
      "tokens": [
        51042,
        2957,
        1441,
        26074,
        11,
        6020,
        1893,
        294,
        20529,
        5637,
        267,
        1063,
        4952,
        424,
        39637,
        2164,
        11649,
        21535,
        6015,
        11,
        2658,
        1482,
        13034,
        39671,
        11,
        2658,
        51324
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2893090844154358,
      "compression_ratio": 1.52173912525177,
      "no_speech_prob": 0.21181295812129974
    },
    {
      "id": 111,
      "seek": 69536,
      "start": 3152.689997558594,
      "end": 3158.929987792969,
      "text": " man ein großes kompliziertes Modell hat, was de facto dann eben von vielen Systemen genutzt wird",
      "tokens": [
        51324,
        587,
        1343,
        48875,
        24526,
        43590,
        279,
        6583,
        898,
        2385,
        11,
        390,
        368,
        42225,
        3594,
        11375,
        2957,
        19885,
        8910,
        268,
        1049,
        325,
        2682,
        4578,
        51636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2893090844154358,
      "compression_ratio": 1.52173912525177,
      "no_speech_prob": 0.21181295812129974
    },
    {
      "id": 112,
      "seek": 72080,
      "start": 3158.929987792969,
      "end": 3167.0900219726564,
      "text": " und schwer änderbar ist. Davon würde ich generell eher Abstand nehmen. Ich halte Integration",
      "tokens": [
        50364,
        674,
        23809,
        24981,
        260,
        5356,
        1418,
        13,
        3724,
        266,
        11942,
        1893,
        41553,
        285,
        24332,
        2847,
        1115,
        19905,
        13,
        3141,
        7523,
        975,
        47713,
        50772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32174819707870483,
      "compression_ratio": 1.597561001777649,
      "no_speech_prob": 0.11749224364757538
    },
    {
      "id": 113,
      "seek": 72080,
      "start": 3167.0900219726564,
      "end": 3176.929987792969,
      "text": " über die Datenbank, über sowas wie Datenbankviews und so weiter eher für schwierig. Auch da kann",
      "tokens": [
        50772,
        4502,
        978,
        31126,
        25423,
        11,
        4502,
        19766,
        296,
        3355,
        31126,
        25423,
        1759,
        82,
        674,
        370,
        8988,
        24332,
        2959,
        37845,
        13,
        13382,
        1120,
        4028,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32174819707870483,
      "compression_ratio": 1.597561001777649,
      "no_speech_prob": 0.11749224364757538
    },
    {
      "id": 114,
      "seek": 72080,
      "start": 3176.929987792969,
      "end": 3181.849970703125,
      "text": " man im Einzelfall wahrscheinlich diskutieren, aber ich würde davon eher Abstand nehmen, weil",
      "tokens": [
        51264,
        587,
        566,
        6391,
        34686,
        336,
        30957,
        36760,
        5695,
        11,
        4340,
        1893,
        11942,
        18574,
        24332,
        2847,
        1115,
        19905,
        11,
        7689,
        51510
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32174819707870483,
      "compression_ratio": 1.597561001777649,
      "no_speech_prob": 0.11749224364757538
    },
    {
      "id": 115,
      "seek": 72080,
      "start": 3181.849970703125,
      "end": 3186.169978027344,
      "text": " ich Angst davor hätte, dass man dann am Ende bei einem großen komplizierten Datenbankmodell rauskommt,",
      "tokens": [
        51510,
        1893,
        28622,
        274,
        1924,
        20041,
        11,
        2658,
        587,
        3594,
        669,
        15152,
        4643,
        6827,
        23076,
        24526,
        590,
        29632,
        31126,
        25423,
        8014,
        898,
        17202,
        74,
        22230,
        11,
        51726
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32174819707870483,
      "compression_ratio": 1.597561001777649,
      "no_speech_prob": 0.11749224364757538
    },
    {
      "id": 116,
      "seek": 74804,
      "start": 3186.169978027344,
      "end": 3200.890009765625,
      "text": " das irgendwie schwerwertig ist. Was mich noch insbesondere gewundert hat, ist, ich hatte es vor",
      "tokens": [
        50364,
        1482,
        20759,
        23809,
        26521,
        328,
        1418,
        13,
        3027,
        6031,
        3514,
        1028,
        6446,
        78,
        273,
        323,
        6906,
        34267,
        2385,
        11,
        1418,
        11,
        1893,
        13299,
        785,
        4245,
        51100
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39967748522758484,
      "compression_ratio": 1.4578946828842163,
      "no_speech_prob": 0.00970689207315445
    },
    {
      "id": 117,
      "seek": 74804,
      "start": 3200.890009765625,
      "end": 3208.5700024414064,
      "text": " allem bei Stefans Artikel nochmal gesagt, es gibt also jetzt ein paar, also warum legen wir,",
      "tokens": [
        51100,
        17585,
        4643,
        43421,
        599,
        5735,
        41486,
        26509,
        12260,
        11,
        785,
        6089,
        611,
        4354,
        1343,
        16509,
        11,
        611,
        24331,
        48315,
        1987,
        11,
        51484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39967748522758484,
      "compression_ratio": 1.4578946828842163,
      "no_speech_prob": 0.00970689207315445
    },
    {
      "id": 118,
      "seek": 74804,
      "start": 3208.5700024414064,
      "end": 3214.169978027344,
      "text": " ich, so viel Wert darauf, dass wir getrennte Modelle haben und Systeme aufteilen mehrere",
      "tokens": [
        51484,
        1893,
        11,
        370,
        5891,
        37205,
        18654,
        11,
        2658,
        1987,
        483,
        1095,
        9358,
        6583,
        4434,
        3084,
        674,
        8910,
        68,
        1609,
        16268,
        17471,
        44677,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39967748522758484,
      "compression_ratio": 1.4578946828842163,
      "no_speech_prob": 0.00970689207315445
    },
    {
      "id": 119,
      "seek": 77604,
      "start": 3214.169978027344,
      "end": 3219.849970703125,
      "text": " Modelle. Einmal deswegen, weil wir sonst in konzeptionelle Schwierigkeiten kommen. Ein",
      "tokens": [
        50364,
        6583,
        4434,
        13,
        6391,
        5579,
        26482,
        11,
        7689,
        1987,
        26309,
        294,
        5897,
        32082,
        313,
        4434,
        17576,
        811,
        37545,
        11729,
        13,
        6391,
        50648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24735577404499054,
      "compression_ratio": 1.4329897165298462,
      "no_speech_prob": 0.0014777521137148142
    },
    {
      "id": 120,
      "seek": 77604,
      "start": 3219.849970703125,
      "end": 3224.5300244140626,
      "text": " Kunde, der eincheckt, ist eben nicht der Kunde, der die Rechnung bekommt. Und dann, weil diese",
      "tokens": [
        50648,
        591,
        13271,
        11,
        1163,
        1343,
        1876,
        19951,
        11,
        1418,
        11375,
        1979,
        1163,
        591,
        13271,
        11,
        1163,
        978,
        1300,
        1377,
        1063,
        33429,
        13,
        2719,
        3594,
        11,
        7689,
        6705,
        50882
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24735577404499054,
      "compression_ratio": 1.4329897165298462,
      "no_speech_prob": 0.0014777521137148142
    },
    {
      "id": 121,
      "seek": 77604,
      "start": 3224.5300244140626,
      "end": 3241.13,
      "text": " umfangreichen großen zentralen Modelle super schwierig zu ändern sind. Es passiert zu häufig,",
      "tokens": [
        50882,
        1105,
        19134,
        29119,
        23076,
        710,
        317,
        2155,
        268,
        6583,
        4434,
        1687,
        37845,
        2164,
        47775,
        3290,
        13,
        2313,
        21671,
        2164,
        47543,
        11,
        51712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24735577404499054,
      "compression_ratio": 1.4329897165298462,
      "no_speech_prob": 0.0014777521137148142
    },
    {
      "id": 122,
      "seek": 80300,
      "start": 3241.169978027344,
      "end": 3244.689997558594,
      "text": " dass man sagt, ich habe hier eine große Datenbank, da ist ein großes kompliziertes",
      "tokens": [
        50366,
        2658,
        587,
        15764,
        11,
        1893,
        6015,
        3296,
        3018,
        19691,
        31126,
        25423,
        11,
        1120,
        1418,
        1343,
        48875,
        24526,
        43590,
        279,
        50542
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29538655281066895,
      "compression_ratio": 1.7644788026809692,
      "no_speech_prob": 0.16007961332798004
    },
    {
      "id": 123,
      "seek": 80300,
      "start": 3244.689997558594,
      "end": 3249.2899731445314,
      "text": " Modell drin. Dann habe ich lauter Systeme drumherum und dann versuche ich, die Systeme",
      "tokens": [
        50542,
        6583,
        898,
        24534,
        13,
        7455,
        6015,
        1893,
        635,
        20314,
        8910,
        68,
        10206,
        511,
        449,
        674,
        3594,
        1774,
        17545,
        1893,
        11,
        978,
        8910,
        68,
        50772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29538655281066895,
      "compression_ratio": 1.7644788026809692,
      "no_speech_prob": 0.16007961332798004
    },
    {
      "id": 124,
      "seek": 80300,
      "start": 3249.2899731445314,
      "end": 3253.890009765625,
      "text": " aufzuteilen. Aber das klappt nicht, weil ich diese Datenbank im Kern habe. Die Datenbank kann",
      "tokens": [
        50772,
        2501,
        89,
        1169,
        17471,
        13,
        5992,
        1482,
        33337,
        42562,
        1979,
        11,
        7689,
        1893,
        6705,
        31126,
        25423,
        566,
        40224,
        6015,
        13,
        3229,
        31126,
        25423,
        4028,
        51002
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29538655281066895,
      "compression_ratio": 1.7644788026809692,
      "no_speech_prob": 0.16007961332798004
    },
    {
      "id": 125,
      "seek": 80300,
      "start": 3253.890009765625,
      "end": 3258.210017089844,
      "text": " ich nicht aufteilen, weil niemand weiß, welche Daten welches System nutzt. Und dann habe ich",
      "tokens": [
        51002,
        1893,
        1979,
        1609,
        16268,
        17471,
        11,
        7689,
        32390,
        13385,
        11,
        24311,
        31126,
        2214,
        3781,
        8910,
        5393,
        2682,
        13,
        2719,
        3594,
        6015,
        1893,
        51218
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29538655281066895,
      "compression_ratio": 1.7644788026809692,
      "no_speech_prob": 0.16007961332798004
    },
    {
      "id": 126,
      "seek": 80300,
      "start": 3258.210017089844,
      "end": 3267.849970703125,
      "text": " letztendlich ein ganz schwieriges Problem, jemals dieses System aufzuteilen. Und zu diesem Thema,",
      "tokens": [
        51218,
        35262,
        521,
        1739,
        1343,
        6312,
        27546,
        20609,
        11676,
        11,
        361,
        443,
        1124,
        12113,
        8910,
        2501,
        89,
        1169,
        17471,
        13,
        2719,
        2164,
        10975,
        16306,
        11,
        51700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29538655281066895,
      "compression_ratio": 1.7644788026809692,
      "no_speech_prob": 0.16007961332798004
    },
    {
      "id": 127,
      "seek": 82972,
      "start": 3267.970026855469,
      "end": 3274.450007324219,
      "text": " dass ein gemeinsames Modell auf der Datenebene zu einer starken Kopplung und zu einer Schwierigkeit",
      "tokens": [
        50370,
        2658,
        1343,
        22971,
        1632,
        6583,
        898,
        2501,
        1163,
        9315,
        1450,
        41605,
        2164,
        6850,
        17417,
        268,
        49656,
        564,
        1063,
        674,
        2164,
        6850,
        17576,
        811,
        16626,
        50694
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3105819821357727,
      "compression_ratio": 1.4039409160614014,
      "no_speech_prob": 0.04882163554430008
    },
    {
      "id": 128,
      "seek": 82972,
      "start": 3274.450007324219,
      "end": 3278.970026855469,
      "text": " führt, das System vernünftig zu modularisieren, findet man halt auch nichts in dem Blogbeitrag.",
      "tokens": [
        50694,
        39671,
        11,
        1482,
        8910,
        35793,
        3412,
        34765,
        2164,
        31111,
        271,
        5695,
        11,
        27752,
        587,
        12479,
        2168,
        13004,
        294,
        1371,
        46693,
        9407,
        3731,
        13,
        50920
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3105819821357727,
      "compression_ratio": 1.4039409160614014,
      "no_speech_prob": 0.04882163554430008
    },
    {
      "id": 129,
      "seek": 82972,
      "start": 3278.970026855469,
      "end": 3294.5300244140626,
      "text": " Und das ist so ein bisschen die Meta-Ebene. So ein Papier zu schreiben und zu lesen ist",
      "tokens": [
        50920,
        2719,
        1482,
        1418,
        370,
        1343,
        10763,
        978,
        6377,
        64,
        12,
        36,
        41605,
        13,
        407,
        1343,
        15919,
        811,
        2164,
        48546,
        674,
        2164,
        1512,
        268,
        1418,
        51698
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3105819821357727,
      "compression_ratio": 1.4039409160614014,
      "no_speech_prob": 0.04882163554430008
    },
    {
      "id": 130,
      "seek": 85640,
      "start": 3294.65001953125,
      "end": 3300.13,
      "text": " eine Form von Kommunikation. Die haben gesagt, wir schreiben einen Blogbeitrag und wir sitzen",
      "tokens": [
        50370,
        3018,
        10126,
        2957,
        28832,
        1035,
        399,
        13,
        3229,
        3084,
        12260,
        11,
        1987,
        48546,
        4891,
        46693,
        9407,
        3731,
        674,
        1987,
        44998,
        50644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3371989130973816,
      "compression_ratio": 1.6521738767623901,
      "no_speech_prob": 0.15798531472682953
    },
    {
      "id": 131,
      "seek": 85640,
      "start": 3300.13,
      "end": 3305.65001953125,
      "text": " jetzt hier nicht und reden drüber, sondern ich habe den Blogbeitrag gelesen, glaube ihn",
      "tokens": [
        50644,
        4354,
        3296,
        1979,
        674,
        26447,
        1224,
        12670,
        11,
        11465,
        1893,
        6015,
        1441,
        46693,
        9407,
        3731,
        4087,
        17403,
        11,
        13756,
        14534,
        50920
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3371989130973816,
      "compression_ratio": 1.6521738767623901,
      "no_speech_prob": 0.15798531472682953
    },
    {
      "id": 132,
      "seek": 85640,
      "start": 3305.65001953125,
      "end": 3312.2499951171876,
      "text": " irgendwie verstanden zu haben. Und das ist eine indirekte Art von Kommunikation. Ich habe nie mit",
      "tokens": [
        50920,
        20759,
        1306,
        33946,
        2164,
        3084,
        13,
        2719,
        1482,
        1418,
        3018,
        1016,
        621,
        18844,
        5735,
        2957,
        28832,
        1035,
        399,
        13,
        3141,
        6015,
        2838,
        2194,
        51250
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3371989130973816,
      "compression_ratio": 1.6521738767623901,
      "no_speech_prob": 0.15798531472682953
    },
    {
      "id": 133,
      "seek": 85640,
      "start": 3312.2499951171876,
      "end": 3320.849970703125,
      "text": " diesen Menschen direkt gesprochen. Und das führt dazu, dass es jetzt so eine Menge an Fragen gibt,",
      "tokens": [
        51250,
        12862,
        8397,
        20315,
        42714,
        13,
        2719,
        1482,
        39671,
        13034,
        11,
        2658,
        785,
        4354,
        370,
        3018,
        40723,
        364,
        25588,
        6089,
        11,
        51680
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3371989130973816,
      "compression_ratio": 1.6521738767623901,
      "no_speech_prob": 0.15798531472682953
    },
    {
      "id": 134,
      "seek": 88272,
      "start": 3320.849970703125,
      "end": 3325.4899853515626,
      "text": " die man jetzt stellen müsste. Also was ist denn nun wirklich das Problem? Ist es eigentlich ein",
      "tokens": [
        50364,
        978,
        587,
        4354,
        24407,
        42962,
        13,
        2743,
        390,
        1418,
        10471,
        8905,
        9696,
        1482,
        11676,
        30,
        12810,
        785,
        10926,
        1343,
        50596
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2724294364452362,
      "compression_ratio": 1.5741935968399048,
      "no_speech_prob": 0.07253409177064896
    },
    {
      "id": 135,
      "seek": 88272,
      "start": 3325.4899853515626,
      "end": 3332.689997558594,
      "text": " Integrationsproblem? Dann wäre für mich die Frage, was ist mit der Autonomie der Teams? Wie stark ist",
      "tokens": [
        50596,
        23894,
        763,
        47419,
        30,
        7455,
        14558,
        2959,
        6031,
        978,
        13685,
        11,
        390,
        1418,
        2194,
        1163,
        6049,
        12481,
        414,
        1163,
        24702,
        30,
        9233,
        17417,
        1418,
        50956
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2724294364452362,
      "compression_ratio": 1.5741935968399048,
      "no_speech_prob": 0.07253409177064896
    },
    {
      "id": 136,
      "seek": 88272,
      "start": 3332.689997558594,
      "end": 3337.890009765625,
      "text": " die Modellierung tatsächlich unabhängig? Habt ihr da Schwierigkeiten? Habt ihr einen hohen",
      "tokens": [
        50956,
        978,
        6583,
        898,
        11651,
        20796,
        517,
        455,
        34591,
        328,
        30,
        14225,
        83,
        5553,
        1120,
        17576,
        811,
        37545,
        30,
        14225,
        83,
        5553,
        4891,
        1106,
        2932,
        51216
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2724294364452362,
      "compression_ratio": 1.5741935968399048,
      "no_speech_prob": 0.07253409177064896
    },
    {
      "id": 137,
      "seek": 88272,
      "start": 3337.890009765625,
      "end": 3343.0100048828126,
      "text": " Koordinationsaufwand? Lauft ihr an so ein Problem, dass ihr ein großes Datenmodell habt, was niemand",
      "tokens": [
        51216,
        10509,
        6241,
        763,
        9507,
        33114,
        30,
        441,
        28245,
        5553,
        364,
        370,
        1343,
        11676,
        11,
        2658,
        5553,
        1343,
        48875,
        31126,
        8014,
        898,
        23660,
        11,
        390,
        32390,
        51472
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2724294364452362,
      "compression_ratio": 1.5741935968399048,
      "no_speech_prob": 0.07253409177064896
    },
    {
      "id": 138,
      "seek": 88272,
      "start": 3343.0100048828126,
      "end": 3348.169978027344,
      "text": " mehr versteht und auseinandernehmen kann? Das wäre so etwas, wo man sich wahrscheinlich mal",
      "tokens": [
        51472,
        5417,
        22442,
        357,
        674,
        257,
        438,
        20553,
        14669,
        4028,
        30,
        2846,
        14558,
        370,
        9569,
        11,
        6020,
        587,
        3041,
        30957,
        2806,
        51730
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2724294364452362,
      "compression_ratio": 1.5741935968399048,
      "no_speech_prob": 0.07253409177064896
    },
    {
      "id": 139,
      "seek": 91004,
      "start": 3348.210017089844,
      "end": 3353.0900219726564,
      "text": " fünf, zehn Minuten oder vielleicht eine halbe Stunde zusammensetzen könnte und dann deutlich",
      "tokens": [
        50366,
        28723,
        11,
        33975,
        27593,
        4513,
        12547,
        3018,
        7523,
        650,
        42781,
        11548,
        5136,
        694,
        24797,
        17646,
        674,
        3594,
        24344,
        50610
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35706019401550293,
      "compression_ratio": 1.6082473993301392,
      "no_speech_prob": 0.08381325751543045
    },
    {
      "id": 140,
      "seek": 91004,
      "start": 3353.0900219726564,
      "end": 3360.970026855469,
      "text": " mehr wüsste. Ich finde das nochmal wichtig, weil es mir zu häufig passiert, dass Leute sagen,",
      "tokens": [
        50610,
        5417,
        261,
        16608,
        2941,
        13,
        3141,
        17841,
        1482,
        26509,
        13621,
        11,
        7689,
        785,
        3149,
        2164,
        47543,
        21671,
        11,
        2658,
        13495,
        8360,
        11,
        51004
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35706019401550293,
      "compression_ratio": 1.6082473993301392,
      "no_speech_prob": 0.08381325751543045
    },
    {
      "id": 141,
      "seek": 91004,
      "start": 3360.970026855469,
      "end": 3367.7299755859376,
      "text": " hey, neue Menschen sollen bei uns irgendwas machen und da sind Schwierigkeiten und deswegen",
      "tokens": [
        51004,
        4177,
        11,
        16842,
        8397,
        24713,
        4643,
        2693,
        47090,
        7069,
        674,
        1120,
        3290,
        17576,
        811,
        37545,
        674,
        26482,
        51342
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35706019401550293,
      "compression_ratio": 1.6082473993301392,
      "no_speech_prob": 0.08381325751543045
    },
    {
      "id": 142,
      "seek": 91004,
      "start": 3367.7299755859376,
      "end": 3372.2899731445314,
      "text": " brauchen wir mehr Dokumentation. Das hilft halt irgendwie nicht. Das sieht man hier relativ gut.",
      "tokens": [
        51342,
        19543,
        1987,
        5417,
        29768,
        2206,
        399,
        13,
        2846,
        42493,
        12479,
        20759,
        1979,
        13,
        2846,
        14289,
        587,
        3296,
        21960,
        5228,
        13,
        51570
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35706019401550293,
      "compression_ratio": 1.6082473993301392,
      "no_speech_prob": 0.08381325751543045
    },
    {
      "id": 143,
      "seek": 91004,
      "start": 3372.2899731445314,
      "end": 3376.5700024414064,
      "text": " Also man sieht irgendwie nicht, das ist gut geschrieben, das ist verständlich. Trotzdem",
      "tokens": [
        51570,
        2743,
        587,
        14289,
        20759,
        1979,
        11,
        1482,
        1418,
        5228,
        47397,
        11,
        1482,
        1418,
        1306,
        16913,
        1739,
        13,
        1765,
        23934,
        51784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35706019401550293,
      "compression_ratio": 1.6082473993301392,
      "no_speech_prob": 0.08381325751543045
    },
    {
      "id": 144,
      "seek": 93844,
      "start": 3376.60998046875,
      "end": 3382.410029296875,
      "text": " ist es so, dass da ein massiver Informationsverlust ist, weil wir eben nicht miteinander direkt",
      "tokens": [
        50366,
        1418,
        785,
        370,
        11,
        2658,
        1120,
        1343,
        2758,
        1837,
        34301,
        763,
        331,
        75,
        381,
        1418,
        11,
        7689,
        1987,
        11375,
        1979,
        43127,
        20315,
        50656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32592976093292236,
      "compression_ratio": 1.639175295829773,
      "no_speech_prob": 0.005137246567755938
    },
    {
      "id": 145,
      "seek": 93844,
      "start": 3382.410029296875,
      "end": 3390.4899853515626,
      "text": " gesprochen haben. Da wäre jetzt für mich auch die Frage, was Sie sagen würden zu diesen verschiedenen",
      "tokens": [
        50656,
        42714,
        3084,
        13,
        3933,
        14558,
        4354,
        2959,
        6031,
        2168,
        978,
        13685,
        11,
        390,
        3559,
        8360,
        27621,
        2164,
        12862,
        41043,
        51060
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32592976093292236,
      "compression_ratio": 1.639175295829773,
      "no_speech_prob": 0.005137246567755938
    },
    {
      "id": 146,
      "seek": 93844,
      "start": 3390.4899853515626,
      "end": 3397.4899853515626,
      "text": " kleinen Modellen, die wir ja eigentlich predigen. Ich bin mir nicht sicher, ob Sie sagen würden,",
      "tokens": [
        51060,
        26512,
        6583,
        8581,
        11,
        978,
        1987,
        2784,
        10926,
        3852,
        3213,
        13,
        3141,
        5171,
        3149,
        1979,
        18623,
        11,
        1111,
        3559,
        8360,
        27621,
        11,
        51410
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32592976093292236,
      "compression_ratio": 1.639175295829773,
      "no_speech_prob": 0.005137246567755938
    },
    {
      "id": 147,
      "seek": 93844,
      "start": 3397.4899853515626,
      "end": 3401.890009765625,
      "text": " das ist ein Fehlansatz. Das weiß ich nicht, weil Sie auf einer anderen Ebene sind bei dieser",
      "tokens": [
        51410,
        1482,
        1418,
        1343,
        3697,
        22950,
        599,
        10300,
        13,
        2846,
        13385,
        1893,
        1979,
        11,
        7689,
        3559,
        2501,
        6850,
        11122,
        20418,
        1450,
        3290,
        4643,
        9053,
        51630
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32592976093292236,
      "compression_ratio": 1.639175295829773,
      "no_speech_prob": 0.005137246567755938
    },
    {
      "id": 148,
      "seek": 93844,
      "start": 3401.890009765625,
      "end": 3405.65001953125,
      "text": " Datenanalyse in erster Linie. Mich würde interessieren, warum Ihr Datamash, was Sie",
      "tokens": [
        51630,
        31126,
        282,
        5222,
        405,
        294,
        1189,
        3120,
        9355,
        414,
        13,
        3392,
        11942,
        12478,
        5695,
        11,
        24331,
        14773,
        9315,
        335,
        1299,
        11,
        390,
        3559,
        51818
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32592976093292236,
      "compression_ratio": 1.639175295829773,
      "no_speech_prob": 0.005137246567755938
    },
    {
      "id": 149,
      "seek": 96752,
      "start": 3405.7700146484376,
      "end": 3411.169978027344,
      "text": " haben, nicht ausreichend ist. Das wäre da so der Punkt. Mich erinnert das auch ein bisschen zu",
      "tokens": [
        50370,
        3084,
        11,
        1979,
        3437,
        12594,
        521,
        1418,
        13,
        2846,
        14558,
        1120,
        370,
        1163,
        25487,
        13,
        3392,
        1189,
        7729,
        911,
        1482,
        2168,
        1343,
        10763,
        2164,
        50640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3190934658050537,
      "compression_ratio": 1.6318840980529785,
      "no_speech_prob": 0.1663181483745575
    },
    {
      "id": 150,
      "seek": 96752,
      "start": 3411.169978027344,
      "end": 3415.210017089844,
      "text": " diesem Paper, was ich vor einiger Zeit mal diskutiert habe. Ich packe den Link dazu auch",
      "tokens": [
        50640,
        10975,
        24990,
        11,
        390,
        1893,
        4245,
        1343,
        4810,
        9394,
        2806,
        36760,
        4859,
        6015,
        13,
        3141,
        15165,
        330,
        1441,
        8466,
        13034,
        2168,
        50842
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3190934658050537,
      "compression_ratio": 1.6318840980529785,
      "no_speech_prob": 0.1663181483745575
    },
    {
      "id": 151,
      "seek": 96752,
      "start": 3415.210017089844,
      "end": 3422.369990234375,
      "text": " nochmal in die Shownotes, wo in der öffentlichen Wahrnehmung stecken übrig geblieben ist. Amazon",
      "tokens": [
        50842,
        26509,
        294,
        978,
        1160,
        648,
        17251,
        11,
        6020,
        294,
        1163,
        34603,
        268,
        36357,
        716,
        8587,
        1063,
        2126,
        13029,
        32343,
        1519,
        5199,
        38243,
        1418,
        13,
        6795,
        51200
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3190934658050537,
      "compression_ratio": 1.6318840980529785,
      "no_speech_prob": 0.1663181483745575
    },
    {
      "id": 152,
      "seek": 96752,
      "start": 3422.369990234375,
      "end": 3426.2899731445314,
      "text": " macht jetzt Monolithen statt Microservices und das stand halt in dem Paper einfach nicht drin.",
      "tokens": [
        51200,
        10857,
        4354,
        4713,
        29131,
        268,
        25675,
        5818,
        2635,
        47480,
        674,
        1482,
        1463,
        12479,
        294,
        1371,
        24990,
        7281,
        1979,
        24534,
        13,
        51396
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3190934658050537,
      "compression_ratio": 1.6318840980529785,
      "no_speech_prob": 0.1663181483745575
    },
    {
      "id": 153,
      "seek": 96752,
      "start": 3426.2899731445314,
      "end": 3430.0499829101564,
      "text": " Ich glaube, das ist hier was Ähnliches. Es steht hier nicht drin, Bau einen Kontext und mehrere",
      "tokens": [
        51396,
        3141,
        13756,
        11,
        1482,
        1418,
        3296,
        390,
        13700,
        35646,
        279,
        13,
        2313,
        16361,
        3296,
        1979,
        24534,
        11,
        28772,
        4891,
        20629,
        3828,
        674,
        44677,
        51584
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3190934658050537,
      "compression_ratio": 1.6318840980529785,
      "no_speech_prob": 0.1663181483745575
    },
    {
      "id": 154,
      "seek": 96752,
      "start": 3430.0499829101564,
      "end": 3433.7299755859376,
      "text": " Modelle sind eine blöde Idee, sondern es steht irgendwie was anderes drin. Ich glaube,",
      "tokens": [
        51584,
        6583,
        4434,
        3290,
        3018,
        888,
        973,
        1479,
        32651,
        11,
        11465,
        785,
        16361,
        20759,
        390,
        31426,
        24534,
        13,
        3141,
        13756,
        11,
        51768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3190934658050537,
      "compression_ratio": 1.6318840980529785,
      "no_speech_prob": 0.1663181483745575
    },
    {
      "id": 155,
      "seek": 99560,
      "start": 3433.7299755859376,
      "end": 3440.450007324219,
      "text": " es steht was drin in der Datenanalyse. Lass uns nochmal durch die Fragen gehen.",
      "tokens": [
        50364,
        785,
        16361,
        390,
        24534,
        294,
        1163,
        31126,
        282,
        5222,
        405,
        13,
        441,
        640,
        2693,
        26509,
        7131,
        978,
        25588,
        13230,
        13,
        50700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5006148815155029,
      "compression_ratio": 1.4935622215270996,
      "no_speech_prob": 0.07465309649705887
    },
    {
      "id": 156,
      "seek": 99560,
      "start": 3440.450007324219,
      "end": 3445.4899853515626,
      "text": " Also Asmir Abdi hat gefragt, geht Netflix zu der Daten-Centric-Architecture? Nein,",
      "tokens": [
        50700,
        2743,
        1018,
        19834,
        2847,
        4504,
        2385,
        42638,
        11,
        7095,
        12778,
        2164,
        1163,
        31126,
        12,
        34,
        32939,
        12,
        10683,
        339,
        5739,
        540,
        30,
        18878,
        11,
        50952
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5006148815155029,
      "compression_ratio": 1.4935622215270996,
      "no_speech_prob": 0.07465309649705887
    },
    {
      "id": 157,
      "seek": 99560,
      "start": 3445.4899853515626,
      "end": 3449.5300244140626,
      "text": " glaube ich nicht. Ich glaube, die bauen einfach eine Daten-Integration da am Ende.",
      "tokens": [
        50952,
        13756,
        1893,
        1979,
        13,
        3141,
        13756,
        11,
        978,
        43787,
        7281,
        3018,
        31126,
        12,
        40,
        9358,
        861,
        399,
        1120,
        669,
        15152,
        13,
        51154
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5006148815155029,
      "compression_ratio": 1.4935622215270996,
      "no_speech_prob": 0.07465309649705887
    },
    {
      "id": 158,
      "seek": 99560,
      "start": 3449.5300244140626,
      "end": 3460.210017089844,
      "text": " Und man sieht es unten, softverbinden-architektur.tv findest du die Episode dann auch nochmal komplett",
      "tokens": [
        51154,
        2719,
        587,
        14289,
        785,
        25693,
        11,
        2787,
        25809,
        10291,
        12,
        1178,
        642,
        2320,
        374,
        13,
        24641,
        915,
        377,
        1581,
        978,
        19882,
        3594,
        2168,
        26509,
        32261,
        51688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5006148815155029,
      "compression_ratio": 1.4935622215270996,
      "no_speech_prob": 0.07465309649705887
    },
    {
      "id": 159,
      "seek": 102208,
      "start": 3460.2499951171876,
      "end": 3465.60998046875,
      "text": " und kannst sie nachhören oder dir angucken. Karl Schmolka hat geschrieben, mögliche Gründe. In der",
      "tokens": [
        50366,
        674,
        20853,
        2804,
        5168,
        71,
        26377,
        4513,
        4746,
        2562,
        49720,
        13,
        20405,
        2065,
        76,
        401,
        2330,
        2385,
        47397,
        11,
        16294,
        68,
        2606,
        25596,
        13,
        682,
        1163,
        50634
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3976377844810486,
      "compression_ratio": 1.5032258033752441,
      "no_speech_prob": 0.09799567610025406
    },
    {
      "id": 160,
      "seek": 102208,
      "start": 3465.60998046875,
      "end": 3470.7700146484376,
      "text": " Vergangenheit haben sie viele autonome Teams dem Part, wenn dann immer nachrängig behandelt.",
      "tokens": [
        50634,
        26610,
        10784,
        8480,
        3084,
        2804,
        9693,
        1476,
        266,
        423,
        24702,
        1371,
        4100,
        11,
        4797,
        3594,
        5578,
        5168,
        81,
        9935,
        328,
        43122,
        2018,
        13,
        50892
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3976377844810486,
      "compression_ratio": 1.5032258033752441,
      "no_speech_prob": 0.09799567610025406
    },
    {
      "id": 161,
      "seek": 102208,
      "start": 3470.7700146484376,
      "end": 3478.4899853515626,
      "text": " Darüber steht dann nichts drin und das ist halt tatsächlich komplette Mutmaßung,",
      "tokens": [
        50892,
        7803,
        12670,
        16361,
        3594,
        13004,
        24534,
        674,
        1482,
        1418,
        12479,
        256,
        1720,
        10168,
        2081,
        339,
        24526,
        3007,
        18517,
        1696,
        2536,
        1063,
        11,
        51278
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3976377844810486,
      "compression_ratio": 1.5032258033752441,
      "no_speech_prob": 0.09799567610025406
    },
    {
      "id": 162,
      "seek": 102208,
      "start": 3478.4899853515626,
      "end": 3484.60998046875,
      "text": " dass irgendwie eine zu große Autonomie dort zu einem Problem geführt hätte. Und selbst wenn,",
      "tokens": [
        51278,
        2658,
        20759,
        3018,
        2164,
        19691,
        6049,
        12481,
        414,
        15775,
        2164,
        6827,
        11676,
        11271,
        19647,
        20041,
        13,
        2719,
        13053,
        4797,
        11,
        51584
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3976377844810486,
      "compression_ratio": 1.5032258033752441,
      "no_speech_prob": 0.09799567610025406
    },
    {
      "id": 163,
      "seek": 102208,
      "start": 3484.60998046875,
      "end": 3489.0899609375,
      "text": " dann kann ich halt Makroarchitektur-Regeln definieren, die halt sagen nicht, also Bau halt",
      "tokens": [
        51584,
        3594,
        4028,
        1893,
        12479,
        16576,
        340,
        1178,
        642,
        2320,
        374,
        12,
        40888,
        9878,
        1561,
        5695,
        11,
        978,
        12479,
        8360,
        1979,
        11,
        611,
        28772,
        12479,
        51808
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3976377844810486,
      "compression_ratio": 1.5032258033752441,
      "no_speech_prob": 0.09799567610025406
    },
    {
      "id": 164,
      "seek": 105096,
      "start": 3489.2499951171876,
      "end": 3496.0899609375,
      "text": " ein Datenprodukt, bietet das an und macht das vernünftig. Was steht hier noch? Karl Schmolka",
      "tokens": [
        50372,
        1343,
        31126,
        14314,
        2320,
        11,
        272,
        45531,
        1482,
        364,
        674,
        10857,
        1482,
        35793,
        3412,
        34765,
        13,
        3027,
        16361,
        3296,
        3514,
        30,
        20405,
        2065,
        76,
        401,
        2330,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2938690185546875,
      "compression_ratio": 1.5508196353912354,
      "no_speech_prob": 0.002396556781604886
    },
    {
      "id": 165,
      "seek": 105096,
      "start": 3496.0899609375,
      "end": 3501.369990234375,
      "text": " schrieb, der Aufruf, doch bitte Daten zu bedienen und zu befüllen, wurde nicht ausreichend und",
      "tokens": [
        50714,
        956,
        31775,
        11,
        1163,
        9462,
        894,
        69,
        11,
        9243,
        23231,
        31126,
        2164,
        2901,
        22461,
        674,
        2164,
        21312,
        774,
        19191,
        11,
        11191,
        1979,
        3437,
        12594,
        521,
        674,
        50978
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2938690185546875,
      "compression_ratio": 1.5508196353912354,
      "no_speech_prob": 0.002396556781604886
    },
    {
      "id": 166,
      "seek": 105096,
      "start": 3501.369990234375,
      "end": 3505.13,
      "text": " zufriedenstellend bedient. Also zwingt man jetzt die Entwicklungsteams. Also wie gesagt,",
      "tokens": [
        50978,
        2164,
        22773,
        268,
        17816,
        521,
        2901,
        1196,
        13,
        2743,
        710,
        7904,
        83,
        587,
        4354,
        978,
        39654,
        2941,
        4070,
        13,
        2743,
        3355,
        12260,
        11,
        51166
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2938690185546875,
      "compression_ratio": 1.5508196353912354,
      "no_speech_prob": 0.002396556781604886
    },
    {
      "id": 167,
      "seek": 105096,
      "start": 3505.13,
      "end": 3511.1700390625,
      "text": " es ist eine komplette Mutmaßung. Und selbst wenn dem so wäre, fände ich, ist das ein Antipattern,",
      "tokens": [
        51166,
        785,
        1418,
        3018,
        24526,
        3007,
        18517,
        1696,
        2536,
        1063,
        13,
        2719,
        13053,
        4797,
        1371,
        370,
        14558,
        11,
        283,
        26973,
        1893,
        11,
        1418,
        1482,
        1343,
        5130,
        647,
        1161,
        77,
        11,
        51468
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2938690185546875,
      "compression_ratio": 1.5508196353912354,
      "no_speech_prob": 0.002396556781604886
    },
    {
      "id": 168,
      "seek": 105096,
      "start": 3511.1700390625,
      "end": 3515.56994140625,
      "text": " weil das ist ein soziales Problem. Die Teams machen nicht das, was sie eigentlich tun sollten",
      "tokens": [
        51468,
        7689,
        1482,
        1418,
        1343,
        31541,
        279,
        11676,
        13,
        3229,
        24702,
        7069,
        1979,
        1482,
        11,
        390,
        2804,
        10926,
        4267,
        29096,
        51688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2938690185546875,
      "compression_ratio": 1.5508196353912354,
      "no_speech_prob": 0.002396556781604886
    },
    {
      "id": 169,
      "seek": 107744,
      "start": 3515.56994140625,
      "end": 3519.65001953125,
      "text": " und was sinnvoll wäre. Und ich baue dann halt eine technische Lösung dafür, halte ich nicht",
      "tokens": [
        50364,
        674,
        390,
        47066,
        20654,
        14558,
        13,
        2719,
        1893,
        4773,
        622,
        3594,
        12479,
        3018,
        1537,
        7864,
        46934,
        13747,
        11,
        7523,
        975,
        1893,
        1979,
        50568
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3448294699192047,
      "compression_ratio": 1.4558823108673096,
      "no_speech_prob": 0.05336795002222061
    },
    {
      "id": 170,
      "seek": 107744,
      "start": 3519.65001953125,
      "end": 3530.369990234375,
      "text": " für eine gute Idee. Kann man machen, schrieb halt dazu. Ich warte noch eine Sekunde, ob noch weitere",
      "tokens": [
        50568,
        2959,
        3018,
        21476,
        32651,
        13,
        29074,
        587,
        7069,
        11,
        956,
        31775,
        12479,
        13034,
        13,
        3141,
        261,
        11026,
        3514,
        3018,
        24285,
        13271,
        11,
        1111,
        3514,
        30020,
        51104
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3448294699192047,
      "compression_ratio": 1.4558823108673096,
      "no_speech_prob": 0.05336795002222061
    },
    {
      "id": 171,
      "seek": 107744,
      "start": 3530.369990234375,
      "end": 3539.8100537109376,
      "text": " Teams sind. Sonst wäre das sozusagen meine kurze Zusammenfassung dazu. Und vielen Dank nochmal für",
      "tokens": [
        51104,
        24702,
        3290,
        13,
        318,
        4068,
        14558,
        1482,
        33762,
        10946,
        10072,
        1381,
        29442,
        69,
        40828,
        13034,
        13,
        2719,
        19885,
        14148,
        26509,
        2959,
        51576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3448294699192047,
      "compression_ratio": 1.4558823108673096,
      "no_speech_prob": 0.05336795002222061
    },
    {
      "id": 172,
      "seek": 110168,
      "start": 3539.8100537109376,
      "end": 3547.369990234375,
      "text": " den Hinweis auf das Paper. Nächste Woche wird es aller Voraussicht nach keine Episode geben.",
      "tokens": [
        50364,
        1441,
        29571,
        35033,
        2501,
        1482,
        24990,
        13,
        426,
        10168,
        2941,
        24511,
        4578,
        785,
        8722,
        691,
        3252,
        2023,
        1405,
        5168,
        9252,
        19882,
        17191,
        13,
        50742
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2960590422153473,
      "compression_ratio": 1.3543689250946045,
      "no_speech_prob": 0.2871229946613312
    },
    {
      "id": 173,
      "seek": 110168,
      "start": 3547.369990234375,
      "end": 3554.0100048828126,
      "text": " Das hängt damit zusammen, dass ich so ein bisschen Zeitschwierigkeiten da gerade habe.",
      "tokens": [
        50742,
        2846,
        276,
        29670,
        9479,
        14311,
        11,
        2658,
        1893,
        370,
        1343,
        10763,
        4853,
        1208,
        34655,
        811,
        37545,
        1120,
        12117,
        6015,
        13,
        51074
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2960590422153473,
      "compression_ratio": 1.3543689250946045,
      "no_speech_prob": 0.2871229946613312
    },
    {
      "id": 174,
      "seek": 110168,
      "start": 3554.0100048828126,
      "end": 3565.69005859375,
      "text": " Die übernächste Woche ist was geplant. Und zwar am 5.9. kommt dann das Thema Webperformance mit",
      "tokens": [
        51074,
        3229,
        4502,
        77,
        10168,
        2941,
        24511,
        1418,
        390,
        1519,
        13067,
        13,
        2719,
        19054,
        669,
        1025,
        13,
        24,
        13,
        10047,
        3594,
        1482,
        16306,
        9573,
        50242,
        2194,
        51658
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2960590422153473,
      "compression_ratio": 1.3543689250946045,
      "no_speech_prob": 0.2871229946613312
    },
    {
      "id": 175,
      "seek": 112756,
      "start": 3565.7700146484376,
      "end": 3574.329951171875,
      "text": " Lukas Domen und Lisa. Das wird also auf jeden Fall die nächste Episode sein. Vielleicht gibt es",
      "tokens": [
        50368,
        34992,
        296,
        413,
        4726,
        674,
        12252,
        13,
        2846,
        4578,
        611,
        2501,
        12906,
        7465,
        978,
        30661,
        19882,
        6195,
        13,
        29838,
        6089,
        785,
        50796
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3634601831436157,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.018529126420617104
    },
    {
      "id": 176,
      "seek": 112756,
      "start": 3574.329951171875,
      "end": 3578.56994140625,
      "text": " vorher nochmal was. Aber da könnt ihr dann auf die Webseite gucken. Vielen Dank für die vielen",
      "tokens": [
        50796,
        29195,
        26509,
        390,
        13,
        5992,
        1120,
        22541,
        5553,
        3594,
        2501,
        978,
        9573,
        405,
        642,
        33135,
        13,
        22502,
        14148,
        2959,
        978,
        19885,
        51008
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3634601831436157,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.018529126420617104
    },
    {
      "id": 177,
      "seek": 112756,
      "start": 3578.56994140625,
      "end": 3583.65001953125,
      "text": " Fragen. Vielen Dank für die Inspiration, für die Diskussion. Und ich wünsche dann schon mal",
      "tokens": [
        51008,
        25588,
        13,
        22502,
        14148,
        2959,
        978,
        32671,
        7611,
        11,
        2959,
        978,
        45963,
        313,
        13,
        2719,
        1893,
        30841,
        12287,
        3594,
        4981,
        2806,
        51262
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3634601831436157,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.018529126420617104
    },
    {
      "id": 178,
      "seek": 112756,
      "start": 3583.65001953125,
      "end": 3585.65001953125,
      "text": " ein schönes Wochenende und bis dahin.",
      "tokens": [
        51262,
        1343,
        13527,
        279,
        23126,
        5445,
        674,
        7393,
        16800,
        259,
        13,
        51362
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3634601831436157,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.018529126420617104
    }
  ],
  "language": "german"
}