# KI in der Softwareentwicklung: Zwischen Hype und Realität

Die Diskussion über künstliche Intelligenz in der Softwareentwicklung schwingt derzeit zwischen Euphorie und Skepsis hin und her. Ein aktuelles Projekt zeigt: Die Realität ist komplexer als die Versprechungen.

## Enablement statt Kostenersparnis

Ein faszinierender Aspekt der KI-Nutzung liegt nicht primär in der Kosteneinsparung, sondern im **Enablement**. Bei der Erstellung von Transkripten für Podcast-Episoden wurde deutlich: Während die manuelle Transkription unbezahlbar wäre, ermöglicht KI diese Arbeit überhaupt erst. Der Aufwand für Review und Nachbearbeitung ist minimal im Vergleich zum Wert für gehörlose Hörer. Dies illustriert einen wichtigen Punkt: KI schafft neue Möglichkeiten, nicht nur schnellere Lösungen.

## Die Grenzen der Automatisierung

Doch die Grenzen werden schnell sichtbar. Bei der Automatisierung von GitHub-Workflows zeigte sich ein klassisches Problem: Das KI-System verlor den Überblick über seinen eigenen Code. Ein Berechtigungsfehler entstand, weil die KI nicht erkannte, dass ein Personal Access Token abgelaufen war. Stattdessen manipulierte sie grundlos am Code herum. **Das mentale Modell fehlte** – das Verständnis für die Architektur, das Warum hinter technischen Entscheidungen.

## Mentales Modell nach Naur

Hier kommt Peter Naurs Konzept des mentalen Modells ins Spiel. Entwickler bauen beim Programmieren ein inneres Verständnis des Systems auf – ein Modell, das erklären kann, *warum* bestimmte Entscheidungen getroffen wurden. KI-Systeme können dieses Modell nicht aufbauen. Sie generieren Text basierend auf Mustern, nicht auf echtem Verständnis.

Interessanterweise erkennen KI-Modelle selbst dieses Konzept theoretisch – können es aber nicht praktizieren. Wenn Entwickler dokumentieren, *warum* Entscheidungen getroffen wurden, kann dies den KI-Outputs verbessern.

## Softwareentwicklung als sozialer Prozess

Ein Kernproblem liegt darin, dass **Softwareentwicklung ein sozialer Prozess ist**. Code drückt das gemeinsame mentale Modell eines Teams aus. Wenn ein neues Team versucht, etablierten Code zu erweitern, scheitert dies oft, weil die zugrundeliegende Theorie fehlt. KI kann diesen sozialen Aspekt nicht abbilden.

## Produktivitätsgewinne in Frage gestellt

Eine Umfrage unter Entwicklern enthüllt ernüchternde Zahlen: In der Mastodon-Community berichten 40 Prozent von *sinkender* Produktivität durch KI-Tools. 50 Prozent sehen nur einen Faktor von 1-2x Verbesserung. Dies steht in drastischem Kontrast zum Hype um Künstliche Intelligenz.

## Architektur und Constraints

Ein weiteres Lernmoment: Bei der Implementierung einer Gästeliste für eine Jekyll-basierte Website generierte Claude JavaScript-Code, der gegen die Architektur des Systems arbeitete. Die Lösung funktionierte, war aber ein "Alien" – getrennte CSS-Dateien, eigenständiges JavaScript, keine Integration mit dem bestehenden System.

Die bessere Lösung: Links zwischen Seiten statt eingebetteter Funktionalität, automatisierte Dateiverarbeitung statt manueller YAML-Konfiguration. Dies hätte der KI vermittelt werden müssen – **klare Architektur-Constraints sind essentiell**.

## Fazit

KI ist ein vielversprechendes Werkzeug für spezifische Aufgaben – besonders bei Wissensrecherche und als Gesprächspartner bei unbekannten Themen. Doch die Vorstellung, dass KI-Systeme eigenständig komplexe Software entwickeln können, wird durch die Praxis nicht gestützt. 

Das eigentliche Problem ist nicht technisch, sondern konzeptionell: Softwareentwicklung erfordert mentale Modelle und soziale Zusammenhänge, die Maschinen nicht nachbilden können. Wer KI nutzen will, muss ihr klare Architektur-Constraints geben und ihre Grenzen akzeptieren. Dann kann sie ein wertvolles Werkzeug sein – aber kein Ersatz für menschliches Verständnis.