# Generative KI in der Software-Architektur: Chancen und Grenzen am Beispiel eines ASCII-Doc Linters

Die Entwicklung von Software mit Hilfe von generativer KI gewinnt zunehmend an Bedeutung. In diesem Blog-Post betrachten wir ein konkretes Experiment: Die Entwicklung eines ASCII-Doc Linters vollständig durch ein Large Language Model (LLM). Dabei beleuchten wir sowohl die technischen Möglichkeiten als auch die damit verbundenen Herausforderungen für die Software-Architektur.

## Das Experiment: Ein KI-generierter Linter

Der Ausgangspunkt war ein reales Problem: Für ASCII-Doc, ein System zur Erstellung technischer Dokumentation, fehlte bislang ein Linter zur Überprüfung von Stilrichtlinien. Mit Hilfe eines selbst entwickelten Chatbot-Frontends mit "Agentic Workflow" wurde das LLM beauftragt, einen solchen Linter zu entwickeln.

Der Agentic Workflow ermöglichte es dem System, eigenständig:
- Code zu schreiben und auszuführen
- Auf Compiler-Fehler zu reagieren und diese zu beheben  
- Plant-UML Diagramme zu generieren
- Tests zu implementieren und durchzuführen

Das System entwickelte nicht nur den Code, sondern erstellte auch:
- Eine komplette Architekturdokumentation nach arc42
- Einen Architecture Communication Canvas
- Plant-UML Diagramme zur Visualisierung

## Stärken der KI-gestützten Entwicklung

Das Experiment zeigte einige bemerkenswerte Fähigkeiten des Systems:

- **Testgetriebene Entwicklung**: Das LLM schrieb zunächst Tests und implementierte dann den Code iterativ, bis die Tests erfolgreich waren.

- **Selbstkorrektur**: Bei Fehlern konnte das System eigenständig Korrekturen vornehmen und neue Lösungsansätze entwickeln.

- **Architektur-Dokumentation**: Das System war in der Lage, seine eigenen Architekturentscheidungen zu dokumentieren und zu begründen.

- **Regelgenerierung**: Basierend auf seinem "Weltwissen" über andere Linter entwickelte das System sinnvolle Prüfregeln.

## Kritische Betrachtung und Grenzen

Trotz der beeindruckenden Ergebnisse gibt es wichtige Einschränkungen:

1. **Qualitätsanforderungen**: Die vom System definierten Qualitätsszenarien erscheinen teilweise willkürlich und sind nicht ausreichend begründet. Beispielsweise wurden Performance-Anforderungen ohne erkennbare Grundlage festgelegt.

2. **Verifikation**: Es bleibt unklar, ob die implementierten Features tatsächlich die gewünschte Funktionalität erfüllen oder nur die Tests erfolgreich durchlaufen.

3. **Kontrollverlust**: Die Gefahr besteht, dass man dem System zu sehr vertraut und wichtige Überprüfungen vernachlässigt.

4. **Schein-Kompetenz**: KI-Systeme sind darauf optimiert, kompetent zu erscheinen, was zu einer Überschätzung ihrer tatsächlichen Fähigkeiten führen kann.

## Implikationen für die Zukunft

Das Experiment wirft interessante Fragen für die Zukunft der Software-Entwicklung auf:

- **Neue Abstraktionsebene**: Ähnlich wie der Übergang von Assembler zu Hochsprachen könnte KI eine neue Abstraktionsebene in der Software-Entwicklung einführen.

- **Anpassung der Entwicklungspraktiken**: Entwickler beginnen bereits, ihren Code mit zusätzlichen Metainformationen für KI-Systeme anzureichern.

- **Review-Prozesse**: Die Rolle und Gestaltung von Code-Reviews muss neu überdacht werden, wenn KI-Systeme komplexen Code generieren.

## Fazit und Empfehlungen

Aktuell empfiehlt sich der Einsatz von KI-Systemen primär als unterstützendes Werkzeug, etwa in Form von Code-Completion wie GitHub Copilot. Experimente wie der ASCII-Doc Linter zeigen das Potenzial für die Zukunft, verdeutlichen aber auch die Notwendigkeit:

- kritischer Überprüfung der generierten Ergebnisse
- bewussten Umgangs mit den Grenzen der Technologie
- Entwicklung neuer Methoden zur Qualitätssicherung

Die Herausforderung wird sein, die Vorteile der KI-gestützten Entwicklung zu nutzen, ohne dabei die Kontrolle und das Verständnis über die entwickelte Software zu verlieren.