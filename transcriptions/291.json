{
  "text": "So, welcome to another episode of Software-Architecture im Stream. Unfortunately, Lisa couldn't make it, so we replaced her with myself and Alf, because it takes two of us to replace her. We are at Software-Architecture Gathering, and first of all, a big thank you to the organizers of Software-Architecture Gathering for the support. So this has to be the most professional episode we ever did. And our guest today is Jackie, and you have already been a guest at our stream several times, I believe. So, can you do a short introduction of yourself? I can. So, I'm Jackie Reed. I've written the book Communication Patterns with O'Reilly, and last time I was on Software-Architecture im Stream, we were talking about that book and about patterns. And since I've written that book, I've been looking at how we can use diagrams as code with AI, and even getting into a bit of spec-driven development at the moment as well. So, still looking at communication, but with different things now. Yeah, and I've also joined me. So, do you want to say a few words about yourself? No. No? Okay. So, you're here because you're one of the... Let's use a time for our guest. Yeah. So, you're one of the experts on diagrams, so that is why I made you join us. So, that is also the workshop that you gave yesterday about diagrams as code with AI, and you're available to also do that workshop elsewhere also for customers on site or virtually. So, how does AI fit into diagrams as code? Where's the benefit? I think a lot of the time at the moment, people are trying to find the problem to fix with AI, but it can actually be useful for our diagrams. But we still need to have that skilled human actually driving this, because anyone can ask an LLM to create a diagram using things like PlantUML or Mermaid or Structurizer for C4 diagrams. But you need to understand what's coming out of it, and you need to understand what you're asking for as well, be that, can you update this diagram, create it, or help me fix it? You need to know how to ask the question, because if you ask things at too high level, very often it will just hallucinate and make things up. And I've got a couple of good examples of that when I teach the workshop. So, in the past, I tried to ask the LLM to create a diagram and it used Delhi or another diffusion generator and the results were ugly. So, you just mentioned PlantUML and Mermaid and Structurizer. Can you go a little bit deeper into detail? What's the trick? Yes. So, when we're talking about diagrams as code, we're talking about creating diagrams using text. And there's lots of domain-specific languages. So, PlantUML is one of the most more popular ones. And it's, as you can probably guess, it was originally made for UML diagrams. So, it supports lots of UML diagrams, but it does support some various other ones as well. And it's got some downsides. Part of what I teach in the course is I give all three of these. So, I give a grounding in PlantUML, Mermaid and Structurizer, because they're all useful in different ways. And so, you can't just say, oh, we're just going to use Mermaid in our organisation. That's all we're ever going to need, because it doesn't cover everything you're going to need. So, in some contexts, you will choose one, and in some contexts, another. So, we look at all the pros and cons. So, PlantUML is built on Java, which makes it a little bit more difficult to then render the diagram. So, that's why things like GitHub don't really support that, because Mermaid's built on JavaScript. It's then a lot easier for that to be rendered in various places on the internet. And so, we look at PlantUML, Java, Structurizer, and Structurizer is just like C4 diagrams. And so, you might think, oh, wait, but I can do C4 diagrams in PlantUML and in Mermaid. So, why should we bother with Structurizer? But Structurizer is a bit different in that you've got a model behind it, and you create lots of different views of that. And so, it's much easier to maintain and manage that data. If you add a new service in or change the name of something, it will update in all of your views that you've created from that. And you can actually export it to things like PlantUML. That's a very good point, because in the past, I always said an architect should model and not draw diagrams. And you say the big difference, a huge difference between PlantUML and Mermaid versus Structurizer is that with PlantUML and Mermaid, I draw diagrams, but don't have a model in the background. Yes, but they are, because they are text, they're much easier to maintain than a drawn diagram if you're using, say, Draw.io or Visio or anything else. To maintain those diagrams, you need that specific software. If you make a change, you probably have to fiddle around and move things around in there. Whereas with the diagrams as code, you can just change a word or add something in, and it will automatically kind of move things around for you. And you can even, you can keep your diagrams with your code so that you have them in the same place. But also, you can actually diff your diagrams and see the differences, because they are text. Whereas, I mean, something like Draw.io does produce a sort of XML style sort of file, but you can't diff that, because it changes in very odd ways. You can't see what the difference is. So, I mean, it sounds to me as if we are basically programming diagrams in some language, and we use LLMs to support us. So, is that sort of the idea of your workshop and of how you're using AI there? Yes. So, we need those skills and understanding, but then we can use the LLMs to help us with that. So, maybe we've got something in PlantUML that we want in Mermaid. You can say, give me this PlantUML diagram as Mermaid. And one of the things that I think might be particularly useful if you, say, wanted to create a full sort of workspace in Structurizr, and you've got 100 or even 20 PlantUML or Mermaid C4 diagrams, you could say, here are all my diagrams, create a workspace from them, or better still, manage your context and give it sort of the main ones first and then add extra ones in. It does vary as to, you've got to experiment with the different models as to which will actually know enough about things like Structurizr. But you said, I mean, obviously LLMs have hallucinations or tend to create hallucinations. So, is it really useful or what's your experience? So, how useful is it to have an LLM do these kinds of conversion work? Because, I mean, if there are too many hallucinations, you're better off doing it yourself, maybe. Yeah, it varies depending on what you ask it to do. So, if you, one of the examples I use is I've got an activity diagram and there are, the sequence means that there are a couple of items that are on the left-hand side. And if you want to move them to the right-hand side, it's a little bit of work to change things round and reorder things. If you ask the LLM to move them from the left to the right, it will go and make up some random syntax. I've seen it do this twice where it said, oh, you can use this little arrow and it will shift stuff over. And you look at the diagram it produces and it's just got these little funny arrows in front of your text. But if you say to reorder the elements so that these two items will appear on the right, it can do it. So, you have to have that knowledge of what you want it to do and be very specific about it. Okay. And you talked about how you are educating people with the skills they need to use these technologies. So, I think I sort of took a note that the people need to be aware of hallucinations. That's one skill. Is that true? Or what kind of skills are you trying to teach the people in that workshop? So, I'm trying to give them a few different skills. The one is to understand the pros and cons of the different diagrams as code. So, I chose PlantUML, Mermaid and Structurizer because they're some of the most popular ones. There's a few more out there. There's one called D2, which is quite young. So, a lot of people won't have used that one yet. So, it's worth looking at other ones as well. But these ones being the most popular, a lot of companies are already using probably one of these. And so, you can go back to your company and assess, is this the right thing to do? Could we add something in that would help us with this as well? And so, we've got that, okay, what's the best tool to use in my particular situation? When people say, oh, but we only use Mermaid here. You can't use PlantUML. You can say, you can actually back up your argument and say, we need to use it because I can't use Mermaid for this. Right, okay. Like if you're doing C4 diagrams, you can use PlantUML. That's quite good. Mermaid really doesn't work very well for C4 diagrams at the moment. So, you may be thinking, okay, if we're not going to use Structurizer, we should probably use PlantUML for that. Or they're all open source, so we can all go and fix it. So, you already mentioned that different libraries support different diagram types. So, this could be one criterion to select a library. But you also mentioned that a Mermaid is supported by web-based frontends. I guess it's just a frontend library and will be rendered on the client side. So, do you have some more criteria to choose the right library? What would be your first approach to select? Yeah, there's quite a few different things to look at. So, as you said, what type of diagram do I need? And sometimes you say, I definitely need a sequence diagram for this and there's nothing else that I'm going to look at. But maybe you think, oh, wait a minute, maybe I could use a flowchart. So, you can look at the different types that are supported. Maybe you need something a bit more complex. So, you need to look at an activity diagram, which is something that PlantUML supports. So, that's like a flowchart plus plus. It's got extra things that you can have. You can create forks so that you've got different things that are happening and they don't have to happen in a certain sequence, but they all have to happen before you can then move on. So, if you need things like that, then you know I need this specific diagram. The other thing to think about is what's your organization using now? Because if more than one of them support it, then it's probably better to go with what people know and what will fit in. If you're using Markdown or something that supports mermaid diagrams, if your knowledge management supports rendering of mermaid diagrams, then that's probably something to look at. So, there's lots of different things and I go into more detail in some of the pros and cons. You can even look at the â€“ they're all open source, but they're all different licenses. So, maybe your company says we can't use anything with this license. So, then that's ruled out, isn't it? There's an awful lot to look at. So, any more skills that come to mind that you want to teach people or that are important to use diagrams as code with AI? So, in my book Communication Patterns, I teach a lot of different patterns and anti-patterns for getting diagrams, the whole part ones about diagrams. So, getting these diagrams to be understood by people. And actually, diagrams as code can help with a lot of that. So, it will automatically render things in a certain way and it allows you to put in things like a title. It has ways of putting in all the labels and things, but it doesn't force you to. So, you still kind of need to know like, yes, I should be definitely using labels. Yes, I should be using a title. The one big thing that especially mermaid falls down on is having a legend or a key. And you can tell that I'm big on legends. I've got a t-shirt for it. And the fact that mermaid just doesn't have this feature at all is quite ridiculous in my mind, really. Plant UML does have a legend. It's not easy to use to define what's within that legend. Structurizer does automatically create a legend for you. So, that's really good. But yeah, I think we really need to sort out the lack of legend in mermaid. So, if anyone wants to contribute to the open source and sort that out, that'd be great. Sorry, just as an addition, it also says asynchronous on your t-shirt and datastore. So, that's the legend. And, you know, it's about play, obviously, just for the people who are listening to the podcast. And I understand that you even have more ideas about t-shirts like that. So, can you get it on Spreadshirt or somewhere? No, at the moment. But if people want me to put it on there. OK, sorry, but I was interrupting you. So, you said that Structurizer always creates a legend. But I think it has an easy position because it's always the same color code. And I think there are only two shapes. And so it's quite a few shapes, actually. Really? You can define lots of different shapes. So, you've got the standard person and rectangle for like a service or a container. Once you get down to the components, it has a different shape for that. You can also use. So, there's the datastore shape. There's a pipe shape if you've got a queue and things like that. And there's actually quite a few extra ones which you can use in there. But I think the thing that the reason it can just auto generate is because it has that model. So, it knows what's in this diagram and it will give you doesn't just give you the full legend. It will give you the very specific to that diagram. So, it's only the stuff that's in that diagram. It also knows how you've styled it. So, the sort of very traditional C4 is the different blue colors. The actual one of the things that I talk about in my book and in some of my talks is considering people who have say color blindness and the actual sort of traditional grays and blues color. I think one of the grays and one of the blues are a bit too close to each other. So, but recently, Simon Brown has been saying to people, look, you do not have to use that color scheme, use whatever you want. So, if you go to the online Structurizer DSL, where you can, it's like a playground, which is what I use in the course. It will randomly choose different themes now. So, you might get orange or you might get pink or things like that. But you can define your own styles in there in a sort of similar to CSS. And so, it will just go look at the model, look at the how you've styled it, and just generate it for you. So, it's that whole model thing. It's leveraging that. We did an episode on Structurizer and the C4 model with Simon Brown, who's the original inventor of that. So, I will include a link in the description to that one, or you can look it up on the webpage. Maybe we should, so you did talk about sequence diagrams and activity diagrams and so on. And I think people probably have a rough understanding about that, that there is some flow. And that's basically what also the name suggests, right? I mean, sequence diagram actually says what it is. I was wondering whether you want to say a few words about C4, because, I mean, C4 doesn't really say what it's about, right? Yeah. So, C4 is about expressing the structure of your architecture in your system. And so, originally, it started with the context being the highest level. There is now a landscape level, because the context diagram is, this is our system that we're interested in, and this is how it interacts with things. Whereas the landscape level is more, these are all our systems within our organization, and how they interact with each other is a bit at a different level. So, that's out of the C4. So, you've got context, then you go down to container, which is kind of individually deployable units. And so, what you're doing there is you're taking that system that you have in your context, and you are kind of zooming in on it and seeing what's within that system, but still how those pieces interact with things outside of that. Then you carry on down to the component. If you need to, I always say to people, you probably, most of the time, only really need those top two. But you can go down to the component level. If you go down to the code, that's when you're actually going to be using UML diagrams. And I would say to people, look, the lower down you go, the more stuff will change. And so, if you don't need to go into that detail, don't, because then you don't have to maintain it. If you really need to document your code, maybe it's an API interface, then if you're using things like OpenAPI, that will then automatically do that for you. So, you don't want to have to manually sort out stuff in detail. And that goes for documentation, too, not just diagrams. Go into the amount of detail that you need. If someone then asks questions, then you can go into that detail, but you will have to maintain everything you create. Yeah, I think that's such an important point, because I guess some people think that the more documentation, the better. But as you pointed out, documentation is also a burden. So, I think that's very important. What I found interesting when I was looking at the slides, I have to admit that I didn't take part in your workshop, but when I took a look at the slides that you gave me access to, it seemed that most of the diagrams that you're talking about are sequence diagrams, activity diagrams, so diagrams that talk about the dynamic behavior of the system, and CIFOR is different. So, I was wondering why you chose sequence diagrams and activity diagrams in particular, and not the UML diagrams that you could use for the structure as well. I mean, there are component diagrams and class diagrams and these kinds of things, so that's basically what I was wondering about. Yeah, so I try to give a bit of a balance because we do look at the CIFOR, so that's structure. Obviously, when I teach this for one day, I can teach it for longer, and we could go into a lot more if people wanted to, but in one day, we can only really cover a certain amount. So, because we're looking at the structure with the CIFOR, I chose the more behavior ones because those are the things that CIFOR doesn't show, and so a lot of people say, oh yeah, we can just use CIFOR for all our diagrams, that's all we need, but actually, we also need to communicate the behavior of the system, which is kind of more important, really, because that's what's meeting the needs of our users, is the behavior, not the structure. Our users don't care if we've got a monolith or which service talks to which, they care about the behavior of the system and whether it does what they want. So, we can't just use CIFOR, we have to use behavior or at least consider our behavior, and of course, diagrams are a good way of communicating that. So, is that sort of your default approach, like you use CIFOR for the structure and then use activity diagrams where they fit in, or is that just to give like a broad spectrum to choose from? Yeah, I mean, I wouldn't necessarily always use an activity diagram, but they're quite useful, along with flow diagrams, sequence diagrams, there's so many different types of diagram, it depends what you're trying to communicate. One of the diagrams that Mermaid does is called a Sankey diagram, which I don't know if you've heard of, but I don't know if you've ever seen these websites where they show maybe the flow of where users are using a website. So, they've started at the home page, and then some of them have gone to this page, and so you get those lines, and that could actually be quite useful for showing lots of different things in the system, not just how users are. Is it where the lines have different signals, depending on how many people are going in these different ways? So, you could use that in lots of different ways, not just how people navigate a website, but how people are using a system or how your services are communicating with each other. And if you created that, you could see where the bottlenecks are, where people are really using things. So, to me, it seems what you're basically saying is, okay, so I want to do some diagrams, so I would use some tools, like you mentioned, like diagrams as code tools. And would you suggest to only do that with AI support, or do you think you can? I mean, there are studies that say if you look at code and coding, it's not obvious whether using AI technology actually improves things and makes people more productive. There are some studies that say that people think they are more productive, but in reality, they are not. So, what's your suggestion? Would you use diagrams as code only with AI? Do you think it's a strong support or is it more optional? What's your take on that? I think it's definitely optional. And in fact, when I teach the course, I say to people when they're doing the exercises, you can use AI if you want, or you can hand code this. One of the examples I show is a really long prompt saying what I would like to show in a sequence diagram. And if you look at how much text you have to actually give it, you may as well have just written it in plant URL or mermaid from the start, it would actually be less writing if you just typed it. So, that's why I'm teaching these basics and saying to people you need these skills because you need to know when it's actually worth using the AI and when it's not. So, if you are really struggling with an error, if you are thinking, I've got a load of plant URL diagrams and I want to convert them to mermaid or I want to convert them to structuriser, that's knowing when it's worth, you're going to get that time saving, but also knowing what to look for the hallucinations and errors and things like that. Like when it says, oh, yeah, you can just use this keyword to move stuff around. Yeah, no. So, as far as I remember, each diagram type has a different domain specific language and some are more complex and some are easier. Would you say that some diagram types are easier to handle with AI than others? And I mean, for instance, with a sequence diagram, I guess there's not much layout information in there because it's just a sequence. But with other diagram types, I run into problems with the layout. Is this maybe a point where the AI can be of good help? Yeah, I mean, I think as long as the AI kind of has the context of understanding that if it's been taught on the DSL, the domain specific language, you can, of course, use things like MCP servers. I think there's one called context seven. I think it's called that, which I've been told is good for coding, but also it does have information in there on Mermaid and Blank UML. And someone in my class yesterday actually said they got really good results. They thought it was probably because they were using that MCP server. So as long as AI kind of understands it, it can probably help you, but it may still try and make things up because it's trying to answer you. And if it doesn't understand something, then it will just still try. So in your slides, I've seen that, I think it was the activity diagram where there's an old DSL available and a new one, which is still in beta. Is this such a case where the LLM might not know the new version yet? And so it might be better to use still the old domain specific language. Yes. So with these, although these diagrams as code languages have been around for a while, they are, of course, still being added to. And some of them are in beta, especially with Blank UML and Mermaid, they are adding new ones on. Mermaid probably a bit more than Blank UML now. And yeah, they're not going to know about those ones that are in beta. And sometimes they do change things. There was one, I think it might be in sequence diagrams with Blank UML where they just changed it from one to the other. But I might be thinking of something else. So yes, your LLM is going to have a cutoff point where it doesn't know about things. And so you're going to have to add in things like an MCP server or just say, look at this documentation, or this is this is the basic structure that I'm expecting you to use. Now, do this. So it's going to your results are going to vary depending on the model you're using, depending on the training data, and depending on how specific you are when you what you ask it to do. Which model do you use most often? I have started using Claude more recently. But I've used ChatGPT a fair bit as well. Claude seems to be at least as good as ChatGPT in most things. This is without supplementing it with an MCP server or anything. But it's not perfect. I gave it a Blank UML file with a load of errors in, and it didn't pick up on some of them. It thought that a bit of gibberish that I chucked in there was supposed to be a color code, but started with a hash. And it started with two hashes. And then it tried to change it, but it still had two hashes. And I was like, that's complete nonsense. So none of them are perfect. I think they just released a new model. So we have to try it out. Yes, that's that's what I do with this course. Every time I teach it, pretty much I'm reviewing it and saying, right, are there any new diagrams to talk about? How is this model doing? And I do a few comparisons in there. I'm like, this is how it happened, what happened in September last year. This is September this year. And sometimes they actually get a bit worse, because of course, it's non-deterministic. And I'm just saying, right, do this now and seeing whether it can do it at that particular time. It's a bit like sitting an exam or something. You can work really hard for two years, sit the exam and not do very well on that day. It was a quite interesting part in your workshop that you compared the results from September 24, something like this. And now it's better. So this gives you more insights. That's quite good. Yes, I was saying when I was teaching yesterday that people in that group were actually getting better results than people when I've taught this before. And I was saying, well, maybe the fact that I'm teaching this is actually teaching these LLMs to do it better. Yeah, that's quite an interesting one to think on. Which leads to the problem that you can't like pin a version of an LLM and say, OK, this is going to be the same model, even if I use it in a few months. So before we went live, you said that there is a relation between what you were doing in your workshop to spec driven development. So what's that? The spec driven development is quite a new thing, and there's lots of different definitions for it at the moment. But essentially, people are now sort of moving. It's quite funny. So I would say that developers have spent sort of the last maybe two decades or more trying to avoid writing documentation so they can write code instead. And now we're talking about writing documentation so that I can write the code. And other people have been saying, oh, yeah, how many people like writing code? And everyone goes, yeah. And how many people like reviewing code? And everyone goes, no, I don't really want to do that. But actually, a lot of people are saying, yeah, let's do this spec driven documentation where that's exactly what we're going to do. We're going to the basic idea is that you create a specification of a spec using things like Markdown. And that's partly a human input and partly an AI input. And there are certain methods and tools that you can use at the moment, like GitHub spec kit. I've been looking at that a little bit. But the idea is that we create the spec along with the AI and then the AI then writes the code for it. And then we hopefully review that code. Because otherwise, we're just doing vibe coding. What do you mean by hopefully? Yes. So, we should definitely if we're doing spec driven development, we are reviewing that code. We are reviewing the tests that it's creating. But the idea with spec driven development compared to vibe coding is that we are managing the context that the LLM is using. So, we are saying these are the principles you should be sticking to. These are architecture decisions that have been made. We need you to record architecture decisions which we can then view. Because we one of the things I'm really big on is architecture documentation should include the why. Because that if we don't include the why we made that decision, then we can never reproduce that. The how and the what can be reproduced from the why, but the why cannot be reproduced from the how or the what. So, that is the information that's being lost. Okay. And diagram as code, how does that fit into spec driven development? So, there's the relation? Yeah. So, you can, of course, in your markdown files, you can include these diagrams as code. You can ask the AI to produce them in there as well. One other thing I've seen being done is to create ASCII diagrams as well. So, you're getting the AI to use pipes and all the different ASCII characters to actually create a diagram for you. And it can do that in the markdown. But it can also, of course, do that in the command line for you as well. And you can say, like create it using ASCII show what we've done so far. And that helps you to review what you are doing, because the diagrams aren't necessarily for the AI. But if you've already got a diagram, you can give it to the AI to help it understand what we're trying to do, or they understand. But also, if you're getting the AI to create the diagrams of what you're doing, you are using that as a validation check. You can say, okay, that's not quite right. We need to make a change to this. That's a very interesting point, the ASCII diagrams, because when you create a plant ML diagram, you have the relationships between components. And I guess that a lamb can read this fine and okay. But I noticed lately that Claude often creates those ASCII diagrams. And I get an impression that it would, I mean, visually, it's easy to read for me, but I guess it's not so easy to read for the LM. And so I have, I guess, the documentation has to contain the relationships and the diagram. Did you also notice a shift in there that the model behaves differently? I've not really noticed that, but I think like what you were saying about the ASCII diagrams, yes, they don't have those relationships. One thing that I've seen that I thought was good for this was it was used to actually mock up how a web page was going to look with some different boxes on it. And so, of course, there are, I think it's, I think it's Mermaid has at least one form of diagram for wireframing, but just using those ASCII to go, right, yeah, we've got a box here and then a box here, and then that's good. And you can show the different versions of something or how it's going to move through different pop-up boxes and things like that. And so if you're wireframing, I think where you don't have those relationships, where it's sort of more of an image, then that's quite a good way to do it, because the command line, you can't, you're not going to have sort of the image unless you actually load up a web page and have a look at it. So the ASCII diagrams that we're talking about, that's, they, I assume they use ASCII characters to sort of draw a diagram. So that's, that's how it works. Yes. Yeah, and LLMs might have problems understanding that. I was wondering whether, so that's it for spec-driven development. And I think that is something that we see in LLMs quite a lot these days, that basically we are trying to use not natural language, but other languages that also have a limited, limited, limited set of things that they can talk to. Any other relations between diagrams and AI? How should I put it? So the workshop seems to talk about how to generate diagrams using AI support. So we have spec-driven development where it's used as an output, but also as an input. Is there anything else, any other relation between diagrams and AI that you're seeing at the moment? I don't think I'm really seeing anything at the moment, but I think they're going to be useful with spec-driven, because a lot that I've seen with spec-driven hasn't really talked about using diagrams as code, which is interesting. It's more about creating just everything sort of in text. And from what I've seen so far, a lot of the tools at the moment are, interestingly, very waterfall. So they kind of, they don't assume that what you create first is wrong, which is, of course, if you're being agile, you've got to assume that you are going to have to iterate on things. And so if you create something in these, like all the tools work with different workflows, but they don't really want you to go back and change things in these workflows, which seems a bit odd to me, because it's like, oh, were these tools written 20 years ago? So I'm interested to see how these tools are going to evolve. At the moment, they're all doing very specific files, very specific workflows. And I think there's probably quite a lot that's missing from them. And I think diagrams as code is one of those other sort of inputs that we might want to put in there. Like if we've been using DDD to work out our different domains and different contexts and things, how are we going to communicate that to the LLM? And so we need to think about how we how we're going to do that and how we're going to break down all these files into small chunks so that we don't overwhelm that context window for the LLM and work on very small things and be able to iterate these things. But yeah, I think it's this is a very young thing, spectrum and development. And it's I think it's got a long way to mature before we can really use it properly. I wonder if this approach is more helpful for the LLM to have the relationships as a specification or whether it helps more us humans to review the spec because we are visual beings. And yeah, it's easier for us to review a diagram. But then I sometimes wonder whether it makes sense to follow all those lines to check whether the diagram is correct. So, yes, of course, you've got to rely on the fact that the diagram is correct. If you've said create if you created the diagram yourself and given it as part of the spec, then yes, the diagram is what I want. And then you've got to review the code to make sure it's followed the diagram and the specification. But if you've asked it to create the diagram, maybe this is just kind of it's giving you what you want rather than the actual reality of it. So say you have created this whole spec and you're saying, OK, this is what I've given you. Show me a diagram of what you've created in the code and it diagrams what's in the spec. But the code, if you haven't checked it, might be completely different and some complete mess. And because we all know at the moment, even if we aren't using AI, we have got these beautiful architecture diagrams and things and specifications. And then we have the code, which is completely different to that. So we can try and use things like architectural fitness functions as sort of tests to make sure that things are as we want them. And so I think that's probably something to try and use with with the spec coding as well. But we can't trust that the LLM is telling us the truth. Yeah, which basically. So I think that's that's a very important and good point. And it's for real. I mean, the things that you mentioned, they do happen as hallucinations, which yeah, which leads to the. Is there a broader problem? Like how do you how do you solve the problem that diagrams might be detached from reality? I mean, shouldn't you somehow create them from the original code then and use that as as diagrams? Yeah, so that's one thing that I think might be helpful for in that if you are give it some code that it hasn't written and say, like create a diagram of how this is all interacting, then that's probably more likely to be correct. It might not be. But you can then say, OK, here's that diagram. Here's the diagram that that we created originally and actually compare them. Because as you were saying, we're we're good with these visuals as humans. And so using AI to review things that it hasn't created or the pattern of using one model to create something and then another model or agent to review it and check that the spec and the code actually match. That's another pattern that we can use. So when when you try to compare them visually, I remember when working with Plant2ML, there are diagrams where the layout is trivial, like activity and sequence diagrams. But for instance, component or class diagrams, where the algorithm tries to place elements in such a way that the lines do not cross. And I could imagine that when I work with those diagrams and add something that everything flips over. What's your experience with this? Can we stabilize this? I think Structurizr has a solution for this. The manual layout, something like this. Yes. So Structurizr has a manual layout. If you're doing some of the different types of diagram in Mermaid and Plant2ML have some ways of specifying things. So if you're creating a C4 diagram in Plant2ML, you can use rel U for a relationship up, rel D for down and left and right. So you have some sort of control. The order that you put items into your code will also determine where they appear as well. And if you're doing things like the activity diagram, if you are adding in branches, say yes and no, the order that you put that in will determine where things are. So you've got some control, but you can still end up even in Structurizr when it's doing the auto layout for you, you can end up with some very odd things where like one thing's up here and it means all the lines are like this and crossing over. And you think, well, if you just put that down there, you wouldn't have that problem. So yes, these tools do try, but you get to that point where you think, I can't line that up. Or you get annoying things like I really like things to line up and like the title is supposed to be in the centre, but it's actually slightly off centre. It's just annoying. But yeah, with Structurizr, there is manual layout. But the downside to that is that when you then change the model, that manual layout is probably going to need to be changed as well. If you add something, that new thing is just going to appear in the top left corner. And that might be covering something else up. And so if you do add things or change the model, you'll have to review your manual layout. So I would say to people only use manual layout when you really need to and have some sort of process, be it manual or automatic, where you will go and check your manual ones when something has changed significantly in the model. So you were talking about how you can sort of review things that one element puts out and have that reviewed by another one. And I mean, we had cases, as you mentioned, even on the stream, like publicly, we had somebody who basically said, okay, he was white coding that stuff, some stuff, and he asked the LLM to create more tests and got suspicious and figured out that, in fact, the tests didn't do anything. They just generated output that looked as if some test was running. Now, and I mean, obviously, if some human would do that, I would basically fire that person because it's just, you know, you can't trust that person anymore, right? Because it's really a bad thing. So what you're saying in a way is, okay, so I have that LLM that I don't trust. And now I have another LLM that I use to review that. And I'm wondering, do you have any experience with that? Is that something that really works in practice? Because that other LLM could also be as erroneous as the original one? Yes, it's not something that I've done that much. But I have heard that if you and so the problem with the context windows, and then sort of overflowing and things, if you create agents that have a very specific task, then you will get much better results. So if you have one that is just there to go through all of your typescript, and one that makes sure that certain things like architecture decisions have been written, and so it's not so much, I've got one LLM that does everything and one that checks everything. It's I'm using different agents to do very specific jobs. And then you still can't guarantee. The thing is, you can't guarantee that a human would either to be to be honest. I mean, obviously, you build things, you build up levels of trust with humans. And like what you were saying about different models coming up, coming out, it's like, Oh, I've built up a level of trust with this model. And now there's a new one. And it's a bit like someone leaving your company who you really trust and someone new coming in, who kind of says, Yeah, here's my CV, all flashy. And you think, well, now I've got to build up this trust again, with you and work out how to work with you. So it's, it's quite interesting dynamic. I wonder whether Eberhard will fire Claude Sonnet 3.7 and then use 4.0. I mean, it is a new model, it could make sense is that it's more reliable, and you can build up more trust. Yeah. But like you were saying with Simon Wardley, I've, I've heard him talk about those tests. But if you if you ask the things at a very high level, which I think is what Simon did, where it's like, yeah, create tests for this. It's like, well, what's the LLM gonna do? It's gonna, it's gonna do what like some teenager would do probably, as well, which is create a load of tests, which basically just return true. Because that's the easiest thing to do. And you say to it, Oh, fix this bug. And, and what instead of doing the hard thing of fixing the bug, it will change the test so that it returns so that it passes. So it's just it's trying to do what you want in the kind of the easiest way possible. Yeah, I have to because you came up with with that, that trust thing. If I may, there are two things that I would like to point out. First of all, I, I have the impression, but maybe maybe your precious different, that there is too much confidence on LLMs and LLMs actually implemented in a way that they that they try to gamble us to trust them. So I think that's that's one problem. And the other problem is, I have to admit that that I had to make my mind about like trying to figure out what exactly the problem is. So the problem is that, in my opinion, an LLM is optimized just by the tests that they that are run, they are punished if they say, I don't know, and they never do that. So therefore, they come up with some answer. And humans, people that I would like to work with, I can't really think of anything that is worse than a person who never says, I don't know, and wouldn't show up and say, okay, you know, so you gave me that task. I don't know how to do it. Please help me. And so therefore, I think it's it's a different because of that it's it's a different way of trust, or a different thing if you have a human. And that is also why why I feel somewhat uncomfortable about LLMs because they are optimized to sort of gain trust, but at the same time, they're optimized to, you know, to just give random answers. And with a human, I would be very scared to have such a person. So and I have to admit that I would probably not hire such a person. But you've got there's a lot of companies out there still that don't have these safe working environments where people feel that they can actually admit that. But it's interesting to think that like people put all these trusts in these kind of personifications that have been kind of created, like they given names like Claude. But the thing is, like the very underlying large language model has basically been trained to play a game of guessing the next word. And so it does that based on what it's been trained on. And so all it's doing is playing, playing this game. And a lot of people just don't really kind of understand that all the LLM is trying to do is guess the next thing. And basically be told, yes, well done. You've done that. And so it's not going to say, I don't know, because it's basically trained to, to do that. And so that's all all it's doing under the hood, we've got an agent or something that is communicating with that LLM. And all that's doing is going, right, okay, now here, now the next word, now give me the next word, now give me the next bit. And it does that over and over again, and then passes that back to the user. And I think if people understood more what was under the hood, then they wouldn't have quite so much trust in it. Anything we still need to talk about? Anything that we forgot to mention? We've covered a lot. Yeah, that's true. That's also what I figured. So thanks a lot for joining. So this evening, we are going to have a live stream of the Fishbowl and where we are going to discuss the impact of AI on software architecture. So yeah, I'm looking forward to that one. So please, yeah, join us there. It's at a quarter to 7pm. So a CET. So to see you there, and hope you enjoy the rest of the conference. And thanks again to Software Architecture Gathering for hosting us. And thanks for watching and listening. Thank you. Thank you.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 3.8399999141693115,
      "text": " So, welcome to another episode of Software-Architecture im Stream.",
      "tokens": [
        50364,
        407,
        11,
        2928,
        281,
        1071,
        3500,
        295,
        27428,
        12,
        10683,
        339,
        5739,
        540,
        566,
        24904,
        13,
        50556
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2700851857662201,
      "compression_ratio": 1.6439024209976196,
      "no_speech_prob": 0.1686202883720398
    },
    {
      "id": 1,
      "seek": 0,
      "start": 4.960000038146973,
      "end": 11.520000457763672,
      "text": " Unfortunately, Lisa couldn't make it, so we replaced her with myself and Alf, because it",
      "tokens": [
        50612,
        8590,
        11,
        12252,
        2809,
        380,
        652,
        309,
        11,
        370,
        321,
        10772,
        720,
        365,
        2059,
        293,
        21996,
        11,
        570,
        309,
        50940
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2700851857662201,
      "compression_ratio": 1.6439024209976196,
      "no_speech_prob": 0.1686202883720398
    },
    {
      "id": 2,
      "seek": 0,
      "start": 11.520000457763672,
      "end": 18.479999542236328,
      "text": " takes two of us to replace her. We are at Software-Architecture Gathering, and first of all,",
      "tokens": [
        50940,
        2516,
        732,
        295,
        505,
        281,
        7406,
        720,
        13,
        492,
        366,
        412,
        27428,
        12,
        10683,
        339,
        5739,
        540,
        39841,
        278,
        11,
        293,
        700,
        295,
        439,
        11,
        51288
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2700851857662201,
      "compression_ratio": 1.6439024209976196,
      "no_speech_prob": 0.1686202883720398
    },
    {
      "id": 3,
      "seek": 0,
      "start": 18.479999542236328,
      "end": 24.239999771118164,
      "text": " a big thank you to the organizers of Software-Architecture Gathering for the support. So",
      "tokens": [
        51288,
        257,
        955,
        1309,
        291,
        281,
        264,
        35071,
        295,
        27428,
        12,
        10683,
        339,
        5739,
        540,
        39841,
        278,
        337,
        264,
        1406,
        13,
        407,
        51576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2700851857662201,
      "compression_ratio": 1.6439024209976196,
      "no_speech_prob": 0.1686202883720398
    },
    {
      "id": 4,
      "seek": 2424,
      "start": 24.239999771118164,
      "end": 31.440000534057617,
      "text": " this has to be the most professional episode we ever did. And our guest today is Jackie,",
      "tokens": [
        50364,
        341,
        575,
        281,
        312,
        264,
        881,
        4843,
        3500,
        321,
        1562,
        630,
        13,
        400,
        527,
        8341,
        965,
        307,
        23402,
        11,
        50724
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1932823210954666,
      "compression_ratio": 1.5042372941970825,
      "no_speech_prob": 0.34013497829437256
    },
    {
      "id": 5,
      "seek": 2424,
      "start": 32.959999084472656,
      "end": 37.36000061035156,
      "text": " and you have already been a guest at our stream several times, I believe. So,",
      "tokens": [
        50800,
        293,
        291,
        362,
        1217,
        668,
        257,
        8341,
        412,
        527,
        4309,
        2940,
        1413,
        11,
        286,
        1697,
        13,
        407,
        11,
        51020
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1932823210954666,
      "compression_ratio": 1.5042372941970825,
      "no_speech_prob": 0.34013497829437256
    },
    {
      "id": 6,
      "seek": 2424,
      "start": 37.36000061035156,
      "end": 43.20000076293945,
      "text": " can you do a short introduction of yourself? I can. So, I'm Jackie Reed. I've written the book",
      "tokens": [
        51020,
        393,
        291,
        360,
        257,
        2099,
        9339,
        295,
        1803,
        30,
        286,
        393,
        13,
        407,
        11,
        286,
        478,
        23402,
        32071,
        13,
        286,
        600,
        3720,
        264,
        1446,
        51312
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1932823210954666,
      "compression_ratio": 1.5042372941970825,
      "no_speech_prob": 0.34013497829437256
    },
    {
      "id": 7,
      "seek": 2424,
      "start": 43.20000076293945,
      "end": 50.31999969482422,
      "text": " Communication Patterns with O'Reilly, and last time I was on Software-Architecture im Stream,",
      "tokens": [
        51312,
        34930,
        34367,
        3695,
        365,
        422,
        6,
        8524,
        6917,
        11,
        293,
        1036,
        565,
        286,
        390,
        322,
        27428,
        12,
        10683,
        339,
        5739,
        540,
        566,
        24904,
        11,
        51668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1932823210954666,
      "compression_ratio": 1.5042372941970825,
      "no_speech_prob": 0.34013497829437256
    },
    {
      "id": 8,
      "seek": 5032,
      "start": 50.31999969482422,
      "end": 57.040000915527344,
      "text": " we were talking about that book and about patterns. And since I've written that book,",
      "tokens": [
        50364,
        321,
        645,
        1417,
        466,
        300,
        1446,
        293,
        466,
        8294,
        13,
        400,
        1670,
        286,
        600,
        3720,
        300,
        1446,
        11,
        50700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2041771411895752,
      "compression_ratio": 1.6177778244018555,
      "no_speech_prob": 0.006352300755679607
    },
    {
      "id": 9,
      "seek": 5032,
      "start": 57.040000915527344,
      "end": 64.87999725341797,
      "text": " I've been looking at how we can use diagrams as code with AI, and even getting into a bit of",
      "tokens": [
        50700,
        286,
        600,
        668,
        1237,
        412,
        577,
        321,
        393,
        764,
        36709,
        382,
        3089,
        365,
        7318,
        11,
        293,
        754,
        1242,
        666,
        257,
        857,
        295,
        51092
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2041771411895752,
      "compression_ratio": 1.6177778244018555,
      "no_speech_prob": 0.006352300755679607
    },
    {
      "id": 10,
      "seek": 5032,
      "start": 64.87999725341797,
      "end": 70.80000305175781,
      "text": " spec-driven development at the moment as well. So, still looking at communication, but with",
      "tokens": [
        51092,
        1608,
        12,
        25456,
        3250,
        412,
        264,
        1623,
        382,
        731,
        13,
        407,
        11,
        920,
        1237,
        412,
        6101,
        11,
        457,
        365,
        51388
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2041771411895752,
      "compression_ratio": 1.6177778244018555,
      "no_speech_prob": 0.006352300755679607
    },
    {
      "id": 11,
      "seek": 5032,
      "start": 70.80000305175781,
      "end": 75.91999816894531,
      "text": " different things now. Yeah, and I've also joined me. So, do you want to say a few words about",
      "tokens": [
        51388,
        819,
        721,
        586,
        13,
        865,
        11,
        293,
        286,
        600,
        611,
        6869,
        385,
        13,
        407,
        11,
        360,
        291,
        528,
        281,
        584,
        257,
        1326,
        2283,
        466,
        51644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2041771411895752,
      "compression_ratio": 1.6177778244018555,
      "no_speech_prob": 0.006352300755679607
    },
    {
      "id": 12,
      "seek": 7592,
      "start": 75.91999816894531,
      "end": 84.31999969482422,
      "text": " yourself? No. No? Okay. So, you're here because you're one of the... Let's use a time for our",
      "tokens": [
        50364,
        1803,
        30,
        883,
        13,
        883,
        30,
        1033,
        13,
        407,
        11,
        291,
        434,
        510,
        570,
        291,
        434,
        472,
        295,
        264,
        485,
        961,
        311,
        764,
        257,
        565,
        337,
        527,
        50784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28906136751174927,
      "compression_ratio": 1.5517241954803467,
      "no_speech_prob": 0.07359235733747482
    },
    {
      "id": 13,
      "seek": 7592,
      "start": 84.31999969482422,
      "end": 91.27999877929688,
      "text": " guest. Yeah. So, you're one of the experts on diagrams, so that is why I made you join us.",
      "tokens": [
        50784,
        8341,
        13,
        865,
        13,
        407,
        11,
        291,
        434,
        472,
        295,
        264,
        8572,
        322,
        36709,
        11,
        370,
        300,
        307,
        983,
        286,
        1027,
        291,
        3917,
        505,
        13,
        51132
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28906136751174927,
      "compression_ratio": 1.5517241954803467,
      "no_speech_prob": 0.07359235733747482
    },
    {
      "id": 14,
      "seek": 7592,
      "start": 91.91999816894531,
      "end": 98.72000122070312,
      "text": " So, that is also the workshop that you gave yesterday about diagrams as code with AI,",
      "tokens": [
        51164,
        407,
        11,
        300,
        307,
        611,
        264,
        13541,
        300,
        291,
        2729,
        5186,
        466,
        36709,
        382,
        3089,
        365,
        7318,
        11,
        51504
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28906136751174927,
      "compression_ratio": 1.5517241954803467,
      "no_speech_prob": 0.07359235733747482
    },
    {
      "id": 15,
      "seek": 9872,
      "start": 99.68000030517578,
      "end": 106.80000305175781,
      "text": " and you're available to also do that workshop elsewhere also for customers on site or virtually.",
      "tokens": [
        50412,
        293,
        291,
        434,
        2435,
        281,
        611,
        360,
        300,
        13541,
        14517,
        611,
        337,
        4581,
        322,
        3621,
        420,
        14103,
        13,
        50768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20603197813034058,
      "compression_ratio": 1.5196506977081299,
      "no_speech_prob": 0.020877059549093246
    },
    {
      "id": 16,
      "seek": 9872,
      "start": 106.80000305175781,
      "end": 111.5999984741211,
      "text": " So, how does AI fit into diagrams as code? Where's the benefit?",
      "tokens": [
        50768,
        407,
        11,
        577,
        775,
        7318,
        3318,
        666,
        36709,
        382,
        3089,
        30,
        2305,
        311,
        264,
        5121,
        30,
        51008
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20603197813034058,
      "compression_ratio": 1.5196506977081299,
      "no_speech_prob": 0.020877059549093246
    },
    {
      "id": 17,
      "seek": 9872,
      "start": 113.12000274658203,
      "end": 118.16000366210938,
      "text": " I think a lot of the time at the moment, people are trying to find the problem to fix with AI,",
      "tokens": [
        51084,
        286,
        519,
        257,
        688,
        295,
        264,
        565,
        412,
        264,
        1623,
        11,
        561,
        366,
        1382,
        281,
        915,
        264,
        1154,
        281,
        3191,
        365,
        7318,
        11,
        51336
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20603197813034058,
      "compression_ratio": 1.5196506977081299,
      "no_speech_prob": 0.020877059549093246
    },
    {
      "id": 18,
      "seek": 9872,
      "start": 119.19999694824219,
      "end": 127.36000061035156,
      "text": " but it can actually be useful for our diagrams. But we still need to have that skilled human",
      "tokens": [
        51388,
        457,
        309,
        393,
        767,
        312,
        4420,
        337,
        527,
        36709,
        13,
        583,
        321,
        920,
        643,
        281,
        362,
        300,
        19690,
        1952,
        51796
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20603197813034058,
      "compression_ratio": 1.5196506977081299,
      "no_speech_prob": 0.020877059549093246
    },
    {
      "id": 19,
      "seek": 12736,
      "start": 127.91999816894531,
      "end": 136.8000030517578,
      "text": " actually driving this, because anyone can ask an LLM to create a diagram using things like",
      "tokens": [
        50392,
        767,
        4840,
        341,
        11,
        570,
        2878,
        393,
        1029,
        364,
        441,
        43,
        44,
        281,
        1884,
        257,
        10686,
        1228,
        721,
        411,
        50836
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23431192338466644,
      "compression_ratio": 1.4943181276321411,
      "no_speech_prob": 0.002516445005312562
    },
    {
      "id": 20,
      "seek": 12736,
      "start": 136.8000030517578,
      "end": 144.47999572753906,
      "text": " PlantUML or Mermaid or Structurizer for C4 diagrams. But you need to understand what's",
      "tokens": [
        50836,
        28995,
        52,
        12683,
        420,
        376,
        32124,
        420,
        745,
        1757,
        374,
        6545,
        337,
        383,
        19,
        36709,
        13,
        583,
        291,
        643,
        281,
        1223,
        437,
        311,
        51220
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23431192338466644,
      "compression_ratio": 1.4943181276321411,
      "no_speech_prob": 0.002516445005312562
    },
    {
      "id": 21,
      "seek": 12736,
      "start": 144.47999572753906,
      "end": 148.8000030517578,
      "text": " coming out of it, and you need to understand what you're asking for as well, be that,",
      "tokens": [
        51220,
        1348,
        484,
        295,
        309,
        11,
        293,
        291,
        643,
        281,
        1223,
        437,
        291,
        434,
        3365,
        337,
        382,
        731,
        11,
        312,
        300,
        11,
        51436
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23431192338466644,
      "compression_ratio": 1.4943181276321411,
      "no_speech_prob": 0.002516445005312562
    },
    {
      "id": 22,
      "seek": 14880,
      "start": 149.75999450683594,
      "end": 158.39999389648438,
      "text": " can you update this diagram, create it, or help me fix it? You need to know how to ask the question,",
      "tokens": [
        50412,
        393,
        291,
        5623,
        341,
        10686,
        11,
        1884,
        309,
        11,
        420,
        854,
        385,
        3191,
        309,
        30,
        509,
        643,
        281,
        458,
        577,
        281,
        1029,
        264,
        1168,
        11,
        50844
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20491378009319305,
      "compression_ratio": 1.424870491027832,
      "no_speech_prob": 0.08359278738498688
    },
    {
      "id": 23,
      "seek": 14880,
      "start": 158.39999389648438,
      "end": 164.63999938964844,
      "text": " because if you ask things at too high level, very often it will just hallucinate and make things up.",
      "tokens": [
        50844,
        570,
        498,
        291,
        1029,
        721,
        412,
        886,
        1090,
        1496,
        11,
        588,
        2049,
        309,
        486,
        445,
        35212,
        13923,
        293,
        652,
        721,
        493,
        13,
        51156
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20491378009319305,
      "compression_ratio": 1.424870491027832,
      "no_speech_prob": 0.08359278738498688
    },
    {
      "id": 24,
      "seek": 14880,
      "start": 164.63999938964844,
      "end": 168.39999389648438,
      "text": " And I've got a couple of good examples of that when I teach the workshop.",
      "tokens": [
        51156,
        400,
        286,
        600,
        658,
        257,
        1916,
        295,
        665,
        5110,
        295,
        300,
        562,
        286,
        2924,
        264,
        13541,
        13,
        51344
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20491378009319305,
      "compression_ratio": 1.424870491027832,
      "no_speech_prob": 0.08359278738498688
    },
    {
      "id": 25,
      "seek": 16840,
      "start": 169.27999877929688,
      "end": 177.67999267578125,
      "text": " So, in the past, I tried to ask the LLM to create a diagram and it used Delhi or another",
      "tokens": [
        50408,
        407,
        11,
        294,
        264,
        1791,
        11,
        286,
        3031,
        281,
        1029,
        264,
        441,
        43,
        44,
        281,
        1884,
        257,
        10686,
        293,
        309,
        1143,
        26680,
        420,
        1071,
        50828
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23622873425483704,
      "compression_ratio": 1.3850266933441162,
      "no_speech_prob": 0.029226891696453094
    },
    {
      "id": 26,
      "seek": 16840,
      "start": 179.67999267578125,
      "end": 186.63999938964844,
      "text": " diffusion generator and the results were ugly. So, you just mentioned PlantUML and",
      "tokens": [
        50928,
        25242,
        19265,
        293,
        264,
        3542,
        645,
        12246,
        13,
        407,
        11,
        291,
        445,
        2835,
        28995,
        52,
        12683,
        293,
        51276
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23622873425483704,
      "compression_ratio": 1.3850266933441162,
      "no_speech_prob": 0.029226891696453094
    },
    {
      "id": 27,
      "seek": 16840,
      "start": 186.63999938964844,
      "end": 193.52000427246094,
      "text": " Mermaid and Structurizer. Can you go a little bit deeper into detail? What's the trick?",
      "tokens": [
        51276,
        376,
        32124,
        293,
        745,
        1757,
        374,
        6545,
        13,
        1664,
        291,
        352,
        257,
        707,
        857,
        7731,
        666,
        2607,
        30,
        708,
        311,
        264,
        4282,
        30,
        51620
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23622873425483704,
      "compression_ratio": 1.3850266933441162,
      "no_speech_prob": 0.029226891696453094
    },
    {
      "id": 28,
      "seek": 19352,
      "start": 194.47999572753906,
      "end": 199.83999633789062,
      "text": " Yes. So, when we're talking about diagrams as code, we're talking about creating diagrams using",
      "tokens": [
        50412,
        1079,
        13,
        407,
        11,
        562,
        321,
        434,
        1417,
        466,
        36709,
        382,
        3089,
        11,
        321,
        434,
        1417,
        466,
        4084,
        36709,
        1228,
        50680
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1891326904296875,
      "compression_ratio": 1.6651583909988403,
      "no_speech_prob": 0.03235941007733345
    },
    {
      "id": 29,
      "seek": 19352,
      "start": 199.83999633789062,
      "end": 207.36000061035156,
      "text": " text. And there's lots of domain-specific languages. So, PlantUML is one of the most",
      "tokens": [
        50680,
        2487,
        13,
        400,
        456,
        311,
        3195,
        295,
        9274,
        12,
        29258,
        8650,
        13,
        407,
        11,
        28995,
        52,
        12683,
        307,
        472,
        295,
        264,
        881,
        51056
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1891326904296875,
      "compression_ratio": 1.6651583909988403,
      "no_speech_prob": 0.03235941007733345
    },
    {
      "id": 30,
      "seek": 19352,
      "start": 207.36000061035156,
      "end": 214.72000122070312,
      "text": " more popular ones. And it's, as you can probably guess, it was originally made for UML diagrams.",
      "tokens": [
        51056,
        544,
        3743,
        2306,
        13,
        400,
        309,
        311,
        11,
        382,
        291,
        393,
        1391,
        2041,
        11,
        309,
        390,
        7993,
        1027,
        337,
        624,
        12683,
        36709,
        13,
        51424
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1891326904296875,
      "compression_ratio": 1.6651583909988403,
      "no_speech_prob": 0.03235941007733345
    },
    {
      "id": 31,
      "seek": 19352,
      "start": 214.72000122070312,
      "end": 220.55999755859375,
      "text": " So, it supports lots of UML diagrams, but it does support some various other ones as well.",
      "tokens": [
        51424,
        407,
        11,
        309,
        9346,
        3195,
        295,
        624,
        12683,
        36709,
        11,
        457,
        309,
        775,
        1406,
        512,
        3683,
        661,
        2306,
        382,
        731,
        13,
        51716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1891326904296875,
      "compression_ratio": 1.6651583909988403,
      "no_speech_prob": 0.03235941007733345
    },
    {
      "id": 32,
      "seek": 22056,
      "start": 221.36000061035156,
      "end": 229.27999877929688,
      "text": " And it's got some downsides. Part of what I teach in the course is I give all three of these. So,",
      "tokens": [
        50404,
        400,
        309,
        311,
        658,
        512,
        21554,
        1875,
        13,
        4100,
        295,
        437,
        286,
        2924,
        294,
        264,
        1164,
        307,
        286,
        976,
        439,
        1045,
        295,
        613,
        13,
        407,
        11,
        50800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20165079832077026,
      "compression_ratio": 1.6034482717514038,
      "no_speech_prob": 0.003534262767061591
    },
    {
      "id": 33,
      "seek": 22056,
      "start": 229.27999877929688,
      "end": 235.60000610351562,
      "text": " I give a grounding in PlantUML, Mermaid and Structurizer, because they're all useful in",
      "tokens": [
        50800,
        286,
        976,
        257,
        46727,
        294,
        28995,
        52,
        12683,
        11,
        376,
        32124,
        293,
        745,
        1757,
        374,
        6545,
        11,
        570,
        436,
        434,
        439,
        4420,
        294,
        51116
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20165079832077026,
      "compression_ratio": 1.6034482717514038,
      "no_speech_prob": 0.003534262767061591
    },
    {
      "id": 34,
      "seek": 22056,
      "start": 235.60000610351562,
      "end": 240.47999572753906,
      "text": " different ways. And so, you can't just say, oh, we're just going to use Mermaid in our",
      "tokens": [
        51116,
        819,
        2098,
        13,
        400,
        370,
        11,
        291,
        393,
        380,
        445,
        584,
        11,
        1954,
        11,
        321,
        434,
        445,
        516,
        281,
        764,
        376,
        32124,
        294,
        527,
        51360
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20165079832077026,
      "compression_ratio": 1.6034482717514038,
      "no_speech_prob": 0.003534262767061591
    },
    {
      "id": 35,
      "seek": 22056,
      "start": 240.47999572753906,
      "end": 245.9199981689453,
      "text": " organisation. That's all we're ever going to need, because it doesn't cover everything you're going",
      "tokens": [
        51360,
        18641,
        13,
        663,
        311,
        439,
        321,
        434,
        1562,
        516,
        281,
        643,
        11,
        570,
        309,
        1177,
        380,
        2060,
        1203,
        291,
        434,
        516,
        51632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20165079832077026,
      "compression_ratio": 1.6034482717514038,
      "no_speech_prob": 0.003534262767061591
    },
    {
      "id": 36,
      "seek": 24592,
      "start": 245.9199981689453,
      "end": 251.0399932861328,
      "text": " to need. So, in some contexts, you will choose one, and in some contexts, another. So, we look",
      "tokens": [
        50364,
        281,
        643,
        13,
        407,
        11,
        294,
        512,
        30628,
        11,
        291,
        486,
        2826,
        472,
        11,
        293,
        294,
        512,
        30628,
        11,
        1071,
        13,
        407,
        11,
        321,
        574,
        50620
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18910393118858337,
      "compression_ratio": 1.6124999523162842,
      "no_speech_prob": 0.1379942148923874
    },
    {
      "id": 37,
      "seek": 24592,
      "start": 251.0399932861328,
      "end": 258.55999755859375,
      "text": " at all the pros and cons. So, PlantUML is built on Java, which makes it a little bit more difficult",
      "tokens": [
        50620,
        412,
        439,
        264,
        6267,
        293,
        1014,
        13,
        407,
        11,
        28995,
        52,
        12683,
        307,
        3094,
        322,
        10745,
        11,
        597,
        1669,
        309,
        257,
        707,
        857,
        544,
        2252,
        50996
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18910393118858337,
      "compression_ratio": 1.6124999523162842,
      "no_speech_prob": 0.1379942148923874
    },
    {
      "id": 38,
      "seek": 24592,
      "start": 258.55999755859375,
      "end": 265.9200134277344,
      "text": " to then render the diagram. So, that's why things like GitHub don't really support that, because",
      "tokens": [
        50996,
        281,
        550,
        15529,
        264,
        10686,
        13,
        407,
        11,
        300,
        311,
        983,
        721,
        411,
        23331,
        500,
        380,
        534,
        1406,
        300,
        11,
        570,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18910393118858337,
      "compression_ratio": 1.6124999523162842,
      "no_speech_prob": 0.1379942148923874
    },
    {
      "id": 39,
      "seek": 24592,
      "start": 265.9200134277344,
      "end": 271.44000244140625,
      "text": " Mermaid's built on JavaScript. It's then a lot easier for that to be rendered in various places",
      "tokens": [
        51364,
        376,
        32124,
        311,
        3094,
        322,
        15778,
        13,
        467,
        311,
        550,
        257,
        688,
        3571,
        337,
        300,
        281,
        312,
        28748,
        294,
        3683,
        3190,
        51640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18910393118858337,
      "compression_ratio": 1.6124999523162842,
      "no_speech_prob": 0.1379942148923874
    },
    {
      "id": 40,
      "seek": 27144,
      "start": 271.44000244140625,
      "end": 279.5199890136719,
      "text": " on the internet. And so, we look at PlantUML, Java, Structurizer, and Structurizer is just",
      "tokens": [
        50364,
        322,
        264,
        4705,
        13,
        400,
        370,
        11,
        321,
        574,
        412,
        28995,
        52,
        12683,
        11,
        10745,
        11,
        745,
        1757,
        374,
        6545,
        11,
        293,
        745,
        1757,
        374,
        6545,
        307,
        445,
        50768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17668071389198303,
      "compression_ratio": 1.6591928005218506,
      "no_speech_prob": 0.021342817693948746
    },
    {
      "id": 41,
      "seek": 27144,
      "start": 280.4800109863281,
      "end": 287.6000061035156,
      "text": " like C4 diagrams. And so, you might think, oh, wait, but I can do C4 diagrams in PlantUML and",
      "tokens": [
        50816,
        411,
        383,
        19,
        36709,
        13,
        400,
        370,
        11,
        291,
        1062,
        519,
        11,
        1954,
        11,
        1699,
        11,
        457,
        286,
        393,
        360,
        383,
        19,
        36709,
        294,
        28995,
        52,
        12683,
        293,
        51172
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17668071389198303,
      "compression_ratio": 1.6591928005218506,
      "no_speech_prob": 0.021342817693948746
    },
    {
      "id": 42,
      "seek": 27144,
      "start": 287.6000061035156,
      "end": 293.0400085449219,
      "text": " in Mermaid. So, why should we bother with Structurizer? But Structurizer is a bit different",
      "tokens": [
        51172,
        294,
        376,
        32124,
        13,
        407,
        11,
        983,
        820,
        321,
        8677,
        365,
        745,
        1757,
        374,
        6545,
        30,
        583,
        745,
        1757,
        374,
        6545,
        307,
        257,
        857,
        819,
        51444
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17668071389198303,
      "compression_ratio": 1.6591928005218506,
      "no_speech_prob": 0.021342817693948746
    },
    {
      "id": 43,
      "seek": 27144,
      "start": 293.0400085449219,
      "end": 297.8399963378906,
      "text": " in that you've got a model behind it, and you create lots of different views of that. And so,",
      "tokens": [
        51444,
        294,
        300,
        291,
        600,
        658,
        257,
        2316,
        2261,
        309,
        11,
        293,
        291,
        1884,
        3195,
        295,
        819,
        6809,
        295,
        300,
        13,
        400,
        370,
        11,
        51684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17668071389198303,
      "compression_ratio": 1.6591928005218506,
      "no_speech_prob": 0.021342817693948746
    },
    {
      "id": 44,
      "seek": 29784,
      "start": 297.8399963378906,
      "end": 302.8800048828125,
      "text": " it's much easier to maintain and manage that data. If you add a new service in or change the",
      "tokens": [
        50364,
        309,
        311,
        709,
        3571,
        281,
        6909,
        293,
        3067,
        300,
        1412,
        13,
        759,
        291,
        909,
        257,
        777,
        2643,
        294,
        420,
        1319,
        264,
        50616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1847262680530548,
      "compression_ratio": 1.5409835577011108,
      "no_speech_prob": 0.11421696096658707
    },
    {
      "id": 45,
      "seek": 29784,
      "start": 302.8800048828125,
      "end": 308.55999755859375,
      "text": " name of something, it will update in all of your views that you've created from that. And you can",
      "tokens": [
        50616,
        1315,
        295,
        746,
        11,
        309,
        486,
        5623,
        294,
        439,
        295,
        428,
        6809,
        300,
        291,
        600,
        2942,
        490,
        300,
        13,
        400,
        291,
        393,
        50900
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1847262680530548,
      "compression_ratio": 1.5409835577011108,
      "no_speech_prob": 0.11421696096658707
    },
    {
      "id": 46,
      "seek": 29784,
      "start": 308.55999755859375,
      "end": 314.4800109863281,
      "text": " actually export it to things like PlantUML. That's a very good point, because in the past,",
      "tokens": [
        50900,
        767,
        10725,
        309,
        281,
        721,
        411,
        28995,
        52,
        12683,
        13,
        663,
        311,
        257,
        588,
        665,
        935,
        11,
        570,
        294,
        264,
        1791,
        11,
        51196
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1847262680530548,
      "compression_ratio": 1.5409835577011108,
      "no_speech_prob": 0.11421696096658707
    },
    {
      "id": 47,
      "seek": 29784,
      "start": 314.4800109863281,
      "end": 322.0799865722656,
      "text": " I always said an architect should model and not draw diagrams. And you say the big difference,",
      "tokens": [
        51196,
        286,
        1009,
        848,
        364,
        6331,
        820,
        2316,
        293,
        406,
        2642,
        36709,
        13,
        400,
        291,
        584,
        264,
        955,
        2649,
        11,
        51576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1847262680530548,
      "compression_ratio": 1.5409835577011108,
      "no_speech_prob": 0.11421696096658707
    },
    {
      "id": 48,
      "seek": 32208,
      "start": 322.0799865722656,
      "end": 330.79998779296875,
      "text": " a huge difference between PlantUML and Mermaid versus Structurizer is that with PlantUML and",
      "tokens": [
        50364,
        257,
        2603,
        2649,
        1296,
        28995,
        52,
        12683,
        293,
        376,
        32124,
        5717,
        745,
        1757,
        374,
        6545,
        307,
        300,
        365,
        28995,
        52,
        12683,
        293,
        50800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2403971403837204,
      "compression_ratio": 1.6061947345733643,
      "no_speech_prob": 0.0838070660829544
    },
    {
      "id": 49,
      "seek": 32208,
      "start": 330.79998779296875,
      "end": 337.67999267578125,
      "text": " Mermaid, I draw diagrams, but don't have a model in the background. Yes, but they are,",
      "tokens": [
        50800,
        376,
        32124,
        11,
        286,
        2642,
        36709,
        11,
        457,
        500,
        380,
        362,
        257,
        2316,
        294,
        264,
        3678,
        13,
        1079,
        11,
        457,
        436,
        366,
        11,
        51144
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2403971403837204,
      "compression_ratio": 1.6061947345733643,
      "no_speech_prob": 0.0838070660829544
    },
    {
      "id": 50,
      "seek": 32208,
      "start": 338.32000732421875,
      "end": 343.760009765625,
      "text": " because they are text, they're much easier to maintain than a drawn diagram if you're using,",
      "tokens": [
        51176,
        570,
        436,
        366,
        2487,
        11,
        436,
        434,
        709,
        3571,
        281,
        6909,
        813,
        257,
        10117,
        10686,
        498,
        291,
        434,
        1228,
        11,
        51448
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2403971403837204,
      "compression_ratio": 1.6061947345733643,
      "no_speech_prob": 0.0838070660829544
    },
    {
      "id": 51,
      "seek": 32208,
      "start": 343.760009765625,
      "end": 350.7200012207031,
      "text": " say, Draw.io or Visio or anything else. To maintain those diagrams, you need that specific",
      "tokens": [
        51448,
        584,
        11,
        20386,
        13,
        1004,
        420,
        10410,
        1004,
        420,
        1340,
        1646,
        13,
        1407,
        6909,
        729,
        36709,
        11,
        291,
        643,
        300,
        2685,
        51796
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2403971403837204,
      "compression_ratio": 1.6061947345733643,
      "no_speech_prob": 0.0838070660829544
    },
    {
      "id": 52,
      "seek": 35072,
      "start": 350.7200012207031,
      "end": 355.760009765625,
      "text": " software. If you make a change, you probably have to fiddle around and move things around",
      "tokens": [
        50364,
        4722,
        13,
        759,
        291,
        652,
        257,
        1319,
        11,
        291,
        1391,
        362,
        281,
        24553,
        2285,
        926,
        293,
        1286,
        721,
        926,
        50616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21176394820213318,
      "compression_ratio": 1.7547169923782349,
      "no_speech_prob": 0.04717047140002251
    },
    {
      "id": 53,
      "seek": 35072,
      "start": 356.32000732421875,
      "end": 362.55999755859375,
      "text": " in there. Whereas with the diagrams as code, you can just change a word or add something in,",
      "tokens": [
        50644,
        294,
        456,
        13,
        13813,
        365,
        264,
        36709,
        382,
        3089,
        11,
        291,
        393,
        445,
        1319,
        257,
        1349,
        420,
        909,
        746,
        294,
        11,
        50956
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21176394820213318,
      "compression_ratio": 1.7547169923782349,
      "no_speech_prob": 0.04717047140002251
    },
    {
      "id": 54,
      "seek": 35072,
      "start": 362.55999755859375,
      "end": 367.5199890136719,
      "text": " and it will automatically kind of move things around for you. And you can even, you can keep",
      "tokens": [
        50956,
        293,
        309,
        486,
        6772,
        733,
        295,
        1286,
        721,
        926,
        337,
        291,
        13,
        400,
        291,
        393,
        754,
        11,
        291,
        393,
        1066,
        51204
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21176394820213318,
      "compression_ratio": 1.7547169923782349,
      "no_speech_prob": 0.04717047140002251
    },
    {
      "id": 55,
      "seek": 35072,
      "start": 367.5199890136719,
      "end": 375.6000061035156,
      "text": " your diagrams with your code so that you have them in the same place. But also, you can actually",
      "tokens": [
        51204,
        428,
        36709,
        365,
        428,
        3089,
        370,
        300,
        291,
        362,
        552,
        294,
        264,
        912,
        1081,
        13,
        583,
        611,
        11,
        291,
        393,
        767,
        51608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21176394820213318,
      "compression_ratio": 1.7547169923782349,
      "no_speech_prob": 0.04717047140002251
    },
    {
      "id": 56,
      "seek": 37560,
      "start": 375.6000061035156,
      "end": 381.9200134277344,
      "text": " diff your diagrams and see the differences, because they are text. Whereas, I mean,",
      "tokens": [
        50364,
        7593,
        428,
        36709,
        293,
        536,
        264,
        7300,
        11,
        570,
        436,
        366,
        2487,
        13,
        13813,
        11,
        286,
        914,
        11,
        50680
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26138031482696533,
      "compression_ratio": 1.6028037071228027,
      "no_speech_prob": 0.050321903079748154
    },
    {
      "id": 57,
      "seek": 37560,
      "start": 381.9200134277344,
      "end": 389.760009765625,
      "text": " something like Draw.io does produce a sort of XML style sort of file, but you can't diff that,",
      "tokens": [
        50680,
        746,
        411,
        20386,
        13,
        1004,
        775,
        5258,
        257,
        1333,
        295,
        43484,
        3758,
        1333,
        295,
        3991,
        11,
        457,
        291,
        393,
        380,
        7593,
        300,
        11,
        51072
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26138031482696533,
      "compression_ratio": 1.6028037071228027,
      "no_speech_prob": 0.050321903079748154
    },
    {
      "id": 58,
      "seek": 37560,
      "start": 389.760009765625,
      "end": 393.6000061035156,
      "text": " because it changes in very odd ways. You can't see what the difference is.",
      "tokens": [
        51072,
        570,
        309,
        2962,
        294,
        588,
        7401,
        2098,
        13,
        509,
        393,
        380,
        536,
        437,
        264,
        2649,
        307,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26138031482696533,
      "compression_ratio": 1.6028037071228027,
      "no_speech_prob": 0.050321903079748154
    },
    {
      "id": 59,
      "seek": 37560,
      "start": 394.6400146484375,
      "end": 402.7200012207031,
      "text": " So, I mean, it sounds to me as if we are basically programming diagrams in some language,",
      "tokens": [
        51316,
        407,
        11,
        286,
        914,
        11,
        309,
        3263,
        281,
        385,
        382,
        498,
        321,
        366,
        1936,
        9410,
        36709,
        294,
        512,
        2856,
        11,
        51720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26138031482696533,
      "compression_ratio": 1.6028037071228027,
      "no_speech_prob": 0.050321903079748154
    },
    {
      "id": 60,
      "seek": 40272,
      "start": 402.79998779296875,
      "end": 410.3999938964844,
      "text": " and we use LLMs to support us. So, is that sort of the idea of your workshop and of how you're",
      "tokens": [
        50368,
        293,
        321,
        764,
        441,
        43,
        26386,
        281,
        1406,
        505,
        13,
        407,
        11,
        307,
        300,
        1333,
        295,
        264,
        1558,
        295,
        428,
        13541,
        293,
        295,
        577,
        291,
        434,
        50748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21166087687015533,
      "compression_ratio": 1.621739149093628,
      "no_speech_prob": 0.006178055424243212
    },
    {
      "id": 61,
      "seek": 40272,
      "start": 410.3999938964844,
      "end": 418.4800109863281,
      "text": " using AI there? Yes. So, we need those skills and understanding, but then we can use the LLMs",
      "tokens": [
        50748,
        1228,
        7318,
        456,
        30,
        1079,
        13,
        407,
        11,
        321,
        643,
        729,
        3942,
        293,
        3701,
        11,
        457,
        550,
        321,
        393,
        764,
        264,
        441,
        43,
        26386,
        51152
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21166087687015533,
      "compression_ratio": 1.621739149093628,
      "no_speech_prob": 0.006178055424243212
    },
    {
      "id": 62,
      "seek": 40272,
      "start": 418.4800109863281,
      "end": 424.9599914550781,
      "text": " to help us with that. So, maybe we've got something in PlantUML that we want in Mermaid.",
      "tokens": [
        51152,
        281,
        854,
        505,
        365,
        300,
        13,
        407,
        11,
        1310,
        321,
        600,
        658,
        746,
        294,
        28995,
        52,
        12683,
        300,
        321,
        528,
        294,
        376,
        32124,
        13,
        51476
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21166087687015533,
      "compression_ratio": 1.621739149093628,
      "no_speech_prob": 0.006178055424243212
    },
    {
      "id": 63,
      "seek": 40272,
      "start": 424.9599914550781,
      "end": 431.20001220703125,
      "text": " You can say, give me this PlantUML diagram as Mermaid. And one of the things that I think might",
      "tokens": [
        51476,
        509,
        393,
        584,
        11,
        976,
        385,
        341,
        28995,
        52,
        12683,
        10686,
        382,
        376,
        32124,
        13,
        400,
        472,
        295,
        264,
        721,
        300,
        286,
        519,
        1062,
        51788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21166087687015533,
      "compression_ratio": 1.621739149093628,
      "no_speech_prob": 0.006178055424243212
    },
    {
      "id": 64,
      "seek": 43120,
      "start": 431.20001220703125,
      "end": 437.9200134277344,
      "text": " be particularly useful if you, say, wanted to create a full sort of workspace in Structurizr,",
      "tokens": [
        50364,
        312,
        4098,
        4420,
        498,
        291,
        11,
        584,
        11,
        1415,
        281,
        1884,
        257,
        1577,
        1333,
        295,
        32706,
        294,
        745,
        1757,
        374,
        590,
        81,
        11,
        50700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22755344212055206,
      "compression_ratio": 1.419354796409607,
      "no_speech_prob": 0.02828342095017433
    },
    {
      "id": 65,
      "seek": 43120,
      "start": 437.9200134277344,
      "end": 445.1199951171875,
      "text": " and you've got 100 or even 20 PlantUML or Mermaid C4 diagrams, you could say,",
      "tokens": [
        50700,
        293,
        291,
        600,
        658,
        2319,
        420,
        754,
        945,
        28995,
        52,
        12683,
        420,
        376,
        32124,
        383,
        19,
        36709,
        11,
        291,
        727,
        584,
        11,
        51060
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22755344212055206,
      "compression_ratio": 1.419354796409607,
      "no_speech_prob": 0.02828342095017433
    },
    {
      "id": 66,
      "seek": 43120,
      "start": 445.1199951171875,
      "end": 454.8800048828125,
      "text": " here are all my diagrams, create a workspace from them, or better still, manage your context",
      "tokens": [
        51060,
        510,
        366,
        439,
        452,
        36709,
        11,
        1884,
        257,
        32706,
        490,
        552,
        11,
        420,
        1101,
        920,
        11,
        3067,
        428,
        4319,
        51548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22755344212055206,
      "compression_ratio": 1.419354796409607,
      "no_speech_prob": 0.02828342095017433
    },
    {
      "id": 67,
      "seek": 45488,
      "start": 454.8800048828125,
      "end": 461.8399963378906,
      "text": " and give it sort of the main ones first and then add extra ones in. It does vary as to,",
      "tokens": [
        50364,
        293,
        976,
        309,
        1333,
        295,
        264,
        2135,
        2306,
        700,
        293,
        550,
        909,
        2857,
        2306,
        294,
        13,
        467,
        775,
        10559,
        382,
        281,
        11,
        50712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2337239533662796,
      "compression_ratio": 1.5677965879440308,
      "no_speech_prob": 0.0850588008761406
    },
    {
      "id": 68,
      "seek": 45488,
      "start": 462.4800109863281,
      "end": 468.6400146484375,
      "text": " you've got to experiment with the different models as to which will actually know enough",
      "tokens": [
        50744,
        291,
        600,
        658,
        281,
        5120,
        365,
        264,
        819,
        5245,
        382,
        281,
        597,
        486,
        767,
        458,
        1547,
        51052
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2337239533662796,
      "compression_ratio": 1.5677965879440308,
      "no_speech_prob": 0.0850588008761406
    },
    {
      "id": 69,
      "seek": 45488,
      "start": 468.6400146484375,
      "end": 477.44000244140625,
      "text": " about things like Structurizr. But you said, I mean, obviously LLMs have hallucinations or tend",
      "tokens": [
        51052,
        466,
        721,
        411,
        745,
        1757,
        374,
        590,
        81,
        13,
        583,
        291,
        848,
        11,
        286,
        914,
        11,
        2745,
        441,
        43,
        26386,
        362,
        35212,
        10325,
        420,
        3928,
        51492
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2337239533662796,
      "compression_ratio": 1.5677965879440308,
      "no_speech_prob": 0.0850588008761406
    },
    {
      "id": 70,
      "seek": 45488,
      "start": 477.44000244140625,
      "end": 484.7200012207031,
      "text": " to create hallucinations. So, is it really useful or what's your experience? So, how useful is it",
      "tokens": [
        51492,
        281,
        1884,
        35212,
        10325,
        13,
        407,
        11,
        307,
        309,
        534,
        4420,
        420,
        437,
        311,
        428,
        1752,
        30,
        407,
        11,
        577,
        4420,
        307,
        309,
        51856
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2337239533662796,
      "compression_ratio": 1.5677965879440308,
      "no_speech_prob": 0.0850588008761406
    },
    {
      "id": 71,
      "seek": 48472,
      "start": 484.7200012207031,
      "end": 490.6400146484375,
      "text": " to have an LLM do these kinds of conversion work? Because, I mean, if there are too many",
      "tokens": [
        50364,
        281,
        362,
        364,
        441,
        43,
        44,
        360,
        613,
        3685,
        295,
        14298,
        589,
        30,
        1436,
        11,
        286,
        914,
        11,
        498,
        456,
        366,
        886,
        867,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2061239629983902,
      "compression_ratio": 1.5635592937469482,
      "no_speech_prob": 0.00914341863244772
    },
    {
      "id": 72,
      "seek": 48472,
      "start": 490.6400146484375,
      "end": 496.239990234375,
      "text": " hallucinations, you're better off doing it yourself, maybe. Yeah, it varies depending on",
      "tokens": [
        50660,
        35212,
        10325,
        11,
        291,
        434,
        1101,
        766,
        884,
        309,
        1803,
        11,
        1310,
        13,
        865,
        11,
        309,
        21716,
        5413,
        322,
        50940
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2061239629983902,
      "compression_ratio": 1.5635592937469482,
      "no_speech_prob": 0.00914341863244772
    },
    {
      "id": 73,
      "seek": 48472,
      "start": 496.239990234375,
      "end": 504.32000732421875,
      "text": " what you ask it to do. So, if you, one of the examples I use is I've got an activity diagram",
      "tokens": [
        50940,
        437,
        291,
        1029,
        309,
        281,
        360,
        13,
        407,
        11,
        498,
        291,
        11,
        472,
        295,
        264,
        5110,
        286,
        764,
        307,
        286,
        600,
        658,
        364,
        5191,
        10686,
        51344
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2061239629983902,
      "compression_ratio": 1.5635592937469482,
      "no_speech_prob": 0.00914341863244772
    },
    {
      "id": 74,
      "seek": 48472,
      "start": 504.32000732421875,
      "end": 510.32000732421875,
      "text": " and there are, the sequence means that there are a couple of items that are on the left-hand side.",
      "tokens": [
        51344,
        293,
        456,
        366,
        11,
        264,
        8310,
        1355,
        300,
        456,
        366,
        257,
        1916,
        295,
        4754,
        300,
        366,
        322,
        264,
        1411,
        12,
        5543,
        1252,
        13,
        51644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2061239629983902,
      "compression_ratio": 1.5635592937469482,
      "no_speech_prob": 0.00914341863244772
    },
    {
      "id": 75,
      "seek": 51032,
      "start": 510.8800048828125,
      "end": 516.0,
      "text": " And if you want to move them to the right-hand side, it's a little bit of work to change things",
      "tokens": [
        50392,
        400,
        498,
        291,
        528,
        281,
        1286,
        552,
        281,
        264,
        558,
        12,
        5543,
        1252,
        11,
        309,
        311,
        257,
        707,
        857,
        295,
        589,
        281,
        1319,
        721,
        50648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1861066073179245,
      "compression_ratio": 1.7366411685943604,
      "no_speech_prob": 0.04097626730799675
    },
    {
      "id": 76,
      "seek": 51032,
      "start": 516.0,
      "end": 521.5999755859375,
      "text": " round and reorder things. If you ask the LLM to move them from the left to the right,",
      "tokens": [
        50648,
        3098,
        293,
        319,
        4687,
        721,
        13,
        759,
        291,
        1029,
        264,
        441,
        43,
        44,
        281,
        1286,
        552,
        490,
        264,
        1411,
        281,
        264,
        558,
        11,
        50928
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1861066073179245,
      "compression_ratio": 1.7366411685943604,
      "no_speech_prob": 0.04097626730799675
    },
    {
      "id": 77,
      "seek": 51032,
      "start": 522.1599731445312,
      "end": 527.1199951171875,
      "text": " it will go and make up some random syntax. I've seen it do this twice where it said,",
      "tokens": [
        50956,
        309,
        486,
        352,
        293,
        652,
        493,
        512,
        4974,
        28431,
        13,
        286,
        600,
        1612,
        309,
        360,
        341,
        6091,
        689,
        309,
        848,
        11,
        51204
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1861066073179245,
      "compression_ratio": 1.7366411685943604,
      "no_speech_prob": 0.04097626730799675
    },
    {
      "id": 78,
      "seek": 51032,
      "start": 527.1199951171875,
      "end": 532.9600219726562,
      "text": " oh, you can use this little arrow and it will shift stuff over. And you look at the diagram",
      "tokens": [
        51204,
        1954,
        11,
        291,
        393,
        764,
        341,
        707,
        11610,
        293,
        309,
        486,
        5513,
        1507,
        670,
        13,
        400,
        291,
        574,
        412,
        264,
        10686,
        51496
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1861066073179245,
      "compression_ratio": 1.7366411685943604,
      "no_speech_prob": 0.04097626730799675
    },
    {
      "id": 79,
      "seek": 51032,
      "start": 532.9600219726562,
      "end": 537.5999755859375,
      "text": " it produces and it's just got these little funny arrows in front of your text. But if you say to",
      "tokens": [
        51496,
        309,
        14725,
        293,
        309,
        311,
        445,
        658,
        613,
        707,
        4074,
        19669,
        294,
        1868,
        295,
        428,
        2487,
        13,
        583,
        498,
        291,
        584,
        281,
        51728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1861066073179245,
      "compression_ratio": 1.7366411685943604,
      "no_speech_prob": 0.04097626730799675
    },
    {
      "id": 80,
      "seek": 53760,
      "start": 538.0800170898438,
      "end": 545.5999755859375,
      "text": " reorder the elements so that these two items will appear on the right, it can do it. So,",
      "tokens": [
        50388,
        319,
        4687,
        264,
        4959,
        370,
        300,
        613,
        732,
        4754,
        486,
        4204,
        322,
        264,
        558,
        11,
        309,
        393,
        360,
        309,
        13,
        407,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22931531071662903,
      "compression_ratio": 1.5195530652999878,
      "no_speech_prob": 0.026296185329556465
    },
    {
      "id": 81,
      "seek": 53760,
      "start": 546.47998046875,
      "end": 551.280029296875,
      "text": " you have to have that knowledge of what you want it to do and be very specific about it.",
      "tokens": [
        50808,
        291,
        362,
        281,
        362,
        300,
        3601,
        295,
        437,
        291,
        528,
        309,
        281,
        360,
        293,
        312,
        588,
        2685,
        466,
        309,
        13,
        51048
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22931531071662903,
      "compression_ratio": 1.5195530652999878,
      "no_speech_prob": 0.026296185329556465
    },
    {
      "id": 82,
      "seek": 53760,
      "start": 552.5599975585938,
      "end": 561.1199951171875,
      "text": " Okay. And you talked about how you are educating people with the skills they need to use these",
      "tokens": [
        51112,
        1033,
        13,
        400,
        291,
        2825,
        466,
        577,
        291,
        366,
        28835,
        561,
        365,
        264,
        3942,
        436,
        643,
        281,
        764,
        613,
        51540
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22931531071662903,
      "compression_ratio": 1.5195530652999878,
      "no_speech_prob": 0.026296185329556465
    },
    {
      "id": 83,
      "seek": 56112,
      "start": 561.2000122070312,
      "end": 569.3599853515625,
      "text": " technologies. So, I think I sort of took a note that the people need to be aware of hallucinations.",
      "tokens": [
        50368,
        7943,
        13,
        407,
        11,
        286,
        519,
        286,
        1333,
        295,
        1890,
        257,
        3637,
        300,
        264,
        561,
        643,
        281,
        312,
        3650,
        295,
        35212,
        10325,
        13,
        50776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2018241286277771,
      "compression_ratio": 1.5351351499557495,
      "no_speech_prob": 0.19399626553058624
    },
    {
      "id": 84,
      "seek": 56112,
      "start": 569.3599853515625,
      "end": 577.280029296875,
      "text": " That's one skill. Is that true? Or what kind of skills are you trying to teach the people in that",
      "tokens": [
        50776,
        663,
        311,
        472,
        5389,
        13,
        1119,
        300,
        2074,
        30,
        1610,
        437,
        733,
        295,
        3942,
        366,
        291,
        1382,
        281,
        2924,
        264,
        561,
        294,
        300,
        51172
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2018241286277771,
      "compression_ratio": 1.5351351499557495,
      "no_speech_prob": 0.19399626553058624
    },
    {
      "id": 85,
      "seek": 56112,
      "start": 577.280029296875,
      "end": 584.47998046875,
      "text": " workshop? So, I'm trying to give them a few different skills. The one is to understand",
      "tokens": [
        51172,
        13541,
        30,
        407,
        11,
        286,
        478,
        1382,
        281,
        976,
        552,
        257,
        1326,
        819,
        3942,
        13,
        440,
        472,
        307,
        281,
        1223,
        51532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2018241286277771,
      "compression_ratio": 1.5351351499557495,
      "no_speech_prob": 0.19399626553058624
    },
    {
      "id": 86,
      "seek": 58448,
      "start": 584.5599975585938,
      "end": 591.5999755859375,
      "text": " the pros and cons of the different diagrams as code. So, I chose PlantUML, Mermaid and Structurizer",
      "tokens": [
        50368,
        264,
        6267,
        293,
        1014,
        295,
        264,
        819,
        36709,
        382,
        3089,
        13,
        407,
        11,
        286,
        5111,
        28995,
        52,
        12683,
        11,
        376,
        32124,
        293,
        745,
        1757,
        374,
        6545,
        50720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23541145026683807,
      "compression_ratio": 1.5860655307769775,
      "no_speech_prob": 0.24425192177295685
    },
    {
      "id": 87,
      "seek": 58448,
      "start": 591.5999755859375,
      "end": 596.3200073242188,
      "text": " because they're some of the most popular ones. There's a few more out there. There's one called",
      "tokens": [
        50720,
        570,
        436,
        434,
        512,
        295,
        264,
        881,
        3743,
        2306,
        13,
        821,
        311,
        257,
        1326,
        544,
        484,
        456,
        13,
        821,
        311,
        472,
        1219,
        50956
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23541145026683807,
      "compression_ratio": 1.5860655307769775,
      "no_speech_prob": 0.24425192177295685
    },
    {
      "id": 88,
      "seek": 58448,
      "start": 596.3200073242188,
      "end": 605.52001953125,
      "text": " D2, which is quite young. So, a lot of people won't have used that one yet. So, it's worth looking at",
      "tokens": [
        50956,
        413,
        17,
        11,
        597,
        307,
        1596,
        2037,
        13,
        407,
        11,
        257,
        688,
        295,
        561,
        1582,
        380,
        362,
        1143,
        300,
        472,
        1939,
        13,
        407,
        11,
        309,
        311,
        3163,
        1237,
        412,
        51416
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23541145026683807,
      "compression_ratio": 1.5860655307769775,
      "no_speech_prob": 0.24425192177295685
    },
    {
      "id": 89,
      "seek": 58448,
      "start": 605.52001953125,
      "end": 609.8400268554688,
      "text": " other ones as well. But these ones being the most popular, a lot of companies are already",
      "tokens": [
        51416,
        661,
        2306,
        382,
        731,
        13,
        583,
        613,
        2306,
        885,
        264,
        881,
        3743,
        11,
        257,
        688,
        295,
        3431,
        366,
        1217,
        51632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23541145026683807,
      "compression_ratio": 1.5860655307769775,
      "no_speech_prob": 0.24425192177295685
    },
    {
      "id": 90,
      "seek": 60984,
      "start": 609.8400268554688,
      "end": 616.6400146484375,
      "text": " using probably one of these. And so, you can go back to your company and assess,",
      "tokens": [
        50364,
        1228,
        1391,
        472,
        295,
        613,
        13,
        400,
        370,
        11,
        291,
        393,
        352,
        646,
        281,
        428,
        2237,
        293,
        5877,
        11,
        50704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19213517010211945,
      "compression_ratio": 1.5580357313156128,
      "no_speech_prob": 0.04623314365744591
    },
    {
      "id": 91,
      "seek": 60984,
      "start": 616.6400146484375,
      "end": 622.7999877929688,
      "text": " is this the right thing to do? Could we add something in that would help us with this as",
      "tokens": [
        50704,
        307,
        341,
        264,
        558,
        551,
        281,
        360,
        30,
        7497,
        321,
        909,
        746,
        294,
        300,
        576,
        854,
        505,
        365,
        341,
        382,
        51012
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19213517010211945,
      "compression_ratio": 1.5580357313156128,
      "no_speech_prob": 0.04623314365744591
    },
    {
      "id": 92,
      "seek": 60984,
      "start": 622.7999877929688,
      "end": 630.4000244140625,
      "text": " well? And so, we've got that, okay, what's the best tool to use in my particular situation?",
      "tokens": [
        51012,
        731,
        30,
        400,
        370,
        11,
        321,
        600,
        658,
        300,
        11,
        1392,
        11,
        437,
        311,
        264,
        1151,
        2290,
        281,
        764,
        294,
        452,
        1729,
        2590,
        30,
        51392
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19213517010211945,
      "compression_ratio": 1.5580357313156128,
      "no_speech_prob": 0.04623314365744591
    },
    {
      "id": 93,
      "seek": 60984,
      "start": 630.4000244140625,
      "end": 635.6799926757812,
      "text": " When people say, oh, but we only use Mermaid here. You can't use PlantUML. You can say,",
      "tokens": [
        51392,
        1133,
        561,
        584,
        11,
        1954,
        11,
        457,
        321,
        787,
        764,
        376,
        32124,
        510,
        13,
        509,
        393,
        380,
        764,
        28995,
        52,
        12683,
        13,
        509,
        393,
        584,
        11,
        51656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19213517010211945,
      "compression_ratio": 1.5580357313156128,
      "no_speech_prob": 0.04623314365744591
    },
    {
      "id": 94,
      "seek": 63568,
      "start": 636.4000244140625,
      "end": 640.9600219726562,
      "text": " you can actually back up your argument and say, we need to use it because I can't use Mermaid for",
      "tokens": [
        50400,
        291,
        393,
        767,
        646,
        493,
        428,
        6770,
        293,
        584,
        11,
        321,
        643,
        281,
        764,
        309,
        570,
        286,
        393,
        380,
        764,
        376,
        32124,
        337,
        50628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.182719886302948,
      "compression_ratio": 1.5672268867492676,
      "no_speech_prob": 0.04573262110352516
    },
    {
      "id": 95,
      "seek": 63568,
      "start": 640.9600219726562,
      "end": 647.4400024414062,
      "text": " this. Right, okay. Like if you're doing C4 diagrams, you can use PlantUML. That's quite",
      "tokens": [
        50628,
        341,
        13,
        1779,
        11,
        1392,
        13,
        1743,
        498,
        291,
        434,
        884,
        383,
        19,
        36709,
        11,
        291,
        393,
        764,
        28995,
        52,
        12683,
        13,
        663,
        311,
        1596,
        50952
      ],
      "temperature": 0.0,
      "avg_logprob": -0.182719886302948,
      "compression_ratio": 1.5672268867492676,
      "no_speech_prob": 0.04573262110352516
    },
    {
      "id": 96,
      "seek": 63568,
      "start": 647.4400024414062,
      "end": 655.4400024414062,
      "text": " good. Mermaid really doesn't work very well for C4 diagrams at the moment. So, you may be thinking,",
      "tokens": [
        50952,
        665,
        13,
        376,
        32124,
        534,
        1177,
        380,
        589,
        588,
        731,
        337,
        383,
        19,
        36709,
        412,
        264,
        1623,
        13,
        407,
        11,
        291,
        815,
        312,
        1953,
        11,
        51352
      ],
      "temperature": 0.0,
      "avg_logprob": -0.182719886302948,
      "compression_ratio": 1.5672268867492676,
      "no_speech_prob": 0.04573262110352516
    },
    {
      "id": 97,
      "seek": 63568,
      "start": 655.4400024414062,
      "end": 660.4000244140625,
      "text": " okay, if we're not going to use Structurizer, we should probably use PlantUML for that.",
      "tokens": [
        51352,
        1392,
        11,
        498,
        321,
        434,
        406,
        516,
        281,
        764,
        745,
        1757,
        374,
        6545,
        11,
        321,
        820,
        1391,
        764,
        28995,
        52,
        12683,
        337,
        300,
        13,
        51600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.182719886302948,
      "compression_ratio": 1.5672268867492676,
      "no_speech_prob": 0.04573262110352516
    },
    {
      "id": 98,
      "seek": 66040,
      "start": 660.4000244140625,
      "end": 663.52001953125,
      "text": " Or they're all open source, so we can all go and fix it.",
      "tokens": [
        50364,
        1610,
        436,
        434,
        439,
        1269,
        4009,
        11,
        370,
        321,
        393,
        439,
        352,
        293,
        3191,
        309,
        13,
        50520
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20690765976905823,
      "compression_ratio": 1.593908667564392,
      "no_speech_prob": 0.007115723565220833
    },
    {
      "id": 99,
      "seek": 66040,
      "start": 664.6400146484375,
      "end": 671.1199951171875,
      "text": " So, you already mentioned that different libraries support different diagram types. So,",
      "tokens": [
        50576,
        407,
        11,
        291,
        1217,
        2835,
        300,
        819,
        15148,
        1406,
        819,
        10686,
        3467,
        13,
        407,
        11,
        50900
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20690765976905823,
      "compression_ratio": 1.593908667564392,
      "no_speech_prob": 0.007115723565220833
    },
    {
      "id": 100,
      "seek": 66040,
      "start": 671.1199951171875,
      "end": 678.5599975585938,
      "text": " this could be one criterion to select a library. But you also mentioned that",
      "tokens": [
        50900,
        341,
        727,
        312,
        472,
        46691,
        281,
        3048,
        257,
        6405,
        13,
        583,
        291,
        611,
        2835,
        300,
        51272
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20690765976905823,
      "compression_ratio": 1.593908667564392,
      "no_speech_prob": 0.007115723565220833
    },
    {
      "id": 101,
      "seek": 66040,
      "start": 679.52001953125,
      "end": 684.9600219726562,
      "text": " a Mermaid is supported by web-based frontends. I guess it's just a frontend library and will",
      "tokens": [
        51320,
        257,
        376,
        32124,
        307,
        8104,
        538,
        3670,
        12,
        6032,
        1868,
        2581,
        13,
        286,
        2041,
        309,
        311,
        445,
        257,
        1868,
        521,
        6405,
        293,
        486,
        51592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20690765976905823,
      "compression_ratio": 1.593908667564392,
      "no_speech_prob": 0.007115723565220833
    },
    {
      "id": 102,
      "seek": 68496,
      "start": 684.9600219726562,
      "end": 695.6799926757812,
      "text": " be rendered on the client side. So, do you have some more criteria to choose the right",
      "tokens": [
        50364,
        312,
        28748,
        322,
        264,
        6423,
        1252,
        13,
        407,
        11,
        360,
        291,
        362,
        512,
        544,
        11101,
        281,
        2826,
        264,
        558,
        50900
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18398436903953552,
      "compression_ratio": 1.5120773315429688,
      "no_speech_prob": 0.04597559571266174
    },
    {
      "id": 103,
      "seek": 68496,
      "start": 695.6799926757812,
      "end": 700.719970703125,
      "text": " library? What would be your first approach to select?",
      "tokens": [
        50900,
        6405,
        30,
        708,
        576,
        312,
        428,
        700,
        3109,
        281,
        3048,
        30,
        51152
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18398436903953552,
      "compression_ratio": 1.5120773315429688,
      "no_speech_prob": 0.04597559571266174
    },
    {
      "id": 104,
      "seek": 68496,
      "start": 701.8400268554688,
      "end": 705.5999755859375,
      "text": " Yeah, there's quite a few different things to look at. So, as you said,",
      "tokens": [
        51208,
        865,
        11,
        456,
        311,
        1596,
        257,
        1326,
        819,
        721,
        281,
        574,
        412,
        13,
        407,
        11,
        382,
        291,
        848,
        11,
        51396
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18398436903953552,
      "compression_ratio": 1.5120773315429688,
      "no_speech_prob": 0.04597559571266174
    },
    {
      "id": 105,
      "seek": 68496,
      "start": 706.4000244140625,
      "end": 713.9199829101562,
      "text": " what type of diagram do I need? And sometimes you say, I definitely need a sequence diagram for this",
      "tokens": [
        51436,
        437,
        2010,
        295,
        10686,
        360,
        286,
        643,
        30,
        400,
        2171,
        291,
        584,
        11,
        286,
        2138,
        643,
        257,
        8310,
        10686,
        337,
        341,
        51812
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18398436903953552,
      "compression_ratio": 1.5120773315429688,
      "no_speech_prob": 0.04597559571266174
    },
    {
      "id": 106,
      "seek": 71392,
      "start": 713.9199829101562,
      "end": 717.8400268554688,
      "text": " and there's nothing else that I'm going to look at. But maybe you think, oh, wait a minute,",
      "tokens": [
        50364,
        293,
        456,
        311,
        1825,
        1646,
        300,
        286,
        478,
        516,
        281,
        574,
        412,
        13,
        583,
        1310,
        291,
        519,
        11,
        1954,
        11,
        1699,
        257,
        3456,
        11,
        50560
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18511074781417847,
      "compression_ratio": 1.778210163116455,
      "no_speech_prob": 0.008015133440494537
    },
    {
      "id": 107,
      "seek": 71392,
      "start": 717.8400268554688,
      "end": 723.4400024414062,
      "text": " maybe I could use a flowchart. So, you can look at the different types that are supported.",
      "tokens": [
        50560,
        1310,
        286,
        727,
        764,
        257,
        3095,
        339,
        446,
        13,
        407,
        11,
        291,
        393,
        574,
        412,
        264,
        819,
        3467,
        300,
        366,
        8104,
        13,
        50840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18511074781417847,
      "compression_ratio": 1.778210163116455,
      "no_speech_prob": 0.008015133440494537
    },
    {
      "id": 108,
      "seek": 71392,
      "start": 724.4000244140625,
      "end": 728.47998046875,
      "text": " Maybe you need something a bit more complex. So, you need to look at an activity diagram,",
      "tokens": [
        50888,
        2704,
        291,
        643,
        746,
        257,
        857,
        544,
        3997,
        13,
        407,
        11,
        291,
        643,
        281,
        574,
        412,
        364,
        5191,
        10686,
        11,
        51092
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18511074781417847,
      "compression_ratio": 1.778210163116455,
      "no_speech_prob": 0.008015133440494537
    },
    {
      "id": 109,
      "seek": 71392,
      "start": 728.47998046875,
      "end": 734.9600219726562,
      "text": " which is something that PlantUML supports. So, that's like a flowchart plus plus. It's got",
      "tokens": [
        51092,
        597,
        307,
        746,
        300,
        28995,
        52,
        12683,
        9346,
        13,
        407,
        11,
        300,
        311,
        411,
        257,
        3095,
        339,
        446,
        1804,
        1804,
        13,
        467,
        311,
        658,
        51416
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18511074781417847,
      "compression_ratio": 1.778210163116455,
      "no_speech_prob": 0.008015133440494537
    },
    {
      "id": 110,
      "seek": 71392,
      "start": 734.9600219726562,
      "end": 741.2000122070312,
      "text": " extra things that you can have. You can create forks so that you've got different things that",
      "tokens": [
        51416,
        2857,
        721,
        300,
        291,
        393,
        362,
        13,
        509,
        393,
        1884,
        337,
        1694,
        370,
        300,
        291,
        600,
        658,
        819,
        721,
        300,
        51728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18511074781417847,
      "compression_ratio": 1.778210163116455,
      "no_speech_prob": 0.008015133440494537
    },
    {
      "id": 111,
      "seek": 74120,
      "start": 741.2000122070312,
      "end": 746.6400146484375,
      "text": " are happening and they don't have to happen in a certain sequence, but they all have to happen",
      "tokens": [
        50364,
        366,
        2737,
        293,
        436,
        500,
        380,
        362,
        281,
        1051,
        294,
        257,
        1629,
        8310,
        11,
        457,
        436,
        439,
        362,
        281,
        1051,
        50636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1954222172498703,
      "compression_ratio": 1.654008388519287,
      "no_speech_prob": 0.054736025631427765
    },
    {
      "id": 112,
      "seek": 74120,
      "start": 746.6400146484375,
      "end": 751.5999755859375,
      "text": " before you can then move on. So, if you need things like that, then you know I need this specific",
      "tokens": [
        50636,
        949,
        291,
        393,
        550,
        1286,
        322,
        13,
        407,
        11,
        498,
        291,
        643,
        721,
        411,
        300,
        11,
        550,
        291,
        458,
        286,
        643,
        341,
        2685,
        50884
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1954222172498703,
      "compression_ratio": 1.654008388519287,
      "no_speech_prob": 0.054736025631427765
    },
    {
      "id": 113,
      "seek": 74120,
      "start": 751.5999755859375,
      "end": 757.5999755859375,
      "text": " diagram. The other thing to think about is what's your organization using now? Because if more than",
      "tokens": [
        50884,
        10686,
        13,
        440,
        661,
        551,
        281,
        519,
        466,
        307,
        437,
        311,
        428,
        4475,
        1228,
        586,
        30,
        1436,
        498,
        544,
        813,
        51184
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1954222172498703,
      "compression_ratio": 1.654008388519287,
      "no_speech_prob": 0.054736025631427765
    },
    {
      "id": 114,
      "seek": 74120,
      "start": 757.5999755859375,
      "end": 763.0399780273438,
      "text": " one of them support it, then it's probably better to go with what people know and what will fit in.",
      "tokens": [
        51184,
        472,
        295,
        552,
        1406,
        309,
        11,
        550,
        309,
        311,
        1391,
        1101,
        281,
        352,
        365,
        437,
        561,
        458,
        293,
        437,
        486,
        3318,
        294,
        13,
        51456
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1954222172498703,
      "compression_ratio": 1.654008388519287,
      "no_speech_prob": 0.054736025631427765
    },
    {
      "id": 115,
      "seek": 76304,
      "start": 763.9199829101562,
      "end": 770.8800048828125,
      "text": " If you're using Markdown or something that supports mermaid diagrams,",
      "tokens": [
        50408,
        759,
        291,
        434,
        1228,
        3934,
        5093,
        420,
        746,
        300,
        9346,
        43146,
        36709,
        11,
        50756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2723388969898224,
      "compression_ratio": 1.6545454263687134,
      "no_speech_prob": 0.14418219029903412
    },
    {
      "id": 116,
      "seek": 76304,
      "start": 772.5599975585938,
      "end": 777.2000122070312,
      "text": " if your knowledge management supports rendering of mermaid diagrams, then that's probably something",
      "tokens": [
        50840,
        498,
        428,
        3601,
        4592,
        9346,
        22407,
        295,
        43146,
        36709,
        11,
        550,
        300,
        311,
        1391,
        746,
        51072
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2723388969898224,
      "compression_ratio": 1.6545454263687134,
      "no_speech_prob": 0.14418219029903412
    },
    {
      "id": 117,
      "seek": 76304,
      "start": 777.2000122070312,
      "end": 785.2000122070312,
      "text": " to look at. So, there's lots of different things and I go into more detail in some of the pros and",
      "tokens": [
        51072,
        281,
        574,
        412,
        13,
        407,
        11,
        456,
        311,
        3195,
        295,
        819,
        721,
        293,
        286,
        352,
        666,
        544,
        2607,
        294,
        512,
        295,
        264,
        6267,
        293,
        51472
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2723388969898224,
      "compression_ratio": 1.6545454263687134,
      "no_speech_prob": 0.14418219029903412
    },
    {
      "id": 118,
      "seek": 76304,
      "start": 785.2000122070312,
      "end": 790.6400146484375,
      "text": " cons. You can even look at the â€“ they're all open source, but they're all different licenses.",
      "tokens": [
        51472,
        1014,
        13,
        509,
        393,
        754,
        574,
        412,
        264,
        1662,
        436,
        434,
        439,
        1269,
        4009,
        11,
        457,
        436,
        434,
        439,
        819,
        32821,
        13,
        51744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2723388969898224,
      "compression_ratio": 1.6545454263687134,
      "no_speech_prob": 0.14418219029903412
    },
    {
      "id": 119,
      "seek": 79064,
      "start": 790.6400146484375,
      "end": 794.47998046875,
      "text": " So, maybe your company says we can't use anything with this license. So, then that's",
      "tokens": [
        50364,
        407,
        11,
        1310,
        428,
        2237,
        1619,
        321,
        393,
        380,
        764,
        1340,
        365,
        341,
        10476,
        13,
        407,
        11,
        550,
        300,
        311,
        50556
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2071102410554886,
      "compression_ratio": 1.5864979028701782,
      "no_speech_prob": 0.006092629861086607
    },
    {
      "id": 120,
      "seek": 79064,
      "start": 794.47998046875,
      "end": 802.6400146484375,
      "text": " ruled out, isn't it? There's an awful lot to look at. So, any more skills that come to mind that you",
      "tokens": [
        50556,
        20077,
        484,
        11,
        1943,
        380,
        309,
        30,
        821,
        311,
        364,
        11232,
        688,
        281,
        574,
        412,
        13,
        407,
        11,
        604,
        544,
        3942,
        300,
        808,
        281,
        1575,
        300,
        291,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2071102410554886,
      "compression_ratio": 1.5864979028701782,
      "no_speech_prob": 0.006092629861086607
    },
    {
      "id": 121,
      "seek": 79064,
      "start": 802.6400146484375,
      "end": 811.5999755859375,
      "text": " want to teach people or that are important to use diagrams as code with AI? So, in my book",
      "tokens": [
        50964,
        528,
        281,
        2924,
        561,
        420,
        300,
        366,
        1021,
        281,
        764,
        36709,
        382,
        3089,
        365,
        7318,
        30,
        407,
        11,
        294,
        452,
        1446,
        51412
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2071102410554886,
      "compression_ratio": 1.5864979028701782,
      "no_speech_prob": 0.006092629861086607
    },
    {
      "id": 122,
      "seek": 79064,
      "start": 811.5999755859375,
      "end": 817.760009765625,
      "text": " Communication Patterns, I teach a lot of different patterns and anti-patterns for getting diagrams,",
      "tokens": [
        51412,
        34930,
        34367,
        3695,
        11,
        286,
        2924,
        257,
        688,
        295,
        819,
        8294,
        293,
        6061,
        12,
        79,
        1161,
        3695,
        337,
        1242,
        36709,
        11,
        51720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2071102410554886,
      "compression_ratio": 1.5864979028701782,
      "no_speech_prob": 0.006092629861086607
    },
    {
      "id": 123,
      "seek": 81776,
      "start": 818.47998046875,
      "end": 825.1199951171875,
      "text": " the whole part ones about diagrams. So, getting these diagrams to be understood by people.",
      "tokens": [
        50400,
        264,
        1379,
        644,
        2306,
        466,
        36709,
        13,
        407,
        11,
        1242,
        613,
        36709,
        281,
        312,
        7320,
        538,
        561,
        13,
        50732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22989991307258606,
      "compression_ratio": 1.5224719047546387,
      "no_speech_prob": 0.010428138077259064
    },
    {
      "id": 124,
      "seek": 81776,
      "start": 825.1199951171875,
      "end": 832.47998046875,
      "text": " And actually, diagrams as code can help with a lot of that. So, it will automatically",
      "tokens": [
        50732,
        400,
        767,
        11,
        36709,
        382,
        3089,
        393,
        854,
        365,
        257,
        688,
        295,
        300,
        13,
        407,
        11,
        309,
        486,
        6772,
        51100
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22989991307258606,
      "compression_ratio": 1.5224719047546387,
      "no_speech_prob": 0.010428138077259064
    },
    {
      "id": 125,
      "seek": 81776,
      "start": 832.47998046875,
      "end": 840.9600219726562,
      "text": " render things in a certain way and it allows you to put in things like a title. It has ways of",
      "tokens": [
        51100,
        15529,
        721,
        294,
        257,
        1629,
        636,
        293,
        309,
        4045,
        291,
        281,
        829,
        294,
        721,
        411,
        257,
        4876,
        13,
        467,
        575,
        2098,
        295,
        51524
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22989991307258606,
      "compression_ratio": 1.5224719047546387,
      "no_speech_prob": 0.010428138077259064
    },
    {
      "id": 126,
      "seek": 84096,
      "start": 840.9600219726562,
      "end": 847.5999755859375,
      "text": " putting in all the labels and things, but it doesn't force you to. So, you still",
      "tokens": [
        50364,
        3372,
        294,
        439,
        264,
        16949,
        293,
        721,
        11,
        457,
        309,
        1177,
        380,
        3464,
        291,
        281,
        13,
        407,
        11,
        291,
        920,
        50696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1947215348482132,
      "compression_ratio": 1.5199999809265137,
      "no_speech_prob": 0.07871972769498825
    },
    {
      "id": 127,
      "seek": 84096,
      "start": 848.239990234375,
      "end": 853.6799926757812,
      "text": " kind of need to know like, yes, I should be definitely using labels. Yes, I should be",
      "tokens": [
        50728,
        733,
        295,
        643,
        281,
        458,
        411,
        11,
        2086,
        11,
        286,
        820,
        312,
        2138,
        1228,
        16949,
        13,
        1079,
        11,
        286,
        820,
        312,
        51000
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1947215348482132,
      "compression_ratio": 1.5199999809265137,
      "no_speech_prob": 0.07871972769498825
    },
    {
      "id": 128,
      "seek": 84096,
      "start": 853.6799926757812,
      "end": 864.0,
      "text": " using a title. The one big thing that especially mermaid falls down on is having a legend or a key.",
      "tokens": [
        51000,
        1228,
        257,
        4876,
        13,
        440,
        472,
        955,
        551,
        300,
        2318,
        43146,
        8804,
        760,
        322,
        307,
        1419,
        257,
        9451,
        420,
        257,
        2141,
        13,
        51516
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1947215348482132,
      "compression_ratio": 1.5199999809265137,
      "no_speech_prob": 0.07871972769498825
    },
    {
      "id": 129,
      "seek": 86400,
      "start": 864.0,
      "end": 872.6400146484375,
      "text": " And you can tell that I'm big on legends. I've got a t-shirt for it. And the fact that mermaid",
      "tokens": [
        50364,
        400,
        291,
        393,
        980,
        300,
        286,
        478,
        955,
        322,
        27695,
        13,
        286,
        600,
        658,
        257,
        256,
        12,
        15313,
        337,
        309,
        13,
        400,
        264,
        1186,
        300,
        43146,
        50796
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20115290582180023,
      "compression_ratio": 1.5774058103561401,
      "no_speech_prob": 0.10632263869047165
    },
    {
      "id": 130,
      "seek": 86400,
      "start": 872.6400146484375,
      "end": 880.3200073242188,
      "text": " just doesn't have this feature at all is quite ridiculous in my mind, really. Plant UML does",
      "tokens": [
        50796,
        445,
        1177,
        380,
        362,
        341,
        4111,
        412,
        439,
        307,
        1596,
        11083,
        294,
        452,
        1575,
        11,
        534,
        13,
        28995,
        624,
        12683,
        775,
        51180
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20115290582180023,
      "compression_ratio": 1.5774058103561401,
      "no_speech_prob": 0.10632263869047165
    },
    {
      "id": 131,
      "seek": 86400,
      "start": 880.3200073242188,
      "end": 887.2000122070312,
      "text": " have a legend. It's not easy to use to define what's within that legend. Structurizer does",
      "tokens": [
        51180,
        362,
        257,
        9451,
        13,
        467,
        311,
        406,
        1858,
        281,
        764,
        281,
        6964,
        437,
        311,
        1951,
        300,
        9451,
        13,
        745,
        1757,
        374,
        6545,
        775,
        51524
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20115290582180023,
      "compression_ratio": 1.5774058103561401,
      "no_speech_prob": 0.10632263869047165
    },
    {
      "id": 132,
      "seek": 86400,
      "start": 887.2000122070312,
      "end": 893.8400268554688,
      "text": " automatically create a legend for you. So, that's really good. But yeah, I think we really need to",
      "tokens": [
        51524,
        6772,
        1884,
        257,
        9451,
        337,
        291,
        13,
        407,
        11,
        300,
        311,
        534,
        665,
        13,
        583,
        1338,
        11,
        286,
        519,
        321,
        534,
        643,
        281,
        51856
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20115290582180023,
      "compression_ratio": 1.5774058103561401,
      "no_speech_prob": 0.10632263869047165
    },
    {
      "id": 133,
      "seek": 89384,
      "start": 893.8400268554688,
      "end": 899.52001953125,
      "text": " sort out the lack of legend in mermaid. So, if anyone wants to contribute to the open source and",
      "tokens": [
        50364,
        1333,
        484,
        264,
        5011,
        295,
        9451,
        294,
        43146,
        13,
        407,
        11,
        498,
        2878,
        2738,
        281,
        10586,
        281,
        264,
        1269,
        4009,
        293,
        50648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2561154365539551,
      "compression_ratio": 1.6877323389053345,
      "no_speech_prob": 0.024655140936374664
    },
    {
      "id": 134,
      "seek": 89384,
      "start": 899.52001953125,
      "end": 905.760009765625,
      "text": " sort that out, that'd be great. Sorry, just as an addition, it also says asynchronous on your",
      "tokens": [
        50648,
        1333,
        300,
        484,
        11,
        300,
        1116,
        312,
        869,
        13,
        4919,
        11,
        445,
        382,
        364,
        4500,
        11,
        309,
        611,
        1619,
        49174,
        322,
        428,
        50960
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2561154365539551,
      "compression_ratio": 1.6877323389053345,
      "no_speech_prob": 0.024655140936374664
    },
    {
      "id": 135,
      "seek": 89384,
      "start": 905.760009765625,
      "end": 912.0800170898438,
      "text": " t-shirt and datastore. So, that's the legend. And, you know, it's about play, obviously,",
      "tokens": [
        50960,
        256,
        12,
        15313,
        293,
        1137,
        525,
        418,
        13,
        407,
        11,
        300,
        311,
        264,
        9451,
        13,
        400,
        11,
        291,
        458,
        11,
        309,
        311,
        466,
        862,
        11,
        2745,
        11,
        51276
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2561154365539551,
      "compression_ratio": 1.6877323389053345,
      "no_speech_prob": 0.024655140936374664
    },
    {
      "id": 136,
      "seek": 89384,
      "start": 912.0800170898438,
      "end": 916.0800170898438,
      "text": " just for the people who are listening to the podcast. And I understand that you even have",
      "tokens": [
        51276,
        445,
        337,
        264,
        561,
        567,
        366,
        4764,
        281,
        264,
        7367,
        13,
        400,
        286,
        1223,
        300,
        291,
        754,
        362,
        51476
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2561154365539551,
      "compression_ratio": 1.6877323389053345,
      "no_speech_prob": 0.024655140936374664
    },
    {
      "id": 137,
      "seek": 89384,
      "start": 916.0800170898438,
      "end": 920.3200073242188,
      "text": " more ideas about t-shirts like that. So, can you get it on Spreadshirt or somewhere?",
      "tokens": [
        51476,
        544,
        3487,
        466,
        256,
        12,
        25892,
        411,
        300,
        13,
        407,
        11,
        393,
        291,
        483,
        309,
        322,
        30308,
        15313,
        420,
        4079,
        30,
        51688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2561154365539551,
      "compression_ratio": 1.6877323389053345,
      "no_speech_prob": 0.024655140936374664
    },
    {
      "id": 138,
      "seek": 92032,
      "start": 921.1199951171875,
      "end": 924.4000244140625,
      "text": " No, at the moment. But if people want me to put it on there.",
      "tokens": [
        50404,
        883,
        11,
        412,
        264,
        1623,
        13,
        583,
        498,
        561,
        528,
        385,
        281,
        829,
        309,
        322,
        456,
        13,
        50568
      ],
      "temperature": 0.0,
      "avg_logprob": -0.322113037109375,
      "compression_ratio": 1.506382942199707,
      "no_speech_prob": 0.024411523714661598
    },
    {
      "id": 139,
      "seek": 92032,
      "start": 926.7999877929688,
      "end": 933.1199951171875,
      "text": " OK, sorry, but I was interrupting you. So, you said that Structurizer always creates a legend.",
      "tokens": [
        50688,
        2264,
        11,
        2597,
        11,
        457,
        286,
        390,
        49455,
        291,
        13,
        407,
        11,
        291,
        848,
        300,
        745,
        1757,
        374,
        6545,
        1009,
        7829,
        257,
        9451,
        13,
        51004
      ],
      "temperature": 0.0,
      "avg_logprob": -0.322113037109375,
      "compression_ratio": 1.506382942199707,
      "no_speech_prob": 0.024411523714661598
    },
    {
      "id": 140,
      "seek": 92032,
      "start": 933.1199951171875,
      "end": 940.0800170898438,
      "text": " But I think it has an easy position because it's always the same color code. And I think there are",
      "tokens": [
        51004,
        583,
        286,
        519,
        309,
        575,
        364,
        1858,
        2535,
        570,
        309,
        311,
        1009,
        264,
        912,
        2017,
        3089,
        13,
        400,
        286,
        519,
        456,
        366,
        51352
      ],
      "temperature": 0.0,
      "avg_logprob": -0.322113037109375,
      "compression_ratio": 1.506382942199707,
      "no_speech_prob": 0.024411523714661598
    },
    {
      "id": 141,
      "seek": 92032,
      "start": 940.0800170898438,
      "end": 945.760009765625,
      "text": " only two shapes. And so it's quite a few shapes, actually. Really? You can define lots of different",
      "tokens": [
        51352,
        787,
        732,
        10854,
        13,
        400,
        370,
        309,
        311,
        1596,
        257,
        1326,
        10854,
        11,
        767,
        13,
        4083,
        30,
        509,
        393,
        6964,
        3195,
        295,
        819,
        51636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.322113037109375,
      "compression_ratio": 1.506382942199707,
      "no_speech_prob": 0.024411523714661598
    },
    {
      "id": 142,
      "seek": 94576,
      "start": 945.760009765625,
      "end": 955.52001953125,
      "text": " shapes. So, you've got the standard person and rectangle for like a service or a container.",
      "tokens": [
        50364,
        10854,
        13,
        407,
        11,
        291,
        600,
        658,
        264,
        3832,
        954,
        293,
        21930,
        337,
        411,
        257,
        2643,
        420,
        257,
        10129,
        13,
        50852
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21890783309936523,
      "compression_ratio": 1.6651982069015503,
      "no_speech_prob": 0.3841085135936737
    },
    {
      "id": 143,
      "seek": 94576,
      "start": 956.239990234375,
      "end": 962.3200073242188,
      "text": " Once you get down to the components, it has a different shape for that. You can also use.",
      "tokens": [
        50888,
        3443,
        291,
        483,
        760,
        281,
        264,
        6677,
        11,
        309,
        575,
        257,
        819,
        3909,
        337,
        300,
        13,
        509,
        393,
        611,
        764,
        13,
        51192
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21890783309936523,
      "compression_ratio": 1.6651982069015503,
      "no_speech_prob": 0.3841085135936737
    },
    {
      "id": 144,
      "seek": 94576,
      "start": 962.3200073242188,
      "end": 968.1599731445312,
      "text": " So, there's the datastore shape. There's a pipe shape if you've got a queue and things like that.",
      "tokens": [
        51192,
        407,
        11,
        456,
        311,
        264,
        1137,
        525,
        418,
        3909,
        13,
        821,
        311,
        257,
        11240,
        3909,
        498,
        291,
        600,
        658,
        257,
        18639,
        293,
        721,
        411,
        300,
        13,
        51484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21890783309936523,
      "compression_ratio": 1.6651982069015503,
      "no_speech_prob": 0.3841085135936737
    },
    {
      "id": 145,
      "seek": 94576,
      "start": 968.1599731445312,
      "end": 973.0399780273438,
      "text": " And there's actually quite a few extra ones which you can use in there. But I think the thing that",
      "tokens": [
        51484,
        400,
        456,
        311,
        767,
        1596,
        257,
        1326,
        2857,
        2306,
        597,
        291,
        393,
        764,
        294,
        456,
        13,
        583,
        286,
        519,
        264,
        551,
        300,
        51728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21890783309936523,
      "compression_ratio": 1.6651982069015503,
      "no_speech_prob": 0.3841085135936737
    },
    {
      "id": 146,
      "seek": 97304,
      "start": 973.52001953125,
      "end": 979.6799926757812,
      "text": " the reason it can just auto generate is because it has that model. So, it knows what's in this",
      "tokens": [
        50388,
        264,
        1778,
        309,
        393,
        445,
        8399,
        8460,
        307,
        570,
        309,
        575,
        300,
        2316,
        13,
        407,
        11,
        309,
        3255,
        437,
        311,
        294,
        341,
        50696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21402698755264282,
      "compression_ratio": 1.7079646587371826,
      "no_speech_prob": 0.02065853588283062
    },
    {
      "id": 147,
      "seek": 97304,
      "start": 979.6799926757812,
      "end": 984.8800048828125,
      "text": " diagram and it will give you doesn't just give you the full legend. It will give you the very",
      "tokens": [
        50696,
        10686,
        293,
        309,
        486,
        976,
        291,
        1177,
        380,
        445,
        976,
        291,
        264,
        1577,
        9451,
        13,
        467,
        486,
        976,
        291,
        264,
        588,
        50956
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21402698755264282,
      "compression_ratio": 1.7079646587371826,
      "no_speech_prob": 0.02065853588283062
    },
    {
      "id": 148,
      "seek": 97304,
      "start": 984.8800048828125,
      "end": 990.3200073242188,
      "text": " specific to that diagram. So, it's only the stuff that's in that diagram. It also knows how you've",
      "tokens": [
        50956,
        2685,
        281,
        300,
        10686,
        13,
        407,
        11,
        309,
        311,
        787,
        264,
        1507,
        300,
        311,
        294,
        300,
        10686,
        13,
        467,
        611,
        3255,
        577,
        291,
        600,
        51228
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21402698755264282,
      "compression_ratio": 1.7079646587371826,
      "no_speech_prob": 0.02065853588283062
    },
    {
      "id": 149,
      "seek": 97304,
      "start": 990.3200073242188,
      "end": 998.0800170898438,
      "text": " styled it. So, the sort of very traditional C4 is the different blue colors. The actual one of the",
      "tokens": [
        51228,
        7952,
        1493,
        309,
        13,
        407,
        11,
        264,
        1333,
        295,
        588,
        5164,
        383,
        19,
        307,
        264,
        819,
        3344,
        4577,
        13,
        440,
        3539,
        472,
        295,
        264,
        51616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21402698755264282,
      "compression_ratio": 1.7079646587371826,
      "no_speech_prob": 0.02065853588283062
    },
    {
      "id": 150,
      "seek": 99808,
      "start": 998.0800170898438,
      "end": 1003.5999755859375,
      "text": " things that I talk about in my book and in some of my talks is considering people who have say",
      "tokens": [
        50364,
        721,
        300,
        286,
        751,
        466,
        294,
        452,
        1446,
        293,
        294,
        512,
        295,
        452,
        6686,
        307,
        8079,
        561,
        567,
        362,
        584,
        50640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23082546889781952,
      "compression_ratio": 1.6784141063690186,
      "no_speech_prob": 0.4001208543777466
    },
    {
      "id": 151,
      "seek": 99808,
      "start": 1003.5999755859375,
      "end": 1009.52001953125,
      "text": " color blindness and the actual sort of traditional grays and blues color. I think one of the grays",
      "tokens": [
        50640,
        2017,
        46101,
        293,
        264,
        3539,
        1333,
        295,
        5164,
        677,
        3772,
        293,
        24244,
        2017,
        13,
        286,
        519,
        472,
        295,
        264,
        677,
        3772,
        50936
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23082546889781952,
      "compression_ratio": 1.6784141063690186,
      "no_speech_prob": 0.4001208543777466
    },
    {
      "id": 152,
      "seek": 99808,
      "start": 1009.52001953125,
      "end": 1016.719970703125,
      "text": " and one of the blues are a bit too close to each other. So, but recently, Simon Brown has been",
      "tokens": [
        50936,
        293,
        472,
        295,
        264,
        24244,
        366,
        257,
        857,
        886,
        1998,
        281,
        1184,
        661,
        13,
        407,
        11,
        457,
        3938,
        11,
        13193,
        8030,
        575,
        668,
        51296
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23082546889781952,
      "compression_ratio": 1.6784141063690186,
      "no_speech_prob": 0.4001208543777466
    },
    {
      "id": 153,
      "seek": 99808,
      "start": 1016.719970703125,
      "end": 1021.280029296875,
      "text": " saying to people, look, you do not have to use that color scheme, use whatever you want. So,",
      "tokens": [
        51296,
        1566,
        281,
        561,
        11,
        574,
        11,
        291,
        360,
        406,
        362,
        281,
        764,
        300,
        2017,
        12232,
        11,
        764,
        2035,
        291,
        528,
        13,
        407,
        11,
        51524
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23082546889781952,
      "compression_ratio": 1.6784141063690186,
      "no_speech_prob": 0.4001208543777466
    },
    {
      "id": 154,
      "seek": 102128,
      "start": 1021.280029296875,
      "end": 1028.0799560546875,
      "text": " if you go to the online Structurizer DSL, where you can, it's like a playground, which is what I",
      "tokens": [
        50364,
        498,
        291,
        352,
        281,
        264,
        2950,
        745,
        1757,
        374,
        6545,
        15816,
        43,
        11,
        689,
        291,
        393,
        11,
        309,
        311,
        411,
        257,
        24646,
        11,
        597,
        307,
        437,
        286,
        50704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25505951046943665,
      "compression_ratio": 1.5924370288848877,
      "no_speech_prob": 0.06472347676753998
    },
    {
      "id": 155,
      "seek": 102128,
      "start": 1028.0799560546875,
      "end": 1035.3599853515625,
      "text": " use in the course. It will randomly choose different themes now. So, you might get orange",
      "tokens": [
        50704,
        764,
        294,
        264,
        1164,
        13,
        467,
        486,
        16979,
        2826,
        819,
        13544,
        586,
        13,
        407,
        11,
        291,
        1062,
        483,
        7671,
        51068
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25505951046943665,
      "compression_ratio": 1.5924370288848877,
      "no_speech_prob": 0.06472347676753998
    },
    {
      "id": 156,
      "seek": 102128,
      "start": 1035.3599853515625,
      "end": 1041.43994140625,
      "text": " or you might get pink or things like that. But you can define your own styles in there in a sort of",
      "tokens": [
        51068,
        420,
        291,
        1062,
        483,
        7022,
        420,
        721,
        411,
        300,
        13,
        583,
        291,
        393,
        6964,
        428,
        1065,
        13273,
        294,
        456,
        294,
        257,
        1333,
        295,
        51372
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25505951046943665,
      "compression_ratio": 1.5924370288848877,
      "no_speech_prob": 0.06472347676753998
    },
    {
      "id": 157,
      "seek": 102128,
      "start": 1041.43994140625,
      "end": 1050.1600341796875,
      "text": " similar to CSS. And so, it will just go look at the model, look at the how you've styled it,",
      "tokens": [
        51372,
        2531,
        281,
        24387,
        13,
        400,
        370,
        11,
        309,
        486,
        445,
        352,
        574,
        412,
        264,
        2316,
        11,
        574,
        412,
        264,
        577,
        291,
        600,
        7952,
        1493,
        309,
        11,
        51808
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25505951046943665,
      "compression_ratio": 1.5924370288848877,
      "no_speech_prob": 0.06472347676753998
    },
    {
      "id": 158,
      "seek": 105016,
      "start": 1050.1600341796875,
      "end": 1055.52001953125,
      "text": " and just generate it for you. So, it's that whole model thing. It's leveraging that.",
      "tokens": [
        50364,
        293,
        445,
        8460,
        309,
        337,
        291,
        13,
        407,
        11,
        309,
        311,
        300,
        1379,
        2316,
        551,
        13,
        467,
        311,
        32666,
        300,
        13,
        50632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22184889018535614,
      "compression_ratio": 1.5850622653961182,
      "no_speech_prob": 0.009842140600085258
    },
    {
      "id": 159,
      "seek": 105016,
      "start": 1056.0799560546875,
      "end": 1062.8800048828125,
      "text": " We did an episode on Structurizer and the C4 model with Simon Brown, who's the original inventor of",
      "tokens": [
        50660,
        492,
        630,
        364,
        3500,
        322,
        745,
        1757,
        374,
        6545,
        293,
        264,
        383,
        19,
        2316,
        365,
        13193,
        8030,
        11,
        567,
        311,
        264,
        3380,
        41593,
        295,
        51000
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22184889018535614,
      "compression_ratio": 1.5850622653961182,
      "no_speech_prob": 0.009842140600085258
    },
    {
      "id": 160,
      "seek": 105016,
      "start": 1062.8800048828125,
      "end": 1069.3599853515625,
      "text": " that. So, I will include a link in the description to that one, or you can look it up on the webpage.",
      "tokens": [
        51000,
        300,
        13,
        407,
        11,
        286,
        486,
        4090,
        257,
        2113,
        294,
        264,
        3855,
        281,
        300,
        472,
        11,
        420,
        291,
        393,
        574,
        309,
        493,
        322,
        264,
        37852,
        13,
        51324
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22184889018535614,
      "compression_ratio": 1.5850622653961182,
      "no_speech_prob": 0.009842140600085258
    },
    {
      "id": 161,
      "seek": 105016,
      "start": 1070.9599609375,
      "end": 1076.719970703125,
      "text": " Maybe we should, so you did talk about sequence diagrams and activity diagrams and so on. And I",
      "tokens": [
        51404,
        2704,
        321,
        820,
        11,
        370,
        291,
        630,
        751,
        466,
        8310,
        36709,
        293,
        5191,
        36709,
        293,
        370,
        322,
        13,
        400,
        286,
        51692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22184889018535614,
      "compression_ratio": 1.5850622653961182,
      "no_speech_prob": 0.009842140600085258
    },
    {
      "id": 162,
      "seek": 107672,
      "start": 1076.719970703125,
      "end": 1083.5999755859375,
      "text": " think people probably have a rough understanding about that, that there is some flow. And that's",
      "tokens": [
        50364,
        519,
        561,
        1391,
        362,
        257,
        5903,
        3701,
        466,
        300,
        11,
        300,
        456,
        307,
        512,
        3095,
        13,
        400,
        300,
        311,
        50708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21611064672470093,
      "compression_ratio": 1.5938864946365356,
      "no_speech_prob": 0.027994317933917046
    },
    {
      "id": 163,
      "seek": 107672,
      "start": 1083.5999755859375,
      "end": 1087.9200439453125,
      "text": " basically what also the name suggests, right? I mean, sequence diagram actually says what it is.",
      "tokens": [
        50708,
        1936,
        437,
        611,
        264,
        1315,
        13409,
        11,
        558,
        30,
        286,
        914,
        11,
        8310,
        10686,
        767,
        1619,
        437,
        309,
        307,
        13,
        50924
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21611064672470093,
      "compression_ratio": 1.5938864946365356,
      "no_speech_prob": 0.027994317933917046
    },
    {
      "id": 164,
      "seek": 107672,
      "start": 1089.0400390625,
      "end": 1094.0799560546875,
      "text": " I was wondering whether you want to say a few words about C4, because, I mean, C4 doesn't",
      "tokens": [
        50980,
        286,
        390,
        6359,
        1968,
        291,
        528,
        281,
        584,
        257,
        1326,
        2283,
        466,
        383,
        19,
        11,
        570,
        11,
        286,
        914,
        11,
        383,
        19,
        1177,
        380,
        51232
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21611064672470093,
      "compression_ratio": 1.5938864946365356,
      "no_speech_prob": 0.027994317933917046
    },
    {
      "id": 165,
      "seek": 107672,
      "start": 1094.0799560546875,
      "end": 1100.47998046875,
      "text": " really say what it's about, right? Yeah. So, C4 is about expressing the structure",
      "tokens": [
        51232,
        534,
        584,
        437,
        309,
        311,
        466,
        11,
        558,
        30,
        865,
        13,
        407,
        11,
        383,
        19,
        307,
        466,
        22171,
        264,
        3877,
        51552
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21611064672470093,
      "compression_ratio": 1.5938864946365356,
      "no_speech_prob": 0.027994317933917046
    },
    {
      "id": 166,
      "seek": 110048,
      "start": 1100.47998046875,
      "end": 1110.4000244140625,
      "text": " of your architecture in your system. And so, originally, it started with the context being",
      "tokens": [
        50364,
        295,
        428,
        9482,
        294,
        428,
        1185,
        13,
        400,
        370,
        11,
        7993,
        11,
        309,
        1409,
        365,
        264,
        4319,
        885,
        50860
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25181686878204346,
      "compression_ratio": 1.7757009267807007,
      "no_speech_prob": 0.05320882424712181
    },
    {
      "id": 167,
      "seek": 110048,
      "start": 1110.4000244140625,
      "end": 1116.4000244140625,
      "text": " the highest level. There is now a landscape level, because the context diagram is, this is our system",
      "tokens": [
        50860,
        264,
        6343,
        1496,
        13,
        821,
        307,
        586,
        257,
        9661,
        1496,
        11,
        570,
        264,
        4319,
        10686,
        307,
        11,
        341,
        307,
        527,
        1185,
        51160
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25181686878204346,
      "compression_ratio": 1.7757009267807007,
      "no_speech_prob": 0.05320882424712181
    },
    {
      "id": 168,
      "seek": 110048,
      "start": 1116.4000244140625,
      "end": 1122.0799560546875,
      "text": " that we're interested in, and this is how it interacts with things. Whereas the landscape",
      "tokens": [
        51160,
        300,
        321,
        434,
        3102,
        294,
        11,
        293,
        341,
        307,
        577,
        309,
        43582,
        365,
        721,
        13,
        13813,
        264,
        9661,
        51444
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25181686878204346,
      "compression_ratio": 1.7757009267807007,
      "no_speech_prob": 0.05320882424712181
    },
    {
      "id": 169,
      "seek": 110048,
      "start": 1122.0799560546875,
      "end": 1128.4000244140625,
      "text": " level is more, these are all our systems within our organization, and how they interact with each",
      "tokens": [
        51444,
        1496,
        307,
        544,
        11,
        613,
        366,
        439,
        527,
        3652,
        1951,
        527,
        4475,
        11,
        293,
        577,
        436,
        4648,
        365,
        1184,
        51760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25181686878204346,
      "compression_ratio": 1.7757009267807007,
      "no_speech_prob": 0.05320882424712181
    },
    {
      "id": 170,
      "seek": 112840,
      "start": 1128.4000244140625,
      "end": 1134.0,
      "text": " other is a bit at a different level. So, that's out of the C4. So, you've got context, then you",
      "tokens": [
        50364,
        661,
        307,
        257,
        857,
        412,
        257,
        819,
        1496,
        13,
        407,
        11,
        300,
        311,
        484,
        295,
        264,
        383,
        19,
        13,
        407,
        11,
        291,
        600,
        658,
        4319,
        11,
        550,
        291,
        50644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18650221824645996,
      "compression_ratio": 1.665235996246338,
      "no_speech_prob": 0.01655445620417595
    },
    {
      "id": 171,
      "seek": 112840,
      "start": 1134.0,
      "end": 1141.5999755859375,
      "text": " go down to container, which is kind of individually deployable units. And so, what you're doing there",
      "tokens": [
        50644,
        352,
        760,
        281,
        10129,
        11,
        597,
        307,
        733,
        295,
        16652,
        7274,
        712,
        6815,
        13,
        400,
        370,
        11,
        437,
        291,
        434,
        884,
        456,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18650221824645996,
      "compression_ratio": 1.665235996246338,
      "no_speech_prob": 0.01655445620417595
    },
    {
      "id": 172,
      "seek": 112840,
      "start": 1141.5999755859375,
      "end": 1145.9200439453125,
      "text": " is you're taking that system that you have in your context, and you are kind of zooming in on it",
      "tokens": [
        51024,
        307,
        291,
        434,
        1940,
        300,
        1185,
        300,
        291,
        362,
        294,
        428,
        4319,
        11,
        293,
        291,
        366,
        733,
        295,
        48226,
        294,
        322,
        309,
        51240
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18650221824645996,
      "compression_ratio": 1.665235996246338,
      "no_speech_prob": 0.01655445620417595
    },
    {
      "id": 173,
      "seek": 112840,
      "start": 1145.9200439453125,
      "end": 1152.56005859375,
      "text": " and seeing what's within that system, but still how those pieces interact with things outside",
      "tokens": [
        51240,
        293,
        2577,
        437,
        311,
        1951,
        300,
        1185,
        11,
        457,
        920,
        577,
        729,
        3755,
        4648,
        365,
        721,
        2380,
        51572
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18650221824645996,
      "compression_ratio": 1.665235996246338,
      "no_speech_prob": 0.01655445620417595
    },
    {
      "id": 174,
      "seek": 115256,
      "start": 1153.43994140625,
      "end": 1160.56005859375,
      "text": " of that. Then you carry on down to the component. If you need to, I always say to people, you probably,",
      "tokens": [
        50408,
        295,
        300,
        13,
        1396,
        291,
        3985,
        322,
        760,
        281,
        264,
        6542,
        13,
        759,
        291,
        643,
        281,
        11,
        286,
        1009,
        584,
        281,
        561,
        11,
        291,
        1391,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1998215913772583,
      "compression_ratio": 1.7567567825317383,
      "no_speech_prob": 0.201102152466774
    },
    {
      "id": 175,
      "seek": 115256,
      "start": 1160.56005859375,
      "end": 1166.56005859375,
      "text": " most of the time, only really need those top two. But you can go down to the component level.",
      "tokens": [
        50764,
        881,
        295,
        264,
        565,
        11,
        787,
        534,
        643,
        729,
        1192,
        732,
        13,
        583,
        291,
        393,
        352,
        760,
        281,
        264,
        6542,
        1496,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1998215913772583,
      "compression_ratio": 1.7567567825317383,
      "no_speech_prob": 0.201102152466774
    },
    {
      "id": 176,
      "seek": 115256,
      "start": 1166.56005859375,
      "end": 1171.43994140625,
      "text": " If you go down to the code, that's when you're actually going to be using UML diagrams. And I",
      "tokens": [
        51064,
        759,
        291,
        352,
        760,
        281,
        264,
        3089,
        11,
        300,
        311,
        562,
        291,
        434,
        767,
        516,
        281,
        312,
        1228,
        624,
        12683,
        36709,
        13,
        400,
        286,
        51308
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1998215913772583,
      "compression_ratio": 1.7567567825317383,
      "no_speech_prob": 0.201102152466774
    },
    {
      "id": 177,
      "seek": 115256,
      "start": 1171.43994140625,
      "end": 1178.239990234375,
      "text": " would say to people, look, the lower down you go, the more stuff will change. And so, if you don't",
      "tokens": [
        51308,
        576,
        584,
        281,
        561,
        11,
        574,
        11,
        264,
        3126,
        760,
        291,
        352,
        11,
        264,
        544,
        1507,
        486,
        1319,
        13,
        400,
        370,
        11,
        498,
        291,
        500,
        380,
        51648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1998215913772583,
      "compression_ratio": 1.7567567825317383,
      "no_speech_prob": 0.201102152466774
    },
    {
      "id": 178,
      "seek": 117824,
      "start": 1178.239990234375,
      "end": 1184.1600341796875,
      "text": " need to go into that detail, don't, because then you don't have to maintain it. If you really need",
      "tokens": [
        50364,
        643,
        281,
        352,
        666,
        300,
        2607,
        11,
        500,
        380,
        11,
        570,
        550,
        291,
        500,
        380,
        362,
        281,
        6909,
        309,
        13,
        759,
        291,
        534,
        643,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.179625004529953,
      "compression_ratio": 1.8252787590026855,
      "no_speech_prob": 0.1535940021276474
    },
    {
      "id": 179,
      "seek": 117824,
      "start": 1184.1600341796875,
      "end": 1191.0400390625,
      "text": " to document your code, maybe it's an API interface, then if you're using things like OpenAPI, that will",
      "tokens": [
        50660,
        281,
        4166,
        428,
        3089,
        11,
        1310,
        309,
        311,
        364,
        9362,
        9226,
        11,
        550,
        498,
        291,
        434,
        1228,
        721,
        411,
        7238,
        4715,
        40,
        11,
        300,
        486,
        51004
      ],
      "temperature": 0.0,
      "avg_logprob": -0.179625004529953,
      "compression_ratio": 1.8252787590026855,
      "no_speech_prob": 0.1535940021276474
    },
    {
      "id": 180,
      "seek": 117824,
      "start": 1191.0400390625,
      "end": 1197.6800537109375,
      "text": " then automatically do that for you. So, you don't want to have to manually sort out stuff in detail.",
      "tokens": [
        51004,
        550,
        6772,
        360,
        300,
        337,
        291,
        13,
        407,
        11,
        291,
        500,
        380,
        528,
        281,
        362,
        281,
        16945,
        1333,
        484,
        1507,
        294,
        2607,
        13,
        51336
      ],
      "temperature": 0.0,
      "avg_logprob": -0.179625004529953,
      "compression_ratio": 1.8252787590026855,
      "no_speech_prob": 0.1535940021276474
    },
    {
      "id": 181,
      "seek": 117824,
      "start": 1197.6800537109375,
      "end": 1203.0400390625,
      "text": " And that goes for documentation, too, not just diagrams. Go into the amount of detail that you",
      "tokens": [
        51336,
        400,
        300,
        1709,
        337,
        14333,
        11,
        886,
        11,
        406,
        445,
        36709,
        13,
        1037,
        666,
        264,
        2372,
        295,
        2607,
        300,
        291,
        51604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.179625004529953,
      "compression_ratio": 1.8252787590026855,
      "no_speech_prob": 0.1535940021276474
    },
    {
      "id": 182,
      "seek": 117824,
      "start": 1203.0400390625,
      "end": 1207.5999755859375,
      "text": " need. If someone then asks questions, then you can go into that detail, but you will have to",
      "tokens": [
        51604,
        643,
        13,
        759,
        1580,
        550,
        8962,
        1651,
        11,
        550,
        291,
        393,
        352,
        666,
        300,
        2607,
        11,
        457,
        291,
        486,
        362,
        281,
        51832
      ],
      "temperature": 0.0,
      "avg_logprob": -0.179625004529953,
      "compression_ratio": 1.8252787590026855,
      "no_speech_prob": 0.1535940021276474
    },
    {
      "id": 183,
      "seek": 120760,
      "start": 1207.5999755859375,
      "end": 1214.8800048828125,
      "text": " maintain everything you create. Yeah, I think that's such an important point, because I guess",
      "tokens": [
        50364,
        6909,
        1203,
        291,
        1884,
        13,
        865,
        11,
        286,
        519,
        300,
        311,
        1270,
        364,
        1021,
        935,
        11,
        570,
        286,
        2041,
        50728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2370864748954773,
      "compression_ratio": 1.5779221057891846,
      "no_speech_prob": 0.003694966435432434
    },
    {
      "id": 184,
      "seek": 120760,
      "start": 1214.8800048828125,
      "end": 1219.3599853515625,
      "text": " some people think that the more documentation, the better. But as you pointed out, documentation",
      "tokens": [
        50728,
        512,
        561,
        519,
        300,
        264,
        544,
        14333,
        11,
        264,
        1101,
        13,
        583,
        382,
        291,
        10932,
        484,
        11,
        14333,
        50952
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2370864748954773,
      "compression_ratio": 1.5779221057891846,
      "no_speech_prob": 0.003694966435432434
    },
    {
      "id": 185,
      "seek": 120760,
      "start": 1219.3599853515625,
      "end": 1222.8800048828125,
      "text": " is also a burden. So, I think that's very important.",
      "tokens": [
        50952,
        307,
        611,
        257,
        12578,
        13,
        407,
        11,
        286,
        519,
        300,
        311,
        588,
        1021,
        13,
        51128
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2370864748954773,
      "compression_ratio": 1.5779221057891846,
      "no_speech_prob": 0.003694966435432434
    },
    {
      "id": 0,
      "seek": 0,
      "start": 1223.9899999952315,
      "end": 1227.9900001144408,
      "text": " What I found interesting when I was looking at the slides, I have to admit that I didn't take",
      "tokens": [
        50408,
        708,
        286,
        1352,
        1880,
        562,
        286,
        390,
        1237,
        412,
        264,
        9788,
        11,
        286,
        362,
        281,
        9796,
        300,
        286,
        994,
        380,
        747,
        50608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22738094627857208,
      "compression_ratio": 1.8471074104309082,
      "no_speech_prob": 0.8525373935699463
    },
    {
      "id": 1,
      "seek": 0,
      "start": 1227.9900001144408,
      "end": 1233.189999923706,
      "text": " part in your workshop, but when I took a look at the slides that you gave me access to,",
      "tokens": [
        50608,
        644,
        294,
        428,
        13541,
        11,
        457,
        562,
        286,
        1890,
        257,
        574,
        412,
        264,
        9788,
        300,
        291,
        2729,
        385,
        2105,
        281,
        11,
        50868
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22738094627857208,
      "compression_ratio": 1.8471074104309082,
      "no_speech_prob": 0.8525373935699463
    },
    {
      "id": 2,
      "seek": 0,
      "start": 1235.0300000762938,
      "end": 1239.8299993133544,
      "text": " it seemed that most of the diagrams that you're talking about are sequence diagrams,",
      "tokens": [
        50960,
        309,
        6576,
        300,
        881,
        295,
        264,
        36709,
        300,
        291,
        434,
        1417,
        466,
        366,
        8310,
        36709,
        11,
        51200
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22738094627857208,
      "compression_ratio": 1.8471074104309082,
      "no_speech_prob": 0.8525373935699463
    },
    {
      "id": 3,
      "seek": 0,
      "start": 1239.8299993133544,
      "end": 1243.9099992370604,
      "text": " activity diagrams, so diagrams that talk about the dynamic behavior of the system,",
      "tokens": [
        51200,
        5191,
        36709,
        11,
        370,
        36709,
        300,
        751,
        466,
        264,
        8546,
        5223,
        295,
        264,
        1185,
        11,
        51404
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22738094627857208,
      "compression_ratio": 1.8471074104309082,
      "no_speech_prob": 0.8525373935699463
    },
    {
      "id": 4,
      "seek": 0,
      "start": 1243.9099992370604,
      "end": 1252.4700006103515,
      "text": " and CIFOR is different. So, I was wondering why you chose sequence diagrams and activity diagrams",
      "tokens": [
        51404,
        293,
        383,
        12775,
        2483,
        307,
        819,
        13,
        407,
        11,
        286,
        390,
        6359,
        983,
        291,
        5111,
        8310,
        36709,
        293,
        5191,
        36709,
        51832
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22738094627857208,
      "compression_ratio": 1.8471074104309082,
      "no_speech_prob": 0.8525373935699463
    },
    {
      "id": 5,
      "seek": 2936,
      "start": 1252.4700006103515,
      "end": 1260.2299989318847,
      "text": " in particular, and not the UML diagrams that you could use for the structure as well. I mean,",
      "tokens": [
        50364,
        294,
        1729,
        11,
        293,
        406,
        264,
        624,
        12683,
        36709,
        300,
        291,
        727,
        764,
        337,
        264,
        3877,
        382,
        731,
        13,
        286,
        914,
        11,
        50752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19742953777313232,
      "compression_ratio": 1.5836910009384155,
      "no_speech_prob": 0.033466849476099014
    },
    {
      "id": 6,
      "seek": 2936,
      "start": 1260.2299989318847,
      "end": 1265.5100015258788,
      "text": " there are component diagrams and class diagrams and these kinds of things, so that's basically",
      "tokens": [
        50752,
        456,
        366,
        6542,
        36709,
        293,
        1508,
        36709,
        293,
        613,
        3685,
        295,
        721,
        11,
        370,
        300,
        311,
        1936,
        51016
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19742953777313232,
      "compression_ratio": 1.5836910009384155,
      "no_speech_prob": 0.033466849476099014
    },
    {
      "id": 7,
      "seek": 2936,
      "start": 1265.5100015258788,
      "end": 1271.0299981689452,
      "text": " what I was wondering about. Yeah, so I try to give a bit of a balance because we do look at",
      "tokens": [
        51016,
        437,
        286,
        390,
        6359,
        466,
        13,
        865,
        11,
        370,
        286,
        853,
        281,
        976,
        257,
        857,
        295,
        257,
        4772,
        570,
        321,
        360,
        574,
        412,
        51292
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19742953777313232,
      "compression_ratio": 1.5836910009384155,
      "no_speech_prob": 0.033466849476099014
    },
    {
      "id": 8,
      "seek": 2936,
      "start": 1271.0299981689452,
      "end": 1278.2299989318847,
      "text": " the CIFOR, so that's structure. Obviously, when I teach this for one day, I can teach it",
      "tokens": [
        51292,
        264,
        383,
        12775,
        2483,
        11,
        370,
        300,
        311,
        3877,
        13,
        7580,
        11,
        562,
        286,
        2924,
        341,
        337,
        472,
        786,
        11,
        286,
        393,
        2924,
        309,
        51652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19742953777313232,
      "compression_ratio": 1.5836910009384155,
      "no_speech_prob": 0.033466849476099014
    },
    {
      "id": 9,
      "seek": 5512,
      "start": 1278.2299989318847,
      "end": 1284.3100007629394,
      "text": " for longer, and we could go into a lot more if people wanted to, but in one day, we can only",
      "tokens": [
        50364,
        337,
        2854,
        11,
        293,
        321,
        727,
        352,
        666,
        257,
        688,
        544,
        498,
        561,
        1415,
        281,
        11,
        457,
        294,
        472,
        786,
        11,
        321,
        393,
        787,
        50668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.182373046875,
      "compression_ratio": 1.7230216264724731,
      "no_speech_prob": 0.023958895355463028
    },
    {
      "id": 10,
      "seek": 5512,
      "start": 1284.3100007629394,
      "end": 1288.7900003051757,
      "text": " really cover a certain amount. So, because we're looking at the structure with the CIFOR, I chose",
      "tokens": [
        50668,
        534,
        2060,
        257,
        1629,
        2372,
        13,
        407,
        11,
        570,
        321,
        434,
        1237,
        412,
        264,
        3877,
        365,
        264,
        383,
        12775,
        2483,
        11,
        286,
        5111,
        50892
      ],
      "temperature": 0.0,
      "avg_logprob": -0.182373046875,
      "compression_ratio": 1.7230216264724731,
      "no_speech_prob": 0.023958895355463028
    },
    {
      "id": 11,
      "seek": 5512,
      "start": 1288.7900003051757,
      "end": 1294.7900003051757,
      "text": " the more behavior ones because those are the things that CIFOR doesn't show, and so a lot of",
      "tokens": [
        50892,
        264,
        544,
        5223,
        2306,
        570,
        729,
        366,
        264,
        721,
        300,
        383,
        12775,
        2483,
        1177,
        380,
        855,
        11,
        293,
        370,
        257,
        688,
        295,
        51192
      ],
      "temperature": 0.0,
      "avg_logprob": -0.182373046875,
      "compression_ratio": 1.7230216264724731,
      "no_speech_prob": 0.023958895355463028
    },
    {
      "id": 12,
      "seek": 5512,
      "start": 1294.7900003051757,
      "end": 1300.3899987792968,
      "text": " people say, oh yeah, we can just use CIFOR for all our diagrams, that's all we need, but actually, we",
      "tokens": [
        51192,
        561,
        584,
        11,
        1954,
        1338,
        11,
        321,
        393,
        445,
        764,
        383,
        12775,
        2483,
        337,
        439,
        527,
        36709,
        11,
        300,
        311,
        439,
        321,
        643,
        11,
        457,
        767,
        11,
        321,
        51472
      ],
      "temperature": 0.0,
      "avg_logprob": -0.182373046875,
      "compression_ratio": 1.7230216264724731,
      "no_speech_prob": 0.023958895355463028
    },
    {
      "id": 13,
      "seek": 5512,
      "start": 1300.3899987792968,
      "end": 1305.3499978637694,
      "text": " also need to communicate the behavior of the system, which is kind of more important, really,",
      "tokens": [
        51472,
        611,
        643,
        281,
        7890,
        264,
        5223,
        295,
        264,
        1185,
        11,
        597,
        307,
        733,
        295,
        544,
        1021,
        11,
        534,
        11,
        51720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.182373046875,
      "compression_ratio": 1.7230216264724731,
      "no_speech_prob": 0.023958895355463028
    },
    {
      "id": 14,
      "seek": 8224,
      "start": 1305.3499978637694,
      "end": 1311.6699975585936,
      "text": " because that's what's meeting the needs of our users, is the behavior, not the structure. Our",
      "tokens": [
        50364,
        570,
        300,
        311,
        437,
        311,
        3440,
        264,
        2203,
        295,
        527,
        5022,
        11,
        307,
        264,
        5223,
        11,
        406,
        264,
        3877,
        13,
        2621,
        50680
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17462275922298431,
      "compression_ratio": 1.6738197803497314,
      "no_speech_prob": 0.004463599994778633
    },
    {
      "id": 15,
      "seek": 8224,
      "start": 1311.6699975585936,
      "end": 1318.230002746582,
      "text": " users don't care if we've got a monolith or which service talks to which, they care about the",
      "tokens": [
        50680,
        5022,
        500,
        380,
        1127,
        498,
        321,
        600,
        658,
        257,
        1108,
        29131,
        420,
        597,
        2643,
        6686,
        281,
        597,
        11,
        436,
        1127,
        466,
        264,
        51008
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17462275922298431,
      "compression_ratio": 1.6738197803497314,
      "no_speech_prob": 0.004463599994778633
    },
    {
      "id": 16,
      "seek": 8224,
      "start": 1318.230002746582,
      "end": 1324.3899987792968,
      "text": " behavior of the system and whether it does what they want. So, we can't just use CIFOR, we have to",
      "tokens": [
        51008,
        5223,
        295,
        264,
        1185,
        293,
        1968,
        309,
        775,
        437,
        436,
        528,
        13,
        407,
        11,
        321,
        393,
        380,
        445,
        764,
        383,
        12775,
        2483,
        11,
        321,
        362,
        281,
        51316
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17462275922298431,
      "compression_ratio": 1.6738197803497314,
      "no_speech_prob": 0.004463599994778633
    },
    {
      "id": 17,
      "seek": 8224,
      "start": 1324.3899987792968,
      "end": 1331.1900018310546,
      "text": " use behavior or at least consider our behavior, and of course, diagrams are a good way of communicating",
      "tokens": [
        51316,
        764,
        5223,
        420,
        412,
        1935,
        1949,
        527,
        5223,
        11,
        293,
        295,
        1164,
        11,
        36709,
        366,
        257,
        665,
        636,
        295,
        17559,
        51656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17462275922298431,
      "compression_ratio": 1.6738197803497314,
      "no_speech_prob": 0.004463599994778633
    },
    {
      "id": 18,
      "seek": 10808,
      "start": 1331.1900018310546,
      "end": 1337.5900033569335,
      "text": " that. So, is that sort of your default approach, like you use CIFOR for the structure and then use",
      "tokens": [
        50364,
        300,
        13,
        407,
        11,
        307,
        300,
        1333,
        295,
        428,
        7576,
        3109,
        11,
        411,
        291,
        764,
        383,
        12775,
        2483,
        337,
        264,
        3877,
        293,
        550,
        764,
        50684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23295782506465912,
      "compression_ratio": 1.5743801593780518,
      "no_speech_prob": 0.031852126121520996
    },
    {
      "id": 19,
      "seek": 10808,
      "start": 1337.5900033569335,
      "end": 1344.3899987792968,
      "text": " activity diagrams where they fit in, or is that just to give like a broad spectrum to choose from?",
      "tokens": [
        50684,
        5191,
        36709,
        689,
        436,
        3318,
        294,
        11,
        420,
        307,
        300,
        445,
        281,
        976,
        411,
        257,
        4152,
        11143,
        281,
        2826,
        490,
        30,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23295782506465912,
      "compression_ratio": 1.5743801593780518,
      "no_speech_prob": 0.031852126121520996
    },
    {
      "id": 20,
      "seek": 10808,
      "start": 1345.2700036621093,
      "end": 1351.11,
      "text": " Yeah, I mean, I wouldn't necessarily always use an activity diagram, but they're quite useful,",
      "tokens": [
        51068,
        865,
        11,
        286,
        914,
        11,
        286,
        2759,
        380,
        4725,
        1009,
        764,
        364,
        5191,
        10686,
        11,
        457,
        436,
        434,
        1596,
        4420,
        11,
        51360
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23295782506465912,
      "compression_ratio": 1.5743801593780518,
      "no_speech_prob": 0.031852126121520996
    },
    {
      "id": 21,
      "seek": 10808,
      "start": 1351.9900048828124,
      "end": 1357.11,
      "text": " along with flow diagrams, sequence diagrams, there's so many different types of diagram,",
      "tokens": [
        51404,
        2051,
        365,
        3095,
        36709,
        11,
        8310,
        36709,
        11,
        456,
        311,
        370,
        867,
        819,
        3467,
        295,
        10686,
        11,
        51660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23295782506465912,
      "compression_ratio": 1.5743801593780518,
      "no_speech_prob": 0.031852126121520996
    },
    {
      "id": 22,
      "seek": 13400,
      "start": 1357.11,
      "end": 1364.5500024414061,
      "text": " it depends what you're trying to communicate. One of the diagrams that Mermaid does is called a",
      "tokens": [
        50364,
        309,
        5946,
        437,
        291,
        434,
        1382,
        281,
        7890,
        13,
        1485,
        295,
        264,
        36709,
        300,
        376,
        32124,
        775,
        307,
        1219,
        257,
        50736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2100907564163208,
      "compression_ratio": 1.6858407258987427,
      "no_speech_prob": 0.005707023665308952
    },
    {
      "id": 23,
      "seek": 13400,
      "start": 1364.5500024414061,
      "end": 1369.1900018310546,
      "text": " Sankey diagram, which I don't know if you've heard of, but I don't know if you've ever seen",
      "tokens": [
        50736,
        5271,
        4119,
        10686,
        11,
        597,
        286,
        500,
        380,
        458,
        498,
        291,
        600,
        2198,
        295,
        11,
        457,
        286,
        500,
        380,
        458,
        498,
        291,
        600,
        1562,
        1612,
        50968
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2100907564163208,
      "compression_ratio": 1.6858407258987427,
      "no_speech_prob": 0.005707023665308952
    },
    {
      "id": 24,
      "seek": 13400,
      "start": 1369.1900018310546,
      "end": 1376.4700006103515,
      "text": " these websites where they show maybe the flow of where users are using a website. So, they've",
      "tokens": [
        50968,
        613,
        12891,
        689,
        436,
        855,
        1310,
        264,
        3095,
        295,
        689,
        5022,
        366,
        1228,
        257,
        3144,
        13,
        407,
        11,
        436,
        600,
        51332
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2100907564163208,
      "compression_ratio": 1.6858407258987427,
      "no_speech_prob": 0.005707023665308952
    },
    {
      "id": 25,
      "seek": 13400,
      "start": 1376.4700006103515,
      "end": 1381.7499993896483,
      "text": " started at the home page, and then some of them have gone to this page, and so you get those lines,",
      "tokens": [
        51332,
        1409,
        412,
        264,
        1280,
        3028,
        11,
        293,
        550,
        512,
        295,
        552,
        362,
        2780,
        281,
        341,
        3028,
        11,
        293,
        370,
        291,
        483,
        729,
        3876,
        11,
        51596
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2100907564163208,
      "compression_ratio": 1.6858407258987427,
      "no_speech_prob": 0.005707023665308952
    },
    {
      "id": 26,
      "seek": 15864,
      "start": 1382.7100061035155,
      "end": 1387.5099938964843,
      "text": " and that could actually be quite useful for showing lots of different things in the system,",
      "tokens": [
        50412,
        293,
        300,
        727,
        767,
        312,
        1596,
        4420,
        337,
        4099,
        3195,
        295,
        819,
        721,
        294,
        264,
        1185,
        11,
        50652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2582465410232544,
      "compression_ratio": 1.8470587730407715,
      "no_speech_prob": 0.01563936471939087
    },
    {
      "id": 27,
      "seek": 15864,
      "start": 1387.5099938964843,
      "end": 1395.2700036621093,
      "text": " not just how users are. Is it where the lines have different signals, depending on how many people are",
      "tokens": [
        50652,
        406,
        445,
        577,
        5022,
        366,
        13,
        1119,
        309,
        689,
        264,
        3876,
        362,
        819,
        12354,
        11,
        5413,
        322,
        577,
        867,
        561,
        366,
        51040
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2582465410232544,
      "compression_ratio": 1.8470587730407715,
      "no_speech_prob": 0.01563936471939087
    },
    {
      "id": 28,
      "seek": 15864,
      "start": 1395.2700036621093,
      "end": 1399.830001220703,
      "text": " going in these different ways? So, you could use that in lots of different ways, not just",
      "tokens": [
        51040,
        516,
        294,
        613,
        819,
        2098,
        30,
        407,
        11,
        291,
        727,
        764,
        300,
        294,
        3195,
        295,
        819,
        2098,
        11,
        406,
        445,
        51268
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2582465410232544,
      "compression_ratio": 1.8470587730407715,
      "no_speech_prob": 0.01563936471939087
    },
    {
      "id": 29,
      "seek": 15864,
      "start": 1400.3899987792968,
      "end": 1405.830001220703,
      "text": " how people navigate a website, but how people are using a system or how your services are",
      "tokens": [
        51296,
        577,
        561,
        12350,
        257,
        3144,
        11,
        457,
        577,
        561,
        366,
        1228,
        257,
        1185,
        420,
        577,
        428,
        3328,
        366,
        51568
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2582465410232544,
      "compression_ratio": 1.8470587730407715,
      "no_speech_prob": 0.01563936471939087
    },
    {
      "id": 30,
      "seek": 15864,
      "start": 1405.830001220703,
      "end": 1411.589995727539,
      "text": " communicating with each other. And if you created that, you could see where the bottlenecks are,",
      "tokens": [
        51568,
        17559,
        365,
        1184,
        661,
        13,
        400,
        498,
        291,
        2942,
        300,
        11,
        291,
        727,
        536,
        689,
        264,
        44641,
        2761,
        366,
        11,
        51856
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2582465410232544,
      "compression_ratio": 1.8470587730407715,
      "no_speech_prob": 0.01563936471939087
    },
    {
      "id": 31,
      "seek": 18848,
      "start": 1411.7499993896483,
      "end": 1415.589995727539,
      "text": " where people are really using things.",
      "tokens": [
        50372,
        689,
        561,
        366,
        534,
        1228,
        721,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2642172574996948,
      "compression_ratio": 1.4680850505828857,
      "no_speech_prob": 0.002652361523360014
    },
    {
      "id": 32,
      "seek": 18848,
      "start": 1419.9900048828124,
      "end": 1423.9100030517577,
      "text": " So, to me, it seems what you're basically saying is, okay, so I want to do some diagrams,",
      "tokens": [
        50784,
        407,
        11,
        281,
        385,
        11,
        309,
        2544,
        437,
        291,
        434,
        1936,
        1566,
        307,
        11,
        1392,
        11,
        370,
        286,
        528,
        281,
        360,
        512,
        36709,
        11,
        50980
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2642172574996948,
      "compression_ratio": 1.4680850505828857,
      "no_speech_prob": 0.002652361523360014
    },
    {
      "id": 33,
      "seek": 18848,
      "start": 1423.9100030517577,
      "end": 1431.5099938964843,
      "text": " so I would use some tools, like you mentioned, like diagrams as code tools. And",
      "tokens": [
        50980,
        370,
        286,
        576,
        764,
        512,
        3873,
        11,
        411,
        291,
        2835,
        11,
        411,
        36709,
        382,
        3089,
        3873,
        13,
        400,
        51360
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2642172574996948,
      "compression_ratio": 1.4680850505828857,
      "no_speech_prob": 0.002652361523360014
    },
    {
      "id": 34,
      "seek": 20840,
      "start": 1432.070006713867,
      "end": 1441.11,
      "text": " would you suggest to only do that with AI support, or do you think you can?",
      "tokens": [
        50392,
        576,
        291,
        3402,
        281,
        787,
        360,
        300,
        365,
        7318,
        1406,
        11,
        420,
        360,
        291,
        519,
        291,
        393,
        30,
        50844
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20200136303901672,
      "compression_ratio": 1.692307710647583,
      "no_speech_prob": 0.028858277946710587
    },
    {
      "id": 35,
      "seek": 20840,
      "start": 1442.6300042724608,
      "end": 1449.4300073242186,
      "text": " I mean, there are studies that say if you look at code and coding, it's not obvious whether",
      "tokens": [
        50920,
        286,
        914,
        11,
        456,
        366,
        5313,
        300,
        584,
        498,
        291,
        574,
        412,
        3089,
        293,
        17720,
        11,
        309,
        311,
        406,
        6322,
        1968,
        51260
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20200136303901672,
      "compression_ratio": 1.692307710647583,
      "no_speech_prob": 0.028858277946710587
    },
    {
      "id": 36,
      "seek": 20840,
      "start": 1449.4300073242186,
      "end": 1454.5500024414061,
      "text": " using AI technology actually improves things and makes people more productive. There are",
      "tokens": [
        51260,
        1228,
        7318,
        2899,
        767,
        24771,
        721,
        293,
        1669,
        561,
        544,
        13304,
        13,
        821,
        366,
        51516
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20200136303901672,
      "compression_ratio": 1.692307710647583,
      "no_speech_prob": 0.028858277946710587
    },
    {
      "id": 37,
      "seek": 20840,
      "start": 1454.5500024414061,
      "end": 1460.070006713867,
      "text": " some studies that say that people think they are more productive, but in reality, they are not.",
      "tokens": [
        51516,
        512,
        5313,
        300,
        584,
        300,
        561,
        519,
        436,
        366,
        544,
        13304,
        11,
        457,
        294,
        4103,
        11,
        436,
        366,
        406,
        13,
        51792
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20200136303901672,
      "compression_ratio": 1.692307710647583,
      "no_speech_prob": 0.028858277946710587
    },
    {
      "id": 38,
      "seek": 23696,
      "start": 1460.070006713867,
      "end": 1465.589995727539,
      "text": " So, what's your suggestion? Would you use diagrams as code only with AI? Do you think",
      "tokens": [
        50364,
        407,
        11,
        437,
        311,
        428,
        16541,
        30,
        6068,
        291,
        764,
        36709,
        382,
        3089,
        787,
        365,
        7318,
        30,
        1144,
        291,
        519,
        50640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1704922616481781,
      "compression_ratio": 1.6588234901428223,
      "no_speech_prob": 0.0018890538485720754
    },
    {
      "id": 39,
      "seek": 23696,
      "start": 1465.589995727539,
      "end": 1470.5500024414061,
      "text": " it's a strong support or is it more optional? What's your take on that?",
      "tokens": [
        50640,
        309,
        311,
        257,
        2068,
        1406,
        420,
        307,
        309,
        544,
        17312,
        30,
        708,
        311,
        428,
        747,
        322,
        300,
        30,
        50888
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1704922616481781,
      "compression_ratio": 1.6588234901428223,
      "no_speech_prob": 0.0018890538485720754
    },
    {
      "id": 40,
      "seek": 23696,
      "start": 1470.5500024414061,
      "end": 1474.7100061035155,
      "text": " I think it's definitely optional. And in fact, when I teach the course, I say to people",
      "tokens": [
        50888,
        286,
        519,
        309,
        311,
        2138,
        17312,
        13,
        400,
        294,
        1186,
        11,
        562,
        286,
        2924,
        264,
        1164,
        11,
        286,
        584,
        281,
        561,
        51096
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1704922616481781,
      "compression_ratio": 1.6588234901428223,
      "no_speech_prob": 0.0018890538485720754
    },
    {
      "id": 41,
      "seek": 23696,
      "start": 1474.7100061035155,
      "end": 1479.349990234375,
      "text": " when they're doing the exercises, you can use AI if you want, or you can hand code this.",
      "tokens": [
        51096,
        562,
        436,
        434,
        884,
        264,
        11900,
        11,
        291,
        393,
        764,
        7318,
        498,
        291,
        528,
        11,
        420,
        291,
        393,
        1011,
        3089,
        341,
        13,
        51328
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1704922616481781,
      "compression_ratio": 1.6588234901428223,
      "no_speech_prob": 0.0018890538485720754
    },
    {
      "id": 42,
      "seek": 23696,
      "start": 1480.1500085449218,
      "end": 1488.3100122070311,
      "text": " One of the examples I show is a really long prompt saying what I would like to show in a",
      "tokens": [
        51368,
        1485,
        295,
        264,
        5110,
        286,
        855,
        307,
        257,
        534,
        938,
        12391,
        1566,
        437,
        286,
        576,
        411,
        281,
        855,
        294,
        257,
        51776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1704922616481781,
      "compression_ratio": 1.6588234901428223,
      "no_speech_prob": 0.0018890538485720754
    },
    {
      "id": 43,
      "seek": 26520,
      "start": 1488.3100122070311,
      "end": 1492.2299951171874,
      "text": " sequence diagram. And if you look at how much text you have to actually give it, you may as",
      "tokens": [
        50364,
        8310,
        10686,
        13,
        400,
        498,
        291,
        574,
        412,
        577,
        709,
        2487,
        291,
        362,
        281,
        767,
        976,
        309,
        11,
        291,
        815,
        382,
        50560
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20582248270511627,
      "compression_ratio": 1.6738197803497314,
      "no_speech_prob": 0.04499952867627144
    },
    {
      "id": 44,
      "seek": 26520,
      "start": 1492.2299951171874,
      "end": 1499.9900048828124,
      "text": " well have just written it in plant URL or mermaid from the start, it would actually be less writing",
      "tokens": [
        50560,
        731,
        362,
        445,
        3720,
        309,
        294,
        3709,
        12905,
        420,
        43146,
        490,
        264,
        722,
        11,
        309,
        576,
        767,
        312,
        1570,
        3579,
        50948
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20582248270511627,
      "compression_ratio": 1.6738197803497314,
      "no_speech_prob": 0.04499952867627144
    },
    {
      "id": 45,
      "seek": 26520,
      "start": 1499.9900048828124,
      "end": 1505.4300073242186,
      "text": " if you just typed it. So, that's why I'm teaching these basics and saying to people you need these",
      "tokens": [
        50948,
        498,
        291,
        445,
        33941,
        309,
        13,
        407,
        11,
        300,
        311,
        983,
        286,
        478,
        4571,
        613,
        14688,
        293,
        1566,
        281,
        561,
        291,
        643,
        613,
        51220
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20582248270511627,
      "compression_ratio": 1.6738197803497314,
      "no_speech_prob": 0.04499952867627144
    },
    {
      "id": 46,
      "seek": 26520,
      "start": 1505.4300073242186,
      "end": 1512.2299951171874,
      "text": " skills because you need to know when it's actually worth using the AI and when it's not. So, if you",
      "tokens": [
        51220,
        3942,
        570,
        291,
        643,
        281,
        458,
        562,
        309,
        311,
        767,
        3163,
        1228,
        264,
        7318,
        293,
        562,
        309,
        311,
        406,
        13,
        407,
        11,
        498,
        291,
        51560
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20582248270511627,
      "compression_ratio": 1.6738197803497314,
      "no_speech_prob": 0.04499952867627144
    },
    {
      "id": 47,
      "seek": 28912,
      "start": 1512.9499963378905,
      "end": 1519.1899865722655,
      "text": " are really struggling with an error, if you are thinking, I've got a load of plant URL diagrams",
      "tokens": [
        50400,
        366,
        534,
        9314,
        365,
        364,
        6713,
        11,
        498,
        291,
        366,
        1953,
        11,
        286,
        600,
        658,
        257,
        3677,
        295,
        3709,
        624,
        49,
        43,
        36709,
        50712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26232486963272095,
      "compression_ratio": 1.6852589845657349,
      "no_speech_prob": 0.3493135869503021
    },
    {
      "id": 48,
      "seek": 28912,
      "start": 1519.1899865722655,
      "end": 1523.0300134277343,
      "text": " and I want to convert them to mermaid or I want to convert them to structuriser,",
      "tokens": [
        50712,
        293,
        286,
        528,
        281,
        7620,
        552,
        281,
        43146,
        420,
        286,
        528,
        281,
        7620,
        552,
        281,
        6594,
        374,
        6694,
        11,
        50904
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26232486963272095,
      "compression_ratio": 1.6852589845657349,
      "no_speech_prob": 0.3493135869503021
    },
    {
      "id": 49,
      "seek": 28912,
      "start": 1523.0300134277343,
      "end": 1528.7899926757811,
      "text": " that's knowing when it's worth, you're going to get that time saving, but also knowing",
      "tokens": [
        50904,
        300,
        311,
        5276,
        562,
        309,
        311,
        3163,
        11,
        291,
        434,
        516,
        281,
        483,
        300,
        565,
        6816,
        11,
        457,
        611,
        5276,
        51192
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26232486963272095,
      "compression_ratio": 1.6852589845657349,
      "no_speech_prob": 0.3493135869503021
    },
    {
      "id": 50,
      "seek": 28912,
      "start": 1528.7899926757811,
      "end": 1533.590010986328,
      "text": " what to look for the hallucinations and errors and things like that. Like when it says,",
      "tokens": [
        51192,
        437,
        281,
        574,
        337,
        264,
        35212,
        10325,
        293,
        13603,
        293,
        721,
        411,
        300,
        13,
        1743,
        562,
        309,
        1619,
        11,
        51432
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26232486963272095,
      "compression_ratio": 1.6852589845657349,
      "no_speech_prob": 0.3493135869503021
    },
    {
      "id": 51,
      "seek": 28912,
      "start": 1533.590010986328,
      "end": 1538.870009765625,
      "text": " oh, yeah, you can just use this keyword to move stuff around. Yeah, no.",
      "tokens": [
        51432,
        1954,
        11,
        1338,
        11,
        291,
        393,
        445,
        764,
        341,
        20428,
        281,
        1286,
        1507,
        926,
        13,
        865,
        11,
        572,
        13,
        51696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26232486963272095,
      "compression_ratio": 1.6852589845657349,
      "no_speech_prob": 0.3493135869503021
    },
    {
      "id": 52,
      "seek": 31576,
      "start": 1538.870009765625,
      "end": 1548.7899926757811,
      "text": " So, as far as I remember, each diagram type has a different domain specific language",
      "tokens": [
        50364,
        407,
        11,
        382,
        1400,
        382,
        286,
        1604,
        11,
        1184,
        10686,
        2010,
        575,
        257,
        819,
        9274,
        2685,
        2856,
        50860
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2149038463830948,
      "compression_ratio": 1.5428571701049805,
      "no_speech_prob": 0.003646763041615486
    },
    {
      "id": 53,
      "seek": 31576,
      "start": 1549.590010986328,
      "end": 1559.5099938964843,
      "text": " and some are more complex and some are easier. Would you say that some diagram types are easier",
      "tokens": [
        50900,
        293,
        512,
        366,
        544,
        3997,
        293,
        512,
        366,
        3571,
        13,
        6068,
        291,
        584,
        300,
        512,
        10686,
        3467,
        366,
        3571,
        51396
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2149038463830948,
      "compression_ratio": 1.5428571701049805,
      "no_speech_prob": 0.003646763041615486
    },
    {
      "id": 54,
      "seek": 31576,
      "start": 1559.5099938964843,
      "end": 1565.9900048828124,
      "text": " to handle with AI than others? And I mean, for instance, with a sequence diagram, I guess",
      "tokens": [
        51396,
        281,
        4813,
        365,
        7318,
        813,
        2357,
        30,
        400,
        286,
        914,
        11,
        337,
        5197,
        11,
        365,
        257,
        8310,
        10686,
        11,
        286,
        2041,
        51720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2149038463830948,
      "compression_ratio": 1.5428571701049805,
      "no_speech_prob": 0.003646763041615486
    },
    {
      "id": 55,
      "seek": 34288,
      "start": 1565.9900048828124,
      "end": 1574.3100122070311,
      "text": " there's not much layout information in there because it's just a sequence. But with other",
      "tokens": [
        50364,
        456,
        311,
        406,
        709,
        13333,
        1589,
        294,
        456,
        570,
        309,
        311,
        445,
        257,
        8310,
        13,
        583,
        365,
        661,
        50780
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2055036723613739,
      "compression_ratio": 1.5027027130126953,
      "no_speech_prob": 0.00030516463448293507
    },
    {
      "id": 56,
      "seek": 34288,
      "start": 1574.3100122070311,
      "end": 1580.9499963378905,
      "text": " diagram types, I run into problems with the layout. Is this maybe a point where the AI can",
      "tokens": [
        50780,
        10686,
        3467,
        11,
        286,
        1190,
        666,
        2740,
        365,
        264,
        13333,
        13,
        1119,
        341,
        1310,
        257,
        935,
        689,
        264,
        7318,
        393,
        51112
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2055036723613739,
      "compression_ratio": 1.5027027130126953,
      "no_speech_prob": 0.00030516463448293507
    },
    {
      "id": 57,
      "seek": 34288,
      "start": 1582.3100122070311,
      "end": 1590.4699853515624,
      "text": " be of good help? Yeah, I mean, I think as long as the AI kind of has the context of understanding",
      "tokens": [
        51180,
        312,
        295,
        665,
        854,
        30,
        865,
        11,
        286,
        914,
        11,
        286,
        519,
        382,
        938,
        382,
        264,
        7318,
        733,
        295,
        575,
        264,
        4319,
        295,
        3701,
        51588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2055036723613739,
      "compression_ratio": 1.5027027130126953,
      "no_speech_prob": 0.00030516463448293507
    },
    {
      "id": 58,
      "seek": 36736,
      "start": 1591.11,
      "end": 1597.7500146484374,
      "text": " that if it's been taught on the DSL, the domain specific language,",
      "tokens": [
        50396,
        300,
        498,
        309,
        311,
        668,
        5928,
        322,
        264,
        15816,
        43,
        11,
        264,
        9274,
        2685,
        2856,
        11,
        50728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23972657322883606,
      "compression_ratio": 1.4254143238067627,
      "no_speech_prob": 0.03330224007368088
    },
    {
      "id": 59,
      "seek": 36736,
      "start": 1598.9499963378905,
      "end": 1605.590010986328,
      "text": " you can, of course, use things like MCP servers. I think there's one called context seven. I think",
      "tokens": [
        50788,
        291,
        393,
        11,
        295,
        1164,
        11,
        764,
        721,
        411,
        8797,
        47,
        15909,
        13,
        286,
        519,
        456,
        311,
        472,
        1219,
        4319,
        3407,
        13,
        286,
        519,
        51120
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23972657322883606,
      "compression_ratio": 1.4254143238067627,
      "no_speech_prob": 0.03330224007368088
    },
    {
      "id": 60,
      "seek": 36736,
      "start": 1605.590010986328,
      "end": 1614.069991455078,
      "text": " it's called that, which I've been told is good for coding, but also it does have information",
      "tokens": [
        51120,
        309,
        311,
        1219,
        300,
        11,
        597,
        286,
        600,
        668,
        1907,
        307,
        665,
        337,
        17720,
        11,
        457,
        611,
        309,
        775,
        362,
        1589,
        51544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23972657322883606,
      "compression_ratio": 1.4254143238067627,
      "no_speech_prob": 0.03330224007368088
    },
    {
      "id": 61,
      "seek": 39096,
      "start": 1614.069991455078,
      "end": 1620.2299951171874,
      "text": " in there on Mermaid and Blank UML. And someone in my class yesterday actually said they got",
      "tokens": [
        50364,
        294,
        456,
        322,
        376,
        32124,
        293,
        2177,
        657,
        624,
        12683,
        13,
        400,
        1580,
        294,
        452,
        1508,
        5186,
        767,
        848,
        436,
        658,
        50672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23821374773979187,
      "compression_ratio": 1.5720164775848389,
      "no_speech_prob": 0.41668984293937683
    },
    {
      "id": 62,
      "seek": 39096,
      "start": 1620.2299951171874,
      "end": 1627.0300134277343,
      "text": " really good results. They thought it was probably because they were using that MCP server. So as",
      "tokens": [
        50672,
        534,
        665,
        3542,
        13,
        814,
        1194,
        309,
        390,
        1391,
        570,
        436,
        645,
        1228,
        300,
        8797,
        47,
        7154,
        13,
        407,
        382,
        51012
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23821374773979187,
      "compression_ratio": 1.5720164775848389,
      "no_speech_prob": 0.41668984293937683
    },
    {
      "id": 63,
      "seek": 39096,
      "start": 1627.0300134277343,
      "end": 1633.9099877929686,
      "text": " long as AI kind of understands it, it can probably help you, but it may still try and make things up",
      "tokens": [
        51012,
        938,
        382,
        7318,
        733,
        295,
        15146,
        309,
        11,
        309,
        393,
        1391,
        854,
        291,
        11,
        457,
        309,
        815,
        920,
        853,
        293,
        652,
        721,
        493,
        51356
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23821374773979187,
      "compression_ratio": 1.5720164775848389,
      "no_speech_prob": 0.41668984293937683
    },
    {
      "id": 64,
      "seek": 39096,
      "start": 1633.9099877929686,
      "end": 1642.5500024414061,
      "text": " because it's trying to answer you. And if it doesn't understand something, then it will just",
      "tokens": [
        51356,
        570,
        309,
        311,
        1382,
        281,
        1867,
        291,
        13,
        400,
        498,
        309,
        1177,
        380,
        1223,
        746,
        11,
        550,
        309,
        486,
        445,
        51788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23821374773979187,
      "compression_ratio": 1.5720164775848389,
      "no_speech_prob": 0.41668984293937683
    },
    {
      "id": 65,
      "seek": 41944,
      "start": 1642.5500024414061,
      "end": 1649.830001220703,
      "text": " still try. So in your slides, I've seen that, I think it was the activity diagram where there's an",
      "tokens": [
        50364,
        920,
        853,
        13,
        407,
        294,
        428,
        9788,
        11,
        286,
        600,
        1612,
        300,
        11,
        286,
        519,
        309,
        390,
        264,
        5191,
        10686,
        689,
        456,
        311,
        364,
        50728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2040235996246338,
      "compression_ratio": 1.4769231081008911,
      "no_speech_prob": 0.003688989207148552
    },
    {
      "id": 66,
      "seek": 41944,
      "start": 1649.830001220703,
      "end": 1658.3899987792968,
      "text": " old DSL available and a new one, which is still in beta. Is this such a case where the LLM might",
      "tokens": [
        50728,
        1331,
        15816,
        43,
        2435,
        293,
        257,
        777,
        472,
        11,
        597,
        307,
        920,
        294,
        9861,
        13,
        1119,
        341,
        1270,
        257,
        1389,
        689,
        264,
        441,
        43,
        44,
        1062,
        51156
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2040235996246338,
      "compression_ratio": 1.4769231081008911,
      "no_speech_prob": 0.003688989207148552
    },
    {
      "id": 67,
      "seek": 41944,
      "start": 1658.3899987792968,
      "end": 1666.870009765625,
      "text": " not know the new version yet? And so it might be better to use still the old domain specific",
      "tokens": [
        51156,
        406,
        458,
        264,
        777,
        3037,
        1939,
        30,
        400,
        370,
        309,
        1062,
        312,
        1101,
        281,
        764,
        920,
        264,
        1331,
        9274,
        2685,
        51580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2040235996246338,
      "compression_ratio": 1.4769231081008911,
      "no_speech_prob": 0.003688989207148552
    },
    {
      "id": 68,
      "seek": 44376,
      "start": 1666.870009765625,
      "end": 1675.0300134277343,
      "text": " language. Yes. So with these, although these diagrams as code languages have been around",
      "tokens": [
        50364,
        2856,
        13,
        1079,
        13,
        407,
        365,
        613,
        11,
        4878,
        613,
        36709,
        382,
        3089,
        8650,
        362,
        668,
        926,
        50772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27303028106689453,
      "compression_ratio": 1.5355191230773926,
      "no_speech_prob": 0.31563475728034973
    },
    {
      "id": 69,
      "seek": 44376,
      "start": 1675.0300134277343,
      "end": 1681.9099877929686,
      "text": " for a while, they are, of course, still being added to. And some of them are in beta, especially",
      "tokens": [
        50772,
        337,
        257,
        1339,
        11,
        436,
        366,
        11,
        295,
        1164,
        11,
        920,
        885,
        3869,
        281,
        13,
        400,
        512,
        295,
        552,
        366,
        294,
        9861,
        11,
        2318,
        51116
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27303028106689453,
      "compression_ratio": 1.5355191230773926,
      "no_speech_prob": 0.31563475728034973
    },
    {
      "id": 70,
      "seek": 44376,
      "start": 1683.7500146484374,
      "end": 1690.870009765625,
      "text": " with Blank UML and Mermaid, they are adding new ones on. Mermaid probably a bit more than Blank",
      "tokens": [
        51208,
        365,
        2177,
        657,
        624,
        12683,
        293,
        376,
        32124,
        11,
        436,
        366,
        5127,
        777,
        2306,
        322,
        13,
        376,
        32124,
        1391,
        257,
        857,
        544,
        813,
        2177,
        657,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27303028106689453,
      "compression_ratio": 1.5355191230773926,
      "no_speech_prob": 0.31563475728034973
    },
    {
      "id": 71,
      "seek": 46776,
      "start": 1690.870009765625,
      "end": 1698.3100122070311,
      "text": " UML now. And yeah, they're not going to know about those ones that are in beta. And sometimes",
      "tokens": [
        50364,
        624,
        12683,
        586,
        13,
        400,
        1338,
        11,
        436,
        434,
        406,
        516,
        281,
        458,
        466,
        729,
        2306,
        300,
        366,
        294,
        9861,
        13,
        400,
        2171,
        50736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2161458283662796,
      "compression_ratio": 1.626609444618225,
      "no_speech_prob": 0.22724545001983643
    },
    {
      "id": 72,
      "seek": 46776,
      "start": 1698.3100122070311,
      "end": 1704.870009765625,
      "text": " they do change things. There was one, I think it might be in sequence diagrams with Blank UML where",
      "tokens": [
        50736,
        436,
        360,
        1319,
        721,
        13,
        821,
        390,
        472,
        11,
        286,
        519,
        309,
        1062,
        312,
        294,
        8310,
        36709,
        365,
        2177,
        657,
        624,
        12683,
        689,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2161458283662796,
      "compression_ratio": 1.626609444618225,
      "no_speech_prob": 0.22724545001983643
    },
    {
      "id": 73,
      "seek": 46776,
      "start": 1704.870009765625,
      "end": 1709.7500146484374,
      "text": " they just changed it from one to the other. But I might be thinking of something else.",
      "tokens": [
        51064,
        436,
        445,
        3105,
        309,
        490,
        472,
        281,
        264,
        661,
        13,
        583,
        286,
        1062,
        312,
        1953,
        295,
        746,
        1646,
        13,
        51308
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2161458283662796,
      "compression_ratio": 1.626609444618225,
      "no_speech_prob": 0.22724545001983643
    },
    {
      "id": 74,
      "seek": 46776,
      "start": 1711.0300134277343,
      "end": 1718.5500024414061,
      "text": " So yes, your LLM is going to have a cutoff point where it doesn't know about things. And so you're",
      "tokens": [
        51372,
        407,
        2086,
        11,
        428,
        441,
        43,
        44,
        307,
        516,
        281,
        362,
        257,
        1723,
        4506,
        935,
        689,
        309,
        1177,
        380,
        458,
        466,
        721,
        13,
        400,
        370,
        291,
        434,
        51748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2161458283662796,
      "compression_ratio": 1.626609444618225,
      "no_speech_prob": 0.22724545001983643
    },
    {
      "id": 75,
      "seek": 49544,
      "start": 1718.5500024414061,
      "end": 1726.1500085449218,
      "text": " going to have to add in things like an MCP server or just say, look at this documentation,",
      "tokens": [
        50364,
        516,
        281,
        362,
        281,
        909,
        294,
        721,
        411,
        364,
        8797,
        47,
        7154,
        420,
        445,
        584,
        11,
        574,
        412,
        341,
        14333,
        11,
        50744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2253398299217224,
      "compression_ratio": 1.5489130020141602,
      "no_speech_prob": 0.027788860723376274
    },
    {
      "id": 76,
      "seek": 49544,
      "start": 1727.0300134277343,
      "end": 1735.349990234375,
      "text": " or this is this is the basic structure that I'm expecting you to use. Now, do this. So it's going",
      "tokens": [
        50788,
        420,
        341,
        307,
        341,
        307,
        264,
        3875,
        3877,
        300,
        286,
        478,
        9650,
        291,
        281,
        764,
        13,
        823,
        11,
        360,
        341,
        13,
        407,
        309,
        311,
        516,
        51204
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2253398299217224,
      "compression_ratio": 1.5489130020141602,
      "no_speech_prob": 0.027788860723376274
    },
    {
      "id": 77,
      "seek": 49544,
      "start": 1735.349990234375,
      "end": 1741.829970703125,
      "text": " to your results are going to vary depending on the model you're using, depending on the training",
      "tokens": [
        51204,
        281,
        428,
        3542,
        366,
        516,
        281,
        10559,
        5413,
        322,
        264,
        2316,
        291,
        434,
        1228,
        11,
        5413,
        322,
        264,
        3097,
        51528
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2253398299217224,
      "compression_ratio": 1.5489130020141602,
      "no_speech_prob": 0.027788860723376274
    },
    {
      "id": 78,
      "seek": 51872,
      "start": 1741.829970703125,
      "end": 1747.2699731445311,
      "text": " data, and depending on how specific you are when you what you ask it to do.",
      "tokens": [
        50364,
        1412,
        11,
        293,
        5413,
        322,
        577,
        2685,
        291,
        366,
        562,
        291,
        437,
        291,
        1029,
        309,
        281,
        360,
        13,
        50636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22777289152145386,
      "compression_ratio": 1.3988438844680786,
      "no_speech_prob": 0.4038490653038025
    },
    {
      "id": 79,
      "seek": 51872,
      "start": 1748.7899926757811,
      "end": 1755.829970703125,
      "text": " Which model do you use most often? I have started using Claude more recently.",
      "tokens": [
        50712,
        3013,
        2316,
        360,
        291,
        764,
        881,
        2049,
        30,
        286,
        362,
        1409,
        1228,
        12947,
        2303,
        544,
        3938,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22777289152145386,
      "compression_ratio": 1.3988438844680786,
      "no_speech_prob": 0.4038490653038025
    },
    {
      "id": 80,
      "seek": 51872,
      "start": 1757.4300073242186,
      "end": 1769.7500146484374,
      "text": " But I've used ChatGPT a fair bit as well. Claude seems to be at least as good as ChatGPT",
      "tokens": [
        51144,
        583,
        286,
        600,
        1143,
        27503,
        38,
        47,
        51,
        257,
        3143,
        857,
        382,
        731,
        13,
        12947,
        2303,
        2544,
        281,
        312,
        412,
        1935,
        382,
        665,
        382,
        27503,
        38,
        47,
        51,
        51760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22777289152145386,
      "compression_ratio": 1.3988438844680786,
      "no_speech_prob": 0.4038490653038025
    },
    {
      "id": 81,
      "seek": 54664,
      "start": 1769.7500146484374,
      "end": 1776.4699853515624,
      "text": " in most things. This is without supplementing it with an MCP server or anything. But it's not",
      "tokens": [
        50364,
        294,
        881,
        721,
        13,
        639,
        307,
        1553,
        15436,
        278,
        309,
        365,
        364,
        8797,
        47,
        7154,
        420,
        1340,
        13,
        583,
        309,
        311,
        406,
        50700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23333798348903656,
      "compression_ratio": 1.5756303071975708,
      "no_speech_prob": 0.06843419373035431
    },
    {
      "id": 82,
      "seek": 54664,
      "start": 1776.4699853515624,
      "end": 1784.4699853515624,
      "text": " perfect. I gave it a Blank UML file with a load of errors in, and it didn't pick up on some of",
      "tokens": [
        50700,
        2176,
        13,
        286,
        2729,
        309,
        257,
        2177,
        657,
        624,
        12683,
        3991,
        365,
        257,
        3677,
        295,
        13603,
        294,
        11,
        293,
        309,
        994,
        380,
        1888,
        493,
        322,
        512,
        295,
        51100
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23333798348903656,
      "compression_ratio": 1.5756303071975708,
      "no_speech_prob": 0.06843419373035431
    },
    {
      "id": 83,
      "seek": 54664,
      "start": 1784.4699853515624,
      "end": 1793.11,
      "text": " them. It thought that a bit of gibberish that I chucked in there was supposed to be a color code,",
      "tokens": [
        51100,
        552,
        13,
        467,
        1194,
        300,
        257,
        857,
        295,
        4553,
        43189,
        300,
        286,
        20870,
        292,
        294,
        456,
        390,
        3442,
        281,
        312,
        257,
        2017,
        3089,
        11,
        51532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23333798348903656,
      "compression_ratio": 1.5756303071975708,
      "no_speech_prob": 0.06843419373035431
    },
    {
      "id": 84,
      "seek": 54664,
      "start": 1793.9099877929686,
      "end": 1798.1499780273436,
      "text": " but started with a hash. And it started with two hashes. And then it tried to change it,",
      "tokens": [
        51572,
        457,
        1409,
        365,
        257,
        22019,
        13,
        400,
        309,
        1409,
        365,
        732,
        575,
        8076,
        13,
        400,
        550,
        309,
        3031,
        281,
        1319,
        309,
        11,
        51784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23333798348903656,
      "compression_ratio": 1.5756303071975708,
      "no_speech_prob": 0.06843419373035431
    },
    {
      "id": 85,
      "seek": 57504,
      "start": 1798.1499780273436,
      "end": 1803.829970703125,
      "text": " but it still had two hashes. And I was like, that's complete nonsense. So none of them are",
      "tokens": [
        50364,
        457,
        309,
        920,
        632,
        732,
        575,
        8076,
        13,
        400,
        286,
        390,
        411,
        11,
        300,
        311,
        3566,
        14925,
        13,
        407,
        6022,
        295,
        552,
        366,
        50648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19205144047737122,
      "compression_ratio": 1.5514403581619263,
      "no_speech_prob": 0.03673035651445389
    },
    {
      "id": 86,
      "seek": 57504,
      "start": 1803.829970703125,
      "end": 1809.9900048828124,
      "text": " perfect. I think they just released a new model. So we have to try it out. Yes, that's that's what",
      "tokens": [
        50648,
        2176,
        13,
        286,
        519,
        436,
        445,
        4736,
        257,
        777,
        2316,
        13,
        407,
        321,
        362,
        281,
        853,
        309,
        484,
        13,
        1079,
        11,
        300,
        311,
        300,
        311,
        437,
        50956
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19205144047737122,
      "compression_ratio": 1.5514403581619263,
      "no_speech_prob": 0.03673035651445389
    },
    {
      "id": 87,
      "seek": 57504,
      "start": 1809.9900048828124,
      "end": 1816.2299951171874,
      "text": " I do with this course. Every time I teach it, pretty much I'm reviewing it and saying, right,",
      "tokens": [
        50956,
        286,
        360,
        365,
        341,
        1164,
        13,
        2048,
        565,
        286,
        2924,
        309,
        11,
        1238,
        709,
        286,
        478,
        19576,
        309,
        293,
        1566,
        11,
        558,
        11,
        51268
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19205144047737122,
      "compression_ratio": 1.5514403581619263,
      "no_speech_prob": 0.03673035651445389
    },
    {
      "id": 88,
      "seek": 57504,
      "start": 1816.2299951171874,
      "end": 1823.5100244140624,
      "text": " are there any new diagrams to talk about? How is this model doing? And I do a few comparisons",
      "tokens": [
        51268,
        366,
        456,
        604,
        777,
        36709,
        281,
        751,
        466,
        30,
        1012,
        307,
        341,
        2316,
        884,
        30,
        400,
        286,
        360,
        257,
        1326,
        33157,
        51632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19205144047737122,
      "compression_ratio": 1.5514403581619263,
      "no_speech_prob": 0.03673035651445389
    },
    {
      "id": 89,
      "seek": 60040,
      "start": 1823.5100244140624,
      "end": 1827.9099877929686,
      "text": " in there. I'm like, this is how it happened, what happened in September last year. This is",
      "tokens": [
        50364,
        294,
        456,
        13,
        286,
        478,
        411,
        11,
        341,
        307,
        577,
        309,
        2011,
        11,
        437,
        2011,
        294,
        7216,
        1036,
        1064,
        13,
        639,
        307,
        50584
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21055728197097778,
      "compression_ratio": 1.6870503425598145,
      "no_speech_prob": 0.421612024307251
    },
    {
      "id": 90,
      "seek": 60040,
      "start": 1827.9099877929686,
      "end": 1833.0299829101561,
      "text": " September this year. And sometimes they actually get a bit worse, because of course, it's",
      "tokens": [
        50584,
        7216,
        341,
        1064,
        13,
        400,
        2171,
        436,
        767,
        483,
        257,
        857,
        5324,
        11,
        570,
        295,
        1164,
        11,
        309,
        311,
        50840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21055728197097778,
      "compression_ratio": 1.6870503425598145,
      "no_speech_prob": 0.421612024307251
    },
    {
      "id": 91,
      "seek": 60040,
      "start": 1833.0299829101561,
      "end": 1837.7500146484374,
      "text": " non-deterministic. And I'm just saying, right, do this now and seeing whether it can do it at that",
      "tokens": [
        50840,
        2107,
        12,
        49136,
        259,
        3142,
        13,
        400,
        286,
        478,
        445,
        1566,
        11,
        558,
        11,
        360,
        341,
        586,
        293,
        2577,
        1968,
        309,
        393,
        360,
        309,
        412,
        300,
        51076
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21055728197097778,
      "compression_ratio": 1.6870503425598145,
      "no_speech_prob": 0.421612024307251
    },
    {
      "id": 92,
      "seek": 60040,
      "start": 1837.7500146484374,
      "end": 1844.7099755859374,
      "text": " particular time. It's a bit like sitting an exam or something. You can work really hard for two",
      "tokens": [
        51076,
        1729,
        565,
        13,
        467,
        311,
        257,
        857,
        411,
        3798,
        364,
        1139,
        420,
        746,
        13,
        509,
        393,
        589,
        534,
        1152,
        337,
        732,
        51424
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21055728197097778,
      "compression_ratio": 1.6870503425598145,
      "no_speech_prob": 0.421612024307251
    },
    {
      "id": 93,
      "seek": 60040,
      "start": 1844.7099755859374,
      "end": 1850.9500268554686,
      "text": " years, sit the exam and not do very well on that day. It was a quite interesting part in your",
      "tokens": [
        51424,
        924,
        11,
        1394,
        264,
        1139,
        293,
        406,
        360,
        588,
        731,
        322,
        300,
        786,
        13,
        467,
        390,
        257,
        1596,
        1880,
        644,
        294,
        428,
        51736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21055728197097778,
      "compression_ratio": 1.6870503425598145,
      "no_speech_prob": 0.421612024307251
    },
    {
      "id": 94,
      "seek": 62784,
      "start": 1850.9500268554686,
      "end": 1860.870009765625,
      "text": " workshop that you compared the results from September 24, something like this. And now it's",
      "tokens": [
        50364,
        13541,
        300,
        291,
        5347,
        264,
        3542,
        490,
        7216,
        4022,
        11,
        746,
        411,
        341,
        13,
        400,
        586,
        309,
        311,
        50860
      ],
      "temperature": 0.0,
      "avg_logprob": -0.234375,
      "compression_ratio": 1.643478274345398,
      "no_speech_prob": 0.02427089959383011
    },
    {
      "id": 95,
      "seek": 62784,
      "start": 1860.870009765625,
      "end": 1871.2699731445311,
      "text": " better. So this gives you more insights. That's quite good. Yes, I was saying when I was teaching",
      "tokens": [
        50860,
        1101,
        13,
        407,
        341,
        2709,
        291,
        544,
        14310,
        13,
        663,
        311,
        1596,
        665,
        13,
        1079,
        11,
        286,
        390,
        1566,
        562,
        286,
        390,
        4571,
        51380
      ],
      "temperature": 0.0,
      "avg_logprob": -0.234375,
      "compression_ratio": 1.643478274345398,
      "no_speech_prob": 0.02427089959383011
    },
    {
      "id": 96,
      "seek": 62784,
      "start": 1871.2699731445311,
      "end": 1876.390029296875,
      "text": " yesterday that people in that group were actually getting better results than people when I've",
      "tokens": [
        51380,
        5186,
        300,
        561,
        294,
        300,
        1594,
        645,
        767,
        1242,
        1101,
        3542,
        813,
        561,
        562,
        286,
        600,
        51636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.234375,
      "compression_ratio": 1.643478274345398,
      "no_speech_prob": 0.02427089959383011
    },
    {
      "id": 97,
      "seek": 62784,
      "start": 1876.390029296875,
      "end": 1880.3100122070311,
      "text": " taught this before. And I was saying, well, maybe the fact that I'm teaching this is actually",
      "tokens": [
        51636,
        5928,
        341,
        949,
        13,
        400,
        286,
        390,
        1566,
        11,
        731,
        11,
        1310,
        264,
        1186,
        300,
        286,
        478,
        4571,
        341,
        307,
        767,
        51832
      ],
      "temperature": 0.0,
      "avg_logprob": -0.234375,
      "compression_ratio": 1.643478274345398,
      "no_speech_prob": 0.02427089959383011
    },
    {
      "id": 98,
      "seek": 65720,
      "start": 1880.3100122070311,
      "end": 1885.5100244140624,
      "text": " teaching these LLMs to do it better. Yeah, that's quite an interesting one to think on.",
      "tokens": [
        50364,
        4571,
        613,
        441,
        43,
        26386,
        281,
        360,
        309,
        1101,
        13,
        865,
        11,
        300,
        311,
        1596,
        364,
        1880,
        472,
        281,
        519,
        322,
        13,
        50624
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22195316851139069,
      "compression_ratio": 1.535398244857788,
      "no_speech_prob": 0.022386206313967705
    },
    {
      "id": 99,
      "seek": 65720,
      "start": 1886.5500024414061,
      "end": 1890.63001953125,
      "text": " Which leads to the problem that you can't like pin a version of an LLM and say, OK,",
      "tokens": [
        50676,
        3013,
        6689,
        281,
        264,
        1154,
        300,
        291,
        393,
        380,
        411,
        5447,
        257,
        3037,
        295,
        364,
        441,
        43,
        44,
        293,
        584,
        11,
        2264,
        11,
        50880
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22195316851139069,
      "compression_ratio": 1.535398244857788,
      "no_speech_prob": 0.022386206313967705
    },
    {
      "id": 100,
      "seek": 65720,
      "start": 1890.63001953125,
      "end": 1900.2299951171874,
      "text": " this is going to be the same model, even if I use it in a few months. So before we went live,",
      "tokens": [
        50880,
        341,
        307,
        516,
        281,
        312,
        264,
        912,
        2316,
        11,
        754,
        498,
        286,
        764,
        309,
        294,
        257,
        1326,
        2493,
        13,
        407,
        949,
        321,
        1437,
        1621,
        11,
        51360
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22195316851139069,
      "compression_ratio": 1.535398244857788,
      "no_speech_prob": 0.022386206313967705
    },
    {
      "id": 101,
      "seek": 65720,
      "start": 1900.2299951171874,
      "end": 1905.829970703125,
      "text": " you said that there is a relation between what you were doing in your workshop to",
      "tokens": [
        51360,
        291,
        848,
        300,
        456,
        307,
        257,
        9721,
        1296,
        437,
        291,
        645,
        884,
        294,
        428,
        13541,
        281,
        51640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22195316851139069,
      "compression_ratio": 1.535398244857788,
      "no_speech_prob": 0.022386206313967705
    },
    {
      "id": 102,
      "seek": 68272,
      "start": 1905.9099877929686,
      "end": 1911.58998046875,
      "text": " spec driven development. So what's that? The spec driven development is quite a new thing,",
      "tokens": [
        50368,
        1608,
        9555,
        3250,
        13,
        407,
        437,
        311,
        300,
        30,
        440,
        1608,
        9555,
        3250,
        307,
        1596,
        257,
        777,
        551,
        11,
        50652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22746394574642181,
      "compression_ratio": 1.7567567825317383,
      "no_speech_prob": 0.1426791399717331
    },
    {
      "id": 103,
      "seek": 68272,
      "start": 1911.58998046875,
      "end": 1917.0299829101561,
      "text": " and there's lots of different definitions for it at the moment. But essentially,",
      "tokens": [
        50652,
        293,
        456,
        311,
        3195,
        295,
        819,
        21988,
        337,
        309,
        412,
        264,
        1623,
        13,
        583,
        4476,
        11,
        50924
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22746394574642181,
      "compression_ratio": 1.7567567825317383,
      "no_speech_prob": 0.1426791399717331
    },
    {
      "id": 104,
      "seek": 68272,
      "start": 1917.9099877929686,
      "end": 1923.2699731445311,
      "text": " people are now sort of moving. It's quite funny. So I would say that developers have spent sort of",
      "tokens": [
        50968,
        561,
        366,
        586,
        1333,
        295,
        2684,
        13,
        467,
        311,
        1596,
        4074,
        13,
        407,
        286,
        576,
        584,
        300,
        8849,
        362,
        4418,
        1333,
        295,
        51236
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22746394574642181,
      "compression_ratio": 1.7567567825317383,
      "no_speech_prob": 0.1426791399717331
    },
    {
      "id": 105,
      "seek": 68272,
      "start": 1923.2699731445311,
      "end": 1929.2699731445311,
      "text": " the last maybe two decades or more trying to avoid writing documentation so they can write code",
      "tokens": [
        51236,
        264,
        1036,
        1310,
        732,
        7878,
        420,
        544,
        1382,
        281,
        5042,
        3579,
        14333,
        370,
        436,
        393,
        2464,
        3089,
        51536
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22746394574642181,
      "compression_ratio": 1.7567567825317383,
      "no_speech_prob": 0.1426791399717331
    },
    {
      "id": 106,
      "seek": 68272,
      "start": 1929.2699731445311,
      "end": 1934.7099755859374,
      "text": " instead. And now we're talking about writing documentation so that I can write the code.",
      "tokens": [
        51536,
        2602,
        13,
        400,
        586,
        321,
        434,
        1417,
        466,
        3579,
        14333,
        370,
        300,
        286,
        393,
        2464,
        264,
        3089,
        13,
        51808
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22746394574642181,
      "compression_ratio": 1.7567567825317383,
      "no_speech_prob": 0.1426791399717331
    },
    {
      "id": 107,
      "seek": 71160,
      "start": 1934.7099755859374,
      "end": 1940.390029296875,
      "text": " And other people have been saying, oh, yeah, how many people like writing code? And everyone goes,",
      "tokens": [
        50364,
        400,
        661,
        561,
        362,
        668,
        1566,
        11,
        1954,
        11,
        1338,
        11,
        577,
        867,
        561,
        411,
        3579,
        3089,
        30,
        400,
        1518,
        1709,
        11,
        50648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20299780368804932,
      "compression_ratio": 1.8365758657455444,
      "no_speech_prob": 0.0063752662390470505
    },
    {
      "id": 108,
      "seek": 71160,
      "start": 1940.390029296875,
      "end": 1943.829970703125,
      "text": " yeah. And how many people like reviewing code? And everyone goes, no, I don't really want to do",
      "tokens": [
        50648,
        1338,
        13,
        400,
        577,
        867,
        561,
        411,
        19576,
        3089,
        30,
        400,
        1518,
        1709,
        11,
        572,
        11,
        286,
        500,
        380,
        534,
        528,
        281,
        360,
        50820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20299780368804932,
      "compression_ratio": 1.8365758657455444,
      "no_speech_prob": 0.0063752662390470505
    },
    {
      "id": 109,
      "seek": 71160,
      "start": 1943.829970703125,
      "end": 1947.829970703125,
      "text": " that. But actually, a lot of people are saying, yeah, let's do this spec driven documentation",
      "tokens": [
        50820,
        300,
        13,
        583,
        767,
        11,
        257,
        688,
        295,
        561,
        366,
        1566,
        11,
        1338,
        11,
        718,
        311,
        360,
        341,
        1608,
        9555,
        14333,
        51020
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20299780368804932,
      "compression_ratio": 1.8365758657455444,
      "no_speech_prob": 0.0063752662390470505
    },
    {
      "id": 110,
      "seek": 71160,
      "start": 1947.829970703125,
      "end": 1952.7899926757811,
      "text": " where that's exactly what we're going to do. We're going to the basic idea is that you create",
      "tokens": [
        51020,
        689,
        300,
        311,
        2293,
        437,
        321,
        434,
        516,
        281,
        360,
        13,
        492,
        434,
        516,
        281,
        264,
        3875,
        1558,
        307,
        300,
        291,
        1884,
        51268
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20299780368804932,
      "compression_ratio": 1.8365758657455444,
      "no_speech_prob": 0.0063752662390470505
    },
    {
      "id": 111,
      "seek": 71160,
      "start": 1952.7899926757811,
      "end": 1960.7099755859374,
      "text": " a specification of a spec using things like Markdown. And that's partly a human input and",
      "tokens": [
        51268,
        257,
        31256,
        295,
        257,
        1608,
        1228,
        721,
        411,
        3934,
        5093,
        13,
        400,
        300,
        311,
        17031,
        257,
        1952,
        4846,
        293,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20299780368804932,
      "compression_ratio": 1.8365758657455444,
      "no_speech_prob": 0.0063752662390470505
    },
    {
      "id": 112,
      "seek": 73760,
      "start": 1960.7099755859374,
      "end": 1966.4699853515624,
      "text": " partly an AI input. And there are certain methods and tools that you can use at the",
      "tokens": [
        50364,
        17031,
        364,
        7318,
        4846,
        13,
        400,
        456,
        366,
        1629,
        7150,
        293,
        3873,
        300,
        291,
        393,
        764,
        412,
        264,
        50652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22797022759914398,
      "compression_ratio": 1.608888864517212,
      "no_speech_prob": 0.04131859540939331
    },
    {
      "id": 113,
      "seek": 73760,
      "start": 1966.4699853515624,
      "end": 1975.58998046875,
      "text": " moment, like GitHub spec kit. I've been looking at that a little bit. But the idea is that we",
      "tokens": [
        50652,
        1623,
        11,
        411,
        23331,
        1608,
        8260,
        13,
        286,
        600,
        668,
        1237,
        412,
        300,
        257,
        707,
        857,
        13,
        583,
        264,
        1558,
        307,
        300,
        321,
        51108
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22797022759914398,
      "compression_ratio": 1.608888864517212,
      "no_speech_prob": 0.04131859540939331
    },
    {
      "id": 114,
      "seek": 73760,
      "start": 1975.58998046875,
      "end": 1981.9900048828124,
      "text": " create the spec along with the AI and then the AI then writes the code for it. And then we",
      "tokens": [
        51108,
        1884,
        264,
        1608,
        2051,
        365,
        264,
        7318,
        293,
        550,
        264,
        7318,
        550,
        13657,
        264,
        3089,
        337,
        309,
        13,
        400,
        550,
        321,
        51428
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22797022759914398,
      "compression_ratio": 1.608888864517212,
      "no_speech_prob": 0.04131859540939331
    },
    {
      "id": 115,
      "seek": 73760,
      "start": 1981.9900048828124,
      "end": 1987.5100244140624,
      "text": " hopefully review that code. Because otherwise, we're just doing vibe coding. What do you mean",
      "tokens": [
        51428,
        4696,
        3131,
        300,
        3089,
        13,
        1436,
        5911,
        11,
        321,
        434,
        445,
        884,
        14606,
        17720,
        13,
        708,
        360,
        291,
        914,
        51704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22797022759914398,
      "compression_ratio": 1.608888864517212,
      "no_speech_prob": 0.04131859540939331
    },
    {
      "id": 116,
      "seek": 76440,
      "start": 1987.5100244140624,
      "end": 1995.9099877929686,
      "text": " by hopefully? Yes. So, we should definitely if we're doing spec driven development, we are",
      "tokens": [
        50364,
        538,
        4696,
        30,
        1079,
        13,
        407,
        11,
        321,
        820,
        2138,
        498,
        321,
        434,
        884,
        1608,
        9555,
        3250,
        11,
        321,
        366,
        50784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2267400622367859,
      "compression_ratio": 1.7488372325897217,
      "no_speech_prob": 0.0652918890118599
    },
    {
      "id": 117,
      "seek": 76440,
      "start": 1995.9099877929686,
      "end": 2002.7899926757811,
      "text": " reviewing that code. We are reviewing the tests that it's creating. But the idea with spec driven",
      "tokens": [
        50784,
        19576,
        300,
        3089,
        13,
        492,
        366,
        19576,
        264,
        6921,
        300,
        309,
        311,
        4084,
        13,
        583,
        264,
        1558,
        365,
        1608,
        9555,
        51128
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2267400622367859,
      "compression_ratio": 1.7488372325897217,
      "no_speech_prob": 0.0652918890118599
    },
    {
      "id": 118,
      "seek": 76440,
      "start": 2002.7899926757811,
      "end": 2009.9099877929686,
      "text": " development compared to vibe coding is that we are managing the context that the LLM is using.",
      "tokens": [
        51128,
        3250,
        5347,
        281,
        14606,
        17720,
        307,
        300,
        321,
        366,
        11642,
        264,
        4319,
        300,
        264,
        441,
        43,
        44,
        307,
        1228,
        13,
        51484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2267400622367859,
      "compression_ratio": 1.7488372325897217,
      "no_speech_prob": 0.0652918890118599
    },
    {
      "id": 119,
      "seek": 76440,
      "start": 2009.9099877929686,
      "end": 2015.9900048828124,
      "text": " So, we are saying these are the principles you should be sticking to. These are architecture",
      "tokens": [
        51484,
        407,
        11,
        321,
        366,
        1566,
        613,
        366,
        264,
        9156,
        291,
        820,
        312,
        13465,
        281,
        13,
        1981,
        366,
        9482,
        51788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2267400622367859,
      "compression_ratio": 1.7488372325897217,
      "no_speech_prob": 0.0652918890118599
    },
    {
      "id": 120,
      "seek": 79288,
      "start": 2016.9500268554686,
      "end": 2023.4300073242186,
      "text": " decisions that have been made. We need you to record architecture decisions which we can then",
      "tokens": [
        50412,
        5327,
        300,
        362,
        668,
        1027,
        13,
        492,
        643,
        291,
        281,
        2136,
        9482,
        5327,
        597,
        321,
        393,
        550,
        50736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21126073598861694,
      "compression_ratio": 1.6590908765792847,
      "no_speech_prob": 0.025114594027400017
    },
    {
      "id": 121,
      "seek": 79288,
      "start": 2023.4300073242186,
      "end": 2030.7899926757811,
      "text": " view. Because we one of the things I'm really big on is architecture documentation should include",
      "tokens": [
        50736,
        1910,
        13,
        1436,
        321,
        472,
        295,
        264,
        721,
        286,
        478,
        534,
        955,
        322,
        307,
        9482,
        14333,
        820,
        4090,
        51104
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21126073598861694,
      "compression_ratio": 1.6590908765792847,
      "no_speech_prob": 0.025114594027400017
    },
    {
      "id": 122,
      "seek": 79288,
      "start": 2030.7899926757811,
      "end": 2039.7500146484374,
      "text": " the why. Because that if we don't include the why we made that decision, then we can never reproduce",
      "tokens": [
        51104,
        264,
        983,
        13,
        1436,
        300,
        498,
        321,
        500,
        380,
        4090,
        264,
        983,
        321,
        1027,
        300,
        3537,
        11,
        550,
        321,
        393,
        1128,
        29501,
        51552
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21126073598861694,
      "compression_ratio": 1.6590908765792847,
      "no_speech_prob": 0.025114594027400017
    },
    {
      "id": 123,
      "seek": 81664,
      "start": 2039.829970703125,
      "end": 2047.5100244140624,
      "text": " that. The how and the what can be reproduced from the why, but the why cannot be reproduced from the",
      "tokens": [
        50368,
        300,
        13,
        440,
        577,
        293,
        264,
        437,
        393,
        312,
        11408,
        1232,
        490,
        264,
        983,
        11,
        457,
        264,
        983,
        2644,
        312,
        11408,
        1232,
        490,
        264,
        50752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2943256199359894,
      "compression_ratio": 1.7239818572998047,
      "no_speech_prob": 0.1799067109823227
    },
    {
      "id": 124,
      "seek": 81664,
      "start": 2047.5100244140624,
      "end": 2054.3900292968747,
      "text": " how or the what. So, that is the information that's being lost. Okay. And diagram as code,",
      "tokens": [
        50752,
        577,
        420,
        264,
        437,
        13,
        407,
        11,
        300,
        307,
        264,
        1589,
        300,
        311,
        885,
        2731,
        13,
        1033,
        13,
        400,
        10686,
        382,
        3089,
        11,
        51096
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2943256199359894,
      "compression_ratio": 1.7239818572998047,
      "no_speech_prob": 0.1799067109823227
    },
    {
      "id": 125,
      "seek": 81664,
      "start": 2054.3900292968747,
      "end": 2060.070021972656,
      "text": " how does that fit into spec driven development? So, there's the relation? Yeah. So, you can,",
      "tokens": [
        51096,
        577,
        775,
        300,
        3318,
        666,
        1608,
        9555,
        3250,
        30,
        407,
        11,
        456,
        311,
        264,
        319,
        24278,
        30,
        865,
        13,
        407,
        11,
        291,
        393,
        11,
        51380
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2943256199359894,
      "compression_ratio": 1.7239818572998047,
      "no_speech_prob": 0.1799067109823227
    },
    {
      "id": 126,
      "seek": 81664,
      "start": 2060.070021972656,
      "end": 2066.3900292968747,
      "text": " of course, in your markdown files, you can include these diagrams as code. You can ask the AI to",
      "tokens": [
        51380,
        295,
        1164,
        11,
        294,
        428,
        1491,
        5093,
        7098,
        11,
        291,
        393,
        4090,
        613,
        36709,
        382,
        3089,
        13,
        509,
        393,
        1029,
        264,
        7318,
        281,
        51696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2943256199359894,
      "compression_ratio": 1.7239818572998047,
      "no_speech_prob": 0.1799067109823227
    },
    {
      "id": 127,
      "seek": 84328,
      "start": 2066.3900292968747,
      "end": 2073.3499902343747,
      "text": " produce them in there as well. One other thing I've seen being done is to create ASCII diagrams",
      "tokens": [
        50364,
        5258,
        552,
        294,
        456,
        382,
        731,
        13,
        1485,
        661,
        551,
        286,
        600,
        1612,
        885,
        1096,
        307,
        281,
        1884,
        7469,
        34,
        9503,
        36709,
        50712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1990022510290146,
      "compression_ratio": 1.706140398979187,
      "no_speech_prob": 0.08430343866348267
    },
    {
      "id": 128,
      "seek": 84328,
      "start": 2073.3499902343747,
      "end": 2081.750014648437,
      "text": " as well. So, you're getting the AI to use pipes and all the different ASCII characters to actually",
      "tokens": [
        50712,
        382,
        731,
        13,
        407,
        11,
        291,
        434,
        1242,
        264,
        7318,
        281,
        764,
        21882,
        293,
        439,
        264,
        819,
        7469,
        34,
        9503,
        4342,
        281,
        767,
        51132
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1990022510290146,
      "compression_ratio": 1.706140398979187,
      "no_speech_prob": 0.08430343866348267
    },
    {
      "id": 129,
      "seek": 84328,
      "start": 2081.750014648437,
      "end": 2086.9500268554684,
      "text": " create a diagram for you. And it can do that in the markdown. But it can also, of course, do that",
      "tokens": [
        51132,
        1884,
        257,
        10686,
        337,
        291,
        13,
        400,
        309,
        393,
        360,
        300,
        294,
        264,
        1491,
        5093,
        13,
        583,
        309,
        393,
        611,
        11,
        295,
        1164,
        11,
        360,
        300,
        51392
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1990022510290146,
      "compression_ratio": 1.706140398979187,
      "no_speech_prob": 0.08430343866348267
    },
    {
      "id": 130,
      "seek": 84328,
      "start": 2086.9500268554684,
      "end": 2091.5899804687497,
      "text": " in the command line for you as well. And you can say, like create it using ASCII show what we've",
      "tokens": [
        51392,
        294,
        264,
        5622,
        1622,
        337,
        291,
        382,
        731,
        13,
        400,
        291,
        393,
        584,
        11,
        411,
        1884,
        309,
        1228,
        7469,
        34,
        9503,
        855,
        437,
        321,
        600,
        51624
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1990022510290146,
      "compression_ratio": 1.706140398979187,
      "no_speech_prob": 0.08430343866348267
    },
    {
      "id": 131,
      "seek": 86848,
      "start": 2091.5899804687497,
      "end": 2099.1099999999997,
      "text": " done so far. And that helps you to review what you are doing, because the diagrams aren't necessarily",
      "tokens": [
        50364,
        1096,
        370,
        1400,
        13,
        400,
        300,
        3665,
        291,
        281,
        3131,
        437,
        291,
        366,
        884,
        11,
        570,
        264,
        36709,
        3212,
        380,
        4725,
        50740
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1937548816204071,
      "compression_ratio": 1.7454545497894287,
      "no_speech_prob": 0.1885194331407547
    },
    {
      "id": 132,
      "seek": 86848,
      "start": 2099.1099999999997,
      "end": 2105.4300073242184,
      "text": " for the AI. But if you've already got a diagram, you can give it to the AI to help it understand",
      "tokens": [
        50740,
        337,
        264,
        7318,
        13,
        583,
        498,
        291,
        600,
        1217,
        658,
        257,
        10686,
        11,
        291,
        393,
        976,
        309,
        281,
        264,
        7318,
        281,
        854,
        309,
        1223,
        51056
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1937548816204071,
      "compression_ratio": 1.7454545497894287,
      "no_speech_prob": 0.1885194331407547
    },
    {
      "id": 133,
      "seek": 86848,
      "start": 2105.4300073242184,
      "end": 2111.510024414062,
      "text": " what we're trying to do, or they understand. But also, if you're getting the AI to create",
      "tokens": [
        51056,
        437,
        321,
        434,
        1382,
        281,
        360,
        11,
        420,
        436,
        1223,
        13,
        583,
        611,
        11,
        498,
        291,
        434,
        1242,
        264,
        7318,
        281,
        1884,
        51360
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1937548816204071,
      "compression_ratio": 1.7454545497894287,
      "no_speech_prob": 0.1885194331407547
    },
    {
      "id": 134,
      "seek": 86848,
      "start": 2111.510024414062,
      "end": 2118.789992675781,
      "text": " the diagrams of what you're doing, you are using that as a validation check. You can say, okay,",
      "tokens": [
        51360,
        264,
        36709,
        295,
        437,
        291,
        434,
        884,
        11,
        291,
        366,
        1228,
        300,
        382,
        257,
        24071,
        1520,
        13,
        509,
        393,
        584,
        11,
        1392,
        11,
        51724
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1937548816204071,
      "compression_ratio": 1.7454545497894287,
      "no_speech_prob": 0.1885194331407547
    },
    {
      "id": 135,
      "seek": 89568,
      "start": 2118.789992675781,
      "end": 2122.1499780273434,
      "text": " that's not quite right. We need to make a change to this.",
      "tokens": [
        50364,
        300,
        311,
        406,
        1596,
        558,
        13,
        492,
        643,
        281,
        652,
        257,
        1319,
        281,
        341,
        13,
        50532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3109815716743469,
      "compression_ratio": 1.5093457698822021,
      "no_speech_prob": 0.00572544801980257
    },
    {
      "id": 136,
      "seek": 89568,
      "start": 2123.029982910156,
      "end": 2129.269973144531,
      "text": " That's a very interesting point, the ASCII diagrams, because when you create a",
      "tokens": [
        50576,
        663,
        311,
        257,
        588,
        1880,
        935,
        11,
        264,
        7469,
        34,
        9503,
        36709,
        11,
        570,
        562,
        291,
        1884,
        257,
        50888
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3109815716743469,
      "compression_ratio": 1.5093457698822021,
      "no_speech_prob": 0.00572544801980257
    },
    {
      "id": 137,
      "seek": 89568,
      "start": 2129.269973144531,
      "end": 2136.1499780273434,
      "text": " plant ML diagram, you have the relationships between components. And I guess that a lamb can",
      "tokens": [
        50888,
        3709,
        21601,
        10686,
        11,
        291,
        362,
        264,
        6159,
        1296,
        6677,
        13,
        400,
        286,
        2041,
        300,
        257,
        10097,
        393,
        51232
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3109815716743469,
      "compression_ratio": 1.5093457698822021,
      "no_speech_prob": 0.00572544801980257
    },
    {
      "id": 138,
      "seek": 89568,
      "start": 2136.1499780273434,
      "end": 2145.5899804687497,
      "text": " read this fine and okay. But I noticed lately that Claude often creates those ASCII diagrams.",
      "tokens": [
        51232,
        1401,
        341,
        2489,
        293,
        1392,
        13,
        583,
        286,
        5694,
        12881,
        300,
        12947,
        2303,
        2049,
        7829,
        729,
        7469,
        34,
        9503,
        36709,
        13,
        51704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3109815716743469,
      "compression_ratio": 1.5093457698822021,
      "no_speech_prob": 0.00572544801980257
    },
    {
      "id": 139,
      "seek": 92248,
      "start": 2146.1499780273434,
      "end": 2152.550002441406,
      "text": " And I get an impression that it would, I mean, visually, it's easy to read for me,",
      "tokens": [
        50392,
        400,
        286,
        483,
        364,
        9995,
        300,
        309,
        576,
        11,
        286,
        914,
        11,
        19622,
        11,
        309,
        311,
        1858,
        281,
        1401,
        337,
        385,
        11,
        50712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22486329078674316,
      "compression_ratio": 1.5578947067260742,
      "no_speech_prob": 0.002980676246806979
    },
    {
      "id": 140,
      "seek": 92248,
      "start": 2152.550002441406,
      "end": 2160.3900292968747,
      "text": " but I guess it's not so easy to read for the LM. And so I have, I guess, the documentation has to",
      "tokens": [
        50712,
        457,
        286,
        2041,
        309,
        311,
        406,
        370,
        1858,
        281,
        1401,
        337,
        264,
        46529,
        13,
        400,
        370,
        286,
        362,
        11,
        286,
        2041,
        11,
        264,
        14333,
        575,
        281,
        51104
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22486329078674316,
      "compression_ratio": 1.5578947067260742,
      "no_speech_prob": 0.002980676246806979
    },
    {
      "id": 141,
      "seek": 92248,
      "start": 2160.3900292968747,
      "end": 2169.5899804687497,
      "text": " contain the relationships and the diagram. Did you also notice a shift in there that the model",
      "tokens": [
        51104,
        5304,
        264,
        6159,
        293,
        264,
        10686,
        13,
        2589,
        291,
        611,
        3449,
        257,
        5513,
        294,
        456,
        300,
        264,
        2316,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22486329078674316,
      "compression_ratio": 1.5578947067260742,
      "no_speech_prob": 0.002980676246806979
    },
    {
      "id": 142,
      "seek": 92248,
      "start": 2169.5899804687497,
      "end": 2170.469985351562,
      "text": " behaves differently?",
      "tokens": [
        51564,
        36896,
        7614,
        30,
        51608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22486329078674316,
      "compression_ratio": 1.5578947067260742,
      "no_speech_prob": 0.002980676246806979
    },
    {
      "id": 0,
      "seek": 0,
      "start": 2170.64,
      "end": 2177.1599999809264,
      "text": " I've not really noticed that, but I think like what you were saying about the ASCII",
      "tokens": [
        50364,
        286,
        600,
        406,
        534,
        5694,
        300,
        11,
        457,
        286,
        519,
        411,
        437,
        291,
        645,
        1566,
        466,
        264,
        7469,
        34,
        9503,
        50690
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29704615473747253,
      "compression_ratio": 1.5720523595809937,
      "no_speech_prob": 0.9305902719497681
    },
    {
      "id": 1,
      "seek": 0,
      "start": 2177.1599999809264,
      "end": 2184.2800003433226,
      "text": " diagrams, yes, they don't have those relationships. One thing that I've seen that I thought was",
      "tokens": [
        50690,
        36709,
        11,
        2086,
        11,
        436,
        500,
        380,
        362,
        729,
        6159,
        13,
        1485,
        551,
        300,
        286,
        600,
        1612,
        300,
        286,
        1194,
        390,
        51046
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29704615473747253,
      "compression_ratio": 1.5720523595809937,
      "no_speech_prob": 0.9305902719497681
    },
    {
      "id": 2,
      "seek": 0,
      "start": 2184.2800003433226,
      "end": 2192.03999961853,
      "text": " good for this was it was used to actually mock up how a web page was going to look with",
      "tokens": [
        51046,
        665,
        337,
        341,
        390,
        309,
        390,
        1143,
        281,
        767,
        17362,
        493,
        577,
        257,
        3670,
        3028,
        390,
        516,
        281,
        574,
        365,
        51434
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29704615473747253,
      "compression_ratio": 1.5720523595809937,
      "no_speech_prob": 0.9305902719497681
    },
    {
      "id": 3,
      "seek": 0,
      "start": 2192.03999961853,
      "end": 2198.719999923706,
      "text": " some different boxes on it. And so, of course, there are, I think it's, I think it's Mermaid",
      "tokens": [
        51434,
        512,
        819,
        9002,
        322,
        309,
        13,
        400,
        370,
        11,
        295,
        1164,
        11,
        456,
        366,
        11,
        286,
        519,
        309,
        311,
        11,
        286,
        519,
        309,
        311,
        376,
        32124,
        51768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29704615473747253,
      "compression_ratio": 1.5720523595809937,
      "no_speech_prob": 0.9305902719497681
    },
    {
      "id": 4,
      "seek": 2808,
      "start": 2198.719999923706,
      "end": 2208.040001525879,
      "text": " has at least one form of diagram for wireframing, but just using those ASCII to go, right, yeah,",
      "tokens": [
        50364,
        575,
        412,
        1935,
        472,
        1254,
        295,
        10686,
        337,
        6234,
        69,
        2356,
        278,
        11,
        457,
        445,
        1228,
        729,
        7469,
        34,
        9503,
        281,
        352,
        11,
        558,
        11,
        1338,
        11,
        50830
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26241543889045715,
      "compression_ratio": 1.668161392211914,
      "no_speech_prob": 0.019677938893437386
    },
    {
      "id": 5,
      "seek": 2808,
      "start": 2208.040001525879,
      "end": 2212.799999847412,
      "text": " we've got a box here and then a box here, and then that's good. And you can show the",
      "tokens": [
        50830,
        321,
        600,
        658,
        257,
        2424,
        510,
        293,
        550,
        257,
        2424,
        510,
        11,
        293,
        550,
        300,
        311,
        665,
        13,
        400,
        291,
        393,
        855,
        264,
        51068
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26241543889045715,
      "compression_ratio": 1.668161392211914,
      "no_speech_prob": 0.019677938893437386
    },
    {
      "id": 6,
      "seek": 2808,
      "start": 2212.799999847412,
      "end": 2217.4800001525878,
      "text": " different versions of something or how it's going to move through different pop-up boxes",
      "tokens": [
        51068,
        819,
        9606,
        295,
        746,
        420,
        577,
        309,
        311,
        516,
        281,
        1286,
        807,
        819,
        1665,
        12,
        1010,
        9002,
        51302
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26241543889045715,
      "compression_ratio": 1.668161392211914,
      "no_speech_prob": 0.019677938893437386
    },
    {
      "id": 7,
      "seek": 2808,
      "start": 2217.4800001525878,
      "end": 2223.520001068115,
      "text": " and things like that. And so if you're wireframing, I think where you don't have those relationships,",
      "tokens": [
        51302,
        293,
        721,
        411,
        300,
        13,
        400,
        370,
        498,
        291,
        434,
        6234,
        69,
        2356,
        278,
        11,
        286,
        519,
        689,
        291,
        500,
        380,
        362,
        729,
        6159,
        11,
        51604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26241543889045715,
      "compression_ratio": 1.668161392211914,
      "no_speech_prob": 0.019677938893437386
    },
    {
      "id": 8,
      "seek": 5288,
      "start": 2223.520001068115,
      "end": 2228.5999990844725,
      "text": " where it's sort of more of an image, then that's quite a good way to do it, because",
      "tokens": [
        50364,
        689,
        309,
        311,
        1333,
        295,
        544,
        295,
        364,
        3256,
        11,
        550,
        300,
        311,
        1596,
        257,
        665,
        636,
        281,
        360,
        309,
        11,
        570,
        50618
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3154503107070923,
      "compression_ratio": 1.643478274345398,
      "no_speech_prob": 0.34119918942451477
    },
    {
      "id": 9,
      "seek": 5288,
      "start": 2228.5999990844725,
      "end": 2232.8800016784667,
      "text": " the command line, you can't, you're not going to have sort of the image unless you actually",
      "tokens": [
        50618,
        264,
        5622,
        1622,
        11,
        291,
        393,
        380,
        11,
        291,
        434,
        406,
        516,
        281,
        362,
        1333,
        295,
        264,
        3256,
        5969,
        291,
        767,
        50832
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3154503107070923,
      "compression_ratio": 1.643478274345398,
      "no_speech_prob": 0.34119918942451477
    },
    {
      "id": 10,
      "seek": 5288,
      "start": 2232.8800016784667,
      "end": 2236.64,
      "text": " load up a web page and have a look at it.",
      "tokens": [
        50832,
        3677,
        493,
        257,
        3670,
        3028,
        293,
        362,
        257,
        574,
        412,
        309,
        13,
        51020
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3154503107070923,
      "compression_ratio": 1.643478274345398,
      "no_speech_prob": 0.34119918942451477
    },
    {
      "id": 11,
      "seek": 5288,
      "start": 2236.64,
      "end": 2245.1200033569335,
      "text": " So the ASCII diagrams that we're talking about, that's, they, I assume they use ASCII characters",
      "tokens": [
        51020,
        407,
        264,
        7469,
        34,
        9503,
        36709,
        300,
        321,
        434,
        1417,
        466,
        11,
        300,
        311,
        11,
        436,
        11,
        286,
        6552,
        436,
        764,
        7469,
        34,
        9503,
        4342,
        51444
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3154503107070923,
      "compression_ratio": 1.643478274345398,
      "no_speech_prob": 0.34119918942451477
    },
    {
      "id": 12,
      "seek": 5288,
      "start": 2245.1200033569335,
      "end": 2248.559998168945,
      "text": " to sort of draw a diagram. So that's, that's how it works.",
      "tokens": [
        51444,
        281,
        1333,
        295,
        2642,
        257,
        10686,
        13,
        407,
        300,
        311,
        11,
        300,
        311,
        577,
        309,
        1985,
        13,
        51616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3154503107070923,
      "compression_ratio": 1.643478274345398,
      "no_speech_prob": 0.34119918942451477
    },
    {
      "id": 13,
      "seek": 5288,
      "start": 2248.559998168945,
      "end": 2249.559998168945,
      "text": " Yes.",
      "tokens": [
        51616,
        1079,
        13,
        51666
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3154503107070923,
      "compression_ratio": 1.643478274345398,
      "no_speech_prob": 0.34119918942451477
    },
    {
      "id": 14,
      "seek": 7892,
      "start": 2249.559998168945,
      "end": 2264.4799963378905,
      "text": " Yeah, and LLMs might have problems understanding that. I was wondering whether, so that's",
      "tokens": [
        50364,
        865,
        11,
        293,
        441,
        43,
        26386,
        1062,
        362,
        2740,
        3701,
        300,
        13,
        286,
        390,
        6359,
        1968,
        11,
        370,
        300,
        311,
        51110
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3433552086353302,
      "compression_ratio": 1.48369562625885,
      "no_speech_prob": 0.7716784477233887
    },
    {
      "id": 15,
      "seek": 7892,
      "start": 2264.4799963378905,
      "end": 2270.9199987792967,
      "text": " it for spec-driven development. And I think that is something that we see in LLMs quite",
      "tokens": [
        51110,
        309,
        337,
        1608,
        12,
        25456,
        3250,
        13,
        400,
        286,
        519,
        300,
        307,
        746,
        300,
        321,
        536,
        294,
        441,
        43,
        26386,
        1596,
        51432
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3433552086353302,
      "compression_ratio": 1.48369562625885,
      "no_speech_prob": 0.7716784477233887
    },
    {
      "id": 16,
      "seek": 7892,
      "start": 2270.9199987792967,
      "end": 2277.3200003051757,
      "text": " a lot these days, that basically we are trying to use not natural language, but other languages",
      "tokens": [
        51432,
        257,
        688,
        613,
        1708,
        11,
        300,
        1936,
        321,
        366,
        1382,
        281,
        764,
        406,
        3303,
        2856,
        11,
        457,
        661,
        8650,
        51752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3433552086353302,
      "compression_ratio": 1.48369562625885,
      "no_speech_prob": 0.7716784477233887
    },
    {
      "id": 17,
      "seek": 10668,
      "start": 2277.3200003051757,
      "end": 2286.959999694824,
      "text": " that also have a limited, limited, limited set of things that they can talk to.",
      "tokens": [
        50364,
        300,
        611,
        362,
        257,
        5567,
        11,
        5567,
        11,
        5567,
        992,
        295,
        721,
        300,
        436,
        393,
        751,
        281,
        13,
        50846
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29648157954216003,
      "compression_ratio": 1.4885057210922241,
      "no_speech_prob": 0.11919064074754715
    },
    {
      "id": 18,
      "seek": 10668,
      "start": 2286.959999694824,
      "end": 2295.3200003051757,
      "text": " Any other relations between diagrams and AI? How should I put it? So the workshop seems",
      "tokens": [
        50846,
        2639,
        661,
        2299,
        1296,
        36709,
        293,
        7318,
        30,
        1012,
        820,
        286,
        829,
        309,
        30,
        407,
        264,
        13541,
        2544,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29648157954216003,
      "compression_ratio": 1.4885057210922241,
      "no_speech_prob": 0.11919064074754715
    },
    {
      "id": 19,
      "seek": 10668,
      "start": 2295.3200003051757,
      "end": 2303.8000036621092,
      "text": " to talk about how to generate diagrams using AI support. So we have spec-driven development",
      "tokens": [
        51264,
        281,
        751,
        466,
        577,
        281,
        8460,
        36709,
        1228,
        7318,
        1406,
        13,
        407,
        321,
        362,
        1608,
        12,
        25456,
        3250,
        51688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29648157954216003,
      "compression_ratio": 1.4885057210922241,
      "no_speech_prob": 0.11919064074754715
    },
    {
      "id": 20,
      "seek": 13316,
      "start": 2303.8000036621092,
      "end": 2309.4799963378905,
      "text": " where it's used as an output, but also as an input. Is there anything else, any other",
      "tokens": [
        50364,
        689,
        309,
        311,
        1143,
        382,
        364,
        5598,
        11,
        457,
        611,
        382,
        364,
        4846,
        13,
        1119,
        456,
        1340,
        1646,
        11,
        604,
        661,
        50648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24543042480945587,
      "compression_ratio": 1.7695473432540894,
      "no_speech_prob": 0.4411906898021698
    },
    {
      "id": 21,
      "seek": 13316,
      "start": 2309.4799963378905,
      "end": 2314.6799932861327,
      "text": " relation between diagrams and AI that you're seeing at the moment?",
      "tokens": [
        50648,
        9721,
        1296,
        36709,
        293,
        7318,
        300,
        291,
        434,
        2577,
        412,
        264,
        1623,
        30,
        50908
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24543042480945587,
      "compression_ratio": 1.7695473432540894,
      "no_speech_prob": 0.4411906898021698
    },
    {
      "id": 22,
      "seek": 13316,
      "start": 2314.6799932861327,
      "end": 2319.4400030517577,
      "text": " I don't think I'm really seeing anything at the moment, but I think they're going to be",
      "tokens": [
        50908,
        286,
        500,
        380,
        519,
        286,
        478,
        534,
        2577,
        1340,
        412,
        264,
        1623,
        11,
        457,
        286,
        519,
        436,
        434,
        516,
        281,
        312,
        51146
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24543042480945587,
      "compression_ratio": 1.7695473432540894,
      "no_speech_prob": 0.4411906898021698
    },
    {
      "id": 23,
      "seek": 13316,
      "start": 2319.4400030517577,
      "end": 2326.0000006103514,
      "text": " useful with spec-driven, because a lot that I've seen with spec-driven hasn't really talked",
      "tokens": [
        51146,
        4420,
        365,
        1608,
        12,
        25456,
        11,
        570,
        257,
        688,
        300,
        286,
        600,
        1612,
        365,
        1608,
        12,
        25456,
        6132,
        380,
        534,
        2825,
        51474
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24543042480945587,
      "compression_ratio": 1.7695473432540894,
      "no_speech_prob": 0.4411906898021698
    },
    {
      "id": 24,
      "seek": 13316,
      "start": 2326.0000006103514,
      "end": 2333.64,
      "text": " about using diagrams as code, which is interesting. It's more about creating just everything sort",
      "tokens": [
        51474,
        466,
        1228,
        36709,
        382,
        3089,
        11,
        597,
        307,
        1880,
        13,
        467,
        311,
        544,
        466,
        4084,
        445,
        1203,
        1333,
        51856
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24543042480945587,
      "compression_ratio": 1.7695473432540894,
      "no_speech_prob": 0.4411906898021698
    },
    {
      "id": 25,
      "seek": 16300,
      "start": 2333.64,
      "end": 2343.2400061035155,
      "text": " of in text. And from what I've seen so far, a lot of the tools at the moment are, interestingly,",
      "tokens": [
        50364,
        295,
        294,
        2487,
        13,
        400,
        490,
        437,
        286,
        600,
        1612,
        370,
        1400,
        11,
        257,
        688,
        295,
        264,
        3873,
        412,
        264,
        1623,
        366,
        11,
        25873,
        11,
        50844
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23955988883972168,
      "compression_ratio": 1.649999976158142,
      "no_speech_prob": 0.07251522690057755
    },
    {
      "id": 26,
      "seek": 16300,
      "start": 2343.2400061035155,
      "end": 2350.119995727539,
      "text": " very waterfall. So they kind of, they don't assume that what you create first is wrong,",
      "tokens": [
        50844,
        588,
        27848,
        13,
        407,
        436,
        733,
        295,
        11,
        436,
        500,
        380,
        6552,
        300,
        437,
        291,
        1884,
        700,
        307,
        2085,
        11,
        51188
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23955988883972168,
      "compression_ratio": 1.649999976158142,
      "no_speech_prob": 0.07251522690057755
    },
    {
      "id": 27,
      "seek": 16300,
      "start": 2350.119995727539,
      "end": 2353.4400030517577,
      "text": " which is, of course, if you're being agile, you've got to assume that you are going to",
      "tokens": [
        51188,
        597,
        307,
        11,
        295,
        1164,
        11,
        498,
        291,
        434,
        885,
        30072,
        11,
        291,
        600,
        658,
        281,
        6552,
        300,
        291,
        366,
        516,
        281,
        51354
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23955988883972168,
      "compression_ratio": 1.649999976158142,
      "no_speech_prob": 0.07251522690057755
    },
    {
      "id": 28,
      "seek": 16300,
      "start": 2353.4400030517577,
      "end": 2360.080002441406,
      "text": " have to iterate on things. And so if you create something in these, like all the tools work",
      "tokens": [
        51354,
        362,
        281,
        44497,
        322,
        721,
        13,
        400,
        370,
        498,
        291,
        1884,
        746,
        294,
        613,
        11,
        411,
        439,
        264,
        3873,
        589,
        51686
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23955988883972168,
      "compression_ratio": 1.649999976158142,
      "no_speech_prob": 0.07251522690057755
    },
    {
      "id": 29,
      "seek": 18944,
      "start": 2360.080002441406,
      "end": 2366.360001220703,
      "text": " with different workflows, but they don't really want you to go back and change things",
      "tokens": [
        50364,
        365,
        819,
        43461,
        11,
        457,
        436,
        500,
        380,
        534,
        528,
        291,
        281,
        352,
        646,
        293,
        1319,
        721,
        50678
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25350990891456604,
      "compression_ratio": 1.683397650718689,
      "no_speech_prob": 0.28209197521209717
    },
    {
      "id": 30,
      "seek": 18944,
      "start": 2366.360001220703,
      "end": 2370.4400030517577,
      "text": " in these workflows, which seems a bit odd to me, because it's like, oh, were these tools",
      "tokens": [
        50678,
        294,
        613,
        43461,
        11,
        597,
        2544,
        257,
        857,
        7401,
        281,
        385,
        11,
        570,
        309,
        311,
        411,
        11,
        1954,
        11,
        645,
        258,
        1130,
        3873,
        50882
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25350990891456604,
      "compression_ratio": 1.683397650718689,
      "no_speech_prob": 0.28209197521209717
    },
    {
      "id": 31,
      "seek": 18944,
      "start": 2370.4400030517577,
      "end": 2377.600006713867,
      "text": " written 20 years ago? So I'm interested to see how these tools are going to evolve. At",
      "tokens": [
        50882,
        3720,
        945,
        924,
        2057,
        30,
        407,
        286,
        478,
        3102,
        281,
        536,
        577,
        613,
        3873,
        366,
        516,
        281,
        16693,
        13,
        1711,
        51240
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25350990891456604,
      "compression_ratio": 1.683397650718689,
      "no_speech_prob": 0.28209197521209717
    },
    {
      "id": 32,
      "seek": 18944,
      "start": 2377.600006713867,
      "end": 2383.0399938964842,
      "text": " the moment, they're all doing very specific files, very specific workflows. And I think",
      "tokens": [
        51240,
        264,
        1623,
        11,
        436,
        434,
        439,
        884,
        588,
        2685,
        7098,
        11,
        588,
        2685,
        43461,
        13,
        400,
        286,
        519,
        51512
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25350990891456604,
      "compression_ratio": 1.683397650718689,
      "no_speech_prob": 0.28209197521209717
    },
    {
      "id": 33,
      "seek": 18944,
      "start": 2383.0399938964842,
      "end": 2387.559998168945,
      "text": " there's probably quite a lot that's missing from them. And I think diagrams as code is",
      "tokens": [
        51512,
        456,
        311,
        1391,
        1596,
        257,
        688,
        300,
        311,
        5361,
        490,
        552,
        13,
        400,
        286,
        519,
        36709,
        382,
        3089,
        307,
        51738
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25350990891456604,
      "compression_ratio": 1.683397650718689,
      "no_speech_prob": 0.28209197521209717
    },
    {
      "id": 34,
      "seek": 21692,
      "start": 2387.559998168945,
      "end": 2394.559998168945,
      "text": " one of those other sort of inputs that we might want to put in there. Like if we've",
      "tokens": [
        50364,
        472,
        295,
        729,
        661,
        1333,
        295,
        15743,
        300,
        321,
        1062,
        528,
        281,
        829,
        294,
        456,
        13,
        1743,
        498,
        321,
        600,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2833496332168579,
      "compression_ratio": 1.6875,
      "no_speech_prob": 0.6368852257728577
    },
    {
      "id": 35,
      "seek": 21692,
      "start": 2394.559998168945,
      "end": 2403.2799993896483,
      "text": " been using DDD to work out our different domains and different contexts and things, how are",
      "tokens": [
        50714,
        668,
        1228,
        413,
        20818,
        281,
        589,
        484,
        527,
        819,
        25514,
        293,
        819,
        30628,
        293,
        721,
        11,
        577,
        366,
        51150
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2833496332168579,
      "compression_ratio": 1.6875,
      "no_speech_prob": 0.6368852257728577
    },
    {
      "id": 36,
      "seek": 21692,
      "start": 2403.2799993896483,
      "end": 2410.8000036621092,
      "text": " we going to communicate that to the LLM? And so we need to think about how we how we're",
      "tokens": [
        51150,
        321,
        516,
        281,
        7890,
        300,
        281,
        264,
        441,
        43,
        44,
        30,
        400,
        370,
        321,
        643,
        281,
        519,
        466,
        577,
        321,
        577,
        321,
        434,
        51526
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2833496332168579,
      "compression_ratio": 1.6875,
      "no_speech_prob": 0.6368852257728577
    },
    {
      "id": 37,
      "seek": 21692,
      "start": 2410.8000036621092,
      "end": 2416.399994506836,
      "text": " going to do that and how we're going to break down all these files into small chunks so",
      "tokens": [
        51526,
        516,
        281,
        360,
        300,
        293,
        577,
        321,
        434,
        516,
        281,
        1821,
        760,
        439,
        613,
        7098,
        666,
        1359,
        24004,
        370,
        51806
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2833496332168579,
      "compression_ratio": 1.6875,
      "no_speech_prob": 0.6368852257728577
    },
    {
      "id": 38,
      "seek": 24576,
      "start": 2416.399994506836,
      "end": 2425.1999975585936,
      "text": " that we don't overwhelm that context window for the LLM and work on very small things",
      "tokens": [
        50364,
        300,
        321,
        500,
        380,
        9103,
        76,
        300,
        4319,
        4910,
        337,
        264,
        441,
        43,
        44,
        293,
        589,
        322,
        588,
        1359,
        721,
        50804
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2692306637763977,
      "compression_ratio": 1.5106383562088013,
      "no_speech_prob": 0.22479209303855896
    },
    {
      "id": 39,
      "seek": 24576,
      "start": 2425.1999975585936,
      "end": 2432.7599951171874,
      "text": " and be able to iterate these things. But yeah, I think it's this is a very young thing, spectrum",
      "tokens": [
        50804,
        293,
        312,
        1075,
        281,
        44497,
        613,
        721,
        13,
        583,
        1338,
        11,
        286,
        519,
        309,
        311,
        341,
        307,
        257,
        588,
        2037,
        551,
        11,
        11143,
        51182
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2692306637763977,
      "compression_ratio": 1.5106383562088013,
      "no_speech_prob": 0.22479209303855896
    },
    {
      "id": 40,
      "seek": 24576,
      "start": 2432.7599951171874,
      "end": 2437.5200048828124,
      "text": " and development. And it's I think it's got a long way to mature before we can really",
      "tokens": [
        51182,
        293,
        3250,
        13,
        400,
        309,
        311,
        286,
        519,
        309,
        311,
        658,
        257,
        938,
        636,
        281,
        14442,
        949,
        321,
        393,
        534,
        51420
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2692306637763977,
      "compression_ratio": 1.5106383562088013,
      "no_speech_prob": 0.22479209303855896
    },
    {
      "id": 41,
      "seek": 24576,
      "start": 2437.5200048828124,
      "end": 2438.5200048828124,
      "text": " use it properly.",
      "tokens": [
        51420,
        764,
        309,
        6108,
        13,
        51470
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2692306637763977,
      "compression_ratio": 1.5106383562088013,
      "no_speech_prob": 0.22479209303855896
    },
    {
      "id": 42,
      "seek": 26788,
      "start": 2438.6800085449217,
      "end": 2447.599991455078,
      "text": " I wonder if this approach is more helpful for the LLM to have the relationships as a",
      "tokens": [
        50372,
        286,
        2441,
        498,
        341,
        3109,
        307,
        544,
        4961,
        337,
        264,
        441,
        43,
        44,
        281,
        362,
        264,
        6159,
        382,
        257,
        50818
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34228515625,
      "compression_ratio": 1.5227272510528564,
      "no_speech_prob": 0.09399189800024033
    },
    {
      "id": 43,
      "seek": 26788,
      "start": 2447.599991455078,
      "end": 2455.5200048828124,
      "text": " specification or whether it helps more us humans to review the spec because we are visual",
      "tokens": [
        50818,
        31256,
        420,
        1968,
        309,
        3665,
        544,
        505,
        6255,
        281,
        3131,
        264,
        1608,
        570,
        321,
        366,
        5056,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34228515625,
      "compression_ratio": 1.5227272510528564,
      "no_speech_prob": 0.09399189800024033
    },
    {
      "id": 44,
      "seek": 26788,
      "start": 2455.5200048828124,
      "end": 2467.2800146484374,
      "text": " beings. And yeah, it's easier for us to review a diagram. But then I sometimes wonder whether",
      "tokens": [
        51214,
        8958,
        13,
        400,
        1338,
        11,
        309,
        311,
        3571,
        337,
        505,
        281,
        3131,
        257,
        10686,
        13,
        583,
        550,
        286,
        2171,
        2441,
        1968,
        51802
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34228515625,
      "compression_ratio": 1.5227272510528564,
      "no_speech_prob": 0.09399189800024033
    },
    {
      "id": 45,
      "seek": 29664,
      "start": 2467.2800146484374,
      "end": 2471.840012207031,
      "text": " it makes sense to follow all those lines to check whether the diagram is correct.",
      "tokens": [
        50364,
        309,
        1669,
        2020,
        281,
        1524,
        439,
        729,
        3876,
        281,
        1520,
        1968,
        264,
        10686,
        307,
        3006,
        13,
        50592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2400188446044922,
      "compression_ratio": 1.9295153617858887,
      "no_speech_prob": 0.011607768014073372
    },
    {
      "id": 46,
      "seek": 29664,
      "start": 2471.840012207031,
      "end": 2476.840012207031,
      "text": " So, yes, of course, you've got to rely on the fact that the diagram is correct. If you've",
      "tokens": [
        50592,
        407,
        11,
        2086,
        11,
        295,
        1164,
        11,
        291,
        600,
        658,
        281,
        10687,
        322,
        264,
        1186,
        300,
        264,
        10686,
        307,
        3006,
        13,
        759,
        291,
        600,
        50842
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2400188446044922,
      "compression_ratio": 1.9295153617858887,
      "no_speech_prob": 0.011607768014073372
    },
    {
      "id": 47,
      "seek": 29664,
      "start": 2476.840012207031,
      "end": 2485.400009765625,
      "text": " said create if you created the diagram yourself and given it as part of the spec, then yes,",
      "tokens": [
        50842,
        848,
        1884,
        498,
        291,
        2942,
        264,
        10686,
        1803,
        293,
        2212,
        309,
        382,
        644,
        295,
        264,
        1608,
        11,
        550,
        2086,
        11,
        51270
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2400188446044922,
      "compression_ratio": 1.9295153617858887,
      "no_speech_prob": 0.011607768014073372
    },
    {
      "id": 48,
      "seek": 29664,
      "start": 2485.400009765625,
      "end": 2489.5200048828124,
      "text": " the diagram is what I want. And then you've got to review the code to make sure it's",
      "tokens": [
        51270,
        264,
        10686,
        307,
        437,
        286,
        528,
        13,
        400,
        550,
        291,
        600,
        658,
        281,
        3131,
        264,
        3089,
        281,
        652,
        988,
        309,
        311,
        51476
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2400188446044922,
      "compression_ratio": 1.9295153617858887,
      "no_speech_prob": 0.011607768014073372
    },
    {
      "id": 49,
      "seek": 29664,
      "start": 2489.5200048828124,
      "end": 2495.2800146484374,
      "text": " followed the diagram and the specification. But if you've asked it to create the diagram,",
      "tokens": [
        51476,
        6263,
        264,
        10686,
        293,
        264,
        31256,
        13,
        583,
        498,
        291,
        600,
        2351,
        309,
        281,
        1884,
        264,
        10686,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2400188446044922,
      "compression_ratio": 1.9295153617858887,
      "no_speech_prob": 0.011607768014073372
    },
    {
      "id": 50,
      "seek": 32464,
      "start": 2495.7599951171874,
      "end": 2502.120010986328,
      "text": " maybe this is just kind of it's giving you what you want rather than the actual reality",
      "tokens": [
        50388,
        1310,
        341,
        307,
        445,
        733,
        295,
        309,
        311,
        2902,
        291,
        437,
        291,
        528,
        2831,
        813,
        264,
        3539,
        4103,
        50706
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2562778890132904,
      "compression_ratio": 1.7250995635986328,
      "no_speech_prob": 0.0443534329533577
    },
    {
      "id": 51,
      "seek": 32464,
      "start": 2502.120010986328,
      "end": 2507.5200048828124,
      "text": " of it. So say you have created this whole spec and you're saying, OK, this is what I've",
      "tokens": [
        50706,
        295,
        309,
        13,
        407,
        584,
        291,
        362,
        2942,
        341,
        1379,
        1608,
        293,
        291,
        434,
        1566,
        11,
        2264,
        11,
        341,
        307,
        437,
        286,
        600,
        50976
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2562778890132904,
      "compression_ratio": 1.7250995635986328,
      "no_speech_prob": 0.0443534329533577
    },
    {
      "id": 52,
      "seek": 32464,
      "start": 2507.5200048828124,
      "end": 2512.64,
      "text": " given you. Show me a diagram of what you've created in the code and it diagrams what's",
      "tokens": [
        50976,
        2212,
        291,
        13,
        6895,
        385,
        257,
        10686,
        295,
        437,
        291,
        600,
        2942,
        294,
        264,
        3089,
        293,
        309,
        36709,
        437,
        311,
        51232
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2562778890132904,
      "compression_ratio": 1.7250995635986328,
      "no_speech_prob": 0.0443534329533577
    },
    {
      "id": 53,
      "seek": 32464,
      "start": 2512.64,
      "end": 2517.5200048828124,
      "text": " in the spec. But the code, if you haven't checked it, might be completely different",
      "tokens": [
        51232,
        294,
        264,
        1608,
        13,
        583,
        264,
        3089,
        11,
        498,
        291,
        2378,
        380,
        10033,
        309,
        11,
        1062,
        312,
        2584,
        819,
        51476
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2562778890132904,
      "compression_ratio": 1.7250995635986328,
      "no_speech_prob": 0.0443534329533577
    },
    {
      "id": 54,
      "seek": 32464,
      "start": 2517.5200048828124,
      "end": 2524.9600073242186,
      "text": " and some complete mess. And because we all know at the moment, even if we aren't using",
      "tokens": [
        51476,
        293,
        512,
        3566,
        2082,
        13,
        400,
        570,
        321,
        439,
        458,
        412,
        264,
        1623,
        11,
        754,
        498,
        321,
        3212,
        380,
        1228,
        51848
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2562778890132904,
      "compression_ratio": 1.7250995635986328,
      "no_speech_prob": 0.0443534329533577
    },
    {
      "id": 55,
      "seek": 35432,
      "start": 2524.9600073242186,
      "end": 2530.8000036621092,
      "text": " AI, we have got these beautiful architecture diagrams and things and specifications. And",
      "tokens": [
        50364,
        7318,
        11,
        321,
        362,
        658,
        613,
        2238,
        9482,
        36709,
        293,
        721,
        293,
        29448,
        13,
        400,
        50656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2773609757423401,
      "compression_ratio": 1.6937799453735352,
      "no_speech_prob": 0.1268526017665863
    },
    {
      "id": 56,
      "seek": 35432,
      "start": 2530.8000036621092,
      "end": 2536.8000036621092,
      "text": " then we have the code, which is completely different to that. So we can try and use things",
      "tokens": [
        50656,
        550,
        321,
        362,
        264,
        3089,
        11,
        597,
        307,
        2584,
        819,
        281,
        300,
        13,
        407,
        321,
        393,
        853,
        293,
        764,
        721,
        50956
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2773609757423401,
      "compression_ratio": 1.6937799453735352,
      "no_speech_prob": 0.1268526017665863
    },
    {
      "id": 57,
      "seek": 35432,
      "start": 2536.8000036621092,
      "end": 2543.120010986328,
      "text": " like architectural fitness functions as sort of tests to make sure that things are as we",
      "tokens": [
        50956,
        411,
        26621,
        15303,
        6828,
        382,
        1333,
        295,
        6921,
        281,
        652,
        988,
        300,
        721,
        366,
        382,
        321,
        51272
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2773609757423401,
      "compression_ratio": 1.6937799453735352,
      "no_speech_prob": 0.1268526017665863
    },
    {
      "id": 58,
      "seek": 35432,
      "start": 2543.120010986328,
      "end": 2549.080002441406,
      "text": " want them. And so I think that's probably something to try and use with with the spec",
      "tokens": [
        51272,
        528,
        552,
        13,
        400,
        370,
        286,
        519,
        300,
        311,
        1391,
        746,
        281,
        853,
        293,
        764,
        365,
        365,
        264,
        1608,
        51570
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2773609757423401,
      "compression_ratio": 1.6937799453735352,
      "no_speech_prob": 0.1268526017665863
    },
    {
      "id": 59,
      "seek": 37844,
      "start": 2549.080002441406,
      "end": 2553.9600073242186,
      "text": " coding as well. But we can't trust that the LLM is telling us the truth.",
      "tokens": [
        50364,
        17720,
        382,
        731,
        13,
        583,
        321,
        393,
        380,
        3361,
        300,
        264,
        441,
        43,
        44,
        307,
        3585,
        505,
        264,
        3494,
        13,
        50608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29066911339759827,
      "compression_ratio": 1.5720930099487305,
      "no_speech_prob": 0.3442738652229309
    },
    {
      "id": 60,
      "seek": 37844,
      "start": 2556.599991455078,
      "end": 2561.879990234375,
      "text": " Yeah, which basically. So I think that's that's a very important and good point. And it's",
      "tokens": [
        50740,
        865,
        11,
        597,
        1936,
        13,
        407,
        286,
        519,
        300,
        311,
        300,
        311,
        257,
        588,
        1021,
        293,
        665,
        935,
        13,
        400,
        309,
        311,
        51004
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29066911339759827,
      "compression_ratio": 1.5720930099487305,
      "no_speech_prob": 0.3442738652229309
    },
    {
      "id": 61,
      "seek": 37844,
      "start": 2561.879990234375,
      "end": 2568.5200048828124,
      "text": " for real. I mean, the things that you mentioned, they do happen as hallucinations, which",
      "tokens": [
        51004,
        337,
        957,
        13,
        286,
        914,
        11,
        264,
        721,
        300,
        291,
        2835,
        11,
        436,
        360,
        1051,
        382,
        35212,
        10325,
        11,
        597,
        51336
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29066911339759827,
      "compression_ratio": 1.5720930099487305,
      "no_speech_prob": 0.3442738652229309
    },
    {
      "id": 62,
      "seek": 37844,
      "start": 2570.1999975585936,
      "end": 2576.1999975585936,
      "text": " yeah, which leads to the. Is there a broader problem? Like how do you how do you solve",
      "tokens": [
        51420,
        1338,
        11,
        597,
        6689,
        281,
        264,
        13,
        1119,
        456,
        257,
        13227,
        1154,
        30,
        1743,
        577,
        360,
        291,
        577,
        360,
        291,
        5039,
        51720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29066911339759827,
      "compression_ratio": 1.5720930099487305,
      "no_speech_prob": 0.3442738652229309
    },
    {
      "id": 63,
      "seek": 40556,
      "start": 2576.1999975585936,
      "end": 2581.2400061035155,
      "text": " the problem that diagrams might be detached from reality? I mean, shouldn't you somehow",
      "tokens": [
        50364,
        264,
        1154,
        300,
        36709,
        1062,
        312,
        42050,
        490,
        4103,
        30,
        286,
        914,
        11,
        4659,
        380,
        291,
        6063,
        50616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2388930767774582,
      "compression_ratio": 1.6699507236480713,
      "no_speech_prob": 0.046948570758104324
    },
    {
      "id": 64,
      "seek": 40556,
      "start": 2581.2400061035155,
      "end": 2586.840012207031,
      "text": " create them from the original code then and use that as as diagrams?",
      "tokens": [
        50616,
        1884,
        552,
        490,
        264,
        3380,
        3089,
        550,
        293,
        764,
        300,
        382,
        382,
        36709,
        30,
        50896
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2388930767774582,
      "compression_ratio": 1.6699507236480713,
      "no_speech_prob": 0.046948570758104324
    },
    {
      "id": 65,
      "seek": 40556,
      "start": 2588.0399938964842,
      "end": 2595.1599890136717,
      "text": " Yeah, so that's one thing that I think might be helpful for in that if you are give it some code",
      "tokens": [
        50956,
        865,
        11,
        370,
        300,
        311,
        472,
        551,
        300,
        286,
        519,
        1062,
        312,
        4961,
        337,
        294,
        300,
        498,
        291,
        366,
        976,
        309,
        512,
        3089,
        51312
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2388930767774582,
      "compression_ratio": 1.6699507236480713,
      "no_speech_prob": 0.046948570758104324
    },
    {
      "id": 66,
      "seek": 40556,
      "start": 2595.1599890136717,
      "end": 2602.4399877929686,
      "text": " that it hasn't written and say, like create a diagram of how this is all interacting,",
      "tokens": [
        51312,
        300,
        309,
        6132,
        380,
        3720,
        293,
        584,
        11,
        411,
        1884,
        257,
        10686,
        295,
        577,
        341,
        307,
        439,
        18017,
        11,
        51676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2388930767774582,
      "compression_ratio": 1.6699507236480713,
      "no_speech_prob": 0.046948570758104324
    },
    {
      "id": 67,
      "seek": 43180,
      "start": 2603.080002441406,
      "end": 2610.4399877929686,
      "text": " then that's probably more likely to be correct. It might not be. But you can then say, OK,",
      "tokens": [
        50396,
        550,
        300,
        311,
        1391,
        544,
        3700,
        281,
        312,
        3006,
        13,
        467,
        1062,
        406,
        312,
        13,
        583,
        291,
        393,
        550,
        584,
        11,
        2264,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22981837391853333,
      "compression_ratio": 1.4894737005233765,
      "no_speech_prob": 0.016789106652140617
    },
    {
      "id": 68,
      "seek": 43180,
      "start": 2610.4399877929686,
      "end": 2616.6800085449217,
      "text": " here's that diagram. Here's the diagram that that we created originally and actually compare them.",
      "tokens": [
        50764,
        510,
        311,
        300,
        10686,
        13,
        1692,
        311,
        264,
        10686,
        300,
        300,
        321,
        2942,
        7993,
        293,
        767,
        6794,
        552,
        13,
        51076
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22981837391853333,
      "compression_ratio": 1.4894737005233765,
      "no_speech_prob": 0.016789106652140617
    },
    {
      "id": 69,
      "seek": 43180,
      "start": 2616.6800085449217,
      "end": 2624.2800146484374,
      "text": " Because as you were saying, we're we're good with these visuals as humans. And so using AI to",
      "tokens": [
        51076,
        1436,
        382,
        291,
        645,
        1566,
        11,
        321,
        434,
        321,
        434,
        665,
        365,
        613,
        26035,
        382,
        6255,
        13,
        400,
        370,
        1228,
        7318,
        281,
        51456
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22981837391853333,
      "compression_ratio": 1.4894737005233765,
      "no_speech_prob": 0.016789106652140617
    },
    {
      "id": 70,
      "seek": 45364,
      "start": 2624.5200048828124,
      "end": 2632.9999853515624,
      "text": " review things that it hasn't created or the pattern of using one model to create something",
      "tokens": [
        50376,
        3131,
        721,
        300,
        309,
        6132,
        380,
        2942,
        420,
        264,
        5102,
        295,
        1228,
        472,
        2316,
        281,
        1884,
        746,
        50800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24440009891986847,
      "compression_ratio": 1.6467065811157227,
      "no_speech_prob": 0.09530089050531387
    },
    {
      "id": 71,
      "seek": 45364,
      "start": 2632.9999853515624,
      "end": 2639.2400061035155,
      "text": " and then another model or agent to review it and check that the spec and the code actually match.",
      "tokens": [
        50800,
        293,
        550,
        1071,
        2316,
        420,
        9461,
        281,
        3131,
        309,
        293,
        1520,
        300,
        264,
        1608,
        293,
        264,
        3089,
        767,
        2995,
        13,
        51112
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24440009891986847,
      "compression_ratio": 1.6467065811157227,
      "no_speech_prob": 0.09530089050531387
    },
    {
      "id": 72,
      "seek": 45364,
      "start": 2640.360001220703,
      "end": 2647.319992675781,
      "text": " That's another pattern that we can use. So when when you try to compare them visually,",
      "tokens": [
        51168,
        663,
        311,
        1071,
        5102,
        300,
        321,
        393,
        764,
        13,
        407,
        562,
        562,
        291,
        853,
        281,
        6794,
        552,
        19622,
        11,
        51516
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24440009891986847,
      "compression_ratio": 1.6467065811157227,
      "no_speech_prob": 0.09530089050531387
    },
    {
      "id": 73,
      "seek": 47668,
      "start": 2648.0399938964842,
      "end": 2654.9999853515624,
      "text": " I remember when working with Plant2ML, there are diagrams where the layout is trivial,",
      "tokens": [
        50400,
        286,
        1604,
        562,
        1364,
        365,
        28995,
        17,
        12683,
        11,
        456,
        366,
        36709,
        689,
        264,
        13333,
        307,
        26703,
        11,
        50748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2673373222351074,
      "compression_ratio": 1.5665024518966675,
      "no_speech_prob": 0.011506984941661358
    },
    {
      "id": 74,
      "seek": 47668,
      "start": 2654.9999853515624,
      "end": 2660.6800085449217,
      "text": " like activity and sequence diagrams. But for instance, component or class diagrams,",
      "tokens": [
        50748,
        411,
        5191,
        293,
        8310,
        36709,
        13,
        583,
        337,
        5197,
        11,
        6542,
        420,
        1508,
        36709,
        11,
        51032
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2673373222351074,
      "compression_ratio": 1.5665024518966675,
      "no_speech_prob": 0.011506984941661358
    },
    {
      "id": 75,
      "seek": 47668,
      "start": 2661.5600134277342,
      "end": 2669.080002441406,
      "text": " where the algorithm tries to place elements in such a way that the lines do not cross.",
      "tokens": [
        51076,
        689,
        264,
        9284,
        9898,
        281,
        1081,
        4959,
        294,
        1270,
        257,
        636,
        300,
        264,
        3876,
        360,
        406,
        3278,
        13,
        51452
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2673373222351074,
      "compression_ratio": 1.5665024518966675,
      "no_speech_prob": 0.011506984941661358
    },
    {
      "id": 76,
      "seek": 47668,
      "start": 2669.879990234375,
      "end": 2674.5200048828124,
      "text": " And I could imagine that when I work with those diagrams and",
      "tokens": [
        51492,
        400,
        286,
        727,
        3811,
        300,
        562,
        286,
        589,
        365,
        729,
        36709,
        293,
        51724
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2673373222351074,
      "compression_ratio": 1.5665024518966675,
      "no_speech_prob": 0.011506984941661358
    },
    {
      "id": 77,
      "seek": 50388,
      "start": 2674.5200048828124,
      "end": 2683.400009765625,
      "text": " add something that everything flips over. What's your experience with this? Can we stabilize this?",
      "tokens": [
        50364,
        909,
        746,
        300,
        1203,
        40249,
        670,
        13,
        708,
        311,
        428,
        1752,
        365,
        341,
        30,
        1664,
        321,
        31870,
        341,
        30,
        50808
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24491426348686218,
      "compression_ratio": 1.5762711763381958,
      "no_speech_prob": 0.007343210279941559
    },
    {
      "id": 78,
      "seek": 50388,
      "start": 2684.7599951171874,
      "end": 2691.319992675781,
      "text": " I think Structurizr has a solution for this. The manual layout, something like this.",
      "tokens": [
        50876,
        286,
        519,
        745,
        1757,
        374,
        590,
        81,
        575,
        257,
        3827,
        337,
        341,
        13,
        440,
        9688,
        13333,
        11,
        746,
        411,
        341,
        13,
        51204
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24491426348686218,
      "compression_ratio": 1.5762711763381958,
      "no_speech_prob": 0.007343210279941559
    },
    {
      "id": 79,
      "seek": 50388,
      "start": 2691.319992675781,
      "end": 2699.9600073242186,
      "text": " Yes. So Structurizr has a manual layout. If you're doing some of the different types of diagram",
      "tokens": [
        51204,
        1079,
        13,
        407,
        745,
        1757,
        374,
        590,
        81,
        575,
        257,
        9688,
        13333,
        13,
        759,
        291,
        434,
        884,
        512,
        295,
        264,
        819,
        3467,
        295,
        10686,
        51636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24491426348686218,
      "compression_ratio": 1.5762711763381958,
      "no_speech_prob": 0.007343210279941559
    },
    {
      "id": 80,
      "seek": 52932,
      "start": 2699.9600073242186,
      "end": 2707.9600073242186,
      "text": " in Mermaid and Plant2ML have some ways of specifying things. So if you're creating a C4",
      "tokens": [
        50364,
        294,
        376,
        32124,
        293,
        28995,
        17,
        12683,
        362,
        512,
        2098,
        295,
        1608,
        5489,
        721,
        13,
        407,
        498,
        291,
        434,
        4084,
        257,
        383,
        19,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23874999582767487,
      "compression_ratio": 1.454545497894287,
      "no_speech_prob": 0.048072151839733124
    },
    {
      "id": 81,
      "seek": 52932,
      "start": 2707.9600073242186,
      "end": 2717.799973144531,
      "text": " diagram in Plant2ML, you can use rel U for a relationship up, rel D for down and left and right.",
      "tokens": [
        50764,
        10686,
        294,
        28995,
        17,
        12683,
        11,
        291,
        393,
        764,
        1039,
        624,
        337,
        257,
        2480,
        493,
        11,
        1039,
        413,
        337,
        760,
        293,
        1411,
        293,
        558,
        13,
        51256
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23874999582767487,
      "compression_ratio": 1.454545497894287,
      "no_speech_prob": 0.048072151839733124
    },
    {
      "id": 82,
      "seek": 52932,
      "start": 2717.799973144531,
      "end": 2728.4399877929686,
      "text": " So you have some sort of control. The order that you put items into your code will also",
      "tokens": [
        51256,
        407,
        291,
        362,
        512,
        1333,
        295,
        1969,
        13,
        440,
        1668,
        300,
        291,
        829,
        4754,
        666,
        428,
        3089,
        486,
        611,
        51788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23874999582767487,
      "compression_ratio": 1.454545497894287,
      "no_speech_prob": 0.048072151839733124
    },
    {
      "id": 83,
      "seek": 55780,
      "start": 2728.4399877929686,
      "end": 2734.11998046875,
      "text": " determine where they appear as well. And if you're doing things like the activity diagram,",
      "tokens": [
        50364,
        6997,
        689,
        436,
        4204,
        382,
        731,
        13,
        400,
        498,
        291,
        434,
        884,
        721,
        411,
        264,
        5191,
        10686,
        11,
        50648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20183634757995605,
      "compression_ratio": 1.707207202911377,
      "no_speech_prob": 0.0073172301054000854
    },
    {
      "id": 84,
      "seek": 55780,
      "start": 2734.11998046875,
      "end": 2739.799973144531,
      "text": " if you are adding in branches, say yes and no, the order that you put that in will determine",
      "tokens": [
        50648,
        498,
        291,
        366,
        5127,
        294,
        14770,
        11,
        584,
        2086,
        293,
        572,
        11,
        264,
        1668,
        300,
        291,
        829,
        300,
        294,
        486,
        6997,
        50932
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20183634757995605,
      "compression_ratio": 1.707207202911377,
      "no_speech_prob": 0.0073172301054000854
    },
    {
      "id": 85,
      "seek": 55780,
      "start": 2739.799973144531,
      "end": 2749.7200170898436,
      "text": " where things are. So you've got some control, but you can still end up even in Structurizr when",
      "tokens": [
        50932,
        689,
        721,
        366,
        13,
        407,
        291,
        600,
        658,
        512,
        1969,
        11,
        457,
        291,
        393,
        920,
        917,
        493,
        754,
        294,
        745,
        1757,
        374,
        590,
        81,
        562,
        51428
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20183634757995605,
      "compression_ratio": 1.707207202911377,
      "no_speech_prob": 0.0073172301054000854
    },
    {
      "id": 86,
      "seek": 55780,
      "start": 2749.7200170898436,
      "end": 2756.359970703125,
      "text": " it's doing the auto layout for you, you can end up with some very odd things where like one thing's",
      "tokens": [
        51428,
        309,
        311,
        884,
        264,
        8399,
        13333,
        337,
        291,
        11,
        291,
        393,
        917,
        493,
        365,
        512,
        588,
        7401,
        721,
        689,
        411,
        472,
        551,
        311,
        51760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20183634757995605,
      "compression_ratio": 1.707207202911377,
      "no_speech_prob": 0.0073172301054000854
    },
    {
      "id": 87,
      "seek": 58572,
      "start": 2756.359970703125,
      "end": 2760.920029296875,
      "text": " up here and it means all the lines are like this and crossing over. And you think, well,",
      "tokens": [
        50364,
        493,
        510,
        293,
        309,
        1355,
        439,
        264,
        3876,
        366,
        411,
        341,
        293,
        14712,
        670,
        13,
        400,
        291,
        519,
        11,
        731,
        11,
        50592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22688937187194824,
      "compression_ratio": 1.7137404680252075,
      "no_speech_prob": 0.03160998597741127
    },
    {
      "id": 88,
      "seek": 58572,
      "start": 2760.920029296875,
      "end": 2767.400009765625,
      "text": " if you just put that down there, you wouldn't have that problem. So yes, these tools do try,",
      "tokens": [
        50592,
        498,
        291,
        445,
        829,
        300,
        760,
        456,
        11,
        291,
        2759,
        380,
        362,
        300,
        1154,
        13,
        407,
        2086,
        11,
        613,
        3873,
        360,
        853,
        11,
        50916
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22688937187194824,
      "compression_ratio": 1.7137404680252075,
      "no_speech_prob": 0.03160998597741127
    },
    {
      "id": 89,
      "seek": 58572,
      "start": 2768.2800146484374,
      "end": 2773.7200170898436,
      "text": " but you get to that point where you think, I can't line that up. Or you get annoying things",
      "tokens": [
        50960,
        457,
        291,
        483,
        281,
        300,
        935,
        689,
        291,
        519,
        11,
        286,
        393,
        380,
        1622,
        300,
        493,
        13,
        1610,
        291,
        483,
        11304,
        721,
        51232
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22688937187194824,
      "compression_ratio": 1.7137404680252075,
      "no_speech_prob": 0.03160998597741127
    },
    {
      "id": 90,
      "seek": 58572,
      "start": 2773.7200170898436,
      "end": 2778.7599951171874,
      "text": " like I really like things to line up and like the title is supposed to be in the centre,",
      "tokens": [
        51232,
        411,
        286,
        534,
        411,
        721,
        281,
        1622,
        493,
        293,
        411,
        264,
        4876,
        307,
        3442,
        281,
        312,
        294,
        264,
        10093,
        11,
        51484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22688937187194824,
      "compression_ratio": 1.7137404680252075,
      "no_speech_prob": 0.03160998597741127
    },
    {
      "id": 91,
      "seek": 58572,
      "start": 2778.7599951171874,
      "end": 2784.2800146484374,
      "text": " but it's actually slightly off centre. It's just annoying. But yeah, with Structurizr,",
      "tokens": [
        51484,
        457,
        309,
        311,
        767,
        4748,
        766,
        10093,
        13,
        467,
        311,
        445,
        11304,
        13,
        583,
        1338,
        11,
        365,
        745,
        1757,
        374,
        590,
        81,
        11,
        51760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22688937187194824,
      "compression_ratio": 1.7137404680252075,
      "no_speech_prob": 0.03160998597741127
    },
    {
      "id": 92,
      "seek": 61364,
      "start": 2784.2800146484374,
      "end": 2790.359970703125,
      "text": " there is manual layout. But the downside to that is that when you then change the model,",
      "tokens": [
        50364,
        456,
        307,
        9688,
        13333,
        13,
        583,
        264,
        25060,
        281,
        300,
        307,
        300,
        562,
        291,
        550,
        1319,
        264,
        2316,
        11,
        50668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18477638065814972,
      "compression_ratio": 1.8907562494277954,
      "no_speech_prob": 0.15457934141159058
    },
    {
      "id": 93,
      "seek": 61364,
      "start": 2791.2399755859374,
      "end": 2796.11998046875,
      "text": " that manual layout is probably going to need to be changed as well. If you add something,",
      "tokens": [
        50712,
        300,
        9688,
        13333,
        307,
        1391,
        516,
        281,
        643,
        281,
        312,
        3105,
        382,
        731,
        13,
        759,
        291,
        909,
        746,
        11,
        50956
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18477638065814972,
      "compression_ratio": 1.8907562494277954,
      "no_speech_prob": 0.15457934141159058
    },
    {
      "id": 94,
      "seek": 61364,
      "start": 2796.11998046875,
      "end": 2801.16001953125,
      "text": " that new thing is just going to appear in the top left corner. And that might be covering",
      "tokens": [
        50956,
        300,
        777,
        551,
        307,
        445,
        516,
        281,
        4204,
        294,
        264,
        1192,
        1411,
        4538,
        13,
        400,
        300,
        1062,
        312,
        10322,
        51208
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18477638065814972,
      "compression_ratio": 1.8907562494277954,
      "no_speech_prob": 0.15457934141159058
    },
    {
      "id": 95,
      "seek": 61364,
      "start": 2801.16001953125,
      "end": 2806.359970703125,
      "text": " something else up. And so if you do add things or change the model, you'll have to review your",
      "tokens": [
        51208,
        746,
        1646,
        493,
        13,
        400,
        370,
        498,
        291,
        360,
        909,
        721,
        420,
        1319,
        264,
        2316,
        11,
        291,
        603,
        362,
        281,
        3131,
        428,
        51468
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18477638065814972,
      "compression_ratio": 1.8907562494277954,
      "no_speech_prob": 0.15457934141159058
    },
    {
      "id": 96,
      "seek": 61364,
      "start": 2806.359970703125,
      "end": 2811.7200170898436,
      "text": " manual layout. So I would say to people only use manual layout when you really need to",
      "tokens": [
        51468,
        9688,
        13333,
        13,
        407,
        286,
        576,
        584,
        281,
        561,
        787,
        764,
        9688,
        13333,
        562,
        291,
        534,
        643,
        281,
        51736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18477638065814972,
      "compression_ratio": 1.8907562494277954,
      "no_speech_prob": 0.15457934141159058
    },
    {
      "id": 97,
      "seek": 64108,
      "start": 2811.7200170898436,
      "end": 2817.319992675781,
      "text": " and have some sort of process, be it manual or automatic, where you will go and check",
      "tokens": [
        50364,
        293,
        362,
        512,
        1333,
        295,
        1399,
        11,
        312,
        309,
        9688,
        420,
        12509,
        11,
        689,
        291,
        486,
        352,
        293,
        1520,
        50644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23618184030056,
      "compression_ratio": 1.5437500476837158,
      "no_speech_prob": 0.0032199816778302193
    },
    {
      "id": 98,
      "seek": 64108,
      "start": 2817.319992675781,
      "end": 2822.2800146484374,
      "text": " your manual ones when something has changed significantly in the model.",
      "tokens": [
        50644,
        428,
        9688,
        2306,
        562,
        746,
        575,
        3105,
        10591,
        294,
        264,
        2316,
        13,
        50892
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23618184030056,
      "compression_ratio": 1.5437500476837158,
      "no_speech_prob": 0.0032199816778302193
    },
    {
      "id": 99,
      "seek": 64108,
      "start": 2824.11998046875,
      "end": 2831.319992675781,
      "text": " So you were talking about how you can sort of review things that one element puts out and",
      "tokens": [
        50984,
        407,
        291,
        645,
        1417,
        466,
        577,
        291,
        393,
        1333,
        295,
        3131,
        721,
        300,
        472,
        4478,
        8137,
        484,
        293,
        51344
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23618184030056,
      "compression_ratio": 1.5437500476837158,
      "no_speech_prob": 0.0032199816778302193
    },
    {
      "id": 100,
      "seek": 66068,
      "start": 2831.319992675781,
      "end": 2839.559982910156,
      "text": " have that reviewed by another one. And I mean, we had cases, as you mentioned,",
      "tokens": [
        50364,
        362,
        300,
        18429,
        538,
        1071,
        472,
        13,
        400,
        286,
        914,
        11,
        321,
        632,
        3331,
        11,
        382,
        291,
        2835,
        11,
        50776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3036063611507416,
      "compression_ratio": 1.4525139331817627,
      "no_speech_prob": 0.20933222770690918
    },
    {
      "id": 101,
      "seek": 66068,
      "start": 2841.319992675781,
      "end": 2847.2399755859374,
      "text": " even on the stream, like publicly, we had somebody who basically said, okay, he was",
      "tokens": [
        50864,
        754,
        322,
        264,
        4309,
        11,
        411,
        14843,
        11,
        321,
        632,
        512,
        47466,
        88,
        567,
        1936,
        848,
        11,
        1392,
        11,
        415,
        390,
        51160
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3036063611507416,
      "compression_ratio": 1.4525139331817627,
      "no_speech_prob": 0.20933222770690918
    },
    {
      "id": 102,
      "seek": 66068,
      "start": 2847.2399755859374,
      "end": 2856.7599951171874,
      "text": " white coding that stuff, some stuff, and he asked the LLM to create more tests and got suspicious",
      "tokens": [
        51160,
        2418,
        17720,
        300,
        1507,
        11,
        512,
        1507,
        11,
        293,
        415,
        2351,
        264,
        441,
        43,
        44,
        281,
        1884,
        544,
        6921,
        293,
        658,
        17931,
        51636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3036063611507416,
      "compression_ratio": 1.4525139331817627,
      "no_speech_prob": 0.20933222770690918
    },
    {
      "id": 103,
      "seek": 68612,
      "start": 2857.319992675781,
      "end": 2863.400009765625,
      "text": " and figured out that, in fact, the tests didn't do anything. They just generated output that",
      "tokens": [
        50392,
        293,
        8932,
        484,
        300,
        11,
        294,
        1186,
        11,
        264,
        6921,
        994,
        380,
        360,
        1340,
        13,
        814,
        445,
        10833,
        5598,
        300,
        50696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2345360815525055,
      "compression_ratio": 1.6238938570022583,
      "no_speech_prob": 0.004330575466156006
    },
    {
      "id": 104,
      "seek": 68612,
      "start": 2863.400009765625,
      "end": 2871.400009765625,
      "text": " looked as if some test was running. Now, and I mean, obviously, if some human would do that,",
      "tokens": [
        50696,
        2956,
        382,
        498,
        512,
        1500,
        390,
        2614,
        13,
        823,
        11,
        293,
        286,
        914,
        11,
        2745,
        11,
        498,
        512,
        1952,
        576,
        360,
        300,
        11,
        51096
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2345360815525055,
      "compression_ratio": 1.6238938570022583,
      "no_speech_prob": 0.004330575466156006
    },
    {
      "id": 105,
      "seek": 68612,
      "start": 2872.5200048828124,
      "end": 2877.64,
      "text": " I would basically fire that person because it's just, you know, you can't trust that person",
      "tokens": [
        51152,
        286,
        576,
        1936,
        2610,
        300,
        954,
        570,
        309,
        311,
        445,
        11,
        291,
        458,
        11,
        291,
        393,
        380,
        3361,
        300,
        954,
        51408
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2345360815525055,
      "compression_ratio": 1.6238938570022583,
      "no_speech_prob": 0.004330575466156006
    },
    {
      "id": 106,
      "seek": 68612,
      "start": 2877.64,
      "end": 2885.2399755859374,
      "text": " anymore, right? Because it's really a bad thing. So what you're saying in a way is, okay,",
      "tokens": [
        51408,
        3602,
        11,
        558,
        30,
        1436,
        309,
        311,
        534,
        257,
        1578,
        551,
        13,
        407,
        437,
        291,
        434,
        1566,
        294,
        257,
        636,
        307,
        11,
        1392,
        11,
        51788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2345360815525055,
      "compression_ratio": 1.6238938570022583,
      "no_speech_prob": 0.004330575466156006
    },
    {
      "id": 107,
      "seek": 71460,
      "start": 2885.2399755859374,
      "end": 2890.359970703125,
      "text": " so I have that LLM that I don't trust. And now I have another LLM that I use to review that.",
      "tokens": [
        50364,
        370,
        286,
        362,
        300,
        441,
        43,
        44,
        300,
        286,
        500,
        380,
        3361,
        13,
        400,
        586,
        286,
        362,
        1071,
        441,
        43,
        44,
        300,
        286,
        764,
        281,
        3131,
        300,
        13,
        50620
      ],
      "temperature": 0.0,
      "avg_logprob": -0.176421120762825,
      "compression_ratio": 1.665071725845337,
      "no_speech_prob": 0.008296459913253784
    },
    {
      "id": 108,
      "seek": 71460,
      "start": 2891.080002441406,
      "end": 2896.11998046875,
      "text": " And I'm wondering, do you have any experience with that? Is that something that really works",
      "tokens": [
        50656,
        400,
        286,
        478,
        6359,
        11,
        360,
        291,
        362,
        604,
        1752,
        365,
        300,
        30,
        1119,
        300,
        746,
        300,
        534,
        1985,
        50908
      ],
      "temperature": 0.0,
      "avg_logprob": -0.176421120762825,
      "compression_ratio": 1.665071725845337,
      "no_speech_prob": 0.008296459913253784
    },
    {
      "id": 109,
      "seek": 71460,
      "start": 2896.11998046875,
      "end": 2903.9600073242186,
      "text": " in practice? Because that other LLM could also be as erroneous as the original one?",
      "tokens": [
        50908,
        294,
        3124,
        30,
        1436,
        300,
        661,
        441,
        43,
        44,
        727,
        611,
        312,
        382,
        1189,
        26446,
        563,
        382,
        264,
        3380,
        472,
        30,
        51300
      ],
      "temperature": 0.0,
      "avg_logprob": -0.176421120762825,
      "compression_ratio": 1.665071725845337,
      "no_speech_prob": 0.008296459913253784
    },
    {
      "id": 110,
      "seek": 71460,
      "start": 2903.9600073242186,
      "end": 2908.2800146484374,
      "text": " Yes, it's not something that I've done that much. But I have heard that if you",
      "tokens": [
        51300,
        1079,
        11,
        309,
        311,
        406,
        746,
        300,
        286,
        600,
        1096,
        300,
        709,
        13,
        583,
        286,
        362,
        2198,
        300,
        498,
        291,
        51516
      ],
      "temperature": 0.0,
      "avg_logprob": -0.176421120762825,
      "compression_ratio": 1.665071725845337,
      "no_speech_prob": 0.008296459913253784
    },
    {
      "id": 111,
      "seek": 73764,
      "start": 2908.9999853515624,
      "end": 2914.920029296875,
      "text": " and so the problem with the context windows, and then sort of overflowing and things,",
      "tokens": [
        50400,
        293,
        370,
        264,
        1154,
        365,
        264,
        4319,
        9309,
        11,
        293,
        550,
        1333,
        295,
        670,
        43955,
        293,
        721,
        11,
        50696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24645796418190002,
      "compression_ratio": 1.5828571319580078,
      "no_speech_prob": 0.14354637265205383
    },
    {
      "id": 112,
      "seek": 73764,
      "start": 2914.920029296875,
      "end": 2923.9600073242186,
      "text": " if you create agents that have a very specific task, then you will get much better results. So",
      "tokens": [
        50696,
        498,
        291,
        1884,
        12554,
        300,
        362,
        257,
        588,
        2685,
        5633,
        11,
        550,
        291,
        486,
        483,
        709,
        1101,
        3542,
        13,
        407,
        51148
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24645796418190002,
      "compression_ratio": 1.5828571319580078,
      "no_speech_prob": 0.14354637265205383
    },
    {
      "id": 113,
      "seek": 73764,
      "start": 2923.9600073242186,
      "end": 2932.7599951171874,
      "text": " if you have one that is just there to go through all of your typescript, and one that makes sure",
      "tokens": [
        51148,
        498,
        291,
        362,
        472,
        300,
        307,
        445,
        456,
        281,
        352,
        807,
        439,
        295,
        428,
        3467,
        5944,
        11,
        293,
        472,
        300,
        1669,
        988,
        51588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24645796418190002,
      "compression_ratio": 1.5828571319580078,
      "no_speech_prob": 0.14354637265205383
    },
    {
      "id": 114,
      "seek": 76212,
      "start": 2932.7599951171874,
      "end": 2937.559982910156,
      "text": " that certain things like architecture decisions have been written, and so it's not so much,",
      "tokens": [
        50364,
        300,
        1629,
        721,
        411,
        9482,
        5327,
        362,
        668,
        3720,
        11,
        293,
        370,
        309,
        311,
        406,
        370,
        709,
        11,
        50604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23712225258350372,
      "compression_ratio": 1.5895196199417114,
      "no_speech_prob": 0.09237781912088394
    },
    {
      "id": 115,
      "seek": 76212,
      "start": 2938.1999975585936,
      "end": 2947.64,
      "text": " I've got one LLM that does everything and one that checks everything. It's I'm using",
      "tokens": [
        50636,
        286,
        600,
        658,
        472,
        441,
        43,
        44,
        300,
        775,
        1203,
        293,
        472,
        300,
        13834,
        1203,
        13,
        467,
        311,
        286,
        478,
        1228,
        51108
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23712225258350372,
      "compression_ratio": 1.5895196199417114,
      "no_speech_prob": 0.09237781912088394
    },
    {
      "id": 116,
      "seek": 76212,
      "start": 2947.64,
      "end": 2955.080002441406,
      "text": " different agents to do very specific jobs. And then you still can't guarantee. The thing is,",
      "tokens": [
        51108,
        819,
        12554,
        281,
        360,
        588,
        2685,
        4782,
        13,
        400,
        550,
        291,
        920,
        393,
        380,
        10815,
        13,
        440,
        551,
        307,
        11,
        51480
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23712225258350372,
      "compression_ratio": 1.5895196199417114,
      "no_speech_prob": 0.09237781912088394
    },
    {
      "id": 117,
      "seek": 76212,
      "start": 2955.080002441406,
      "end": 2961.2399755859374,
      "text": " you can't guarantee that a human would either to be to be honest. I mean, obviously, you build",
      "tokens": [
        51480,
        291,
        393,
        380,
        10815,
        300,
        257,
        1952,
        576,
        2139,
        281,
        312,
        281,
        312,
        3245,
        13,
        286,
        914,
        11,
        2745,
        11,
        291,
        1322,
        51788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23712225258350372,
      "compression_ratio": 1.5895196199417114,
      "no_speech_prob": 0.09237781912088394
    },
    {
      "id": 118,
      "seek": 79060,
      "start": 2961.2399755859374,
      "end": 2966.7599951171874,
      "text": " things, you build up levels of trust with humans. And like what you were saying about different",
      "tokens": [
        50364,
        721,
        11,
        291,
        1322,
        493,
        4358,
        295,
        3361,
        365,
        6255,
        13,
        400,
        411,
        437,
        291,
        645,
        1566,
        466,
        819,
        50640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2262347936630249,
      "compression_ratio": 1.6905829906463623,
      "no_speech_prob": 0.3202809989452362
    },
    {
      "id": 119,
      "seek": 79060,
      "start": 2966.7599951171874,
      "end": 2972.7599951171874,
      "text": " models coming up, coming out, it's like, Oh, I've built up a level of trust with this model.",
      "tokens": [
        50640,
        5245,
        1348,
        493,
        11,
        1348,
        484,
        11,
        309,
        311,
        411,
        11,
        876,
        11,
        286,
        600,
        3094,
        493,
        257,
        1496,
        295,
        3361,
        365,
        341,
        2316,
        13,
        50940
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2262347936630249,
      "compression_ratio": 1.6905829906463623,
      "no_speech_prob": 0.3202809989452362
    },
    {
      "id": 120,
      "seek": 79060,
      "start": 2972.7599951171874,
      "end": 2977.9600073242186,
      "text": " And now there's a new one. And it's a bit like someone leaving your company who you really trust",
      "tokens": [
        50940,
        400,
        586,
        456,
        311,
        257,
        777,
        472,
        13,
        400,
        309,
        311,
        257,
        857,
        411,
        1580,
        5012,
        428,
        2237,
        567,
        291,
        534,
        3361,
        51200
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2262347936630249,
      "compression_ratio": 1.6905829906463623,
      "no_speech_prob": 0.3202809989452362
    },
    {
      "id": 121,
      "seek": 79060,
      "start": 2977.9600073242186,
      "end": 2985.16001953125,
      "text": " and someone new coming in, who kind of says, Yeah, here's my CV, all flashy. And you think,",
      "tokens": [
        51200,
        293,
        1580,
        777,
        1348,
        294,
        11,
        567,
        733,
        295,
        1619,
        11,
        865,
        11,
        510,
        311,
        452,
        22995,
        11,
        439,
        47873,
        13,
        400,
        291,
        519,
        11,
        51560
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2262347936630249,
      "compression_ratio": 1.6905829906463623,
      "no_speech_prob": 0.3202809989452362
    },
    {
      "id": 122,
      "seek": 81452,
      "start": 2985.319992675781,
      "end": 2991.080002441406,
      "text": " well, now I've got to build up this trust again, with you and work out how to work with you.",
      "tokens": [
        50372,
        731,
        11,
        586,
        286,
        600,
        658,
        281,
        1322,
        493,
        341,
        3361,
        797,
        11,
        365,
        291,
        293,
        589,
        484,
        577,
        281,
        589,
        365,
        291,
        13,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2707350254058838,
      "compression_ratio": 1.5087718963623047,
      "no_speech_prob": 0.16557751595973969
    },
    {
      "id": 123,
      "seek": 81452,
      "start": 2991.080002441406,
      "end": 2996.359970703125,
      "text": " So it's, it's quite interesting dynamic. I wonder whether Eberhard will fire",
      "tokens": [
        50660,
        407,
        309,
        311,
        11,
        309,
        311,
        1596,
        1880,
        8546,
        13,
        286,
        2441,
        1968,
        462,
        607,
        21491,
        486,
        2610,
        50924
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2707350254058838,
      "compression_ratio": 1.5087718963623047,
      "no_speech_prob": 0.16557751595973969
    },
    {
      "id": 124,
      "seek": 81452,
      "start": 2996.359970703125,
      "end": 3005.64,
      "text": " Claude Sonnet 3.7 and then use 4.0. I mean, it is a new model, it could make sense",
      "tokens": [
        50924,
        12947,
        2303,
        5185,
        7129,
        805,
        13,
        22,
        293,
        550,
        764,
        1017,
        13,
        15,
        13,
        286,
        914,
        11,
        309,
        307,
        257,
        777,
        2316,
        11,
        309,
        727,
        652,
        2020,
        51388
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2707350254058838,
      "compression_ratio": 1.5087718963623047,
      "no_speech_prob": 0.16557751595973969
    },
    {
      "id": 125,
      "seek": 81452,
      "start": 3005.64,
      "end": 3012.11998046875,
      "text": " is that it's more reliable, and you can build up more trust. Yeah. But like you were saying",
      "tokens": [
        51388,
        307,
        300,
        309,
        311,
        544,
        12924,
        11,
        293,
        291,
        393,
        1322,
        493,
        544,
        3361,
        13,
        865,
        13,
        583,
        411,
        291,
        645,
        1566,
        51712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2707350254058838,
      "compression_ratio": 1.5087718963623047,
      "no_speech_prob": 0.16557751595973969
    },
    {
      "id": 126,
      "seek": 84148,
      "start": 3012.11998046875,
      "end": 3017.64,
      "text": " with Simon Wardley, I've, I've heard him talk about those tests. But if you if you ask the",
      "tokens": [
        50364,
        365,
        13193,
        23794,
        3420,
        11,
        286,
        600,
        11,
        286,
        600,
        2198,
        796,
        751,
        466,
        729,
        6921,
        13,
        583,
        498,
        291,
        498,
        291,
        1029,
        264,
        50640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1991157829761505,
      "compression_ratio": 1.7034220695495605,
      "no_speech_prob": 0.5420902371406555
    },
    {
      "id": 127,
      "seek": 84148,
      "start": 3017.64,
      "end": 3021.319992675781,
      "text": " things at a very high level, which I think is what Simon did, where it's like, yeah,",
      "tokens": [
        50640,
        721,
        412,
        257,
        588,
        1090,
        1496,
        11,
        597,
        286,
        519,
        307,
        437,
        13193,
        630,
        11,
        689,
        309,
        311,
        411,
        11,
        1338,
        11,
        50824
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1991157829761505,
      "compression_ratio": 1.7034220695495605,
      "no_speech_prob": 0.5420902371406555
    },
    {
      "id": 128,
      "seek": 84148,
      "start": 3021.319992675781,
      "end": 3027.64,
      "text": " create tests for this. It's like, well, what's the LLM gonna do? It's gonna, it's gonna do",
      "tokens": [
        50824,
        1884,
        6921,
        337,
        341,
        13,
        467,
        311,
        411,
        11,
        731,
        11,
        437,
        311,
        264,
        441,
        43,
        44,
        799,
        360,
        30,
        467,
        311,
        799,
        11,
        309,
        311,
        799,
        360,
        51140
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1991157829761505,
      "compression_ratio": 1.7034220695495605,
      "no_speech_prob": 0.5420902371406555
    },
    {
      "id": 129,
      "seek": 84148,
      "start": 3027.64,
      "end": 3032.4399877929686,
      "text": " what like some teenager would do probably, as well, which is create a load of tests,",
      "tokens": [
        51140,
        437,
        411,
        512,
        21440,
        576,
        360,
        1391,
        11,
        382,
        731,
        11,
        597,
        307,
        1884,
        257,
        3677,
        295,
        6921,
        11,
        51380
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1991157829761505,
      "compression_ratio": 1.7034220695495605,
      "no_speech_prob": 0.5420902371406555
    },
    {
      "id": 130,
      "seek": 84148,
      "start": 3032.4399877929686,
      "end": 3038.359970703125,
      "text": " which basically just return true. Because that's the easiest thing to do. And you say to it, Oh,",
      "tokens": [
        51380,
        597,
        1936,
        445,
        2736,
        2074,
        13,
        1436,
        300,
        311,
        264,
        12889,
        551,
        281,
        360,
        13,
        400,
        291,
        584,
        281,
        309,
        11,
        876,
        11,
        51676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1991157829761505,
      "compression_ratio": 1.7034220695495605,
      "no_speech_prob": 0.5420902371406555
    },
    {
      "id": 131,
      "seek": 86772,
      "start": 3038.359970703125,
      "end": 3044.2800146484374,
      "text": " fix this bug. And, and what instead of doing the hard thing of fixing the bug, it will",
      "tokens": [
        50364,
        3191,
        341,
        7426,
        13,
        400,
        11,
        293,
        437,
        2602,
        295,
        884,
        264,
        1152,
        551,
        295,
        19442,
        264,
        7426,
        11,
        309,
        486,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2497151643037796,
      "compression_ratio": 1.6609442234039307,
      "no_speech_prob": 0.12873475253582
    },
    {
      "id": 132,
      "seek": 86772,
      "start": 3044.840012207031,
      "end": 3050.5200048828124,
      "text": " change the test so that it returns so that it passes. So it's just it's trying to",
      "tokens": [
        50688,
        1319,
        264,
        1500,
        370,
        300,
        309,
        11247,
        370,
        300,
        309,
        11335,
        13,
        407,
        309,
        311,
        445,
        309,
        311,
        1382,
        281,
        50972
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2497151643037796,
      "compression_ratio": 1.6609442234039307,
      "no_speech_prob": 0.12873475253582
    },
    {
      "id": 133,
      "seek": 86772,
      "start": 3051.2399755859374,
      "end": 3054.5200048828124,
      "text": " do what you want in the kind of the easiest way possible.",
      "tokens": [
        51008,
        360,
        437,
        291,
        528,
        294,
        264,
        733,
        295,
        264,
        12889,
        636,
        1944,
        13,
        51172
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2497151643037796,
      "compression_ratio": 1.6609442234039307,
      "no_speech_prob": 0.12873475253582
    },
    {
      "id": 134,
      "seek": 86772,
      "start": 3054.5200048828124,
      "end": 3058.920029296875,
      "text": " Yeah, I have to because you came up with with that, that trust thing.",
      "tokens": [
        51172,
        865,
        11,
        286,
        362,
        281,
        570,
        291,
        1361,
        493,
        365,
        365,
        300,
        11,
        300,
        3361,
        551,
        13,
        51392
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2497151643037796,
      "compression_ratio": 1.6609442234039307,
      "no_speech_prob": 0.12873475253582
    },
    {
      "id": 135,
      "seek": 86772,
      "start": 3061.2399755859374,
      "end": 3065.9600073242186,
      "text": " If I may, there are two things that I would like to point out. First of all, I, I have the",
      "tokens": [
        51508,
        759,
        286,
        815,
        11,
        456,
        366,
        732,
        721,
        300,
        286,
        576,
        411,
        281,
        935,
        484,
        13,
        2386,
        295,
        439,
        11,
        286,
        11,
        286,
        362,
        264,
        51744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2497151643037796,
      "compression_ratio": 1.6609442234039307,
      "no_speech_prob": 0.12873475253582
    },
    {
      "id": 136,
      "seek": 89532,
      "start": 3065.9600073242186,
      "end": 3072.1999975585936,
      "text": " impression, but maybe maybe your precious different, that there is too much confidence",
      "tokens": [
        50364,
        9995,
        11,
        457,
        1310,
        1310,
        428,
        12406,
        819,
        11,
        300,
        456,
        307,
        886,
        709,
        6687,
        50676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2270078808069229,
      "compression_ratio": 1.6635944843292236,
      "no_speech_prob": 0.019716205075383186
    },
    {
      "id": 137,
      "seek": 89532,
      "start": 3072.1999975585936,
      "end": 3080.4399877929686,
      "text": " on LLMs and LLMs actually implemented in a way that they that they try to gamble us to trust",
      "tokens": [
        50676,
        322,
        441,
        43,
        26386,
        293,
        441,
        43,
        26386,
        767,
        12270,
        294,
        257,
        636,
        300,
        436,
        300,
        436,
        853,
        281,
        44128,
        505,
        281,
        3361,
        51088
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2270078808069229,
      "compression_ratio": 1.6635944843292236,
      "no_speech_prob": 0.019716205075383186
    },
    {
      "id": 138,
      "seek": 89532,
      "start": 3080.4399877929686,
      "end": 3086.11998046875,
      "text": " them. So I think that's that's one problem. And the other problem is, I have to admit that that",
      "tokens": [
        51088,
        552,
        13,
        407,
        286,
        519,
        300,
        311,
        300,
        311,
        472,
        1154,
        13,
        400,
        264,
        661,
        1154,
        307,
        11,
        286,
        362,
        281,
        9796,
        300,
        300,
        51372
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2270078808069229,
      "compression_ratio": 1.6635944843292236,
      "no_speech_prob": 0.019716205075383186
    },
    {
      "id": 139,
      "seek": 89532,
      "start": 3086.11998046875,
      "end": 3091.64,
      "text": " I had to make my mind about like trying to figure out what exactly the problem is. So",
      "tokens": [
        51372,
        286,
        632,
        281,
        652,
        452,
        1575,
        466,
        411,
        1382,
        281,
        2573,
        484,
        437,
        2293,
        264,
        1154,
        307,
        13,
        407,
        51648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2270078808069229,
      "compression_ratio": 1.6635944843292236,
      "no_speech_prob": 0.019716205075383186
    },
    {
      "id": 140,
      "seek": 92100,
      "start": 3092.5200048828124,
      "end": 3100.0400244140624,
      "text": " the problem is that, in my opinion, an LLM is optimized just by the tests that they that are",
      "tokens": [
        50408,
        264,
        1154,
        307,
        300,
        11,
        294,
        452,
        4800,
        11,
        364,
        441,
        43,
        44,
        307,
        26941,
        445,
        538,
        264,
        6921,
        300,
        436,
        300,
        366,
        50784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3012448251247406,
      "compression_ratio": 1.521276593208313,
      "no_speech_prob": 0.002182471100240946
    },
    {
      "id": 141,
      "seek": 92100,
      "start": 3100.0400244140624,
      "end": 3107.400009765625,
      "text": " run, they are punished if they say, I don't know, and they never do that. So therefore, they come up",
      "tokens": [
        50784,
        1190,
        11,
        436,
        366,
        22365,
        498,
        436,
        584,
        11,
        286,
        500,
        380,
        458,
        11,
        293,
        436,
        1128,
        360,
        300,
        13,
        407,
        4412,
        11,
        436,
        808,
        493,
        51152
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3012448251247406,
      "compression_ratio": 1.521276593208313,
      "no_speech_prob": 0.002182471100240946
    },
    {
      "id": 142,
      "seek": 92100,
      "start": 3107.400009765625,
      "end": 3118.11998046875,
      "text": " with some answer. And humans, people that I would like to work with, I can't really think of",
      "tokens": [
        51152,
        365,
        512,
        1867,
        13,
        400,
        6255,
        11,
        561,
        300,
        286,
        576,
        411,
        281,
        589,
        365,
        11,
        286,
        393,
        380,
        534,
        519,
        295,
        51688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3012448251247406,
      "compression_ratio": 1.521276593208313,
      "no_speech_prob": 0.002182471100240946
    },
    {
      "id": 143,
      "seek": 94748,
      "start": 3118.920029296875,
      "end": 3125.559982910156,
      "text": " anything that is worse than a person who never says, I don't know, and wouldn't show up and say,",
      "tokens": [
        50404,
        1340,
        300,
        307,
        5324,
        813,
        257,
        954,
        567,
        1128,
        1619,
        11,
        286,
        500,
        380,
        458,
        11,
        293,
        2759,
        380,
        855,
        493,
        293,
        584,
        11,
        50736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2068452388048172,
      "compression_ratio": 1.7375565767288208,
      "no_speech_prob": 0.10227183997631073
    },
    {
      "id": 144,
      "seek": 94748,
      "start": 3125.559982910156,
      "end": 3133.400009765625,
      "text": " okay, you know, so you gave me that task. I don't know how to do it. Please help me. And so therefore,",
      "tokens": [
        50736,
        1392,
        11,
        291,
        458,
        11,
        370,
        291,
        2729,
        385,
        300,
        5633,
        13,
        286,
        500,
        380,
        458,
        577,
        281,
        360,
        309,
        13,
        2555,
        854,
        385,
        13,
        400,
        370,
        4412,
        11,
        51128
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2068452388048172,
      "compression_ratio": 1.7375565767288208,
      "no_speech_prob": 0.10227183997631073
    },
    {
      "id": 145,
      "seek": 94748,
      "start": 3133.400009765625,
      "end": 3140.5200048828124,
      "text": " I think it's it's a different because of that it's it's a different way of trust, or a different",
      "tokens": [
        51128,
        286,
        519,
        309,
        311,
        309,
        311,
        257,
        819,
        570,
        295,
        300,
        309,
        311,
        309,
        311,
        257,
        819,
        636,
        295,
        3361,
        11,
        420,
        257,
        819,
        51484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2068452388048172,
      "compression_ratio": 1.7375565767288208,
      "no_speech_prob": 0.10227183997631073
    },
    {
      "id": 146,
      "seek": 94748,
      "start": 3140.5200048828124,
      "end": 3145.2399755859374,
      "text": " thing if you have a human. And that is also why why I feel somewhat uncomfortable about",
      "tokens": [
        51484,
        551,
        498,
        291,
        362,
        257,
        1952,
        13,
        400,
        300,
        307,
        611,
        983,
        983,
        286,
        841,
        8344,
        10532,
        466,
        51720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2068452388048172,
      "compression_ratio": 1.7375565767288208,
      "no_speech_prob": 0.10227183997631073
    },
    {
      "id": 147,
      "seek": 97460,
      "start": 3145.879990234375,
      "end": 3151.799973144531,
      "text": " LLMs because they are optimized to sort of gain trust, but at the same time,",
      "tokens": [
        50396,
        441,
        43,
        26386,
        570,
        436,
        366,
        26941,
        281,
        1333,
        295,
        6052,
        3361,
        11,
        457,
        412,
        264,
        912,
        565,
        11,
        50692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19635669887065887,
      "compression_ratio": 1.6136363744735718,
      "no_speech_prob": 0.016379421576857567
    },
    {
      "id": 148,
      "seek": 97460,
      "start": 3151.799973144531,
      "end": 3158.6799780273436,
      "text": " they're optimized to, you know, to just give random answers. And with a human, I would be very",
      "tokens": [
        50692,
        436,
        434,
        26941,
        281,
        11,
        291,
        458,
        11,
        281,
        445,
        976,
        4974,
        6338,
        13,
        400,
        365,
        257,
        1952,
        11,
        286,
        576,
        312,
        588,
        51036
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19635669887065887,
      "compression_ratio": 1.6136363744735718,
      "no_speech_prob": 0.016379421576857567
    },
    {
      "id": 149,
      "seek": 97460,
      "start": 3158.6799780273436,
      "end": 3167.2399755859374,
      "text": " scared to have such a person. So and I have to admit that I would probably not hire such a person.",
      "tokens": [
        51036,
        5338,
        281,
        362,
        1270,
        257,
        954,
        13,
        407,
        293,
        286,
        362,
        281,
        9796,
        300,
        286,
        576,
        1391,
        406,
        11158,
        1270,
        257,
        954,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19635669887065887,
      "compression_ratio": 1.6136363744735718,
      "no_speech_prob": 0.016379421576857567
    },
    {
      "id": 150,
      "seek": 97460,
      "start": 3168.0400244140624,
      "end": 3172.600021972656,
      "text": " But you've got there's a lot of companies out there still that don't have these safe",
      "tokens": [
        51504,
        583,
        291,
        600,
        658,
        456,
        311,
        257,
        688,
        295,
        3431,
        484,
        456,
        920,
        300,
        500,
        380,
        362,
        613,
        3273,
        51732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19635669887065887,
      "compression_ratio": 1.6136363744735718,
      "no_speech_prob": 0.016379421576857567
    },
    {
      "id": 151,
      "seek": 100196,
      "start": 3172.600021972656,
      "end": 3177.879990234375,
      "text": " working environments where people feel that they can actually admit that. But it's interesting to",
      "tokens": [
        50364,
        1364,
        12388,
        689,
        561,
        841,
        300,
        436,
        393,
        767,
        9796,
        300,
        13,
        583,
        309,
        311,
        1880,
        281,
        50628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2302827388048172,
      "compression_ratio": 1.6608695983886719,
      "no_speech_prob": 0.04842405766248703
    },
    {
      "id": 152,
      "seek": 100196,
      "start": 3177.879990234375,
      "end": 3184.1999975585936,
      "text": " think that like people put all these trusts in these kind of personifications that have been",
      "tokens": [
        50628,
        519,
        300,
        411,
        561,
        829,
        439,
        613,
        45358,
        294,
        613,
        733,
        295,
        954,
        7833,
        300,
        362,
        668,
        50944
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2302827388048172,
      "compression_ratio": 1.6608695983886719,
      "no_speech_prob": 0.04842405766248703
    },
    {
      "id": 153,
      "seek": 100196,
      "start": 3184.1999975585936,
      "end": 3191.16001953125,
      "text": " kind of created, like they given names like Claude. But the thing is, like the very underlying",
      "tokens": [
        50944,
        733,
        295,
        2942,
        11,
        411,
        436,
        2212,
        5288,
        411,
        12947,
        2303,
        13,
        583,
        264,
        551,
        307,
        11,
        411,
        264,
        588,
        14217,
        51292
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2302827388048172,
      "compression_ratio": 1.6608695983886719,
      "no_speech_prob": 0.04842405766248703
    },
    {
      "id": 154,
      "seek": 100196,
      "start": 3191.799973144531,
      "end": 3200.5999609375,
      "text": " large language model has basically been trained to play a game of guessing the next word. And so",
      "tokens": [
        51324,
        2416,
        2856,
        2316,
        575,
        1936,
        668,
        8895,
        281,
        862,
        257,
        1216,
        295,
        17939,
        264,
        958,
        1349,
        13,
        400,
        370,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2302827388048172,
      "compression_ratio": 1.6608695983886719,
      "no_speech_prob": 0.04842405766248703
    },
    {
      "id": 155,
      "seek": 102996,
      "start": 3200.5999609375,
      "end": 3208.839951171875,
      "text": " it does that based on what it's been trained on. And so all it's doing is playing, playing this",
      "tokens": [
        50364,
        309,
        775,
        300,
        2361,
        322,
        437,
        309,
        311,
        668,
        8895,
        322,
        13,
        400,
        370,
        439,
        309,
        311,
        884,
        307,
        2433,
        11,
        2433,
        341,
        50776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19195879995822906,
      "compression_ratio": 1.601123571395874,
      "no_speech_prob": 0.05554846674203873
    },
    {
      "id": 156,
      "seek": 102996,
      "start": 3208.839951171875,
      "end": 3214.11998046875,
      "text": " game. And a lot of people just don't really kind of understand that all the LLM is trying to do",
      "tokens": [
        50776,
        1216,
        13,
        400,
        257,
        688,
        295,
        561,
        445,
        500,
        380,
        534,
        733,
        295,
        1223,
        300,
        439,
        264,
        441,
        43,
        44,
        307,
        1382,
        281,
        360,
        51040
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19195879995822906,
      "compression_ratio": 1.601123571395874,
      "no_speech_prob": 0.05554846674203873
    },
    {
      "id": 157,
      "seek": 102996,
      "start": 3214.6800390625,
      "end": 3222.0400244140624,
      "text": " is guess the next thing. And basically be told, yes, well done. You've done that. And so it's",
      "tokens": [
        51068,
        307,
        2041,
        264,
        958,
        551,
        13,
        400,
        1936,
        312,
        1907,
        11,
        2086,
        11,
        731,
        1096,
        13,
        509,
        600,
        1096,
        300,
        13,
        400,
        370,
        309,
        311,
        51436
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19195879995822906,
      "compression_ratio": 1.601123571395874,
      "no_speech_prob": 0.05554846674203873
    },
    {
      "id": 158,
      "seek": 105140,
      "start": 3222.0400244140624,
      "end": 3230.359970703125,
      "text": " not going to say, I don't know, because it's basically trained to, to do that. And so that's",
      "tokens": [
        50364,
        406,
        516,
        281,
        584,
        11,
        286,
        500,
        380,
        458,
        11,
        570,
        309,
        311,
        1936,
        8895,
        281,
        11,
        281,
        360,
        300,
        13,
        400,
        370,
        300,
        311,
        50780
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22878704965114594,
      "compression_ratio": 1.8037383556365967,
      "no_speech_prob": 0.3809731900691986
    },
    {
      "id": 159,
      "seek": 105140,
      "start": 3230.359970703125,
      "end": 3236.5200048828124,
      "text": " all all it's doing under the hood, we've got an agent or something that is communicating with that",
      "tokens": [
        50780,
        439,
        439,
        309,
        311,
        884,
        833,
        264,
        13376,
        11,
        321,
        600,
        658,
        364,
        9461,
        420,
        746,
        300,
        307,
        17559,
        365,
        300,
        51088
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22878704965114594,
      "compression_ratio": 1.8037383556365967,
      "no_speech_prob": 0.3809731900691986
    },
    {
      "id": 160,
      "seek": 105140,
      "start": 3236.5200048828124,
      "end": 3241.879990234375,
      "text": " LLM. And all that's doing is going, right, okay, now here, now the next word, now give me the next",
      "tokens": [
        51088,
        441,
        43,
        44,
        13,
        400,
        439,
        300,
        311,
        884,
        307,
        516,
        11,
        558,
        11,
        1392,
        11,
        586,
        510,
        11,
        586,
        264,
        958,
        1349,
        11,
        586,
        976,
        385,
        264,
        958,
        51356
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22878704965114594,
      "compression_ratio": 1.8037383556365967,
      "no_speech_prob": 0.3809731900691986
    },
    {
      "id": 161,
      "seek": 105140,
      "start": 3241.879990234375,
      "end": 3246.7599951171874,
      "text": " word, now give me the next bit. And it does that over and over again, and then passes that back",
      "tokens": [
        51356,
        1349,
        11,
        586,
        976,
        385,
        264,
        958,
        857,
        13,
        400,
        309,
        775,
        300,
        670,
        293,
        670,
        797,
        11,
        293,
        550,
        11335,
        300,
        646,
        51600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22878704965114594,
      "compression_ratio": 1.8037383556365967,
      "no_speech_prob": 0.3809731900691986
    },
    {
      "id": 162,
      "seek": 107612,
      "start": 3246.7599951171874,
      "end": 3253.7199560546874,
      "text": " to the user. And I think if people understood more what was under the hood, then they wouldn't",
      "tokens": [
        50364,
        281,
        264,
        4195,
        13,
        400,
        286,
        519,
        498,
        561,
        7320,
        544,
        437,
        390,
        833,
        264,
        13376,
        11,
        550,
        436,
        2759,
        380,
        50712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23272104561328888,
      "compression_ratio": 1.4924622774124146,
      "no_speech_prob": 0.1309317648410797
    },
    {
      "id": 163,
      "seek": 107612,
      "start": 3253.7199560546874,
      "end": 3259.7199560546874,
      "text": " have quite so much trust in it. Anything we still need to talk about?",
      "tokens": [
        50712,
        362,
        1596,
        370,
        709,
        3361,
        294,
        309,
        13,
        11998,
        321,
        920,
        643,
        281,
        751,
        466,
        30,
        51012
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23272104561328888,
      "compression_ratio": 1.4924622774124146,
      "no_speech_prob": 0.1309317648410797
    },
    {
      "id": 164,
      "seek": 107612,
      "start": 3259.7199560546874,
      "end": 3265.07994140625,
      "text": " Anything that we forgot to mention? We've covered a lot.",
      "tokens": [
        51012,
        11998,
        300,
        321,
        5298,
        281,
        2152,
        30,
        492,
        600,
        5343,
        257,
        688,
        13,
        51280
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23272104561328888,
      "compression_ratio": 1.4924622774124146,
      "no_speech_prob": 0.1309317648410797
    },
    {
      "id": 165,
      "seek": 107612,
      "start": 3265.07994140625,
      "end": 3269.5600439453124,
      "text": " Yeah, that's true. That's also what I figured. So thanks a lot for joining.",
      "tokens": [
        51280,
        865,
        11,
        300,
        311,
        2074,
        13,
        663,
        311,
        611,
        437,
        286,
        8932,
        13,
        407,
        3231,
        257,
        688,
        337,
        5549,
        13,
        51504
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23272104561328888,
      "compression_ratio": 1.4924622774124146,
      "no_speech_prob": 0.1309317648410797
    },
    {
      "id": 166,
      "seek": 109892,
      "start": 3270.440048828125,
      "end": 3280.9999853515624,
      "text": " So this evening, we are going to have a live stream of the Fishbowl and where we are going",
      "tokens": [
        50408,
        407,
        341,
        5634,
        11,
        321,
        366,
        516,
        281,
        362,
        257,
        1621,
        4309,
        295,
        264,
        18096,
        8202,
        75,
        293,
        689,
        321,
        366,
        516,
        50936
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25175511837005615,
      "compression_ratio": 1.3609023094177246,
      "no_speech_prob": 0.1420883983373642
    },
    {
      "id": 167,
      "seek": 109892,
      "start": 3280.9999853515624,
      "end": 3288.440048828125,
      "text": " to discuss the impact of AI on software architecture. So yeah, I'm looking forward to that",
      "tokens": [
        50936,
        281,
        2248,
        264,
        2712,
        295,
        7318,
        322,
        4722,
        9482,
        13,
        407,
        1338,
        11,
        286,
        478,
        1237,
        2128,
        281,
        300,
        51308
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25175511837005615,
      "compression_ratio": 1.3609023094177246,
      "no_speech_prob": 0.1420883983373642
    },
    {
      "id": 168,
      "seek": 111780,
      "start": 3288.440048828125,
      "end": 3299.3200537109374,
      "text": " one. So please, yeah, join us there. It's at a quarter to 7pm. So a CET. So to see you there,",
      "tokens": [
        50364,
        472,
        13,
        407,
        1767,
        11,
        1338,
        11,
        3917,
        505,
        456,
        13,
        467,
        311,
        412,
        257,
        6555,
        281,
        1614,
        14395,
        13,
        407,
        257,
        383,
        4850,
        13,
        407,
        281,
        536,
        291,
        456,
        11,
        50908
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29838451743125916,
      "compression_ratio": 1.5549132823944092,
      "no_speech_prob": 0.25044381618499756
    },
    {
      "id": 169,
      "seek": 111780,
      "start": 3299.3200537109374,
      "end": 3304.7599951171874,
      "text": " and hope you enjoy the rest of the conference. And thanks again to Software Architecture",
      "tokens": [
        50908,
        293,
        1454,
        291,
        2103,
        264,
        1472,
        295,
        264,
        7586,
        13,
        400,
        3231,
        797,
        281,
        27428,
        43049,
        51180
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29838451743125916,
      "compression_ratio": 1.5549132823944092,
      "no_speech_prob": 0.25044381618499756
    },
    {
      "id": 170,
      "seek": 111780,
      "start": 3304.7599951171874,
      "end": 3308.20005859375,
      "text": " Gathering for hosting us. And thanks for watching and listening.",
      "tokens": [
        51180,
        39841,
        278,
        337,
        16058,
        505,
        13,
        400,
        3231,
        337,
        1976,
        293,
        4764,
        13,
        51352
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29838451743125916,
      "compression_ratio": 1.5549132823944092,
      "no_speech_prob": 0.25044381618499756
    },
    {
      "id": 171,
      "seek": 111780,
      "start": 3309.4799658203124,
      "end": 3310.359970703125,
      "text": " Thank you.",
      "tokens": [
        51416,
        1044,
        291,
        13,
        51460
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29838451743125916,
      "compression_ratio": 1.5549132823944092,
      "no_speech_prob": 0.25044381618499756
    },
    {
      "id": 172,
      "seek": 111780,
      "start": 3310.359970703125,
      "end": 3311.16001953125,
      "text": " Thank you.",
      "tokens": [
        51460,
        1044,
        291,
        13,
        51500
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29838451743125916,
      "compression_ratio": 1.5549132823944092,
      "no_speech_prob": 0.25044381618499756
    }
  ],
  "language": "english"
}