# Das Eichhörnchen im Kopf: KI-Architektur zwischen Hype und Realität

## Wichtige Keytakeaways

- Große KI-Modelle haben einen Reifegrad erreicht; weiteres Skalieren bringt nicht zwangsläufig bessere Ergebnisse
- Spezialisierte, kleinere Modelle sind oft sinnvoller als große General-Purpose Modelle
- KI-Systeme sind probabilistisch, nicht deterministisch - das muss bei der Implementierung berücksichtigt werden
- Kontextmanagement ist entscheidend und geht über einfache Vektordatenbanken hinaus
- Die Kombination aus LLMs und Reinforcement Learning ermöglicht "intelligentes" Verhalten
- KI-Modelle sind durch menschliche Trainingsdaten inherent "menschlich" geprägt
- Es gibt keine grundsätzlichen Limits der Technologie, aber nicht alle Anwendungsfälle sind sinnvoll

## Behandelte Kernfragen

- Wie entwickeln sich große Sprachmodelle weiter?
- Was bedeutet Kontext für LLMs und wie kann man ihn effektiv managen?
- Wie können Modelle spezialisiert und verkleinert werden?
- Woher kommt das "intelligente" Verhalten von KI-Systemen?
- Wie unterscheidet sich maschinelle von menschlicher Intelligenz?
- Welche Rolle spielen Reinforcement Learning und Motivation?

## Glossar wichtiger Begriffe

- LLM (Large Language Model): Großes Sprachmodell basierend auf Transformern
- Quantisierung: Methode zur Verkleinerung von Modellen durch Reduzierung der numerischen Präzision
- Model Distillation: Technik zum Training eines kleineren Modells durch ein größeres (Student-Teacher Modell)
- Reinforcement Learning: Maschinelles Lernen durch Belohnungssignale
- Dark Patterns: Algorithmen zur Manipulation von Nutzerverhalten
- Hybrid-Modelle: KI-Modelle die zwischen klassischem und Reasoning-Modus wechseln können
- Kontextfenster: Menge an Text/Tokens die ein Modell gleichzeitig verarbeiten kann