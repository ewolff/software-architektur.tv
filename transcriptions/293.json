{
  "text": "Welcome to a new short episode of Software-Architektur im Stream. We are here live from the ISAQB Software Architecture Gathering in Berlin. Here with me is Claudine Allen from Jamaica. Claudine, will you introduce yourself a little bit? Hi, my name is Claudine Allen. I'm a lecturer at the University of the West Indies, MONO in Jamaica. I'm also an ISAQB board member. I work primarily with the university working group and I'm also a CPSA foundational level trainer in Jamaica. The talk you've given last day was about how to use AI with software architecture to create a software architecture. Can you tell a little bit about your approach, how you use AI? The main thing I've been trying is looking at, for example, the way that we approach software architecture. It's sort of methodological, so we do have different steps that we use usually and different aspects that are important. So first of all, clarification of requirements, understanding your constraints and so on. And what I try to do is incorporate LLMs in a way that they help me to do background research faster when it comes down to, for example, standard documentation. It helps me to answer questions in terms of information that I need faster. Furthermore, I find it very useful as long as you have the appropriate contextual information in terms of rewriting and clarifying your requirements. For example, having your quality scenarios well written and very clear. So I find it useful in that way. It's also useful, again, as you go about architectural design, if you're using an incremental approach and doing small parts at a time, providing the necessary context as you try to solve small problems. So, for example, once you have decided on, OK, these are the primary blocks that you need for your static structure. And you can use the LLM to help to define those structures. For each structure, you can get information. You can get help, for example, with the logics of the structure or what the interface might look like, things like that. So I would not try to use and I wouldn't recommend using an LLM like ChatGPT or Software Architect 4.0 to solve the overall architectural problem at once. But a stepwise approach that's incremental, I find it to be quite useful, especially if you're looking at the LLM as kind of an assistant, you know, asking it questions. Once you get responses, trying to clarify, doing your research, yes. So you use it more for, I mean, there are many people out there who try to use AI to create the whole architecture. But as I do understand, you advise people to use it for brainstorming, for research, to get deeper inside inspiration. And so this works when you work on a topic which is well known to the LLM, right? Yes, yes. Actually, that's very important. The LLM is, of course, depending on documents that it has access to on the Internet. So when the topic is not something, so there may be a green field of projects where you might not have that type of information. Sorry, novel types of projects in novel domains where the information might not be there. So the type of help that you can get will be different. But information, for example, on methodologies is available. So methodologies like R42 or 4 plus 1 views, that information is available. So it can help you in a methodological way. So it can help you with identifying a template that's useful for, let's say, an interface definition. So you work a lot with students, and so you not only use AI for research in the business domain, but also for how do I write an ADR and things like that? That's correct, yes. That's a great idea. The topic you presented was, so the business domain was about sign language. Yes. I think it's quite interesting. Yes. So can you elaborate a little bit on this, how AI helps with this domain? I mean, it's a special domain which is not really known to most of us. Right. And I wouldn't know how I should approach this. So AI also helps there? So in the experience that I had, there were things that I did not know in terms of how do you translate natural language into something like sign language. Sign language is not necessarily a one-to-one. I know some sign language. I used to do sign language. So you don't have necessarily a one-to-one relationship between words that people say and a specific sign. Sometimes there's a sign for a whole expression. So I kind of wondered how would this work. And the research that was available online, I was able to access that. Obviously, you can go ahead and read the research papers. But when I used the LLM, it pointed me to the right papers, and it answered some of the questions that I had very quickly. So for example, the idea of something called glossing, which I'd never heard before. What's it? So it's basically, it's kind of like an activity between getting the natural language, the audio, into text and then going from text to sign language. So glossing is like taking the text and translating it into a version of the text or a nuanced representation that matches more with sign language. So it's in between the two things. Okay. That, for me, is a quite interesting part because when you talk about sign language and translation of audio, I first thought, hey, if you have the text, why need the sign language? But I had to learn that this is a whole different thing for people who need the sign language. And not only for sign language, there are, even in natural language, there are languages that don't have necessarily the same kind of structure as, like the structure of languages are different. So there are nuances between two languages. And what I understand is that that glossing helps, that glossing process helps to, I guess, smooth out the translation from one language to another. Okay. So in this case, with this special architecture, with a domain which is not well known to everybody, the AI helps with brainstorming about the architecture, how to build it, but also about the business domain. Exactly. What glossing is and how to build a pipeline for it. Yes. And especially the issue of a part of translation is not just the words. Translation also includes the way that people, the gesticulation and so on. So one of the things that I realized is that the avatar, there are two different ways that you can process this, is you can take the gestures and expressions from the human, because the purpose of the translation is to take the human, the beta, and translate what they're saying into sign language. So you can either capture the expressions, the facial expressions, the hand movements, the body movements, and so on. You can capture that and replay it in the form of the avatar, or you can ensure that the translation from the avatar, depending on the kind of resources you have in terms of time and so on for development, if you can keep the timing of the avatar close enough to the visuals of the actual speaker, then you wouldn't lose the gestures because then the person who's viewing would see the sign language along with the person's gestures. So there are two approaches that could be used depending on the kind of resources and time available. So I remember there was a quality criteria that within two seconds the translation should be there. From my understanding, it doesn't translate word by word, so it needs to know the full sentence, and after it got the full sentence, two seconds. So the whole process, what I wanted to accomplish, or what the quality requirement is describing, is from the time that the phrase that's being translated is said to the time that the avatar completes the translation, then we don't want more than two seconds to elapse because we want the two things to be. So the approach that I am taking is to keep the actual speaker beside the avatar so that the sign language can be interpreted along with the gestures of the original speaker. Okay, and you also said that the AI also helps with those quality requirements. Yes To to find them or to formulate them both both so it might not be able to find the quality requirement from scratch But the research that is necessary to so for every quality requirement Basically, it's work. It exists within a domain So if I'm gonna talk about performance, I need to understand how do people measure the performance in in relation to You know any particular thing if I'm gonna talk about availability. I need to have the correct vocabulary I need to know the possible metrics if I'm gonna talk about usability There are a bunch of different ways that we can measure usability and describe it. So for Novice architect and ID with students and I'm mainly in academia. So there's a way in which There's a way in which You you know not being in the industry all the time there are so many things you want to learn so many things you want to try and experiment with and what I have found is that being able to describe The response and a response measure for a quality requirement the LNM. Yeah, I can help you with that So you may be able to explain what it is that you want or what is important in this quality in English But not necessarily with a precision necessary for architecture work and LLM can help with that Okay now I remember that the architecture was more or less a pipeline a processing pipeline and now when it comes to to all those single steps to turn audio into Transcription, so I guess you use some Not necessarily a large language model, but machine learning I guess so so Not really Yes, there's some machine learning that will be necessary because you do have to you're collecting a lot of data about various signs And so yes, there's there be some machine learning involved. So I guess there are already libraries away Also for the for the glossing All those things there are libraries and the good thing was that LLM was able to recommend various technologies for all the stages Because it has a knowledge from it access to all this documentation so Did you mainly use the knowledge from the training data or did you use a web research? Which is mainly research because we haven't actually trained a model or anything like that yet. It's really just a matter of The starting point of developing this architecture Okay, that's great you mentioned arc 42 and I was happy to hear that arc 42 is used in Jamaica Jamaica Jamaica we talked about the pronunciation pronunciation so that's Jamaica, yes Can you elaborate a little bit on that? Because I think it's quite fascinating to see how Arc 42 is used. Okay in the world so arc 42 is new in a way to Jamaica as is the SAQB and the training and so on over the last three years. We've been training students Using the CPSC curriculum now Maybe about five six years ago No, no, no, no, not so much about four years ago. We started software architecture as a course in my university a lot of what we did and the way the curriculum was developed was based on based on Textbooks by people like Len Bass and Rick Caseman and so on and we used a lot of the tools and Methodologies from the Software Engineering Institute, which I found just amazing In that process I started being involved with Excel going to Excel conferences and so on and that's how I found out about the SAQB Once I found out about the SAQB I did training with the SAQB I did the CPSC and what I found was so one of the things I learned was well The experience with SEI was phenomenal But I did realize that a lot of the work that SEI did was for really heavy mission critical systems Because you know work with the Department of Defense and government and so on so a lot of times the methodologies were not necessarily suitable for the types of the types of industries that the students went into But the principles were always relevant and so we'd have to tweak things to match these smaller projects When I got introduced to ARC 42 and I saw the methodology and the different views the four simple views and the way that ARC 42 documentation was set up I decided to start incorporating that into our course and at the same time the students were being exposed to the CPSC of training as well But once I started doing that the difficulty level for documentation went down significantly for the students ARC 42 presents Exactly what they needed for the types of business projects that they were more likely to be solving it's easier for them to understand the Learning curve was a lot less steep and I didn't have to spend quite as much time clarifying what different sections meant So that was a good transition for us That's great to hear. So my experience is that LLM the Gen AI already knows about ARC 42 because it's Open-source it exists for now 20 years. It's in the training data In what format do you Document the architecture. Do you use a DOCSIS code approach? Markdown or do you use Word or wiki? Right. No, we just use Word or I might use a latex template for it But for right now the students are using Microsoft Word Okay, and as I understood the students writes a documentation with the help of AI not AI Right. Absolutely. So not only in terms of writing a documentation, but for the last two years I have been encouraging the students to use AI and use LLMs so when the explosion of chat GPT and all these things came around for Universities for schools in general for education. It was a little bit jolting because no you're wondering Are my students really learning is the work that they're giving me their work. So about two years ago I realized that this was not going to disappear. So I had to find a way to incorporate this into my teaching So the fact is that when they're going to the industry They will have all these tools available to them so I needed them I've always when I'm teaching courses I want as much as possible for the students to function the way that they're going to function in the industry. So I Wanted them to start using the LLMs so I'd create Activities on on the virtual learning environment that would require them to use the LLM So maybe I remember one of the first things I did was I gave them a small projects. This is not for grades This is just I just wanted to see what would happen. So I gave them a small project it was on the LLM and it's a You know, they just share what their experience was. And so it's like a discussion forum. So they had to identify quality remote data the four top quality requirements and You know write them in such a way that they are measurable so they have a response and response measure and the six parts and Then they did that and then the other part of exercise was to ask the LLM to do it and compare the results So that was the first step to bringing LLMs into the experience that the students had in the classroom And so little by little all the different aspects of the course I encouraged them to utilize the LLM and to be honest about their use Document what they did not like try to pretend that oh I did this on my own by you But you know in secret I use the LLM and I found that with that transparency I learned a lot and the students learned we learn more by Working with LLMs and being transparent about it. I Think it's a good approach. I remember my own studies where I was not allowed to quote Wikipedia and This changed and now it's changing again that people use AI and it really makes sense Another question. What do you use for the diagrams in the architecture? Okay. So right now I Like star UML. There's a tool called star UML used to be free. It's not free anymore, but it's really simple So we use a lot of you and well a lot of our software engineering courses We incorporate UML a lot. And so we do use Star UML for that. However students use a number of different tools students use Lucid draw they use a lot of drawing tools Try to discourage them from using drawing tools because the semantics are not there. You don't get as much Feedback from the system. So right now in terms of Accessibility and affordability star UML is what we use for a lot of our courses Of course, there are diagrams for example when students want to describe Cloud-based deployments or they want to talk about containerization UML is not really quite as amenable to that situation and so I encourage them for software architecture when when we do Object-oriented design course will focus on UML. But for this course, I Encourage them to use whatever tools they want to use So any tools and then recently I realized that Well, I've always experimented with diagrams and LLMs. So I'll create diagrams then upload them to The LLM and see whether or not it really understands. So the first thing I started with was Use case diagrams and to see if it could write user stories for me So you upload is a diagram image to the LLM Yes, and then see if and it did understand what the use case diagram was about and in one case it actually Suggested a missing use case and then it tried to modify the diagram, but this was quite some time ago No, I have found that using know a phone that the software architects app application It's even more dynamic than that So you can describe your use cases or Describe a sequence diagram or describe a component diagram and it generates code mermaid code And then you can upload that to my copy it into mermaid and in what you create a diagram for you So these are things that I'm just experimenting with students experiment with But it gives you a little glimpse into the future telling you that okay the abstraction level for Software development will be Will it will be higher again, so I compare it to the transition from machine language to To Assembly language to high-level programming languages to frameworks and so on developers can focus on More of the business of what they want to produce versus the details of the technologies sometimes So when you mentioned mermaid, I find it quite interesting that we as humans like the diagrams and the machine can read the code of the mermaid diagram and doesn't have to waste the token for the image and As I remember you mentioned that there is an AI tool for mermaid available Yeah, I was a little bit surprised. I Didn't know about it What it is capable of how does it support architect so when so let's say that you got the code the mermaid code from the LLM, so you're discussing exchanging with the LLM and You have a block diagram it will sometimes give it a description for the block diagram. But instead of giving you a JPEG or a PNG, it will give you the code, or you can ask it for the mermaid code. Sometimes there are errors in there, or you may even, maybe you're not using an LLM, but you are writing the code for a diagram, which is not hard to do. So, for example, with a sequence diagram, you're identifying the participants, and you're just writing some simple code to describe the messages, exchanges, and the order that they're supposed to be in. If there are errors in there, Mermaid itself as an AI tool that detects what you're trying to do and corrects the code for you. So, I found that to be quite useful. Yeah, it sounds like to be quite useful. So, I think, I wonder that other tools don't have this component, this AI component. But otherwise, I see a problem that when your students now work on open source tools, open source software, and later working in a company and can't use those tools anymore, but maybe then they are more advanced. And I guess with Mermaid, is this an open source tool, which I can... It's not open source. Okay, so it's not open source. But I think what is interesting is that these experiences aren't just about, I can do this faster. I think these experiences are quite useful for learning. I think, well, for me, and I think for my students, there are things that would have taken longer to learn or longer to realize that, oh, this is the way you do this thing. But if you're an authentic person and you're using the tools in a responsible way, you're not only getting the answer and saying, hey, this is the answer, but you're learning through the exchange. Through the answer, you get the answer and you're studying it. You're trying to understand. Why is this thing here? Why is that there? Why does this work? Why doesn't that work? It's a good way of learning. I liken it to, if I were doing something, if I were doing architecture work and you're also an architect and I'm asking you for help and you're giving me ideas, I should question your ideas. I should experiment with your ideas and I'm learning from your ideas. Maybe you're learning from teaching me and that type of back and forth is not, it's not just about the answer. It's about the process and about learning as well. So you're a lecturer and you teach people and now you tell me that AI is perfect for learning because it helps. Okay, so how do you see that your role changes? Right, so I think not only with AI, but I think maybe as many as 15 years ago, I realized that my job as a teacher was not just to impart knowledge because of the internet, because of Google, because knowledge is available. My interest is not so much in collecting knowledge and spitting it back out at students. My interest is in what process can we use to develop the competencies that we want to develop and this is not only beneficial for the students, it's beneficial for me because, I mean, as a lecturer you're not like a repositor of all the knowledge and understanding and skills in the world. So you're also growing. So I think when you create a classroom environment that allows the students to learn through whatever tools they need to use, I think it's better for them and I think it's better for you and I think it's better for them when they get into the working world because the industry is not interested in how much you know, they're interested in what skills you have and how you will function and grow in an organization. Okay. What about hallucinations and cheating? I mean, when I see my son doing his maths homework, he has several choices to give the image of the task to the AI and say, hey, solve this problem for me or to ask how to solve it. So isn't this a problem? I know with the architecture, I realized that this is a task where you can't really cheat, where the AI will not solve your problem, but help you in brainstorming. Is this a solution that you give the right task to the students? That's absolutely, that's an issue. That's something that I have to have grappled with, like how do I write an assignment in such a way that using the tool does not take away from their learning experience. So I think I'm trying to focus more on the learning experience rather than did you get it right? Did you get it wrong? I'm really interested in are you learning? And if that learning can take place with some tools, I'm okay with it. But at the end of the day, I think there's also so one of the things that I do also is have students when they create anything, they have to explain it. So that's one of the ways of managing that question of have you learnt? So they have to present, they have to explain, they need to be able to answer questions and the LLM is not there with them while they're doing it. Okay, and what about hallucinations? Is this a problem? Do you notice that AI tells your students wrong things and they pick it up or is it, do they notice it when it happens? Yes, so I think I think they notice it when it happens because they've explained some of the things that they have seen. The thing is that at the end of the day, they're responsible for the final work and I think an irresponsible student will spit out whatever the LLM gives them. A responsible student knows that the answer that I give has to be my answer and I need to be responsible for it. So they're aware that LLMs can be quite inconsistent and sometimes produce errors in the answers that they give. When it comes down to things like methods or just plain documented facts, like for example, the structure of Arc 42 for instance or the explanation for each of the parts of Arc 42, they're not usually errors with that. The errors really come in with your specific context. And so it's their responsibility. Okay, that's a good solution. Claudine, thanks for sharing your experience. It was really nice to get to know what you're working on and how you use AI. Thank you. Thank you very much for having me. It was fun.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 5.0,
      "text": " Welcome to a new short episode of Software-Architektur im Stream.",
      "tokens": [
        50364,
        4027,
        281,
        257,
        777,
        2099,
        3500,
        295,
        27428,
        12,
        10683,
        339,
        642,
        2320,
        374,
        566,
        24904,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24752208590507507,
      "compression_ratio": 1.5546218156814575,
      "no_speech_prob": 0.2795395851135254
    },
    {
      "id": 1,
      "seek": 0,
      "start": 5.0,
      "end": 11.0,
      "text": " We are here live from the ISAQB Software Architecture Gathering in Berlin.",
      "tokens": [
        50614,
        492,
        366,
        510,
        1621,
        490,
        264,
        6205,
        32,
        48,
        33,
        27428,
        43049,
        39841,
        278,
        294,
        13848,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24752208590507507,
      "compression_ratio": 1.5546218156814575,
      "no_speech_prob": 0.2795395851135254
    },
    {
      "id": 2,
      "seek": 0,
      "start": 11.0,
      "end": 15.0,
      "text": " Here with me is Claudine Allen from Jamaica.",
      "tokens": [
        50914,
        1692,
        365,
        385,
        307,
        24858,
        533,
        17160,
        490,
        42927,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24752208590507507,
      "compression_ratio": 1.5546218156814575,
      "no_speech_prob": 0.2795395851135254
    },
    {
      "id": 3,
      "seek": 0,
      "start": 15.0,
      "end": 18.0,
      "text": " Claudine, will you introduce yourself a little bit?",
      "tokens": [
        51114,
        24858,
        533,
        11,
        486,
        291,
        5366,
        1803,
        257,
        707,
        857,
        30,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24752208590507507,
      "compression_ratio": 1.5546218156814575,
      "no_speech_prob": 0.2795395851135254
    },
    {
      "id": 4,
      "seek": 0,
      "start": 18.0,
      "end": 24.0,
      "text": " Hi, my name is Claudine Allen. I'm a lecturer at the University of the West Indies, MONO in Jamaica.",
      "tokens": [
        51264,
        2421,
        11,
        452,
        1315,
        307,
        24858,
        533,
        17160,
        13,
        286,
        478,
        257,
        49881,
        412,
        264,
        3535,
        295,
        264,
        4055,
        2333,
        530,
        11,
        27398,
        46,
        294,
        42927,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24752208590507507,
      "compression_ratio": 1.5546218156814575,
      "no_speech_prob": 0.2795395851135254
    },
    {
      "id": 5,
      "seek": 0,
      "start": 24.0,
      "end": 28.0,
      "text": " I'm also an ISAQB board member.",
      "tokens": [
        51564,
        286,
        478,
        611,
        364,
        6205,
        32,
        48,
        33,
        3150,
        4006,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24752208590507507,
      "compression_ratio": 1.5546218156814575,
      "no_speech_prob": 0.2795395851135254
    },
    {
      "id": 6,
      "seek": 2800,
      "start": 28.0,
      "end": 42.0,
      "text": " I work primarily with the university working group and I'm also a CPSA foundational level trainer in Jamaica.",
      "tokens": [
        50364,
        286,
        589,
        10029,
        365,
        264,
        5454,
        1364,
        1594,
        293,
        286,
        478,
        611,
        257,
        383,
        6273,
        32,
        32195,
        1496,
        21110,
        294,
        42927,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2238684594631195,
      "compression_ratio": 1.4303797483444214,
      "no_speech_prob": 0.3121616840362549
    },
    {
      "id": 7,
      "seek": 2800,
      "start": 42.0,
      "end": 52.0,
      "text": " The talk you've given last day was about how to use AI with software architecture to create a software architecture.",
      "tokens": [
        51064,
        440,
        751,
        291,
        600,
        2212,
        1036,
        786,
        390,
        466,
        577,
        281,
        764,
        7318,
        365,
        4722,
        9482,
        281,
        1884,
        257,
        4722,
        9482,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2238684594631195,
      "compression_ratio": 1.4303797483444214,
      "no_speech_prob": 0.3121616840362549
    },
    {
      "id": 8,
      "seek": 5200,
      "start": 52.0,
      "end": 61.0,
      "text": " Can you tell a little bit about your approach, how you use AI?",
      "tokens": [
        50364,
        1664,
        291,
        980,
        257,
        707,
        857,
        466,
        428,
        3109,
        11,
        577,
        291,
        764,
        7318,
        30,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23664656281471252,
      "compression_ratio": 1.5077719688415527,
      "no_speech_prob": 0.11032620817422867
    },
    {
      "id": 9,
      "seek": 5200,
      "start": 61.0,
      "end": 71.0,
      "text": " The main thing I've been trying is looking at, for example, the way that we approach software architecture.",
      "tokens": [
        50814,
        440,
        2135,
        551,
        286,
        600,
        668,
        1382,
        307,
        1237,
        412,
        11,
        337,
        1365,
        11,
        264,
        636,
        300,
        321,
        3109,
        4722,
        9482,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23664656281471252,
      "compression_ratio": 1.5077719688415527,
      "no_speech_prob": 0.11032620817422867
    },
    {
      "id": 10,
      "seek": 5200,
      "start": 71.0,
      "end": 80.0,
      "text": " It's sort of methodological, so we do have different steps that we use usually and different aspects that are important.",
      "tokens": [
        51314,
        467,
        311,
        1333,
        295,
        3170,
        4383,
        11,
        370,
        321,
        360,
        362,
        819,
        4439,
        300,
        321,
        764,
        2673,
        293,
        819,
        7270,
        300,
        366,
        1021,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23664656281471252,
      "compression_ratio": 1.5077719688415527,
      "no_speech_prob": 0.11032620817422867
    },
    {
      "id": 11,
      "seek": 8000,
      "start": 80.0,
      "end": 85.0,
      "text": " So first of all, clarification of requirements, understanding your constraints and so on.",
      "tokens": [
        50364,
        407,
        700,
        295,
        439,
        11,
        34449,
        295,
        7728,
        11,
        3701,
        428,
        18491,
        293,
        370,
        322,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20570388436317444,
      "compression_ratio": 1.6819788217544556,
      "no_speech_prob": 0.061343878507614136
    },
    {
      "id": 12,
      "seek": 8000,
      "start": 85.0,
      "end": 95.0,
      "text": " And what I try to do is incorporate LLMs in a way that they help me to do background research faster when it comes down to, for example, standard documentation.",
      "tokens": [
        50614,
        400,
        437,
        286,
        853,
        281,
        360,
        307,
        16091,
        441,
        43,
        26386,
        294,
        257,
        636,
        300,
        436,
        854,
        385,
        281,
        360,
        3678,
        2132,
        4663,
        562,
        309,
        1487,
        760,
        281,
        11,
        337,
        1365,
        11,
        3832,
        14333,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20570388436317444,
      "compression_ratio": 1.6819788217544556,
      "no_speech_prob": 0.061343878507614136
    },
    {
      "id": 13,
      "seek": 8000,
      "start": 95.0,
      "end": 99.0,
      "text": " It helps me to answer questions in terms of information that I need faster.",
      "tokens": [
        51114,
        467,
        3665,
        385,
        281,
        1867,
        1651,
        294,
        2115,
        295,
        1589,
        300,
        286,
        643,
        4663,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20570388436317444,
      "compression_ratio": 1.6819788217544556,
      "no_speech_prob": 0.061343878507614136
    },
    {
      "id": 14,
      "seek": 8000,
      "start": 99.0,
      "end": 109.0,
      "text": " Furthermore, I find it very useful as long as you have the appropriate contextual information in terms of rewriting and clarifying your requirements.",
      "tokens": [
        51314,
        23999,
        11,
        286,
        915,
        309,
        588,
        4420,
        382,
        938,
        382,
        291,
        362,
        264,
        6854,
        35526,
        1589,
        294,
        2115,
        295,
        319,
        19868,
        293,
        6093,
        5489,
        428,
        7728,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20570388436317444,
      "compression_ratio": 1.6819788217544556,
      "no_speech_prob": 0.061343878507614136
    },
    {
      "id": 15,
      "seek": 10900,
      "start": 109.0,
      "end": 113.0,
      "text": " For example, having your quality scenarios well written and very clear.",
      "tokens": [
        50364,
        1171,
        1365,
        11,
        1419,
        428,
        3125,
        15077,
        731,
        3720,
        293,
        588,
        1850,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21890783309936523,
      "compression_ratio": 1.6159695386886597,
      "no_speech_prob": 0.04331502690911293
    },
    {
      "id": 16,
      "seek": 10900,
      "start": 113.0,
      "end": 115.0,
      "text": " So I find it useful in that way.",
      "tokens": [
        50564,
        407,
        286,
        915,
        309,
        4420,
        294,
        300,
        636,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21890783309936523,
      "compression_ratio": 1.6159695386886597,
      "no_speech_prob": 0.04331502690911293
    },
    {
      "id": 17,
      "seek": 10900,
      "start": 115.0,
      "end": 130.0,
      "text": " It's also useful, again, as you go about architectural design, if you're using an incremental approach and doing small parts at a time, providing the necessary context as you try to solve small problems.",
      "tokens": [
        50664,
        467,
        311,
        611,
        4420,
        11,
        797,
        11,
        382,
        291,
        352,
        466,
        26621,
        1715,
        11,
        498,
        291,
        434,
        1228,
        364,
        35759,
        3109,
        293,
        884,
        1359,
        3166,
        412,
        257,
        565,
        11,
        6530,
        264,
        4818,
        4319,
        382,
        291,
        853,
        281,
        5039,
        1359,
        2740,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21890783309936523,
      "compression_ratio": 1.6159695386886597,
      "no_speech_prob": 0.04331502690911293
    },
    {
      "id": 18,
      "seek": 10900,
      "start": 130.0,
      "end": 138.0,
      "text": " So, for example, once you have decided on, OK, these are the primary blocks that you need for your static structure.",
      "tokens": [
        51414,
        407,
        11,
        337,
        1365,
        11,
        1564,
        291,
        362,
        3047,
        322,
        11,
        2264,
        11,
        613,
        366,
        264,
        6194,
        8474,
        300,
        291,
        643,
        337,
        428,
        13437,
        3877,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21890783309936523,
      "compression_ratio": 1.6159695386886597,
      "no_speech_prob": 0.04331502690911293
    },
    {
      "id": 19,
      "seek": 13800,
      "start": 138.0,
      "end": 142.0,
      "text": " And you can use the LLM to help to define those structures.",
      "tokens": [
        50364,
        400,
        291,
        393,
        764,
        264,
        441,
        43,
        44,
        281,
        854,
        281,
        6964,
        729,
        9227,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1782943457365036,
      "compression_ratio": 1.510067105293274,
      "no_speech_prob": 0.12688297033309937
    },
    {
      "id": 20,
      "seek": 13800,
      "start": 142.0,
      "end": 145.0,
      "text": " For each structure, you can get information.",
      "tokens": [
        50564,
        1171,
        1184,
        3877,
        11,
        291,
        393,
        483,
        1589,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1782943457365036,
      "compression_ratio": 1.510067105293274,
      "no_speech_prob": 0.12688297033309937
    },
    {
      "id": 21,
      "seek": 13800,
      "start": 145.0,
      "end": 153.0,
      "text": " You can get help, for example, with the logics of the structure or what the interface might look like, things like that.",
      "tokens": [
        50714,
        509,
        393,
        483,
        854,
        11,
        337,
        1365,
        11,
        365,
        264,
        3565,
        1167,
        295,
        264,
        3877,
        420,
        437,
        264,
        9226,
        1062,
        574,
        411,
        11,
        721,
        411,
        300,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1782943457365036,
      "compression_ratio": 1.510067105293274,
      "no_speech_prob": 0.12688297033309937
    },
    {
      "id": 22,
      "seek": 15300,
      "start": 153.0,
      "end": 164.0,
      "text": " So I would not try to use and I wouldn't recommend using an LLM like ChatGPT or Software Architect 4.0 to solve the overall architectural problem at once.",
      "tokens": [
        50364,
        407,
        286,
        576,
        406,
        853,
        281,
        764,
        293,
        286,
        2759,
        380,
        2748,
        1228,
        364,
        441,
        43,
        44,
        411,
        27503,
        38,
        47,
        51,
        420,
        27428,
        29306,
        1017,
        13,
        15,
        281,
        5039,
        264,
        4787,
        26621,
        1154,
        412,
        1564,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20283949375152588,
      "compression_ratio": 1.4464285373687744,
      "no_speech_prob": 0.3947484493255615
    },
    {
      "id": 23,
      "seek": 15300,
      "start": 164.0,
      "end": 177.0,
      "text": " But a stepwise approach that's incremental, I find it to be quite useful, especially if you're looking at the LLM as kind of an assistant, you know, asking it questions.",
      "tokens": [
        50914,
        583,
        257,
        1823,
        3711,
        3109,
        300,
        311,
        35759,
        11,
        286,
        915,
        309,
        281,
        312,
        1596,
        4420,
        11,
        2318,
        498,
        291,
        434,
        1237,
        412,
        264,
        441,
        43,
        44,
        382,
        733,
        295,
        364,
        10994,
        11,
        291,
        458,
        11,
        3365,
        309,
        1651,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20283949375152588,
      "compression_ratio": 1.4464285373687744,
      "no_speech_prob": 0.3947484493255615
    },
    {
      "id": 24,
      "seek": 17700,
      "start": 178.0,
      "end": 184.0,
      "text": " Once you get responses, trying to clarify, doing your research, yes.",
      "tokens": [
        50414,
        3443,
        291,
        483,
        13019,
        11,
        1382,
        281,
        17594,
        11,
        884,
        428,
        2132,
        11,
        2086,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25490620732307434,
      "compression_ratio": 1.5699481964111328,
      "no_speech_prob": 0.5884087681770325
    },
    {
      "id": 25,
      "seek": 17700,
      "start": 184.0,
      "end": 194.0,
      "text": " So you use it more for, I mean, there are many people out there who try to use AI to create the whole architecture.",
      "tokens": [
        50714,
        407,
        291,
        764,
        309,
        544,
        337,
        11,
        286,
        914,
        11,
        456,
        366,
        867,
        561,
        484,
        456,
        567,
        853,
        281,
        764,
        7318,
        281,
        1884,
        264,
        1379,
        9482,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25490620732307434,
      "compression_ratio": 1.5699481964111328,
      "no_speech_prob": 0.5884087681770325
    },
    {
      "id": 26,
      "seek": 17700,
      "start": 194.0,
      "end": 205.0,
      "text": " But as I do understand, you advise people to use it for brainstorming, for research, to get deeper inside inspiration.",
      "tokens": [
        51214,
        583,
        382,
        286,
        360,
        1223,
        11,
        291,
        18312,
        561,
        281,
        764,
        309,
        337,
        35245,
        278,
        11,
        337,
        2132,
        11,
        281,
        483,
        7731,
        1854,
        10249,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25490620732307434,
      "compression_ratio": 1.5699481964111328,
      "no_speech_prob": 0.5884087681770325
    },
    {
      "id": 27,
      "seek": 20500,
      "start": 205.0,
      "end": 216.0,
      "text": " And so this works when you work on a topic which is well known to the LLM, right?",
      "tokens": [
        50364,
        400,
        370,
        341,
        1985,
        562,
        291,
        589,
        322,
        257,
        4829,
        597,
        307,
        731,
        2570,
        281,
        264,
        441,
        43,
        44,
        11,
        558,
        30,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2247682809829712,
      "compression_ratio": 1.3312101364135742,
      "no_speech_prob": 0.010310722514986992
    },
    {
      "id": 28,
      "seek": 20500,
      "start": 216.0,
      "end": 218.0,
      "text": " Yes, yes. Actually, that's very important.",
      "tokens": [
        50914,
        1079,
        11,
        2086,
        13,
        5135,
        11,
        300,
        311,
        588,
        1021,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2247682809829712,
      "compression_ratio": 1.3312101364135742,
      "no_speech_prob": 0.010310722514986992
    },
    {
      "id": 29,
      "seek": 20500,
      "start": 218.0,
      "end": 224.0,
      "text": " The LLM is, of course, depending on documents that it has access to on the Internet.",
      "tokens": [
        51014,
        440,
        441,
        43,
        44,
        307,
        11,
        295,
        1164,
        11,
        5413,
        322,
        8512,
        300,
        309,
        575,
        2105,
        281,
        322,
        264,
        7703,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2247682809829712,
      "compression_ratio": 1.3312101364135742,
      "no_speech_prob": 0.010310722514986992
    },
    {
      "id": 30,
      "seek": 22400,
      "start": 224.0,
      "end": 232.0,
      "text": " So when the topic is not something, so there may be a green field of projects where you might not have that type of information.",
      "tokens": [
        50364,
        407,
        562,
        264,
        4829,
        307,
        406,
        746,
        11,
        370,
        456,
        815,
        312,
        257,
        3092,
        2519,
        295,
        4455,
        689,
        291,
        1062,
        406,
        362,
        300,
        2010,
        295,
        1589,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2432006448507309,
      "compression_ratio": 1.6809816360473633,
      "no_speech_prob": 0.6191285252571106
    },
    {
      "id": 31,
      "seek": 22400,
      "start": 232.0,
      "end": 239.0,
      "text": " Sorry, novel types of projects in novel domains where the information might not be there.",
      "tokens": [
        50764,
        4919,
        11,
        7613,
        3467,
        295,
        4455,
        294,
        7613,
        25514,
        689,
        264,
        1589,
        1062,
        406,
        312,
        456,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2432006448507309,
      "compression_ratio": 1.6809816360473633,
      "no_speech_prob": 0.6191285252571106
    },
    {
      "id": 32,
      "seek": 22400,
      "start": 239.0,
      "end": 242.0,
      "text": " So the type of help that you can get will be different.",
      "tokens": [
        51114,
        407,
        264,
        2010,
        295,
        854,
        300,
        291,
        393,
        483,
        486,
        312,
        819,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2432006448507309,
      "compression_ratio": 1.6809816360473633,
      "no_speech_prob": 0.6191285252571106
    },
    {
      "id": 33,
      "seek": 24200,
      "start": 242.0,
      "end": 247.0,
      "text": " But information, for example, on methodologies is available.",
      "tokens": [
        50364,
        583,
        1589,
        11,
        337,
        1365,
        11,
        322,
        3170,
        6204,
        307,
        2435,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21068666875362396,
      "compression_ratio": 1.668639063835144,
      "no_speech_prob": 0.5482358932495117
    },
    {
      "id": 34,
      "seek": 24200,
      "start": 247.0,
      "end": 256.0,
      "text": " So methodologies like R42 or 4 plus 1 views, that information is available.",
      "tokens": [
        50614,
        407,
        3170,
        6204,
        411,
        497,
        15628,
        420,
        1017,
        1804,
        502,
        6809,
        11,
        300,
        1589,
        307,
        2435,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21068666875362396,
      "compression_ratio": 1.668639063835144,
      "no_speech_prob": 0.5482358932495117
    },
    {
      "id": 35,
      "seek": 24200,
      "start": 256.0,
      "end": 258.0,
      "text": " So it can help you in a methodological way.",
      "tokens": [
        51064,
        407,
        309,
        393,
        854,
        291,
        294,
        257,
        3170,
        4383,
        636,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21068666875362396,
      "compression_ratio": 1.668639063835144,
      "no_speech_prob": 0.5482358932495117
    },
    {
      "id": 36,
      "seek": 24200,
      "start": 258.0,
      "end": 265.0,
      "text": " So it can help you with identifying a template that's useful for, let's say, an interface definition.",
      "tokens": [
        51164,
        407,
        309,
        393,
        854,
        291,
        365,
        16696,
        257,
        12379,
        300,
        311,
        4420,
        337,
        11,
        718,
        311,
        584,
        11,
        364,
        9226,
        7123,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21068666875362396,
      "compression_ratio": 1.668639063835144,
      "no_speech_prob": 0.5482358932495117
    },
    {
      "id": 37,
      "seek": 26500,
      "start": 266.0,
      "end": 279.0,
      "text": " So you work a lot with students, and so you not only use AI for research in the business domain, but also for how do I write an ADR and things like that?",
      "tokens": [
        50414,
        407,
        291,
        589,
        257,
        688,
        365,
        1731,
        11,
        293,
        370,
        291,
        406,
        787,
        764,
        7318,
        337,
        2132,
        294,
        264,
        1606,
        9274,
        11,
        457,
        611,
        337,
        577,
        360,
        286,
        2464,
        364,
        9135,
        49,
        293,
        721,
        411,
        300,
        30,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2011183500289917,
      "compression_ratio": 1.5467979907989502,
      "no_speech_prob": 0.4908358156681061
    },
    {
      "id": 38,
      "seek": 26500,
      "start": 279.0,
      "end": 280.0,
      "text": " That's correct, yes.",
      "tokens": [
        51064,
        663,
        311,
        3006,
        11,
        2086,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2011183500289917,
      "compression_ratio": 1.5467979907989502,
      "no_speech_prob": 0.4908358156681061
    },
    {
      "id": 39,
      "seek": 26500,
      "start": 280.0,
      "end": 281.0,
      "text": " That's a great idea.",
      "tokens": [
        51114,
        663,
        311,
        257,
        869,
        1558,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2011183500289917,
      "compression_ratio": 1.5467979907989502,
      "no_speech_prob": 0.4908358156681061
    },
    {
      "id": 40,
      "seek": 26500,
      "start": 281.0,
      "end": 287.0,
      "text": " The topic you presented was, so the business domain was about sign language.",
      "tokens": [
        51164,
        440,
        4829,
        291,
        8212,
        390,
        11,
        370,
        264,
        1606,
        9274,
        390,
        466,
        1465,
        2856,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2011183500289917,
      "compression_ratio": 1.5467979907989502,
      "no_speech_prob": 0.4908358156681061
    },
    {
      "id": 41,
      "seek": 26500,
      "start": 287.0,
      "end": 288.0,
      "text": " Yes.",
      "tokens": [
        51464,
        1079,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2011183500289917,
      "compression_ratio": 1.5467979907989502,
      "no_speech_prob": 0.4908358156681061
    },
    {
      "id": 42,
      "seek": 26500,
      "start": 288.0,
      "end": 291.0,
      "text": " I think it's quite interesting.",
      "tokens": [
        51514,
        286,
        519,
        309,
        311,
        1596,
        1880,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2011183500289917,
      "compression_ratio": 1.5467979907989502,
      "no_speech_prob": 0.4908358156681061
    },
    {
      "id": 43,
      "seek": 26500,
      "start": 291.0,
      "end": 292.0,
      "text": " Yes.",
      "tokens": [
        51664,
        1079,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2011183500289917,
      "compression_ratio": 1.5467979907989502,
      "no_speech_prob": 0.4908358156681061
    },
    {
      "id": 44,
      "seek": 29200,
      "start": 292.0,
      "end": 299.0,
      "text": " So can you elaborate a little bit on this, how AI helps with this domain?",
      "tokens": [
        50364,
        407,
        393,
        291,
        20945,
        257,
        707,
        857,
        322,
        341,
        11,
        577,
        7318,
        3665,
        365,
        341,
        9274,
        30,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1651916652917862,
      "compression_ratio": 1.4113924503326416,
      "no_speech_prob": 0.022279758006334305
    },
    {
      "id": 45,
      "seek": 29200,
      "start": 299.0,
      "end": 305.0,
      "text": " I mean, it's a special domain which is not really known to most of us.",
      "tokens": [
        50714,
        286,
        914,
        11,
        309,
        311,
        257,
        2121,
        9274,
        597,
        307,
        406,
        534,
        2570,
        281,
        881,
        295,
        505,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1651916652917862,
      "compression_ratio": 1.4113924503326416,
      "no_speech_prob": 0.022279758006334305
    },
    {
      "id": 46,
      "seek": 29200,
      "start": 305.0,
      "end": 306.0,
      "text": " Right.",
      "tokens": [
        51014,
        1779,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1651916652917862,
      "compression_ratio": 1.4113924503326416,
      "no_speech_prob": 0.022279758006334305
    },
    {
      "id": 47,
      "seek": 29200,
      "start": 306.0,
      "end": 311.0,
      "text": " And I wouldn't know how I should approach this.",
      "tokens": [
        51064,
        400,
        286,
        2759,
        380,
        458,
        577,
        286,
        820,
        3109,
        341,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1651916652917862,
      "compression_ratio": 1.4113924503326416,
      "no_speech_prob": 0.022279758006334305
    },
    {
      "id": 48,
      "seek": 29200,
      "start": 311.0,
      "end": 314.0,
      "text": " So AI also helps there?",
      "tokens": [
        51314,
        407,
        7318,
        611,
        3665,
        456,
        30,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1651916652917862,
      "compression_ratio": 1.4113924503326416,
      "no_speech_prob": 0.022279758006334305
    },
    {
      "id": 49,
      "seek": 31400,
      "start": 315.0,
      "end": 327.0,
      "text": " So in the experience that I had, there were things that I did not know in terms of how do you translate natural language into something like sign language.",
      "tokens": [
        50414,
        407,
        294,
        264,
        1752,
        300,
        286,
        632,
        11,
        456,
        645,
        721,
        300,
        286,
        630,
        406,
        458,
        294,
        2115,
        295,
        577,
        360,
        291,
        13799,
        3303,
        2856,
        666,
        746,
        411,
        1465,
        2856,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16459344327449799,
      "compression_ratio": 1.8034934997558594,
      "no_speech_prob": 0.27375200390815735
    },
    {
      "id": 50,
      "seek": 31400,
      "start": 327.0,
      "end": 330.0,
      "text": " Sign language is not necessarily a one-to-one.",
      "tokens": [
        51014,
        13515,
        2856,
        307,
        406,
        4725,
        257,
        472,
        12,
        1353,
        12,
        546,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16459344327449799,
      "compression_ratio": 1.8034934997558594,
      "no_speech_prob": 0.27375200390815735
    },
    {
      "id": 51,
      "seek": 31400,
      "start": 330.0,
      "end": 331.0,
      "text": " I know some sign language.",
      "tokens": [
        51164,
        286,
        458,
        512,
        1465,
        2856,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16459344327449799,
      "compression_ratio": 1.8034934997558594,
      "no_speech_prob": 0.27375200390815735
    },
    {
      "id": 52,
      "seek": 31400,
      "start": 331.0,
      "end": 333.0,
      "text": " I used to do sign language.",
      "tokens": [
        51214,
        286,
        1143,
        281,
        360,
        1465,
        2856,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16459344327449799,
      "compression_ratio": 1.8034934997558594,
      "no_speech_prob": 0.27375200390815735
    },
    {
      "id": 53,
      "seek": 31400,
      "start": 333.0,
      "end": 340.0,
      "text": " So you don't have necessarily a one-to-one relationship between words that people say and a specific sign.",
      "tokens": [
        51314,
        407,
        291,
        500,
        380,
        362,
        4725,
        257,
        472,
        12,
        1353,
        12,
        546,
        2480,
        1296,
        2283,
        300,
        561,
        584,
        293,
        257,
        2685,
        1465,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16459344327449799,
      "compression_ratio": 1.8034934997558594,
      "no_speech_prob": 0.27375200390815735
    },
    {
      "id": 54,
      "seek": 31400,
      "start": 340.0,
      "end": 343.0,
      "text": " Sometimes there's a sign for a whole expression.",
      "tokens": [
        51664,
        4803,
        456,
        311,
        257,
        1465,
        337,
        257,
        1379,
        6114,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16459344327449799,
      "compression_ratio": 1.8034934997558594,
      "no_speech_prob": 0.27375200390815735
    },
    {
      "id": 55,
      "seek": 34300,
      "start": 343.0,
      "end": 346.0,
      "text": " So I kind of wondered how would this work.",
      "tokens": [
        50364,
        407,
        286,
        733,
        295,
        17055,
        577,
        576,
        341,
        589,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18368598818778992,
      "compression_ratio": 1.5537848472595215,
      "no_speech_prob": 0.04283943399786949
    },
    {
      "id": 56,
      "seek": 34300,
      "start": 346.0,
      "end": 352.0,
      "text": " And the research that was available online, I was able to access that.",
      "tokens": [
        50514,
        400,
        264,
        2132,
        300,
        390,
        2435,
        2950,
        11,
        286,
        390,
        1075,
        281,
        2105,
        300,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18368598818778992,
      "compression_ratio": 1.5537848472595215,
      "no_speech_prob": 0.04283943399786949
    },
    {
      "id": 57,
      "seek": 34300,
      "start": 352.0,
      "end": 356.0,
      "text": " Obviously, you can go ahead and read the research papers.",
      "tokens": [
        50814,
        7580,
        11,
        291,
        393,
        352,
        2286,
        293,
        1401,
        264,
        2132,
        10577,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18368598818778992,
      "compression_ratio": 1.5537848472595215,
      "no_speech_prob": 0.04283943399786949
    },
    {
      "id": 58,
      "seek": 34300,
      "start": 356.0,
      "end": 364.0,
      "text": " But when I used the LLM, it pointed me to the right papers, and it answered some of the questions that I had very quickly.",
      "tokens": [
        51014,
        583,
        562,
        286,
        1143,
        264,
        441,
        43,
        44,
        11,
        309,
        10932,
        385,
        281,
        264,
        558,
        10577,
        11,
        293,
        309,
        10103,
        512,
        295,
        264,
        1651,
        300,
        286,
        632,
        588,
        2661,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18368598818778992,
      "compression_ratio": 1.5537848472595215,
      "no_speech_prob": 0.04283943399786949
    },
    {
      "id": 59,
      "seek": 34300,
      "start": 364.0,
      "end": 369.0,
      "text": " So for example, the idea of something called glossing, which I'd never heard before.",
      "tokens": [
        51414,
        407,
        337,
        1365,
        11,
        264,
        1558,
        295,
        746,
        1219,
        19574,
        278,
        11,
        597,
        286,
        1116,
        1128,
        2198,
        949,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18368598818778992,
      "compression_ratio": 1.5537848472595215,
      "no_speech_prob": 0.04283943399786949
    },
    {
      "id": 60,
      "seek": 34300,
      "start": 369.0,
      "end": 370.0,
      "text": " What's it?",
      "tokens": [
        51664,
        708,
        311,
        309,
        30,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18368598818778992,
      "compression_ratio": 1.5537848472595215,
      "no_speech_prob": 0.04283943399786949
    },
    {
      "id": 61,
      "seek": 37000,
      "start": 370.0,
      "end": 382.0,
      "text": " So it's basically, it's kind of like an activity between getting the natural language, the audio, into text and then going from text to sign language.",
      "tokens": [
        50364,
        407,
        309,
        311,
        1936,
        11,
        309,
        311,
        733,
        295,
        411,
        364,
        5191,
        1296,
        1242,
        264,
        3303,
        2856,
        11,
        264,
        6278,
        11,
        666,
        2487,
        293,
        550,
        516,
        490,
        2487,
        281,
        1465,
        2856,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.219180166721344,
      "compression_ratio": 1.734375,
      "no_speech_prob": 0.11331135779619217
    },
    {
      "id": 62,
      "seek": 37000,
      "start": 382.0,
      "end": 395.0,
      "text": " So glossing is like taking the text and translating it into a version of the text or a nuanced representation that matches more with sign language.",
      "tokens": [
        50964,
        407,
        19574,
        278,
        307,
        411,
        1940,
        264,
        2487,
        293,
        35030,
        309,
        666,
        257,
        3037,
        295,
        264,
        2487,
        420,
        257,
        45115,
        10290,
        300,
        10676,
        544,
        365,
        1465,
        2856,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.219180166721344,
      "compression_ratio": 1.734375,
      "no_speech_prob": 0.11331135779619217
    },
    {
      "id": 63,
      "seek": 37000,
      "start": 395.0,
      "end": 397.0,
      "text": " So it's in between the two things.",
      "tokens": [
        51614,
        407,
        309,
        311,
        294,
        1296,
        264,
        732,
        721,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.219180166721344,
      "compression_ratio": 1.734375,
      "no_speech_prob": 0.11331135779619217
    },
    {
      "id": 64,
      "seek": 39700,
      "start": 397.0,
      "end": 398.0,
      "text": " Okay.",
      "tokens": [
        50364,
        1033,
        13,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2124561071395874,
      "compression_ratio": 1.5494505167007446,
      "no_speech_prob": 0.19183200597763062
    },
    {
      "id": 65,
      "seek": 39700,
      "start": 398.0,
      "end": 406.0,
      "text": " That, for me, is a quite interesting part because when you talk about sign language and translation of audio,",
      "tokens": [
        50414,
        663,
        11,
        337,
        385,
        11,
        307,
        257,
        1596,
        1880,
        644,
        570,
        562,
        291,
        751,
        466,
        1465,
        2856,
        293,
        12853,
        295,
        6278,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2124561071395874,
      "compression_ratio": 1.5494505167007446,
      "no_speech_prob": 0.19183200597763062
    },
    {
      "id": 66,
      "seek": 39700,
      "start": 406.0,
      "end": 412.0,
      "text": " I first thought, hey, if you have the text, why need the sign language?",
      "tokens": [
        50814,
        286,
        700,
        1194,
        11,
        4177,
        11,
        498,
        291,
        362,
        264,
        2487,
        11,
        983,
        643,
        264,
        1465,
        2856,
        30,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2124561071395874,
      "compression_ratio": 1.5494505167007446,
      "no_speech_prob": 0.19183200597763062
    },
    {
      "id": 67,
      "seek": 39700,
      "start": 412.0,
      "end": 422.0,
      "text": " But I had to learn that this is a whole different thing for people who need the sign language.",
      "tokens": [
        51114,
        583,
        286,
        632,
        281,
        1466,
        300,
        341,
        307,
        257,
        1379,
        819,
        551,
        337,
        561,
        567,
        643,
        264,
        1465,
        2856,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2124561071395874,
      "compression_ratio": 1.5494505167007446,
      "no_speech_prob": 0.19183200597763062
    },
    {
      "id": 68,
      "seek": 42200,
      "start": 423.0,
      "end": 434.0,
      "text": " And not only for sign language, there are, even in natural language, there are languages that don't have necessarily the same kind of structure as,",
      "tokens": [
        50414,
        400,
        406,
        787,
        337,
        1465,
        2856,
        11,
        456,
        366,
        11,
        754,
        294,
        3303,
        2856,
        11,
        456,
        366,
        8650,
        300,
        500,
        380,
        362,
        4725,
        264,
        912,
        733,
        295,
        3877,
        382,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2591097056865692,
      "compression_ratio": 1.7834101915359497,
      "no_speech_prob": 0.2766849398612976
    },
    {
      "id": 69,
      "seek": 42200,
      "start": 434.0,
      "end": 437.0,
      "text": " like the structure of languages are different.",
      "tokens": [
        50964,
        411,
        264,
        3877,
        295,
        8650,
        366,
        819,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2591097056865692,
      "compression_ratio": 1.7834101915359497,
      "no_speech_prob": 0.2766849398612976
    },
    {
      "id": 70,
      "seek": 42200,
      "start": 437.0,
      "end": 440.0,
      "text": " So there are nuances between two languages.",
      "tokens": [
        51114,
        407,
        456,
        366,
        38775,
        1296,
        732,
        8650,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2591097056865692,
      "compression_ratio": 1.7834101915359497,
      "no_speech_prob": 0.2766849398612976
    },
    {
      "id": 71,
      "seek": 42200,
      "start": 440.0,
      "end": 451.0,
      "text": " And what I understand is that that glossing helps, that glossing process helps to, I guess, smooth out the translation from one language to another.",
      "tokens": [
        51264,
        400,
        437,
        286,
        1223,
        307,
        300,
        300,
        19574,
        278,
        3665,
        11,
        300,
        19574,
        278,
        1399,
        3665,
        281,
        11,
        286,
        2041,
        11,
        5508,
        484,
        264,
        12853,
        490,
        472,
        2856,
        281,
        1071,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2591097056865692,
      "compression_ratio": 1.7834101915359497,
      "no_speech_prob": 0.2766849398612976
    },
    {
      "id": 72,
      "seek": 45100,
      "start": 451.0,
      "end": 452.0,
      "text": " Okay.",
      "tokens": [
        50364,
        1033,
        13,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19667786359786987,
      "compression_ratio": 1.538888931274414,
      "no_speech_prob": 0.020956814289093018
    },
    {
      "id": 73,
      "seek": 45100,
      "start": 452.0,
      "end": 460.0,
      "text": " So in this case, with this special architecture, with a domain which is not well known to everybody,",
      "tokens": [
        50414,
        407,
        294,
        341,
        1389,
        11,
        365,
        341,
        2121,
        9482,
        11,
        365,
        257,
        9274,
        597,
        307,
        406,
        731,
        2570,
        281,
        2201,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19667786359786987,
      "compression_ratio": 1.538888931274414,
      "no_speech_prob": 0.020956814289093018
    },
    {
      "id": 74,
      "seek": 45100,
      "start": 460.0,
      "end": 469.0,
      "text": " the AI helps with brainstorming about the architecture, how to build it, but also about the business domain.",
      "tokens": [
        50814,
        264,
        7318,
        3665,
        365,
        35245,
        278,
        466,
        264,
        9482,
        11,
        577,
        281,
        1322,
        309,
        11,
        457,
        611,
        466,
        264,
        1606,
        9274,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19667786359786987,
      "compression_ratio": 1.538888931274414,
      "no_speech_prob": 0.020956814289093018
    },
    {
      "id": 75,
      "seek": 45100,
      "start": 469.0,
      "end": 470.0,
      "text": " Exactly.",
      "tokens": [
        51264,
        7587,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19667786359786987,
      "compression_ratio": 1.538888931274414,
      "no_speech_prob": 0.020956814289093018
    },
    {
      "id": 76,
      "seek": 45100,
      "start": 470.0,
      "end": 474.0,
      "text": " What glossing is and how to build a pipeline for it.",
      "tokens": [
        51314,
        708,
        19574,
        278,
        307,
        293,
        577,
        281,
        1322,
        257,
        15517,
        337,
        309,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19667786359786987,
      "compression_ratio": 1.538888931274414,
      "no_speech_prob": 0.020956814289093018
    },
    {
      "id": 77,
      "seek": 47400,
      "start": 474.0,
      "end": 484.0,
      "text": " Yes. And especially the issue of a part of translation is not just the words.",
      "tokens": [
        50364,
        1079,
        13,
        400,
        2318,
        264,
        2734,
        295,
        257,
        644,
        295,
        12853,
        307,
        406,
        445,
        264,
        2283,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21781058609485626,
      "compression_ratio": 1.5647058486938477,
      "no_speech_prob": 0.4985710680484772
    },
    {
      "id": 78,
      "seek": 47400,
      "start": 484.0,
      "end": 488.0,
      "text": " Translation also includes the way that people, the gesticulation and so on.",
      "tokens": [
        50864,
        6531,
        24278,
        611,
        5974,
        264,
        636,
        300,
        561,
        11,
        264,
        7219,
        299,
        2776,
        293,
        370,
        322,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21781058609485626,
      "compression_ratio": 1.5647058486938477,
      "no_speech_prob": 0.4985710680484772
    },
    {
      "id": 79,
      "seek": 47400,
      "start": 488.0,
      "end": 495.0,
      "text": " So one of the things that I realized is that the avatar, there are two different ways that you can process this,",
      "tokens": [
        51064,
        407,
        472,
        295,
        264,
        721,
        300,
        286,
        5334,
        307,
        300,
        264,
        36205,
        11,
        456,
        366,
        732,
        819,
        2098,
        300,
        291,
        393,
        1399,
        341,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21781058609485626,
      "compression_ratio": 1.5647058486938477,
      "no_speech_prob": 0.4985710680484772
    },
    {
      "id": 80,
      "seek": 49500,
      "start": 495.0,
      "end": 504.0,
      "text": " is you can take the gestures and expressions from the human, because the purpose of the translation is to take the human, the beta,",
      "tokens": [
        50364,
        307,
        291,
        393,
        747,
        264,
        28475,
        293,
        15277,
        490,
        264,
        1952,
        11,
        570,
        264,
        4334,
        295,
        264,
        12853,
        307,
        281,
        747,
        264,
        1952,
        11,
        264,
        9861,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2503693699836731,
      "compression_ratio": 1.8035714626312256,
      "no_speech_prob": 0.45939305424690247
    },
    {
      "id": 81,
      "seek": 49500,
      "start": 504.0,
      "end": 508.0,
      "text": " and translate what they're saying into sign language.",
      "tokens": [
        50814,
        293,
        13799,
        437,
        436,
        434,
        1566,
        666,
        1465,
        2856,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2503693699836731,
      "compression_ratio": 1.8035714626312256,
      "no_speech_prob": 0.45939305424690247
    },
    {
      "id": 82,
      "seek": 49500,
      "start": 508.0,
      "end": 515.0,
      "text": " So you can either capture the expressions, the facial expressions, the hand movements, the body movements, and so on.",
      "tokens": [
        51014,
        407,
        291,
        393,
        2139,
        7983,
        264,
        15277,
        11,
        264,
        15642,
        15277,
        11,
        264,
        1011,
        9981,
        11,
        264,
        1772,
        9981,
        11,
        293,
        370,
        322,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2503693699836731,
      "compression_ratio": 1.8035714626312256,
      "no_speech_prob": 0.45939305424690247
    },
    {
      "id": 83,
      "seek": 51500,
      "start": 516.0,
      "end": 526.0,
      "text": " You can capture that and replay it in the form of the avatar, or you can ensure that the translation from the avatar,",
      "tokens": [
        50414,
        509,
        393,
        7983,
        300,
        293,
        23836,
        309,
        294,
        264,
        1254,
        295,
        264,
        36205,
        11,
        420,
        291,
        393,
        5586,
        300,
        264,
        12853,
        490,
        264,
        36205,
        11,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19004638493061066,
      "compression_ratio": 1.736842155456543,
      "no_speech_prob": 0.436707466840744
    },
    {
      "id": 84,
      "seek": 51500,
      "start": 526.0,
      "end": 531.0,
      "text": " depending on the kind of resources you have in terms of time and so on for development,",
      "tokens": [
        50914,
        5413,
        322,
        264,
        733,
        295,
        3593,
        291,
        362,
        294,
        2115,
        295,
        565,
        293,
        370,
        322,
        337,
        3250,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19004638493061066,
      "compression_ratio": 1.736842155456543,
      "no_speech_prob": 0.436707466840744
    },
    {
      "id": 85,
      "seek": 51500,
      "start": 531.0,
      "end": 537.0,
      "text": " if you can keep the timing of the avatar close enough to the visuals of the actual speaker,",
      "tokens": [
        51164,
        498,
        291,
        393,
        1066,
        264,
        10822,
        295,
        264,
        36205,
        1998,
        1547,
        281,
        264,
        26035,
        295,
        264,
        3539,
        8145,
        11,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19004638493061066,
      "compression_ratio": 1.736842155456543,
      "no_speech_prob": 0.436707466840744
    },
    {
      "id": 86,
      "seek": 53700,
      "start": 537.0,
      "end": 544.0,
      "text": " then you wouldn't lose the gestures because then the person who's viewing would see the sign language along with the person's gestures.",
      "tokens": [
        50364,
        550,
        291,
        2759,
        380,
        3624,
        264,
        28475,
        570,
        550,
        264,
        954,
        567,
        311,
        17480,
        576,
        536,
        264,
        1465,
        2856,
        2051,
        365,
        264,
        954,
        311,
        28475,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2344312220811844,
      "compression_ratio": 1.6600985527038574,
      "no_speech_prob": 0.12221240252256393
    },
    {
      "id": 87,
      "seek": 53700,
      "start": 544.0,
      "end": 549.0,
      "text": " So there are two approaches that could be used depending on the kind of resources and time available.",
      "tokens": [
        50714,
        407,
        456,
        366,
        732,
        11587,
        300,
        727,
        312,
        1143,
        5413,
        322,
        264,
        733,
        295,
        3593,
        293,
        565,
        2435,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2344312220811844,
      "compression_ratio": 1.6600985527038574,
      "no_speech_prob": 0.12221240252256393
    },
    {
      "id": 88,
      "seek": 53700,
      "start": 549.0,
      "end": 560.0,
      "text": " So I remember there was a quality criteria that within two seconds the translation should be there.",
      "tokens": [
        50964,
        407,
        286,
        1604,
        456,
        390,
        257,
        3125,
        11101,
        300,
        1951,
        732,
        3949,
        264,
        12853,
        820,
        312,
        456,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2344312220811844,
      "compression_ratio": 1.6600985527038574,
      "no_speech_prob": 0.12221240252256393
    },
    {
      "id": 89,
      "seek": 56000,
      "start": 561.0,
      "end": 573.0,
      "text": " From my understanding, it doesn't translate word by word, so it needs to know the full sentence, and after it got the full sentence, two seconds.",
      "tokens": [
        50414,
        3358,
        452,
        3701,
        11,
        309,
        1177,
        380,
        13799,
        1349,
        538,
        1349,
        11,
        370,
        309,
        2203,
        281,
        458,
        264,
        1577,
        8174,
        11,
        293,
        934,
        309,
        658,
        264,
        1577,
        8174,
        11,
        732,
        3949,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30830857157707214,
      "compression_ratio": 1.355140209197998,
      "no_speech_prob": 0.1637454628944397
    },
    {
      "id": 90,
      "seek": 57300,
      "start": 574.0,
      "end": 579.0,
      "text": " So the whole process, what I wanted to accomplish, or what the quality requirement is describing,",
      "tokens": [
        50414,
        407,
        264,
        1379,
        1399,
        11,
        437,
        286,
        1415,
        281,
        9021,
        11,
        420,
        437,
        264,
        3125,
        11695,
        307,
        16141,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24878311157226562,
      "compression_ratio": 1.654054045677185,
      "no_speech_prob": 0.23306165635585785
    },
    {
      "id": 91,
      "seek": 57300,
      "start": 579.0,
      "end": 593.0,
      "text": " is from the time that the phrase that's being translated is said to the time that the avatar completes the translation,",
      "tokens": [
        50664,
        307,
        490,
        264,
        565,
        300,
        264,
        9535,
        300,
        311,
        885,
        16805,
        307,
        848,
        281,
        264,
        565,
        300,
        264,
        36205,
        36362,
        264,
        12853,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24878311157226562,
      "compression_ratio": 1.654054045677185,
      "no_speech_prob": 0.23306165635585785
    },
    {
      "id": 92,
      "seek": 57300,
      "start": 593.0,
      "end": 598.0,
      "text": " then we don't want more than two seconds to elapse because we want the two things to be.",
      "tokens": [
        51364,
        550,
        321,
        500,
        380,
        528,
        544,
        813,
        732,
        3949,
        281,
        806,
        11145,
        570,
        321,
        528,
        264,
        732,
        721,
        281,
        312,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24878311157226562,
      "compression_ratio": 1.654054045677185,
      "no_speech_prob": 0.23306165635585785
    },
    {
      "id": 93,
      "seek": 59800,
      "start": 598.0,
      "end": 604.0,
      "text": " So the approach that I am taking is to keep the actual speaker beside the avatar",
      "tokens": [
        50364,
        407,
        264,
        3109,
        300,
        286,
        669,
        1940,
        307,
        281,
        1066,
        264,
        3539,
        8145,
        15726,
        264,
        36205,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19934655725955963,
      "compression_ratio": 1.4500000476837158,
      "no_speech_prob": 0.05433379486203194
    },
    {
      "id": 94,
      "seek": 59800,
      "start": 604.0,
      "end": 609.0,
      "text": " so that the sign language can be interpreted along with the gestures of the original speaker.",
      "tokens": [
        50664,
        370,
        300,
        264,
        1465,
        2856,
        393,
        312,
        26749,
        2051,
        365,
        264,
        28475,
        295,
        264,
        3380,
        8145,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19934655725955963,
      "compression_ratio": 1.4500000476837158,
      "no_speech_prob": 0.05433379486203194
    },
    {
      "id": 0,
      "seek": 0,
      "start": 609.954,
      "end": 616.3140001335144,
      "text": " Okay, and you also said that the AI also helps with those quality requirements. Yes",
      "tokens": [
        50414,
        1033,
        11,
        293,
        291,
        611,
        848,
        300,
        264,
        7318,
        611,
        3665,
        365,
        729,
        3125,
        7728,
        13,
        1079,
        50732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.414348304271698,
      "compression_ratio": 1.664921522140503,
      "no_speech_prob": 0.9274699687957764
    },
    {
      "id": 1,
      "seek": 0,
      "start": 617.1539998092651,
      "end": 624.8740000762939,
      "text": " To to find them or to formulate them both both so it might not be able to find the quality requirement from scratch",
      "tokens": [
        50774,
        1407,
        281,
        915,
        552,
        420,
        281,
        47881,
        552,
        1293,
        1293,
        370,
        309,
        1062,
        406,
        312,
        1075,
        281,
        915,
        264,
        3125,
        11695,
        490,
        8459,
        51160
      ],
      "temperature": 0.0,
      "avg_logprob": -0.414348304271698,
      "compression_ratio": 1.664921522140503,
      "no_speech_prob": 0.9274699687957764
    },
    {
      "id": 2,
      "seek": 0,
      "start": 625.1540007629394,
      "end": 629.5540003814697,
      "text": " But the research that is necessary to so for every quality requirement",
      "tokens": [
        51174,
        583,
        264,
        2132,
        300,
        307,
        4818,
        281,
        370,
        337,
        633,
        3125,
        11695,
        51394
      ],
      "temperature": 0.0,
      "avg_logprob": -0.414348304271698,
      "compression_ratio": 1.664921522140503,
      "no_speech_prob": 0.9274699687957764
    },
    {
      "id": 3,
      "seek": 0,
      "start": 630.1139998474121,
      "end": 632.7940001525878,
      "text": " Basically, it's work. It exists within a domain",
      "tokens": [
        51422,
        8537,
        11,
        309,
        311,
        589,
        13,
        467,
        8198,
        1951,
        257,
        9274,
        51556
      ],
      "temperature": 0.0,
      "avg_logprob": -0.414348304271698,
      "compression_ratio": 1.664921522140503,
      "no_speech_prob": 0.9274699687957764
    },
    {
      "id": 4,
      "seek": 2384,
      "start": 633.1939997711181,
      "end": 639.8740000762939,
      "text": " So if I'm gonna talk about performance, I need to understand how do people measure the performance in in relation to",
      "tokens": [
        50384,
        407,
        498,
        286,
        478,
        799,
        751,
        466,
        3389,
        11,
        286,
        643,
        281,
        1223,
        577,
        360,
        561,
        3481,
        264,
        3389,
        294,
        294,
        9721,
        281,
        50718
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32756125926971436,
      "compression_ratio": 1.8091603517532349,
      "no_speech_prob": 0.31769582629203796
    },
    {
      "id": 5,
      "seek": 2384,
      "start": 640.3940005340576,
      "end": 644.954,
      "text": " You know any particular thing if I'm gonna talk about availability. I need to have the correct vocabulary",
      "tokens": [
        50744,
        509,
        458,
        604,
        1729,
        551,
        498,
        286,
        478,
        799,
        751,
        466,
        17945,
        13,
        286,
        643,
        281,
        362,
        264,
        3006,
        19864,
        50972
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32756125926971436,
      "compression_ratio": 1.8091603517532349,
      "no_speech_prob": 0.31769582629203796
    },
    {
      "id": 6,
      "seek": 2384,
      "start": 644.954,
      "end": 648.2339987792968,
      "text": " I need to know the possible metrics if I'm gonna talk about usability",
      "tokens": [
        50972,
        286,
        643,
        281,
        458,
        264,
        1944,
        16367,
        498,
        286,
        478,
        799,
        751,
        466,
        46878,
        51136
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32756125926971436,
      "compression_ratio": 1.8091603517532349,
      "no_speech_prob": 0.31769582629203796
    },
    {
      "id": 7,
      "seek": 2384,
      "start": 648.4740004577636,
      "end": 652.4339995422363,
      "text": " There are a bunch of different ways that we can measure usability and describe it. So",
      "tokens": [
        51148,
        821,
        366,
        257,
        3840,
        295,
        819,
        2098,
        300,
        321,
        393,
        3481,
        46878,
        293,
        6786,
        309,
        13,
        407,
        51346
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32756125926971436,
      "compression_ratio": 1.8091603517532349,
      "no_speech_prob": 0.31769582629203796
    },
    {
      "id": 8,
      "seek": 2384,
      "start": 652.9940009155273,
      "end": 654.6340003051757,
      "text": " for",
      "tokens": [
        51374,
        337,
        51456
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32756125926971436,
      "compression_ratio": 1.8091603517532349,
      "no_speech_prob": 0.31769582629203796
    },
    {
      "id": 9,
      "seek": 2384,
      "start": 654.6340003051757,
      "end": 660.1940016784667,
      "text": " Novice architect and ID with students and I'm mainly in academia. So there's a way in which",
      "tokens": [
        51456,
        31948,
        573,
        6331,
        293,
        7348,
        365,
        1731,
        293,
        286,
        478,
        8704,
        294,
        28937,
        13,
        407,
        456,
        311,
        257,
        636,
        294,
        597,
        51734
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32756125926971436,
      "compression_ratio": 1.8091603517532349,
      "no_speech_prob": 0.31769582629203796
    },
    {
      "id": 10,
      "seek": 5124,
      "start": 661.1940016784667,
      "end": 663.1940016784667,
      "text": " There's a way in which",
      "tokens": [
        50414,
        821,
        311,
        257,
        636,
        294,
        597,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27122393250465393,
      "compression_ratio": 1.7676348686218262,
      "no_speech_prob": 0.004239003174006939
    },
    {
      "id": 11,
      "seek": 5124,
      "start": 663.7139983215332,
      "end": 666.3939986267089,
      "text": " You you know not being in the industry all the time",
      "tokens": [
        50540,
        509,
        291,
        458,
        406,
        885,
        294,
        264,
        3518,
        439,
        264,
        565,
        50674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27122393250465393,
      "compression_ratio": 1.7676348686218262,
      "no_speech_prob": 0.004239003174006939
    },
    {
      "id": 12,
      "seek": 5124,
      "start": 666.514001373291,
      "end": 671.954,
      "text": " there are so many things you want to learn so many things you want to try and experiment with and what I have found is",
      "tokens": [
        50680,
        456,
        366,
        370,
        867,
        721,
        291,
        528,
        281,
        1466,
        370,
        867,
        721,
        291,
        528,
        281,
        853,
        293,
        5120,
        365,
        293,
        437,
        286,
        362,
        1352,
        307,
        50952
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27122393250465393,
      "compression_ratio": 1.7676348686218262,
      "no_speech_prob": 0.004239003174006939
    },
    {
      "id": 13,
      "seek": 5124,
      "start": 671.954,
      "end": 673.074002746582,
      "text": " that",
      "tokens": [
        50952,
        300,
        51008
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27122393250465393,
      "compression_ratio": 1.7676348686218262,
      "no_speech_prob": 0.004239003174006939
    },
    {
      "id": 14,
      "seek": 5124,
      "start": 673.074002746582,
      "end": 675.074002746582,
      "text": " being able to describe",
      "tokens": [
        51008,
        885,
        1075,
        281,
        6786,
        51108
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27122393250465393,
      "compression_ratio": 1.7676348686218262,
      "no_speech_prob": 0.004239003174006939
    },
    {
      "id": 15,
      "seek": 5124,
      "start": 675.2339987792968,
      "end": 681.8739981689453,
      "text": " The response and a response measure for a quality requirement the LNM. Yeah, I can help you with that",
      "tokens": [
        51116,
        440,
        4134,
        293,
        257,
        4134,
        3481,
        337,
        257,
        3125,
        11695,
        264,
        441,
        45,
        44,
        13,
        865,
        11,
        286,
        393,
        854,
        291,
        365,
        300,
        51448
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27122393250465393,
      "compression_ratio": 1.7676348686218262,
      "no_speech_prob": 0.004239003174006939
    },
    {
      "id": 16,
      "seek": 5124,
      "start": 682.9940009155273,
      "end": 689.7540030517578,
      "text": " So you may be able to explain what it is that you want or what is important in this quality in English",
      "tokens": [
        51504,
        407,
        291,
        815,
        312,
        1075,
        281,
        2903,
        437,
        309,
        307,
        300,
        291,
        528,
        420,
        437,
        307,
        1021,
        294,
        341,
        3125,
        294,
        3669,
        51842
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27122393250465393,
      "compression_ratio": 1.7676348686218262,
      "no_speech_prob": 0.004239003174006939
    },
    {
      "id": 17,
      "seek": 8124,
      "start": 690.1939978637695,
      "end": 694.9139990844726,
      "text": " But not necessarily with a precision necessary for architecture work and LLM can help with that",
      "tokens": [
        50364,
        583,
        406,
        4725,
        365,
        257,
        18356,
        4818,
        337,
        9482,
        589,
        293,
        441,
        43,
        44,
        393,
        854,
        365,
        300,
        50600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3279130756855011,
      "compression_ratio": 1.5744681358337402,
      "no_speech_prob": 0.0013450649566948414
    },
    {
      "id": 18,
      "seek": 8124,
      "start": 695.4340033569335,
      "end": 696.4739966430664,
      "text": " Okay",
      "tokens": [
        50626,
        1033,
        50678
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3279130756855011,
      "compression_ratio": 1.5744681358337402,
      "no_speech_prob": 0.0013450649566948414
    },
    {
      "id": 19,
      "seek": 8124,
      "start": 696.4739966430664,
      "end": 703.2339987792968,
      "text": " now I remember that the architecture was more or less a pipeline a processing pipeline and",
      "tokens": [
        50678,
        586,
        286,
        1604,
        300,
        264,
        9482,
        390,
        544,
        420,
        1570,
        257,
        15517,
        257,
        9007,
        15517,
        293,
        51016
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3279130756855011,
      "compression_ratio": 1.5744681358337402,
      "no_speech_prob": 0.0013450649566948414
    },
    {
      "id": 20,
      "seek": 8124,
      "start": 703.553998474121,
      "end": 705.553998474121,
      "text": " now when it comes to",
      "tokens": [
        51032,
        586,
        562,
        309,
        1487,
        281,
        51132
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3279130756855011,
      "compression_ratio": 1.5744681358337402,
      "no_speech_prob": 0.0013450649566948414
    },
    {
      "id": 21,
      "seek": 8124,
      "start": 706.1539969482421,
      "end": 708.7140021362304,
      "text": " to all those single steps to",
      "tokens": [
        51162,
        281,
        439,
        729,
        2167,
        4439,
        281,
        51290
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3279130756855011,
      "compression_ratio": 1.5744681358337402,
      "no_speech_prob": 0.0013450649566948414
    },
    {
      "id": 22,
      "seek": 8124,
      "start": 709.3540015258789,
      "end": 711.3540015258789,
      "text": " turn audio into",
      "tokens": [
        51322,
        1261,
        6278,
        666,
        51422
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3279130756855011,
      "compression_ratio": 1.5744681358337402,
      "no_speech_prob": 0.0013450649566948414
    },
    {
      "id": 23,
      "seek": 8124,
      "start": 712.1140036621093,
      "end": 714.9940009155273,
      "text": " Transcription, so I guess you use some",
      "tokens": [
        51460,
        6531,
        12432,
        11,
        370,
        286,
        2041,
        291,
        764,
        512,
        51604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3279130756855011,
      "compression_ratio": 1.5744681358337402,
      "no_speech_prob": 0.0013450649566948414
    },
    {
      "id": 24,
      "seek": 10604,
      "start": 715.7540030517578,
      "end": 721.9139990844726,
      "text": " Not necessarily a large language model, but machine learning I guess so so",
      "tokens": [
        50402,
        1726,
        4725,
        257,
        2416,
        2856,
        2316,
        11,
        457,
        3479,
        2539,
        286,
        2041,
        370,
        370,
        50710
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4057823717594147,
      "compression_ratio": 1.6735751628875732,
      "no_speech_prob": 0.004522188100963831
    },
    {
      "id": 25,
      "seek": 10604,
      "start": 723.3940024414062,
      "end": 725.2339987792968,
      "text": " Not really",
      "tokens": [
        50784,
        1726,
        534,
        50876
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4057823717594147,
      "compression_ratio": 1.6735751628875732,
      "no_speech_prob": 0.004522188100963831
    },
    {
      "id": 26,
      "seek": 10604,
      "start": 725.2339987792968,
      "end": 732.6740012207031,
      "text": " Yes, there's some machine learning that will be necessary because you do have to you're collecting a lot of data about various signs",
      "tokens": [
        50876,
        1079,
        11,
        456,
        311,
        512,
        3479,
        2539,
        300,
        486,
        312,
        4818,
        570,
        291,
        360,
        362,
        281,
        291,
        434,
        12510,
        257,
        688,
        295,
        1412,
        466,
        3683,
        7880,
        51248
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4057823717594147,
      "compression_ratio": 1.6735751628875732,
      "no_speech_prob": 0.004522188100963831
    },
    {
      "id": 27,
      "seek": 10604,
      "start": 733.5939993896484,
      "end": 739.5540061035156,
      "text": " And so yes, there's there be some machine learning involved. So I guess there are already libraries away",
      "tokens": [
        51294,
        400,
        370,
        2086,
        11,
        456,
        311,
        456,
        312,
        512,
        3479,
        2539,
        3288,
        13,
        407,
        286,
        2041,
        456,
        366,
        1217,
        15148,
        1314,
        51592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4057823717594147,
      "compression_ratio": 1.6735751628875732,
      "no_speech_prob": 0.004522188100963831
    },
    {
      "id": 28,
      "seek": 13060,
      "start": 740.433995727539,
      "end": 742.433995727539,
      "text": " Also for the for the glossing",
      "tokens": [
        50408,
        2743,
        337,
        264,
        337,
        264,
        19574,
        278,
        50508
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43731746077537537,
      "compression_ratio": 1.65625,
      "no_speech_prob": 0.012776997871696949
    },
    {
      "id": 29,
      "seek": 13060,
      "start": 742.6740012207031,
      "end": 749.0340018310546,
      "text": " All those things there are libraries and the good thing was that LLM was able to recommend various technologies for all the stages",
      "tokens": [
        50520,
        1057,
        729,
        721,
        456,
        366,
        15148,
        293,
        264,
        665,
        551,
        390,
        300,
        441,
        43,
        44,
        390,
        1075,
        281,
        2748,
        3683,
        7943,
        337,
        439,
        264,
        10232,
        50838
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43731746077537537,
      "compression_ratio": 1.65625,
      "no_speech_prob": 0.012776997871696949
    },
    {
      "id": 30,
      "seek": 13060,
      "start": 749.6339926757812,
      "end": 753.5540061035156,
      "text": " Because it has a knowledge from it access to all this documentation",
      "tokens": [
        50868,
        1436,
        309,
        575,
        257,
        3601,
        490,
        309,
        2105,
        281,
        439,
        341,
        14333,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43731746077537537,
      "compression_ratio": 1.65625,
      "no_speech_prob": 0.012776997871696949
    },
    {
      "id": 31,
      "seek": 13060,
      "start": 754.3940024414062,
      "end": 755.5139975585937,
      "text": " so",
      "tokens": [
        51106,
        370,
        51162
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43731746077537537,
      "compression_ratio": 1.65625,
      "no_speech_prob": 0.012776997871696949
    },
    {
      "id": 32,
      "seek": 13060,
      "start": 755.5139975585937,
      "end": 762.9140067138671,
      "text": " Did you mainly use the knowledge from the training data or did you use a web research?",
      "tokens": [
        51162,
        2589,
        291,
        8704,
        764,
        264,
        3601,
        490,
        264,
        3097,
        1412,
        420,
        630,
        291,
        764,
        257,
        3670,
        2132,
        30,
        51532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43731746077537537,
      "compression_ratio": 1.65625,
      "no_speech_prob": 0.012776997871696949
    },
    {
      "id": 33,
      "seek": 15396,
      "start": 763.433995727539,
      "end": 770.5540061035156,
      "text": " Which is mainly research because we haven't actually trained a model or anything like that yet. It's really just a matter of",
      "tokens": [
        50390,
        3013,
        307,
        8704,
        2132,
        570,
        321,
        2378,
        380,
        767,
        8895,
        257,
        2316,
        420,
        1340,
        411,
        300,
        1939,
        13,
        467,
        311,
        534,
        445,
        257,
        1871,
        295,
        50746
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47821876406669617,
      "compression_ratio": 1.45549738407135,
      "no_speech_prob": 0.023976143449544907
    },
    {
      "id": 34,
      "seek": 15396,
      "start": 771.5939993896484,
      "end": 774.3940024414062,
      "text": " The starting point of developing this architecture",
      "tokens": [
        50798,
        440,
        2891,
        935,
        295,
        6416,
        341,
        9482,
        50938
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47821876406669617,
      "compression_ratio": 1.45549738407135,
      "no_speech_prob": 0.023976143449544907
    },
    {
      "id": 35,
      "seek": 15396,
      "start": 775.1140036621093,
      "end": 777.1140036621093,
      "text": " Okay, that's great",
      "tokens": [
        50974,
        1033,
        11,
        300,
        311,
        869,
        51074
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47821876406669617,
      "compression_ratio": 1.45549738407135,
      "no_speech_prob": 0.023976143449544907
    },
    {
      "id": 36,
      "seek": 15396,
      "start": 777.9140067138671,
      "end": 780.1539969482421,
      "text": " you mentioned arc 42 and",
      "tokens": [
        51114,
        291,
        2835,
        10346,
        14034,
        293,
        51226
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47821876406669617,
      "compression_ratio": 1.45549738407135,
      "no_speech_prob": 0.023976143449544907
    },
    {
      "id": 37,
      "seek": 15396,
      "start": 781.194005493164,
      "end": 788.1140036621093,
      "text": " I was happy to hear that arc 42 is used in Jamaica Jamaica",
      "tokens": [
        51278,
        286,
        390,
        2055,
        281,
        1568,
        300,
        10346,
        14034,
        307,
        1143,
        294,
        42927,
        42927,
        51624
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47821876406669617,
      "compression_ratio": 1.45549738407135,
      "no_speech_prob": 0.023976143449544907
    },
    {
      "id": 38,
      "seek": 17916,
      "start": 789.0340018310546,
      "end": 791.0340018310546,
      "text": " Jamaica we talked about the pronunciation",
      "tokens": [
        50410,
        42927,
        321,
        2825,
        466,
        264,
        23338,
        50510
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4270941913127899,
      "compression_ratio": 1.560185194015503,
      "no_speech_prob": 0.003508355002850294
    },
    {
      "id": 39,
      "seek": 17916,
      "start": 792.0739951171875,
      "end": 793.8340048828125,
      "text": " pronunciation so that's",
      "tokens": [
        50562,
        23338,
        370,
        300,
        311,
        50650
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4270941913127899,
      "compression_ratio": 1.560185194015503,
      "no_speech_prob": 0.003508355002850294
    },
    {
      "id": 40,
      "seek": 17916,
      "start": 793.8340048828125,
      "end": 795.194005493164,
      "text": " Jamaica, yes",
      "tokens": [
        50650,
        42927,
        11,
        2086,
        50718
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4270941913127899,
      "compression_ratio": 1.560185194015503,
      "no_speech_prob": 0.003508355002850294
    },
    {
      "id": 41,
      "seek": 17916,
      "start": 795.194005493164,
      "end": 801.9140067138671,
      "text": " Can you elaborate a little bit on that? Because I think it's quite fascinating to see how",
      "tokens": [
        50718,
        1664,
        291,
        20945,
        257,
        707,
        857,
        322,
        300,
        30,
        1436,
        286,
        519,
        309,
        311,
        1596,
        10343,
        281,
        536,
        577,
        51054
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4270941913127899,
      "compression_ratio": 1.560185194015503,
      "no_speech_prob": 0.003508355002850294
    },
    {
      "id": 42,
      "seek": 17916,
      "start": 802.6740012207031,
      "end": 805.5540061035156,
      "text": " Arc 42 is used. Okay in the world",
      "tokens": [
        51092,
        21727,
        14034,
        307,
        1143,
        13,
        1033,
        294,
        264,
        1002,
        51236
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4270941913127899,
      "compression_ratio": 1.560185194015503,
      "no_speech_prob": 0.003508355002850294
    },
    {
      "id": 43,
      "seek": 17916,
      "start": 805.5540061035156,
      "end": 810.5540061035156,
      "text": " so arc 42 is new in a way to Jamaica as is the",
      "tokens": [
        51236,
        370,
        10346,
        14034,
        307,
        777,
        294,
        257,
        636,
        281,
        42927,
        382,
        307,
        264,
        51486
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4270941913127899,
      "compression_ratio": 1.560185194015503,
      "no_speech_prob": 0.003508355002850294
    },
    {
      "id": 44,
      "seek": 17916,
      "start": 811.1539969482421,
      "end": 816.7540030517578,
      "text": " SAQB and the training and so on over the last three years. We've been training students",
      "tokens": [
        51516,
        16482,
        48,
        33,
        293,
        264,
        3097,
        293,
        370,
        322,
        670,
        264,
        1036,
        1045,
        924,
        13,
        492,
        600,
        668,
        3097,
        1731,
        51796
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4270941913127899,
      "compression_ratio": 1.560185194015503,
      "no_speech_prob": 0.003508355002850294
    },
    {
      "id": 45,
      "seek": 20780,
      "start": 817.5139975585937,
      "end": 821.1539969482421,
      "text": " Using the CPSC curriculum now",
      "tokens": [
        50402,
        11142,
        264,
        383,
        6273,
        34,
        14302,
        586,
        50584
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39974188804626465,
      "compression_ratio": 1.5329341888427734,
      "no_speech_prob": 0.00266872625797987
    },
    {
      "id": 46,
      "seek": 20780,
      "start": 823.3140006103515,
      "end": 826.4740042724609,
      "text": " Maybe about five six years ago",
      "tokens": [
        50692,
        2704,
        466,
        1732,
        2309,
        924,
        2057,
        50850
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39974188804626465,
      "compression_ratio": 1.5329341888427734,
      "no_speech_prob": 0.00266872625797987
    },
    {
      "id": 47,
      "seek": 20780,
      "start": 827.954,
      "end": 834.6339926757812,
      "text": " No, no, no, no, not so much about four years ago. We started software architecture as a course in my university",
      "tokens": [
        50924,
        883,
        11,
        572,
        11,
        572,
        11,
        572,
        11,
        406,
        370,
        709,
        466,
        1451,
        924,
        2057,
        13,
        492,
        1409,
        4722,
        9482,
        382,
        257,
        1164,
        294,
        452,
        5454,
        51258
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39974188804626465,
      "compression_ratio": 1.5329341888427734,
      "no_speech_prob": 0.00266872625797987
    },
    {
      "id": 48,
      "seek": 20780,
      "start": 835.0739951171875,
      "end": 840.2339987792968,
      "text": " a lot of what we did and the way the curriculum was developed was based on",
      "tokens": [
        51280,
        257,
        688,
        295,
        437,
        321,
        630,
        293,
        264,
        636,
        264,
        14302,
        390,
        4743,
        390,
        2361,
        322,
        51538
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39974188804626465,
      "compression_ratio": 1.5329341888427734,
      "no_speech_prob": 0.00266872625797987
    },
    {
      "id": 49,
      "seek": 20780,
      "start": 841.1140036621093,
      "end": 842.7939963378906,
      "text": " based on",
      "tokens": [
        51582,
        2361,
        322,
        51666
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39974188804626465,
      "compression_ratio": 1.5329341888427734,
      "no_speech_prob": 0.00266872625797987
    },
    {
      "id": 50,
      "seek": 23384,
      "start": 842.7939963378906,
      "end": 848.9939932861328,
      "text": " Textbooks by people like Len Bass and Rick Caseman and so on and we used a lot of the tools and",
      "tokens": [
        50364,
        18643,
        15170,
        538,
        561,
        411,
        23009,
        29626,
        293,
        11224,
        16100,
        15023,
        293,
        370,
        322,
        293,
        321,
        1143,
        257,
        688,
        295,
        264,
        3873,
        293,
        50674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30227163434028625,
      "compression_ratio": 1.7450979948043823,
      "no_speech_prob": 0.03351727873086929
    },
    {
      "id": 51,
      "seek": 23384,
      "start": 850.7139945068359,
      "end": 854.9140067138671,
      "text": " Methodologies from the Software Engineering Institute, which I found just amazing",
      "tokens": [
        50760,
        25285,
        6204,
        490,
        264,
        27428,
        16215,
        9446,
        11,
        597,
        286,
        1352,
        445,
        2243,
        50970
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30227163434028625,
      "compression_ratio": 1.7450979948043823,
      "no_speech_prob": 0.03351727873086929
    },
    {
      "id": 52,
      "seek": 23384,
      "start": 856.1140036621093,
      "end": 863.1539969482421,
      "text": " In that process I started being involved with Excel going to Excel conferences and so on and that's how I found out about the SAQB",
      "tokens": [
        51030,
        682,
        300,
        1399,
        286,
        1409,
        885,
        3288,
        365,
        19060,
        516,
        281,
        19060,
        22032,
        293,
        370,
        322,
        293,
        300,
        311,
        577,
        286,
        1352,
        484,
        466,
        264,
        16482,
        48,
        33,
        51382
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30227163434028625,
      "compression_ratio": 1.7450979948043823,
      "no_speech_prob": 0.03351727873086929
    },
    {
      "id": 53,
      "seek": 23384,
      "start": 863.7139945068359,
      "end": 867.3940024414062,
      "text": " Once I found out about the SAQB I did training with the SAQB",
      "tokens": [
        51410,
        3443,
        286,
        1352,
        484,
        466,
        264,
        16482,
        48,
        33,
        286,
        630,
        3097,
        365,
        264,
        16482,
        48,
        33,
        51594
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30227163434028625,
      "compression_ratio": 1.7450979948043823,
      "no_speech_prob": 0.03351727873086929
    },
    {
      "id": 54,
      "seek": 23384,
      "start": 867.3940024414062,
      "end": 872.5540061035156,
      "text": " I did the CPSC and what I found was so one of the things I learned was well",
      "tokens": [
        51594,
        286,
        630,
        264,
        383,
        6273,
        34,
        293,
        437,
        286,
        1352,
        390,
        370,
        472,
        295,
        264,
        721,
        286,
        3264,
        390,
        731,
        51852
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30227163434028625,
      "compression_ratio": 1.7450979948043823,
      "no_speech_prob": 0.03351727873086929
    },
    {
      "id": 55,
      "seek": 26384,
      "start": 872.7939963378906,
      "end": 875.454,
      "text": " The experience with SEI was phenomenal",
      "tokens": [
        50364,
        440,
        1752,
        365,
        10269,
        40,
        390,
        17778,
        50497
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30619680881500244,
      "compression_ratio": 1.6888889074325562,
      "no_speech_prob": 0.0006043929606676102
    },
    {
      "id": 56,
      "seek": 26384,
      "start": 875.6740012207031,
      "end": 883.2339987792968,
      "text": " But I did realize that a lot of the work that SEI did was for really heavy mission critical systems",
      "tokens": [
        50508,
        583,
        286,
        630,
        4325,
        300,
        257,
        688,
        295,
        264,
        589,
        300,
        10269,
        40,
        630,
        390,
        337,
        534,
        4676,
        4447,
        4924,
        3652,
        50886
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30619680881500244,
      "compression_ratio": 1.6888889074325562,
      "no_speech_prob": 0.0006043929606676102
    },
    {
      "id": 57,
      "seek": 26384,
      "start": 883.2339987792968,
      "end": 886.7539877929687,
      "text": " Because you know work with the Department of Defense and government and so on",
      "tokens": [
        50886,
        1436,
        291,
        458,
        589,
        365,
        264,
        5982,
        295,
        17410,
        293,
        2463,
        293,
        370,
        322,
        51062
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30619680881500244,
      "compression_ratio": 1.6888889074325562,
      "no_speech_prob": 0.0006043929606676102
    },
    {
      "id": 58,
      "seek": 26384,
      "start": 886.954,
      "end": 891.5940146484375,
      "text": " so a lot of times the methodologies were not necessarily suitable for the types of",
      "tokens": [
        51072,
        370,
        257,
        688,
        295,
        1413,
        264,
        3170,
        6204,
        645,
        406,
        4725,
        12873,
        337,
        264,
        3467,
        295,
        51304
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30619680881500244,
      "compression_ratio": 1.6888889074325562,
      "no_speech_prob": 0.0006043929606676102
    },
    {
      "id": 59,
      "seek": 26384,
      "start": 892.3940024414062,
      "end": 895.0339865722656,
      "text": " the types of industries that the students went into",
      "tokens": [
        51344,
        264,
        3467,
        295,
        13284,
        300,
        264,
        1731,
        1437,
        666,
        51476
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30619680881500244,
      "compression_ratio": 1.6888889074325562,
      "no_speech_prob": 0.0006043929606676102
    },
    {
      "id": 60,
      "seek": 26384,
      "start": 895.193990234375,
      "end": 900.5540061035156,
      "text": " But the principles were always relevant and so we'd have to tweak things to match these smaller projects",
      "tokens": [
        51484,
        583,
        264,
        9156,
        645,
        1009,
        7340,
        293,
        370,
        321,
        1116,
        362,
        281,
        29879,
        721,
        281,
        2995,
        613,
        4356,
        4455,
        51752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30619680881500244,
      "compression_ratio": 1.6888889074325562,
      "no_speech_prob": 0.0006043929606676102
    },
    {
      "id": 61,
      "seek": 29160,
      "start": 900.8740134277343,
      "end": 903.5139975585937,
      "text": " When I got introduced to ARC 42 and",
      "tokens": [
        50380,
        1133,
        286,
        658,
        7268,
        281,
        8943,
        34,
        14034,
        293,
        50512
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2857323884963989,
      "compression_ratio": 1.7447699308395386,
      "no_speech_prob": 0.003282163990661502
    },
    {
      "id": 62,
      "seek": 29160,
      "start": 904.0339865722656,
      "end": 911.5940146484375,
      "text": " I saw the methodology and the different views the four simple views and the way that ARC 42 documentation was set up",
      "tokens": [
        50538,
        286,
        1866,
        264,
        24850,
        293,
        264,
        819,
        6809,
        264,
        1451,
        2199,
        6809,
        293,
        264,
        636,
        300,
        8943,
        34,
        14034,
        14333,
        390,
        992,
        493,
        50916
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2857323884963989,
      "compression_ratio": 1.7447699308395386,
      "no_speech_prob": 0.003282163990661502
    },
    {
      "id": 63,
      "seek": 29160,
      "start": 911.5940146484375,
      "end": 918.2339987792968,
      "text": " I decided to start incorporating that into our course and at the same time the students were being exposed to the CPSC of training as well",
      "tokens": [
        50916,
        286,
        3047,
        281,
        722,
        33613,
        300,
        666,
        527,
        1164,
        293,
        412,
        264,
        912,
        565,
        264,
        1731,
        645,
        885,
        9495,
        281,
        264,
        383,
        6273,
        34,
        295,
        3097,
        382,
        731,
        51248
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2857323884963989,
      "compression_ratio": 1.7447699308395386,
      "no_speech_prob": 0.003282163990661502
    },
    {
      "id": 64,
      "seek": 29160,
      "start": 919.0739951171875,
      "end": 926.9139914550781,
      "text": " But once I started doing that the difficulty level for documentation went down significantly for the students ARC 42 presents",
      "tokens": [
        51290,
        583,
        1564,
        286,
        1409,
        884,
        300,
        264,
        10360,
        1496,
        337,
        14333,
        1437,
        760,
        10591,
        337,
        264,
        1731,
        8943,
        34,
        14034,
        13533,
        51682
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2857323884963989,
      "compression_ratio": 1.7447699308395386,
      "no_speech_prob": 0.003282163990661502
    },
    {
      "id": 65,
      "seek": 31796,
      "start": 927.4340109863281,
      "end": 932.3139853515625,
      "text": " Exactly what they needed for the types of business projects that they were more likely to be solving",
      "tokens": [
        50390,
        7587,
        437,
        436,
        2978,
        337,
        264,
        3467,
        295,
        1606,
        4455,
        300,
        436,
        645,
        544,
        3700,
        281,
        312,
        12606,
        50634
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32005423307418823,
      "compression_ratio": 1.542307734489441,
      "no_speech_prob": 0.012608103454113007
    },
    {
      "id": 66,
      "seek": 31796,
      "start": 932.9940085449218,
      "end": 935.5139975585937,
      "text": " it's easier for them to understand the",
      "tokens": [
        50668,
        309,
        311,
        3571,
        337,
        552,
        281,
        1223,
        264,
        50794
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32005423307418823,
      "compression_ratio": 1.542307734489441,
      "no_speech_prob": 0.012608103454113007
    },
    {
      "id": 67,
      "seek": 31796,
      "start": 936.1140036621093,
      "end": 942.8340048828125,
      "text": " Learning curve was a lot less steep and I didn't have to spend quite as much time clarifying what different sections meant",
      "tokens": [
        50824,
        15205,
        7605,
        390,
        257,
        688,
        1570,
        16841,
        293,
        286,
        994,
        380,
        362,
        281,
        3496,
        1596,
        382,
        709,
        565,
        6093,
        5489,
        437,
        819,
        10863,
        4140,
        51160
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32005423307418823,
      "compression_ratio": 1.542307734489441,
      "no_speech_prob": 0.012608103454113007
    },
    {
      "id": 68,
      "seek": 31796,
      "start": 943.1140036621093,
      "end": 945.3139853515625,
      "text": " So that was a good transition for us",
      "tokens": [
        51174,
        407,
        300,
        390,
        257,
        665,
        6034,
        337,
        505,
        51284
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32005423307418823,
      "compression_ratio": 1.542307734489441,
      "no_speech_prob": 0.012608103454113007
    },
    {
      "id": 69,
      "seek": 31796,
      "start": 945.8740134277343,
      "end": 953.7539877929687,
      "text": " That's great to hear. So my experience is that LLM the Gen AI already knows about ARC 42 because it's",
      "tokens": [
        51312,
        663,
        311,
        869,
        281,
        1568,
        13,
        407,
        452,
        1752,
        307,
        300,
        441,
        43,
        44,
        264,
        3632,
        7318,
        1217,
        3255,
        466,
        8943,
        34,
        14034,
        570,
        309,
        311,
        51706
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32005423307418823,
      "compression_ratio": 1.542307734489441,
      "no_speech_prob": 0.012608103454113007
    },
    {
      "id": 70,
      "seek": 34480,
      "start": 954.1140036621093,
      "end": 958.3539938964843,
      "text": " Open-source it exists for now 20 years. It's in the training data",
      "tokens": [
        50382,
        7238,
        12,
        41676,
        309,
        8198,
        337,
        586,
        945,
        924,
        13,
        467,
        311,
        294,
        264,
        3097,
        1412,
        50594
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4479522705078125,
      "compression_ratio": 1.464455008506775,
      "no_speech_prob": 0.005463914945721626
    },
    {
      "id": 71,
      "seek": 34480,
      "start": 960.3539938964843,
      "end": 962.954,
      "text": " In what format do you",
      "tokens": [
        50694,
        682,
        437,
        7877,
        360,
        291,
        50824
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4479522705078125,
      "compression_ratio": 1.464455008506775,
      "no_speech_prob": 0.005463914945721626
    },
    {
      "id": 72,
      "seek": 34480,
      "start": 963.954,
      "end": 967.3139853515625,
      "text": " Document the architecture. Do you use a DOCSIS code approach?",
      "tokens": [
        50874,
        37684,
        264,
        9482,
        13,
        1144,
        291,
        764,
        257,
        10699,
        26283,
        2343,
        3089,
        3109,
        30,
        51042
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4479522705078125,
      "compression_ratio": 1.464455008506775,
      "no_speech_prob": 0.005463914945721626
    },
    {
      "id": 73,
      "seek": 34480,
      "start": 968.3940024414062,
      "end": 971.4340109863281,
      "text": " Markdown or do you use Word or wiki?",
      "tokens": [
        51096,
        3934,
        5093,
        420,
        360,
        291,
        764,
        8725,
        420,
        261,
        9850,
        30,
        51248
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4479522705078125,
      "compression_ratio": 1.464455008506775,
      "no_speech_prob": 0.005463914945721626
    },
    {
      "id": 74,
      "seek": 34480,
      "start": 971.954,
      "end": 976.4739890136718,
      "text": " Right. No, we just use Word or I might use a latex template for it",
      "tokens": [
        51274,
        1779,
        13,
        883,
        11,
        321,
        445,
        764,
        8725,
        420,
        286,
        1062,
        764,
        257,
        3469,
        87,
        12379,
        337,
        309,
        51500
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4479522705078125,
      "compression_ratio": 1.464455008506775,
      "no_speech_prob": 0.005463914945721626
    },
    {
      "id": 75,
      "seek": 34480,
      "start": 976.4739890136718,
      "end": 978.7939963378906,
      "text": " But for right now the students are using Microsoft Word",
      "tokens": [
        51500,
        583,
        337,
        558,
        586,
        264,
        1731,
        366,
        1228,
        8116,
        8725,
        51616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4479522705078125,
      "compression_ratio": 1.464455008506775,
      "no_speech_prob": 0.005463914945721626
    },
    {
      "id": 76,
      "seek": 36984,
      "start": 979.2339987792968,
      "end": 986.3139853515625,
      "text": " Okay, and as I understood the students writes a documentation with the help of AI not AI",
      "tokens": [
        50386,
        1033,
        11,
        293,
        382,
        286,
        7320,
        264,
        1731,
        13657,
        257,
        14333,
        365,
        264,
        854,
        295,
        7318,
        406,
        7318,
        50740
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3238238990306854,
      "compression_ratio": 1.6007604598999023,
      "no_speech_prob": 0.005353795830160379
    },
    {
      "id": 77,
      "seek": 36984,
      "start": 986.714009765625,
      "end": 992.193990234375,
      "text": " Right. Absolutely. So not only in terms of writing a documentation, but for the last two years",
      "tokens": [
        50760,
        1779,
        13,
        7021,
        13,
        407,
        406,
        787,
        294,
        2115,
        295,
        3579,
        257,
        14333,
        11,
        457,
        337,
        264,
        1036,
        732,
        924,
        51034
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3238238990306854,
      "compression_ratio": 1.6007604598999023,
      "no_speech_prob": 0.005353795830160379
    },
    {
      "id": 78,
      "seek": 36984,
      "start": 992.3139853515625,
      "end": 996.954,
      "text": " I have been encouraging the students to use AI and use LLMs",
      "tokens": [
        51040,
        286,
        362,
        668,
        14580,
        264,
        1731,
        281,
        764,
        7318,
        293,
        764,
        441,
        43,
        26386,
        51272
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3238238990306854,
      "compression_ratio": 1.6007604598999023,
      "no_speech_prob": 0.005353795830160379
    },
    {
      "id": 79,
      "seek": 36984,
      "start": 997.0339865722656,
      "end": 1002.8340048828125,
      "text": " so when the explosion of chat GPT and all these things came around for",
      "tokens": [
        51276,
        370,
        562,
        264,
        15673,
        295,
        5081,
        26039,
        51,
        293,
        439,
        613,
        721,
        1361,
        926,
        337,
        51566
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3238238990306854,
      "compression_ratio": 1.6007604598999023,
      "no_speech_prob": 0.005353795830160379
    },
    {
      "id": 80,
      "seek": 36984,
      "start": 1003.193990234375,
      "end": 1008.3139853515625,
      "text": " Universities for schools in general for education. It was a little bit jolting because no you're wondering",
      "tokens": [
        51584,
        14052,
        1088,
        337,
        4656,
        294,
        2674,
        337,
        3309,
        13,
        467,
        390,
        257,
        707,
        857,
        361,
        401,
        783,
        570,
        572,
        291,
        434,
        6359,
        51840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3238238990306854,
      "compression_ratio": 1.6007604598999023,
      "no_speech_prob": 0.005353795830160379
    },
    {
      "id": 81,
      "seek": 39984,
      "start": 1008.7939963378906,
      "end": 1014.4340109863281,
      "text": " Are my students really learning is the work that they're giving me their work. So about two years ago",
      "tokens": [
        50364,
        2014,
        452,
        1731,
        534,
        2539,
        307,
        264,
        589,
        300,
        436,
        434,
        2902,
        385,
        641,
        589,
        13,
        407,
        466,
        732,
        924,
        2057,
        50646
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2749364674091339,
      "compression_ratio": 1.6696832180023193,
      "no_speech_prob": 0.0008774980087764561
    },
    {
      "id": 82,
      "seek": 39984,
      "start": 1014.4340109863281,
      "end": 1021.714009765625,
      "text": " I realized that this was not going to disappear. So I had to find a way to incorporate this into my teaching",
      "tokens": [
        50646,
        286,
        5334,
        300,
        341,
        390,
        406,
        516,
        281,
        11596,
        13,
        407,
        286,
        632,
        281,
        915,
        257,
        636,
        281,
        16091,
        341,
        666,
        452,
        4571,
        51010
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2749364674091339,
      "compression_ratio": 1.6696832180023193,
      "no_speech_prob": 0.0008774980087764561
    },
    {
      "id": 83,
      "seek": 39984,
      "start": 1022.0339865722656,
      "end": 1025.4739890136718,
      "text": " So the fact is that when they're going to the industry",
      "tokens": [
        51026,
        407,
        264,
        1186,
        307,
        300,
        562,
        436,
        434,
        516,
        281,
        264,
        3518,
        51198
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2749364674091339,
      "compression_ratio": 1.6696832180023193,
      "no_speech_prob": 0.0008774980087764561
    },
    {
      "id": 84,
      "seek": 39984,
      "start": 1027.714009765625,
      "end": 1033.4739890136718,
      "text": " They will have all these tools available to them so I needed them I've always when I'm teaching courses",
      "tokens": [
        51310,
        814,
        486,
        362,
        439,
        613,
        3873,
        2435,
        281,
        552,
        370,
        286,
        2978,
        552,
        286,
        600,
        1009,
        562,
        286,
        478,
        4571,
        7712,
        51598
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2749364674091339,
      "compression_ratio": 1.6696832180023193,
      "no_speech_prob": 0.0008774980087764561
    },
    {
      "id": 85,
      "seek": 42452,
      "start": 1033.4739890136718,
      "end": 1040.9940085449218,
      "text": " I want as much as possible for the students to function the way that they're going to function in the industry. So I",
      "tokens": [
        50364,
        286,
        528,
        382,
        709,
        382,
        1944,
        337,
        264,
        1731,
        281,
        2445,
        264,
        636,
        300,
        436,
        434,
        516,
        281,
        2445,
        294,
        264,
        3518,
        13,
        407,
        286,
        50740
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24359130859375,
      "compression_ratio": 1.7628458738327026,
      "no_speech_prob": 0.027405206114053726
    },
    {
      "id": 86,
      "seek": 42452,
      "start": 1042.2740073242187,
      "end": 1045.0739951171875,
      "text": " Wanted them to start using the LLMs so I'd create",
      "tokens": [
        50804,
        11773,
        292,
        552,
        281,
        722,
        1228,
        264,
        441,
        43,
        26386,
        370,
        286,
        1116,
        1884,
        50944
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24359130859375,
      "compression_ratio": 1.7628458738327026,
      "no_speech_prob": 0.027405206114053726
    },
    {
      "id": 87,
      "seek": 42452,
      "start": 1046.7539877929687,
      "end": 1051.913991455078,
      "text": " Activities on on the virtual learning environment that would require them to use the LLM",
      "tokens": [
        51028,
        28550,
        1088,
        322,
        322,
        264,
        6374,
        2539,
        2823,
        300,
        576,
        3651,
        552,
        281,
        764,
        264,
        441,
        43,
        44,
        51286
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24359130859375,
      "compression_ratio": 1.7628458738327026,
      "no_speech_prob": 0.027405206114053726
    },
    {
      "id": 88,
      "seek": 42452,
      "start": 1051.9940085449218,
      "end": 1058.434010986328,
      "text": " So maybe I remember one of the first things I did was I gave them a small projects. This is not for grades",
      "tokens": [
        51290,
        407,
        1310,
        286,
        1604,
        472,
        295,
        264,
        700,
        721,
        286,
        630,
        390,
        286,
        2729,
        552,
        257,
        1359,
        4455,
        13,
        639,
        307,
        406,
        337,
        18041,
        51612
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24359130859375,
      "compression_ratio": 1.7628458738327026,
      "no_speech_prob": 0.027405206114053726
    },
    {
      "id": 89,
      "seek": 42452,
      "start": 1058.434010986328,
      "end": 1062.9940085449218,
      "text": " This is just I just wanted to see what would happen. So I gave them a small project",
      "tokens": [
        51612,
        639,
        307,
        445,
        286,
        445,
        1415,
        281,
        536,
        437,
        576,
        1051,
        13,
        407,
        286,
        2729,
        552,
        257,
        1359,
        1716,
        51840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24359130859375,
      "compression_ratio": 1.7628458738327026,
      "no_speech_prob": 0.027405206114053726
    },
    {
      "id": 90,
      "seek": 45404,
      "start": 1062.9940085449218,
      "end": 1064.913991455078,
      "text": " it was on the LLM and it's a",
      "tokens": [
        50364,
        309,
        390,
        322,
        264,
        441,
        43,
        44,
        293,
        309,
        311,
        257,
        50460
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3769972324371338,
      "compression_ratio": 1.6218905448913574,
      "no_speech_prob": 0.009670802392065525
    },
    {
      "id": 91,
      "seek": 45404,
      "start": 1064.913991455078,
      "end": 1071.714009765625,
      "text": " You know, they just share what their experience was. And so it's like a discussion forum. So they had to identify",
      "tokens": [
        50460,
        509,
        458,
        11,
        436,
        445,
        2073,
        437,
        641,
        1752,
        390,
        13,
        400,
        370,
        309,
        311,
        411,
        257,
        5017,
        17542,
        13,
        407,
        436,
        632,
        281,
        5876,
        50800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3769972324371338,
      "compression_ratio": 1.6218905448913574,
      "no_speech_prob": 0.009670802392065525
    },
    {
      "id": 92,
      "seek": 45404,
      "start": 1072.954,
      "end": 1077.193990234375,
      "text": " quality remote data the four top quality requirements and",
      "tokens": [
        50862,
        3125,
        8607,
        1412,
        264,
        1451,
        1192,
        3125,
        7728,
        293,
        51074
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3769972324371338,
      "compression_ratio": 1.6218905448913574,
      "no_speech_prob": 0.009670802392065525
    },
    {
      "id": 93,
      "seek": 45404,
      "start": 1077.9940085449218,
      "end": 1081.3539938964843,
      "text": " You know write them in such a way that they are measurable",
      "tokens": [
        51114,
        509,
        458,
        2464,
        552,
        294,
        1270,
        257,
        636,
        300,
        436,
        366,
        43615,
        51282
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3769972324371338,
      "compression_ratio": 1.6218905448913574,
      "no_speech_prob": 0.009670802392065525
    },
    {
      "id": 94,
      "seek": 45404,
      "start": 1081.5940146484375,
      "end": 1086.913991455078,
      "text": " so they have a response and response measure and the six parts and",
      "tokens": [
        51294,
        370,
        436,
        362,
        257,
        4134,
        293,
        4134,
        3481,
        293,
        264,
        2309,
        3166,
        293,
        51560
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3769972324371338,
      "compression_ratio": 1.6218905448913574,
      "no_speech_prob": 0.009670802392065525
    },
    {
      "id": 95,
      "seek": 47796,
      "start": 1087.913991455078,
      "end": 1093.8340048828125,
      "text": " Then they did that and then the other part of exercise was to ask the LLM to do it and compare the results",
      "tokens": [
        50414,
        1396,
        436,
        630,
        300,
        293,
        550,
        264,
        661,
        644,
        295,
        5380,
        390,
        281,
        1029,
        264,
        441,
        43,
        44,
        281,
        360,
        309,
        293,
        6794,
        264,
        3542,
        50710
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2955286502838135,
      "compression_ratio": 1.6570048332214355,
      "no_speech_prob": 0.007199855986982584
    },
    {
      "id": 96,
      "seek": 47796,
      "start": 1093.8340048828125,
      "end": 1101.1540122070312,
      "text": " So that was the first step to bringing LLMs into the experience that the students had in the classroom",
      "tokens": [
        50710,
        407,
        300,
        390,
        264,
        700,
        1823,
        281,
        5062,
        441,
        43,
        26386,
        666,
        264,
        1752,
        300,
        264,
        1731,
        632,
        294,
        264,
        7419,
        51076
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2955286502838135,
      "compression_ratio": 1.6570048332214355,
      "no_speech_prob": 0.007199855986982584
    },
    {
      "id": 97,
      "seek": 47796,
      "start": 1101.1540122070312,
      "end": 1105.0739951171875,
      "text": " And so little by little all the different aspects of the course",
      "tokens": [
        51076,
        400,
        370,
        707,
        538,
        707,
        439,
        264,
        819,
        7270,
        295,
        264,
        1164,
        51272
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2955286502838135,
      "compression_ratio": 1.6570048332214355,
      "no_speech_prob": 0.007199855986982584
    },
    {
      "id": 98,
      "seek": 47796,
      "start": 1105.0739951171875,
      "end": 1109.5540061035156,
      "text": " I encouraged them to utilize the LLM and to be honest about their use",
      "tokens": [
        51272,
        286,
        14658,
        552,
        281,
        16117,
        264,
        441,
        43,
        44,
        293,
        281,
        312,
        3245,
        466,
        641,
        764,
        51496
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2955286502838135,
      "compression_ratio": 1.6570048332214355,
      "no_speech_prob": 0.007199855986982584
    },
    {
      "id": 99,
      "seek": 50060,
      "start": 1110.1140036621093,
      "end": 1115.7539877929687,
      "text": " Document what they did not like try to pretend that oh I did this on my own by you",
      "tokens": [
        50392,
        37684,
        437,
        436,
        630,
        406,
        411,
        853,
        281,
        11865,
        300,
        1954,
        286,
        630,
        341,
        322,
        452,
        1065,
        538,
        291,
        50674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33555686473846436,
      "compression_ratio": 1.6017316579818726,
      "no_speech_prob": 0.26169657707214355
    },
    {
      "id": 100,
      "seek": 50060,
      "start": 1115.7539877929687,
      "end": 1119.714009765625,
      "text": " But you know in secret I use the LLM and I found that with that transparency",
      "tokens": [
        50674,
        583,
        291,
        458,
        294,
        4054,
        286,
        764,
        264,
        441,
        43,
        44,
        293,
        286,
        1352,
        300,
        365,
        300,
        1145,
        79,
        4484,
        1344,
        50872
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33555686473846436,
      "compression_ratio": 1.6017316579818726,
      "no_speech_prob": 0.26169657707214355
    },
    {
      "id": 101,
      "seek": 50060,
      "start": 1119.714009765625,
      "end": 1122.714009765625,
      "text": " I learned a lot and the students learned we learn more",
      "tokens": [
        50872,
        286,
        3264,
        257,
        688,
        293,
        264,
        1731,
        3264,
        321,
        1466,
        544,
        51022
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33555686473846436,
      "compression_ratio": 1.6017316579818726,
      "no_speech_prob": 0.26169657707214355
    },
    {
      "id": 102,
      "seek": 50060,
      "start": 1123.2740073242187,
      "end": 1124.3540244140625,
      "text": " by",
      "tokens": [
        51050,
        538,
        51104
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33555686473846436,
      "compression_ratio": 1.6017316579818726,
      "no_speech_prob": 0.26169657707214355
    },
    {
      "id": 103,
      "seek": 50060,
      "start": 1124.3540244140625,
      "end": 1127.714009765625,
      "text": " Working with LLMs and being transparent about it. I",
      "tokens": [
        51104,
        18337,
        365,
        441,
        43,
        26386,
        293,
        885,
        12737,
        466,
        309,
        13,
        286,
        51272
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33555686473846436,
      "compression_ratio": 1.6017316579818726,
      "no_speech_prob": 0.26169657707214355
    },
    {
      "id": 104,
      "seek": 50060,
      "start": 1128.7539877929687,
      "end": 1133.8739829101562,
      "text": " Think it's a good approach. I remember my own studies where I",
      "tokens": [
        51324,
        6557,
        309,
        311,
        257,
        665,
        3109,
        13,
        286,
        1604,
        452,
        1065,
        5313,
        689,
        286,
        51580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33555686473846436,
      "compression_ratio": 1.6017316579818726,
      "no_speech_prob": 0.26169657707214355
    },
    {
      "id": 105,
      "seek": 50060,
      "start": 1134.43398046875,
      "end": 1137.234029296875,
      "text": " was not allowed to quote Wikipedia and",
      "tokens": [
        51608,
        390,
        406,
        4350,
        281,
        6513,
        28999,
        293,
        51748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33555686473846436,
      "compression_ratio": 1.6017316579818726,
      "no_speech_prob": 0.26169657707214355
    },
    {
      "id": 106,
      "seek": 52828,
      "start": 1137.9140219726562,
      "end": 1144.8739829101562,
      "text": " This changed and now it's changing again that people use AI and it really makes sense",
      "tokens": [
        50398,
        639,
        3105,
        293,
        586,
        309,
        311,
        4473,
        797,
        300,
        561,
        764,
        7318,
        293,
        309,
        534,
        1669,
        2020,
        50746
      ],
      "temperature": 0.0,
      "avg_logprob": -0.314007043838501,
      "compression_ratio": 1.5627706050872803,
      "no_speech_prob": 0.003314474830403924
    },
    {
      "id": 107,
      "seek": 52828,
      "start": 1145.954,
      "end": 1151.7539877929687,
      "text": " Another question. What do you use for the diagrams in the architecture? Okay. So right now I",
      "tokens": [
        50800,
        3996,
        1168,
        13,
        708,
        360,
        291,
        764,
        337,
        264,
        36709,
        294,
        264,
        9482,
        30,
        1033,
        13,
        407,
        558,
        586,
        286,
        51090
      ],
      "temperature": 0.0,
      "avg_logprob": -0.314007043838501,
      "compression_ratio": 1.5627706050872803,
      "no_speech_prob": 0.003314474830403924
    },
    {
      "id": 108,
      "seek": 52828,
      "start": 1152.2740073242187,
      "end": 1157.9939780273437,
      "text": " Like star UML. There's a tool called star UML used to be free. It's not free anymore, but it's really simple",
      "tokens": [
        51116,
        1743,
        3543,
        624,
        12683,
        13,
        821,
        311,
        257,
        2290,
        1219,
        3543,
        624,
        12683,
        1143,
        281,
        312,
        1737,
        13,
        467,
        311,
        406,
        1737,
        3602,
        11,
        457,
        309,
        311,
        534,
        2199,
        51402
      ],
      "temperature": 0.0,
      "avg_logprob": -0.314007043838501,
      "compression_ratio": 1.5627706050872803,
      "no_speech_prob": 0.003314474830403924
    },
    {
      "id": 109,
      "seek": 52828,
      "start": 1158.9939780273437,
      "end": 1163.9140219726562,
      "text": " So we use a lot of you and well a lot of our software engineering courses",
      "tokens": [
        51452,
        407,
        321,
        764,
        257,
        688,
        295,
        291,
        293,
        731,
        257,
        688,
        295,
        527,
        4722,
        7043,
        7712,
        51698
      ],
      "temperature": 0.0,
      "avg_logprob": -0.314007043838501,
      "compression_ratio": 1.5627706050872803,
      "no_speech_prob": 0.003314474830403924
    },
    {
      "id": 110,
      "seek": 55496,
      "start": 1163.9140219726562,
      "end": 1166.8739829101562,
      "text": " We incorporate UML a lot. And so we do use",
      "tokens": [
        50364,
        492,
        16091,
        624,
        12683,
        257,
        688,
        13,
        400,
        370,
        321,
        360,
        764,
        50512
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3104315996170044,
      "compression_ratio": 1.6530612707138062,
      "no_speech_prob": 0.008451790548861027
    },
    {
      "id": 111,
      "seek": 55496,
      "start": 1168.234029296875,
      "end": 1171.954,
      "text": " Star UML for that. However students use a number of different tools",
      "tokens": [
        50580,
        5705,
        624,
        12683,
        337,
        300,
        13,
        2908,
        1731,
        764,
        257,
        1230,
        295,
        819,
        3873,
        50766
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3104315996170044,
      "compression_ratio": 1.6530612707138062,
      "no_speech_prob": 0.008451790548861027
    },
    {
      "id": 112,
      "seek": 55496,
      "start": 1172.6339926757812,
      "end": 1174.234029296875,
      "text": " students use",
      "tokens": [
        50800,
        1731,
        764,
        50880
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3104315996170044,
      "compression_ratio": 1.6530612707138062,
      "no_speech_prob": 0.008451790548861027
    },
    {
      "id": 113,
      "seek": 55496,
      "start": 1174.234029296875,
      "end": 1176.47401953125,
      "text": " Lucid draw they use a lot of drawing tools",
      "tokens": [
        50880,
        9593,
        327,
        2642,
        436,
        764,
        257,
        688,
        295,
        6316,
        3873,
        50992
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3104315996170044,
      "compression_ratio": 1.6530612707138062,
      "no_speech_prob": 0.008451790548861027
    },
    {
      "id": 114,
      "seek": 55496,
      "start": 1176.714009765625,
      "end": 1181.7940268554687,
      "text": " Try to discourage them from using drawing tools because the semantics are not there. You don't get as much",
      "tokens": [
        51004,
        6526,
        281,
        21497,
        609,
        552,
        490,
        1228,
        6316,
        3873,
        570,
        264,
        4361,
        45298,
        366,
        406,
        456,
        13,
        509,
        500,
        380,
        483,
        382,
        709,
        51258
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3104315996170044,
      "compression_ratio": 1.6530612707138062,
      "no_speech_prob": 0.008451790548861027
    },
    {
      "id": 115,
      "seek": 55496,
      "start": 1182.3940024414062,
      "end": 1186.3540244140625,
      "text": " Feedback from the system. So right now in terms of",
      "tokens": [
        51288,
        33720,
        3207,
        490,
        264,
        1185,
        13,
        407,
        558,
        586,
        294,
        2115,
        295,
        51486
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3104315996170044,
      "compression_ratio": 1.6530612707138062,
      "no_speech_prob": 0.008451790548861027
    },
    {
      "id": 116,
      "seek": 55496,
      "start": 1187.234029296875,
      "end": 1191.3540244140625,
      "text": " Accessibility and affordability star UML is what we use for a lot of our courses",
      "tokens": [
        51530,
        17166,
        2841,
        293,
        6157,
        2310,
        3543,
        624,
        12683,
        307,
        437,
        321,
        764,
        337,
        257,
        688,
        295,
        527,
        7712,
        51736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3104315996170044,
      "compression_ratio": 1.6530612707138062,
      "no_speech_prob": 0.008451790548861027
    },
    {
      "id": 117,
      "seek": 58240,
      "start": 1191.8340048828125,
      "end": 1195.9939780273437,
      "text": " Of course, there are diagrams for example when students want to describe",
      "tokens": [
        50388,
        2720,
        1164,
        11,
        456,
        366,
        36709,
        337,
        1365,
        562,
        1731,
        528,
        281,
        6786,
        50596
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3772530257701874,
      "compression_ratio": 1.621848702430725,
      "no_speech_prob": 0.006200908683240414
    },
    {
      "id": 118,
      "seek": 58240,
      "start": 1197.1139731445312,
      "end": 1200.6339926757812,
      "text": " Cloud-based deployments or they want to talk about containerization",
      "tokens": [
        50652,
        8061,
        12,
        6032,
        7274,
        1117,
        420,
        436,
        528,
        281,
        751,
        466,
        10129,
        2144,
        50828
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3772530257701874,
      "compression_ratio": 1.621848702430725,
      "no_speech_prob": 0.006200908683240414
    },
    {
      "id": 119,
      "seek": 58240,
      "start": 1201.43398046875,
      "end": 1203.43398046875,
      "text": " UML is not really quite as",
      "tokens": [
        50868,
        624,
        12683,
        307,
        406,
        534,
        1596,
        382,
        50968
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3772530257701874,
      "compression_ratio": 1.621848702430725,
      "no_speech_prob": 0.006200908683240414
    },
    {
      "id": 120,
      "seek": 58240,
      "start": 1204.6339926757812,
      "end": 1210.0739951171875,
      "text": " amenable to that situation and so I encourage them for software architecture when when we do",
      "tokens": [
        51028,
        18497,
        712,
        281,
        300,
        2590,
        293,
        370,
        286,
        5373,
        552,
        337,
        4722,
        9482,
        562,
        562,
        321,
        360,
        51300
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3772530257701874,
      "compression_ratio": 1.621848702430725,
      "no_speech_prob": 0.006200908683240414
    },
    {
      "id": 121,
      "seek": 58240,
      "start": 1210.714009765625,
      "end": 1214.47401953125,
      "text": " Object-oriented design course will focus on UML. But for this course, I",
      "tokens": [
        51332,
        24753,
        12,
        27414,
        1715,
        1164,
        486,
        1879,
        322,
        624,
        12683,
        13,
        583,
        337,
        341,
        1164,
        11,
        286,
        51520
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3772530257701874,
      "compression_ratio": 1.621848702430725,
      "no_speech_prob": 0.006200908683240414
    },
    {
      "id": 122,
      "seek": 58240,
      "start": 1214.9939780273437,
      "end": 1217.1139731445312,
      "text": " Encourage them to use whatever tools they want to use",
      "tokens": [
        51546,
        29584,
        44720,
        552,
        281,
        764,
        2035,
        3873,
        436,
        528,
        281,
        764,
        51652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3772530257701874,
      "compression_ratio": 1.621848702430725,
      "no_speech_prob": 0.006200908683240414
    },
    {
      "id": 123,
      "seek": 60816,
      "start": 1217.673970703125,
      "end": 1221.1139731445312,
      "text": " So any tools and then recently I realized that",
      "tokens": [
        50392,
        407,
        604,
        3873,
        293,
        550,
        3938,
        286,
        5334,
        300,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34512996673583984,
      "compression_ratio": 1.6492891311645508,
      "no_speech_prob": 0.05456581711769104
    },
    {
      "id": 124,
      "seek": 60816,
      "start": 1221.9939780273437,
      "end": 1228.1139731445312,
      "text": " Well, I've always experimented with diagrams and LLMs. So I'll create diagrams then upload them to",
      "tokens": [
        50608,
        1042,
        11,
        286,
        600,
        1009,
        5120,
        292,
        365,
        36709,
        293,
        441,
        43,
        26386,
        13,
        407,
        286,
        603,
        1884,
        36709,
        550,
        6580,
        552,
        281,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34512996673583984,
      "compression_ratio": 1.6492891311645508,
      "no_speech_prob": 0.05456581711769104
    },
    {
      "id": 125,
      "seek": 60816,
      "start": 1228.9140219726562,
      "end": 1234.0739951171875,
      "text": " The LLM and see whether or not it really understands. So the first thing I started with was",
      "tokens": [
        50954,
        440,
        441,
        43,
        44,
        293,
        536,
        1968,
        420,
        406,
        309,
        534,
        15146,
        13,
        407,
        264,
        700,
        551,
        286,
        1409,
        365,
        390,
        51212
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34512996673583984,
      "compression_ratio": 1.6492891311645508,
      "no_speech_prob": 0.05456581711769104
    },
    {
      "id": 126,
      "seek": 60816,
      "start": 1234.5940146484375,
      "end": 1239.5539755859375,
      "text": " Use case diagrams and to see if it could write user stories for me",
      "tokens": [
        51238,
        8278,
        1389,
        36709,
        293,
        281,
        536,
        498,
        309,
        727,
        2464,
        4195,
        3676,
        337,
        385,
        51486
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34512996673583984,
      "compression_ratio": 1.6492891311645508,
      "no_speech_prob": 0.05456581711769104
    },
    {
      "id": 127,
      "seek": 60816,
      "start": 1240.1540122070312,
      "end": 1244.43398046875,
      "text": " So you upload is a diagram image to the LLM",
      "tokens": [
        51516,
        407,
        291,
        6580,
        307,
        257,
        10686,
        3256,
        281,
        264,
        441,
        43,
        44,
        51730
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34512996673583984,
      "compression_ratio": 1.6492891311645508,
      "no_speech_prob": 0.05456581711769104
    },
    {
      "id": 128,
      "seek": 63548,
      "start": 1244.43398046875,
      "end": 1251.8340048828125,
      "text": " Yes, and then see if and it did understand what the use case diagram was about and in one case it actually",
      "tokens": [
        50364,
        1079,
        11,
        293,
        550,
        536,
        498,
        293,
        309,
        630,
        1223,
        437,
        264,
        764,
        1389,
        10686,
        390,
        466,
        293,
        294,
        472,
        1389,
        309,
        767,
        50734
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3726429045200348,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.012331466190516949
    },
    {
      "id": 129,
      "seek": 63548,
      "start": 1252.7539877929687,
      "end": 1259.6339926757812,
      "text": " Suggested a missing use case and then it tried to modify the diagram, but this was quite some time ago",
      "tokens": [
        50780,
        39131,
        2629,
        292,
        257,
        5361,
        764,
        1389,
        293,
        550,
        309,
        3031,
        281,
        16927,
        264,
        10686,
        11,
        457,
        341,
        390,
        1596,
        512,
        565,
        2057,
        51124
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3726429045200348,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.012331466190516949
    },
    {
      "id": 130,
      "seek": 63548,
      "start": 1259.6339926757812,
      "end": 1264.673970703125,
      "text": " No, I have found that using know a phone that the software architects app",
      "tokens": [
        51124,
        883,
        11,
        286,
        362,
        1352,
        300,
        1228,
        458,
        257,
        2593,
        300,
        264,
        4722,
        30491,
        724,
        51376
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3726429045200348,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.012331466190516949
    },
    {
      "id": 131,
      "seek": 63548,
      "start": 1265.234029296875,
      "end": 1267.234029296875,
      "text": " application",
      "tokens": [
        51404,
        3861,
        51504
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3726429045200348,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.012331466190516949
    },
    {
      "id": 132,
      "seek": 63548,
      "start": 1267.3540244140625,
      "end": 1269.1139731445312,
      "text": " It's even more dynamic than that",
      "tokens": [
        51510,
        467,
        311,
        754,
        544,
        8546,
        813,
        300,
        51598
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3726429045200348,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.012331466190516949
    },
    {
      "id": 133,
      "seek": 66016,
      "start": 1269.2740073242187,
      "end": 1273.3940024414062,
      "text": " So you can describe your use cases or",
      "tokens": [
        50372,
        407,
        291,
        393,
        6786,
        428,
        764,
        3331,
        420,
        50578
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32925713062286377,
      "compression_ratio": 1.7685589790344238,
      "no_speech_prob": 0.19930878281593323
    },
    {
      "id": 134,
      "seek": 66016,
      "start": 1273.9140219726562,
      "end": 1279.3139853515625,
      "text": " Describe a sequence diagram or describe a component diagram and it generates code mermaid code",
      "tokens": [
        50604,
        3885,
        8056,
        257,
        8310,
        10686,
        420,
        6786,
        257,
        6542,
        10686,
        293,
        309,
        23815,
        3089,
        43146,
        3089,
        50874
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32925713062286377,
      "compression_ratio": 1.7685589790344238,
      "no_speech_prob": 0.19930878281593323
    },
    {
      "id": 135,
      "seek": 66016,
      "start": 1279.3139853515625,
      "end": 1284.8340048828125,
      "text": " And then you can upload that to my copy it into mermaid and in what you create a diagram for you",
      "tokens": [
        50874,
        400,
        550,
        291,
        393,
        6580,
        300,
        281,
        452,
        5055,
        309,
        666,
        43146,
        293,
        294,
        437,
        291,
        1884,
        257,
        10686,
        337,
        291,
        51150
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32925713062286377,
      "compression_ratio": 1.7685589790344238,
      "no_speech_prob": 0.19930878281593323
    },
    {
      "id": 136,
      "seek": 66016,
      "start": 1285.1540122070312,
      "end": 1289.3940024414062,
      "text": " So these are things that I'm just experimenting with students experiment with",
      "tokens": [
        51166,
        407,
        613,
        366,
        721,
        300,
        286,
        478,
        445,
        29070,
        365,
        1731,
        5120,
        365,
        51378
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32925713062286377,
      "compression_ratio": 1.7685589790344238,
      "no_speech_prob": 0.19930878281593323
    },
    {
      "id": 137,
      "seek": 66016,
      "start": 1290.1540122070312,
      "end": 1297.5940146484375,
      "text": " But it gives you a little glimpse into the future telling you that okay the abstraction level for",
      "tokens": [
        51416,
        583,
        309,
        2709,
        291,
        257,
        707,
        25838,
        666,
        264,
        2027,
        3585,
        291,
        300,
        1392,
        264,
        37765,
        1496,
        337,
        51788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32925713062286377,
      "compression_ratio": 1.7685589790344238,
      "no_speech_prob": 0.19930878281593323
    },
    {
      "id": 138,
      "seek": 68864,
      "start": 1297.954,
      "end": 1299.954,
      "text": " Software development will be",
      "tokens": [
        50382,
        27428,
        3250,
        486,
        312,
        50482
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35066816210746765,
      "compression_ratio": 1.589108943939209,
      "no_speech_prob": 0.0014839795185253024
    },
    {
      "id": 139,
      "seek": 68864,
      "start": 1301.193990234375,
      "end": 1309.2740073242187,
      "text": " Will it will be higher again, so I compare it to the transition from machine language to",
      "tokens": [
        50544,
        3099,
        309,
        486,
        312,
        2946,
        797,
        11,
        370,
        286,
        6794,
        309,
        281,
        264,
        6034,
        490,
        3479,
        2856,
        281,
        50948
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35066816210746765,
      "compression_ratio": 1.589108943939209,
      "no_speech_prob": 0.0014839795185253024
    },
    {
      "id": 140,
      "seek": 68864,
      "start": 1311.714009765625,
      "end": 1312.954,
      "text": " To",
      "tokens": [
        51070,
        1407,
        51132
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35066816210746765,
      "compression_ratio": 1.589108943939209,
      "no_speech_prob": 0.0014839795185253024
    },
    {
      "id": 141,
      "seek": 68864,
      "start": 1312.954,
      "end": 1316.7539877929687,
      "text": " Assembly language to high-level programming languages to frameworks and so on",
      "tokens": [
        51132,
        20399,
        2856,
        281,
        1090,
        12,
        12418,
        9410,
        8650,
        281,
        29834,
        293,
        370,
        322,
        51322
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35066816210746765,
      "compression_ratio": 1.589108943939209,
      "no_speech_prob": 0.0014839795185253024
    },
    {
      "id": 142,
      "seek": 68864,
      "start": 1317.7539877929687,
      "end": 1319.7539877929687,
      "text": " developers can focus on",
      "tokens": [
        51372,
        8849,
        393,
        1879,
        322,
        51472
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35066816210746765,
      "compression_ratio": 1.589108943939209,
      "no_speech_prob": 0.0014839795185253024
    },
    {
      "id": 143,
      "seek": 68864,
      "start": 1319.8739829101562,
      "end": 1323.1139731445312,
      "text": " More of the business of what they want to produce",
      "tokens": [
        51478,
        5048,
        295,
        264,
        1606,
        295,
        437,
        436,
        528,
        281,
        5258,
        51640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35066816210746765,
      "compression_ratio": 1.589108943939209,
      "no_speech_prob": 0.0014839795185253024
    },
    {
      "id": 144,
      "seek": 68864,
      "start": 1324.1540122070312,
      "end": 1326.7539877929687,
      "text": " versus the details of the technologies sometimes",
      "tokens": [
        51692,
        5717,
        264,
        4365,
        295,
        264,
        7943,
        2171,
        51822
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35066816210746765,
      "compression_ratio": 1.589108943939209,
      "no_speech_prob": 0.0014839795185253024
    },
    {
      "id": 145,
      "seek": 71864,
      "start": 1328.1139731445312,
      "end": 1332.234029296875,
      "text": " So when you mentioned mermaid, I find it quite interesting that",
      "tokens": [
        50390,
        407,
        562,
        291,
        2835,
        43146,
        11,
        286,
        915,
        309,
        1596,
        1880,
        300,
        50596
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36196136474609375,
      "compression_ratio": 1.614213228225708,
      "no_speech_prob": 0.003705838695168495
    },
    {
      "id": 146,
      "seek": 71864,
      "start": 1332.9140219726562,
      "end": 1339.9140219726562,
      "text": " we as humans like the diagrams and the machine can read the code of the mermaid diagram and",
      "tokens": [
        50630,
        321,
        382,
        6255,
        411,
        264,
        36709,
        293,
        264,
        3479,
        393,
        1401,
        264,
        3089,
        295,
        264,
        43146,
        10686,
        293,
        50980
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36196136474609375,
      "compression_ratio": 1.614213228225708,
      "no_speech_prob": 0.003705838695168495
    },
    {
      "id": 147,
      "seek": 71864,
      "start": 1340.5940146484375,
      "end": 1344.3540244140625,
      "text": " doesn't have to waste the token for the image and",
      "tokens": [
        51014,
        1177,
        380,
        362,
        281,
        5964,
        264,
        14862,
        337,
        264,
        3256,
        293,
        51202
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36196136474609375,
      "compression_ratio": 1.614213228225708,
      "no_speech_prob": 0.003705838695168495
    },
    {
      "id": 148,
      "seek": 71864,
      "start": 1345.193990234375,
      "end": 1351.47401953125,
      "text": " As I remember you mentioned that there is an AI tool for mermaid available",
      "tokens": [
        51244,
        1018,
        286,
        1604,
        291,
        2835,
        300,
        456,
        307,
        364,
        7318,
        2290,
        337,
        43146,
        2435,
        51558
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36196136474609375,
      "compression_ratio": 1.614213228225708,
      "no_speech_prob": 0.003705838695168495
    },
    {
      "id": 149,
      "seek": 71864,
      "start": 1352.7940268554687,
      "end": 1355.47401953125,
      "text": " Yeah, I was a little bit surprised. I",
      "tokens": [
        51624,
        865,
        11,
        286,
        390,
        257,
        707,
        857,
        6100,
        13,
        286,
        51758
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36196136474609375,
      "compression_ratio": 1.614213228225708,
      "no_speech_prob": 0.003705838695168495
    },
    {
      "id": 150,
      "seek": 74652,
      "start": 1355.9140219726562,
      "end": 1357.9140219726562,
      "text": " Didn't know about it",
      "tokens": [
        50386,
        11151,
        380,
        458,
        466,
        309,
        50486
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3262045085430145,
      "compression_ratio": 1.4285714626312256,
      "no_speech_prob": 0.002045007422566414
    },
    {
      "id": 151,
      "seek": 74652,
      "start": 1358.7940268554687,
      "end": 1361.9140219726562,
      "text": " What it is capable of how does it support",
      "tokens": [
        50530,
        708,
        309,
        307,
        8189,
        295,
        577,
        775,
        309,
        1406,
        50686
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3262045085430145,
      "compression_ratio": 1.4285714626312256,
      "no_speech_prob": 0.002045007422566414
    },
    {
      "id": 152,
      "seek": 74652,
      "start": 1363.0340170898437,
      "end": 1365.0340170898437,
      "text": " architect so",
      "tokens": [
        50742,
        6331,
        370,
        50842
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3262045085430145,
      "compression_ratio": 1.4285714626312256,
      "no_speech_prob": 0.002045007422566414
    },
    {
      "id": 153,
      "seek": 74652,
      "start": 1365.0340170898437,
      "end": 1368.1540122070312,
      "text": " when so let's say that you got the",
      "tokens": [
        50842,
        562,
        370,
        718,
        311,
        584,
        300,
        291,
        658,
        264,
        50998
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3262045085430145,
      "compression_ratio": 1.4285714626312256,
      "no_speech_prob": 0.002045007422566414
    },
    {
      "id": 154,
      "seek": 74652,
      "start": 1368.714009765625,
      "end": 1374.3940024414062,
      "text": " code the mermaid code from the LLM, so you're discussing exchanging with the",
      "tokens": [
        51026,
        3089,
        264,
        43146,
        3089,
        490,
        264,
        441,
        43,
        44,
        11,
        370,
        291,
        434,
        10850,
        6210,
        9741,
        365,
        264,
        51310
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3262045085430145,
      "compression_ratio": 1.4285714626312256,
      "no_speech_prob": 0.002045007422566414
    },
    {
      "id": 155,
      "seek": 74652,
      "start": 1375.0739951171875,
      "end": 1376.8739829101562,
      "text": " LLM and",
      "tokens": [
        51344,
        441,
        43,
        44,
        293,
        51434
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3262045085430145,
      "compression_ratio": 1.4285714626312256,
      "no_speech_prob": 0.002045007422566414
    },
    {
      "id": 156,
      "seek": 74652,
      "start": 1376.8739829101562,
      "end": 1379.673970703125,
      "text": " You have a block diagram",
      "tokens": [
        51434,
        509,
        362,
        257,
        3461,
        10686,
        51574
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3262045085430145,
      "compression_ratio": 1.4285714626312256,
      "no_speech_prob": 0.002045007422566414
    },
    {
      "id": 0,
      "seek": 0,
      "start": 1380.6200000119209,
      "end": 1382.6199999523162,
      "text": " it will",
      "tokens": [
        50404,
        309,
        486,
        50504
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2922656238079071,
      "compression_ratio": 1.7352941036224365,
      "no_speech_prob": 0.9374237656593323
    },
    {
      "id": 1,
      "seek": 0,
      "start": 1382.6199999523162,
      "end": 1384.6200001907348,
      "text": " sometimes give it a description for the block diagram.",
      "tokens": [
        50504,
        2171,
        976,
        309,
        257,
        3855,
        337,
        264,
        3461,
        10686,
        13,
        50604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2922656238079071,
      "compression_ratio": 1.7352941036224365,
      "no_speech_prob": 0.9374237656593323
    },
    {
      "id": 2,
      "seek": 0,
      "start": 1384.899999923706,
      "end": 1390.979999847412,
      "text": " But instead of giving you a JPEG or a PNG, it will give you the code, or you can ask it for the mermaid code.",
      "tokens": [
        50618,
        583,
        2602,
        295,
        2902,
        291,
        257,
        508,
        5208,
        38,
        420,
        257,
        430,
        30237,
        11,
        309,
        486,
        976,
        291,
        264,
        3089,
        11,
        420,
        291,
        393,
        1029,
        309,
        337,
        264,
        43146,
        3089,
        13,
        50922
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2922656238079071,
      "compression_ratio": 1.7352941036224365,
      "no_speech_prob": 0.9374237656593323
    },
    {
      "id": 3,
      "seek": 0,
      "start": 1392.6600001525878,
      "end": 1397.3400004577636,
      "text": " Sometimes there are errors in there, or you may even, maybe you're not using an LLM,",
      "tokens": [
        51006,
        4803,
        456,
        366,
        13603,
        294,
        456,
        11,
        420,
        291,
        815,
        754,
        11,
        1310,
        291,
        434,
        406,
        1228,
        364,
        441,
        43,
        44,
        11,
        51240
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2922656238079071,
      "compression_ratio": 1.7352941036224365,
      "no_speech_prob": 0.9374237656593323
    },
    {
      "id": 4,
      "seek": 0,
      "start": 1397.3400004577636,
      "end": 1403.6600001525878,
      "text": " but you are writing the code for a diagram, which is not hard to do. So, for example, with a sequence diagram,",
      "tokens": [
        51240,
        457,
        291,
        366,
        3579,
        264,
        3089,
        337,
        257,
        10686,
        11,
        597,
        307,
        406,
        1152,
        281,
        360,
        13,
        407,
        11,
        337,
        1365,
        11,
        365,
        257,
        8310,
        10686,
        11,
        51556
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2922656238079071,
      "compression_ratio": 1.7352941036224365,
      "no_speech_prob": 0.9374237656593323
    },
    {
      "id": 5,
      "seek": 0,
      "start": 1403.6600001525878,
      "end": 1408.059999771118,
      "text": " you're identifying the participants, and you're just writing some simple code to describe the messages,",
      "tokens": [
        51556,
        291,
        434,
        16696,
        264,
        10503,
        11,
        293,
        291,
        434,
        445,
        3579,
        512,
        2199,
        3089,
        281,
        6786,
        264,
        7897,
        11,
        51776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2922656238079071,
      "compression_ratio": 1.7352941036224365,
      "no_speech_prob": 0.9374237656593323
    },
    {
      "id": 6,
      "seek": 2824,
      "start": 1408.6999991607665,
      "end": 1412.540001220703,
      "text": " exchanges, and the order that they're supposed to be in. If there are errors in there,",
      "tokens": [
        50396,
        27374,
        11,
        293,
        264,
        1668,
        300,
        436,
        434,
        3442,
        281,
        312,
        294,
        13,
        759,
        456,
        366,
        13603,
        294,
        456,
        11,
        50588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32000964879989624,
      "compression_ratio": 1.6523809432983398,
      "no_speech_prob": 0.03959101811051369
    },
    {
      "id": 7,
      "seek": 2824,
      "start": 1412.82,
      "end": 1418.7799990844726,
      "text": " Mermaid itself as an AI tool that detects what you're trying to do and corrects the code for you.",
      "tokens": [
        50602,
        376,
        32124,
        2564,
        382,
        364,
        7318,
        2290,
        300,
        5531,
        82,
        437,
        291,
        434,
        1382,
        281,
        360,
        293,
        3006,
        82,
        264,
        3089,
        337,
        291,
        13,
        50900
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32000964879989624,
      "compression_ratio": 1.6523809432983398,
      "no_speech_prob": 0.03959101811051369
    },
    {
      "id": 8,
      "seek": 2824,
      "start": 1419.3400004577636,
      "end": 1426.5000003051757,
      "text": " So, I found that to be quite useful. Yeah, it sounds like to be quite useful. So, I think, I wonder that",
      "tokens": [
        50928,
        407,
        11,
        286,
        1352,
        300,
        281,
        312,
        1596,
        4420,
        13,
        865,
        11,
        309,
        3263,
        411,
        281,
        312,
        1596,
        4420,
        13,
        407,
        11,
        286,
        519,
        11,
        286,
        2441,
        300,
        51286
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32000964879989624,
      "compression_ratio": 1.6523809432983398,
      "no_speech_prob": 0.03959101811051369
    },
    {
      "id": 9,
      "seek": 2824,
      "start": 1427.380001373291,
      "end": 1431.9000018310546,
      "text": " other tools don't have this component, this AI component.",
      "tokens": [
        51330,
        661,
        3873,
        500,
        380,
        362,
        341,
        6542,
        11,
        341,
        7318,
        6542,
        13,
        51556
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32000964879989624,
      "compression_ratio": 1.6523809432983398,
      "no_speech_prob": 0.03959101811051369
    },
    {
      "id": 10,
      "seek": 5208,
      "start": 1432.5000003051757,
      "end": 1439.0200007629394,
      "text": " But otherwise, I see a problem that when your students now work on open source",
      "tokens": [
        50394,
        583,
        5911,
        11,
        286,
        536,
        257,
        1154,
        300,
        562,
        428,
        1731,
        586,
        589,
        322,
        1269,
        4009,
        50720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3781200647354126,
      "compression_ratio": 1.6584157943725586,
      "no_speech_prob": 0.09132861346006393
    },
    {
      "id": 11,
      "seek": 5208,
      "start": 1440.1399996948242,
      "end": 1442.7399981689452,
      "text": " tools, open source software, and later",
      "tokens": [
        50776,
        3873,
        11,
        1269,
        4009,
        4722,
        11,
        293,
        1780,
        50906
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3781200647354126,
      "compression_ratio": 1.6584157943725586,
      "no_speech_prob": 0.09132861346006393
    },
    {
      "id": 12,
      "seek": 5208,
      "start": 1443.6600001525878,
      "end": 1447.5000003051757,
      "text": " working in a company and can't use those tools anymore,",
      "tokens": [
        50952,
        1364,
        294,
        257,
        2237,
        293,
        393,
        380,
        764,
        729,
        3873,
        3602,
        11,
        51144
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3781200647354126,
      "compression_ratio": 1.6584157943725586,
      "no_speech_prob": 0.09132861346006393
    },
    {
      "id": 13,
      "seek": 5208,
      "start": 1447.7399981689452,
      "end": 1454.7799990844726,
      "text": " but maybe then they are more advanced. And I guess with Mermaid, is this an open source tool, which I can...",
      "tokens": [
        51156,
        457,
        1310,
        550,
        436,
        366,
        544,
        7339,
        13,
        400,
        286,
        2041,
        365,
        376,
        32124,
        11,
        307,
        341,
        364,
        1269,
        4009,
        2290,
        11,
        597,
        286,
        393,
        485,
        51508
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3781200647354126,
      "compression_ratio": 1.6584157943725586,
      "no_speech_prob": 0.09132861346006393
    },
    {
      "id": 14,
      "seek": 5208,
      "start": 1454.7799990844726,
      "end": 1458.1800006103515,
      "text": " It's not open source. Okay, so it's not open source.",
      "tokens": [
        51508,
        467,
        311,
        406,
        1269,
        4009,
        13,
        1033,
        11,
        370,
        309,
        311,
        406,
        1269,
        4009,
        13,
        51678
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3781200647354126,
      "compression_ratio": 1.6584157943725586,
      "no_speech_prob": 0.09132861346006393
    },
    {
      "id": 15,
      "seek": 7836,
      "start": 1458.2200015258788,
      "end": 1465.2200015258788,
      "text": " But I think what is interesting is that these experiences aren't just about, I can do this faster.",
      "tokens": [
        50366,
        583,
        286,
        519,
        437,
        307,
        1880,
        307,
        300,
        613,
        5235,
        3212,
        380,
        445,
        466,
        11,
        286,
        393,
        360,
        341,
        4663,
        13,
        50716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28225791454315186,
      "compression_ratio": 1.8247863054275513,
      "no_speech_prob": 0.029373981058597565
    },
    {
      "id": 16,
      "seek": 7836,
      "start": 1465.2200015258788,
      "end": 1468.540001220703,
      "text": " I think these experiences are quite useful for learning.",
      "tokens": [
        50716,
        286,
        519,
        613,
        5235,
        366,
        1596,
        4420,
        337,
        2539,
        13,
        50882
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28225791454315186,
      "compression_ratio": 1.8247863054275513,
      "no_speech_prob": 0.029373981058597565
    },
    {
      "id": 17,
      "seek": 7836,
      "start": 1468.540001220703,
      "end": 1471.9800036621093,
      "text": " I think, well, for me, and I think for my students,",
      "tokens": [
        50882,
        286,
        519,
        11,
        731,
        11,
        337,
        385,
        11,
        293,
        286,
        519,
        337,
        452,
        1731,
        11,
        51054
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28225791454315186,
      "compression_ratio": 1.8247863054275513,
      "no_speech_prob": 0.029373981058597565
    },
    {
      "id": 18,
      "seek": 7836,
      "start": 1472.0199969482421,
      "end": 1478.0599978637695,
      "text": " there are things that would have taken longer to learn or longer to realize that, oh, this is the way you do this thing.",
      "tokens": [
        51056,
        456,
        366,
        721,
        300,
        576,
        362,
        2726,
        2854,
        281,
        1466,
        420,
        2854,
        281,
        4325,
        300,
        11,
        1954,
        11,
        341,
        307,
        264,
        636,
        291,
        360,
        341,
        551,
        13,
        51358
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28225791454315186,
      "compression_ratio": 1.8247863054275513,
      "no_speech_prob": 0.029373981058597565
    },
    {
      "id": 19,
      "seek": 7836,
      "start": 1478.3000033569335,
      "end": 1485.0199969482421,
      "text": " But if you're an authentic person and you're using the tools in a responsible way,",
      "tokens": [
        51370,
        583,
        498,
        291,
        434,
        364,
        12466,
        954,
        293,
        291,
        434,
        1228,
        264,
        3873,
        294,
        257,
        6250,
        636,
        11,
        51706
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28225791454315186,
      "compression_ratio": 1.8247863054275513,
      "no_speech_prob": 0.029373981058597565
    },
    {
      "id": 20,
      "seek": 7836,
      "start": 1485.2600024414062,
      "end": 1487.2600024414062,
      "text": " you're not only",
      "tokens": [
        51718,
        291,
        434,
        406,
        787,
        51818
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28225791454315186,
      "compression_ratio": 1.8247863054275513,
      "no_speech_prob": 0.029373981058597565
    },
    {
      "id": 21,
      "seek": 10744,
      "start": 1487.419998474121,
      "end": 1491.699997253418,
      "text": " getting the answer and saying, hey, this is the answer, but you're learning through the exchange.",
      "tokens": [
        50372,
        1242,
        264,
        1867,
        293,
        1566,
        11,
        4177,
        11,
        341,
        307,
        264,
        1867,
        11,
        457,
        291,
        434,
        2539,
        807,
        264,
        7742,
        13,
        50586
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26130586862564087,
      "compression_ratio": 1.9642857313156128,
      "no_speech_prob": 0.004587002098560333
    },
    {
      "id": 22,
      "seek": 10744,
      "start": 1492.0199969482421,
      "end": 1496.7799990844726,
      "text": " Through the answer, you get the answer and you're studying it. You're trying to understand. Why is this thing here?",
      "tokens": [
        50602,
        8927,
        264,
        1867,
        11,
        291,
        483,
        264,
        1867,
        293,
        291,
        434,
        7601,
        309,
        13,
        509,
        434,
        1382,
        281,
        1223,
        13,
        1545,
        307,
        341,
        551,
        510,
        30,
        50840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26130586862564087,
      "compression_ratio": 1.9642857313156128,
      "no_speech_prob": 0.004587002098560333
    },
    {
      "id": 23,
      "seek": 10744,
      "start": 1496.7799990844726,
      "end": 1502.3000033569335,
      "text": " Why is that there? Why does this work? Why doesn't that work? It's a good way of learning. I liken it to,",
      "tokens": [
        50840,
        1545,
        307,
        300,
        456,
        30,
        1545,
        775,
        341,
        589,
        30,
        1545,
        1177,
        380,
        300,
        589,
        30,
        467,
        311,
        257,
        665,
        636,
        295,
        2539,
        13,
        286,
        36946,
        309,
        281,
        11,
        51116
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26130586862564087,
      "compression_ratio": 1.9642857313156128,
      "no_speech_prob": 0.004587002098560333
    },
    {
      "id": 24,
      "seek": 10744,
      "start": 1502.940002746582,
      "end": 1509.7399981689452,
      "text": " if I were doing something, if I were doing architecture work and you're also an architect and I'm asking you for help and",
      "tokens": [
        51148,
        498,
        286,
        645,
        884,
        746,
        11,
        498,
        286,
        645,
        884,
        9482,
        589,
        293,
        291,
        434,
        611,
        364,
        6331,
        293,
        286,
        478,
        3365,
        291,
        337,
        854,
        293,
        51488
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26130586862564087,
      "compression_ratio": 1.9642857313156128,
      "no_speech_prob": 0.004587002098560333
    },
    {
      "id": 25,
      "seek": 10744,
      "start": 1509.9000018310546,
      "end": 1513.4200061035156,
      "text": " you're giving me ideas, I should question your ideas.",
      "tokens": [
        51496,
        291,
        434,
        2902,
        385,
        3487,
        11,
        286,
        820,
        1168,
        428,
        3487,
        13,
        51672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26130586862564087,
      "compression_ratio": 1.9642857313156128,
      "no_speech_prob": 0.004587002098560333
    },
    {
      "id": 26,
      "seek": 13360,
      "start": 1513.4200061035156,
      "end": 1516.82,
      "text": " I should experiment with your ideas and I'm learning from your ideas.",
      "tokens": [
        50364,
        286,
        820,
        5120,
        365,
        428,
        3487,
        293,
        286,
        478,
        2539,
        490,
        428,
        3487,
        13,
        50534
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33473917841911316,
      "compression_ratio": 1.7149122953414917,
      "no_speech_prob": 0.12022969871759415
    },
    {
      "id": 27,
      "seek": 13360,
      "start": 1516.82,
      "end": 1520.9800036621093,
      "text": " Maybe you're learning from teaching me and that type of back and forth is not,",
      "tokens": [
        50534,
        2704,
        291,
        434,
        2539,
        490,
        4571,
        385,
        293,
        300,
        2010,
        295,
        646,
        293,
        5220,
        307,
        406,
        11,
        50742
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33473917841911316,
      "compression_ratio": 1.7149122953414917,
      "no_speech_prob": 0.12022969871759415
    },
    {
      "id": 28,
      "seek": 13360,
      "start": 1521.9800036621093,
      "end": 1526.1800006103515,
      "text": " it's not just about the answer. It's about the process and about learning as well.",
      "tokens": [
        50792,
        309,
        311,
        406,
        445,
        466,
        264,
        1867,
        13,
        467,
        311,
        466,
        264,
        1399,
        293,
        466,
        2539,
        382,
        731,
        13,
        51002
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33473917841911316,
      "compression_ratio": 1.7149122953414917,
      "no_speech_prob": 0.12022969871759415
    },
    {
      "id": 29,
      "seek": 13360,
      "start": 1526.1800006103515,
      "end": 1534.82,
      "text": " So you're a lecturer and you teach people and now you tell me that AI is perfect for learning because it helps.",
      "tokens": [
        51002,
        407,
        291,
        434,
        257,
        49881,
        293,
        291,
        2924,
        561,
        293,
        586,
        291,
        980,
        385,
        300,
        7318,
        307,
        2176,
        337,
        2539,
        570,
        309,
        3665,
        13,
        51434
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33473917841911316,
      "compression_ratio": 1.7149122953414917,
      "no_speech_prob": 0.12022969871759415
    },
    {
      "id": 30,
      "seek": 13360,
      "start": 1536.060005493164,
      "end": 1538.060005493164,
      "text": " Okay, so",
      "tokens": [
        51496,
        1033,
        11,
        370,
        51596
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33473917841911316,
      "compression_ratio": 1.7149122953414917,
      "no_speech_prob": 0.12022969871759415
    },
    {
      "id": 31,
      "seek": 13360,
      "start": 1538.3799975585937,
      "end": 1541.1400073242187,
      "text": " how do you see that your role changes?",
      "tokens": [
        51612,
        577,
        360,
        291,
        536,
        300,
        428,
        3090,
        2962,
        30,
        51750
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33473917841911316,
      "compression_ratio": 1.7149122953414917,
      "no_speech_prob": 0.12022969871759415
    },
    {
      "id": 32,
      "seek": 16132,
      "start": 1541.4599993896484,
      "end": 1545.3400042724609,
      "text": " Right, so I think not only with AI, but I think maybe",
      "tokens": [
        50380,
        1779,
        11,
        370,
        286,
        519,
        406,
        787,
        365,
        7318,
        11,
        457,
        286,
        519,
        1310,
        50574
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26815518736839294,
      "compression_ratio": 1.6872427463531494,
      "no_speech_prob": 0.04242828115820885
    },
    {
      "id": 33,
      "seek": 16132,
      "start": 1546.0999987792968,
      "end": 1551.9800036621093,
      "text": " as many as 15 years ago, I realized that my job as a teacher was not just to impart knowledge",
      "tokens": [
        50612,
        382,
        867,
        382,
        2119,
        924,
        2057,
        11,
        286,
        5334,
        300,
        452,
        1691,
        382,
        257,
        5027,
        390,
        406,
        445,
        281,
        32177,
        3601,
        50906
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26815518736839294,
      "compression_ratio": 1.6872427463531494,
      "no_speech_prob": 0.04242828115820885
    },
    {
      "id": 34,
      "seek": 16132,
      "start": 1552.7399981689452,
      "end": 1560.2600024414062,
      "text": " because of the internet, because of Google, because knowledge is available. My interest is not so much in",
      "tokens": [
        50944,
        570,
        295,
        264,
        4705,
        11,
        570,
        295,
        3329,
        11,
        570,
        3601,
        307,
        2435,
        13,
        1222,
        1179,
        307,
        406,
        370,
        709,
        294,
        51320
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26815518736839294,
      "compression_ratio": 1.6872427463531494,
      "no_speech_prob": 0.04242828115820885
    },
    {
      "id": 35,
      "seek": 16132,
      "start": 1561.299995727539,
      "end": 1563.7800067138671,
      "text": " collecting knowledge and spitting it back out at students.",
      "tokens": [
        51372,
        12510,
        3601,
        293,
        637,
        2414,
        309,
        646,
        484,
        412,
        1731,
        13,
        51496
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26815518736839294,
      "compression_ratio": 1.6872427463531494,
      "no_speech_prob": 0.04242828115820885
    },
    {
      "id": 36,
      "seek": 16132,
      "start": 1563.82,
      "end": 1569.299995727539,
      "text": " My interest is in what process can we use to develop the competencies that we want to develop and",
      "tokens": [
        51498,
        1222,
        1179,
        307,
        294,
        437,
        1399,
        393,
        321,
        764,
        281,
        1499,
        264,
        2850,
        6464,
        300,
        321,
        528,
        281,
        1499,
        293,
        51772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26815518736839294,
      "compression_ratio": 1.6872427463531494,
      "no_speech_prob": 0.04242828115820885
    },
    {
      "id": 37,
      "seek": 18948,
      "start": 1570.2600024414062,
      "end": 1576.7399981689452,
      "text": " this is not only beneficial for the students, it's beneficial for me because, I mean, as a lecturer you're not like",
      "tokens": [
        50412,
        341,
        307,
        406,
        787,
        14072,
        337,
        264,
        1731,
        11,
        309,
        311,
        14072,
        337,
        385,
        570,
        11,
        286,
        914,
        11,
        382,
        257,
        49881,
        291,
        434,
        406,
        411,
        50736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2793002128601074,
      "compression_ratio": 1.9277108907699585,
      "no_speech_prob": 0.002546923002228141
    },
    {
      "id": 38,
      "seek": 18948,
      "start": 1577.3799975585937,
      "end": 1583.1800006103515,
      "text": " a repositor of all the knowledge and understanding and skills in the world. So you're also growing.",
      "tokens": [
        50768,
        257,
        1085,
        329,
        3029,
        295,
        439,
        264,
        3601,
        293,
        3701,
        293,
        3942,
        294,
        264,
        1002,
        13,
        407,
        291,
        434,
        611,
        4194,
        13,
        51058
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2793002128601074,
      "compression_ratio": 1.9277108907699585,
      "no_speech_prob": 0.002546923002228141
    },
    {
      "id": 39,
      "seek": 18948,
      "start": 1583.3400042724609,
      "end": 1587.5799945068359,
      "text": " So I think when you create a classroom environment that allows the students to",
      "tokens": [
        51066,
        407,
        286,
        519,
        562,
        291,
        1884,
        257,
        7419,
        2823,
        300,
        4045,
        264,
        1731,
        281,
        51278
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2793002128601074,
      "compression_ratio": 1.9277108907699585,
      "no_speech_prob": 0.002546923002228141
    },
    {
      "id": 40,
      "seek": 18948,
      "start": 1588.4999926757812,
      "end": 1592.4599993896484,
      "text": " learn through whatever tools they need to use, I think it's better for them",
      "tokens": [
        51324,
        1466,
        807,
        2035,
        3873,
        436,
        643,
        281,
        764,
        11,
        286,
        519,
        309,
        311,
        1101,
        337,
        552,
        51522
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2793002128601074,
      "compression_ratio": 1.9277108907699585,
      "no_speech_prob": 0.002546923002228141
    },
    {
      "id": 41,
      "seek": 18948,
      "start": 1592.4599993896484,
      "end": 1596.7800067138671,
      "text": " and I think it's better for you and I think it's better for them when they get into the working world because",
      "tokens": [
        51522,
        293,
        286,
        519,
        309,
        311,
        1101,
        337,
        291,
        293,
        286,
        519,
        309,
        311,
        1101,
        337,
        552,
        562,
        436,
        483,
        666,
        264,
        1364,
        1002,
        570,
        51738
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2793002128601074,
      "compression_ratio": 1.9277108907699585,
      "no_speech_prob": 0.002546923002228141
    },
    {
      "id": 42,
      "seek": 21696,
      "start": 1597.0999987792968,
      "end": 1601.82,
      "text": " the industry is not interested in how much you know, they're interested in what skills you have and",
      "tokens": [
        50380,
        264,
        3518,
        307,
        406,
        3102,
        294,
        577,
        709,
        291,
        458,
        11,
        436,
        434,
        3102,
        294,
        437,
        3942,
        291,
        362,
        293,
        50616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30312663316726685,
      "compression_ratio": 1.505494475364685,
      "no_speech_prob": 0.0024269921705126762
    },
    {
      "id": 43,
      "seek": 21696,
      "start": 1602.1800006103515,
      "end": 1605.540001220703,
      "text": " how you will function and grow in an organization.",
      "tokens": [
        50634,
        577,
        291,
        486,
        2445,
        293,
        1852,
        294,
        364,
        4475,
        13,
        50802
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30312663316726685,
      "compression_ratio": 1.505494475364685,
      "no_speech_prob": 0.0024269921705126762
    },
    {
      "id": 44,
      "seek": 21696,
      "start": 1606.4599993896484,
      "end": 1607.6599963378906,
      "text": " Okay.",
      "tokens": [
        50848,
        1033,
        13,
        50908
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30312663316726685,
      "compression_ratio": 1.505494475364685,
      "no_speech_prob": 0.0024269921705126762
    },
    {
      "id": 45,
      "seek": 21696,
      "start": 1607.6599963378906,
      "end": 1609.1800006103515,
      "text": " What about",
      "tokens": [
        50908,
        708,
        466,
        50984
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30312663316726685,
      "compression_ratio": 1.505494475364685,
      "no_speech_prob": 0.0024269921705126762
    },
    {
      "id": 46,
      "seek": 21696,
      "start": 1609.1800006103515,
      "end": 1611.1800006103515,
      "text": " hallucinations and",
      "tokens": [
        50984,
        35212,
        10325,
        293,
        51084
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30312663316726685,
      "compression_ratio": 1.505494475364685,
      "no_speech_prob": 0.0024269921705126762
    },
    {
      "id": 47,
      "seek": 21696,
      "start": 1611.3799975585937,
      "end": 1613.3799975585937,
      "text": " cheating? I mean,",
      "tokens": [
        51094,
        18309,
        30,
        286,
        914,
        11,
        51194
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30312663316726685,
      "compression_ratio": 1.505494475364685,
      "no_speech_prob": 0.0024269921705126762
    },
    {
      "id": 48,
      "seek": 21696,
      "start": 1613.9000018310546,
      "end": 1619.4999926757812,
      "text": " when I see my son doing his maths homework, he has several choices to",
      "tokens": [
        51220,
        562,
        286,
        536,
        452,
        1872,
        884,
        702,
        36287,
        14578,
        11,
        415,
        575,
        2940,
        7994,
        281,
        51500
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30312663316726685,
      "compression_ratio": 1.505494475364685,
      "no_speech_prob": 0.0024269921705126762
    },
    {
      "id": 49,
      "seek": 23968,
      "start": 1620.1800006103515,
      "end": 1622.1800006103515,
      "text": " give the image of the",
      "tokens": [
        50398,
        976,
        264,
        3256,
        295,
        264,
        50498
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3374970257282257,
      "compression_ratio": 1.6132596731185913,
      "no_speech_prob": 0.31705284118652344
    },
    {
      "id": 50,
      "seek": 23968,
      "start": 1622.5799945068359,
      "end": 1630.060005493164,
      "text": " task to the AI and say, hey, solve this problem for me or to ask how to solve it. So",
      "tokens": [
        50518,
        5633,
        281,
        264,
        7318,
        293,
        584,
        11,
        4177,
        11,
        5039,
        341,
        1154,
        337,
        385,
        420,
        281,
        1029,
        577,
        281,
        5039,
        309,
        13,
        407,
        50892
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3374970257282257,
      "compression_ratio": 1.6132596731185913,
      "no_speech_prob": 0.31705284118652344
    },
    {
      "id": 51,
      "seek": 23968,
      "start": 1631.2600024414062,
      "end": 1638.4999926757812,
      "text": " isn't this a problem? I know with the architecture, I realized that this is a task where",
      "tokens": [
        50952,
        1943,
        380,
        341,
        257,
        1154,
        30,
        286,
        458,
        365,
        264,
        9482,
        11,
        286,
        5334,
        300,
        341,
        307,
        257,
        5633,
        689,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3374970257282257,
      "compression_ratio": 1.6132596731185913,
      "no_speech_prob": 0.31705284118652344
    },
    {
      "id": 52,
      "seek": 23968,
      "start": 1639.540001220703,
      "end": 1647.1400073242187,
      "text": " you can't really cheat, where the AI will not solve your problem, but help you in brainstorming.",
      "tokens": [
        51366,
        291,
        393,
        380,
        534,
        17470,
        11,
        689,
        264,
        7318,
        486,
        406,
        5039,
        428,
        1154,
        11,
        457,
        854,
        291,
        294,
        35245,
        278,
        13,
        51746
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3374970257282257,
      "compression_ratio": 1.6132596731185913,
      "no_speech_prob": 0.31705284118652344
    },
    {
      "id": 53,
      "seek": 26732,
      "start": 1648.0999987792968,
      "end": 1653.580009765625,
      "text": " Is this a solution that you give the right task to the students?",
      "tokens": [
        50412,
        1119,
        341,
        257,
        3827,
        300,
        291,
        976,
        264,
        558,
        5633,
        281,
        264,
        1731,
        30,
        50686
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3333950340747833,
      "compression_ratio": 1.6956521272659302,
      "no_speech_prob": 0.0026661474257707596
    },
    {
      "id": 54,
      "seek": 26732,
      "start": 1654.4600146484374,
      "end": 1659.3799975585937,
      "text": " That's absolutely, that's an issue. That's something that I have to",
      "tokens": [
        50730,
        663,
        311,
        3122,
        11,
        300,
        311,
        364,
        2734,
        13,
        663,
        311,
        746,
        300,
        286,
        362,
        281,
        50976
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3333950340747833,
      "compression_ratio": 1.6956521272659302,
      "no_speech_prob": 0.0026661474257707596
    },
    {
      "id": 55,
      "seek": 26732,
      "start": 1660.0999987792968,
      "end": 1664.7400134277343,
      "text": " have grappled with, like how do I write an assignment in such a way that",
      "tokens": [
        51012,
        362,
        27165,
        1493,
        365,
        11,
        411,
        577,
        360,
        286,
        2464,
        364,
        15187,
        294,
        1270,
        257,
        636,
        300,
        51244
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3333950340747833,
      "compression_ratio": 1.6956521272659302,
      "no_speech_prob": 0.0026661474257707596
    },
    {
      "id": 56,
      "seek": 26732,
      "start": 1666.3799975585937,
      "end": 1668.059990234375,
      "text": " using the tool",
      "tokens": [
        51326,
        1228,
        264,
        2290,
        51410
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3333950340747833,
      "compression_ratio": 1.6956521272659302,
      "no_speech_prob": 0.0026661474257707596
    },
    {
      "id": 57,
      "seek": 26732,
      "start": 1668.059990234375,
      "end": 1670.82,
      "text": " does not take away from their learning experience.",
      "tokens": [
        51410,
        775,
        406,
        747,
        1314,
        490,
        641,
        2539,
        1752,
        13,
        51548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3333950340747833,
      "compression_ratio": 1.6956521272659302,
      "no_speech_prob": 0.0026661474257707596
    },
    {
      "id": 58,
      "seek": 26732,
      "start": 1670.82,
      "end": 1676.9399951171874,
      "text": " So I think I'm trying to focus more on the learning experience rather than did you get it right? Did you get it wrong?",
      "tokens": [
        51548,
        407,
        286,
        519,
        286,
        478,
        1382,
        281,
        1879,
        544,
        322,
        264,
        2539,
        1752,
        2831,
        813,
        630,
        291,
        483,
        309,
        558,
        30,
        2589,
        291,
        483,
        309,
        2085,
        30,
        51854
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3333950340747833,
      "compression_ratio": 1.6956521272659302,
      "no_speech_prob": 0.0026661474257707596
    },
    {
      "id": 59,
      "seek": 29732,
      "start": 1677.4999926757812,
      "end": 1683.2199938964843,
      "text": " I'm really interested in are you learning? And if that learning can take place",
      "tokens": [
        50382,
        286,
        478,
        534,
        3102,
        294,
        366,
        291,
        2539,
        30,
        400,
        498,
        300,
        2539,
        393,
        747,
        1081,
        50668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3122652769088745,
      "compression_ratio": 1.656862735748291,
      "no_speech_prob": 0.002101779915392399
    },
    {
      "id": 60,
      "seek": 29732,
      "start": 1683.7400134277343,
      "end": 1687.300010986328,
      "text": " with some tools, I'm okay with it. But",
      "tokens": [
        50694,
        365,
        512,
        3873,
        11,
        286,
        478,
        1392,
        365,
        309,
        13,
        583,
        50872
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3122652769088745,
      "compression_ratio": 1.656862735748291,
      "no_speech_prob": 0.002101779915392399
    },
    {
      "id": 61,
      "seek": 29732,
      "start": 1688.059990234375,
      "end": 1691.6599963378906,
      "text": " at the end of the day, I think there's also",
      "tokens": [
        50910,
        412,
        264,
        917,
        295,
        264,
        786,
        11,
        286,
        519,
        456,
        311,
        611,
        51090
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3122652769088745,
      "compression_ratio": 1.656862735748291,
      "no_speech_prob": 0.002101779915392399
    },
    {
      "id": 62,
      "seek": 29732,
      "start": 1693.9399951171874,
      "end": 1699.9800036621093,
      "text": " so one of the things that I do also is have students when they create anything, they have to explain it.",
      "tokens": [
        51204,
        370,
        472,
        295,
        264,
        721,
        300,
        286,
        360,
        611,
        307,
        362,
        1731,
        562,
        436,
        1884,
        1340,
        11,
        436,
        362,
        281,
        2903,
        309,
        13,
        51506
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3122652769088745,
      "compression_ratio": 1.656862735748291,
      "no_speech_prob": 0.002101779915392399
    },
    {
      "id": 63,
      "seek": 29732,
      "start": 1700.779991455078,
      "end": 1706.0999987792968,
      "text": " So that's one of the ways of managing that question of have you learnt?",
      "tokens": [
        51546,
        407,
        300,
        311,
        472,
        295,
        264,
        2098,
        295,
        11642,
        300,
        1168,
        295,
        362,
        291,
        18991,
        30,
        51812
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3122652769088745,
      "compression_ratio": 1.656862735748291,
      "no_speech_prob": 0.002101779915392399
    },
    {
      "id": 64,
      "seek": 32732,
      "start": 1707.1400073242187,
      "end": 1712.580009765625,
      "text": " So they have to present, they have to explain, they need to be able to answer questions and the LLM is not there with them",
      "tokens": [
        50364,
        407,
        436,
        362,
        281,
        1974,
        11,
        436,
        362,
        281,
        2903,
        11,
        436,
        643,
        281,
        312,
        1075,
        281,
        1867,
        1651,
        293,
        264,
        441,
        43,
        44,
        307,
        406,
        456,
        365,
        552,
        50636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3381979465484619,
      "compression_ratio": 1.5504586696624756,
      "no_speech_prob": 0.003262885380536318
    },
    {
      "id": 65,
      "seek": 32732,
      "start": 1712.82,
      "end": 1714.82,
      "text": " while they're doing it.",
      "tokens": [
        50648,
        1339,
        436,
        434,
        884,
        309,
        13,
        50748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3381979465484619,
      "compression_ratio": 1.5504586696624756,
      "no_speech_prob": 0.003262885380536318
    },
    {
      "id": 66,
      "seek": 32732,
      "start": 1715.3799975585937,
      "end": 1720.3399890136718,
      "text": " Okay, and what about hallucinations? Is this a problem? Do you notice that",
      "tokens": [
        50776,
        1033,
        11,
        293,
        437,
        466,
        35212,
        10325,
        30,
        1119,
        341,
        257,
        1154,
        30,
        1144,
        291,
        3449,
        300,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3381979465484619,
      "compression_ratio": 1.5504586696624756,
      "no_speech_prob": 0.003262885380536318
    },
    {
      "id": 67,
      "seek": 32732,
      "start": 1721.2199938964843,
      "end": 1728.2600024414062,
      "text": " AI tells your students wrong things and they pick it up or is it, do they",
      "tokens": [
        51068,
        7318,
        5112,
        428,
        1731,
        2085,
        721,
        293,
        436,
        1888,
        309,
        493,
        420,
        307,
        309,
        11,
        360,
        436,
        51420
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3381979465484619,
      "compression_ratio": 1.5504586696624756,
      "no_speech_prob": 0.003262885380536318
    },
    {
      "id": 68,
      "seek": 32732,
      "start": 1729.300010986328,
      "end": 1731.300010986328,
      "text": " notice it when it happens?",
      "tokens": [
        51472,
        3449,
        309,
        562,
        309,
        2314,
        30,
        51572
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3381979465484619,
      "compression_ratio": 1.5504586696624756,
      "no_speech_prob": 0.003262885380536318
    },
    {
      "id": 69,
      "seek": 32732,
      "start": 1731.300010986328,
      "end": 1733.300010986328,
      "text": " Yes, so I think",
      "tokens": [
        51572,
        1079,
        11,
        370,
        286,
        519,
        51672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3381979465484619,
      "compression_ratio": 1.5504586696624756,
      "no_speech_prob": 0.003262885380536318
    },
    {
      "id": 70,
      "seek": 35348,
      "start": 1733.779991455078,
      "end": 1737.6199877929687,
      "text": " I think they notice it when it happens because they've explained some of the things that they have seen.",
      "tokens": [
        50388,
        286,
        519,
        436,
        3449,
        309,
        562,
        309,
        2314,
        570,
        436,
        600,
        8825,
        512,
        295,
        264,
        721,
        300,
        436,
        362,
        1612,
        13,
        50580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25464820861816406,
      "compression_ratio": 1.8376067876815796,
      "no_speech_prob": 0.012014089152216911
    },
    {
      "id": 71,
      "seek": 35348,
      "start": 1740.1799853515624,
      "end": 1747.2199938964843,
      "text": " The thing is that at the end of the day, they're responsible for the final work and I think an irresponsible student will spit out",
      "tokens": [
        50708,
        440,
        551,
        307,
        300,
        412,
        264,
        917,
        295,
        264,
        786,
        11,
        436,
        434,
        6250,
        337,
        264,
        2572,
        589,
        293,
        286,
        519,
        364,
        46320,
        3107,
        486,
        22127,
        484,
        51060
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25464820861816406,
      "compression_ratio": 1.8376067876815796,
      "no_speech_prob": 0.012014089152216911
    },
    {
      "id": 72,
      "seek": 35348,
      "start": 1747.300010986328,
      "end": 1749.300010986328,
      "text": " whatever the LLM gives them.",
      "tokens": [
        51064,
        2035,
        264,
        441,
        43,
        44,
        2709,
        552,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25464820861816406,
      "compression_ratio": 1.8376067876815796,
      "no_speech_prob": 0.012014089152216911
    },
    {
      "id": 73,
      "seek": 35348,
      "start": 1749.7000048828124,
      "end": 1752.4200061035156,
      "text": " A responsible student knows that",
      "tokens": [
        51184,
        316,
        6250,
        3107,
        3255,
        300,
        51320
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25464820861816406,
      "compression_ratio": 1.8376067876815796,
      "no_speech_prob": 0.012014089152216911
    },
    {
      "id": 74,
      "seek": 35348,
      "start": 1753.1400073242187,
      "end": 1755.300010986328,
      "text": " the answer that I give has to be my answer",
      "tokens": [
        51356,
        264,
        1867,
        300,
        286,
        976,
        575,
        281,
        312,
        452,
        1867,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25464820861816406,
      "compression_ratio": 1.8376067876815796,
      "no_speech_prob": 0.012014089152216911
    },
    {
      "id": 75,
      "seek": 35348,
      "start": 1755.8600085449218,
      "end": 1761.4800036621093,
      "text": " and I need to be responsible for it. So they're aware that LLMs can be quite inconsistent",
      "tokens": [
        51492,
        293,
        286,
        643,
        281,
        312,
        6250,
        337,
        309,
        13,
        407,
        436,
        434,
        3650,
        300,
        441,
        43,
        26386,
        393,
        312,
        1596,
        36891,
        51773
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25464820861816406,
      "compression_ratio": 1.8376067876815796,
      "no_speech_prob": 0.012014089152216911
    },
    {
      "id": 76,
      "seek": 38166,
      "start": 1762.279991455078,
      "end": 1766.9200061035156,
      "text": " and sometimes produce errors in the answers that they give.",
      "tokens": [
        50404,
        293,
        2171,
        5258,
        13603,
        294,
        264,
        6338,
        300,
        436,
        976,
        13,
        50636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30975812673568726,
      "compression_ratio": 1.5696202516555786,
      "no_speech_prob": 0.004427995067089796
    },
    {
      "id": 77,
      "seek": 38166,
      "start": 1768.5999987792968,
      "end": 1772.300010986328,
      "text": " When it comes down to things like methods or just plain documented",
      "tokens": [
        50720,
        1133,
        309,
        1487,
        760,
        281,
        721,
        411,
        7150,
        420,
        445,
        11121,
        23007,
        50905
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30975812673568726,
      "compression_ratio": 1.5696202516555786,
      "no_speech_prob": 0.004427995067089796
    },
    {
      "id": 78,
      "seek": 38166,
      "start": 1773.8799975585937,
      "end": 1779.9600146484374,
      "text": " facts, like for example, the structure of Arc 42 for instance or the explanation for each of the parts of Arc 42,",
      "tokens": [
        50984,
        9130,
        11,
        411,
        337,
        1365,
        11,
        264,
        3877,
        295,
        220,
        10683,
        66,
        14034,
        337,
        5197,
        420,
        264,
        10835,
        337,
        1184,
        295,
        264,
        3166,
        295,
        21727,
        14034,
        11,
        51288
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30975812673568726,
      "compression_ratio": 1.5696202516555786,
      "no_speech_prob": 0.004427995067089796
    },
    {
      "id": 79,
      "seek": 38166,
      "start": 1780.3600085449218,
      "end": 1785.6599963378906,
      "text": " they're not usually errors with that. The errors really come in with your specific context.",
      "tokens": [
        51308,
        436,
        434,
        406,
        2673,
        13603,
        365,
        300,
        13,
        440,
        13603,
        534,
        808,
        294,
        365,
        428,
        2685,
        4319,
        13,
        51573
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30975812673568726,
      "compression_ratio": 1.5696202516555786,
      "no_speech_prob": 0.004427995067089796
    },
    {
      "id": 80,
      "seek": 38166,
      "start": 1787.080009765625,
      "end": 1789.080009765625,
      "text": " And so it's their responsibility.",
      "tokens": [
        51644,
        400,
        370,
        309,
        311,
        641,
        6357,
        13,
        51744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30975812673568726,
      "compression_ratio": 1.5696202516555786,
      "no_speech_prob": 0.004427995067089796
    },
    {
      "id": 81,
      "seek": 38166,
      "start": 1789.6400073242187,
      "end": 1790.9999926757812,
      "text": " Okay,",
      "tokens": [
        51772,
        1033,
        11,
        51840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30975812673568726,
      "compression_ratio": 1.5696202516555786,
      "no_speech_prob": 0.004427995067089796
    },
    {
      "id": 82,
      "seek": 41118,
      "start": 1790.9999926757812,
      "end": 1792.9999926757812,
      "text": " that's a good solution.",
      "tokens": [
        50364,
        300,
        311,
        257,
        665,
        3827,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2138136923313141,
      "compression_ratio": 1.397260308265686,
      "no_speech_prob": 0.0019548493437469006
    },
    {
      "id": 83,
      "seek": 41118,
      "start": 1793.4800036621093,
      "end": 1796.300010986328,
      "text": " Claudine, thanks for sharing your experience.",
      "tokens": [
        50488,
        24858,
        533,
        11,
        3231,
        337,
        5414,
        428,
        1752,
        13,
        50629
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2138136923313141,
      "compression_ratio": 1.397260308265686,
      "no_speech_prob": 0.0019548493437469006
    },
    {
      "id": 84,
      "seek": 41118,
      "start": 1797.32,
      "end": 1799.32,
      "text": " It was really nice to",
      "tokens": [
        50680,
        467,
        390,
        534,
        1481,
        281,
        50780
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2138136923313141,
      "compression_ratio": 1.397260308265686,
      "no_speech_prob": 0.0019548493437469006
    },
    {
      "id": 85,
      "seek": 41118,
      "start": 1799.9600146484374,
      "end": 1802.9999926757812,
      "text": " get to know what you're working on and how you use",
      "tokens": [
        50812,
        483,
        281,
        458,
        437,
        291,
        434,
        1364,
        322,
        293,
        577,
        291,
        764,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2138136923313141,
      "compression_ratio": 1.397260308265686,
      "no_speech_prob": 0.0019548493437469006
    },
    {
      "id": 86,
      "seek": 41118,
      "start": 1803.7199938964843,
      "end": 1804.7600024414062,
      "text": " AI.",
      "tokens": [
        51000,
        7318,
        13,
        51052
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2138136923313141,
      "compression_ratio": 1.397260308265686,
      "no_speech_prob": 0.0019548493437469006
    },
    {
      "id": 87,
      "seek": 41118,
      "start": 1804.7600024414062,
      "end": 1807.7400134277343,
      "text": " Thank you. Thank you very much for having me. It was fun.",
      "tokens": [
        51052,
        1044,
        291,
        13,
        1044,
        291,
        588,
        709,
        337,
        1419,
        385,
        13,
        467,
        390,
        1019,
        13,
        51201
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2138136923313141,
      "compression_ratio": 1.397260308265686,
      "no_speech_prob": 0.0019548493437469006
    }
  ],
  "language": "english"
}