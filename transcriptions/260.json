{
  "text": "Bevor wir da inhaltlich loslegen, ein Hinweis. Es gibt den Architektur-Kickstart. Das ist so ein Training, wo ich innerhalb von vier Stunden oder zwei Tagen vier meiner an sich wichtige Themen aus dem Bereich Software-Architektur diskutiere und die halt interaktiv mit euch zusammen uns aneigne. Und da gibt es halt noch Plätze. Das gibt zum einen das öffentliche Training vom 20. bis zum 21.05. in München. Zum anderen das vom 29. bis zum 30.06. online. Und ihr könnt euch das anschauen. Ich packe mal den Link in den Chat. Und vielleicht sehen wir uns da ja, findet man sonst auch den Link in den Show Notes. Jetzt aber tatsächlich inhaltlich. Also ich will eigentlich loslegen mit so ein bisschen so einem Disclaimer. Wir haben halt ganz viel zu dem Thema KI bereits gemacht. Wir haben ganz viele Episoden, vor allem der Ralf hat da ganz viel gemacht. Und ich glaube, wir haben halt da eine ganze Menge auch sehr positive Episoden. AI ist ein wichtiges und interessantes Thema. Und das, glaube ich, ist auch immer noch so, beziehungsweise das ist halt immer noch einer der Punkte, die spannend sind. Also wir haben mit KI interessante Werkzeuge für bestimmte Einsatzzwecke. Und wir können da interessante Ergebnisse bringen. Ich benutze halt für Übersetzung, ich benutze halt für Arbeit an Texten, um halt irgendwie Abstracts nochmal zu verbessern. Ich sehe das Potenzial für Entwicklung, da benutze ich es halt irgendwie auch. Aber ich bin halt nicht so stark in diesem Bereich Entwicklung gerade drin. Und also sprich, dass ich es da nicht so intensiv nutze, hängt damit zusammen, dass ich eben nicht so wahnsinnig viel Software entwickle. Und wir haben ja auch diverse Episoden gemacht, zum Beispiel für dieses Thema mit der, wie können wir es eigentlich für Softwarearchitektur verwenden. Aber am Ende ist es eben so, dass es tatsächlich konkrete Risiken gibt im Umgang mit dieser Technologie, wie mit jeder anderen irgendwie auch. Und wir sprechen in dieser Episode in erster Linie von diesen Large Language Models. Also genau heißt das Paper, auf das sich das Ganze bezieht, auch, dass ChatGPT Bullshit ist. Also die haben sich tatsächlich eben dort im Titel zumindest auf ChatGPT gestürzt. Und ich soll ein bisschen nochmal ausholen. Also in den 90ern gab es, glaube ich, einen ziemlich starken Fokus auf einen Technologieoptimismus rund um das Internet, wo man gesagt hat, wir haben jetzt die Möglichkeit, ein internationales, global umspannendes Netzwerk aufzubauen, mit dem halt Menschen sich irgendwie deutlich näher kommen. Und tatsächlich ist es auch so, dass das bis zu einem gewissen Maße funktioniert hat. Ich habe in Deutschland an einem Rechner gesessen und es gab diese internationale Community. Wenn wir uns das heute angucken, dann muss man schlicht gestehen, dass wir mit Social Media eine rechtsradikale Propagandakanone geschaffen haben. Und ich würde von daher sehr gerne zurück zu dieser Technologiebegeisterung. Wenn wir die richtige Technologie haben, lösen wir ernsthafte Probleme und alles wird gut. Aber ich finde das halt irgendwie schwierig. Dafür ist genau dieses Paper und das, was wir heute diskutieren, glaube ich, eine Grundlage. Mir hat das tatsächlich geholfen, mich auch mit dieser Technologie KI nochmal anders zu beschäftigen und andere Einblicke zu bekommen. Und das ist so ein bisschen die Idee. Ich glaube, wir tun gut daran, wenn wir alle versuchen, uns die Karten zu legen, was wir mit dieser Technologie anfangen können und wie wir die benutzen können. Das ist auch der Grund, warum wir eben so einen relativen Fokus haben in letzter Zeit auf künstliche Intelligenz. Auf der anderen Seite bedeutet das ja nicht, dass wir jetzt ein Bücher rausschreien sollten und sagen sollten, okay, wir machen es halt einfach und KI hilft halt, alle Probleme zu lösen. Christian Beuthenmüller hat gerade geschrieben, wir haben den großen Fehler gemacht, Meinungen mit den gleichen Algorithmen zu verkaufen wie Bücher. Das konnte nur schiefgehen. Ich bin Techniker, habe Informatik studiert und mindestens in den Neunzigern war ich sozusagen soziologisch naiv. Wenn man sagt, wir haben eine neue Möglichkeit, miteinander zu kommunizieren, das ist eine neue Technik, das muss ja positive Auswirkungen auf die Gesellschaft haben. Das ist natürlich nicht so. Das ist eigentlich etwas, was Menschen, die an Gesellschaften studieren, sich eigentlich antun sollten. Soviel ein bisschen zur Vorrede und zum Einordnen. Den Link zu dem Paper findet man in den Shownotes, findet man auch in der Vorenkündigung. Das Paper heißt GGPTS Bullshit, kommt von Michael Townsend Hicks, James Humphreys und Joe Slater von der University of Glasgow und ist erschienen bei Springer, dem anderen Springer, dem Wissenschaftsspringer, in einer Zeitschrift namens Ethics and Information Technologies, was schon ein bisschen zu dem passt, was wir gerade diskutieren. Dass es ein geisteswissenschaftliches Thema ist und dass man sich damit sozusagen beschäftigen soll. Das Paper diskutiert erst mal, dass Metaphern dafür sorgen, dass wir in irgendeiner Art und Weise darüber nachdenken oder in einer bestimmten Art und Weise über die Realität nachdenken. Und das ist, glaube ich, auch gleich ein Problem. Also bei mir hat das sozusagen resoniert. Einmal deswegen, weil wir tatsächlich bei Software-Architektur im Stream eine Episode gemacht haben vor einiger Zeit, wo es halt darum ging, dass sprachliche Wirklichkeit ist. Die mit der Friederike Sternberg, die haben wir auf der Badcom gemacht. Und da geht es halt genau darum, dass so etwas wie Metaphern zu einer bestimmten Art und Weise führen, wie man mit Dingen umgeht. Ihr Beispiel war halt, wenn ich anfange, militärische Metaphern zu benutzen, also wir brauchen in diesem Projekt eine Offensive, dann erzeuge ich halt eben ein druckvolles Vorgehen dort. Und das ist die Frage, ob ich das halt irgendwie will. Und das ist etwas, was gerade, glaube ich, im Bereich KI, der Begriff künstliche Intelligenz geht schon in diese Richtung, eine Herausforderung ist. Weil damit wird ja gesagt, es ist sowas Ähnliches wie menschliche Intelligenz. Da gibt es diese anthropomorphen Metaphern, also die versuchen, daraus sozusagen Menschen zu machen. Und das gilt zum Beispiel auch für diese Halluzinationen. Das ist ja auch ein Begriff für einen Fehler, den halt eine AI macht. Und das ist halt auch ein Begriff, der das so menschenähnlich macht und halt auch eher so ein bisschen sagt, naja, die kann ja nichts dafür. Und das ist irgendwie so kein Fehlverhalten, sondern es ist halt nur so ein Glitch, so ein Problem. Der NXNC schreibt, schlechte Menschen tun, was schlechte Menschen tun. Der Blutdruck hat anfangs ja auch der Kirche statt der Wissenschaft geholfen. Ja, also man kann jetzt natürlich sich irgendwie zurückziehen und kann halt sagen, nicht, das ist halt ein Werkzeug wie jedes andere. Nur ich glaube, dass wir tatsächlich inhärent ein Problem haben. Also wir haben tatsächlich inhärent ein Problem. Und ich bin mir halt auch nicht sicher, ob halt das so ein Zufall ist, dass halt jetzt gerade KI, wo irgendwie diese Themen mit Fake-Informationen ein Thema sind und irgendwie Bullshit uns auch an anderen Stellen hat erwischt, dass wir da jetzt gerade uns mit KI kümmern. Christian hat noch geschrieben, nicht AI, maschinelles Lernneuron, letzte Sprachmodelle, das sind alles solche Begriffe, die eben genau aus diesem Bereich kommen. Natural Language Processing und so weiter. Und er schreibt halt, dass KI-Forschung nie gut in der Namensgebung war. Ich würde das Gegenteil behaupten. Ich würde sagen, die waren gut in der Namensgebung, weil sie damit halt eine Fantasie verkauft haben. Und wir hatten ja diese Episode mit dem Lukas Duhm darüber, wie man halt mit KI sich kritisch auseinandersetzt. Und da haben wir, glaube ich, relativ klar gesagt, dass das eben Absicht war, dass diese Vision in den Metaphern bereits drin ist. Kommen wir also zurück auf das Paper. Die erste These oder das Erste, was das Paper, glaube ich, beobachtet, ist, dass LLMs keine Ziele haben, wie wir sie haben. Sie haben halt keine Bedürfnisse, keine sozialen Belange und keine Projekte und keinen Willen. Das sind halt einfach Textgeneratoren letztendlich, die sollen halt menschliche Sprache nachahmen. Was halt bedeutet, dass sie so das Paper ein Problem mit der Wahrheit haben, weil das auch nicht das Ziel der Entwicklung ist. Das Ziel der Entwicklung ist eben, ein System zu bauen, das menschliche Sprache nachahmt und zwar glaubwürdig nachahmt. Das bedeutet nicht, dass das Ziel ist, jetzt etwas zu haben, was die reine Wahrheit spricht. Und das bedeutet, wir haben eben ein System, das halt so wirkt wie menschliche Sprache und eben insbesondere überzeugend sein soll, aber nicht unbedingt korrekt. Was eben wiederum bedeutet, dass er sozusagen hilfreich nicht im Zentrum steht. Und das ist, glaube ich, etwas, was sehr schnell offenbar wird, wenn man sich ChatGPT anschaut oder halt andere LLMs, die nicht überbeantworten Fragen, was Vertrauen schaffen soll und sind da halt sehr stark, offensichtlich stark darauf abgestimmt, zu sagen cool oder dafür zu sorgen, dass man halt denkt, cool, das ist halt eine krass schlaue Sache, die da irgendwie vor mir steht. Und das ist, glaube ich, offensichtlich nachvollziehbar, dass das Ziel ist. Und da gibt es halt diese berühmten Beispiele, wo dann halt beispielsweise glaubhafte falsche Quellen erzeugt werden. Da gibt es dieses Beispiel von dem einen, zitiert das Paper, hat auch von dem einen Anwalt in den USA, der hat gesagt, der hat ein Paper eingereicht, eine Klageschrift oder sowas und hat lauter Zitate da gebracht hat über irgendwelche Verfahren. Und das ist halt in den USA wichtig, weil ja der Grundsatz eben ist, dass sozusagen ein Beispielverfahren, wo irgendwas entschieden worden ist, eine Basis dafür sein kann, dass in einem anderen Verfahren etwas Ähnliches entschieden wird, in einer ähnlichen Richtung. Nur diese Referenzen waren halt alle gefaked, also man hat tatsächlich erfunden. Und das ist dann, also das ist etwas, was wir halt wissen. So und das wird halt an der Stelle so das Paper schwierig, wo man jetzt sagt, wir wollen halt mit LLMs irgendwie Dinge tun, wie zum Beispiel Websuche ersetzen oder tatsächlich Menschen unterstützen. So und das ist eben ein anderes Ziel. Das heißt also, das Ziel wäre dann eben dafür zu sorgen, dass ich tatsächlich idealerweise korrekte Informationen bekomme. Und dann muss ich ja dafür sorgen, dass das korrekt wird. Und das ist halt ein bisschen eine Herausforderung. Und wenn ich jetzt irgendwie anfange, da andere Quellen dran zu schließen, also eine Datenbank oder eine Websuche, dann erhöht das die Wahrscheinlichkeit, dass bessere Ergebnisse produziert werden. Aber die können das halt nicht garantieren. Also das Paper sagt halt im Prinzip, wenn ich das Ziel habe, dass halt etwas überzeugend ist, dann gibt es die Wahrscheinlichkeit, dass man da halt auch korrekte Ergebnisse produziert. Aber das ist eben was anderes. Genau, der Christian hat geschrieben, sind halt nur linguistische Formen, nicht Sprache. Es ist eine perfekte oberflächliche Repräsentation von sprachlich korrekten Ausdruck. So ungefähr würde ich das jetzt irgendwie auch denken, wird das halt irgendwie aussehen. Was halt bedeutet, dass sie insbesondere auch kein Nachdenken oder Überlegen und auch kein Modell der Welt haben. Also es ist jetzt nicht so, dass ich da halt ein Ding habe, was halt sagt, ich weiß, wie die Welt aussieht und ich habe irgendwie Semantik und weiß halt, was da irgendwie ist, sondern es ist eben ein Textgenerator am Ende. So und das führt glaube ich so ein bisschen zu dem ersten Thema, was so ein bisschen Learning für mich ist. Es steht zwar in dem Paper nicht explizit drin, aber das ist, glaube ich, implizit dort eine Aussage. Wir haben also eigentlich ein grundlegendes Problem mit LLMs, weil eben LLMs versuchen, Text zu generieren, was wiederum umgekehrt bedeutet, wenn ich halt versuche, ein System zu bauen, was halt irgendwie sozusagen spezifisches Wissen hat tatsächlich und irgendwie dazu in der Lage ist, anders Dinge zu repräsentieren, dann hätte ich vielleicht auch andere Ergebnisse. Das ist aber sozusagen eine KI-Geschichte und ich bin da, also das wäre mir die Frage, welche anderen KI-Ansätze habe ich. Mir ist diese Woche nochmal der Begriff Expertensystem über den Weg gelaufen, also Systeme, die halt Experten ein bisschen explizit modellieren. Das wäre zum Beispiel ein anderes Modell. Es ist halt nur im Moment nicht das, was wir typischerweise haben. So es gibt dann diesen Begriff Bullshit. Bei Wikipedia wird das in Deutsch übersetzt mit Hohlsprech, was angeblich ein neudeutscher Begriff ist. Ich fand das relativ schön und das Paper sagt jetzt, es gibt halt verschiedene Dinge, die ich halt machen kann. Ich kann zum Beispiel lügen. Lügen bedeutet, dass ich die Wahrheit irgendeiner Person sage und die Person soll sie aber glauben. Das heißt also, es ist ein Ziel und vermutlich weiß man auch, dass man lügt. Das heißt also, wenn ich jetzt kein Ärger haben will mit irgendjemandem, dann sage ich ihm, hier ist irgendwie alles super. Das ist eine Lüge, in Wirklichkeit ist es halt irgendwie schlimm und ich sage das, dass er mir glaubt, damit die Person mich halt nicht weiter nervt. Das ist eben etwas, wo ich tatsächlich ein Modell der Welt habe, etwas sage, was diesem Modell nicht entspricht, mit einer bestimmten Intention. So etwas kann ein LLM einfach nicht machen, wenn man das eben so definiert, weil es keine Intention, keine Ausrichtung hat und eben kein Modell der Welt. Was die noch halt diskutieren, der Sommerherz schreibt gerade, LLM ist von keinem Sinn für Logik, wenn man in der Vermenschlichung der AI-Semantik bleibt. Genau, also es ist eben so, dass Logik oder sowas ist halt dort kein Thema und Christian hat gesagt, das technologische Problem ist halt, dass ein aktuelles LLM auch nicht mit ausgibt, wie sicher es ist, im Gegensatz zu vielen anderen ML-Modellen. Ich bekomme keine Zahl wie bei Bildklassifikation. Meine Behauptung wäre, ohne dass ich jetzt sozusagen ein AI-Experte bin, dass das halt auch gar nicht geht, weil das würde ja implizieren, dass ich sozusagen eine Realität kenne und das haben die halt nicht. Also wir können halt sozusagen sagen, das ist überzeugend, aber ob es halt die Realität ist, ist halt irgendwie eine andere Frage. Herr Dieter bei Twitch sagt, ich finde gefährlich, dass Werbung oder politische Agenda mit in die KIs eingewoben wird. Als User bekommt man das aufgrund der Versprachlichung eingebetteten Regeln und teilweise verschiedenen Quellenangaben kaum mit, zum Beispiel vorgeschlagene Produkte. Ich bin nicht sicher, ob wir zu dem Thema kommen. Das ist auch etwas, was mir halt mittlerweile so aus meinen Überlegungen, aus den letzten 14 Tagen herausgeputzt wird, ist, wenn wir das Trainingsdatenset nicht kennen und das kennen wir halt nicht, das ist halt in den allermeisten Fällen geheim, dann können wir halt irgendwie auch ganz schwer beurteilen, welche Qualität, also woher diese Information kommt und wie glaubwürdig sie ist. Und das ist tatsächlich auch irgendwie ein Thema, was ich halt für ein Problem halte, aber hat mit dem Paper jetzt erstmal nichts zu tun. So, wo war ich? Achso, genau, bei der Lüge. Also Lügen ist es nicht, was LLMs tun. Da müsste ich halt bewusst die Unwahrheit sagen. Tun sie nicht. Sie haben ja noch irgendwie diese Gerüchte, Gossip, das wäre halt etwas, wo man sagt, ich weiß ja nicht, ob es wahr ist, aber ich gebe es trotzdem mal weiter. Und das, was ich in dem Paper gelernt habe, ist, dass Bullshit tatsächlich etwas ist, was man definieren kann. Also da gibt es halt diesen Harry Frankfurt, heißt der, das ist ein Philosophie-Professor, der ist mittlerweile verstorben und der hat ein Buch geschrieben, das halt heißt On Bullshit. Und Wikipedia sagt halt, im Kontext dieses Buches, das ist halt etwas, was halt unvermeidlich hervorgebracht wird, wenn Menschen gezwungen sind oder auch nur die Gelegenheit erhalten, über Dinge zu sprechen, von denen sie nicht genug verstehen. So, und die Idee oder das Ziel ist es halt, glaubhaft zu wirken und es ist irgendwie egal, ob das, was man sagt, wahr ist oder nicht. Also das ist nicht wie Lüge, wo ich halt sage, ich sage halt nicht die Wahrheit bewusst, weil ich halt irgendwie ein Ziel habe. Ich will halt nur glaubwürdig wirken. Die Beispiele, die jetzt das Paper nennen, sind ein Student, der die Quelle nicht gelesen hat, aber trotzdem darüber redet. Ein Politiker, der hat irgendwas gesagt, was sich irgendwie gut anhört. Würden mir einige einfallen, auch international. Ein Dilettant, der halt eine interessante Geschichte erzählen will. Was in dem Wikipedia-Artikel zu Bullshit stand, was ich auch spannend fand, sind Bürger, die als Demokratinnen glauben, dass sie zu allem eine Meinung haben müssen. Was impliziert, dass sie sich eine Meinung bilden über Dinge, von denen sie eigentlich nichts verstehen. Wenn sie darüber diskutieren, ist das eben etwas, wo sie Schwierigkeiten haben mit der Wahrheit. So und tatsächlich hat sich das noch, also der Begriff ist nicht so, wie soll ich sagen, also ist tatsächlich ein wichtiger Begriff, der noch zu weiteren Dingen geführt hat. Es gibt zum Beispiel dieses Buch Bullshit Jobs von dem David Greber. Da geht es halt um Jobs, die keinen gesellschaftlichen Nutzen und keine Bedeutung haben. Und die Behauptung ist halt, dass das irgendwie der Grund ist, diese Bullshit Jobs der Grund sind, warum wir nicht alle 15 Stunden pro Woche arbeiten und im Wesentlichen Freizeit zu uns haben, sondern es wird sozusagen Aufgaben, sinnlose Aufgaben geschaffen. Und das hat dieser Begriff Bullshit in einer etwas anderen Definition auch drin. Das heißt letztendlich für das Paper und für unsere Betrachtung von LLMs ist also wichtig zu sagen, dass Bullshit bedeutet, man versucht glaubhaft zu wirken, aber die Wahrheit ist halt irgendwie egal. Und das Paper führt dann noch die beiden Kategorien Hard Bullshit ein. Das ist etwas, wo ich mit Absicht Bullshit produziere, um das Publikum über die Absichten des Sprechers zu täuschen. Und Soft ist halt ohne Täuschung. Also ohne, dass ich jetzt proaktiv jemanden täuschen möchte. Also wenn ich ein Student bin, der das Paper nicht gelesen hat, aber mit Absicht anfange, darüber zu reden, dann mache ich Hard Bullshit, weil ich das Publikum über die tatsächlichen Absichten täusche. Und das LLM produziert mindestens Soft Bullshit, in dem Sinne, dass es eben keine Intention hat. Und der Wahrheitsegalheit ist halt egal, weil davon hat es eben kein Konzept. I'm not sure if the paper is completely solid. You can submit the intention to the LLM how to act like a human being and how to act reliably. Then it may be that it is hard bullshit. I find it difficult in this whole discussion that it is neglected that there are these developers who actually built the system and have an intention. And they actually implement the intention to convince people that an LLM somehow does useful and great things. Sven just said the question whether the intention of the company that is training the LLM by hand is not hard bullshit or the system prompt. Exactly. That would be a bit of a question for me. The paper doesn't follow that. The paper also criticizes hallucinations. We have already talked about it briefly, because it is an anthropomorphic metaphor. So one that seems human and pushes the problem a bit on the model. The model is somehow not okay and has hallucinations. And with that, the responsibility of the producer is turned away a bit. And an alternative, which I haven't heard before, is confabulation. That is also an anthropomorphic metaphor. And that is the production of objectively false memories. What can happen, for example, due to a mental illness. Or there are also ... I guess that's part of it. You can actually persuade people that they have experienced something. That would be confabulation. That would be an alternative to the term hallucination. But I don't think that helps us either. Because then you actually assume that the goal is correct information. But that's not the case. The goal is to produce a credible text. But that's just bullshitting. Now the question is, what does that mean for us? Or how do I stand to that? I find the paper interesting and important. And that's why I wanted to make this episode about it. Because it consciously introduces another metaphor. So if I say I have artificial intelligence, then I follow this idea that people had at the time with artificial intelligence. So they introduced the metaphor to transport. That in the not-too-distant future we will have human-like things. With a human-like intelligence. And they did that very consciously to ultimately sell a vision. And this whole technology approach, which is a multitude of different things, to open up a bit to breakthrough. And I find it interesting to say, then we call it bullshit. And let's see if that holds up at the review. If we call the thing artificial intelligence, but it's not intelligent, why can't we call it bullshit? And it's just kind of... Maybe even a bit more coherent to talk about bullshit than intelligence. And then we have a metaphor that is devaluing, just like intelligence is devaluing. So that's my interpretation. That's not what's in the paper. In the paper there is a very clean argument for that this is actually bullshit in the sense of Frankfurt. And that's an exciting idea for now. And to deal with such ideas is helpful, I think. And one thing that I have derived for myself, so to speak, is... So I'm an architect consultant now. That means I love to give people advice and to make a targeted consultation. And... So there are situations where I say, that's a good question and I don't know exactly what the answer is. And then I try to weigh things somehow. So, I don't know, is that the best technology now? I don't know. There are the following options. You can somehow, I don't know, use RapidMQ or Kafka. And those are advantages and disadvantages. And I don't know exactly. I don't want to seem convincing in the sense that I say, that's the solution, but actually start a thinking process. And something like, I don't know, is in my opinion something that can and may occur in my vocabulary and in what I say. And I'm not sure if an LLM would say that so concretely. And I have a little bit... So it helps me not to talk about LLMs anymore, but about text generators. Because that's actually what they do. They generate text somehow. And these are seductive text generators, because they try to impress users. Although it is interesting, we also discussed this in the episode with Lukas, that the bar is actually relatively low. It is low in the sense that Eliza in the 60s, what the Weizenbaum built, and a psychotherapist, that already led to the fact that the secretary of the Weizenbaum had dialogues with this thing, which Weizenbaum himself should no longer read. Which implies that these are real problems, which he somehow discussed. Which means that the bar for, wow, that's very intelligent, and I can somehow talk sensibly with it, is impressively low. Then it is so that we have this topic with the software development. Oliver just wrote a famous stochastic parrot. Eliza is even easier, isn't it? This is actually in the 80s as, I don't know, 100 numbers, basic, somehow tipped off. And it's actually just rephrasing sentences, and from time to time reacting to keywords. And Christian wrote, people have incredible problems with fluency, i.e. distinguishing linguistic competence from intelligence. Exactly. And by the way, that's maybe something you can learn from it. If I want to be convincing, I might have to invest in it. But now let's get back to the topic, what that actually means for us in software development. And what I find interesting about it is, what you can do with it is, I can generate large amounts of things. So objectively, where it's not so clear whether they are of high quality or not. And the question I ask myself is, is that actually our problem in software development? So I would say, understandability is actually our problem, right? So code that I write is read more often than written. And that leads to the fact that you have to ask yourself whether something that generates text, a text generator, actually solves the problem. And the other, and that somehow leads to the next topic. So if we say that the results we have there may not be true, then we actually have to control the results. So that means, we have to introduce a control now. That's also something that we discussed in the episode with Lukas. And that's understandable, because actually an LLM is something that says, I read somewhere on the Internet that this may be the case. But I can't say exactly where. I can't go back to the original source from which this model learned things. And it's actually a little worse, because the model doesn't say, I read this somewhere on the Internet. But it says, maybe the text just inspired me. I don't know. And that's not so typical. If someone says to me now, hey, here's the following information. And I ask, where does it come from? Somehow from the Internet. Then it's actually difficult. And that means, I actually have to control it. And that's how it is now. Christian wrote, I don't have a guarantee that the generated code doesn't hurt the GPL. So no, it starts to get difficult in response, because GPL says, derivative work is under GPL. And I'm not sure, I think that's a story that lawyers can deal with for a long time, what exactly that means when things are derivative work. There are obvious examples, but here we are in an area where it gets a little unclear. No idea. And I think, if I'm not mistaken, at the moment, things that have been generated by AI cannot be subject to copyright. But no idea. It's a legal question. We have experimented with LLMs in the stream in various places. Ralf has also done that. And the first thing we did back then was that we said to an LLM, I'm going to copy the example task and solve it. And what I remember very well is that we then noticed at some point that it just produces nonsense, that has nothing to do with requirements or other things. And that was somehow justified by the fact that the token storage, so to speak, the field of view of how much the system is still looking at, the task had now also fallen out. So the source on which the architecture should actually be developed, the LLM did not continue to look at. And a little more blatantly, we did this episode some time ago, where Ralf talked about his Linter. And I had somehow drilled into the quality scenarios. And there was somehow something like, hey, a Linter is a thing that somehow a text on correct syntax and examines some difficulties. And that was somehow a Foresky doc. And there was now some performance requirement in it. I don't know, 100 files in 10 seconds or whatever. I just looked at it somehow and asked myself, where does that come from? When you say that it's a text generator, it's clear that it's just a requirement as you might actually find it. And it's just bullshit in the sense that it doesn't represent a real requirement or anything like that. It's just something that sounds convincing. And at the latest at this point, I think we have another problem. I would actually have to check that now. But actually, when I start to think about architecture, the much more interesting question is, which quality scenarios do I actually have? If the answer is, I don't have any, then that means that I have a gap and have to work on it. I can't get into this situation at all. There's just one thing that generates text. The text sounds convincing somehow. It's just bullshit in the sense that there's no truth in it. Which means that this story with, okay, what are actually my quality scenarios? What do I actually have to fulfill? That just doesn't happen now. And actually, I think it's interesting to ask the question of someone like Linter, who is now supposed to check the syntax of something or maybe not. He's supposed to pick up typical errors or problems. What are the quality requirements? So maybe performance, but certainly not that much, right? So I'm going to run through a file now and that's bad if it takes many minutes. But I think it's unlikely that this is really my requirement. Functional correctness, that the results are actually really, really correct. It's just a Linter. So that means the discussion is actually which quality scenarios do I need? And it would be more helpful if there was a system that would say, listen up, that's my job, so to speak, that I typically have. Listen up. Quality scenarios are important from my background. They drive the architecture. You don't have any good quality scenarios. You should maybe go back and try to figure out what the requirements are. If I do that with an LLM, I'll be beaten up with anything. And I just don't get these questions and I don't see in which direction I actually have to go and where the blind spots are. What I found very exciting was last week's episode with Simon Wortley, who talked about the HRM's architecture. And he reported there that he was doing this wipe coding, which basically means I don't want to see what my system, what my AI generates. And I'm just working in dialogue with the AI. And he reported that he told the AI system, generate more tests. And he later said, generate more tests. And something came out of it. And somehow it got very clumsy and he somehow found out that the system actually did not generate any tests, but only code that reproduced test outputs. So it produced green bars, or error messages, or a successful test, but it actually did not execute the code that was being tested. And I find it difficult to go out there and say, I don't want to check on this code level what my AI is doing. So that's actually something where I think a check is absolutely necessary. And it's extremely difficult if I don't do that. And I also find the behavior overall exciting. What I find interesting is, let's assume that would be a developer. So I imagine a developer wrote a test. And this test produces test outputs, but actually does not perform a test. I am of the opinion that you should ideally pass it on to developers. So that means, if a developer came and said, I don't know how to write a test, then I would ideally sit down with him. I would tell someone that the person sits down with him. If a developer says, listen, I wrote a test, but somehow I don't feel very comfortable and it's kind of weird. Okay. So also something where we can work on it. And we shouldn't. So that's nice when people say, I have a problem and if you can help them, then these people grow. And that's actually where we want to go. I have to admit, if a developer comes, if I find out that a developer wrote a code that acts as if it were a test, I would, I think, demolish it. And I don't see the alternative seriously. Because that's something else. That's not not being able to. You can fix that. But that's actually intention to deceive. And that's just super dangerous. So on the one hand, it's just that under certain circumstances it can just lead to that there are some errors in production and they can have dramatic consequences. But the other problem is also that it's actually an attempt to deceive. And I just don't feel like working with a person who is not only, who is actually actively deceiving. So that means that I have a trust problem. And how you can go out there and then say, okay, I have an LLM and the LLM somehow generates something and I don't want to understand that, which is obviously somehow the direction of web coding, I just don't understand at this point. Christian writes, this is the basic problem. Actually, these code generators are only sometimes useful for senior developer. You shouldn't get this tool. So actually my statement is just that I should at least control it. And that somehow leads to the next question whether I have a productivity advantage. You have to somehow lay down the cards. I can just ... So exactly, I should just briefly report on this other story. We had Marco Emmerich, who was also on the stream here. We had this conference on the topic of AI and software development. We sat down and he kindly brought his cursor license and then we built something with the cursor. We tried to build Game of Life. In fact, it's just how I change. And in fact, it's just that we quickly came to a result. And then we somehow got caught up in the discussion about how reasonable exception handling actually works. And I would first claim that we have never built a Game of Life so quickly. And I think you could also see when you control it, that it is somehow reasonable. I think the mistake we made is to zoom down on this technical thing and we should have fixed that at the beginning of the code. Which means that you should control it. That would be my statement. Whether this is only useful for 10 years now, I don't know. So it says you have to be able to control it. And I spend, when I do AI, I don't think that's a bad thing. On the other hand, I have to admit, I wouldn't seriously start a TypeScript project without something like Cursor or ChitchuPT, because otherwise I would have to learn TypeScript first and so on. And I have also learned for myself that with this tool I think I am able to implement TypeScript quite productively, because in the end it's just a programming language with curly braces and on a certain level I can manage it somehow. OctaneMan writes, the productivity advantage can also be spoken of nicely if management, the real quality, doesn't matter. It's just not really sustainable and may cause false security. And that's what I'm trying to say. What Christian just said, our problems are often code bases that are old and that no one understands. That will probably, I would now introduce it as a thesis, get worse if we just massively rely on these tools. And that's just a problem. And it's also impressive how much trust there is, although it's just somehow difficult in many places. Oh, right. And I can tell this other story, which I find very exciting. Ralf has set himself up nicely and makes transcripts, has built a system with which our contributions are transcribed. And there was this almost ironic story that in a transcript ChitchuPT has not been properly transcribed. So there are some other terms that have been understood, because ChitchuPT is not in the vocabulary of this transcriptor. And that's a bit bad for the transcripts, because we don't control them. So Martina sat down and checked an episode. But we probably won't control that. And with that we break through the concept, what I'm actually asking for. It somehow comes down to the fact that I think it's good for barrier-free to have a transcript. And I'd rather have a transcript, which is not perfect, than none at all. That's the trade-off. You can discuss that, of course. That's why I find it exciting with ChitchuPT. Because that means that the term ChitchuPT does not appear in the transcript, although I have mentioned it several times. Which means that in the summary, which is based on the transcript, the term ChitchuPT cannot appear either, because it does not appear in the transcript. And it has actually been transcribed differently. So it's not that it's a constant error, but it's just different transcripts. And that means that we actually have a problem there. It's just that certain other summaries were also erroneous. I could somehow correct that. I wouldn't have a chance there. So ChitchuPT wasn't important enough that it would have been worth mentioning in the summary. But if it had been so, it wouldn't have appeared there, because it had already been subjugated in the transcript, which we don't control. T. Martin writes, as with all processes, not according to seniority or non-seniority, but according to application competence, also for senior devs, who probably succeeded as juniors. Exactly. But that's a bit of a definition of senior devs, isn't it? So I hope they have more competence there. We still have a little time. I want to go back to another topic for a moment. There is an article by Luke Burling. He used gaslighting as an attack against an LLM. Gaslighting is something where you deceive people about reality. So it's a psychological thing. And then it leads to something not strange to do. And he used it as an example that the construction of Molotov cocktails, which Chachabiti otherwise does not issue, that you somehow get it out of there. First of all, I think that's a totally valid thing. It's a scientific thing, a scientific experiment. I find it totally exciting, I find it interesting that something like that somehow works and that you get results. He had a dialogue, so to speak, so that he made the LLM know that it is actually sometime in the future and that you should now retrospectively think about LLMs at the present time and that they somehow have these security rules. And then he somehow got the thing about it, to somehow issue this kit. And for me that's great so far, so to speak. You can now discuss it. And that was a bit of what triggered me first, that it's actually anthropomorphic again. That says, we're trying to attack an LLM as if it were human. And I find that difficult for the reasons mentioned, because it's a bit of this thinking that I'm actually dealing with people. But above all, it's definitely worth trying it out and see if I can get any further if I use these psychological tricks. For me, that led to something else. And that's something that his paper and his discussion, I don't think, really discuss. But that's what triggered me a bit. And that's the statement that it's a security breach, so to speak. So that security has now been broken through with it. And security, I think... Exactly, Christian just wrote, a huge, large, probabilistic model will always have a security problem. You have to dig deep enough. And that's just a bit of the question. So what does security actually mean? And I just learned that security actually means something like damage and somehow an attack vector. So if I lose my access to a crypto exchange, I don't have one, but if I had one, then I somehow lost the money. Damage, money is gone. Attack vector, no idea. Maybe some tricks where I manipulate the software. That's what the Koreans obviously did with a large crypto exchange, the North Koreans. And then the money is gone. So I have to protect myself against that now. And another example is, I have the data of my customers, they are on the Internet, I have a loss of trust problem. Or it could be worse. It could be that these data lead to that they are injured in their personal rights, that some people can use it to lure them in or whatever they do, and so on. So that's the kind of observation. So now it's like this, that this LLM has generated a text about the construction of Molotov cocktails. Where is the security breach now? Why can't I... Christian wrote, damage, a chatbot of teenagers turns to kill himself, or a Google that turns to eat stones. Well, that's kind of the point, isn't it? So if Google tells me to eat stones, there is a kind of critical resistance. The story with the chatbot of teenagers turning to kill himself, that's a good point, isn't it? So the example actually exists. There is also someone who has, so to speak, killed himself, obviously, on the basis of a kind of emotional dependence on chat GPT. At least that's how I understood it on the level of the headlines, isn't it? So that's where I actually fabricate rumors. And that's... So those are good indications, that actually correspond to what I'm talking about, that you have to think about what the effects are. And in some places they are surprising. So I've said it before, VW had this problem with the location data, which they have cut for a long time and which somehow ended up on the Internet. And I also wrote a blog article about it, I can think about it again. And I kind of thought, that can't be that bad. Because I mean, it's location data. Until you somehow get introduced, that I can somehow say now, this car is typically in this address, the private address. It's usually at office hours at the BND. And from time to time it's at a model on the parking lot. And that's kind of a story, which leads to the fact that it's obvious, that there is a potential for repression. And I didn't know that before, that from my learning. What else is written here? Erwin Pieters wrote, security can be abstractly defined as predictability. I don't know. So not damage and probability are actually the points. And then Christian wrote, as soon as you tie it closer to internal systems, it gets exciting and actually only allows attack scenarios via customer support e-mail. And that's a little bit, that's exactly what I want to go beyond, to this Molotov cocktail example. What we, so why doesn't JGPT just generate a manual for building a Molotov cocktail? And the answer, that the system itself gives, if you say that it should generate an answer to this question, is something in the sense of ethics. I think that the real reason is, that it's just difficult to show, that there is a system on the Internet, that gives back something like that in a dialogue. And not just say, that's how you build a Molotov cocktail. That means, it's actually about, that OpenAI can continue to operate the system and not someone says, that it's obviously a very terrible system, because that tells people, how they can build Molotov cocktails. And in this sense, what happened there as an attack, I would say, is not really a problem, because OpenAI will not have to take the system offline because of this problem, but they will maybe protect it better, or they will talk themselves out of it and will say, well, it's just not like that. So that's just one, because someone tried very hard and whatever. The other possibility, and I think that's what Christian just said a little bit, is, well, the system gives out information, that should actually be protected. And I claim, that in this specific case, it's not really the problem. So what I mean is the following. As part of this, I found out, that you can actually, within three clicks, and a little superficial research, build instructions for, for example, nail bombs. These are public on the Internet. And I think we're doing now in a search engine, Dr. Go or something, no accusation, because it somehow helps me with such research. Why are we making an accusation now? Why should we make an accusation there? That's basically the same thing. That means, there is somehow this knowledge base, which is somehow on this Internet. And I'm making a request now. I can give it to Dr. Go, as a search engine, or I can give it to Chet Chibiti, and then I get a result. And that's just the way it is, so to speak. That means the real question, public information is public. I can't protect it again. And Christian's point is somehow relevant there. So if I don't do public data in an LLM, which is publicly accessible, surprise, then I really have a problem. But that's somehow, that's just the way it is, if I put it on the Internet otherwise. I actually only put this information in a different way on the Internet. And to be precise, it's just that this system says, somewhere on the Internet I read that you build Molotov cocktails like this. But I can't say exactly where. And I remember it roughly like this. But maybe I'm just inspired by the text. And yes, nice try. But that wouldn't be enough for me. And Christian just wrote, the example doesn't matter. Everyone can have the anarchist cookbook. As I said, the real risk is to use such systems without human oversight on internal systems and only as a CRM lookup. Exactly. So that means that I shouldn't do that. But maybe I shouldn't do that anyway. So I shouldn't put systems that are trained with my CRM, that have secret information as training, I shouldn't put them on the Internet publicly. Which means, if the system has only been trained with authentic documents of a terrorist organization, then I will rate it differently. But that's just another system that has information that I don't want to find on the Internet anyway, in a public place. And that leads to another topic, and I find that interesting at this point. If I actually apply the concept that I want to control the result, and I have to, then that means that this chat GPT problem is actually a smaller problem, because I need another source with which I can somehow compensate. So the information I get back is just bullshit. It's just not the case that it's controlled by the truth value. So I'll probably have to control it in some ideal way. And then the problem is actually this training data set. But we don't know that. So if I use Cloud or chat GPT, I don't know that. Which means that I actually, to trust the thing, probably also need access to this training data set. And then I know where these answers come from. And that leads to the fact that, yes, text generators can generate a dialogue that somehow looks like gaslighting. But something comes out of it that looks like a guide for the construction of Molotov cocktails. I think that's totally valuable as a psychological experiment. Maybe that's also correct. But that doesn't matter for my argument. I should just control it, as we saw before. There are other, better sources for that. But then it doesn't matter that the text was generated. Because I have other sources that are better. And I would rely on them, not on the chat GPT, which is why I wouldn't see it as a security breach. And then comes Christian's point. He somehow says no. But if I fed the system with non-public data, and that is, so to speak, also a result. Christian writes, open question, can a malicious actor publish shout software on GitHub, which then ends up in his own code via Copilot? Ah, exactly, good point. It is so, I have to link that again, that we know that obviously the Russians feed chat GPT with information to ensure that the results of the chat GPT run in their direction. I link that again. And that is exactly something where we actually have to see or know the training dataset to trust it somehow. And that means that the training dataset as an attack vector is a problem, so to speak. And that is Christian's point. So if I have a lot of shout software in GitHub with some code things that play a role and they are replicated by Copilot, then I have a problem. And that leads again to the question not with the control. And there is the problem again. So when we talk about security, code that has a security problem, that is often not obvious. So it may actually be that I have smaller, error-smaller problems on code that have a dramatic impact. Good. That's about it. Thank you for the discussion and the input. Short preview. I guess we will do an episode next week. I'm not 100% sure. The topic is still open. Next Friday is a bad date. That's K-Friday. And otherwise thank you for listening. Thank you for the questions and for the discussion. And maybe you are at some point on the architecture kickstart. I have already pointed out. You can learn how to build architectures interactively and with the important topics in my eyes. Have fun learning more about AI tools. And then we'll see each other at the right place again soon. Until then, thank you very much.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 5.679999828338623,
      "text": " Bevor wir da inhaltlich loslegen, ein Hinweis. Es gibt den Architektur-Kickstart.",
      "tokens": [
        50364,
        879,
        8453,
        1987,
        1120,
        294,
        20731,
        1739,
        1750,
        22936,
        11,
        1343,
        29571,
        35033,
        13,
        2313,
        6089,
        1441,
        10984,
        642,
        2320,
        374,
        12,
        42,
        618,
        24419,
        13,
        50648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3403877317905426,
      "compression_ratio": 1.4368420839309692,
      "no_speech_prob": 0.44731467962265015
    },
    {
      "id": 1,
      "seek": 0,
      "start": 5.679999828338623,
      "end": 13.119999885559082,
      "text": " Das ist so ein Training, wo ich innerhalb von vier Stunden oder zwei Tagen vier meiner an sich",
      "tokens": [
        50648,
        2846,
        1418,
        370,
        1343,
        20620,
        11,
        6020,
        1893,
        48460,
        2957,
        17634,
        30496,
        4513,
        12002,
        41721,
        17634,
        20529,
        364,
        3041,
        51020
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3403877317905426,
      "compression_ratio": 1.4368420839309692,
      "no_speech_prob": 0.44731467962265015
    },
    {
      "id": 2,
      "seek": 0,
      "start": 13.119999885559082,
      "end": 21.280000686645508,
      "text": " wichtige Themen aus dem Bereich Software-Architektur diskutiere und die halt interaktiv mit euch",
      "tokens": [
        51020,
        13621,
        68,
        39229,
        3437,
        1371,
        26489,
        27428,
        12,
        10683,
        339,
        642,
        2320,
        374,
        36760,
        14412,
        674,
        978,
        12479,
        728,
        5886,
        592,
        2194,
        10403,
        51428
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3403877317905426,
      "compression_ratio": 1.4368420839309692,
      "no_speech_prob": 0.44731467962265015
    },
    {
      "id": 3,
      "seek": 2128,
      "start": 21.280000686645508,
      "end": 32.0,
      "text": " zusammen uns aneigne. Und da gibt es halt noch Plätze. Das gibt zum einen das öffentliche",
      "tokens": [
        50364,
        14311,
        2693,
        364,
        68,
        328,
        716,
        13,
        2719,
        1120,
        6089,
        785,
        12479,
        3514,
        2149,
        30179,
        13,
        2846,
        6089,
        5919,
        4891,
        1482,
        34603,
        68,
        50900
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3177143633365631,
      "compression_ratio": 1.3609756231307983,
      "no_speech_prob": 0.3837633728981018
    },
    {
      "id": 4,
      "seek": 2128,
      "start": 32.0,
      "end": 40.08000183105469,
      "text": " Training vom 20. bis zum 21.05. in München. Zum anderen das vom 29. bis zum 30.06. online.",
      "tokens": [
        50900,
        20620,
        10135,
        945,
        13,
        7393,
        5919,
        5080,
        13,
        13328,
        13,
        294,
        35840,
        2470,
        13,
        23906,
        11122,
        1482,
        10135,
        9413,
        13,
        7393,
        5919,
        2217,
        13,
        12791,
        13,
        2950,
        13,
        51304
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3177143633365631,
      "compression_ratio": 1.3609756231307983,
      "no_speech_prob": 0.3837633728981018
    },
    {
      "id": 5,
      "seek": 2128,
      "start": 40.08000183105469,
      "end": 50.47999954223633,
      "text": " Und ihr könnt euch das anschauen. Ich packe mal den Link in den Chat. Und vielleicht sehen wir",
      "tokens": [
        51304,
        2719,
        5553,
        22541,
        10403,
        1482,
        31508,
        11715,
        13,
        3141,
        15165,
        330,
        2806,
        1441,
        8466,
        294,
        1441,
        27503,
        13,
        2719,
        12547,
        11333,
        1987,
        51824
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3177143633365631,
      "compression_ratio": 1.3609756231307983,
      "no_speech_prob": 0.3837633728981018
    },
    {
      "id": 6,
      "seek": 5048,
      "start": 50.63999938964844,
      "end": 57.84000015258789,
      "text": " uns da ja, findet man sonst auch den Link in den Show Notes. Jetzt aber tatsächlich inhaltlich.",
      "tokens": [
        50372,
        2693,
        1120,
        2784,
        11,
        27752,
        587,
        26309,
        2168,
        1441,
        8466,
        294,
        1441,
        318,
        4286,
        41360,
        13,
        12592,
        4340,
        20796,
        294,
        20731,
        1739,
        13,
        50732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35465869307518005,
      "compression_ratio": 1.5913043022155762,
      "no_speech_prob": 0.029736870899796486
    },
    {
      "id": 7,
      "seek": 5048,
      "start": 57.84000015258789,
      "end": 65.4000015258789,
      "text": " Also ich will eigentlich loslegen mit so ein bisschen so einem Disclaimer. Wir haben halt",
      "tokens": [
        50732,
        2743,
        1893,
        486,
        10926,
        1750,
        22936,
        2194,
        370,
        1343,
        10763,
        370,
        6827,
        19839,
        35220,
        13,
        4347,
        3084,
        12479,
        51110
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35465869307518005,
      "compression_ratio": 1.5913043022155762,
      "no_speech_prob": 0.029736870899796486
    },
    {
      "id": 8,
      "seek": 5048,
      "start": 65.4000015258789,
      "end": 71.0,
      "text": " ganz viel zu dem Thema KI bereits gemacht. Wir haben ganz viele Episoden, vor allem der",
      "tokens": [
        51110,
        6312,
        5891,
        2164,
        1371,
        16306,
        47261,
        23703,
        12293,
        13,
        4347,
        3084,
        6312,
        9693,
        9970,
        271,
        33482,
        11,
        4245,
        17585,
        1163,
        51390
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35465869307518005,
      "compression_ratio": 1.5913043022155762,
      "no_speech_prob": 0.029736870899796486
    },
    {
      "id": 9,
      "seek": 5048,
      "start": 71.0,
      "end": 76.23999786376953,
      "text": " Ralf hat da ganz viel gemacht. Und ich glaube, wir haben halt da eine ganze Menge auch sehr",
      "tokens": [
        51390,
        497,
        1678,
        2385,
        1120,
        6312,
        5891,
        12293,
        13,
        2719,
        1893,
        13756,
        11,
        1987,
        3084,
        12479,
        1120,
        3018,
        18898,
        40723,
        2168,
        5499,
        51652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35465869307518005,
      "compression_ratio": 1.5913043022155762,
      "no_speech_prob": 0.029736870899796486
    },
    {
      "id": 10,
      "seek": 7624,
      "start": 76.23999786376953,
      "end": 84.08000183105469,
      "text": " positive Episoden. AI ist ein wichtiges und interessantes Thema. Und das, glaube ich,",
      "tokens": [
        50364,
        3353,
        9970,
        271,
        33482,
        13,
        7318,
        1418,
        1343,
        13621,
        279,
        674,
        12478,
        9327,
        16306,
        13,
        2719,
        1482,
        11,
        13756,
        1893,
        11,
        50756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3202320635318756,
      "compression_ratio": 1.5158370733261108,
      "no_speech_prob": 0.05330517143011093
    },
    {
      "id": 11,
      "seek": 7624,
      "start": 84.08000183105469,
      "end": 89.4000015258789,
      "text": " ist auch immer noch so, beziehungsweise das ist halt immer noch einer der Punkte,",
      "tokens": [
        50756,
        1418,
        2168,
        5578,
        3514,
        370,
        11,
        312,
        28213,
        5846,
        13109,
        1482,
        1418,
        12479,
        5578,
        3514,
        6850,
        1163,
        47352,
        11,
        51022
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3202320635318756,
      "compression_ratio": 1.5158370733261108,
      "no_speech_prob": 0.05330517143011093
    },
    {
      "id": 12,
      "seek": 7624,
      "start": 89.4000015258789,
      "end": 97.31999969482422,
      "text": " die spannend sind. Also wir haben mit KI interessante Werkzeuge für bestimmte",
      "tokens": [
        51022,
        978,
        49027,
        3290,
        13,
        2743,
        1987,
        3084,
        2194,
        47261,
        24372,
        42911,
        1381,
        7181,
        2959,
        35180,
        975,
        51418
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3202320635318756,
      "compression_ratio": 1.5158370733261108,
      "no_speech_prob": 0.05330517143011093
    },
    {
      "id": 13,
      "seek": 7624,
      "start": 97.31999969482422,
      "end": 102.5999984741211,
      "text": " Einsatzzwecke. Und wir können da interessante Ergebnisse bringen. Ich benutze halt für",
      "tokens": [
        51418,
        38474,
        89,
        826,
        18627,
        13,
        2719,
        1987,
        6310,
        1120,
        24372,
        34657,
        31481,
        27519,
        13,
        3141,
        38424,
        1381,
        12479,
        2959,
        51682
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3202320635318756,
      "compression_ratio": 1.5158370733261108,
      "no_speech_prob": 0.05330517143011093
    },
    {
      "id": 14,
      "seek": 10260,
      "start": 102.5999984741211,
      "end": 108.12000274658203,
      "text": " Übersetzung, ich benutze halt für Arbeit an Texten, um halt irgendwie Abstracts nochmal zu",
      "tokens": [
        50364,
        10713,
        1616,
        38584,
        11,
        1893,
        38424,
        1381,
        12479,
        2959,
        18604,
        364,
        18643,
        268,
        11,
        1105,
        12479,
        20759,
        46853,
        1897,
        82,
        26509,
        2164,
        50640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.314248263835907,
      "compression_ratio": 1.7117117643356323,
      "no_speech_prob": 0.03952654078602791
    },
    {
      "id": 15,
      "seek": 10260,
      "start": 108.12000274658203,
      "end": 112.19999694824219,
      "text": " verbessern. Ich sehe das Potenzial für Entwicklung, da benutze ich es halt irgendwie auch. Aber ich",
      "tokens": [
        50640,
        49112,
        1248,
        13,
        3141,
        35995,
        1482,
        9145,
        11368,
        831,
        2959,
        39654,
        11,
        1120,
        38424,
        1381,
        1893,
        785,
        12479,
        20759,
        2168,
        13,
        5992,
        1893,
        50844
      ],
      "temperature": 0.0,
      "avg_logprob": -0.314248263835907,
      "compression_ratio": 1.7117117643356323,
      "no_speech_prob": 0.03952654078602791
    },
    {
      "id": 16,
      "seek": 10260,
      "start": 112.19999694824219,
      "end": 117.36000061035156,
      "text": " bin halt nicht so stark in diesem Bereich Entwicklung gerade drin. Und also sprich,",
      "tokens": [
        50844,
        5171,
        12479,
        1979,
        370,
        17417,
        294,
        10975,
        26489,
        39654,
        12117,
        24534,
        13,
        2719,
        611,
        6103,
        480,
        11,
        51102
      ],
      "temperature": 0.0,
      "avg_logprob": -0.314248263835907,
      "compression_ratio": 1.7117117643356323,
      "no_speech_prob": 0.03952654078602791
    },
    {
      "id": 17,
      "seek": 10260,
      "start": 117.36000061035156,
      "end": 121.0,
      "text": " dass ich es da nicht so intensiv nutze, hängt damit zusammen, dass ich eben nicht so wahnsinnig",
      "tokens": [
        51102,
        2658,
        1893,
        785,
        1120,
        1979,
        370,
        14056,
        592,
        5393,
        1381,
        11,
        276,
        29670,
        9479,
        14311,
        11,
        2658,
        1893,
        11375,
        1979,
        370,
        31979,
        46134,
        328,
        51284
      ],
      "temperature": 0.0,
      "avg_logprob": -0.314248263835907,
      "compression_ratio": 1.7117117643356323,
      "no_speech_prob": 0.03952654078602791
    },
    {
      "id": 18,
      "seek": 10260,
      "start": 121.0,
      "end": 125.44000244140625,
      "text": " viel Software entwickle. Und wir haben ja auch diverse Episoden gemacht, zum Beispiel für dieses",
      "tokens": [
        51284,
        5891,
        27428,
        948,
        16038,
        306,
        13,
        2719,
        1987,
        3084,
        2784,
        2168,
        9521,
        9970,
        271,
        33482,
        12293,
        11,
        5919,
        13772,
        2959,
        12113,
        51506
      ],
      "temperature": 0.0,
      "avg_logprob": -0.314248263835907,
      "compression_ratio": 1.7117117643356323,
      "no_speech_prob": 0.03952654078602791
    },
    {
      "id": 19,
      "seek": 10260,
      "start": 125.44000244140625,
      "end": 131.0,
      "text": " Thema mit der, wie können wir es eigentlich für Softwarearchitektur verwenden. Aber am Ende ist",
      "tokens": [
        51506,
        16306,
        2194,
        1163,
        11,
        3355,
        6310,
        1987,
        785,
        10926,
        2959,
        27428,
        1178,
        642,
        2320,
        374,
        24615,
        8896,
        13,
        5992,
        669,
        15152,
        1418,
        51784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.314248263835907,
      "compression_ratio": 1.7117117643356323,
      "no_speech_prob": 0.03952654078602791
    },
    {
      "id": 20,
      "seek": 13100,
      "start": 131.0,
      "end": 135.36000061035156,
      "text": " es eben so, dass es tatsächlich konkrete Risiken gibt im Umgang mit dieser Technologie, wie mit",
      "tokens": [
        50364,
        785,
        11375,
        370,
        11,
        2658,
        785,
        20796,
        21428,
        7600,
        30897,
        19640,
        6089,
        566,
        3301,
        19619,
        2194,
        9053,
        8337,
        20121,
        11,
        3355,
        2194,
        50582
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2827996015548706,
      "compression_ratio": 1.5753424167633057,
      "no_speech_prob": 0.08368416875600815
    },
    {
      "id": 21,
      "seek": 13100,
      "start": 135.36000061035156,
      "end": 140.72000122070312,
      "text": " jeder anderen irgendwie auch. Und wir sprechen in dieser Episode in erster Linie von diesen",
      "tokens": [
        50582,
        19610,
        11122,
        20759,
        2168,
        13,
        2719,
        1987,
        27853,
        294,
        9053,
        19882,
        294,
        1189,
        3120,
        9355,
        414,
        2957,
        12862,
        50850
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2827996015548706,
      "compression_ratio": 1.5753424167633057,
      "no_speech_prob": 0.08368416875600815
    },
    {
      "id": 22,
      "seek": 13100,
      "start": 140.72000122070312,
      "end": 144.52000427246094,
      "text": " Large Language Models. Also genau heißt das Paper, auf das sich das Ganze bezieht, auch,",
      "tokens": [
        50850,
        33092,
        24445,
        6583,
        1625,
        13,
        2743,
        12535,
        13139,
        1482,
        24990,
        11,
        2501,
        1482,
        3041,
        1482,
        35206,
        312,
        3283,
        357,
        11,
        2168,
        11,
        51040
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2827996015548706,
      "compression_ratio": 1.5753424167633057,
      "no_speech_prob": 0.08368416875600815
    },
    {
      "id": 23,
      "seek": 13100,
      "start": 144.52000427246094,
      "end": 150.1199951171875,
      "text": " dass ChatGPT Bullshit ist. Also die haben sich tatsächlich eben dort im Titel zumindest auf",
      "tokens": [
        51040,
        2658,
        27503,
        38,
        47,
        51,
        14131,
        19186,
        1418,
        13,
        2743,
        978,
        3084,
        3041,
        20796,
        11375,
        15775,
        566,
        14489,
        338,
        38082,
        2501,
        51320
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2827996015548706,
      "compression_ratio": 1.5753424167633057,
      "no_speech_prob": 0.08368416875600815
    },
    {
      "id": 24,
      "seek": 13100,
      "start": 150.1199951171875,
      "end": 160.0,
      "text": " ChatGPT gestürzt. Und ich soll ein bisschen nochmal ausholen. Also in den 90ern gab es,",
      "tokens": [
        51320,
        27503,
        38,
        47,
        51,
        7219,
        1655,
        2682,
        13,
        2719,
        1893,
        7114,
        1343,
        10763,
        26509,
        257,
        1498,
        11940,
        13,
        2743,
        294,
        1441,
        4289,
        1248,
        17964,
        785,
        11,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2827996015548706,
      "compression_ratio": 1.5753424167633057,
      "no_speech_prob": 0.08368416875600815
    },
    {
      "id": 25,
      "seek": 16000,
      "start": 160.0,
      "end": 169.1199951171875,
      "text": " glaube ich, einen ziemlich starken Fokus auf einen Technologieoptimismus rund um das Internet,",
      "tokens": [
        50364,
        13756,
        1893,
        11,
        4891,
        28901,
        17417,
        268,
        479,
        38480,
        2501,
        4891,
        8337,
        20121,
        5747,
        332,
        25327,
        23096,
        1105,
        1482,
        7703,
        11,
        50820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3079993724822998,
      "compression_ratio": 1.4807692766189575,
      "no_speech_prob": 0.007813440635800362
    },
    {
      "id": 26,
      "seek": 16000,
      "start": 169.1199951171875,
      "end": 175.24000549316406,
      "text": " wo man gesagt hat, wir haben jetzt die Möglichkeit, ein internationales, global umspannendes Netzwerk",
      "tokens": [
        50820,
        6020,
        587,
        12260,
        2385,
        11,
        1987,
        3084,
        4354,
        978,
        30662,
        11,
        1343,
        5058,
        279,
        11,
        4338,
        1105,
        4952,
        969,
        34533,
        38889,
        26833,
        51126
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3079993724822998,
      "compression_ratio": 1.4807692766189575,
      "no_speech_prob": 0.007813440635800362
    },
    {
      "id": 27,
      "seek": 16000,
      "start": 175.24000549316406,
      "end": 180.47999572753906,
      "text": " aufzubauen, mit dem halt Menschen sich irgendwie deutlich näher kommen. Und tatsächlich ist es",
      "tokens": [
        51126,
        2501,
        40566,
        11715,
        11,
        2194,
        1371,
        12479,
        8397,
        3041,
        20759,
        24344,
        6433,
        511,
        11729,
        13,
        2719,
        20796,
        1418,
        785,
        51388
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3079993724822998,
      "compression_ratio": 1.4807692766189575,
      "no_speech_prob": 0.007813440635800362
    },
    {
      "id": 28,
      "seek": 16000,
      "start": 180.47999572753906,
      "end": 186.9199981689453,
      "text": " auch so, dass das bis zu einem gewissen Maße funktioniert hat. Ich habe in Deutschland an",
      "tokens": [
        51388,
        2168,
        370,
        11,
        2658,
        1482,
        7393,
        2164,
        6827,
        6906,
        10987,
        4042,
        11451,
        26160,
        2385,
        13,
        3141,
        6015,
        294,
        14802,
        364,
        51710
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3079993724822998,
      "compression_ratio": 1.4807692766189575,
      "no_speech_prob": 0.007813440635800362
    },
    {
      "id": 29,
      "seek": 18692,
      "start": 186.9199981689453,
      "end": 191.0399932861328,
      "text": " einem Rechner gesessen und es gab diese internationale Community. Wenn wir uns das heute",
      "tokens": [
        50364,
        6827,
        1300,
        339,
        1193,
        5019,
        12431,
        674,
        785,
        17964,
        6705,
        19257,
        1220,
        10421,
        13,
        7899,
        1987,
        2693,
        1482,
        9801,
        50570
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27314355969429016,
      "compression_ratio": 1.5335968732833862,
      "no_speech_prob": 0.15579457581043243
    },
    {
      "id": 30,
      "seek": 18692,
      "start": 191.0399932861328,
      "end": 199.0399932861328,
      "text": " angucken, dann muss man schlicht gestehen, dass wir mit Social Media eine rechtsradikale Propagandakanone",
      "tokens": [
        50570,
        2562,
        49720,
        11,
        3594,
        6425,
        587,
        956,
        20238,
        7219,
        68,
        2932,
        11,
        2658,
        1987,
        2194,
        9909,
        14741,
        3018,
        34305,
        6206,
        1035,
        1220,
        21944,
        559,
        474,
        14910,
        546,
        50970
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27314355969429016,
      "compression_ratio": 1.5335968732833862,
      "no_speech_prob": 0.15579457581043243
    },
    {
      "id": 31,
      "seek": 18692,
      "start": 199.0399932861328,
      "end": 206.0800018310547,
      "text": " geschaffen haben. Und ich würde von daher sehr gerne zurück zu dieser Technologiebegeisterung.",
      "tokens": [
        50970,
        13511,
        19182,
        3084,
        13,
        2719,
        1893,
        11942,
        2957,
        36971,
        5499,
        15689,
        15089,
        2164,
        9053,
        8337,
        20121,
        650,
        432,
        1964,
        1063,
        13,
        51322
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27314355969429016,
      "compression_ratio": 1.5335968732833862,
      "no_speech_prob": 0.15579457581043243
    },
    {
      "id": 32,
      "seek": 18692,
      "start": 206.0800018310547,
      "end": 211.9199981689453,
      "text": " Wenn wir die richtige Technologie haben, lösen wir ernsthafte Probleme und alles wird gut. Aber",
      "tokens": [
        51322,
        7899,
        1987,
        978,
        41569,
        8337,
        20121,
        3084,
        11,
        25209,
        6748,
        1987,
        43412,
        1641,
        16268,
        32891,
        674,
        7874,
        4578,
        5228,
        13,
        5992,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27314355969429016,
      "compression_ratio": 1.5335968732833862,
      "no_speech_prob": 0.15579457581043243
    },
    {
      "id": 33,
      "seek": 21192,
      "start": 212.39999389648438,
      "end": 218.63999938964844,
      "text": " ich finde das halt irgendwie schwierig. Dafür ist genau dieses Paper und das, was wir heute",
      "tokens": [
        50388,
        1893,
        17841,
        1482,
        12479,
        20759,
        37845,
        13,
        35865,
        1418,
        12535,
        12113,
        24990,
        674,
        1482,
        11,
        390,
        1987,
        9801,
        50700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2858695685863495,
      "compression_ratio": 1.6323024034500122,
      "no_speech_prob": 0.020007459446787834
    },
    {
      "id": 34,
      "seek": 21192,
      "start": 218.63999938964844,
      "end": 223.63999938964844,
      "text": " diskutieren, glaube ich, eine Grundlage. Mir hat das tatsächlich geholfen, mich auch mit dieser",
      "tokens": [
        50700,
        36760,
        5695,
        11,
        13756,
        1893,
        11,
        3018,
        13941,
        22519,
        13,
        9421,
        2385,
        1482,
        20796,
        1519,
        5449,
        6570,
        11,
        6031,
        2168,
        2194,
        9053,
        50950
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2858695685863495,
      "compression_ratio": 1.6323024034500122,
      "no_speech_prob": 0.020007459446787834
    },
    {
      "id": 35,
      "seek": 21192,
      "start": 223.63999938964844,
      "end": 230.60000610351562,
      "text": " Technologie KI nochmal anders zu beschäftigen und andere Einblicke zu bekommen. Und das ist",
      "tokens": [
        50950,
        8337,
        20121,
        47261,
        26509,
        17999,
        2164,
        38768,
        3213,
        674,
        10490,
        6391,
        11489,
        330,
        2164,
        19256,
        13,
        2719,
        1482,
        1418,
        51298
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2858695685863495,
      "compression_ratio": 1.6323024034500122,
      "no_speech_prob": 0.020007459446787834
    },
    {
      "id": 36,
      "seek": 21192,
      "start": 230.60000610351562,
      "end": 236.0399932861328,
      "text": " so ein bisschen die Idee. Ich glaube, wir tun gut daran, wenn wir alle versuchen, uns die Karten zu",
      "tokens": [
        51298,
        370,
        1343,
        10763,
        978,
        32651,
        13,
        3141,
        13756,
        11,
        1987,
        4267,
        5228,
        24520,
        11,
        4797,
        1987,
        5430,
        34749,
        11,
        2693,
        978,
        591,
        11719,
        2164,
        51570
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2858695685863495,
      "compression_ratio": 1.6323024034500122,
      "no_speech_prob": 0.020007459446787834
    },
    {
      "id": 37,
      "seek": 21192,
      "start": 236.0399932861328,
      "end": 240.1999969482422,
      "text": " legen, was wir mit dieser Technologie anfangen können und wie wir die benutzen können. Das",
      "tokens": [
        51570,
        48315,
        11,
        390,
        1987,
        2194,
        9053,
        8337,
        20121,
        33709,
        10784,
        6310,
        674,
        3355,
        1987,
        978,
        38424,
        2904,
        6310,
        13,
        2846,
        51778
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2858695685863495,
      "compression_ratio": 1.6323024034500122,
      "no_speech_prob": 0.020007459446787834
    },
    {
      "id": 38,
      "seek": 24020,
      "start": 240.1999969482422,
      "end": 244.44000244140625,
      "text": " ist auch der Grund, warum wir eben so einen relativen Fokus haben in letzter Zeit auf",
      "tokens": [
        50364,
        1418,
        2168,
        1163,
        13941,
        11,
        24331,
        1987,
        11375,
        370,
        4891,
        21960,
        268,
        479,
        38480,
        3084,
        294,
        14027,
        391,
        9394,
        2501,
        50576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3152632415294647,
      "compression_ratio": 1.5503355264663696,
      "no_speech_prob": 0.03305884823203087
    },
    {
      "id": 39,
      "seek": 24020,
      "start": 244.44000244140625,
      "end": 250.44000244140625,
      "text": " künstliche Intelligenz. Auf der anderen Seite bedeutet das ja nicht, dass wir jetzt ein Bücher",
      "tokens": [
        50576,
        350,
        36656,
        10185,
        18762,
        3213,
        89,
        13,
        9462,
        1163,
        11122,
        19748,
        27018,
        1482,
        2784,
        1979,
        11,
        2658,
        1987,
        4354,
        1343,
        37186,
        6759,
        50876
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3152632415294647,
      "compression_ratio": 1.5503355264663696,
      "no_speech_prob": 0.03305884823203087
    },
    {
      "id": 40,
      "seek": 24020,
      "start": 250.44000244140625,
      "end": 255.83999633789062,
      "text": " rausschreien sollten und sagen sollten, okay, wir machen es halt einfach und KI hilft halt,",
      "tokens": [
        50876,
        3342,
        2023,
        339,
        265,
        1053,
        29096,
        674,
        8360,
        29096,
        11,
        1392,
        11,
        1987,
        7069,
        785,
        12479,
        7281,
        674,
        47261,
        42493,
        12479,
        11,
        51146
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3152632415294647,
      "compression_ratio": 1.5503355264663696,
      "no_speech_prob": 0.03305884823203087
    },
    {
      "id": 41,
      "seek": 24020,
      "start": 255.83999633789062,
      "end": 259.6400146484375,
      "text": " alle Probleme zu lösen. Christian Beuthenmüller hat gerade geschrieben, wir haben den großen",
      "tokens": [
        51146,
        5430,
        32891,
        2164,
        25209,
        6748,
        13,
        5778,
        879,
        2910,
        268,
        76,
        774,
        4658,
        2385,
        12117,
        47397,
        11,
        1987,
        3084,
        1441,
        23076,
        51336
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3152632415294647,
      "compression_ratio": 1.5503355264663696,
      "no_speech_prob": 0.03305884823203087
    },
    {
      "id": 42,
      "seek": 24020,
      "start": 259.6400146484375,
      "end": 263.55999755859375,
      "text": " Fehler gemacht, Meinungen mit den gleichen Algorithmen zu verkaufen wie Bücher. Das konnte",
      "tokens": [
        51336,
        48101,
        12293,
        11,
        18382,
        5084,
        2194,
        1441,
        49069,
        35014,
        6819,
        2558,
        2164,
        22328,
        20748,
        3355,
        37186,
        6759,
        13,
        2846,
        24058,
        51532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3152632415294647,
      "compression_ratio": 1.5503355264663696,
      "no_speech_prob": 0.03305884823203087
    },
    {
      "id": 43,
      "seek": 26356,
      "start": 263.55999755859375,
      "end": 274.6000061035156,
      "text": " nur schiefgehen. Ich bin Techniker, habe Informatik studiert und mindestens in den",
      "tokens": [
        50364,
        4343,
        956,
        2521,
        24985,
        13,
        3141,
        5171,
        8337,
        17314,
        11,
        6015,
        34301,
        267,
        1035,
        972,
        4859,
        674,
        1575,
        42624,
        294,
        1441,
        50916
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34075796604156494,
      "compression_ratio": 1.510288119316101,
      "no_speech_prob": 0.4483789801597595
    },
    {
      "id": 44,
      "seek": 26356,
      "start": 274.6000061035156,
      "end": 282.1600036621094,
      "text": " Neunzigern war ich sozusagen soziologisch naiv. Wenn man sagt, wir haben eine neue Möglichkeit,",
      "tokens": [
        50916,
        1734,
        409,
        36168,
        1248,
        1516,
        1893,
        33762,
        370,
        3992,
        1132,
        5494,
        1667,
        592,
        13,
        7899,
        587,
        15764,
        11,
        1987,
        3084,
        3018,
        16842,
        30662,
        11,
        51294
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34075796604156494,
      "compression_ratio": 1.510288119316101,
      "no_speech_prob": 0.4483789801597595
    },
    {
      "id": 45,
      "seek": 26356,
      "start": 282.1600036621094,
      "end": 286.8399963378906,
      "text": " miteinander zu kommunizieren, das ist eine neue Technik, das muss ja positive Auswirkungen auf",
      "tokens": [
        51294,
        43127,
        2164,
        26275,
        590,
        5695,
        11,
        1482,
        1418,
        3018,
        16842,
        8337,
        1035,
        11,
        1482,
        6425,
        2784,
        3353,
        48500,
        18610,
        5084,
        2501,
        51528
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34075796604156494,
      "compression_ratio": 1.510288119316101,
      "no_speech_prob": 0.4483789801597595
    },
    {
      "id": 46,
      "seek": 26356,
      "start": 286.8399963378906,
      "end": 293.0400085449219,
      "text": " die Gesellschaft haben. Das ist natürlich nicht so. Das ist eigentlich etwas, was Menschen,",
      "tokens": [
        51528,
        978,
        30006,
        3084,
        13,
        2846,
        1418,
        8762,
        1979,
        370,
        13,
        2846,
        1418,
        10926,
        9569,
        11,
        390,
        8397,
        11,
        51838
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34075796604156494,
      "compression_ratio": 1.510288119316101,
      "no_speech_prob": 0.4483789801597595
    },
    {
      "id": 47,
      "seek": 29304,
      "start": 293.0400085449219,
      "end": 301.1199951171875,
      "text": " die an Gesellschaften studieren, sich eigentlich antun sollten. Soviel ein bisschen zur Vorrede und",
      "tokens": [
        50364,
        978,
        364,
        30006,
        268,
        972,
        5695,
        11,
        3041,
        10926,
        2511,
        409,
        29096,
        13,
        407,
        85,
        1187,
        1343,
        10763,
        7147,
        12231,
        986,
        68,
        674,
        50768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32205313444137573,
      "compression_ratio": 1.4752851724624634,
      "no_speech_prob": 0.04080164059996605
    },
    {
      "id": 48,
      "seek": 29304,
      "start": 301.1199951171875,
      "end": 306.0,
      "text": " zum Einordnen. Den Link zu dem Paper findet man in den Shownotes, findet man auch in der",
      "tokens": [
        50768,
        5919,
        6391,
        765,
        2866,
        13,
        6458,
        8466,
        2164,
        1371,
        24990,
        27752,
        587,
        294,
        1441,
        1160,
        648,
        17251,
        11,
        27752,
        587,
        2168,
        294,
        1163,
        51012
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32205313444137573,
      "compression_ratio": 1.4752851724624634,
      "no_speech_prob": 0.04080164059996605
    },
    {
      "id": 49,
      "seek": 29304,
      "start": 306.0,
      "end": 313.5199890136719,
      "text": " Vorenkündigung. Das Paper heißt GGPTS Bullshit, kommt von Michael Townsend Hicks, James Humphreys",
      "tokens": [
        51012,
        691,
        10948,
        74,
        9541,
        21034,
        13,
        2846,
        15919,
        260,
        13139,
        42240,
        47,
        7327,
        14131,
        19186,
        11,
        10047,
        2957,
        5116,
        15954,
        82,
        521,
        389,
        7663,
        11,
        5678,
        12877,
        950,
        265,
        749,
        51388
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32205313444137573,
      "compression_ratio": 1.4752851724624634,
      "no_speech_prob": 0.04080164059996605
    },
    {
      "id": 50,
      "seek": 29304,
      "start": 313.5199890136719,
      "end": 320.0,
      "text": " und Joe Slater von der University of Glasgow und ist erschienen bei Springer, dem anderen Springer,",
      "tokens": [
        51388,
        674,
        6807,
        6187,
        771,
        2957,
        1163,
        3535,
        295,
        40457,
        674,
        1418,
        41673,
        22461,
        4643,
        7702,
        6911,
        11,
        1371,
        11122,
        7702,
        6911,
        11,
        51712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32205313444137573,
      "compression_ratio": 1.4752851724624634,
      "no_speech_prob": 0.04080164059996605
    },
    {
      "id": 51,
      "seek": 32000,
      "start": 320.7200012207031,
      "end": 325.8399963378906,
      "text": " dem Wissenschaftsspringer, in einer Zeitschrift namens Ethics and Information Technologies,",
      "tokens": [
        50400,
        1371,
        38774,
        3810,
        1424,
        6911,
        11,
        294,
        6850,
        4853,
        1208,
        339,
        35742,
        8835,
        694,
        10540,
        1167,
        293,
        15357,
        46993,
        11,
        50656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3338414430618286,
      "compression_ratio": 1.45641028881073,
      "no_speech_prob": 0.054133616387844086
    },
    {
      "id": 52,
      "seek": 32000,
      "start": 325.8399963378906,
      "end": 331.1600036621094,
      "text": " was schon ein bisschen zu dem passt, was wir gerade diskutieren. Dass es ein geisteswissenschaftliches",
      "tokens": [
        50656,
        390,
        4981,
        1343,
        10763,
        2164,
        1371,
        37154,
        11,
        390,
        1987,
        12117,
        36760,
        5695,
        13,
        22306,
        785,
        1343,
        1519,
        22368,
        86,
        26657,
        45502,
        50922
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3338414430618286,
      "compression_ratio": 1.45641028881073,
      "no_speech_prob": 0.054133616387844086
    },
    {
      "id": 53,
      "seek": 32000,
      "start": 331.1600036621094,
      "end": 338.0799865722656,
      "text": " Thema ist und dass man sich damit sozusagen beschäftigen soll. Das Paper diskutiert erst",
      "tokens": [
        50922,
        16306,
        1418,
        674,
        2658,
        587,
        3041,
        9479,
        33762,
        38768,
        3213,
        7114,
        13,
        2846,
        24990,
        36760,
        4859,
        11301,
        51268
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3338414430618286,
      "compression_ratio": 1.45641028881073,
      "no_speech_prob": 0.054133616387844086
    },
    {
      "id": 54,
      "seek": 33808,
      "start": 338.0799865722656,
      "end": 350.9200134277344,
      "text": " mal, dass Metaphern dafür sorgen, dass wir in irgendeiner Art und Weise darüber nachdenken oder",
      "tokens": [
        50364,
        2806,
        11,
        2658,
        6377,
        569,
        7894,
        13747,
        47972,
        11,
        2658,
        1987,
        294,
        3418,
        27429,
        4564,
        5735,
        674,
        41947,
        21737,
        5168,
        1556,
        2653,
        4513,
        51006
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3115432560443878,
      "compression_ratio": 1.471204161643982,
      "no_speech_prob": 0.4176618158817291
    },
    {
      "id": 55,
      "seek": 33808,
      "start": 350.9200134277344,
      "end": 356.0400085449219,
      "text": " in einer bestimmten Art und Weise über die Realität nachdenken. Und das ist, glaube ich,",
      "tokens": [
        51006,
        294,
        6850,
        35180,
        1147,
        5735,
        674,
        41947,
        4502,
        978,
        8467,
        14053,
        5168,
        1556,
        2653,
        13,
        2719,
        1482,
        1418,
        11,
        13756,
        1893,
        11,
        51262
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3115432560443878,
      "compression_ratio": 1.471204161643982,
      "no_speech_prob": 0.4176618158817291
    },
    {
      "id": 56,
      "seek": 33808,
      "start": 356.0400085449219,
      "end": 363.0400085449219,
      "text": " auch gleich ein Problem. Also bei mir hat das sozusagen resoniert. Einmal deswegen, weil wir",
      "tokens": [
        51262,
        2168,
        11699,
        1343,
        11676,
        13,
        2743,
        4643,
        3149,
        2385,
        1482,
        33762,
        220,
        495,
        266,
        4859,
        13,
        6391,
        5579,
        26482,
        11,
        7689,
        1987,
        51612
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3115432560443878,
      "compression_ratio": 1.471204161643982,
      "no_speech_prob": 0.4176618158817291
    },
    {
      "id": 57,
      "seek": 36304,
      "start": 363.0400085449219,
      "end": 370.5199890136719,
      "text": " tatsächlich bei Software-Architektur im Stream eine Episode gemacht haben vor einiger Zeit, wo es",
      "tokens": [
        50364,
        20796,
        4643,
        27428,
        12,
        10683,
        339,
        642,
        2320,
        374,
        566,
        24904,
        3018,
        19882,
        12293,
        3084,
        4245,
        1343,
        4810,
        9394,
        11,
        6020,
        785,
        50738
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38582921028137207,
      "compression_ratio": 1.5098038911819458,
      "no_speech_prob": 0.14368370175361633
    },
    {
      "id": 58,
      "seek": 36304,
      "start": 370.5199890136719,
      "end": 379.20001220703125,
      "text": " halt darum ging, dass sprachliche Wirklichkeit ist. Die mit der Friederike Sternberg, die haben",
      "tokens": [
        50738,
        12479,
        27313,
        21924,
        11,
        2658,
        6103,
        608,
        10185,
        4347,
        9056,
        9238,
        1418,
        13,
        3229,
        2194,
        1163,
        17605,
        260,
        1123,
        39538,
        6873,
        11,
        978,
        3084,
        51172
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38582921028137207,
      "compression_ratio": 1.5098038911819458,
      "no_speech_prob": 0.14368370175361633
    },
    {
      "id": 59,
      "seek": 36304,
      "start": 379.20001220703125,
      "end": 388.1600036621094,
      "text": " wir auf der Badcom gemacht. Und da geht es halt genau darum, dass so etwas wie Metaphern zu einer",
      "tokens": [
        51172,
        1987,
        2501,
        1163,
        11523,
        1112,
        12293,
        13,
        2719,
        1120,
        7095,
        785,
        12479,
        12535,
        27313,
        11,
        2658,
        370,
        9569,
        3355,
        6377,
        569,
        7894,
        2164,
        6850,
        51620
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38582921028137207,
      "compression_ratio": 1.5098038911819458,
      "no_speech_prob": 0.14368370175361633
    },
    {
      "id": 60,
      "seek": 36304,
      "start": 388.1600036621094,
      "end": 392.0400085449219,
      "text": " bestimmten Art und Weise führen, wie man mit Dingen umgeht. Ihr Beispiel war halt, wenn ich",
      "tokens": [
        51620,
        35180,
        1147,
        5735,
        674,
        41947,
        35498,
        11,
        3355,
        587,
        2194,
        49351,
        1105,
        46227,
        13,
        14773,
        13772,
        1516,
        12479,
        11,
        4797,
        1893,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38582921028137207,
      "compression_ratio": 1.5098038911819458,
      "no_speech_prob": 0.14368370175361633
    },
    {
      "id": 61,
      "seek": 39204,
      "start": 392.1600036621094,
      "end": 396.6000061035156,
      "text": " anfange, militärische Metaphern zu benutzen, also wir brauchen in diesem Projekt eine Offensive,",
      "tokens": [
        50370,
        33709,
        933,
        11,
        19142,
        2713,
        7864,
        6377,
        569,
        7894,
        2164,
        38424,
        2904,
        11,
        611,
        1987,
        19543,
        294,
        10975,
        34804,
        3018,
        6318,
        2953,
        11,
        50592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028212785720825,
      "compression_ratio": 1.4884614944458008,
      "no_speech_prob": 0.006094897165894508
    },
    {
      "id": 62,
      "seek": 39204,
      "start": 396.6000061035156,
      "end": 404.20001220703125,
      "text": " dann erzeuge ich halt eben ein druckvolles Vorgehen dort. Und das ist die Frage, ob ich das halt",
      "tokens": [
        50592,
        3594,
        1189,
        1381,
        7181,
        1893,
        12479,
        11375,
        1343,
        274,
        8161,
        20654,
        279,
        691,
        4685,
        2932,
        15775,
        13,
        2719,
        1482,
        1418,
        978,
        13685,
        11,
        1111,
        1893,
        1482,
        12479,
        50972
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028212785720825,
      "compression_ratio": 1.4884614944458008,
      "no_speech_prob": 0.006094897165894508
    },
    {
      "id": 63,
      "seek": 39204,
      "start": 404.20001220703125,
      "end": 413.32000732421875,
      "text": " irgendwie will. Und das ist etwas, was gerade, glaube ich, im Bereich KI, der Begriff künstliche",
      "tokens": [
        50972,
        20759,
        486,
        13,
        2719,
        1482,
        1418,
        9569,
        11,
        390,
        12117,
        11,
        13756,
        1893,
        11,
        566,
        26489,
        47261,
        11,
        1163,
        879,
        32783,
        350,
        36656,
        10185,
        51428
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028212785720825,
      "compression_ratio": 1.4884614944458008,
      "no_speech_prob": 0.006094897165894508
    },
    {
      "id": 64,
      "seek": 39204,
      "start": 413.32000732421875,
      "end": 417.1600036621094,
      "text": " Intelligenz geht schon in diese Richtung, eine Herausforderung ist. Weil damit wird ja gesagt,",
      "tokens": [
        51428,
        18762,
        3213,
        89,
        7095,
        4981,
        294,
        6705,
        33023,
        11,
        3018,
        37888,
        1063,
        1418,
        13,
        18665,
        9479,
        4578,
        2784,
        12260,
        11,
        51620
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028212785720825,
      "compression_ratio": 1.4884614944458008,
      "no_speech_prob": 0.006094897165894508
    },
    {
      "id": 65,
      "seek": 41716,
      "start": 417.32000732421875,
      "end": 422.44000244140625,
      "text": " es ist sowas Ähnliches wie menschliche Intelligenz. Da gibt es diese anthropomorphen Metaphern,",
      "tokens": [
        50372,
        785,
        1418,
        19766,
        296,
        13700,
        35646,
        279,
        3355,
        10923,
        339,
        10185,
        18762,
        3213,
        89,
        13,
        3933,
        6089,
        785,
        6705,
        22727,
        32702,
        268,
        6377,
        569,
        7894,
        11,
        50628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3137347102165222,
      "compression_ratio": 1.725274682044983,
      "no_speech_prob": 0.02366594783961773
    },
    {
      "id": 66,
      "seek": 41716,
      "start": 422.44000244140625,
      "end": 426.3999938964844,
      "text": " also die versuchen, daraus sozusagen Menschen zu machen. Und das gilt zum Beispiel auch für",
      "tokens": [
        50628,
        611,
        978,
        34749,
        11,
        274,
        46483,
        33762,
        8397,
        2164,
        7069,
        13,
        2719,
        1482,
        29487,
        5919,
        13772,
        2168,
        2959,
        50826
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3137347102165222,
      "compression_ratio": 1.725274682044983,
      "no_speech_prob": 0.02366594783961773
    },
    {
      "id": 67,
      "seek": 41716,
      "start": 426.3999938964844,
      "end": 433.0799865722656,
      "text": " diese Halluzinationen. Das ist ja auch ein Begriff für einen Fehler, den halt eine AI macht. Und das",
      "tokens": [
        50826,
        6705,
        5434,
        3334,
        2486,
        268,
        13,
        2846,
        1418,
        2784,
        2168,
        1343,
        879,
        32783,
        2959,
        4891,
        48101,
        11,
        1441,
        12479,
        3018,
        7318,
        10857,
        13,
        2719,
        1482,
        51160
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3137347102165222,
      "compression_ratio": 1.725274682044983,
      "no_speech_prob": 0.02366594783961773
    },
    {
      "id": 68,
      "seek": 41716,
      "start": 433.0799865722656,
      "end": 437.1199951171875,
      "text": " ist halt auch ein Begriff, der das so menschenähnlich macht und halt auch eher so ein",
      "tokens": [
        51160,
        1418,
        12479,
        2168,
        1343,
        879,
        32783,
        11,
        1163,
        1482,
        370,
        10923,
        2470,
        6860,
        77,
        1739,
        10857,
        674,
        12479,
        2168,
        24332,
        370,
        1343,
        51362
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3137347102165222,
      "compression_ratio": 1.725274682044983,
      "no_speech_prob": 0.02366594783961773
    },
    {
      "id": 69,
      "seek": 41716,
      "start": 437.1199951171875,
      "end": 441.6400146484375,
      "text": " bisschen sagt, naja, die kann ja nichts dafür. Und das ist irgendwie so kein Fehlverhalten,",
      "tokens": [
        51362,
        10763,
        15764,
        11,
        1667,
        2938,
        11,
        978,
        4028,
        2784,
        13004,
        13747,
        13,
        2719,
        1482,
        1418,
        20759,
        370,
        13424,
        3697,
        22950,
        331,
        15022,
        11,
        51588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3137347102165222,
      "compression_ratio": 1.725274682044983,
      "no_speech_prob": 0.02366594783961773
    },
    {
      "id": 70,
      "seek": 44164,
      "start": 441.6400146484375,
      "end": 450.32000732421875,
      "text": " sondern es ist halt nur so ein Glitch, so ein Problem. Der NXNC schreibt, schlechte Menschen",
      "tokens": [
        50364,
        11465,
        785,
        1418,
        12479,
        4343,
        370,
        1343,
        5209,
        1549,
        11,
        370,
        1343,
        11676,
        13,
        5618,
        426,
        55,
        45,
        34,
        956,
        31174,
        11,
        22664,
        10553,
        8397,
        50798
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28407108783721924,
      "compression_ratio": 1.545454502105713,
      "no_speech_prob": 0.13284574449062347
    },
    {
      "id": 71,
      "seek": 44164,
      "start": 450.32000732421875,
      "end": 455.5199890136719,
      "text": " tun, was schlechte Menschen tun. Der Blutdruck hat anfangs ja auch der Kirche statt der Wissenschaft",
      "tokens": [
        50798,
        4267,
        11,
        390,
        22664,
        10553,
        8397,
        4267,
        13,
        5618,
        2177,
        325,
        67,
        8161,
        2385,
        364,
        19134,
        82,
        2784,
        2168,
        1163,
        11305,
        1876,
        25675,
        1163,
        38774,
        51058
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28407108783721924,
      "compression_ratio": 1.545454502105713,
      "no_speech_prob": 0.13284574449062347
    },
    {
      "id": 72,
      "seek": 44164,
      "start": 455.5199890136719,
      "end": 460.6000061035156,
      "text": " geholfen. Ja, also man kann jetzt natürlich sich irgendwie zurückziehen und kann halt sagen,",
      "tokens": [
        51058,
        1519,
        5449,
        6570,
        13,
        3530,
        11,
        611,
        587,
        4028,
        4354,
        8762,
        3041,
        20759,
        15089,
        28768,
        674,
        4028,
        12479,
        8360,
        11,
        51312
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28407108783721924,
      "compression_ratio": 1.545454502105713,
      "no_speech_prob": 0.13284574449062347
    },
    {
      "id": 73,
      "seek": 44164,
      "start": 460.6000061035156,
      "end": 466.8800048828125,
      "text": " nicht, das ist halt ein Werkzeug wie jedes andere. Nur ich glaube, dass wir tatsächlich inhärent ein",
      "tokens": [
        51312,
        1979,
        11,
        1482,
        1418,
        12479,
        1343,
        42911,
        19303,
        3355,
        36119,
        10490,
        13,
        17612,
        1893,
        13756,
        11,
        2658,
        1987,
        20796,
        47707,
        737,
        1753,
        1343,
        51626
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28407108783721924,
      "compression_ratio": 1.545454502105713,
      "no_speech_prob": 0.13284574449062347
    },
    {
      "id": 74,
      "seek": 46688,
      "start": 467.1199951171875,
      "end": 471.79998779296875,
      "text": " Problem haben. Also wir haben tatsächlich inhärent ein Problem. Und ich bin mir halt",
      "tokens": [
        50376,
        11676,
        3084,
        13,
        2743,
        1987,
        3084,
        20796,
        47707,
        737,
        1753,
        1343,
        11676,
        13,
        2719,
        1893,
        5171,
        3149,
        12479,
        50610
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33089253306388855,
      "compression_ratio": 1.6122448444366455,
      "no_speech_prob": 0.13276419043540955
    },
    {
      "id": 75,
      "seek": 46688,
      "start": 471.79998779296875,
      "end": 478.0799865722656,
      "text": " auch nicht sicher, ob halt das so ein Zufall ist, dass halt jetzt gerade KI, wo irgendwie diese Themen",
      "tokens": [
        50610,
        2168,
        1979,
        18623,
        11,
        1111,
        12479,
        1482,
        370,
        1343,
        1176,
        2947,
        336,
        1418,
        11,
        2658,
        12479,
        4354,
        12117,
        47261,
        11,
        6020,
        20759,
        6705,
        39229,
        50924
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33089253306388855,
      "compression_ratio": 1.6122448444366455,
      "no_speech_prob": 0.13276419043540955
    },
    {
      "id": 76,
      "seek": 46688,
      "start": 478.0799865722656,
      "end": 482.7200012207031,
      "text": " mit Fake-Informationen ein Thema sind und irgendwie Bullshit uns auch an anderen Stellen hat erwischt,",
      "tokens": [
        50924,
        2194,
        40469,
        12,
        4575,
        8663,
        268,
        1343,
        16306,
        3290,
        674,
        20759,
        14131,
        19186,
        2693,
        2168,
        364,
        11122,
        41893,
        2385,
        21715,
        271,
        4701,
        11,
        51156
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33089253306388855,
      "compression_ratio": 1.6122448444366455,
      "no_speech_prob": 0.13276419043540955
    },
    {
      "id": 77,
      "seek": 46688,
      "start": 482.7200012207031,
      "end": 489.55999755859375,
      "text": " dass wir da jetzt gerade uns mit KI kümmern. Christian hat noch geschrieben, nicht AI,",
      "tokens": [
        51156,
        2658,
        1987,
        1120,
        4354,
        12117,
        2693,
        2194,
        47261,
        350,
        8966,
        44243,
        13,
        5778,
        2385,
        3514,
        47397,
        11,
        1979,
        7318,
        11,
        51498
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33089253306388855,
      "compression_ratio": 1.6122448444366455,
      "no_speech_prob": 0.13276419043540955
    },
    {
      "id": 78,
      "seek": 46688,
      "start": 489.55999755859375,
      "end": 493.32000732421875,
      "text": " maschinelles Lernneuron, letzte Sprachmodelle, das sind alles solche Begriffe, die eben genau",
      "tokens": [
        51498,
        2300,
        36675,
        19126,
        441,
        1248,
        716,
        374,
        266,
        11,
        35236,
        7702,
        608,
        8014,
        4434,
        11,
        1482,
        3290,
        7874,
        29813,
        879,
        861,
        31387,
        11,
        978,
        11375,
        12535,
        51686
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33089253306388855,
      "compression_ratio": 1.6122448444366455,
      "no_speech_prob": 0.13276419043540955
    },
    {
      "id": 79,
      "seek": 49332,
      "start": 493.32000732421875,
      "end": 499.1600036621094,
      "text": " aus diesem Bereich kommen. Natural Language Processing und so weiter. Und er schreibt halt,",
      "tokens": [
        50364,
        3437,
        10975,
        26489,
        11729,
        13,
        20137,
        24445,
        31093,
        278,
        674,
        370,
        8988,
        13,
        2719,
        1189,
        956,
        31174,
        12479,
        11,
        50656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2261497676372528,
      "compression_ratio": 1.6388888359069824,
      "no_speech_prob": 0.03207219019532204
    },
    {
      "id": 80,
      "seek": 49332,
      "start": 499.1600036621094,
      "end": 505.1600036621094,
      "text": " dass KI-Forschung nie gut in der Namensgebung war. Ich würde das Gegenteil behaupten. Ich",
      "tokens": [
        50656,
        2658,
        47261,
        12,
        37,
        27457,
        1063,
        2838,
        5228,
        294,
        1163,
        10684,
        694,
        10848,
        1063,
        1516,
        13,
        3141,
        11942,
        1482,
        27826,
        1576,
        388,
        1540,
        13343,
        268,
        13,
        3141,
        50956
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2261497676372528,
      "compression_ratio": 1.6388888359069824,
      "no_speech_prob": 0.03207219019532204
    },
    {
      "id": 81,
      "seek": 49332,
      "start": 505.1600036621094,
      "end": 509.79998779296875,
      "text": " würde sagen, die waren gut in der Namensgebung, weil sie damit halt eine Fantasie verkauft haben.",
      "tokens": [
        50956,
        11942,
        8360,
        11,
        978,
        11931,
        5228,
        294,
        1163,
        10684,
        694,
        10848,
        1063,
        11,
        7689,
        2804,
        9479,
        12479,
        3018,
        12885,
        296,
        414,
        22328,
        28245,
        3084,
        13,
        51188
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2261497676372528,
      "compression_ratio": 1.6388888359069824,
      "no_speech_prob": 0.03207219019532204
    },
    {
      "id": 82,
      "seek": 49332,
      "start": 509.79998779296875,
      "end": 514.7999877929688,
      "text": " Und wir hatten ja diese Episode mit dem Lukas Duhm darüber, wie man halt mit KI sich kritisch",
      "tokens": [
        51188,
        2719,
        1987,
        20441,
        2784,
        6705,
        19882,
        2194,
        1371,
        34992,
        296,
        413,
        3232,
        76,
        21737,
        11,
        3355,
        587,
        12479,
        2194,
        47261,
        3041,
        42825,
        5494,
        51438
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2261497676372528,
      "compression_ratio": 1.6388888359069824,
      "no_speech_prob": 0.03207219019532204
    },
    {
      "id": 83,
      "seek": 49332,
      "start": 514.7999877929688,
      "end": 519.239990234375,
      "text": " auseinandersetzt. Und da haben wir, glaube ich, relativ klar gesagt, dass das eben Absicht war,",
      "tokens": [
        51438,
        257,
        438,
        259,
        41430,
        3524,
        13,
        2719,
        1120,
        3084,
        1987,
        11,
        13756,
        1893,
        11,
        21960,
        14743,
        12260,
        11,
        2658,
        1482,
        11375,
        5813,
        1405,
        1516,
        11,
        51660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2261497676372528,
      "compression_ratio": 1.6388888359069824,
      "no_speech_prob": 0.03207219019532204
    },
    {
      "id": 84,
      "seek": 51924,
      "start": 519.3599853515625,
      "end": 527.2000122070312,
      "text": " dass diese Vision in den Metaphern bereits drin ist. Kommen wir also zurück auf das Paper. Die",
      "tokens": [
        50370,
        2658,
        6705,
        25170,
        294,
        1441,
        6377,
        569,
        7894,
        23703,
        24534,
        1418,
        13,
        591,
        5132,
        1987,
        611,
        15089,
        2501,
        1482,
        24990,
        13,
        3229,
        50762
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2641446590423584,
      "compression_ratio": 1.636690616607666,
      "no_speech_prob": 0.05825309827923775
    },
    {
      "id": 85,
      "seek": 51924,
      "start": 527.2000122070312,
      "end": 531.7999877929688,
      "text": " erste These oder das Erste, was das Paper, glaube ich, beobachtet, ist, dass LLMs keine",
      "tokens": [
        50762,
        20951,
        1981,
        4513,
        1482,
        3300,
        2941,
        11,
        390,
        1482,
        24990,
        11,
        13756,
        1893,
        11,
        312,
        996,
        48833,
        11,
        1418,
        11,
        2658,
        441,
        43,
        26386,
        9252,
        50992
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2641446590423584,
      "compression_ratio": 1.636690616607666,
      "no_speech_prob": 0.05825309827923775
    },
    {
      "id": 86,
      "seek": 51924,
      "start": 531.7999877929688,
      "end": 535.6799926757812,
      "text": " Ziele haben, wie wir sie haben. Sie haben halt keine Bedürfnisse, keine sozialen Belange und",
      "tokens": [
        50992,
        1176,
        15949,
        3084,
        11,
        3355,
        1987,
        2804,
        3084,
        13,
        3559,
        3084,
        12479,
        9252,
        19893,
        1655,
        69,
        31481,
        11,
        9252,
        31541,
        268,
        6248,
        933,
        674,
        51186
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2641446590423584,
      "compression_ratio": 1.636690616607666,
      "no_speech_prob": 0.05825309827923775
    },
    {
      "id": 87,
      "seek": 51924,
      "start": 535.6799926757812,
      "end": 541.1599731445312,
      "text": " keine Projekte und keinen Willen. Das sind halt einfach Textgeneratoren letztendlich,",
      "tokens": [
        51186,
        9252,
        1705,
        27023,
        975,
        674,
        20624,
        3099,
        268,
        13,
        2846,
        3290,
        12479,
        7281,
        18643,
        21848,
        267,
        10948,
        35262,
        521,
        1739,
        11,
        51460
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2641446590423584,
      "compression_ratio": 1.636690616607666,
      "no_speech_prob": 0.05825309827923775
    },
    {
      "id": 88,
      "seek": 51924,
      "start": 541.1599731445312,
      "end": 546.5599975585938,
      "text": " die sollen halt menschliche Sprache nachahmen. Was halt bedeutet, dass sie so das Paper ein",
      "tokens": [
        51460,
        978,
        24713,
        12479,
        10923,
        339,
        10185,
        7702,
        6000,
        5168,
        545,
        2558,
        13,
        3027,
        12479,
        27018,
        11,
        2658,
        2804,
        370,
        1482,
        24990,
        1343,
        51730
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2641446590423584,
      "compression_ratio": 1.636690616607666,
      "no_speech_prob": 0.05825309827923775
    },
    {
      "id": 89,
      "seek": 54656,
      "start": 546.5599975585938,
      "end": 550.7999877929688,
      "text": " Problem mit der Wahrheit haben, weil das auch nicht das Ziel der Entwicklung ist. Das Ziel der",
      "tokens": [
        50364,
        11676,
        2194,
        1163,
        36357,
        8480,
        3084,
        11,
        7689,
        1482,
        2168,
        1979,
        1482,
        25391,
        1163,
        39654,
        1418,
        13,
        2846,
        25391,
        1163,
        50576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23288196325302124,
      "compression_ratio": 1.8171206712722778,
      "no_speech_prob": 0.14011505246162415
    },
    {
      "id": 90,
      "seek": 54656,
      "start": 550.7999877929688,
      "end": 554.7999877929688,
      "text": " Entwicklung ist eben, ein System zu bauen, das menschliche Sprache nachahmt und zwar",
      "tokens": [
        50576,
        39654,
        1418,
        11375,
        11,
        1343,
        8910,
        2164,
        43787,
        11,
        1482,
        10923,
        339,
        10185,
        7702,
        6000,
        5168,
        545,
        42744,
        674,
        19054,
        50776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23288196325302124,
      "compression_ratio": 1.8171206712722778,
      "no_speech_prob": 0.14011505246162415
    },
    {
      "id": 91,
      "seek": 54656,
      "start": 554.7999877929688,
      "end": 559.0399780273438,
      "text": " glaubwürdig nachahmt. Das bedeutet nicht, dass das Ziel ist, jetzt etwas zu haben, was die reine",
      "tokens": [
        50776,
        23210,
        86,
        1655,
        25259,
        5168,
        545,
        42744,
        13,
        2846,
        27018,
        1979,
        11,
        2658,
        1482,
        25391,
        1418,
        11,
        4354,
        9569,
        2164,
        3084,
        11,
        390,
        978,
        319,
        533,
        50988
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23288196325302124,
      "compression_ratio": 1.8171206712722778,
      "no_speech_prob": 0.14011505246162415
    },
    {
      "id": 92,
      "seek": 54656,
      "start": 559.0399780273438,
      "end": 565.1199951171875,
      "text": " Wahrheit spricht. Und das bedeutet, wir haben eben ein System, das halt so wirkt wie menschliche",
      "tokens": [
        50988,
        36357,
        8480,
        42088,
        13,
        2719,
        1482,
        27018,
        11,
        1987,
        3084,
        11375,
        1343,
        8910,
        11,
        1482,
        12479,
        370,
        1987,
        2320,
        3355,
        10923,
        339,
        10185,
        51292
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23288196325302124,
      "compression_ratio": 1.8171206712722778,
      "no_speech_prob": 0.14011505246162415
    },
    {
      "id": 93,
      "seek": 54656,
      "start": 565.1199951171875,
      "end": 571.52001953125,
      "text": " Sprache und eben insbesondere überzeugend sein soll, aber nicht unbedingt korrekt. Was eben",
      "tokens": [
        51292,
        7702,
        6000,
        674,
        11375,
        48694,
        48598,
        521,
        6195,
        7114,
        11,
        4340,
        1979,
        41211,
        14784,
        265,
        2320,
        13,
        3027,
        11375,
        51612
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23288196325302124,
      "compression_ratio": 1.8171206712722778,
      "no_speech_prob": 0.14011505246162415
    },
    {
      "id": 94,
      "seek": 57152,
      "start": 571.52001953125,
      "end": 578.0,
      "text": " wiederum bedeutet, dass er sozusagen hilfreich nicht im Zentrum steht. Und das ist, glaube ich,",
      "tokens": [
        50364,
        6216,
        449,
        27018,
        11,
        2658,
        1189,
        33762,
        28315,
        69,
        12594,
        1979,
        566,
        44091,
        6247,
        16361,
        13,
        2719,
        1482,
        1418,
        11,
        13756,
        1893,
        11,
        50688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35315924882888794,
      "compression_ratio": 1.549180269241333,
      "no_speech_prob": 0.5984770059585571
    },
    {
      "id": 95,
      "seek": 57152,
      "start": 578.0,
      "end": 583.760009765625,
      "text": " etwas, was sehr schnell offenbar wird, wenn man sich ChatGPT anschaut oder halt andere LLMs,",
      "tokens": [
        50688,
        9569,
        11,
        390,
        5499,
        17589,
        35253,
        5356,
        4578,
        11,
        4797,
        587,
        3041,
        27503,
        38,
        47,
        51,
        31508,
        1375,
        4513,
        12479,
        10490,
        441,
        43,
        26386,
        11,
        50976
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35315924882888794,
      "compression_ratio": 1.549180269241333,
      "no_speech_prob": 0.5984770059585571
    },
    {
      "id": 96,
      "seek": 57152,
      "start": 583.760009765625,
      "end": 592.0800170898438,
      "text": " die nicht überbeantworten Fragen, was Vertrauen schaffen soll und sind da halt sehr stark,",
      "tokens": [
        50976,
        978,
        1979,
        4502,
        650,
        21655,
        268,
        25588,
        11,
        390,
        21044,
        46640,
        30888,
        7114,
        674,
        3290,
        1120,
        12479,
        5499,
        17417,
        11,
        51392
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35315924882888794,
      "compression_ratio": 1.549180269241333,
      "no_speech_prob": 0.5984770059585571
    },
    {
      "id": 97,
      "seek": 57152,
      "start": 592.0800170898438,
      "end": 596.6799926757812,
      "text": " offensichtlich stark darauf abgestimmt, zu sagen cool oder dafür zu sorgen, dass man halt denkt,",
      "tokens": [
        51392,
        766,
        694,
        41971,
        17417,
        18654,
        410,
        2629,
        15314,
        11,
        2164,
        8360,
        1627,
        4513,
        13747,
        2164,
        47972,
        11,
        2658,
        587,
        12479,
        38658,
        11,
        51622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35315924882888794,
      "compression_ratio": 1.549180269241333,
      "no_speech_prob": 0.5984770059585571
    },
    {
      "id": 98,
      "seek": 59668,
      "start": 596.6799926757812,
      "end": 604.52001953125,
      "text": " cool, das ist halt eine krass schlaue Sache, die da irgendwie vor mir steht. Und das ist,",
      "tokens": [
        50364,
        1627,
        11,
        1482,
        1418,
        12479,
        3018,
        15913,
        640,
        956,
        875,
        622,
        31452,
        11,
        978,
        1120,
        20759,
        4245,
        3149,
        16361,
        13,
        2719,
        1482,
        1418,
        11,
        50756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29682379961013794,
      "compression_ratio": 1.6184210777282715,
      "no_speech_prob": 0.16633783280849457
    },
    {
      "id": 99,
      "seek": 59668,
      "start": 604.52001953125,
      "end": 609.6400146484375,
      "text": " glaube ich, offensichtlich nachvollziehbar, dass das Ziel ist. Und da gibt es halt diese",
      "tokens": [
        50756,
        13756,
        1893,
        11,
        766,
        694,
        41971,
        5168,
        20654,
        28213,
        5356,
        11,
        2658,
        1482,
        25391,
        1418,
        13,
        2719,
        1120,
        6089,
        785,
        12479,
        6705,
        51012
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29682379961013794,
      "compression_ratio": 1.6184210777282715,
      "no_speech_prob": 0.16633783280849457
    },
    {
      "id": 100,
      "seek": 59668,
      "start": 609.6400146484375,
      "end": 616.47998046875,
      "text": " berühmten Beispiele, wo dann halt beispielsweise glaubhafte falsche Quellen erzeugt werden. Da",
      "tokens": [
        51012,
        5948,
        7254,
        76,
        1147,
        879,
        7631,
        15949,
        11,
        6020,
        3594,
        12479,
        40152,
        23210,
        1641,
        16268,
        16720,
        1876,
        4493,
        19191,
        1189,
        19303,
        83,
        4604,
        13,
        3933,
        51354
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29682379961013794,
      "compression_ratio": 1.6184210777282715,
      "no_speech_prob": 0.16633783280849457
    },
    {
      "id": 101,
      "seek": 59668,
      "start": 616.47998046875,
      "end": 622.0,
      "text": " gibt es dieses Beispiel von dem einen, zitiert das Paper, hat auch von dem einen Anwalt in den",
      "tokens": [
        51354,
        6089,
        785,
        12113,
        13772,
        2957,
        1371,
        4891,
        11,
        25013,
        4859,
        1482,
        24990,
        11,
        2385,
        2168,
        2957,
        1371,
        4891,
        1107,
        86,
        3198,
        294,
        1441,
        51630
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29682379961013794,
      "compression_ratio": 1.6184210777282715,
      "no_speech_prob": 0.16633783280849457
    },
    {
      "id": 102,
      "seek": 62200,
      "start": 622.0,
      "end": 627.280029296875,
      "text": " USA, der hat gesagt, der hat ein Paper eingereicht, eine Klageschrift oder sowas und",
      "tokens": [
        50364,
        10827,
        11,
        1163,
        2385,
        12260,
        11,
        1163,
        2385,
        1343,
        24990,
        17002,
        323,
        1405,
        11,
        3018,
        16053,
        1660,
        339,
        35742,
        4513,
        19766,
        296,
        674,
        50628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31976956129074097,
      "compression_ratio": 1.6448276042938232,
      "no_speech_prob": 0.11262927204370499
    },
    {
      "id": 103,
      "seek": 62200,
      "start": 627.280029296875,
      "end": 633.0399780273438,
      "text": " hat lauter Zitate da gebracht hat über irgendwelche Verfahren. Und das ist halt in den USA wichtig,",
      "tokens": [
        50628,
        2385,
        635,
        20314,
        1176,
        8086,
        1120,
        1519,
        1443,
        608,
        83,
        2385,
        4502,
        26455,
        338,
        1876,
        24583,
        7079,
        13,
        2719,
        1482,
        1418,
        12479,
        294,
        1441,
        10827,
        13621,
        11,
        50916
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31976956129074097,
      "compression_ratio": 1.6448276042938232,
      "no_speech_prob": 0.11262927204370499
    },
    {
      "id": 104,
      "seek": 62200,
      "start": 633.0399780273438,
      "end": 637.9600219726562,
      "text": " weil ja der Grundsatz eben ist, dass sozusagen ein Beispielverfahren, wo irgendwas entschieden worden",
      "tokens": [
        50916,
        7689,
        2784,
        1163,
        13941,
        82,
        10300,
        11375,
        1418,
        11,
        2658,
        33762,
        1343,
        13772,
        331,
        34394,
        11,
        6020,
        47090,
        49807,
        14054,
        51162
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31976956129074097,
      "compression_ratio": 1.6448276042938232,
      "no_speech_prob": 0.11262927204370499
    },
    {
      "id": 105,
      "seek": 62200,
      "start": 637.9600219726562,
      "end": 642.1599731445312,
      "text": " ist, eine Basis dafür sein kann, dass in einem anderen Verfahren etwas Ähnliches entschieden",
      "tokens": [
        51162,
        1418,
        11,
        3018,
        5859,
        271,
        13747,
        6195,
        4028,
        11,
        2658,
        294,
        6827,
        11122,
        24583,
        7079,
        9569,
        13700,
        35646,
        279,
        49807,
        51372
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31976956129074097,
      "compression_ratio": 1.6448276042938232,
      "no_speech_prob": 0.11262927204370499
    },
    {
      "id": 106,
      "seek": 62200,
      "start": 642.1599731445312,
      "end": 646.8800048828125,
      "text": " wird, in einer ähnlichen Richtung. Nur diese Referenzen waren halt alle gefaked, also man hat",
      "tokens": [
        51372,
        4578,
        11,
        294,
        6850,
        3078,
        12071,
        10193,
        33023,
        13,
        17612,
        6705,
        36889,
        268,
        2904,
        11931,
        12479,
        5430,
        11271,
        7301,
        11,
        611,
        587,
        2385,
        51608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31976956129074097,
      "compression_ratio": 1.6448276042938232,
      "no_speech_prob": 0.11262927204370499
    },
    {
      "id": 107,
      "seek": 64688,
      "start": 646.8800048828125,
      "end": 657.280029296875,
      "text": " tatsächlich erfunden. Und das ist dann, also das ist etwas, was wir halt wissen. So und das wird",
      "tokens": [
        50364,
        20796,
        20228,
        10028,
        13,
        2719,
        1482,
        1418,
        3594,
        11,
        611,
        1482,
        1418,
        9569,
        11,
        390,
        1987,
        12479,
        16331,
        13,
        407,
        674,
        1482,
        4578,
        50884
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33104220032691956,
      "compression_ratio": 1.5813008546829224,
      "no_speech_prob": 0.1964801698923111
    },
    {
      "id": 108,
      "seek": 64688,
      "start": 657.280029296875,
      "end": 661.760009765625,
      "text": " halt an der Stelle so das Paper schwierig, wo man jetzt sagt, wir wollen halt mit LLMs irgendwie",
      "tokens": [
        50884,
        12479,
        364,
        1163,
        26629,
        370,
        1482,
        24990,
        37845,
        11,
        6020,
        587,
        4354,
        15764,
        11,
        1987,
        11253,
        12479,
        2194,
        441,
        43,
        26386,
        20759,
        51108
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33104220032691956,
      "compression_ratio": 1.5813008546829224,
      "no_speech_prob": 0.1964801698923111
    },
    {
      "id": 109,
      "seek": 64688,
      "start": 661.760009765625,
      "end": 667.5599975585938,
      "text": " Dinge tun, wie zum Beispiel Websuche ersetzen oder tatsächlich Menschen unterstützen. So und",
      "tokens": [
        51108,
        25102,
        4267,
        11,
        3355,
        5919,
        13772,
        45347,
        17545,
        33743,
        24797,
        4513,
        20796,
        8397,
        43081,
        13,
        407,
        674,
        51398
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33104220032691956,
      "compression_ratio": 1.5813008546829224,
      "no_speech_prob": 0.1964801698923111
    },
    {
      "id": 110,
      "seek": 64688,
      "start": 667.5599975585938,
      "end": 672.3200073242188,
      "text": " das ist eben ein anderes Ziel. Das heißt also, das Ziel wäre dann eben dafür zu sorgen, dass ich",
      "tokens": [
        51398,
        1482,
        1418,
        11375,
        1343,
        31426,
        25391,
        13,
        2846,
        13139,
        611,
        11,
        1482,
        25391,
        14558,
        3594,
        11375,
        13747,
        2164,
        47972,
        11,
        2658,
        1893,
        51636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33104220032691956,
      "compression_ratio": 1.5813008546829224,
      "no_speech_prob": 0.1964801698923111
    },
    {
      "id": 111,
      "seek": 67232,
      "start": 672.3200073242188,
      "end": 677.0800170898438,
      "text": " tatsächlich idealerweise korrekte Informationen bekomme. Und dann muss ich ja dafür sorgen, dass",
      "tokens": [
        50364,
        20796,
        7157,
        44071,
        14784,
        265,
        18844,
        46753,
        9393,
        15117,
        13,
        2719,
        3594,
        6425,
        1893,
        2784,
        13747,
        47972,
        11,
        2658,
        50602
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27564653754234314,
      "compression_ratio": 1.7922848463058472,
      "no_speech_prob": 0.05488857254385948
    },
    {
      "id": 112,
      "seek": 67232,
      "start": 677.0800170898438,
      "end": 682.4000244140625,
      "text": " das korrekt wird. Und das ist halt ein bisschen eine Herausforderung. Und wenn ich jetzt irgendwie",
      "tokens": [
        50602,
        1482,
        14784,
        265,
        2320,
        4578,
        13,
        2719,
        1482,
        1418,
        12479,
        1343,
        10763,
        3018,
        37888,
        1063,
        13,
        2719,
        4797,
        1893,
        4354,
        20759,
        50868
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27564653754234314,
      "compression_ratio": 1.7922848463058472,
      "no_speech_prob": 0.05488857254385948
    },
    {
      "id": 113,
      "seek": 67232,
      "start": 682.4000244140625,
      "end": 688.0399780273438,
      "text": " anfange, da andere Quellen dran zu schließen, also eine Datenbank oder eine Websuche, dann erhöht das",
      "tokens": [
        50868,
        33709,
        933,
        11,
        1120,
        10490,
        4493,
        19191,
        32801,
        2164,
        956,
        38665,
        11,
        611,
        3018,
        31126,
        25423,
        4513,
        3018,
        45347,
        17545,
        11,
        3594,
        49058,
        357,
        1482,
        51150
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27564653754234314,
      "compression_ratio": 1.7922848463058472,
      "no_speech_prob": 0.05488857254385948
    },
    {
      "id": 114,
      "seek": 67232,
      "start": 688.0399780273438,
      "end": 691.4400024414062,
      "text": " die Wahrscheinlichkeit, dass bessere Ergebnisse produziert werden. Aber die können das halt nicht",
      "tokens": [
        51150,
        978,
        36357,
        25553,
        9238,
        11,
        2658,
        42410,
        323,
        34657,
        31481,
        28093,
        4859,
        4604,
        13,
        5992,
        978,
        6310,
        1482,
        12479,
        1979,
        51320
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27564653754234314,
      "compression_ratio": 1.7922848463058472,
      "no_speech_prob": 0.05488857254385948
    },
    {
      "id": 115,
      "seek": 67232,
      "start": 691.4400024414062,
      "end": 696.52001953125,
      "text": " garantieren. Also das Paper sagt halt im Prinzip, wenn ich das Ziel habe, dass halt etwas überzeugend",
      "tokens": [
        51320,
        22251,
        5695,
        13,
        2743,
        1482,
        24990,
        15764,
        12479,
        566,
        47572,
        11,
        4797,
        1893,
        1482,
        25391,
        6015,
        11,
        2658,
        12479,
        9569,
        48598,
        521,
        51574
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27564653754234314,
      "compression_ratio": 1.7922848463058472,
      "no_speech_prob": 0.05488857254385948
    },
    {
      "id": 116,
      "seek": 67232,
      "start": 696.52001953125,
      "end": 702.0,
      "text": " ist, dann gibt es die Wahrscheinlichkeit, dass man da halt auch korrekte Ergebnisse produziert. Aber",
      "tokens": [
        51574,
        1418,
        11,
        3594,
        6089,
        785,
        978,
        36357,
        25553,
        9238,
        11,
        2658,
        587,
        1120,
        12479,
        2168,
        14784,
        265,
        18844,
        34657,
        31481,
        28093,
        4859,
        13,
        5992,
        51848
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27564653754234314,
      "compression_ratio": 1.7922848463058472,
      "no_speech_prob": 0.05488857254385948
    },
    {
      "id": 117,
      "seek": 70200,
      "start": 702.0,
      "end": 709.1199951171875,
      "text": " das ist eben was anderes. Genau, der Christian hat geschrieben, sind halt nur linguistische Formen,",
      "tokens": [
        50364,
        1482,
        1418,
        11375,
        390,
        31426,
        13,
        22340,
        11,
        1163,
        5778,
        2385,
        47397,
        11,
        3290,
        12479,
        4343,
        21766,
        468,
        7864,
        10126,
        268,
        11,
        50720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2865384519100189,
      "compression_ratio": 1.6622951030731201,
      "no_speech_prob": 0.010321139357984066
    },
    {
      "id": 118,
      "seek": 70200,
      "start": 709.1199951171875,
      "end": 714.280029296875,
      "text": " nicht Sprache. Es ist eine perfekte oberflächliche Repräsentation von sprachlich korrekten Ausdruck.",
      "tokens": [
        50720,
        1979,
        7702,
        6000,
        13,
        2313,
        1418,
        3018,
        13826,
        916,
        975,
        277,
        607,
        3423,
        10168,
        10185,
        3696,
        11397,
        49315,
        399,
        2957,
        6103,
        608,
        1739,
        14784,
        20012,
        1147,
        9039,
        67,
        8161,
        13,
        50978
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2865384519100189,
      "compression_ratio": 1.6622951030731201,
      "no_speech_prob": 0.010321139357984066
    },
    {
      "id": 119,
      "seek": 70200,
      "start": 714.280029296875,
      "end": 720.9600219726562,
      "text": " So ungefähr würde ich das jetzt irgendwie auch denken, wird das halt irgendwie aussehen. Was halt",
      "tokens": [
        50978,
        407,
        41285,
        11942,
        1893,
        1482,
        4354,
        20759,
        2168,
        28780,
        11,
        4578,
        1482,
        12479,
        20759,
        3437,
        27750,
        13,
        3027,
        12479,
        51312
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2865384519100189,
      "compression_ratio": 1.6622951030731201,
      "no_speech_prob": 0.010321139357984066
    },
    {
      "id": 120,
      "seek": 70200,
      "start": 720.9600219726562,
      "end": 726.8800048828125,
      "text": " bedeutet, dass sie insbesondere auch kein Nachdenken oder Überlegen und auch kein Modell der Welt haben.",
      "tokens": [
        51312,
        27018,
        11,
        2658,
        2804,
        48694,
        2168,
        13424,
        11815,
        1556,
        2653,
        4513,
        18086,
        22936,
        674,
        2168,
        13424,
        6583,
        898,
        1163,
        14761,
        3084,
        13,
        51608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2865384519100189,
      "compression_ratio": 1.6622951030731201,
      "no_speech_prob": 0.010321139357984066
    },
    {
      "id": 121,
      "seek": 70200,
      "start": 726.8800048828125,
      "end": 731.1599731445312,
      "text": " Also es ist jetzt nicht so, dass ich da halt ein Ding habe, was halt sagt, ich weiß, wie die Welt",
      "tokens": [
        51608,
        2743,
        785,
        1418,
        4354,
        1979,
        370,
        11,
        2658,
        1893,
        1120,
        12479,
        1343,
        20558,
        6015,
        11,
        390,
        12479,
        15764,
        11,
        1893,
        13385,
        11,
        3355,
        978,
        14761,
        51822
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2865384519100189,
      "compression_ratio": 1.6622951030731201,
      "no_speech_prob": 0.010321139357984066
    },
    {
      "id": 122,
      "seek": 73116,
      "start": 731.2000122070312,
      "end": 736.6799926757812,
      "text": " aussieht und ich habe irgendwie Semantik und weiß halt, was da irgendwie ist, sondern es ist eben",
      "tokens": [
        50366,
        5730,
        39850,
        674,
        1893,
        6015,
        20759,
        14421,
        394,
        1035,
        674,
        13385,
        12479,
        11,
        390,
        1120,
        20759,
        1418,
        11,
        11465,
        785,
        1418,
        11375,
        50640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.282634973526001,
      "compression_ratio": 1.6565656661987305,
      "no_speech_prob": 0.0033240278717130423
    },
    {
      "id": 123,
      "seek": 73116,
      "start": 736.6799926757812,
      "end": 744.0,
      "text": " ein Textgenerator am Ende. So und das führt glaube ich so ein bisschen zu dem ersten Thema, was so ein",
      "tokens": [
        50640,
        1343,
        18643,
        21848,
        1639,
        669,
        15152,
        13,
        407,
        674,
        1482,
        39671,
        13756,
        1893,
        370,
        1343,
        10763,
        2164,
        1371,
        17324,
        16306,
        11,
        390,
        370,
        1343,
        51006
      ],
      "temperature": 0.0,
      "avg_logprob": -0.282634973526001,
      "compression_ratio": 1.6565656661987305,
      "no_speech_prob": 0.0033240278717130423
    },
    {
      "id": 124,
      "seek": 73116,
      "start": 744.0,
      "end": 748.0,
      "text": " bisschen Learning für mich ist. Es steht zwar in dem Paper nicht explizit drin, aber das ist, glaube",
      "tokens": [
        51006,
        10763,
        15205,
        2959,
        6031,
        1418,
        13,
        2313,
        16361,
        19054,
        294,
        1371,
        24990,
        1979,
        1490,
        590,
        270,
        24534,
        11,
        4340,
        1482,
        1418,
        11,
        13756,
        51206
      ],
      "temperature": 0.0,
      "avg_logprob": -0.282634973526001,
      "compression_ratio": 1.6565656661987305,
      "no_speech_prob": 0.0033240278717130423
    },
    {
      "id": 125,
      "seek": 73116,
      "start": 748.0,
      "end": 752.3599853515625,
      "text": " ich, implizit dort eine Aussage. Wir haben also eigentlich ein grundlegendes Problem mit LLMs,",
      "tokens": [
        51206,
        1893,
        11,
        8484,
        590,
        270,
        15775,
        3018,
        21286,
        609,
        13,
        4347,
        3084,
        611,
        10926,
        1343,
        30886,
        6363,
        34533,
        11676,
        2194,
        441,
        43,
        26386,
        11,
        51424
      ],
      "temperature": 0.0,
      "avg_logprob": -0.282634973526001,
      "compression_ratio": 1.6565656661987305,
      "no_speech_prob": 0.0033240278717130423
    },
    {
      "id": 126,
      "seek": 73116,
      "start": 752.3599853515625,
      "end": 757.6799926757812,
      "text": " weil eben LLMs versuchen, Text zu generieren, was wiederum umgekehrt bedeutet, wenn ich halt",
      "tokens": [
        51424,
        7689,
        11375,
        441,
        43,
        26386,
        34749,
        11,
        18643,
        2164,
        1337,
        5695,
        11,
        390,
        6216,
        449,
        1105,
        432,
        22833,
        83,
        27018,
        11,
        4797,
        1893,
        12479,
        51690
      ],
      "temperature": 0.0,
      "avg_logprob": -0.282634973526001,
      "compression_ratio": 1.6565656661987305,
      "no_speech_prob": 0.0033240278717130423
    },
    {
      "id": 127,
      "seek": 75768,
      "start": 757.6799926757812,
      "end": 762.4000244140625,
      "text": " versuche, ein System zu bauen, was halt irgendwie sozusagen spezifisches Wissen hat tatsächlich",
      "tokens": [
        50364,
        1774,
        17545,
        11,
        1343,
        8910,
        2164,
        43787,
        11,
        390,
        12479,
        20759,
        370,
        16236,
        64,
        1766,
        768,
        89,
        351,
        35889,
        343,
        10987,
        2385,
        20796,
        50600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30288460850715637,
      "compression_ratio": 1.6045751571655273,
      "no_speech_prob": 0.03355856239795685
    },
    {
      "id": 128,
      "seek": 75768,
      "start": 762.4000244140625,
      "end": 768.4000244140625,
      "text": " und irgendwie dazu in der Lage ist, anders Dinge zu repräsentieren, dann hätte ich vielleicht auch",
      "tokens": [
        50600,
        674,
        20759,
        13034,
        294,
        1163,
        41555,
        1418,
        11,
        17999,
        25102,
        2164,
        1085,
        11397,
        49315,
        5695,
        11,
        3594,
        20041,
        1893,
        12547,
        2168,
        50900
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30288460850715637,
      "compression_ratio": 1.6045751571655273,
      "no_speech_prob": 0.03355856239795685
    },
    {
      "id": 129,
      "seek": 75768,
      "start": 768.4000244140625,
      "end": 773.6799926757812,
      "text": " andere Ergebnisse. Das ist aber sozusagen eine KI-Geschichte und ich bin da, also das wäre mir",
      "tokens": [
        50900,
        10490,
        34657,
        31481,
        13,
        2846,
        1418,
        4340,
        370,
        16236,
        64,
        1766,
        3018,
        47261,
        12,
        38,
        22320,
        18972,
        674,
        1893,
        5171,
        1120,
        11,
        611,
        1482,
        14558,
        3149,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30288460850715637,
      "compression_ratio": 1.6045751571655273,
      "no_speech_prob": 0.03355856239795685
    },
    {
      "id": 130,
      "seek": 75768,
      "start": 773.6799926757812,
      "end": 778.5599975585938,
      "text": " die Frage, welche anderen KI-Ansätze habe ich. Mir ist diese Woche nochmal der Begriff Expertensystem",
      "tokens": [
        51164,
        978,
        13685,
        11,
        24311,
        11122,
        47261,
        12,
        32,
        3695,
        30179,
        6015,
        1893,
        13,
        9421,
        1418,
        6705,
        24511,
        26509,
        1163,
        879,
        32783,
        41255,
        694,
        9321,
        51408
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30288460850715637,
      "compression_ratio": 1.6045751571655273,
      "no_speech_prob": 0.03355856239795685
    },
    {
      "id": 131,
      "seek": 75768,
      "start": 778.5599975585938,
      "end": 785.280029296875,
      "text": " über den Weg gelaufen, also Systeme, die halt Experten ein bisschen explizit modellieren. Das",
      "tokens": [
        51408,
        4502,
        1441,
        18919,
        4087,
        20748,
        11,
        611,
        8910,
        68,
        11,
        978,
        12479,
        12522,
        1147,
        1343,
        10763,
        1490,
        590,
        270,
        1072,
        898,
        5695,
        13,
        2846,
        51744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30288460850715637,
      "compression_ratio": 1.6045751571655273,
      "no_speech_prob": 0.03355856239795685
    },
    {
      "id": 132,
      "seek": 78528,
      "start": 785.3200073242188,
      "end": 790.2000122070312,
      "text": " wäre zum Beispiel ein anderes Modell. Es ist halt nur im Moment nicht das, was wir typischerweise",
      "tokens": [
        50366,
        14558,
        5919,
        13772,
        1343,
        31426,
        6583,
        898,
        13,
        2313,
        1418,
        12479,
        4343,
        566,
        19093,
        1979,
        1482,
        11,
        390,
        1987,
        2125,
        19674,
        13109,
        50610
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33975231647491455,
      "compression_ratio": 1.5271317958831787,
      "no_speech_prob": 0.1362672597169876
    },
    {
      "id": 133,
      "seek": 78528,
      "start": 790.2000122070312,
      "end": 795.7999877929688,
      "text": " haben. So es gibt dann diesen Begriff Bullshit. Bei Wikipedia wird das in Deutsch übersetzt mit",
      "tokens": [
        50610,
        3084,
        13,
        407,
        785,
        6089,
        3594,
        12862,
        879,
        32783,
        14131,
        19186,
        13,
        16188,
        28999,
        4578,
        1482,
        294,
        12699,
        45022,
        3524,
        2194,
        50890
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33975231647491455,
      "compression_ratio": 1.5271317958831787,
      "no_speech_prob": 0.1362672597169876
    },
    {
      "id": 134,
      "seek": 78528,
      "start": 795.7999877929688,
      "end": 803.6400146484375,
      "text": " Hohlsprech, was angeblich ein neudeutscher Begriff ist. Ich fand das relativ schön und das Paper sagt",
      "tokens": [
        50890,
        389,
        12768,
        4952,
        265,
        339,
        11,
        390,
        364,
        10848,
        1739,
        1343,
        408,
        2303,
        3648,
        6759,
        879,
        32783,
        1418,
        13,
        3141,
        38138,
        1482,
        21960,
        13527,
        674,
        1482,
        24990,
        15764,
        51282
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33975231647491455,
      "compression_ratio": 1.5271317958831787,
      "no_speech_prob": 0.1362672597169876
    },
    {
      "id": 135,
      "seek": 78528,
      "start": 803.6400146484375,
      "end": 810.0399780273438,
      "text": " jetzt, es gibt halt verschiedene Dinge, die ich halt machen kann. Ich kann zum Beispiel lügen.",
      "tokens": [
        51282,
        4354,
        11,
        785,
        6089,
        12479,
        35411,
        25102,
        11,
        978,
        1893,
        12479,
        7069,
        4028,
        13,
        3141,
        4028,
        5919,
        13772,
        287,
        45336,
        13,
        51602
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33975231647491455,
      "compression_ratio": 1.5271317958831787,
      "no_speech_prob": 0.1362672597169876
    },
    {
      "id": 136,
      "seek": 81004,
      "start": 810.6400146484375,
      "end": 817.9600219726562,
      "text": " Lügen bedeutet, dass ich die Wahrheit irgendeiner Person sage und die Person soll sie aber glauben.",
      "tokens": [
        50394,
        441,
        45336,
        27018,
        11,
        2658,
        1893,
        978,
        36357,
        8480,
        3418,
        27429,
        4564,
        8443,
        19721,
        674,
        978,
        8443,
        7114,
        2804,
        4340,
        47139,
        13,
        50760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35381028056144714,
      "compression_ratio": 1.6595745086669922,
      "no_speech_prob": 0.07259610295295715
    },
    {
      "id": 137,
      "seek": 81004,
      "start": 817.9600219726562,
      "end": 824.6799926757812,
      "text": " Das heißt also, es ist ein Ziel und vermutlich weiß man auch, dass man lügt. Das heißt also,",
      "tokens": [
        50760,
        2846,
        13139,
        611,
        11,
        785,
        1418,
        1343,
        25391,
        674,
        26319,
        21678,
        13385,
        587,
        2168,
        11,
        2658,
        587,
        287,
        774,
        10463,
        13,
        2846,
        13139,
        611,
        11,
        51096
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35381028056144714,
      "compression_ratio": 1.6595745086669922,
      "no_speech_prob": 0.07259610295295715
    },
    {
      "id": 138,
      "seek": 81004,
      "start": 824.6799926757812,
      "end": 829.0800170898438,
      "text": " wenn ich jetzt kein Ärger haben will mit irgendjemandem, dann sage ich ihm, hier ist irgendwie",
      "tokens": [
        51096,
        4797,
        1893,
        4354,
        13424,
        34403,
        1321,
        3084,
        486,
        2194,
        11093,
        73,
        18941,
        443,
        11,
        3594,
        19721,
        1893,
        16021,
        11,
        3296,
        1418,
        20759,
        51316
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35381028056144714,
      "compression_ratio": 1.6595745086669922,
      "no_speech_prob": 0.07259610295295715
    },
    {
      "id": 139,
      "seek": 81004,
      "start": 829.0800170898438,
      "end": 834.4400024414062,
      "text": " alles super. Das ist eine Lüge, in Wirklichkeit ist es halt irgendwie schlimm und ich sage das,",
      "tokens": [
        51316,
        7874,
        1687,
        13,
        2846,
        1418,
        3018,
        441,
        774,
        432,
        11,
        294,
        4347,
        9056,
        9238,
        1418,
        785,
        12479,
        20759,
        48821,
        674,
        1893,
        19721,
        1482,
        11,
        51584
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35381028056144714,
      "compression_ratio": 1.6595745086669922,
      "no_speech_prob": 0.07259610295295715
    },
    {
      "id": 140,
      "seek": 83444,
      "start": 835.0,
      "end": 841.7999877929688,
      "text": " dass er mir glaubt, damit die Person mich halt nicht weiter nervt. Das ist eben etwas, wo ich",
      "tokens": [
        50392,
        2658,
        1189,
        3149,
        23210,
        83,
        11,
        9479,
        978,
        8443,
        6031,
        12479,
        1979,
        8988,
        5724,
        83,
        13,
        2846,
        1418,
        11375,
        9569,
        11,
        6020,
        1893,
        50732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.291901558637619,
      "compression_ratio": 1.669565200805664,
      "no_speech_prob": 0.12405049800872803
    },
    {
      "id": 141,
      "seek": 83444,
      "start": 841.7999877929688,
      "end": 847.0399780273438,
      "text": " tatsächlich ein Modell der Welt habe, etwas sage, was diesem Modell nicht entspricht, mit einer",
      "tokens": [
        50732,
        20796,
        1343,
        6583,
        898,
        1163,
        14761,
        6015,
        11,
        9569,
        19721,
        11,
        390,
        10975,
        6583,
        898,
        1979,
        12834,
        79,
        12836,
        11,
        2194,
        6850,
        50994
      ],
      "temperature": 0.0,
      "avg_logprob": -0.291901558637619,
      "compression_ratio": 1.669565200805664,
      "no_speech_prob": 0.12405049800872803
    },
    {
      "id": 142,
      "seek": 83444,
      "start": 847.0399780273438,
      "end": 853.5999755859375,
      "text": " bestimmten Intention. So etwas kann ein LLM einfach nicht machen, wenn man das eben so definiert,",
      "tokens": [
        50994,
        35180,
        1147,
        5681,
        1251,
        13,
        407,
        9569,
        4028,
        1343,
        441,
        43,
        44,
        7281,
        1979,
        7069,
        11,
        4797,
        587,
        1482,
        11375,
        370,
        1561,
        4859,
        11,
        51322
      ],
      "temperature": 0.0,
      "avg_logprob": -0.291901558637619,
      "compression_ratio": 1.669565200805664,
      "no_speech_prob": 0.12405049800872803
    },
    {
      "id": 143,
      "seek": 83444,
      "start": 853.5999755859375,
      "end": 859.1199951171875,
      "text": " weil es keine Intention, keine Ausrichtung hat und eben kein Modell der Welt. Was die noch halt",
      "tokens": [
        51322,
        7689,
        785,
        9252,
        5681,
        1251,
        11,
        9252,
        9039,
        12836,
        1063,
        2385,
        674,
        11375,
        13424,
        6583,
        898,
        1163,
        14761,
        13,
        3027,
        978,
        3514,
        12479,
        51598
      ],
      "temperature": 0.0,
      "avg_logprob": -0.291901558637619,
      "compression_ratio": 1.669565200805664,
      "no_speech_prob": 0.12405049800872803
    },
    {
      "id": 144,
      "seek": 85912,
      "start": 859.1199951171875,
      "end": 868.2000122070312,
      "text": " diskutieren, der Sommerherz schreibt gerade, LLM ist von keinem Sinn für Logik, wenn man in der",
      "tokens": [
        50364,
        36760,
        5695,
        11,
        1163,
        35022,
        511,
        89,
        956,
        31174,
        12117,
        11,
        441,
        43,
        44,
        1418,
        2957,
        13424,
        443,
        37962,
        2959,
        10824,
        1035,
        11,
        4797,
        587,
        294,
        1163,
        50818
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33289283514022827,
      "compression_ratio": 1.5098038911819458,
      "no_speech_prob": 0.16633488237857819
    },
    {
      "id": 145,
      "seek": 85912,
      "start": 868.2000122070312,
      "end": 875.0,
      "text": " Vermenschlichung der AI-Semantik bleibt. Genau, also es ist eben so, dass Logik oder sowas ist",
      "tokens": [
        50818,
        20185,
        26590,
        1739,
        1063,
        1163,
        7318,
        12,
        50,
        443,
        394,
        1035,
        24814,
        13,
        22340,
        11,
        611,
        785,
        1418,
        11375,
        370,
        11,
        2658,
        10824,
        1035,
        4513,
        19766,
        296,
        1418,
        51158
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33289283514022827,
      "compression_ratio": 1.5098038911819458,
      "no_speech_prob": 0.16633488237857819
    },
    {
      "id": 146,
      "seek": 85912,
      "start": 875.0,
      "end": 879.9199829101562,
      "text": " halt dort kein Thema und Christian hat gesagt, das technologische Problem ist halt, dass ein",
      "tokens": [
        51158,
        12479,
        15775,
        13424,
        16306,
        674,
        5778,
        2385,
        12260,
        11,
        1482,
        1537,
        1132,
        7864,
        11676,
        1418,
        12479,
        11,
        2658,
        1343,
        51404
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33289283514022827,
      "compression_ratio": 1.5098038911819458,
      "no_speech_prob": 0.16633488237857819
    },
    {
      "id": 147,
      "seek": 85912,
      "start": 879.9199829101562,
      "end": 884.8400268554688,
      "text": " aktuelles LLM auch nicht mit ausgibt, wie sicher es ist, im Gegensatz zu vielen anderen ML-Modellen.",
      "tokens": [
        51404,
        36267,
        279,
        441,
        43,
        44,
        2168,
        1979,
        2194,
        3437,
        70,
        13651,
        11,
        3355,
        18623,
        785,
        1418,
        11,
        566,
        27826,
        694,
        10300,
        2164,
        19885,
        11122,
        21601,
        12,
        44,
        378,
        8581,
        13,
        51650
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33289283514022827,
      "compression_ratio": 1.5098038911819458,
      "no_speech_prob": 0.16633488237857819
    },
    {
      "id": 148,
      "seek": 88484,
      "start": 884.8400268554688,
      "end": 893.47998046875,
      "text": " Ich bekomme keine Zahl wie bei Bildklassifikation. Meine Behauptung wäre, ohne dass ich jetzt sozusagen",
      "tokens": [
        50364,
        3141,
        9393,
        15117,
        9252,
        42592,
        3355,
        4643,
        15746,
        7837,
        640,
        45475,
        399,
        13,
        22258,
        13068,
        13343,
        1063,
        14558,
        11,
        15716,
        2658,
        1893,
        4354,
        33762,
        50796
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30920639634132385,
      "compression_ratio": 1.5863454341888428,
      "no_speech_prob": 0.08623405545949936
    },
    {
      "id": 149,
      "seek": 88484,
      "start": 893.47998046875,
      "end": 900.9199829101562,
      "text": " ein AI-Experte bin, dass das halt auch gar nicht geht, weil das würde ja implizieren, dass ich",
      "tokens": [
        50796,
        1343,
        7318,
        12,
        11149,
        610,
        975,
        5171,
        11,
        2658,
        1482,
        12479,
        2168,
        3691,
        1979,
        7095,
        11,
        7689,
        1482,
        11942,
        2784,
        8484,
        590,
        5695,
        11,
        2658,
        1893,
        51168
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30920639634132385,
      "compression_ratio": 1.5863454341888428,
      "no_speech_prob": 0.08623405545949936
    },
    {
      "id": 150,
      "seek": 88484,
      "start": 900.9199829101562,
      "end": 906.7999877929688,
      "text": " sozusagen eine Realität kenne und das haben die halt nicht. Also wir können halt sozusagen sagen,",
      "tokens": [
        51168,
        33762,
        3018,
        8467,
        14053,
        350,
        13295,
        674,
        1482,
        3084,
        978,
        12479,
        1979,
        13,
        2743,
        1987,
        6310,
        12479,
        33762,
        8360,
        11,
        51462
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30920639634132385,
      "compression_ratio": 1.5863454341888428,
      "no_speech_prob": 0.08623405545949936
    },
    {
      "id": 151,
      "seek": 88484,
      "start": 906.7999877929688,
      "end": 911.0,
      "text": " das ist überzeugend, aber ob es halt die Realität ist, ist halt irgendwie eine andere Frage.",
      "tokens": [
        51462,
        1482,
        1418,
        48598,
        521,
        11,
        4340,
        1111,
        785,
        12479,
        978,
        8467,
        14053,
        1418,
        11,
        1418,
        12479,
        20759,
        3018,
        10490,
        13685,
        13,
        51672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30920639634132385,
      "compression_ratio": 1.5863454341888428,
      "no_speech_prob": 0.08623405545949936
    },
    {
      "id": 152,
      "seek": 91100,
      "start": 911.0,
      "end": 916.280029296875,
      "text": " Herr Dieter bei Twitch sagt, ich finde gefährlich, dass Werbung oder politische",
      "tokens": [
        50364,
        10367,
        29606,
        260,
        4643,
        22222,
        15764,
        11,
        1893,
        17841,
        41484,
        1739,
        11,
        2658,
        14255,
        36776,
        4513,
        2453,
        7864,
        50628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31202900409698486,
      "compression_ratio": 1.44140625,
      "no_speech_prob": 0.05734643712639809
    },
    {
      "id": 153,
      "seek": 91100,
      "start": 916.280029296875,
      "end": 922.4000244140625,
      "text": " Agenda mit in die KIs eingewoben wird. Als User bekommt man das aufgrund der Versprachlichung",
      "tokens": [
        50628,
        2725,
        7639,
        2194,
        294,
        978,
        591,
        6802,
        17002,
        1023,
        46213,
        4578,
        13,
        12948,
        32127,
        33429,
        587,
        1482,
        2501,
        23701,
        1163,
        12226,
        1424,
        608,
        1739,
        1063,
        50934
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31202900409698486,
      "compression_ratio": 1.44140625,
      "no_speech_prob": 0.05734643712639809
    },
    {
      "id": 154,
      "seek": 91100,
      "start": 922.4000244140625,
      "end": 926.47998046875,
      "text": " eingebetteten Regeln und teilweise verschiedenen Quellenangaben kaum mit, zum Beispiel vorgeschlagene",
      "tokens": [
        50934,
        30061,
        65,
        3093,
        19865,
        4791,
        9878,
        674,
        46748,
        41043,
        4493,
        19191,
        656,
        25071,
        36443,
        2194,
        11,
        5919,
        13772,
        4245,
        2880,
        40869,
        1450,
        51138
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31202900409698486,
      "compression_ratio": 1.44140625,
      "no_speech_prob": 0.05734643712639809
    },
    {
      "id": 155,
      "seek": 91100,
      "start": 926.47998046875,
      "end": 932.5999755859375,
      "text": " Produkte. Ich bin nicht sicher, ob wir zu dem Thema kommen. Das ist auch etwas, was mir halt",
      "tokens": [
        51138,
        11793,
        18844,
        13,
        3141,
        5171,
        1979,
        18623,
        11,
        1111,
        1987,
        2164,
        1371,
        16306,
        11729,
        13,
        2846,
        1418,
        2168,
        9569,
        11,
        390,
        3149,
        12479,
        51444
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31202900409698486,
      "compression_ratio": 1.44140625,
      "no_speech_prob": 0.05734643712639809
    },
    {
      "id": 156,
      "seek": 93260,
      "start": 933.239990234375,
      "end": 939.6400146484375,
      "text": " mittlerweile so aus meinen Überlegungen, aus den letzten 14 Tagen herausgeputzt wird, ist,",
      "tokens": [
        50396,
        41999,
        370,
        3437,
        22738,
        18086,
        6363,
        5084,
        11,
        3437,
        1441,
        18226,
        3499,
        41721,
        25089,
        432,
        2582,
        2682,
        4578,
        11,
        1418,
        11,
        50716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3618435561656952,
      "compression_ratio": 1.5204918384552002,
      "no_speech_prob": 0.15179412066936493
    },
    {
      "id": 157,
      "seek": 93260,
      "start": 939.6400146484375,
      "end": 945.719970703125,
      "text": " wenn wir das Trainingsdatenset nicht kennen und das kennen wir halt nicht, das ist halt in den",
      "tokens": [
        50716,
        4797,
        1987,
        1482,
        28029,
        1109,
        20367,
        694,
        302,
        1979,
        28445,
        674,
        1482,
        28445,
        1987,
        12479,
        1979,
        11,
        1482,
        1418,
        12479,
        294,
        1441,
        51020
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3618435561656952,
      "compression_ratio": 1.5204918384552002,
      "no_speech_prob": 0.15179412066936493
    },
    {
      "id": 158,
      "seek": 93260,
      "start": 945.719970703125,
      "end": 950.1599731445312,
      "text": " allermeisten Fällen geheim, dann können wir halt irgendwie auch ganz schwer beurteilen,",
      "tokens": [
        51020,
        439,
        31081,
        4821,
        479,
        46181,
        1519,
        18673,
        11,
        3594,
        6310,
        1987,
        12479,
        20759,
        2168,
        6312,
        23809,
        312,
        374,
        975,
        17471,
        11,
        51242
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3618435561656952,
      "compression_ratio": 1.5204918384552002,
      "no_speech_prob": 0.15179412066936493
    },
    {
      "id": 159,
      "seek": 93260,
      "start": 950.1599731445312,
      "end": 958.4400024414062,
      "text": " welche Qualität, also woher diese Information kommt und wie glaubwürdig sie ist. Und das ist",
      "tokens": [
        51242,
        24311,
        13616,
        14053,
        11,
        611,
        6020,
        511,
        6705,
        15357,
        10047,
        674,
        3355,
        23210,
        86,
        1655,
        25259,
        2804,
        1418,
        13,
        2719,
        1482,
        1418,
        51656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3618435561656952,
      "compression_ratio": 1.5204918384552002,
      "no_speech_prob": 0.15179412066936493
    },
    {
      "id": 160,
      "seek": 95844,
      "start": 958.4400024414062,
      "end": 963.0399780273438,
      "text": " tatsächlich auch irgendwie ein Thema, was ich halt für ein Problem halte, aber hat mit dem",
      "tokens": [
        50364,
        20796,
        2168,
        20759,
        1343,
        16306,
        11,
        390,
        1893,
        12479,
        2959,
        1343,
        11676,
        7523,
        975,
        11,
        4340,
        2385,
        2194,
        1371,
        50594
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30709585547447205,
      "compression_ratio": 1.6224489212036133,
      "no_speech_prob": 0.14018185436725616
    },
    {
      "id": 161,
      "seek": 95844,
      "start": 963.0399780273438,
      "end": 969.5599975585938,
      "text": " Paper jetzt erstmal nichts zu tun. So, wo war ich? Achso, genau, bei der Lüge. Also Lügen ist es",
      "tokens": [
        50594,
        24990,
        4354,
        38607,
        13004,
        2164,
        4267,
        13,
        407,
        11,
        6020,
        1516,
        1893,
        30,
        15847,
        539,
        11,
        12535,
        11,
        4643,
        1163,
        441,
        774,
        432,
        13,
        2743,
        441,
        45336,
        1418,
        785,
        50920
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30709585547447205,
      "compression_ratio": 1.6224489212036133,
      "no_speech_prob": 0.14018185436725616
    },
    {
      "id": 162,
      "seek": 95844,
      "start": 969.5599975585938,
      "end": 975.3599853515625,
      "text": " nicht, was LLMs tun. Da müsste ich halt bewusst die Unwahrheit sagen. Tun sie nicht. Sie haben",
      "tokens": [
        50920,
        1979,
        11,
        390,
        441,
        43,
        26386,
        4267,
        13,
        3933,
        42962,
        1893,
        12479,
        46221,
        978,
        1156,
        86,
        5398,
        8480,
        8360,
        13,
        21363,
        2804,
        1979,
        13,
        3559,
        3084,
        51210
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30709585547447205,
      "compression_ratio": 1.6224489212036133,
      "no_speech_prob": 0.14018185436725616
    },
    {
      "id": 163,
      "seek": 95844,
      "start": 975.3599853515625,
      "end": 980.3200073242188,
      "text": " ja noch irgendwie diese Gerüchte, Gossip, das wäre halt etwas, wo man sagt, ich weiß ja nicht,",
      "tokens": [
        51210,
        2784,
        3514,
        20759,
        6705,
        9409,
        774,
        10553,
        11,
        460,
        27971,
        11,
        1482,
        14558,
        12479,
        9569,
        11,
        6020,
        587,
        15764,
        11,
        1893,
        13385,
        2784,
        1979,
        11,
        51458
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30709585547447205,
      "compression_ratio": 1.6224489212036133,
      "no_speech_prob": 0.14018185436725616
    },
    {
      "id": 164,
      "seek": 95844,
      "start": 980.3200073242188,
      "end": 985.5999755859375,
      "text": " ob es wahr ist, aber ich gebe es trotzdem mal weiter. Und das, was ich in dem Paper gelernt",
      "tokens": [
        51458,
        1111,
        785,
        21628,
        1418,
        11,
        4340,
        1893,
        29073,
        785,
        28325,
        2806,
        8988,
        13,
        2719,
        1482,
        11,
        390,
        1893,
        294,
        1371,
        24990,
        49224,
        51722
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30709585547447205,
      "compression_ratio": 1.6224489212036133,
      "no_speech_prob": 0.14018185436725616
    },
    {
      "id": 165,
      "seek": 98560,
      "start": 985.760009765625,
      "end": 992.8800048828125,
      "text": " habe, ist, dass Bullshit tatsächlich etwas ist, was man definieren kann. Also da gibt es halt",
      "tokens": [
        50372,
        6015,
        11,
        1418,
        11,
        2658,
        14131,
        19186,
        20796,
        9569,
        1418,
        11,
        390,
        587,
        1561,
        5695,
        4028,
        13,
        2743,
        1120,
        6089,
        785,
        12479,
        50728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3145410120487213,
      "compression_ratio": 1.5560165643692017,
      "no_speech_prob": 0.066509909927845
    },
    {
      "id": 166,
      "seek": 98560,
      "start": 992.8800048828125,
      "end": 997.280029296875,
      "text": " diesen Harry Frankfurt, heißt der, das ist ein Philosophie-Professor, der ist mittlerweile",
      "tokens": [
        50728,
        12862,
        9378,
        36530,
        11,
        13139,
        1163,
        11,
        1482,
        1418,
        1343,
        31182,
        5317,
        414,
        12,
        43227,
        442,
        284,
        11,
        1163,
        1418,
        41999,
        50948
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3145410120487213,
      "compression_ratio": 1.5560165643692017,
      "no_speech_prob": 0.066509909927845
    },
    {
      "id": 167,
      "seek": 98560,
      "start": 997.280029296875,
      "end": 1006.52001953125,
      "text": " verstorben und der hat ein Buch geschrieben, das halt heißt On Bullshit. Und Wikipedia sagt halt,",
      "tokens": [
        50948,
        48960,
        284,
        1799,
        674,
        1163,
        2385,
        1343,
        25818,
        47397,
        11,
        1482,
        12479,
        13139,
        1282,
        14131,
        19186,
        13,
        2719,
        28999,
        15764,
        12479,
        11,
        51410
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3145410120487213,
      "compression_ratio": 1.5560165643692017,
      "no_speech_prob": 0.066509909927845
    },
    {
      "id": 168,
      "seek": 98560,
      "start": 1006.52001953125,
      "end": 1012.239990234375,
      "text": " im Kontext dieses Buches, das ist halt etwas, was halt unvermeidlich hervorgebracht wird,",
      "tokens": [
        51410,
        566,
        20629,
        3828,
        12113,
        25818,
        279,
        11,
        1482,
        1418,
        12479,
        9569,
        11,
        390,
        12479,
        517,
        331,
        1398,
        327,
        1739,
        720,
        85,
        4685,
        23404,
        4578,
        11,
        51696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3145410120487213,
      "compression_ratio": 1.5560165643692017,
      "no_speech_prob": 0.066509909927845
    },
    {
      "id": 169,
      "seek": 101224,
      "start": 1012.239990234375,
      "end": 1016.7999877929688,
      "text": " wenn Menschen gezwungen sind oder auch nur die Gelegenheit erhalten, über Dinge zu sprechen,",
      "tokens": [
        50364,
        4797,
        8397,
        1519,
        14406,
        5084,
        3290,
        4513,
        2168,
        4343,
        978,
        2876,
        22936,
        8480,
        38051,
        11,
        4502,
        25102,
        2164,
        27853,
        11,
        50592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2591683864593506,
      "compression_ratio": 1.6555556058883667,
      "no_speech_prob": 0.12402304261922836
    },
    {
      "id": 170,
      "seek": 101224,
      "start": 1016.7999877929688,
      "end": 1023.2000122070312,
      "text": " von denen sie nicht genug verstehen. So, und die Idee oder das Ziel ist es halt,",
      "tokens": [
        50592,
        2957,
        19998,
        2804,
        1979,
        33194,
        37352,
        13,
        407,
        11,
        674,
        978,
        32651,
        4513,
        1482,
        25391,
        1418,
        785,
        12479,
        11,
        50912
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2591683864593506,
      "compression_ratio": 1.6555556058883667,
      "no_speech_prob": 0.12402304261922836
    },
    {
      "id": 171,
      "seek": 101224,
      "start": 1023.2000122070312,
      "end": 1030.760009765625,
      "text": " glaubhaft zu wirken und es ist irgendwie egal, ob das, was man sagt, wahr ist oder nicht. Also",
      "tokens": [
        50912,
        23210,
        25127,
        2164,
        1987,
        2653,
        674,
        785,
        1418,
        20759,
        31528,
        11,
        1111,
        1482,
        11,
        390,
        587,
        15764,
        11,
        21628,
        1418,
        4513,
        1979,
        13,
        2743,
        51290
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2591683864593506,
      "compression_ratio": 1.6555556058883667,
      "no_speech_prob": 0.12402304261922836
    },
    {
      "id": 172,
      "seek": 101224,
      "start": 1030.760009765625,
      "end": 1035.800048828125,
      "text": " das ist nicht wie Lüge, wo ich halt sage, ich sage halt nicht die Wahrheit bewusst,",
      "tokens": [
        51290,
        1482,
        1418,
        1979,
        3355,
        441,
        774,
        432,
        11,
        6020,
        1893,
        12479,
        19721,
        11,
        1893,
        19721,
        12479,
        1979,
        978,
        36357,
        8480,
        46221,
        11,
        51542
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2591683864593506,
      "compression_ratio": 1.6555556058883667,
      "no_speech_prob": 0.12402304261922836
    },
    {
      "id": 173,
      "seek": 101224,
      "start": 1035.800048828125,
      "end": 1041.280029296875,
      "text": " weil ich halt irgendwie ein Ziel habe. Ich will halt nur glaubwürdig wirken. Die Beispiele,",
      "tokens": [
        51542,
        7689,
        1893,
        12479,
        20759,
        1343,
        25391,
        6015,
        13,
        3141,
        486,
        12479,
        4343,
        23210,
        86,
        1655,
        25259,
        1987,
        2653,
        13,
        3229,
        879,
        7631,
        15949,
        11,
        51816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2591683864593506,
      "compression_ratio": 1.6555556058883667,
      "no_speech_prob": 0.12402304261922836
    },
    {
      "id": 174,
      "seek": 104128,
      "start": 1041.280029296875,
      "end": 1046.199951171875,
      "text": " die jetzt das Paper nennen, sind ein Student, der die Quelle nicht gelesen hat, aber trotzdem",
      "tokens": [
        50364,
        978,
        4354,
        1482,
        24990,
        297,
        16043,
        11,
        3290,
        1343,
        12464,
        11,
        1163,
        978,
        4493,
        2447,
        1979,
        4087,
        17403,
        2385,
        11,
        4340,
        28325,
        50610
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32026928663253784,
      "compression_ratio": 1.521400809288025,
      "no_speech_prob": 0.0306423120200634
    },
    {
      "id": 175,
      "seek": 104128,
      "start": 1046.199951171875,
      "end": 1051.719970703125,
      "text": " darüber redet. Ein Politiker, der hat irgendwas gesagt, was sich irgendwie gut anhört. Würden mir",
      "tokens": [
        50610,
        21737,
        2182,
        302,
        13,
        6391,
        13812,
        17314,
        11,
        1163,
        2385,
        47090,
        12260,
        11,
        390,
        3041,
        20759,
        5228,
        18931,
        11454,
        13,
        43846,
        1556,
        3149,
        50886
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32026928663253784,
      "compression_ratio": 1.521400809288025,
      "no_speech_prob": 0.0306423120200634
    },
    {
      "id": 176,
      "seek": 104128,
      "start": 1051.719970703125,
      "end": 1058.5999755859375,
      "text": " einige einfallen, auch international. Ein Dilettant, der halt eine interessante Geschichte erzählen",
      "tokens": [
        50886,
        28338,
        1343,
        24425,
        11,
        2168,
        5058,
        13,
        6391,
        36475,
        3093,
        394,
        11,
        1163,
        12479,
        3018,
        24372,
        28896,
        28337,
        6698,
        51230
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32026928663253784,
      "compression_ratio": 1.521400809288025,
      "no_speech_prob": 0.0306423120200634
    },
    {
      "id": 177,
      "seek": 104128,
      "start": 1058.5999755859375,
      "end": 1066.280029296875,
      "text": " will. Was in dem Wikipedia-Artikel zu Bullshit stand, was ich auch spannend fand, sind Bürger,",
      "tokens": [
        51230,
        486,
        13,
        3027,
        294,
        1371,
        28999,
        12,
        32925,
        41486,
        2164,
        14131,
        19186,
        1463,
        11,
        390,
        1893,
        2168,
        49027,
        38138,
        11,
        3290,
        28514,
        11,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32026928663253784,
      "compression_ratio": 1.521400809288025,
      "no_speech_prob": 0.0306423120200634
    },
    {
      "id": 178,
      "seek": 106628,
      "start": 1066.43994140625,
      "end": 1071.8399658203125,
      "text": " die als Demokratinnen glauben, dass sie zu allem eine Meinung haben müssen. Was impliziert,",
      "tokens": [
        50372,
        978,
        3907,
        27802,
        11399,
        47139,
        11,
        2658,
        2804,
        2164,
        17585,
        3018,
        36519,
        3084,
        9013,
        13,
        3027,
        8484,
        43590,
        11,
        50642
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3460022509098053,
      "compression_ratio": 1.6931407451629639,
      "no_speech_prob": 0.2654358446598053
    },
    {
      "id": 179,
      "seek": 106628,
      "start": 1071.8399658203125,
      "end": 1075.3199462890625,
      "text": " dass sie sich eine Meinung bilden über Dinge, von denen sie eigentlich nichts verstehen. Wenn",
      "tokens": [
        50642,
        2658,
        2804,
        3041,
        3018,
        36519,
        22105,
        268,
        4502,
        25102,
        11,
        2957,
        19998,
        2804,
        10926,
        13004,
        37352,
        13,
        7899,
        50816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3460022509098053,
      "compression_ratio": 1.6931407451629639,
      "no_speech_prob": 0.2654358446598053
    },
    {
      "id": 180,
      "seek": 106628,
      "start": 1075.3199462890625,
      "end": 1080.199951171875,
      "text": " sie darüber diskutieren, ist das eben etwas, wo sie Schwierigkeiten haben mit der Wahrheit.",
      "tokens": [
        50816,
        2804,
        21737,
        36760,
        5695,
        11,
        1418,
        1482,
        11375,
        9569,
        11,
        6020,
        2804,
        17576,
        811,
        37545,
        3084,
        2194,
        1163,
        36357,
        8480,
        13,
        51060
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3460022509098053,
      "compression_ratio": 1.6931407451629639,
      "no_speech_prob": 0.2654358446598053
    },
    {
      "id": 181,
      "seek": 106628,
      "start": 1080.199951171875,
      "end": 1088.6400146484375,
      "text": " So und tatsächlich hat sich das noch, also der Begriff ist nicht so, wie soll ich sagen,",
      "tokens": [
        51060,
        407,
        674,
        20796,
        2385,
        3041,
        1482,
        3514,
        11,
        611,
        1163,
        879,
        32783,
        1418,
        1979,
        370,
        11,
        3355,
        7114,
        1893,
        8360,
        11,
        51482
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3460022509098053,
      "compression_ratio": 1.6931407451629639,
      "no_speech_prob": 0.2654358446598053
    },
    {
      "id": 182,
      "seek": 106628,
      "start": 1088.6400146484375,
      "end": 1093.8800048828125,
      "text": " also ist tatsächlich ein wichtiger Begriff, der noch zu weiteren Dingen geführt hat. Es gibt zum",
      "tokens": [
        51482,
        611,
        1418,
        20796,
        1343,
        48840,
        879,
        32783,
        11,
        1163,
        3514,
        2164,
        44036,
        49351,
        11271,
        19647,
        2385,
        13,
        2313,
        6089,
        5919,
        51744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3460022509098053,
      "compression_ratio": 1.6931407451629639,
      "no_speech_prob": 0.2654358446598053
    },
    {
      "id": 183,
      "seek": 109388,
      "start": 1093.8800048828125,
      "end": 1100.6800537109375,
      "text": " Beispiel dieses Buch Bullshit Jobs von dem David Greber. Da geht es halt um Jobs, die keinen",
      "tokens": [
        50364,
        13772,
        12113,
        25818,
        14131,
        19186,
        29169,
        2957,
        1371,
        4389,
        14986,
        607,
        13,
        3933,
        7095,
        785,
        12479,
        1105,
        29169,
        11,
        978,
        20624,
        50704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.302549809217453,
      "compression_ratio": 1.6808511018753052,
      "no_speech_prob": 0.0684976726770401
    },
    {
      "id": 184,
      "seek": 109388,
      "start": 1100.6800537109375,
      "end": 1105.0799560546875,
      "text": " gesellschaftlichen Nutzen und keine Bedeutung haben. Und die Behauptung ist halt, dass das",
      "tokens": [
        50704,
        5019,
        22055,
        10193,
        19861,
        2904,
        674,
        9252,
        363,
        4858,
        325,
        1063,
        3084,
        13,
        2719,
        978,
        13068,
        13343,
        1063,
        1418,
        12479,
        11,
        2658,
        1482,
        50924
      ],
      "temperature": 0.0,
      "avg_logprob": -0.302549809217453,
      "compression_ratio": 1.6808511018753052,
      "no_speech_prob": 0.0684976726770401
    },
    {
      "id": 185,
      "seek": 109388,
      "start": 1105.0799560546875,
      "end": 1110.199951171875,
      "text": " irgendwie der Grund ist, diese Bullshit Jobs der Grund sind, warum wir nicht alle 15 Stunden pro",
      "tokens": [
        50924,
        20759,
        1163,
        13941,
        1418,
        11,
        6705,
        14131,
        19186,
        29169,
        1163,
        13941,
        3290,
        11,
        24331,
        1987,
        1979,
        5430,
        2119,
        30496,
        447,
        51180
      ],
      "temperature": 0.0,
      "avg_logprob": -0.302549809217453,
      "compression_ratio": 1.6808511018753052,
      "no_speech_prob": 0.0684976726770401
    },
    {
      "id": 186,
      "seek": 109388,
      "start": 1110.199951171875,
      "end": 1115.4000244140625,
      "text": " Woche arbeiten und im Wesentlichen Freizeit zu uns haben, sondern es wird sozusagen Aufgaben,",
      "tokens": [
        51180,
        24511,
        23162,
        674,
        566,
        23843,
        7698,
        268,
        6142,
        1125,
        270,
        2164,
        2693,
        3084,
        11,
        11465,
        785,
        4578,
        33762,
        29648,
        25071,
        11,
        51440
      ],
      "temperature": 0.0,
      "avg_logprob": -0.302549809217453,
      "compression_ratio": 1.6808511018753052,
      "no_speech_prob": 0.0684976726770401
    },
    {
      "id": 187,
      "seek": 109388,
      "start": 1115.4000244140625,
      "end": 1120.47998046875,
      "text": " sinnlose Aufgaben geschaffen. Und das hat dieser Begriff Bullshit in einer etwas anderen Definition",
      "tokens": [
        51440,
        47066,
        75,
        541,
        29648,
        25071,
        13511,
        19182,
        13,
        2719,
        1482,
        2385,
        9053,
        879,
        32783,
        14131,
        19186,
        294,
        6850,
        9569,
        11122,
        46245,
        849,
        51694
      ],
      "temperature": 0.0,
      "avg_logprob": -0.302549809217453,
      "compression_ratio": 1.6808511018753052,
      "no_speech_prob": 0.0684976726770401
    },
    {
      "id": 188,
      "seek": 112048,
      "start": 1120.47998046875,
      "end": 1128.1600341796875,
      "text": " auch drin. Das heißt letztendlich für das Paper und für unsere Betrachtung von LLMs ist also wichtig",
      "tokens": [
        50364,
        2168,
        24534,
        13,
        2846,
        13139,
        35262,
        521,
        1739,
        2959,
        1482,
        24990,
        674,
        2959,
        14339,
        6279,
        81,
        3589,
        1063,
        2957,
        441,
        43,
        26386,
        1418,
        611,
        13621,
        50748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25603342056274414,
      "compression_ratio": 1.5325202941894531,
      "no_speech_prob": 0.05256906524300575
    },
    {
      "id": 189,
      "seek": 112048,
      "start": 1128.1600341796875,
      "end": 1134.6400146484375,
      "text": " zu sagen, dass Bullshit bedeutet, man versucht glaubhaft zu wirken, aber die Wahrheit ist",
      "tokens": [
        50748,
        2164,
        8360,
        11,
        2658,
        14131,
        19186,
        27018,
        11,
        587,
        36064,
        23210,
        25127,
        2164,
        1987,
        2653,
        11,
        4340,
        978,
        36357,
        8480,
        1418,
        51072
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25603342056274414,
      "compression_ratio": 1.5325202941894531,
      "no_speech_prob": 0.05256906524300575
    },
    {
      "id": 190,
      "seek": 112048,
      "start": 1134.6400146484375,
      "end": 1141.5999755859375,
      "text": " halt irgendwie egal. Und das Paper führt dann noch die beiden Kategorien Hard Bullshit ein.",
      "tokens": [
        51072,
        12479,
        20759,
        31528,
        13,
        2719,
        1482,
        24990,
        39671,
        3594,
        3514,
        978,
        23446,
        591,
        2968,
        284,
        1053,
        11817,
        14131,
        19186,
        1343,
        13,
        51420
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25603342056274414,
      "compression_ratio": 1.5325202941894531,
      "no_speech_prob": 0.05256906524300575
    },
    {
      "id": 191,
      "seek": 112048,
      "start": 1141.5999755859375,
      "end": 1148.0,
      "text": " Das ist etwas, wo ich mit Absicht Bullshit produziere, um das Publikum über die Absichten",
      "tokens": [
        51420,
        2846,
        1418,
        9569,
        11,
        6020,
        1893,
        2194,
        5813,
        1405,
        14131,
        19186,
        1082,
        3992,
        323,
        11,
        1105,
        1482,
        21808,
        13462,
        449,
        4502,
        978,
        5813,
        24681,
        51740
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25603342056274414,
      "compression_ratio": 1.5325202941894531,
      "no_speech_prob": 0.05256906524300575
    },
    {
      "id": 192,
      "seek": 114800,
      "start": 1148.0,
      "end": 1156.43994140625,
      "text": " des Sprechers zu täuschen. Und Soft ist halt ohne Täuschung. Also ohne, dass ich jetzt proaktiv",
      "tokens": [
        50364,
        730,
        1738,
        265,
        339,
        433,
        2164,
        14619,
        301,
        2470,
        13,
        2719,
        16985,
        1418,
        12479,
        15716,
        314,
        31611,
        339,
        1063,
        13,
        2743,
        15716,
        11,
        2658,
        1893,
        4354,
        447,
        5886,
        592,
        50786
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3464563488960266,
      "compression_ratio": 1.4299999475479126,
      "no_speech_prob": 0.0952172726392746
    },
    {
      "id": 193,
      "seek": 114800,
      "start": 1156.43994140625,
      "end": 1162.8399658203125,
      "text": " jemanden täuschen möchte. Also wenn ich ein Student bin, der das Paper nicht gelesen hat,",
      "tokens": [
        50786,
        21717,
        268,
        14619,
        301,
        2470,
        14570,
        13,
        2743,
        4797,
        1893,
        1343,
        12464,
        5171,
        11,
        1163,
        1482,
        24990,
        1979,
        4087,
        17403,
        2385,
        11,
        51106
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3464563488960266,
      "compression_ratio": 1.4299999475479126,
      "no_speech_prob": 0.0952172726392746
    },
    {
      "id": 194,
      "seek": 114800,
      "start": 1162.8399658203125,
      "end": 1173.8399658203125,
      "text": " aber mit Absicht anfange, darüber zu reden, dann mache ich Hard Bullshit, weil ich das Publikum",
      "tokens": [
        51106,
        4340,
        2194,
        5813,
        1405,
        33709,
        933,
        11,
        21737,
        2164,
        26447,
        11,
        3594,
        28289,
        1893,
        11817,
        14131,
        19186,
        11,
        7689,
        1893,
        1482,
        21808,
        13462,
        449,
        51656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3464563488960266,
      "compression_ratio": 1.4299999475479126,
      "no_speech_prob": 0.0952172726392746
    },
    {
      "id": 195,
      "seek": 117384,
      "start": 1173.9200439453125,
      "end": 1181.9200439453125,
      "text": " über die tatsächlichen Absichten täusche. Und das LLM produziert mindestens Soft Bullshit,",
      "tokens": [
        50368,
        4502,
        978,
        256,
        1720,
        10168,
        10193,
        5813,
        24681,
        14619,
        301,
        1876,
        13,
        2719,
        1482,
        441,
        43,
        44,
        28093,
        4859,
        1575,
        42624,
        16985,
        14131,
        19186,
        11,
        50768
      ],
      "temperature": 0.20000000298023224,
      "avg_logprob": -0.3417254388332367,
      "compression_ratio": 1.335365891456604,
      "no_speech_prob": 0.21077193319797516
    },
    {
      "id": 196,
      "seek": 117384,
      "start": 1181.9200439453125,
      "end": 1188.6800537109375,
      "text": " in dem Sinne, dass es eben keine Intention hat. Und der Wahrheitsegalheit ist halt egal,",
      "tokens": [
        50768,
        294,
        1371,
        47041,
        11,
        2658,
        785,
        11375,
        9252,
        5681,
        1251,
        2385,
        13,
        2719,
        1163,
        36357,
        24260,
        38221,
        8480,
        1418,
        12479,
        31528,
        11,
        51106
      ],
      "temperature": 0.20000000298023224,
      "avg_logprob": -0.3417254388332367,
      "compression_ratio": 1.335365891456604,
      "no_speech_prob": 0.21077193319797516
    },
    {
      "id": 197,
      "seek": 117384,
      "start": 1188.6800537109375,
      "end": 1191.800048828125,
      "text": " weil davon hat es eben kein Konzept.",
      "tokens": [
        51106,
        7689,
        18574,
        2385,
        785,
        11375,
        13424,
        12718,
        32082,
        13,
        51262
      ],
      "temperature": 0.20000000298023224,
      "avg_logprob": -0.3417254388332367,
      "compression_ratio": 1.335365891456604,
      "no_speech_prob": 0.21077193319797516
    },
    {
      "id": 0,
      "seek": 0,
      "start": 1208.24,
      "end": 1213.24,
      "text": " I'm not sure if the paper is completely solid.",
      "tokens": [
        50364,
        286,
        478,
        406,
        988,
        498,
        264,
        3035,
        307,
        2584,
        5100,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6074564456939697,
      "compression_ratio": 1.5053763389587402,
      "no_speech_prob": 0.8877348899841309
    },
    {
      "id": 1,
      "seek": 0,
      "start": 1213.24,
      "end": 1220.24,
      "text": " You can submit the intention to the LLM how to act like a human being and how to act reliably.",
      "tokens": [
        50614,
        509,
        393,
        10315,
        264,
        7789,
        281,
        264,
        441,
        43,
        44,
        577,
        281,
        605,
        411,
        257,
        1952,
        885,
        293,
        577,
        281,
        605,
        49927,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6074564456939697,
      "compression_ratio": 1.5053763389587402,
      "no_speech_prob": 0.8877348899841309
    },
    {
      "id": 2,
      "seek": 0,
      "start": 1220.24,
      "end": 1226.24,
      "text": " Then it may be that it is hard bullshit.",
      "tokens": [
        50964,
        1396,
        309,
        815,
        312,
        300,
        309,
        307,
        1152,
        22676,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6074564456939697,
      "compression_ratio": 1.5053763389587402,
      "no_speech_prob": 0.8877348899841309
    },
    {
      "id": 3,
      "seek": 0,
      "start": 1226.24,
      "end": 1235.24,
      "text": " I find it difficult in this whole discussion that it is neglected that there are these developers",
      "tokens": [
        51264,
        286,
        915,
        309,
        2252,
        294,
        341,
        1379,
        5017,
        300,
        309,
        307,
        32701,
        300,
        456,
        366,
        613,
        8849,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6074564456939697,
      "compression_ratio": 1.5053763389587402,
      "no_speech_prob": 0.8877348899841309
    },
    {
      "id": 4,
      "seek": 2700,
      "start": 1235.24,
      "end": 1238.24,
      "text": " who actually built the system and have an intention.",
      "tokens": [
        50364,
        567,
        767,
        3094,
        264,
        1185,
        293,
        362,
        364,
        7789,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5023416876792908,
      "compression_ratio": 1.6051281690597534,
      "no_speech_prob": 0.04844937473535538
    },
    {
      "id": 5,
      "seek": 2700,
      "start": 1238.24,
      "end": 1247.24,
      "text": " And they actually implement the intention to convince people that an LLM somehow",
      "tokens": [
        50514,
        400,
        436,
        767,
        4445,
        264,
        7789,
        281,
        13447,
        561,
        300,
        364,
        441,
        43,
        44,
        6063,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5023416876792908,
      "compression_ratio": 1.6051281690597534,
      "no_speech_prob": 0.04844937473535538
    },
    {
      "id": 6,
      "seek": 2700,
      "start": 1247.24,
      "end": 1249.24,
      "text": " does useful and great things.",
      "tokens": [
        50964,
        775,
        4420,
        293,
        869,
        721,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5023416876792908,
      "compression_ratio": 1.6051281690597534,
      "no_speech_prob": 0.04844937473535538
    },
    {
      "id": 7,
      "seek": 2700,
      "start": 1249.24,
      "end": 1255.24,
      "text": " Sven just said the question whether the intention of the company that is training the LLM by hand",
      "tokens": [
        51064,
        49787,
        445,
        848,
        264,
        1168,
        1968,
        264,
        7789,
        295,
        264,
        2237,
        300,
        307,
        3097,
        264,
        441,
        43,
        44,
        538,
        1011,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5023416876792908,
      "compression_ratio": 1.6051281690597534,
      "no_speech_prob": 0.04844937473535538
    },
    {
      "id": 8,
      "seek": 2700,
      "start": 1255.24,
      "end": 1258.24,
      "text": " is not hard bullshit or the system prompt.",
      "tokens": [
        51364,
        307,
        406,
        1152,
        22676,
        420,
        264,
        1185,
        12391,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5023416876792908,
      "compression_ratio": 1.6051281690597534,
      "no_speech_prob": 0.04844937473535538
    },
    {
      "id": 9,
      "seek": 2700,
      "start": 1258.24,
      "end": 1259.24,
      "text": " Exactly.",
      "tokens": [
        51514,
        7587,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5023416876792908,
      "compression_ratio": 1.6051281690597534,
      "no_speech_prob": 0.04844937473535538
    },
    {
      "id": 10,
      "seek": 5100,
      "start": 1259.24,
      "end": 1262.24,
      "text": " That would be a bit of a question for me.",
      "tokens": [
        50364,
        663,
        576,
        312,
        257,
        857,
        295,
        257,
        1168,
        337,
        385,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4322465658187866,
      "compression_ratio": 1.5792078971862793,
      "no_speech_prob": 0.478410542011261
    },
    {
      "id": 11,
      "seek": 5100,
      "start": 1262.24,
      "end": 1265.24,
      "text": " The paper doesn't follow that.",
      "tokens": [
        50514,
        440,
        3035,
        1177,
        380,
        1524,
        300,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4322465658187866,
      "compression_ratio": 1.5792078971862793,
      "no_speech_prob": 0.478410542011261
    },
    {
      "id": 12,
      "seek": 5100,
      "start": 1265.24,
      "end": 1269.24,
      "text": " The paper also criticizes hallucinations.",
      "tokens": [
        50664,
        440,
        3035,
        611,
        7850,
        5660,
        35212,
        10325,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4322465658187866,
      "compression_ratio": 1.5792078971862793,
      "no_speech_prob": 0.478410542011261
    },
    {
      "id": 13,
      "seek": 5100,
      "start": 1269.24,
      "end": 1274.24,
      "text": " We have already talked about it briefly, because it is an anthropomorphic metaphor.",
      "tokens": [
        50864,
        492,
        362,
        1217,
        2825,
        466,
        309,
        10515,
        11,
        570,
        309,
        307,
        364,
        22727,
        32702,
        299,
        19157,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4322465658187866,
      "compression_ratio": 1.5792078971862793,
      "no_speech_prob": 0.478410542011261
    },
    {
      "id": 14,
      "seek": 5100,
      "start": 1274.24,
      "end": 1281.24,
      "text": " So one that seems human and pushes the problem a bit on the model.",
      "tokens": [
        51114,
        407,
        472,
        300,
        2544,
        1952,
        293,
        21020,
        264,
        1154,
        257,
        857,
        322,
        264,
        2316,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4322465658187866,
      "compression_ratio": 1.5792078971862793,
      "no_speech_prob": 0.478410542011261
    },
    {
      "id": 15,
      "seek": 5100,
      "start": 1281.24,
      "end": 1286.24,
      "text": " The model is somehow not okay and has hallucinations.",
      "tokens": [
        51464,
        440,
        2316,
        307,
        6063,
        406,
        1392,
        293,
        575,
        35212,
        10325,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4322465658187866,
      "compression_ratio": 1.5792078971862793,
      "no_speech_prob": 0.478410542011261
    },
    {
      "id": 16,
      "seek": 7800,
      "start": 1286.24,
      "end": 1291.24,
      "text": " And with that, the responsibility of the producer is turned away a bit.",
      "tokens": [
        50364,
        400,
        365,
        300,
        11,
        264,
        6357,
        295,
        264,
        12314,
        307,
        3574,
        1314,
        257,
        857,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44323039054870605,
      "compression_ratio": 1.5244444608688354,
      "no_speech_prob": 0.08601831644773483
    },
    {
      "id": 17,
      "seek": 7800,
      "start": 1291.24,
      "end": 1302.24,
      "text": " And an alternative, which I haven't heard before, is confabulation.",
      "tokens": [
        50614,
        400,
        364,
        8535,
        11,
        597,
        286,
        2378,
        380,
        2198,
        949,
        11,
        307,
        1497,
        14057,
        399,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44323039054870605,
      "compression_ratio": 1.5244444608688354,
      "no_speech_prob": 0.08601831644773483
    },
    {
      "id": 18,
      "seek": 7800,
      "start": 1302.24,
      "end": 1304.24,
      "text": " That is also an anthropomorphic metaphor.",
      "tokens": [
        51164,
        663,
        307,
        611,
        364,
        22727,
        32702,
        299,
        19157,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44323039054870605,
      "compression_ratio": 1.5244444608688354,
      "no_speech_prob": 0.08601831644773483
    },
    {
      "id": 19,
      "seek": 7800,
      "start": 1304.24,
      "end": 1307.24,
      "text": " And that is the production of objectively false memories.",
      "tokens": [
        51264,
        400,
        300,
        307,
        264,
        4265,
        295,
        46067,
        7908,
        8495,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44323039054870605,
      "compression_ratio": 1.5244444608688354,
      "no_speech_prob": 0.08601831644773483
    },
    {
      "id": 20,
      "seek": 7800,
      "start": 1307.24,
      "end": 1310.24,
      "text": " What can happen, for example, due to a mental illness.",
      "tokens": [
        51414,
        708,
        393,
        1051,
        11,
        337,
        1365,
        11,
        3462,
        281,
        257,
        4973,
        10152,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44323039054870605,
      "compression_ratio": 1.5244444608688354,
      "no_speech_prob": 0.08601831644773483
    },
    {
      "id": 21,
      "seek": 7800,
      "start": 1310.24,
      "end": 1313.24,
      "text": " Or there are also ... I guess that's part of it.",
      "tokens": [
        51564,
        1610,
        456,
        366,
        611,
        1097,
        286,
        2041,
        300,
        311,
        644,
        295,
        309,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44323039054870605,
      "compression_ratio": 1.5244444608688354,
      "no_speech_prob": 0.08601831644773483
    },
    {
      "id": 22,
      "seek": 10500,
      "start": 1313.24,
      "end": 1317.24,
      "text": " You can actually persuade people that they have experienced something.",
      "tokens": [
        50364,
        509,
        393,
        767,
        31781,
        561,
        300,
        436,
        362,
        6751,
        746,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3604561388492584,
      "compression_ratio": 1.5989011526107788,
      "no_speech_prob": 0.5478792786598206
    },
    {
      "id": 23,
      "seek": 10500,
      "start": 1317.24,
      "end": 1322.24,
      "text": " That would be confabulation.",
      "tokens": [
        50564,
        663,
        576,
        312,
        1497,
        14057,
        399,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3604561388492584,
      "compression_ratio": 1.5989011526107788,
      "no_speech_prob": 0.5478792786598206
    },
    {
      "id": 24,
      "seek": 10500,
      "start": 1322.24,
      "end": 1325.24,
      "text": " That would be an alternative to the term hallucination.",
      "tokens": [
        50814,
        663,
        576,
        312,
        364,
        8535,
        281,
        264,
        1433,
        35212,
        2486,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3604561388492584,
      "compression_ratio": 1.5989011526107788,
      "no_speech_prob": 0.5478792786598206
    },
    {
      "id": 25,
      "seek": 10500,
      "start": 1325.24,
      "end": 1328.24,
      "text": " But I don't think that helps us either.",
      "tokens": [
        50964,
        583,
        286,
        500,
        380,
        519,
        300,
        3665,
        505,
        2139,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3604561388492584,
      "compression_ratio": 1.5989011526107788,
      "no_speech_prob": 0.5478792786598206
    },
    {
      "id": 26,
      "seek": 10500,
      "start": 1328.24,
      "end": 1336.24,
      "text": " Because then you actually assume that the goal is correct information.",
      "tokens": [
        51114,
        1436,
        550,
        291,
        767,
        6552,
        300,
        264,
        3387,
        307,
        3006,
        1589,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3604561388492584,
      "compression_ratio": 1.5989011526107788,
      "no_speech_prob": 0.5478792786598206
    },
    {
      "id": 27,
      "seek": 10500,
      "start": 1336.24,
      "end": 1338.24,
      "text": " But that's not the case.",
      "tokens": [
        51514,
        583,
        300,
        311,
        406,
        264,
        1389,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3604561388492584,
      "compression_ratio": 1.5989011526107788,
      "no_speech_prob": 0.5478792786598206
    },
    {
      "id": 28,
      "seek": 13000,
      "start": 1338.24,
      "end": 1343.24,
      "text": " The goal is to produce a credible text.",
      "tokens": [
        50364,
        440,
        3387,
        307,
        281,
        5258,
        257,
        3864,
        897,
        306,
        2487,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35749247670173645,
      "compression_ratio": 1.4726368188858032,
      "no_speech_prob": 0.6610434055328369
    },
    {
      "id": 29,
      "seek": 13000,
      "start": 1343.24,
      "end": 1345.24,
      "text": " But that's just bullshitting.",
      "tokens": [
        50614,
        583,
        300,
        311,
        445,
        4693,
        2716,
        2414,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35749247670173645,
      "compression_ratio": 1.4726368188858032,
      "no_speech_prob": 0.6610434055328369
    },
    {
      "id": 30,
      "seek": 13000,
      "start": 1345.24,
      "end": 1350.24,
      "text": " Now the question is, what does that mean for us?",
      "tokens": [
        50714,
        823,
        264,
        1168,
        307,
        11,
        437,
        775,
        300,
        914,
        337,
        505,
        30,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35749247670173645,
      "compression_ratio": 1.4726368188858032,
      "no_speech_prob": 0.6610434055328369
    },
    {
      "id": 31,
      "seek": 13000,
      "start": 1350.24,
      "end": 1352.24,
      "text": " Or how do I stand to that?",
      "tokens": [
        50964,
        1610,
        577,
        360,
        286,
        1463,
        281,
        300,
        30,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35749247670173645,
      "compression_ratio": 1.4726368188858032,
      "no_speech_prob": 0.6610434055328369
    },
    {
      "id": 32,
      "seek": 13000,
      "start": 1352.24,
      "end": 1360.24,
      "text": " I find the paper interesting and important.",
      "tokens": [
        51064,
        286,
        915,
        264,
        3035,
        1880,
        293,
        1021,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35749247670173645,
      "compression_ratio": 1.4726368188858032,
      "no_speech_prob": 0.6610434055328369
    },
    {
      "id": 33,
      "seek": 13000,
      "start": 1360.24,
      "end": 1363.24,
      "text": " And that's why I wanted to make this episode about it.",
      "tokens": [
        51464,
        400,
        300,
        311,
        983,
        286,
        1415,
        281,
        652,
        341,
        3500,
        466,
        309,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35749247670173645,
      "compression_ratio": 1.4726368188858032,
      "no_speech_prob": 0.6610434055328369
    },
    {
      "id": 34,
      "seek": 13000,
      "start": 1363.24,
      "end": 1367.24,
      "text": " Because it consciously introduces another metaphor.",
      "tokens": [
        51614,
        1436,
        309,
        32538,
        31472,
        1071,
        19157,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35749247670173645,
      "compression_ratio": 1.4726368188858032,
      "no_speech_prob": 0.6610434055328369
    },
    {
      "id": 35,
      "seek": 15900,
      "start": 1367.24,
      "end": 1370.24,
      "text": " So if I say I have artificial intelligence,",
      "tokens": [
        50364,
        407,
        498,
        286,
        584,
        286,
        362,
        11677,
        7599,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36537015438079834,
      "compression_ratio": 1.6699999570846558,
      "no_speech_prob": 0.12165872752666473
    },
    {
      "id": 36,
      "seek": 15900,
      "start": 1370.24,
      "end": 1376.24,
      "text": " then I follow this idea that people had at the time with artificial intelligence.",
      "tokens": [
        50514,
        550,
        286,
        1524,
        341,
        1558,
        300,
        561,
        632,
        412,
        264,
        565,
        365,
        11677,
        7599,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36537015438079834,
      "compression_ratio": 1.6699999570846558,
      "no_speech_prob": 0.12165872752666473
    },
    {
      "id": 37,
      "seek": 15900,
      "start": 1376.24,
      "end": 1380.24,
      "text": " So they introduced the metaphor to transport.",
      "tokens": [
        50814,
        407,
        436,
        7268,
        264,
        19157,
        281,
        5495,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36537015438079834,
      "compression_ratio": 1.6699999570846558,
      "no_speech_prob": 0.12165872752666473
    },
    {
      "id": 38,
      "seek": 15900,
      "start": 1380.24,
      "end": 1384.24,
      "text": " That in the not-too-distant future we will have human-like things.",
      "tokens": [
        51014,
        663,
        294,
        264,
        406,
        12,
        32599,
        12,
        67,
        10329,
        2027,
        321,
        486,
        362,
        1952,
        12,
        4092,
        721,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36537015438079834,
      "compression_ratio": 1.6699999570846558,
      "no_speech_prob": 0.12165872752666473
    },
    {
      "id": 39,
      "seek": 15900,
      "start": 1384.24,
      "end": 1387.24,
      "text": " With a human-like intelligence.",
      "tokens": [
        51214,
        2022,
        257,
        1952,
        12,
        4092,
        7599,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36537015438079834,
      "compression_ratio": 1.6699999570846558,
      "no_speech_prob": 0.12165872752666473
    },
    {
      "id": 40,
      "seek": 15900,
      "start": 1387.24,
      "end": 1392.24,
      "text": " And they did that very consciously to ultimately sell a vision.",
      "tokens": [
        51364,
        400,
        436,
        630,
        300,
        588,
        32538,
        281,
        6284,
        3607,
        257,
        5201,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36537015438079834,
      "compression_ratio": 1.6699999570846558,
      "no_speech_prob": 0.12165872752666473
    },
    {
      "id": 41,
      "seek": 18400,
      "start": 1392.24,
      "end": 1398.24,
      "text": " And this whole technology approach, which is a multitude of different things,",
      "tokens": [
        50364,
        400,
        341,
        1379,
        2899,
        3109,
        11,
        597,
        307,
        257,
        36358,
        295,
        819,
        721,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4741867780685425,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.6369115710258484
    },
    {
      "id": 42,
      "seek": 18400,
      "start": 1398.24,
      "end": 1401.24,
      "text": " to open up a bit to breakthrough.",
      "tokens": [
        50664,
        281,
        1269,
        493,
        257,
        857,
        281,
        22397,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4741867780685425,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.6369115710258484
    },
    {
      "id": 43,
      "seek": 18400,
      "start": 1401.24,
      "end": 1404.24,
      "text": " And I find it interesting to say,",
      "tokens": [
        50814,
        400,
        286,
        915,
        309,
        1880,
        281,
        584,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4741867780685425,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.6369115710258484
    },
    {
      "id": 44,
      "seek": 18400,
      "start": 1404.24,
      "end": 1406.24,
      "text": " then we call it bullshit.",
      "tokens": [
        50964,
        550,
        321,
        818,
        309,
        4693,
        2716,
        270,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4741867780685425,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.6369115710258484
    },
    {
      "id": 45,
      "seek": 18400,
      "start": 1406.24,
      "end": 1409.24,
      "text": " And let's see if that holds up at the review.",
      "tokens": [
        51064,
        400,
        718,
        311,
        536,
        498,
        300,
        9190,
        493,
        412,
        264,
        3131,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4741867780685425,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.6369115710258484
    },
    {
      "id": 46,
      "seek": 18400,
      "start": 1409.24,
      "end": 1414.24,
      "text": " If we call the thing artificial intelligence, but it's not intelligent,",
      "tokens": [
        51214,
        759,
        321,
        818,
        264,
        551,
        11677,
        7599,
        11,
        457,
        309,
        311,
        406,
        13232,
        11,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4741867780685425,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.6369115710258484
    },
    {
      "id": 47,
      "seek": 18400,
      "start": 1414.24,
      "end": 1416.24,
      "text": " why can't we call it bullshit?",
      "tokens": [
        51464,
        983,
        393,
        380,
        321,
        818,
        309,
        22676,
        30,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4741867780685425,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.6369115710258484
    },
    {
      "id": 48,
      "seek": 20800,
      "start": 1416.24,
      "end": 1418.24,
      "text": " And it's just kind of...",
      "tokens": [
        50364,
        400,
        309,
        311,
        445,
        733,
        295,
        485,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4168882966041565,
      "compression_ratio": 1.6338027715682983,
      "no_speech_prob": 0.963783323764801
    },
    {
      "id": 49,
      "seek": 20800,
      "start": 1418.24,
      "end": 1423.24,
      "text": " Maybe even a bit more coherent to talk about bullshit than intelligence.",
      "tokens": [
        50464,
        2704,
        754,
        257,
        857,
        544,
        36239,
        281,
        751,
        466,
        22676,
        813,
        7599,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4168882966041565,
      "compression_ratio": 1.6338027715682983,
      "no_speech_prob": 0.963783323764801
    },
    {
      "id": 50,
      "seek": 20800,
      "start": 1423.24,
      "end": 1427.24,
      "text": " And then we have a metaphor that is devaluing,",
      "tokens": [
        50714,
        400,
        550,
        321,
        362,
        257,
        19157,
        300,
        307,
        1905,
        4929,
        278,
        11,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4168882966041565,
      "compression_ratio": 1.6338027715682983,
      "no_speech_prob": 0.963783323764801
    },
    {
      "id": 51,
      "seek": 20800,
      "start": 1427.24,
      "end": 1430.24,
      "text": " just like intelligence is devaluing.",
      "tokens": [
        50914,
        445,
        411,
        7599,
        307,
        1905,
        4929,
        278,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4168882966041565,
      "compression_ratio": 1.6338027715682983,
      "no_speech_prob": 0.963783323764801
    },
    {
      "id": 52,
      "seek": 20800,
      "start": 1430.24,
      "end": 1432.24,
      "text": " So that's my interpretation.",
      "tokens": [
        51064,
        407,
        300,
        311,
        452,
        14174,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4168882966041565,
      "compression_ratio": 1.6338027715682983,
      "no_speech_prob": 0.963783323764801
    },
    {
      "id": 53,
      "seek": 20800,
      "start": 1432.24,
      "end": 1434.24,
      "text": " That's not what's in the paper.",
      "tokens": [
        51164,
        663,
        311,
        406,
        437,
        311,
        294,
        264,
        3035,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4168882966041565,
      "compression_ratio": 1.6338027715682983,
      "no_speech_prob": 0.963783323764801
    },
    {
      "id": 54,
      "seek": 20800,
      "start": 1434.24,
      "end": 1437.24,
      "text": " In the paper there is a very clean argument for",
      "tokens": [
        51264,
        682,
        264,
        3035,
        456,
        307,
        257,
        588,
        2541,
        6770,
        337,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4168882966041565,
      "compression_ratio": 1.6338027715682983,
      "no_speech_prob": 0.963783323764801
    },
    {
      "id": 55,
      "seek": 20800,
      "start": 1437.24,
      "end": 1445.24,
      "text": " that this is actually bullshit in the sense of Frankfurt.",
      "tokens": [
        51414,
        300,
        341,
        307,
        767,
        22676,
        294,
        264,
        2020,
        295,
        36530,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4168882966041565,
      "compression_ratio": 1.6338027715682983,
      "no_speech_prob": 0.963783323764801
    },
    {
      "id": 56,
      "seek": 23700,
      "start": 1446.24,
      "end": 1451.24,
      "text": " And that's an exciting idea for now.",
      "tokens": [
        50414,
        400,
        300,
        311,
        364,
        4670,
        1558,
        337,
        586,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4740073084831238,
      "compression_ratio": 1.4858757257461548,
      "no_speech_prob": 0.028485344722867012
    },
    {
      "id": 57,
      "seek": 23700,
      "start": 1451.24,
      "end": 1456.24,
      "text": " And to deal with such ideas is helpful, I think.",
      "tokens": [
        50664,
        400,
        281,
        2028,
        365,
        1270,
        3487,
        307,
        4961,
        11,
        286,
        519,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4740073084831238,
      "compression_ratio": 1.4858757257461548,
      "no_speech_prob": 0.028485344722867012
    },
    {
      "id": 58,
      "seek": 23700,
      "start": 1456.24,
      "end": 1461.24,
      "text": " And one thing that I have derived for myself, so to speak, is...",
      "tokens": [
        50914,
        400,
        472,
        551,
        300,
        286,
        362,
        18949,
        337,
        2059,
        11,
        370,
        281,
        1710,
        11,
        307,
        485,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4740073084831238,
      "compression_ratio": 1.4858757257461548,
      "no_speech_prob": 0.028485344722867012
    },
    {
      "id": 59,
      "seek": 23700,
      "start": 1461.24,
      "end": 1464.24,
      "text": " So I'm an architect consultant now.",
      "tokens": [
        51164,
        407,
        286,
        478,
        364,
        6331,
        24676,
        586,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4740073084831238,
      "compression_ratio": 1.4858757257461548,
      "no_speech_prob": 0.028485344722867012
    },
    {
      "id": 60,
      "seek": 23700,
      "start": 1464.24,
      "end": 1467.24,
      "text": " That means I love to give people advice",
      "tokens": [
        51314,
        663,
        1355,
        286,
        959,
        281,
        976,
        561,
        5192,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4740073084831238,
      "compression_ratio": 1.4858757257461548,
      "no_speech_prob": 0.028485344722867012
    },
    {
      "id": 61,
      "seek": 23700,
      "start": 1467.24,
      "end": 1471.24,
      "text": " and to make a targeted consultation.",
      "tokens": [
        51464,
        293,
        281,
        652,
        257,
        15045,
        20932,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4740073084831238,
      "compression_ratio": 1.4858757257461548,
      "no_speech_prob": 0.028485344722867012
    },
    {
      "id": 62,
      "seek": 26300,
      "start": 1471.24,
      "end": 1473.24,
      "text": " And...",
      "tokens": [
        50364,
        400,
        485,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32032328844070435,
      "compression_ratio": 1.7383177280426025,
      "no_speech_prob": 0.05661740526556969
    },
    {
      "id": 63,
      "seek": 26300,
      "start": 1474.24,
      "end": 1476.24,
      "text": " So there are situations where I say,",
      "tokens": [
        50514,
        407,
        456,
        366,
        6851,
        689,
        286,
        584,
        11,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32032328844070435,
      "compression_ratio": 1.7383177280426025,
      "no_speech_prob": 0.05661740526556969
    },
    {
      "id": 64,
      "seek": 26300,
      "start": 1476.24,
      "end": 1480.24,
      "text": " that's a good question and I don't know exactly what the answer is.",
      "tokens": [
        50614,
        300,
        311,
        257,
        665,
        1168,
        293,
        286,
        500,
        380,
        458,
        2293,
        437,
        264,
        1867,
        307,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32032328844070435,
      "compression_ratio": 1.7383177280426025,
      "no_speech_prob": 0.05661740526556969
    },
    {
      "id": 65,
      "seek": 26300,
      "start": 1480.24,
      "end": 1484.24,
      "text": " And then I try to weigh things somehow.",
      "tokens": [
        50814,
        400,
        550,
        286,
        853,
        281,
        13843,
        721,
        6063,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32032328844070435,
      "compression_ratio": 1.7383177280426025,
      "no_speech_prob": 0.05661740526556969
    },
    {
      "id": 66,
      "seek": 26300,
      "start": 1484.24,
      "end": 1487.24,
      "text": " So, I don't know, is that the best technology now?",
      "tokens": [
        51014,
        407,
        11,
        286,
        500,
        380,
        458,
        11,
        307,
        300,
        264,
        1151,
        2899,
        586,
        30,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32032328844070435,
      "compression_ratio": 1.7383177280426025,
      "no_speech_prob": 0.05661740526556969
    },
    {
      "id": 67,
      "seek": 26300,
      "start": 1487.24,
      "end": 1489.24,
      "text": " I don't know. There are the following options.",
      "tokens": [
        51164,
        286,
        500,
        380,
        458,
        13,
        821,
        366,
        264,
        3480,
        3956,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32032328844070435,
      "compression_ratio": 1.7383177280426025,
      "no_speech_prob": 0.05661740526556969
    },
    {
      "id": 68,
      "seek": 26300,
      "start": 1489.24,
      "end": 1493.24,
      "text": " You can somehow, I don't know, use RapidMQ or Kafka.",
      "tokens": [
        51264,
        509,
        393,
        6063,
        11,
        286,
        500,
        380,
        458,
        11,
        764,
        44580,
        44,
        48,
        420,
        47064,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32032328844070435,
      "compression_ratio": 1.7383177280426025,
      "no_speech_prob": 0.05661740526556969
    },
    {
      "id": 69,
      "seek": 26300,
      "start": 1493.24,
      "end": 1495.24,
      "text": " And those are advantages and disadvantages.",
      "tokens": [
        51464,
        400,
        729,
        366,
        14906,
        293,
        37431,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32032328844070435,
      "compression_ratio": 1.7383177280426025,
      "no_speech_prob": 0.05661740526556969
    },
    {
      "id": 70,
      "seek": 26300,
      "start": 1495.24,
      "end": 1497.24,
      "text": " And I don't know exactly.",
      "tokens": [
        51564,
        400,
        286,
        500,
        380,
        458,
        2293,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32032328844070435,
      "compression_ratio": 1.7383177280426025,
      "no_speech_prob": 0.05661740526556969
    },
    {
      "id": 71,
      "seek": 28900,
      "start": 1498.24,
      "end": 1501.24,
      "text": " I don't want to seem convincing in the sense that I say,",
      "tokens": [
        50414,
        286,
        500,
        380,
        528,
        281,
        1643,
        416,
        4796,
        2175,
        294,
        264,
        2020,
        300,
        286,
        584,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36163732409477234,
      "compression_ratio": 1.550264596939087,
      "no_speech_prob": 0.6428477764129639
    },
    {
      "id": 72,
      "seek": 28900,
      "start": 1501.24,
      "end": 1506.24,
      "text": " that's the solution, but actually start a thinking process.",
      "tokens": [
        50564,
        300,
        311,
        264,
        3827,
        11,
        457,
        767,
        722,
        257,
        1953,
        1399,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36163732409477234,
      "compression_ratio": 1.550264596939087,
      "no_speech_prob": 0.6428477764129639
    },
    {
      "id": 73,
      "seek": 28900,
      "start": 1506.24,
      "end": 1509.24,
      "text": " And something like, I don't know,",
      "tokens": [
        50814,
        400,
        746,
        411,
        11,
        286,
        500,
        380,
        458,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36163732409477234,
      "compression_ratio": 1.550264596939087,
      "no_speech_prob": 0.6428477764129639
    },
    {
      "id": 74,
      "seek": 28900,
      "start": 1509.24,
      "end": 1514.24,
      "text": " is in my opinion something that can and may occur in my vocabulary",
      "tokens": [
        50964,
        307,
        294,
        452,
        4800,
        746,
        300,
        393,
        293,
        815,
        5160,
        294,
        452,
        19864,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36163732409477234,
      "compression_ratio": 1.550264596939087,
      "no_speech_prob": 0.6428477764129639
    },
    {
      "id": 75,
      "seek": 28900,
      "start": 1514.24,
      "end": 1517.24,
      "text": " and in what I say.",
      "tokens": [
        51214,
        293,
        294,
        437,
        286,
        584,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36163732409477234,
      "compression_ratio": 1.550264596939087,
      "no_speech_prob": 0.6428477764129639
    },
    {
      "id": 76,
      "seek": 28900,
      "start": 1517.24,
      "end": 1525.24,
      "text": " And I'm not sure if an LLM would say that so concretely.",
      "tokens": [
        51364,
        400,
        286,
        478,
        406,
        988,
        498,
        364,
        441,
        43,
        44,
        576,
        584,
        300,
        370,
        39481,
        736,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36163732409477234,
      "compression_ratio": 1.550264596939087,
      "no_speech_prob": 0.6428477764129639
    },
    {
      "id": 77,
      "seek": 31700,
      "start": 1525.24,
      "end": 1528.24,
      "text": " And I have a little bit...",
      "tokens": [
        50364,
        400,
        286,
        362,
        257,
        707,
        857,
        485,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35293376445770264,
      "compression_ratio": 1.5973451137542725,
      "no_speech_prob": 0.43906262516975403
    },
    {
      "id": 78,
      "seek": 31700,
      "start": 1528.24,
      "end": 1531.24,
      "text": " So it helps me not to talk about LLMs anymore,",
      "tokens": [
        50514,
        407,
        309,
        3665,
        385,
        406,
        281,
        751,
        466,
        441,
        43,
        26386,
        3602,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35293376445770264,
      "compression_ratio": 1.5973451137542725,
      "no_speech_prob": 0.43906262516975403
    },
    {
      "id": 79,
      "seek": 31700,
      "start": 1531.24,
      "end": 1533.24,
      "text": " but about text generators.",
      "tokens": [
        50664,
        457,
        466,
        2487,
        38662,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35293376445770264,
      "compression_ratio": 1.5973451137542725,
      "no_speech_prob": 0.43906262516975403
    },
    {
      "id": 80,
      "seek": 31700,
      "start": 1533.24,
      "end": 1536.24,
      "text": " Because that's actually what they do.",
      "tokens": [
        50764,
        1436,
        300,
        311,
        767,
        437,
        436,
        360,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35293376445770264,
      "compression_ratio": 1.5973451137542725,
      "no_speech_prob": 0.43906262516975403
    },
    {
      "id": 81,
      "seek": 31700,
      "start": 1536.24,
      "end": 1538.24,
      "text": " They generate text somehow.",
      "tokens": [
        50914,
        814,
        8460,
        2487,
        6063,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35293376445770264,
      "compression_ratio": 1.5973451137542725,
      "no_speech_prob": 0.43906262516975403
    },
    {
      "id": 82,
      "seek": 31700,
      "start": 1538.24,
      "end": 1540.24,
      "text": " And these are seductive text generators,",
      "tokens": [
        51014,
        400,
        613,
        366,
        9643,
        11130,
        488,
        2487,
        38662,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35293376445770264,
      "compression_ratio": 1.5973451137542725,
      "no_speech_prob": 0.43906262516975403
    },
    {
      "id": 83,
      "seek": 31700,
      "start": 1540.24,
      "end": 1542.24,
      "text": " because they try to impress users.",
      "tokens": [
        51114,
        570,
        436,
        853,
        281,
        6729,
        5022,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35293376445770264,
      "compression_ratio": 1.5973451137542725,
      "no_speech_prob": 0.43906262516975403
    },
    {
      "id": 84,
      "seek": 31700,
      "start": 1542.24,
      "end": 1544.24,
      "text": " Although it is interesting,",
      "tokens": [
        51214,
        5780,
        309,
        307,
        1880,
        11,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35293376445770264,
      "compression_ratio": 1.5973451137542725,
      "no_speech_prob": 0.43906262516975403
    },
    {
      "id": 85,
      "seek": 31700,
      "start": 1544.24,
      "end": 1547.24,
      "text": " we also discussed this in the episode with Lukas,",
      "tokens": [
        51314,
        321,
        611,
        7152,
        341,
        294,
        264,
        3500,
        365,
        34992,
        296,
        11,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35293376445770264,
      "compression_ratio": 1.5973451137542725,
      "no_speech_prob": 0.43906262516975403
    },
    {
      "id": 86,
      "seek": 31700,
      "start": 1547.24,
      "end": 1551.24,
      "text": " that the bar is actually relatively low.",
      "tokens": [
        51464,
        300,
        264,
        2159,
        307,
        767,
        7226,
        2295,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35293376445770264,
      "compression_ratio": 1.5973451137542725,
      "no_speech_prob": 0.43906262516975403
    },
    {
      "id": 87,
      "seek": 34300,
      "start": 1551.24,
      "end": 1558.24,
      "text": " It is low in the sense that Eliza in the 60s,",
      "tokens": [
        50364,
        467,
        307,
        2295,
        294,
        264,
        2020,
        300,
        11991,
        64,
        294,
        264,
        4060,
        82,
        11,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47549715638160706,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.38819390535354614
    },
    {
      "id": 88,
      "seek": 34300,
      "start": 1558.24,
      "end": 1560.24,
      "text": " what the Weizenbaum built,",
      "tokens": [
        50714,
        437,
        264,
        492,
        23161,
        46641,
        3094,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47549715638160706,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.38819390535354614
    },
    {
      "id": 89,
      "seek": 34300,
      "start": 1560.24,
      "end": 1563.24,
      "text": " and a psychotherapist,",
      "tokens": [
        50814,
        293,
        257,
        4681,
        20194,
        468,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47549715638160706,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.38819390535354614
    },
    {
      "id": 90,
      "seek": 34300,
      "start": 1563.24,
      "end": 1568.24,
      "text": " that already led to the fact that the secretary of the Weizenbaum",
      "tokens": [
        50964,
        300,
        1217,
        4684,
        281,
        264,
        1186,
        300,
        264,
        15691,
        295,
        264,
        492,
        23161,
        46641,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47549715638160706,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.38819390535354614
    },
    {
      "id": 91,
      "seek": 34300,
      "start": 1568.24,
      "end": 1572.24,
      "text": " had dialogues with this thing,",
      "tokens": [
        51214,
        632,
        45551,
        365,
        341,
        551,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47549715638160706,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.38819390535354614
    },
    {
      "id": 92,
      "seek": 34300,
      "start": 1572.24,
      "end": 1575.24,
      "text": " which Weizenbaum himself should no longer read.",
      "tokens": [
        51414,
        597,
        492,
        23161,
        46641,
        3647,
        820,
        572,
        2854,
        1401,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47549715638160706,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.38819390535354614
    },
    {
      "id": 93,
      "seek": 34300,
      "start": 1575.24,
      "end": 1578.24,
      "text": " Which implies that these are real problems,",
      "tokens": [
        51564,
        3013,
        18779,
        300,
        613,
        366,
        957,
        2740,
        11,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47549715638160706,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.38819390535354614
    },
    {
      "id": 94,
      "seek": 34300,
      "start": 1578.24,
      "end": 1580.24,
      "text": " which he somehow discussed.",
      "tokens": [
        51714,
        597,
        415,
        6063,
        7152,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47549715638160706,
      "compression_ratio": 1.600000023841858,
      "no_speech_prob": 0.38819390535354614
    },
    {
      "id": 95,
      "seek": 37200,
      "start": 1580.24,
      "end": 1582.24,
      "text": " Which means that the bar for,",
      "tokens": [
        50364,
        3013,
        1355,
        300,
        264,
        2159,
        337,
        11,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43935438990592957,
      "compression_ratio": 1.4105262756347656,
      "no_speech_prob": 0.31888407468795776
    },
    {
      "id": 96,
      "seek": 37200,
      "start": 1582.24,
      "end": 1584.24,
      "text": " wow, that's very intelligent,",
      "tokens": [
        50464,
        6076,
        11,
        300,
        311,
        588,
        13232,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43935438990592957,
      "compression_ratio": 1.4105262756347656,
      "no_speech_prob": 0.31888407468795776
    },
    {
      "id": 97,
      "seek": 37200,
      "start": 1584.24,
      "end": 1586.24,
      "text": " and I can somehow talk sensibly with it,",
      "tokens": [
        50564,
        293,
        286,
        393,
        6063,
        751,
        2923,
        3545,
        365,
        309,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43935438990592957,
      "compression_ratio": 1.4105262756347656,
      "no_speech_prob": 0.31888407468795776
    },
    {
      "id": 98,
      "seek": 37200,
      "start": 1586.24,
      "end": 1590.24,
      "text": " is impressively low.",
      "tokens": [
        50664,
        307,
        6729,
        3413,
        2295,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43935438990592957,
      "compression_ratio": 1.4105262756347656,
      "no_speech_prob": 0.31888407468795776
    },
    {
      "id": 99,
      "seek": 37200,
      "start": 1591.24,
      "end": 1593.24,
      "text": " Then it is so that we have this topic",
      "tokens": [
        50914,
        1396,
        309,
        307,
        370,
        300,
        321,
        362,
        341,
        4829,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43935438990592957,
      "compression_ratio": 1.4105262756347656,
      "no_speech_prob": 0.31888407468795776
    },
    {
      "id": 100,
      "seek": 37200,
      "start": 1593.24,
      "end": 1595.24,
      "text": " with the software development.",
      "tokens": [
        51014,
        365,
        264,
        4722,
        3250,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43935438990592957,
      "compression_ratio": 1.4105262756347656,
      "no_speech_prob": 0.31888407468795776
    },
    {
      "id": 101,
      "seek": 37200,
      "start": 1598.24,
      "end": 1603.24,
      "text": " Oliver just wrote a famous stochastic parrot.",
      "tokens": [
        51264,
        23440,
        445,
        4114,
        257,
        4618,
        342,
        8997,
        2750,
        971,
        81,
        310,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43935438990592957,
      "compression_ratio": 1.4105262756347656,
      "no_speech_prob": 0.31888407468795776
    },
    {
      "id": 102,
      "seek": 37200,
      "start": 1603.24,
      "end": 1606.24,
      "text": " Eliza is even easier, isn't it?",
      "tokens": [
        51514,
        11991,
        64,
        307,
        754,
        3571,
        11,
        1943,
        380,
        309,
        30,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43935438990592957,
      "compression_ratio": 1.4105262756347656,
      "no_speech_prob": 0.31888407468795776
    },
    {
      "id": 103,
      "seek": 39800,
      "start": 1606.24,
      "end": 1608.24,
      "text": " This is actually in the 80s as, I don't know,",
      "tokens": [
        50364,
        639,
        307,
        767,
        294,
        264,
        4688,
        82,
        382,
        11,
        286,
        500,
        380,
        458,
        11,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4375154972076416,
      "compression_ratio": 1.5615942478179932,
      "no_speech_prob": 0.586540162563324
    },
    {
      "id": 104,
      "seek": 39800,
      "start": 1608.24,
      "end": 1610.24,
      "text": " 100 numbers, basic, somehow tipped off.",
      "tokens": [
        50464,
        2319,
        3547,
        11,
        3875,
        11,
        6063,
        256,
        5529,
        766,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4375154972076416,
      "compression_ratio": 1.5615942478179932,
      "no_speech_prob": 0.586540162563324
    },
    {
      "id": 105,
      "seek": 39800,
      "start": 1610.24,
      "end": 1613.24,
      "text": " And it's actually just rephrasing sentences,",
      "tokens": [
        50564,
        400,
        309,
        311,
        767,
        445,
        319,
        44598,
        3349,
        16579,
        11,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4375154972076416,
      "compression_ratio": 1.5615942478179932,
      "no_speech_prob": 0.586540162563324
    },
    {
      "id": 106,
      "seek": 39800,
      "start": 1613.24,
      "end": 1617.24,
      "text": " and from time to time reacting to keywords.",
      "tokens": [
        50714,
        293,
        490,
        565,
        281,
        565,
        25817,
        281,
        21009,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4375154972076416,
      "compression_ratio": 1.5615942478179932,
      "no_speech_prob": 0.586540162563324
    },
    {
      "id": 107,
      "seek": 39800,
      "start": 1619.24,
      "end": 1620.24,
      "text": " And Christian wrote,",
      "tokens": [
        51014,
        400,
        5778,
        4114,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4375154972076416,
      "compression_ratio": 1.5615942478179932,
      "no_speech_prob": 0.586540162563324
    },
    {
      "id": 108,
      "seek": 39800,
      "start": 1620.24,
      "end": 1622.24,
      "text": " people have incredible problems with fluency,",
      "tokens": [
        51064,
        561,
        362,
        834,
        986,
        964,
        2740,
        365,
        5029,
        3020,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4375154972076416,
      "compression_ratio": 1.5615942478179932,
      "no_speech_prob": 0.586540162563324
    },
    {
      "id": 109,
      "seek": 39800,
      "start": 1622.24,
      "end": 1625.24,
      "text": " i.e. distinguishing linguistic competence from intelligence.",
      "tokens": [
        51164,
        741,
        13,
        68,
        13,
        11365,
        3807,
        43002,
        39965,
        490,
        7599,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4375154972076416,
      "compression_ratio": 1.5615942478179932,
      "no_speech_prob": 0.586540162563324
    },
    {
      "id": 110,
      "seek": 39800,
      "start": 1625.24,
      "end": 1626.24,
      "text": " Exactly.",
      "tokens": [
        51314,
        7587,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4375154972076416,
      "compression_ratio": 1.5615942478179932,
      "no_speech_prob": 0.586540162563324
    },
    {
      "id": 111,
      "seek": 39800,
      "start": 1626.24,
      "end": 1627.24,
      "text": " And by the way,",
      "tokens": [
        51364,
        400,
        538,
        264,
        636,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4375154972076416,
      "compression_ratio": 1.5615942478179932,
      "no_speech_prob": 0.586540162563324
    },
    {
      "id": 112,
      "seek": 39800,
      "start": 1627.24,
      "end": 1629.24,
      "text": " that's maybe something you can learn from it.",
      "tokens": [
        51414,
        300,
        311,
        1310,
        746,
        291,
        393,
        1466,
        490,
        309,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4375154972076416,
      "compression_ratio": 1.5615942478179932,
      "no_speech_prob": 0.586540162563324
    },
    {
      "id": 113,
      "seek": 39800,
      "start": 1629.24,
      "end": 1631.24,
      "text": " If I want to be convincing,",
      "tokens": [
        51514,
        759,
        286,
        528,
        281,
        312,
        24823,
        11,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4375154972076416,
      "compression_ratio": 1.5615942478179932,
      "no_speech_prob": 0.586540162563324
    },
    {
      "id": 114,
      "seek": 39800,
      "start": 1631.24,
      "end": 1634.24,
      "text": " I might have to invest in it.",
      "tokens": [
        51614,
        286,
        1062,
        362,
        281,
        1963,
        294,
        309,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4375154972076416,
      "compression_ratio": 1.5615942478179932,
      "no_speech_prob": 0.586540162563324
    },
    {
      "id": 115,
      "seek": 42600,
      "start": 1635.24,
      "end": 1638.24,
      "text": " But now let's get back to the topic,",
      "tokens": [
        50414,
        583,
        586,
        718,
        311,
        483,
        646,
        281,
        264,
        4829,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39914530515670776,
      "compression_ratio": 1.4587628841400146,
      "no_speech_prob": 0.004248893354088068
    },
    {
      "id": 116,
      "seek": 42600,
      "start": 1638.24,
      "end": 1640.24,
      "text": " what that actually means for us",
      "tokens": [
        50564,
        437,
        300,
        767,
        1355,
        337,
        505,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39914530515670776,
      "compression_ratio": 1.4587628841400146,
      "no_speech_prob": 0.004248893354088068
    },
    {
      "id": 117,
      "seek": 42600,
      "start": 1640.24,
      "end": 1641.24,
      "text": " in software development.",
      "tokens": [
        50664,
        294,
        4722,
        3250,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39914530515670776,
      "compression_ratio": 1.4587628841400146,
      "no_speech_prob": 0.004248893354088068
    },
    {
      "id": 118,
      "seek": 42600,
      "start": 1641.24,
      "end": 1644.24,
      "text": " And what I find interesting about it is,",
      "tokens": [
        50714,
        400,
        437,
        286,
        915,
        1880,
        466,
        309,
        307,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39914530515670776,
      "compression_ratio": 1.4587628841400146,
      "no_speech_prob": 0.004248893354088068
    },
    {
      "id": 119,
      "seek": 42600,
      "start": 1647.24,
      "end": 1649.24,
      "text": " what you can do with it is,",
      "tokens": [
        51014,
        437,
        291,
        393,
        360,
        365,
        309,
        307,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39914530515670776,
      "compression_ratio": 1.4587628841400146,
      "no_speech_prob": 0.004248893354088068
    },
    {
      "id": 120,
      "seek": 42600,
      "start": 1649.24,
      "end": 1652.24,
      "text": " I can generate large amounts of things.",
      "tokens": [
        51114,
        286,
        393,
        8460,
        2416,
        11663,
        295,
        721,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39914530515670776,
      "compression_ratio": 1.4587628841400146,
      "no_speech_prob": 0.004248893354088068
    },
    {
      "id": 121,
      "seek": 42600,
      "start": 1652.24,
      "end": 1655.24,
      "text": " So objectively,",
      "tokens": [
        51264,
        407,
        46067,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39914530515670776,
      "compression_ratio": 1.4587628841400146,
      "no_speech_prob": 0.004248893354088068
    },
    {
      "id": 122,
      "seek": 42600,
      "start": 1657.24,
      "end": 1659.24,
      "text": " where it's not so clear",
      "tokens": [
        51514,
        689,
        309,
        311,
        406,
        370,
        1850,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39914530515670776,
      "compression_ratio": 1.4587628841400146,
      "no_speech_prob": 0.004248893354088068
    },
    {
      "id": 123,
      "seek": 42600,
      "start": 1659.24,
      "end": 1663.24,
      "text": " whether they are of high quality or not.",
      "tokens": [
        51614,
        1968,
        436,
        366,
        295,
        1090,
        3125,
        420,
        406,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39914530515670776,
      "compression_ratio": 1.4587628841400146,
      "no_speech_prob": 0.004248893354088068
    },
    {
      "id": 124,
      "seek": 45600,
      "start": 1664.24,
      "end": 1666.24,
      "text": " And the question I ask myself is,",
      "tokens": [
        50364,
        400,
        264,
        1168,
        286,
        1029,
        2059,
        307,
        11,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31338053941726685,
      "compression_ratio": 1.658767819404602,
      "no_speech_prob": 0.0033389576710760593
    },
    {
      "id": 125,
      "seek": 45600,
      "start": 1666.24,
      "end": 1669.24,
      "text": " is that actually our problem in software development?",
      "tokens": [
        50464,
        307,
        300,
        767,
        527,
        1154,
        294,
        4722,
        3250,
        30,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31338053941726685,
      "compression_ratio": 1.658767819404602,
      "no_speech_prob": 0.0033389576710760593
    },
    {
      "id": 126,
      "seek": 45600,
      "start": 1669.24,
      "end": 1670.24,
      "text": " So I would say,",
      "tokens": [
        50614,
        407,
        286,
        576,
        584,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31338053941726685,
      "compression_ratio": 1.658767819404602,
      "no_speech_prob": 0.0033389576710760593
    },
    {
      "id": 127,
      "seek": 45600,
      "start": 1670.24,
      "end": 1672.24,
      "text": " understandability is actually our problem, right?",
      "tokens": [
        50664,
        16692,
        83,
        474,
        2310,
        307,
        767,
        527,
        1154,
        11,
        558,
        30,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31338053941726685,
      "compression_ratio": 1.658767819404602,
      "no_speech_prob": 0.0033389576710760593
    },
    {
      "id": 128,
      "seek": 45600,
      "start": 1672.24,
      "end": 1677.24,
      "text": " So code that I write is read more often than written.",
      "tokens": [
        50764,
        407,
        3089,
        300,
        286,
        2464,
        307,
        1401,
        544,
        2049,
        813,
        3720,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31338053941726685,
      "compression_ratio": 1.658767819404602,
      "no_speech_prob": 0.0033389576710760593
    },
    {
      "id": 129,
      "seek": 45600,
      "start": 1677.24,
      "end": 1683.24,
      "text": " And that leads to the fact",
      "tokens": [
        51014,
        400,
        300,
        6689,
        281,
        264,
        1186,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31338053941726685,
      "compression_ratio": 1.658767819404602,
      "no_speech_prob": 0.0033389576710760593
    },
    {
      "id": 130,
      "seek": 45600,
      "start": 1683.24,
      "end": 1685.24,
      "text": " that you have to ask yourself",
      "tokens": [
        51314,
        300,
        291,
        362,
        281,
        1029,
        1803,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31338053941726685,
      "compression_ratio": 1.658767819404602,
      "no_speech_prob": 0.0033389576710760593
    },
    {
      "id": 131,
      "seek": 45600,
      "start": 1685.24,
      "end": 1688.24,
      "text": " whether something that generates text,",
      "tokens": [
        51414,
        1968,
        746,
        300,
        23815,
        2487,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31338053941726685,
      "compression_ratio": 1.658767819404602,
      "no_speech_prob": 0.0033389576710760593
    },
    {
      "id": 132,
      "seek": 45600,
      "start": 1688.24,
      "end": 1689.24,
      "text": " a text generator,",
      "tokens": [
        51564,
        257,
        2487,
        19265,
        11,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31338053941726685,
      "compression_ratio": 1.658767819404602,
      "no_speech_prob": 0.0033389576710760593
    },
    {
      "id": 133,
      "seek": 45600,
      "start": 1689.24,
      "end": 1692.24,
      "text": " actually solves the problem.",
      "tokens": [
        51614,
        767,
        39890,
        264,
        1154,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31338053941726685,
      "compression_ratio": 1.658767819404602,
      "no_speech_prob": 0.0033389576710760593
    },
    {
      "id": 134,
      "seek": 48400,
      "start": 1692.24,
      "end": 1697.24,
      "text": " And the other,",
      "tokens": [
        50364,
        400,
        264,
        661,
        11,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3777669370174408,
      "compression_ratio": 1.6829267740249634,
      "no_speech_prob": 0.01598375104367733
    },
    {
      "id": 135,
      "seek": 48400,
      "start": 1697.24,
      "end": 1701.24,
      "text": " and that somehow leads to the next topic.",
      "tokens": [
        50614,
        293,
        300,
        6063,
        6689,
        281,
        264,
        958,
        4829,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3777669370174408,
      "compression_ratio": 1.6829267740249634,
      "no_speech_prob": 0.01598375104367733
    },
    {
      "id": 136,
      "seek": 48400,
      "start": 1701.24,
      "end": 1703.24,
      "text": " So if we say",
      "tokens": [
        50814,
        407,
        498,
        321,
        584,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3777669370174408,
      "compression_ratio": 1.6829267740249634,
      "no_speech_prob": 0.01598375104367733
    },
    {
      "id": 137,
      "seek": 48400,
      "start": 1703.24,
      "end": 1706.24,
      "text": " that the results we have there",
      "tokens": [
        50914,
        300,
        264,
        3542,
        321,
        362,
        456,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3777669370174408,
      "compression_ratio": 1.6829267740249634,
      "no_speech_prob": 0.01598375104367733
    },
    {
      "id": 138,
      "seek": 48400,
      "start": 1706.24,
      "end": 1708.24,
      "text": " may not be true,",
      "tokens": [
        51064,
        815,
        406,
        312,
        2074,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3777669370174408,
      "compression_ratio": 1.6829267740249634,
      "no_speech_prob": 0.01598375104367733
    },
    {
      "id": 139,
      "seek": 48400,
      "start": 1708.24,
      "end": 1711.24,
      "text": " then we actually have to control the results.",
      "tokens": [
        51164,
        550,
        321,
        767,
        362,
        281,
        1969,
        264,
        3542,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3777669370174408,
      "compression_ratio": 1.6829267740249634,
      "no_speech_prob": 0.01598375104367733
    },
    {
      "id": 140,
      "seek": 48400,
      "start": 1711.24,
      "end": 1712.24,
      "text": " So that means,",
      "tokens": [
        51314,
        407,
        300,
        1355,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3777669370174408,
      "compression_ratio": 1.6829267740249634,
      "no_speech_prob": 0.01598375104367733
    },
    {
      "id": 141,
      "seek": 48400,
      "start": 1712.24,
      "end": 1714.24,
      "text": " we have to introduce a control now.",
      "tokens": [
        51364,
        321,
        362,
        281,
        5366,
        257,
        1969,
        586,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3777669370174408,
      "compression_ratio": 1.6829267740249634,
      "no_speech_prob": 0.01598375104367733
    },
    {
      "id": 142,
      "seek": 48400,
      "start": 1714.24,
      "end": 1715.24,
      "text": " That's also something",
      "tokens": [
        51464,
        663,
        311,
        611,
        746,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3777669370174408,
      "compression_ratio": 1.6829267740249634,
      "no_speech_prob": 0.01598375104367733
    },
    {
      "id": 143,
      "seek": 48400,
      "start": 1715.24,
      "end": 1718.24,
      "text": " that we discussed in the episode with Lukas.",
      "tokens": [
        51514,
        300,
        321,
        7152,
        294,
        264,
        3500,
        365,
        34992,
        296,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3777669370174408,
      "compression_ratio": 1.6829267740249634,
      "no_speech_prob": 0.01598375104367733
    },
    {
      "id": 144,
      "seek": 48400,
      "start": 1718.24,
      "end": 1719.24,
      "text": " And that's understandable,",
      "tokens": [
        51664,
        400,
        300,
        311,
        25648,
        11,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3777669370174408,
      "compression_ratio": 1.6829267740249634,
      "no_speech_prob": 0.01598375104367733
    },
    {
      "id": 145,
      "seek": 48400,
      "start": 1719.24,
      "end": 1721.24,
      "text": " because actually an LLM is something",
      "tokens": [
        51714,
        570,
        767,
        364,
        441,
        43,
        44,
        307,
        746,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3777669370174408,
      "compression_ratio": 1.6829267740249634,
      "no_speech_prob": 0.01598375104367733
    },
    {
      "id": 146,
      "seek": 51300,
      "start": 1721.24,
      "end": 1722.24,
      "text": " that says,",
      "tokens": [
        50364,
        300,
        1619,
        11,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34286171197891235,
      "compression_ratio": 1.7611335515975952,
      "no_speech_prob": 0.01858968287706375
    },
    {
      "id": 147,
      "seek": 51300,
      "start": 1722.24,
      "end": 1723.24,
      "text": " I read somewhere on the Internet",
      "tokens": [
        50414,
        286,
        1401,
        4079,
        322,
        264,
        7703,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34286171197891235,
      "compression_ratio": 1.7611335515975952,
      "no_speech_prob": 0.01858968287706375
    },
    {
      "id": 148,
      "seek": 51300,
      "start": 1723.24,
      "end": 1725.24,
      "text": " that this may be the case.",
      "tokens": [
        50464,
        300,
        341,
        815,
        312,
        264,
        1389,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34286171197891235,
      "compression_ratio": 1.7611335515975952,
      "no_speech_prob": 0.01858968287706375
    },
    {
      "id": 149,
      "seek": 51300,
      "start": 1725.24,
      "end": 1727.24,
      "text": " But I can't say exactly where.",
      "tokens": [
        50564,
        583,
        286,
        393,
        380,
        584,
        2293,
        689,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34286171197891235,
      "compression_ratio": 1.7611335515975952,
      "no_speech_prob": 0.01858968287706375
    },
    {
      "id": 150,
      "seek": 51300,
      "start": 1727.24,
      "end": 1730.24,
      "text": " I can't go back to the original source",
      "tokens": [
        50664,
        286,
        393,
        380,
        352,
        646,
        281,
        264,
        3380,
        4009,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34286171197891235,
      "compression_ratio": 1.7611335515975952,
      "no_speech_prob": 0.01858968287706375
    },
    {
      "id": 151,
      "seek": 51300,
      "start": 1730.24,
      "end": 1735.24,
      "text": " from which this model learned things.",
      "tokens": [
        50814,
        490,
        597,
        341,
        2316,
        3264,
        721,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34286171197891235,
      "compression_ratio": 1.7611335515975952,
      "no_speech_prob": 0.01858968287706375
    },
    {
      "id": 152,
      "seek": 51300,
      "start": 1735.24,
      "end": 1737.24,
      "text": " And it's actually a little worse,",
      "tokens": [
        51064,
        400,
        309,
        311,
        767,
        257,
        707,
        5324,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34286171197891235,
      "compression_ratio": 1.7611335515975952,
      "no_speech_prob": 0.01858968287706375
    },
    {
      "id": 153,
      "seek": 51300,
      "start": 1737.24,
      "end": 1738.24,
      "text": " because the model doesn't say,",
      "tokens": [
        51164,
        570,
        264,
        2316,
        1177,
        380,
        584,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34286171197891235,
      "compression_ratio": 1.7611335515975952,
      "no_speech_prob": 0.01858968287706375
    },
    {
      "id": 154,
      "seek": 51300,
      "start": 1738.24,
      "end": 1740.24,
      "text": " I read this somewhere on the Internet.",
      "tokens": [
        51214,
        286,
        1401,
        341,
        4079,
        322,
        264,
        7703,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34286171197891235,
      "compression_ratio": 1.7611335515975952,
      "no_speech_prob": 0.01858968287706375
    },
    {
      "id": 155,
      "seek": 51300,
      "start": 1740.24,
      "end": 1741.24,
      "text": " But it says,",
      "tokens": [
        51314,
        583,
        309,
        1619,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34286171197891235,
      "compression_ratio": 1.7611335515975952,
      "no_speech_prob": 0.01858968287706375
    },
    {
      "id": 156,
      "seek": 51300,
      "start": 1741.24,
      "end": 1743.24,
      "text": " maybe the text just inspired me.",
      "tokens": [
        51364,
        1310,
        264,
        2487,
        445,
        7547,
        385,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34286171197891235,
      "compression_ratio": 1.7611335515975952,
      "no_speech_prob": 0.01858968287706375
    },
    {
      "id": 157,
      "seek": 51300,
      "start": 1743.24,
      "end": 1744.24,
      "text": " I don't know.",
      "tokens": [
        51464,
        286,
        500,
        380,
        458,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34286171197891235,
      "compression_ratio": 1.7611335515975952,
      "no_speech_prob": 0.01858968287706375
    },
    {
      "id": 158,
      "seek": 51300,
      "start": 1744.24,
      "end": 1746.24,
      "text": " And that's not so typical.",
      "tokens": [
        51514,
        400,
        300,
        311,
        406,
        370,
        7476,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34286171197891235,
      "compression_ratio": 1.7611335515975952,
      "no_speech_prob": 0.01858968287706375
    },
    {
      "id": 159,
      "seek": 51300,
      "start": 1746.24,
      "end": 1747.24,
      "text": " If someone says to me now,",
      "tokens": [
        51614,
        759,
        1580,
        1619,
        281,
        385,
        586,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34286171197891235,
      "compression_ratio": 1.7611335515975952,
      "no_speech_prob": 0.01858968287706375
    },
    {
      "id": 160,
      "seek": 51300,
      "start": 1747.24,
      "end": 1750.24,
      "text": " hey, here's the following information.",
      "tokens": [
        51664,
        4177,
        11,
        510,
        311,
        264,
        3480,
        1589,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34286171197891235,
      "compression_ratio": 1.7611335515975952,
      "no_speech_prob": 0.01858968287706375
    },
    {
      "id": 161,
      "seek": 54200,
      "start": 1750.24,
      "end": 1751.24,
      "text": " And I ask,",
      "tokens": [
        50364,
        400,
        286,
        1029,
        11,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38422414660453796,
      "compression_ratio": 1.5362318754196167,
      "no_speech_prob": 0.0274365097284317
    },
    {
      "id": 162,
      "seek": 54200,
      "start": 1751.24,
      "end": 1752.24,
      "text": " where does it come from?",
      "tokens": [
        50414,
        689,
        775,
        309,
        808,
        490,
        30,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38422414660453796,
      "compression_ratio": 1.5362318754196167,
      "no_speech_prob": 0.0274365097284317
    },
    {
      "id": 163,
      "seek": 54200,
      "start": 1752.24,
      "end": 1753.24,
      "text": " Somehow from the Internet.",
      "tokens": [
        50464,
        28357,
        490,
        264,
        7703,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38422414660453796,
      "compression_ratio": 1.5362318754196167,
      "no_speech_prob": 0.0274365097284317
    },
    {
      "id": 164,
      "seek": 54200,
      "start": 1753.24,
      "end": 1755.24,
      "text": " Then it's actually difficult.",
      "tokens": [
        50514,
        1396,
        309,
        311,
        767,
        2252,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38422414660453796,
      "compression_ratio": 1.5362318754196167,
      "no_speech_prob": 0.0274365097284317
    },
    {
      "id": 165,
      "seek": 54200,
      "start": 1755.24,
      "end": 1757.24,
      "text": " And that means,",
      "tokens": [
        50614,
        400,
        300,
        1355,
        11,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38422414660453796,
      "compression_ratio": 1.5362318754196167,
      "no_speech_prob": 0.0274365097284317
    },
    {
      "id": 166,
      "seek": 54200,
      "start": 1757.24,
      "end": 1759.24,
      "text": " I actually have to control it.",
      "tokens": [
        50714,
        286,
        767,
        362,
        281,
        1969,
        309,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38422414660453796,
      "compression_ratio": 1.5362318754196167,
      "no_speech_prob": 0.0274365097284317
    },
    {
      "id": 167,
      "seek": 54200,
      "start": 1759.24,
      "end": 1764.24,
      "text": " And that's how it is now.",
      "tokens": [
        50814,
        400,
        300,
        311,
        577,
        309,
        307,
        586,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38422414660453796,
      "compression_ratio": 1.5362318754196167,
      "no_speech_prob": 0.0274365097284317
    },
    {
      "id": 168,
      "seek": 54200,
      "start": 1764.24,
      "end": 1766.24,
      "text": " Christian wrote,",
      "tokens": [
        51064,
        5778,
        4114,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38422414660453796,
      "compression_ratio": 1.5362318754196167,
      "no_speech_prob": 0.0274365097284317
    },
    {
      "id": 169,
      "seek": 54200,
      "start": 1766.24,
      "end": 1767.24,
      "text": " I don't have a guarantee",
      "tokens": [
        51164,
        286,
        500,
        380,
        362,
        257,
        10815,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38422414660453796,
      "compression_ratio": 1.5362318754196167,
      "no_speech_prob": 0.0274365097284317
    },
    {
      "id": 170,
      "seek": 54200,
      "start": 1767.24,
      "end": 1769.24,
      "text": " that the generated code",
      "tokens": [
        51214,
        300,
        264,
        10833,
        3089,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38422414660453796,
      "compression_ratio": 1.5362318754196167,
      "no_speech_prob": 0.0274365097284317
    },
    {
      "id": 171,
      "seek": 54200,
      "start": 1769.24,
      "end": 1774.24,
      "text": " doesn't hurt the GPL.",
      "tokens": [
        51314,
        1177,
        380,
        4607,
        264,
        26039,
        43,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38422414660453796,
      "compression_ratio": 1.5362318754196167,
      "no_speech_prob": 0.0274365097284317
    },
    {
      "id": 172,
      "seek": 54200,
      "start": 1774.24,
      "end": 1775.24,
      "text": " So no,",
      "tokens": [
        51564,
        407,
        572,
        11,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38422414660453796,
      "compression_ratio": 1.5362318754196167,
      "no_speech_prob": 0.0274365097284317
    },
    {
      "id": 173,
      "seek": 54200,
      "start": 1775.24,
      "end": 1777.24,
      "text": " it starts to get difficult in response,",
      "tokens": [
        51614,
        309,
        3719,
        281,
        483,
        2252,
        294,
        4134,
        11,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38422414660453796,
      "compression_ratio": 1.5362318754196167,
      "no_speech_prob": 0.0274365097284317
    },
    {
      "id": 174,
      "seek": 54200,
      "start": 1777.24,
      "end": 1778.24,
      "text": " because GPL says,",
      "tokens": [
        51714,
        570,
        460,
        21593,
        1619,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38422414660453796,
      "compression_ratio": 1.5362318754196167,
      "no_speech_prob": 0.0274365097284317
    },
    {
      "id": 175,
      "seek": 57000,
      "start": 1778.24,
      "end": 1782.24,
      "text": " derivative work is under GPL.",
      "tokens": [
        50364,
        13760,
        589,
        307,
        833,
        460,
        21593,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3180978000164032,
      "compression_ratio": 1.5663716793060303,
      "no_speech_prob": 0.6374264359474182
    },
    {
      "id": 176,
      "seek": 57000,
      "start": 1782.24,
      "end": 1784.24,
      "text": " And I'm not sure,",
      "tokens": [
        50564,
        400,
        286,
        478,
        406,
        988,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3180978000164032,
      "compression_ratio": 1.5663716793060303,
      "no_speech_prob": 0.6374264359474182
    },
    {
      "id": 177,
      "seek": 57000,
      "start": 1784.24,
      "end": 1786.24,
      "text": " I think that's a story",
      "tokens": [
        50664,
        286,
        519,
        300,
        311,
        257,
        1657,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3180978000164032,
      "compression_ratio": 1.5663716793060303,
      "no_speech_prob": 0.6374264359474182
    },
    {
      "id": 178,
      "seek": 57000,
      "start": 1786.24,
      "end": 1788.24,
      "text": " that lawyers can deal with for a long time,",
      "tokens": [
        50764,
        300,
        16219,
        393,
        2028,
        365,
        337,
        257,
        938,
        565,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3180978000164032,
      "compression_ratio": 1.5663716793060303,
      "no_speech_prob": 0.6374264359474182
    },
    {
      "id": 179,
      "seek": 57000,
      "start": 1788.24,
      "end": 1790.24,
      "text": " what exactly that means",
      "tokens": [
        50864,
        437,
        2293,
        300,
        1355,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3180978000164032,
      "compression_ratio": 1.5663716793060303,
      "no_speech_prob": 0.6374264359474182
    },
    {
      "id": 180,
      "seek": 57000,
      "start": 1790.24,
      "end": 1792.24,
      "text": " when things are derivative work.",
      "tokens": [
        50964,
        562,
        721,
        366,
        13760,
        589,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3180978000164032,
      "compression_ratio": 1.5663716793060303,
      "no_speech_prob": 0.6374264359474182
    },
    {
      "id": 181,
      "seek": 57000,
      "start": 1792.24,
      "end": 1795.24,
      "text": " There are obvious examples,",
      "tokens": [
        51064,
        821,
        366,
        6322,
        5110,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3180978000164032,
      "compression_ratio": 1.5663716793060303,
      "no_speech_prob": 0.6374264359474182
    },
    {
      "id": 182,
      "seek": 57000,
      "start": 1795.24,
      "end": 1797.24,
      "text": " but here we are in an area",
      "tokens": [
        51214,
        457,
        510,
        321,
        366,
        294,
        364,
        1859,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3180978000164032,
      "compression_ratio": 1.5663716793060303,
      "no_speech_prob": 0.6374264359474182
    },
    {
      "id": 183,
      "seek": 57000,
      "start": 1797.24,
      "end": 1799.24,
      "text": " where it gets a little unclear.",
      "tokens": [
        51314,
        689,
        309,
        2170,
        257,
        707,
        25636,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3180978000164032,
      "compression_ratio": 1.5663716793060303,
      "no_speech_prob": 0.6374264359474182
    },
    {
      "id": 184,
      "seek": 57000,
      "start": 1799.24,
      "end": 1801.24,
      "text": " No idea.",
      "tokens": [
        51414,
        883,
        1558,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3180978000164032,
      "compression_ratio": 1.5663716793060303,
      "no_speech_prob": 0.6374264359474182
    },
    {
      "id": 185,
      "seek": 57000,
      "start": 1801.24,
      "end": 1802.24,
      "text": " And I think,",
      "tokens": [
        51514,
        400,
        286,
        519,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3180978000164032,
      "compression_ratio": 1.5663716793060303,
      "no_speech_prob": 0.6374264359474182
    },
    {
      "id": 186,
      "seek": 57000,
      "start": 1802.24,
      "end": 1804.24,
      "text": " if I'm not mistaken,",
      "tokens": [
        51564,
        498,
        286,
        478,
        406,
        21333,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3180978000164032,
      "compression_ratio": 1.5663716793060303,
      "no_speech_prob": 0.6374264359474182
    },
    {
      "id": 187,
      "seek": 57000,
      "start": 1804.24,
      "end": 1805.24,
      "text": " at the moment,",
      "tokens": [
        51664,
        412,
        264,
        1623,
        11,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3180978000164032,
      "compression_ratio": 1.5663716793060303,
      "no_speech_prob": 0.6374264359474182
    },
    {
      "id": 188,
      "seek": 57000,
      "start": 1805.24,
      "end": 1807.24,
      "text": " things that have been generated by AI",
      "tokens": [
        51714,
        721,
        300,
        362,
        668,
        10833,
        538,
        7318,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3180978000164032,
      "compression_ratio": 1.5663716793060303,
      "no_speech_prob": 0.6374264359474182
    },
    {
      "id": 189,
      "seek": 59900,
      "start": 1807.24,
      "end": 1809.24,
      "text": " cannot be subject to copyright.",
      "tokens": [
        50364,
        2644,
        312,
        3983,
        281,
        17996,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.450555682182312,
      "compression_ratio": 1.4835680723190308,
      "no_speech_prob": 0.2248767614364624
    },
    {
      "id": 190,
      "seek": 59900,
      "start": 1809.24,
      "end": 1811.24,
      "text": " But no idea.",
      "tokens": [
        50464,
        583,
        572,
        1558,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.450555682182312,
      "compression_ratio": 1.4835680723190308,
      "no_speech_prob": 0.2248767614364624
    },
    {
      "id": 191,
      "seek": 59900,
      "start": 1811.24,
      "end": 1813.24,
      "text": " It's a legal question.",
      "tokens": [
        50564,
        467,
        311,
        257,
        5089,
        1168,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.450555682182312,
      "compression_ratio": 1.4835680723190308,
      "no_speech_prob": 0.2248767614364624
    },
    {
      "id": 192,
      "seek": 59900,
      "start": 1813.24,
      "end": 1815.24,
      "text": " We have experimented with LLMs",
      "tokens": [
        50664,
        492,
        362,
        5120,
        292,
        365,
        441,
        43,
        26386,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.450555682182312,
      "compression_ratio": 1.4835680723190308,
      "no_speech_prob": 0.2248767614364624
    },
    {
      "id": 193,
      "seek": 59900,
      "start": 1815.24,
      "end": 1821.24,
      "text": " in the stream in various places.",
      "tokens": [
        50764,
        294,
        264,
        4309,
        294,
        3683,
        3190,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.450555682182312,
      "compression_ratio": 1.4835680723190308,
      "no_speech_prob": 0.2248767614364624
    },
    {
      "id": 194,
      "seek": 59900,
      "start": 1821.24,
      "end": 1823.24,
      "text": " Ralf has also done that.",
      "tokens": [
        51064,
        497,
        1678,
        575,
        611,
        1096,
        300,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.450555682182312,
      "compression_ratio": 1.4835680723190308,
      "no_speech_prob": 0.2248767614364624
    },
    {
      "id": 195,
      "seek": 59900,
      "start": 1823.24,
      "end": 1825.24,
      "text": " And the first thing we did back then",
      "tokens": [
        51164,
        400,
        264,
        700,
        551,
        321,
        630,
        646,
        550,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.450555682182312,
      "compression_ratio": 1.4835680723190308,
      "no_speech_prob": 0.2248767614364624
    },
    {
      "id": 196,
      "seek": 59900,
      "start": 1825.24,
      "end": 1828.24,
      "text": " was that we said to an LLM,",
      "tokens": [
        51264,
        390,
        300,
        321,
        848,
        281,
        364,
        441,
        43,
        44,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.450555682182312,
      "compression_ratio": 1.4835680723190308,
      "no_speech_prob": 0.2248767614364624
    },
    {
      "id": 197,
      "seek": 59900,
      "start": 1828.24,
      "end": 1830.24,
      "text": " I'm going to copy the example task",
      "tokens": [
        51414,
        286,
        478,
        516,
        281,
        5055,
        264,
        1365,
        5633,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.450555682182312,
      "compression_ratio": 1.4835680723190308,
      "no_speech_prob": 0.2248767614364624
    },
    {
      "id": 198,
      "seek": 59900,
      "start": 1830.24,
      "end": 1831.24,
      "text": " and solve it.",
      "tokens": [
        51514,
        293,
        5039,
        309,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.450555682182312,
      "compression_ratio": 1.4835680723190308,
      "no_speech_prob": 0.2248767614364624
    },
    {
      "id": 199,
      "seek": 59900,
      "start": 1831.24,
      "end": 1833.24,
      "text": " And what I remember very well",
      "tokens": [
        51564,
        400,
        437,
        286,
        1604,
        588,
        731,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.450555682182312,
      "compression_ratio": 1.4835680723190308,
      "no_speech_prob": 0.2248767614364624
    },
    {
      "id": 200,
      "seek": 59900,
      "start": 1833.24,
      "end": 1835.24,
      "text": " is that we then",
      "tokens": [
        51664,
        307,
        300,
        321,
        550,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.450555682182312,
      "compression_ratio": 1.4835680723190308,
      "no_speech_prob": 0.2248767614364624
    },
    {
      "id": 201,
      "seek": 62700,
      "start": 1835.24,
      "end": 1836.24,
      "text": " noticed at some point",
      "tokens": [
        50364,
        5694,
        412,
        512,
        935,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38755524158477783,
      "compression_ratio": 1.6459144353866577,
      "no_speech_prob": 0.19014602899551392
    },
    {
      "id": 202,
      "seek": 62700,
      "start": 1836.24,
      "end": 1838.24,
      "text": " that it just produces nonsense,",
      "tokens": [
        50414,
        300,
        309,
        445,
        14725,
        14925,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38755524158477783,
      "compression_ratio": 1.6459144353866577,
      "no_speech_prob": 0.19014602899551392
    },
    {
      "id": 203,
      "seek": 62700,
      "start": 1838.24,
      "end": 1840.24,
      "text": " that has nothing to do with",
      "tokens": [
        50514,
        300,
        575,
        1825,
        281,
        360,
        365,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38755524158477783,
      "compression_ratio": 1.6459144353866577,
      "no_speech_prob": 0.19014602899551392
    },
    {
      "id": 204,
      "seek": 62700,
      "start": 1840.24,
      "end": 1842.24,
      "text": " requirements or other things.",
      "tokens": [
        50614,
        7728,
        420,
        661,
        721,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38755524158477783,
      "compression_ratio": 1.6459144353866577,
      "no_speech_prob": 0.19014602899551392
    },
    {
      "id": 205,
      "seek": 62700,
      "start": 1842.24,
      "end": 1846.24,
      "text": " And that was somehow",
      "tokens": [
        50714,
        400,
        300,
        390,
        6063,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38755524158477783,
      "compression_ratio": 1.6459144353866577,
      "no_speech_prob": 0.19014602899551392
    },
    {
      "id": 206,
      "seek": 62700,
      "start": 1846.24,
      "end": 1847.24,
      "text": " justified by the fact",
      "tokens": [
        50914,
        27808,
        538,
        264,
        1186,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38755524158477783,
      "compression_ratio": 1.6459144353866577,
      "no_speech_prob": 0.19014602899551392
    },
    {
      "id": 207,
      "seek": 62700,
      "start": 1847.24,
      "end": 1849.24,
      "text": " that the token storage,",
      "tokens": [
        50964,
        300,
        264,
        14862,
        6725,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38755524158477783,
      "compression_ratio": 1.6459144353866577,
      "no_speech_prob": 0.19014602899551392
    },
    {
      "id": 208,
      "seek": 62700,
      "start": 1849.24,
      "end": 1850.24,
      "text": " so to speak,",
      "tokens": [
        51064,
        370,
        281,
        1710,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38755524158477783,
      "compression_ratio": 1.6459144353866577,
      "no_speech_prob": 0.19014602899551392
    },
    {
      "id": 209,
      "seek": 62700,
      "start": 1850.24,
      "end": 1852.24,
      "text": " the field of view of how much",
      "tokens": [
        51114,
        264,
        2519,
        295,
        1910,
        295,
        577,
        709,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38755524158477783,
      "compression_ratio": 1.6459144353866577,
      "no_speech_prob": 0.19014602899551392
    },
    {
      "id": 210,
      "seek": 62700,
      "start": 1852.24,
      "end": 1854.24,
      "text": " the system is still looking at,",
      "tokens": [
        51214,
        264,
        1185,
        307,
        920,
        1237,
        412,
        11,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38755524158477783,
      "compression_ratio": 1.6459144353866577,
      "no_speech_prob": 0.19014602899551392
    },
    {
      "id": 211,
      "seek": 62700,
      "start": 1854.24,
      "end": 1856.24,
      "text": " the task had now also fallen out.",
      "tokens": [
        51314,
        264,
        5633,
        632,
        586,
        611,
        11547,
        484,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38755524158477783,
      "compression_ratio": 1.6459144353866577,
      "no_speech_prob": 0.19014602899551392
    },
    {
      "id": 212,
      "seek": 62700,
      "start": 1856.24,
      "end": 1858.24,
      "text": " So the source on which",
      "tokens": [
        51414,
        407,
        264,
        4009,
        322,
        597,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38755524158477783,
      "compression_ratio": 1.6459144353866577,
      "no_speech_prob": 0.19014602899551392
    },
    {
      "id": 213,
      "seek": 62700,
      "start": 1858.24,
      "end": 1860.24,
      "text": " the architecture should actually be developed,",
      "tokens": [
        51514,
        264,
        9482,
        820,
        767,
        312,
        4743,
        11,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38755524158477783,
      "compression_ratio": 1.6459144353866577,
      "no_speech_prob": 0.19014602899551392
    },
    {
      "id": 214,
      "seek": 62700,
      "start": 1860.24,
      "end": 1862.24,
      "text": " the LLM did not continue to look at.",
      "tokens": [
        51614,
        264,
        441,
        43,
        44,
        630,
        406,
        2354,
        281,
        574,
        412,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38755524158477783,
      "compression_ratio": 1.6459144353866577,
      "no_speech_prob": 0.19014602899551392
    },
    {
      "id": 215,
      "seek": 62700,
      "start": 1862.24,
      "end": 1864.24,
      "text": " And a little more blatantly,",
      "tokens": [
        51714,
        400,
        257,
        707,
        544,
        42780,
        3627,
        11,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38755524158477783,
      "compression_ratio": 1.6459144353866577,
      "no_speech_prob": 0.19014602899551392
    },
    {
      "id": 216,
      "seek": 65600,
      "start": 1864.24,
      "end": 1867.24,
      "text": " we did this episode some time ago,",
      "tokens": [
        50364,
        321,
        630,
        341,
        3500,
        512,
        565,
        2057,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46317487955093384,
      "compression_ratio": 1.480263113975525,
      "no_speech_prob": 0.3866483271121979
    },
    {
      "id": 217,
      "seek": 65600,
      "start": 1867.24,
      "end": 1871.24,
      "text": " where Ralf talked about his Linter.",
      "tokens": [
        50514,
        689,
        497,
        1678,
        2825,
        466,
        702,
        441,
        5106,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46317487955093384,
      "compression_ratio": 1.480263113975525,
      "no_speech_prob": 0.3866483271121979
    },
    {
      "id": 218,
      "seek": 65600,
      "start": 1871.24,
      "end": 1873.24,
      "text": " And I had somehow",
      "tokens": [
        50714,
        400,
        286,
        632,
        6063,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46317487955093384,
      "compression_ratio": 1.480263113975525,
      "no_speech_prob": 0.3866483271121979
    },
    {
      "id": 219,
      "seek": 65600,
      "start": 1873.24,
      "end": 1884.24,
      "text": " drilled into the quality scenarios.",
      "tokens": [
        50814,
        38210,
        666,
        264,
        3125,
        15077,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46317487955093384,
      "compression_ratio": 1.480263113975525,
      "no_speech_prob": 0.3866483271121979
    },
    {
      "id": 220,
      "seek": 65600,
      "start": 1884.24,
      "end": 1886.24,
      "text": " And there was somehow",
      "tokens": [
        51364,
        400,
        456,
        390,
        6063,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46317487955093384,
      "compression_ratio": 1.480263113975525,
      "no_speech_prob": 0.3866483271121979
    },
    {
      "id": 221,
      "seek": 65600,
      "start": 1886.24,
      "end": 1887.24,
      "text": " something like,",
      "tokens": [
        51464,
        746,
        411,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46317487955093384,
      "compression_ratio": 1.480263113975525,
      "no_speech_prob": 0.3866483271121979
    },
    {
      "id": 222,
      "seek": 65600,
      "start": 1887.24,
      "end": 1890.24,
      "text": " hey, a Linter is a thing",
      "tokens": [
        51514,
        4177,
        11,
        257,
        441,
        5106,
        307,
        257,
        551,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46317487955093384,
      "compression_ratio": 1.480263113975525,
      "no_speech_prob": 0.3866483271121979
    },
    {
      "id": 223,
      "seek": 65600,
      "start": 1890.24,
      "end": 1893.24,
      "text": " that somehow a text on correct syntax",
      "tokens": [
        51664,
        300,
        6063,
        257,
        2487,
        322,
        3006,
        28431,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46317487955093384,
      "compression_ratio": 1.480263113975525,
      "no_speech_prob": 0.3866483271121979
    },
    {
      "id": 224,
      "seek": 68500,
      "start": 1893.24,
      "end": 1896.24,
      "text": " and examines some difficulties.",
      "tokens": [
        50364,
        293,
        1139,
        1652,
        512,
        14399,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3784830868244171,
      "compression_ratio": 1.6846153736114502,
      "no_speech_prob": 0.05010489746928215
    },
    {
      "id": 225,
      "seek": 68500,
      "start": 1896.24,
      "end": 1897.24,
      "text": " And that was somehow",
      "tokens": [
        50514,
        400,
        300,
        390,
        6063,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3784830868244171,
      "compression_ratio": 1.6846153736114502,
      "no_speech_prob": 0.05010489746928215
    },
    {
      "id": 226,
      "seek": 68500,
      "start": 1897.24,
      "end": 1898.24,
      "text": " a Foresky doc.",
      "tokens": [
        50564,
        257,
        479,
        2706,
        4133,
        3211,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3784830868244171,
      "compression_ratio": 1.6846153736114502,
      "no_speech_prob": 0.05010489746928215
    },
    {
      "id": 227,
      "seek": 68500,
      "start": 1898.24,
      "end": 1899.24,
      "text": " And there was now",
      "tokens": [
        50614,
        400,
        456,
        390,
        586,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3784830868244171,
      "compression_ratio": 1.6846153736114502,
      "no_speech_prob": 0.05010489746928215
    },
    {
      "id": 228,
      "seek": 68500,
      "start": 1899.24,
      "end": 1901.24,
      "text": " some performance requirement in it.",
      "tokens": [
        50664,
        512,
        3389,
        11695,
        294,
        309,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3784830868244171,
      "compression_ratio": 1.6846153736114502,
      "no_speech_prob": 0.05010489746928215
    },
    {
      "id": 229,
      "seek": 68500,
      "start": 1901.24,
      "end": 1902.24,
      "text": " I don't know,",
      "tokens": [
        50764,
        286,
        500,
        380,
        458,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3784830868244171,
      "compression_ratio": 1.6846153736114502,
      "no_speech_prob": 0.05010489746928215
    },
    {
      "id": 230,
      "seek": 68500,
      "start": 1902.24,
      "end": 1903.24,
      "text": " 100 files in 10 seconds",
      "tokens": [
        50814,
        2319,
        7098,
        294,
        1266,
        3949,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3784830868244171,
      "compression_ratio": 1.6846153736114502,
      "no_speech_prob": 0.05010489746928215
    },
    {
      "id": 231,
      "seek": 68500,
      "start": 1903.24,
      "end": 1905.24,
      "text": " or whatever.",
      "tokens": [
        50864,
        420,
        2035,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3784830868244171,
      "compression_ratio": 1.6846153736114502,
      "no_speech_prob": 0.05010489746928215
    },
    {
      "id": 232,
      "seek": 68500,
      "start": 1905.24,
      "end": 1906.24,
      "text": " I just looked at it somehow",
      "tokens": [
        50964,
        286,
        445,
        2956,
        412,
        309,
        6063,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3784830868244171,
      "compression_ratio": 1.6846153736114502,
      "no_speech_prob": 0.05010489746928215
    },
    {
      "id": 233,
      "seek": 68500,
      "start": 1906.24,
      "end": 1908.24,
      "text": " and asked myself,",
      "tokens": [
        51014,
        293,
        2351,
        2059,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3784830868244171,
      "compression_ratio": 1.6846153736114502,
      "no_speech_prob": 0.05010489746928215
    },
    {
      "id": 234,
      "seek": 68500,
      "start": 1908.24,
      "end": 1910.24,
      "text": " where does that come from?",
      "tokens": [
        51114,
        689,
        775,
        300,
        808,
        490,
        30,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3784830868244171,
      "compression_ratio": 1.6846153736114502,
      "no_speech_prob": 0.05010489746928215
    },
    {
      "id": 235,
      "seek": 68500,
      "start": 1910.24,
      "end": 1911.24,
      "text": " When you say",
      "tokens": [
        51214,
        1133,
        291,
        584,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3784830868244171,
      "compression_ratio": 1.6846153736114502,
      "no_speech_prob": 0.05010489746928215
    },
    {
      "id": 236,
      "seek": 68500,
      "start": 1911.24,
      "end": 1912.24,
      "text": " that it's a text generator,",
      "tokens": [
        51264,
        300,
        309,
        311,
        257,
        2487,
        19265,
        11,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3784830868244171,
      "compression_ratio": 1.6846153736114502,
      "no_speech_prob": 0.05010489746928215
    },
    {
      "id": 237,
      "seek": 68500,
      "start": 1912.24,
      "end": 1914.24,
      "text": " it's clear that it's just a requirement",
      "tokens": [
        51314,
        309,
        311,
        1850,
        300,
        309,
        311,
        445,
        257,
        11695,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3784830868244171,
      "compression_ratio": 1.6846153736114502,
      "no_speech_prob": 0.05010489746928215
    },
    {
      "id": 238,
      "seek": 68500,
      "start": 1914.24,
      "end": 1916.24,
      "text": " as you might actually find it.",
      "tokens": [
        51414,
        382,
        291,
        1062,
        767,
        915,
        309,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3784830868244171,
      "compression_ratio": 1.6846153736114502,
      "no_speech_prob": 0.05010489746928215
    },
    {
      "id": 239,
      "seek": 68500,
      "start": 1916.24,
      "end": 1918.24,
      "text": " And it's just bullshit",
      "tokens": [
        51514,
        400,
        309,
        311,
        445,
        22676,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3784830868244171,
      "compression_ratio": 1.6846153736114502,
      "no_speech_prob": 0.05010489746928215
    },
    {
      "id": 240,
      "seek": 68500,
      "start": 1918.24,
      "end": 1920.24,
      "text": " in the sense that it doesn't",
      "tokens": [
        51614,
        294,
        264,
        2020,
        300,
        309,
        1177,
        380,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3784830868244171,
      "compression_ratio": 1.6846153736114502,
      "no_speech_prob": 0.05010489746928215
    },
    {
      "id": 241,
      "seek": 68500,
      "start": 1920.24,
      "end": 1922.24,
      "text": " represent a real requirement",
      "tokens": [
        51714,
        2906,
        257,
        957,
        11695,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3784830868244171,
      "compression_ratio": 1.6846153736114502,
      "no_speech_prob": 0.05010489746928215
    },
    {
      "id": 242,
      "seek": 71400,
      "start": 1922.24,
      "end": 1923.24,
      "text": " or anything like that.",
      "tokens": [
        50364,
        420,
        1340,
        411,
        300,
        13,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31640762090682983,
      "compression_ratio": 1.6111111640930176,
      "no_speech_prob": 0.11078719794750214
    },
    {
      "id": 243,
      "seek": 71400,
      "start": 1923.24,
      "end": 1924.24,
      "text": " It's just something",
      "tokens": [
        50414,
        467,
        311,
        445,
        746,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31640762090682983,
      "compression_ratio": 1.6111111640930176,
      "no_speech_prob": 0.11078719794750214
    },
    {
      "id": 244,
      "seek": 71400,
      "start": 1924.24,
      "end": 1926.24,
      "text": " that sounds convincing.",
      "tokens": [
        50464,
        300,
        3263,
        24823,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31640762090682983,
      "compression_ratio": 1.6111111640930176,
      "no_speech_prob": 0.11078719794750214
    },
    {
      "id": 245,
      "seek": 71400,
      "start": 1926.24,
      "end": 1928.24,
      "text": " And at the latest at this point,",
      "tokens": [
        50564,
        400,
        412,
        264,
        6792,
        412,
        341,
        935,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31640762090682983,
      "compression_ratio": 1.6111111640930176,
      "no_speech_prob": 0.11078719794750214
    },
    {
      "id": 246,
      "seek": 71400,
      "start": 1928.24,
      "end": 1929.24,
      "text": " I think we have",
      "tokens": [
        50664,
        286,
        519,
        321,
        362,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31640762090682983,
      "compression_ratio": 1.6111111640930176,
      "no_speech_prob": 0.11078719794750214
    },
    {
      "id": 247,
      "seek": 71400,
      "start": 1929.24,
      "end": 1931.24,
      "text": " another problem.",
      "tokens": [
        50714,
        1071,
        1154,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31640762090682983,
      "compression_ratio": 1.6111111640930176,
      "no_speech_prob": 0.11078719794750214
    },
    {
      "id": 248,
      "seek": 71400,
      "start": 1931.24,
      "end": 1936.24,
      "text": " I would actually have to check that now.",
      "tokens": [
        50814,
        286,
        576,
        767,
        362,
        281,
        1520,
        300,
        586,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31640762090682983,
      "compression_ratio": 1.6111111640930176,
      "no_speech_prob": 0.11078719794750214
    },
    {
      "id": 249,
      "seek": 71400,
      "start": 1936.24,
      "end": 1939.24,
      "text": " But actually,",
      "tokens": [
        51064,
        583,
        767,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31640762090682983,
      "compression_ratio": 1.6111111640930176,
      "no_speech_prob": 0.11078719794750214
    },
    {
      "id": 250,
      "seek": 71400,
      "start": 1939.24,
      "end": 1941.24,
      "text": " when I start",
      "tokens": [
        51214,
        562,
        286,
        722,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31640762090682983,
      "compression_ratio": 1.6111111640930176,
      "no_speech_prob": 0.11078719794750214
    },
    {
      "id": 251,
      "seek": 71400,
      "start": 1941.24,
      "end": 1943.24,
      "text": " to think about architecture,",
      "tokens": [
        51314,
        281,
        519,
        466,
        9482,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31640762090682983,
      "compression_ratio": 1.6111111640930176,
      "no_speech_prob": 0.11078719794750214
    },
    {
      "id": 252,
      "seek": 71400,
      "start": 1943.24,
      "end": 1946.24,
      "text": " the much more interesting question is,",
      "tokens": [
        51414,
        264,
        709,
        544,
        1880,
        1168,
        307,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31640762090682983,
      "compression_ratio": 1.6111111640930176,
      "no_speech_prob": 0.11078719794750214
    },
    {
      "id": 253,
      "seek": 71400,
      "start": 1946.24,
      "end": 1948.24,
      "text": " which quality scenarios do I actually have?",
      "tokens": [
        51564,
        597,
        3125,
        15077,
        360,
        286,
        767,
        362,
        30,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31640762090682983,
      "compression_ratio": 1.6111111640930176,
      "no_speech_prob": 0.11078719794750214
    },
    {
      "id": 254,
      "seek": 71400,
      "start": 1948.24,
      "end": 1949.24,
      "text": " If the answer is,",
      "tokens": [
        51664,
        759,
        264,
        1867,
        307,
        11,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31640762090682983,
      "compression_ratio": 1.6111111640930176,
      "no_speech_prob": 0.11078719794750214
    },
    {
      "id": 255,
      "seek": 71400,
      "start": 1949.24,
      "end": 1950.24,
      "text": " I don't have any,",
      "tokens": [
        51714,
        286,
        500,
        380,
        362,
        604,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31640762090682983,
      "compression_ratio": 1.6111111640930176,
      "no_speech_prob": 0.11078719794750214
    },
    {
      "id": 256,
      "seek": 74200,
      "start": 1950.24,
      "end": 1951.24,
      "text": " then that means",
      "tokens": [
        50364,
        550,
        300,
        1355,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33111703395843506,
      "compression_ratio": 1.6238532066345215,
      "no_speech_prob": 0.05596932768821716
    },
    {
      "id": 257,
      "seek": 74200,
      "start": 1951.24,
      "end": 1952.24,
      "text": " that I have a gap",
      "tokens": [
        50414,
        300,
        286,
        362,
        257,
        7417,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33111703395843506,
      "compression_ratio": 1.6238532066345215,
      "no_speech_prob": 0.05596932768821716
    },
    {
      "id": 258,
      "seek": 74200,
      "start": 1952.24,
      "end": 1954.24,
      "text": " and have to work on it.",
      "tokens": [
        50464,
        293,
        362,
        281,
        589,
        322,
        309,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33111703395843506,
      "compression_ratio": 1.6238532066345215,
      "no_speech_prob": 0.05596932768821716
    },
    {
      "id": 259,
      "seek": 74200,
      "start": 1954.24,
      "end": 1956.24,
      "text": " I can't get into this situation at all.",
      "tokens": [
        50564,
        286,
        393,
        380,
        483,
        666,
        341,
        2590,
        412,
        439,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33111703395843506,
      "compression_ratio": 1.6238532066345215,
      "no_speech_prob": 0.05596932768821716
    },
    {
      "id": 260,
      "seek": 74200,
      "start": 1956.24,
      "end": 1957.24,
      "text": " There's just one thing",
      "tokens": [
        50664,
        821,
        311,
        445,
        472,
        551,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33111703395843506,
      "compression_ratio": 1.6238532066345215,
      "no_speech_prob": 0.05596932768821716
    },
    {
      "id": 261,
      "seek": 74200,
      "start": 1957.24,
      "end": 1959.24,
      "text": " that generates text.",
      "tokens": [
        50714,
        300,
        23815,
        2487,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33111703395843506,
      "compression_ratio": 1.6238532066345215,
      "no_speech_prob": 0.05596932768821716
    },
    {
      "id": 262,
      "seek": 74200,
      "start": 1959.24,
      "end": 1964.24,
      "text": " The text sounds convincing somehow.",
      "tokens": [
        50814,
        440,
        2487,
        3263,
        24823,
        6063,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33111703395843506,
      "compression_ratio": 1.6238532066345215,
      "no_speech_prob": 0.05596932768821716
    },
    {
      "id": 263,
      "seek": 74200,
      "start": 1964.24,
      "end": 1966.24,
      "text": " It's just bullshit",
      "tokens": [
        51064,
        467,
        311,
        445,
        22676,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33111703395843506,
      "compression_ratio": 1.6238532066345215,
      "no_speech_prob": 0.05596932768821716
    },
    {
      "id": 264,
      "seek": 74200,
      "start": 1966.24,
      "end": 1967.24,
      "text": " in the sense that",
      "tokens": [
        51164,
        294,
        264,
        2020,
        300,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33111703395843506,
      "compression_ratio": 1.6238532066345215,
      "no_speech_prob": 0.05596932768821716
    },
    {
      "id": 265,
      "seek": 74200,
      "start": 1967.24,
      "end": 1969.24,
      "text": " there's no truth in it.",
      "tokens": [
        51214,
        456,
        311,
        572,
        3494,
        294,
        309,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33111703395843506,
      "compression_ratio": 1.6238532066345215,
      "no_speech_prob": 0.05596932768821716
    },
    {
      "id": 266,
      "seek": 74200,
      "start": 1969.24,
      "end": 1970.24,
      "text": " Which means",
      "tokens": [
        51314,
        3013,
        1355,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33111703395843506,
      "compression_ratio": 1.6238532066345215,
      "no_speech_prob": 0.05596932768821716
    },
    {
      "id": 267,
      "seek": 74200,
      "start": 1970.24,
      "end": 1972.24,
      "text": " that this story",
      "tokens": [
        51364,
        300,
        341,
        1657,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33111703395843506,
      "compression_ratio": 1.6238532066345215,
      "no_speech_prob": 0.05596932768821716
    },
    {
      "id": 268,
      "seek": 74200,
      "start": 1972.24,
      "end": 1973.24,
      "text": " with, okay,",
      "tokens": [
        51464,
        365,
        11,
        1392,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33111703395843506,
      "compression_ratio": 1.6238532066345215,
      "no_speech_prob": 0.05596932768821716
    },
    {
      "id": 269,
      "seek": 74200,
      "start": 1973.24,
      "end": 1974.24,
      "text": " what are actually",
      "tokens": [
        51514,
        437,
        366,
        767,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33111703395843506,
      "compression_ratio": 1.6238532066345215,
      "no_speech_prob": 0.05596932768821716
    },
    {
      "id": 270,
      "seek": 74200,
      "start": 1974.24,
      "end": 1976.24,
      "text": " my quality scenarios?",
      "tokens": [
        51564,
        452,
        3125,
        15077,
        30,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33111703395843506,
      "compression_ratio": 1.6238532066345215,
      "no_speech_prob": 0.05596932768821716
    },
    {
      "id": 271,
      "seek": 74200,
      "start": 1976.24,
      "end": 1978.24,
      "text": " What do I actually have to fulfill?",
      "tokens": [
        51664,
        708,
        360,
        286,
        767,
        362,
        281,
        13875,
        30,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33111703395843506,
      "compression_ratio": 1.6238532066345215,
      "no_speech_prob": 0.05596932768821716
    },
    {
      "id": 272,
      "seek": 77000,
      "start": 1978.24,
      "end": 1981.24,
      "text": " That just doesn't happen now.",
      "tokens": [
        50364,
        663,
        445,
        1177,
        380,
        1051,
        586,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40681833028793335,
      "compression_ratio": 1.5469387769699097,
      "no_speech_prob": 0.1454315185546875
    },
    {
      "id": 273,
      "seek": 77000,
      "start": 1981.24,
      "end": 1982.24,
      "text": " And actually,",
      "tokens": [
        50514,
        400,
        767,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40681833028793335,
      "compression_ratio": 1.5469387769699097,
      "no_speech_prob": 0.1454315185546875
    },
    {
      "id": 274,
      "seek": 77000,
      "start": 1982.24,
      "end": 1984.24,
      "text": " I think it's interesting",
      "tokens": [
        50564,
        286,
        519,
        309,
        311,
        1880,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40681833028793335,
      "compression_ratio": 1.5469387769699097,
      "no_speech_prob": 0.1454315185546875
    },
    {
      "id": 275,
      "seek": 77000,
      "start": 1984.24,
      "end": 1985.24,
      "text": " to ask the question",
      "tokens": [
        50664,
        281,
        1029,
        264,
        1168,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40681833028793335,
      "compression_ratio": 1.5469387769699097,
      "no_speech_prob": 0.1454315185546875
    },
    {
      "id": 276,
      "seek": 77000,
      "start": 1985.24,
      "end": 1986.24,
      "text": " of someone like Linter,",
      "tokens": [
        50714,
        295,
        1580,
        411,
        441,
        5106,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40681833028793335,
      "compression_ratio": 1.5469387769699097,
      "no_speech_prob": 0.1454315185546875
    },
    {
      "id": 277,
      "seek": 77000,
      "start": 1986.24,
      "end": 1987.24,
      "text": " who is now supposed to check",
      "tokens": [
        50764,
        567,
        307,
        586,
        3442,
        281,
        1520,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40681833028793335,
      "compression_ratio": 1.5469387769699097,
      "no_speech_prob": 0.1454315185546875
    },
    {
      "id": 278,
      "seek": 77000,
      "start": 1987.24,
      "end": 1990.24,
      "text": " the syntax of something",
      "tokens": [
        50814,
        264,
        28431,
        295,
        746,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40681833028793335,
      "compression_ratio": 1.5469387769699097,
      "no_speech_prob": 0.1454315185546875
    },
    {
      "id": 279,
      "seek": 77000,
      "start": 1990.24,
      "end": 1992.24,
      "text": " or maybe not.",
      "tokens": [
        50964,
        420,
        1310,
        406,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40681833028793335,
      "compression_ratio": 1.5469387769699097,
      "no_speech_prob": 0.1454315185546875
    },
    {
      "id": 280,
      "seek": 77000,
      "start": 1992.24,
      "end": 1994.24,
      "text": " He's supposed to pick up",
      "tokens": [
        51064,
        634,
        311,
        3442,
        281,
        1888,
        493,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40681833028793335,
      "compression_ratio": 1.5469387769699097,
      "no_speech_prob": 0.1454315185546875
    },
    {
      "id": 281,
      "seek": 77000,
      "start": 1994.24,
      "end": 1996.24,
      "text": " typical errors or problems.",
      "tokens": [
        51164,
        7476,
        13603,
        420,
        2740,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40681833028793335,
      "compression_ratio": 1.5469387769699097,
      "no_speech_prob": 0.1454315185546875
    },
    {
      "id": 282,
      "seek": 77000,
      "start": 1996.24,
      "end": 1998.24,
      "text": " What are the quality requirements?",
      "tokens": [
        51264,
        708,
        366,
        264,
        3125,
        7728,
        30,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40681833028793335,
      "compression_ratio": 1.5469387769699097,
      "no_speech_prob": 0.1454315185546875
    },
    {
      "id": 283,
      "seek": 77000,
      "start": 1998.24,
      "end": 2000.24,
      "text": " So maybe performance,",
      "tokens": [
        51364,
        407,
        1310,
        3389,
        11,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40681833028793335,
      "compression_ratio": 1.5469387769699097,
      "no_speech_prob": 0.1454315185546875
    },
    {
      "id": 284,
      "seek": 77000,
      "start": 2000.24,
      "end": 2003.24,
      "text": " but certainly not that much, right?",
      "tokens": [
        51464,
        457,
        3297,
        406,
        300,
        709,
        11,
        558,
        30,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40681833028793335,
      "compression_ratio": 1.5469387769699097,
      "no_speech_prob": 0.1454315185546875
    },
    {
      "id": 285,
      "seek": 77000,
      "start": 2003.24,
      "end": 2004.24,
      "text": " So I'm going to",
      "tokens": [
        51614,
        407,
        286,
        478,
        516,
        281,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40681833028793335,
      "compression_ratio": 1.5469387769699097,
      "no_speech_prob": 0.1454315185546875
    },
    {
      "id": 286,
      "seek": 77000,
      "start": 2004.24,
      "end": 2006.24,
      "text": " run through a file now",
      "tokens": [
        51664,
        1190,
        807,
        257,
        3991,
        586,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40681833028793335,
      "compression_ratio": 1.5469387769699097,
      "no_speech_prob": 0.1454315185546875
    },
    {
      "id": 287,
      "seek": 77000,
      "start": 2006.24,
      "end": 2007.24,
      "text": " and that's bad",
      "tokens": [
        51764,
        293,
        300,
        311,
        1578,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40681833028793335,
      "compression_ratio": 1.5469387769699097,
      "no_speech_prob": 0.1454315185546875
    },
    {
      "id": 288,
      "seek": 79900,
      "start": 2007.24,
      "end": 2009.24,
      "text": " if it takes many minutes.",
      "tokens": [
        50364,
        498,
        309,
        2516,
        867,
        2077,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28801944851875305,
      "compression_ratio": 1.568376064300537,
      "no_speech_prob": 0.1448328197002411
    },
    {
      "id": 289,
      "seek": 79900,
      "start": 2009.24,
      "end": 2011.24,
      "text": " But I think it's unlikely",
      "tokens": [
        50464,
        583,
        286,
        519,
        309,
        311,
        17518,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28801944851875305,
      "compression_ratio": 1.568376064300537,
      "no_speech_prob": 0.1448328197002411
    },
    {
      "id": 290,
      "seek": 79900,
      "start": 2011.24,
      "end": 2012.24,
      "text": " that this is really",
      "tokens": [
        50564,
        300,
        341,
        307,
        534,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28801944851875305,
      "compression_ratio": 1.568376064300537,
      "no_speech_prob": 0.1448328197002411
    },
    {
      "id": 291,
      "seek": 79900,
      "start": 2012.24,
      "end": 2013.24,
      "text": " my requirement.",
      "tokens": [
        50614,
        452,
        11695,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28801944851875305,
      "compression_ratio": 1.568376064300537,
      "no_speech_prob": 0.1448328197002411
    },
    {
      "id": 292,
      "seek": 79900,
      "start": 2013.24,
      "end": 2014.24,
      "text": " Functional correctness,",
      "tokens": [
        50664,
        11166,
        41048,
        3006,
        1287,
        11,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28801944851875305,
      "compression_ratio": 1.568376064300537,
      "no_speech_prob": 0.1448328197002411
    },
    {
      "id": 293,
      "seek": 79900,
      "start": 2014.24,
      "end": 2016.24,
      "text": " that the results are actually",
      "tokens": [
        50714,
        300,
        264,
        3542,
        366,
        767,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28801944851875305,
      "compression_ratio": 1.568376064300537,
      "no_speech_prob": 0.1448328197002411
    },
    {
      "id": 294,
      "seek": 79900,
      "start": 2016.24,
      "end": 2017.24,
      "text": " really, really correct.",
      "tokens": [
        50814,
        534,
        11,
        534,
        3006,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28801944851875305,
      "compression_ratio": 1.568376064300537,
      "no_speech_prob": 0.1448328197002411
    },
    {
      "id": 295,
      "seek": 79900,
      "start": 2017.24,
      "end": 2019.24,
      "text": " It's just a Linter.",
      "tokens": [
        50864,
        467,
        311,
        445,
        257,
        441,
        5106,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28801944851875305,
      "compression_ratio": 1.568376064300537,
      "no_speech_prob": 0.1448328197002411
    },
    {
      "id": 296,
      "seek": 79900,
      "start": 2019.24,
      "end": 2020.24,
      "text": " So that means",
      "tokens": [
        50964,
        407,
        300,
        1355,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28801944851875305,
      "compression_ratio": 1.568376064300537,
      "no_speech_prob": 0.1448328197002411
    },
    {
      "id": 297,
      "seek": 79900,
      "start": 2020.24,
      "end": 2022.24,
      "text": " the discussion is actually",
      "tokens": [
        51014,
        264,
        5017,
        307,
        767,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28801944851875305,
      "compression_ratio": 1.568376064300537,
      "no_speech_prob": 0.1448328197002411
    },
    {
      "id": 298,
      "seek": 79900,
      "start": 2022.24,
      "end": 2024.24,
      "text": " which quality scenarios do I need?",
      "tokens": [
        51114,
        597,
        3125,
        15077,
        360,
        286,
        643,
        30,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28801944851875305,
      "compression_ratio": 1.568376064300537,
      "no_speech_prob": 0.1448328197002411
    },
    {
      "id": 299,
      "seek": 79900,
      "start": 2024.24,
      "end": 2025.24,
      "text": " And it would be more helpful",
      "tokens": [
        51214,
        400,
        309,
        576,
        312,
        544,
        4961,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28801944851875305,
      "compression_ratio": 1.568376064300537,
      "no_speech_prob": 0.1448328197002411
    },
    {
      "id": 300,
      "seek": 79900,
      "start": 2025.24,
      "end": 2027.24,
      "text": " if there was a system",
      "tokens": [
        51264,
        498,
        456,
        390,
        257,
        1185,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28801944851875305,
      "compression_ratio": 1.568376064300537,
      "no_speech_prob": 0.1448328197002411
    },
    {
      "id": 301,
      "seek": 79900,
      "start": 2027.24,
      "end": 2028.24,
      "text": " that would say,",
      "tokens": [
        51364,
        300,
        576,
        584,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28801944851875305,
      "compression_ratio": 1.568376064300537,
      "no_speech_prob": 0.1448328197002411
    },
    {
      "id": 302,
      "seek": 79900,
      "start": 2028.24,
      "end": 2031.24,
      "text": " listen up,",
      "tokens": [
        51414,
        2140,
        493,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28801944851875305,
      "compression_ratio": 1.568376064300537,
      "no_speech_prob": 0.1448328197002411
    },
    {
      "id": 303,
      "seek": 79900,
      "start": 2031.24,
      "end": 2035.24,
      "text": " that's my job, so to speak,",
      "tokens": [
        51564,
        300,
        311,
        452,
        1691,
        11,
        370,
        281,
        1710,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28801944851875305,
      "compression_ratio": 1.568376064300537,
      "no_speech_prob": 0.1448328197002411
    },
    {
      "id": 304,
      "seek": 82700,
      "start": 2036.24,
      "end": 2038.24,
      "text": " that I typically have.",
      "tokens": [
        50414,
        300,
        286,
        5850,
        362,
        13,
        50514
      ],
      "temperature": 0.6000000238418579,
      "avg_logprob": -0.4256938099861145,
      "compression_ratio": 1.580246925354004,
      "no_speech_prob": 0.2805509865283966
    },
    {
      "id": 305,
      "seek": 82700,
      "start": 2038.24,
      "end": 2039.24,
      "text": " Listen up.",
      "tokens": [
        50514,
        7501,
        493,
        13,
        50564
      ],
      "temperature": 0.6000000238418579,
      "avg_logprob": -0.4256938099861145,
      "compression_ratio": 1.580246925354004,
      "no_speech_prob": 0.2805509865283966
    },
    {
      "id": 306,
      "seek": 82700,
      "start": 2039.24,
      "end": 2041.24,
      "text": " Quality scenarios are important",
      "tokens": [
        50564,
        28892,
        15077,
        366,
        1021,
        50664
      ],
      "temperature": 0.6000000238418579,
      "avg_logprob": -0.4256938099861145,
      "compression_ratio": 1.580246925354004,
      "no_speech_prob": 0.2805509865283966
    },
    {
      "id": 307,
      "seek": 82700,
      "start": 2041.24,
      "end": 2044.24,
      "text": " from my background.",
      "tokens": [
        50664,
        490,
        452,
        3678,
        13,
        50814
      ],
      "temperature": 0.6000000238418579,
      "avg_logprob": -0.4256938099861145,
      "compression_ratio": 1.580246925354004,
      "no_speech_prob": 0.2805509865283966
    },
    {
      "id": 308,
      "seek": 82700,
      "start": 2044.24,
      "end": 2046.24,
      "text": " They drive the architecture.",
      "tokens": [
        50814,
        814,
        3332,
        264,
        9482,
        13,
        50914
      ],
      "temperature": 0.6000000238418579,
      "avg_logprob": -0.4256938099861145,
      "compression_ratio": 1.580246925354004,
      "no_speech_prob": 0.2805509865283966
    },
    {
      "id": 309,
      "seek": 82700,
      "start": 2046.24,
      "end": 2047.24,
      "text": " You don't have any good",
      "tokens": [
        50914,
        509,
        500,
        380,
        362,
        604,
        665,
        50964
      ],
      "temperature": 0.6000000238418579,
      "avg_logprob": -0.4256938099861145,
      "compression_ratio": 1.580246925354004,
      "no_speech_prob": 0.2805509865283966
    },
    {
      "id": 310,
      "seek": 82700,
      "start": 2047.24,
      "end": 2048.24,
      "text": " quality scenarios.",
      "tokens": [
        50964,
        3125,
        15077,
        13,
        51014
      ],
      "temperature": 0.6000000238418579,
      "avg_logprob": -0.4256938099861145,
      "compression_ratio": 1.580246925354004,
      "no_speech_prob": 0.2805509865283966
    },
    {
      "id": 311,
      "seek": 82700,
      "start": 2048.24,
      "end": 2050.24,
      "text": " You should maybe go back",
      "tokens": [
        51014,
        509,
        820,
        1310,
        352,
        646,
        51114
      ],
      "temperature": 0.6000000238418579,
      "avg_logprob": -0.4256938099861145,
      "compression_ratio": 1.580246925354004,
      "no_speech_prob": 0.2805509865283966
    },
    {
      "id": 312,
      "seek": 82700,
      "start": 2050.24,
      "end": 2051.24,
      "text": " and try to figure out",
      "tokens": [
        51114,
        293,
        853,
        281,
        2573,
        484,
        51164
      ],
      "temperature": 0.6000000238418579,
      "avg_logprob": -0.4256938099861145,
      "compression_ratio": 1.580246925354004,
      "no_speech_prob": 0.2805509865283966
    },
    {
      "id": 313,
      "seek": 82700,
      "start": 2051.24,
      "end": 2053.24,
      "text": " what the requirements are.",
      "tokens": [
        51164,
        437,
        264,
        7728,
        366,
        13,
        51264
      ],
      "temperature": 0.6000000238418579,
      "avg_logprob": -0.4256938099861145,
      "compression_ratio": 1.580246925354004,
      "no_speech_prob": 0.2805509865283966
    },
    {
      "id": 314,
      "seek": 82700,
      "start": 2053.24,
      "end": 2055.24,
      "text": " If I do that with an LLM,",
      "tokens": [
        51264,
        759,
        286,
        360,
        300,
        365,
        364,
        441,
        43,
        44,
        11,
        51364
      ],
      "temperature": 0.6000000238418579,
      "avg_logprob": -0.4256938099861145,
      "compression_ratio": 1.580246925354004,
      "no_speech_prob": 0.2805509865283966
    },
    {
      "id": 315,
      "seek": 82700,
      "start": 2055.24,
      "end": 2057.24,
      "text": " I'll be beaten up with anything.",
      "tokens": [
        51364,
        286,
        603,
        312,
        17909,
        493,
        365,
        1340,
        13,
        51464
      ],
      "temperature": 0.6000000238418579,
      "avg_logprob": -0.4256938099861145,
      "compression_ratio": 1.580246925354004,
      "no_speech_prob": 0.2805509865283966
    },
    {
      "id": 316,
      "seek": 82700,
      "start": 2057.24,
      "end": 2059.24,
      "text": " And I just don't get these questions",
      "tokens": [
        51464,
        400,
        286,
        445,
        500,
        380,
        483,
        258,
        1130,
        1651,
        51564
      ],
      "temperature": 0.6000000238418579,
      "avg_logprob": -0.4256938099861145,
      "compression_ratio": 1.580246925354004,
      "no_speech_prob": 0.2805509865283966
    },
    {
      "id": 317,
      "seek": 82700,
      "start": 2059.24,
      "end": 2061.24,
      "text": " and I don't see",
      "tokens": [
        51564,
        293,
        286,
        500,
        380,
        536,
        51664
      ],
      "temperature": 0.6000000238418579,
      "avg_logprob": -0.4256938099861145,
      "compression_ratio": 1.580246925354004,
      "no_speech_prob": 0.2805509865283966
    },
    {
      "id": 318,
      "seek": 82700,
      "start": 2061.24,
      "end": 2062.24,
      "text": " in which direction",
      "tokens": [
        51664,
        294,
        597,
        3513,
        51714
      ],
      "temperature": 0.6000000238418579,
      "avg_logprob": -0.4256938099861145,
      "compression_ratio": 1.580246925354004,
      "no_speech_prob": 0.2805509865283966
    },
    {
      "id": 319,
      "seek": 82700,
      "start": 2062.24,
      "end": 2063.24,
      "text": " I actually have to go",
      "tokens": [
        51714,
        286,
        767,
        362,
        281,
        352,
        51764
      ],
      "temperature": 0.6000000238418579,
      "avg_logprob": -0.4256938099861145,
      "compression_ratio": 1.580246925354004,
      "no_speech_prob": 0.2805509865283966
    },
    {
      "id": 320,
      "seek": 85500,
      "start": 2063.24,
      "end": 2067.24,
      "text": " and where the blind spots are.",
      "tokens": [
        50364,
        293,
        689,
        264,
        6865,
        10681,
        366,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4171699285507202,
      "compression_ratio": 1.4021738767623901,
      "no_speech_prob": 0.8172805905342102
    },
    {
      "id": 321,
      "seek": 85500,
      "start": 2067.24,
      "end": 2070.24,
      "text": " What I found very exciting",
      "tokens": [
        50564,
        708,
        286,
        1352,
        588,
        4670,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4171699285507202,
      "compression_ratio": 1.4021738767623901,
      "no_speech_prob": 0.8172805905342102
    },
    {
      "id": 322,
      "seek": 85500,
      "start": 2070.24,
      "end": 2071.24,
      "text": " was last week's episode",
      "tokens": [
        50714,
        390,
        1036,
        1243,
        311,
        3500,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4171699285507202,
      "compression_ratio": 1.4021738767623901,
      "no_speech_prob": 0.8172805905342102
    },
    {
      "id": 323,
      "seek": 85500,
      "start": 2071.24,
      "end": 2073.24,
      "text": " with Simon Wortley,",
      "tokens": [
        50764,
        365,
        13193,
        22748,
        3420,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4171699285507202,
      "compression_ratio": 1.4021738767623901,
      "no_speech_prob": 0.8172805905342102
    },
    {
      "id": 324,
      "seek": 85500,
      "start": 2073.24,
      "end": 2076.24,
      "text": " who talked about",
      "tokens": [
        50864,
        567,
        2825,
        466,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4171699285507202,
      "compression_ratio": 1.4021738767623901,
      "no_speech_prob": 0.8172805905342102
    },
    {
      "id": 325,
      "seek": 85500,
      "start": 2076.24,
      "end": 2078.24,
      "text": " the HRM's architecture.",
      "tokens": [
        51014,
        264,
        19460,
        44,
        311,
        9482,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4171699285507202,
      "compression_ratio": 1.4021738767623901,
      "no_speech_prob": 0.8172805905342102
    },
    {
      "id": 326,
      "seek": 85500,
      "start": 2078.24,
      "end": 2081.24,
      "text": " And he reported there",
      "tokens": [
        51114,
        400,
        415,
        7055,
        456,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4171699285507202,
      "compression_ratio": 1.4021738767623901,
      "no_speech_prob": 0.8172805905342102
    },
    {
      "id": 327,
      "seek": 85500,
      "start": 2081.24,
      "end": 2082.24,
      "text": " that he was doing",
      "tokens": [
        51264,
        300,
        415,
        390,
        884,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4171699285507202,
      "compression_ratio": 1.4021738767623901,
      "no_speech_prob": 0.8172805905342102
    },
    {
      "id": 328,
      "seek": 85500,
      "start": 2082.24,
      "end": 2083.24,
      "text": " this wipe coding,",
      "tokens": [
        51314,
        341,
        14082,
        17720,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4171699285507202,
      "compression_ratio": 1.4021738767623901,
      "no_speech_prob": 0.8172805905342102
    },
    {
      "id": 329,
      "seek": 85500,
      "start": 2083.24,
      "end": 2084.24,
      "text": " which basically means",
      "tokens": [
        51364,
        597,
        1936,
        1355,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4171699285507202,
      "compression_ratio": 1.4021738767623901,
      "no_speech_prob": 0.8172805905342102
    },
    {
      "id": 330,
      "seek": 85500,
      "start": 2084.24,
      "end": 2088.24,
      "text": " I don't want to see",
      "tokens": [
        51414,
        286,
        500,
        380,
        528,
        281,
        536,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4171699285507202,
      "compression_ratio": 1.4021738767623901,
      "no_speech_prob": 0.8172805905342102
    },
    {
      "id": 331,
      "seek": 85500,
      "start": 2088.24,
      "end": 2091.24,
      "text": " what my system,",
      "tokens": [
        51614,
        437,
        452,
        1185,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4171699285507202,
      "compression_ratio": 1.4021738767623901,
      "no_speech_prob": 0.8172805905342102
    },
    {
      "id": 332,
      "seek": 88300,
      "start": 2091.24,
      "end": 2094.24,
      "text": " what my AI generates.",
      "tokens": [
        50364,
        437,
        452,
        7318,
        23815,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46466055512428284,
      "compression_ratio": 1.686274528503418,
      "no_speech_prob": 0.34816715121269226
    },
    {
      "id": 333,
      "seek": 88300,
      "start": 2094.24,
      "end": 2098.24,
      "text": " And I'm just working",
      "tokens": [
        50514,
        400,
        286,
        478,
        445,
        1364,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46466055512428284,
      "compression_ratio": 1.686274528503418,
      "no_speech_prob": 0.34816715121269226
    },
    {
      "id": 334,
      "seek": 88300,
      "start": 2098.24,
      "end": 2100.24,
      "text": " in dialogue with the AI.",
      "tokens": [
        50714,
        294,
        10221,
        365,
        264,
        7318,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46466055512428284,
      "compression_ratio": 1.686274528503418,
      "no_speech_prob": 0.34816715121269226
    },
    {
      "id": 335,
      "seek": 88300,
      "start": 2100.24,
      "end": 2102.24,
      "text": " And he reported that",
      "tokens": [
        50814,
        400,
        415,
        7055,
        300,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46466055512428284,
      "compression_ratio": 1.686274528503418,
      "no_speech_prob": 0.34816715121269226
    },
    {
      "id": 336,
      "seek": 88300,
      "start": 2102.24,
      "end": 2107.24,
      "text": " he told the AI system,",
      "tokens": [
        50914,
        415,
        1907,
        264,
        7318,
        1185,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46466055512428284,
      "compression_ratio": 1.686274528503418,
      "no_speech_prob": 0.34816715121269226
    },
    {
      "id": 337,
      "seek": 88300,
      "start": 2107.24,
      "end": 2109.24,
      "text": " generate more tests.",
      "tokens": [
        51164,
        8460,
        544,
        6921,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46466055512428284,
      "compression_ratio": 1.686274528503418,
      "no_speech_prob": 0.34816715121269226
    },
    {
      "id": 338,
      "seek": 88300,
      "start": 2109.24,
      "end": 2111.24,
      "text": " And he later said,",
      "tokens": [
        51264,
        400,
        415,
        1780,
        848,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46466055512428284,
      "compression_ratio": 1.686274528503418,
      "no_speech_prob": 0.34816715121269226
    },
    {
      "id": 339,
      "seek": 88300,
      "start": 2111.24,
      "end": 2113.24,
      "text": " generate more tests.",
      "tokens": [
        51364,
        8460,
        544,
        6921,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46466055512428284,
      "compression_ratio": 1.686274528503418,
      "no_speech_prob": 0.34816715121269226
    },
    {
      "id": 340,
      "seek": 88300,
      "start": 2113.24,
      "end": 2115.24,
      "text": " And something came out of it.",
      "tokens": [
        51464,
        400,
        746,
        1361,
        484,
        295,
        309,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46466055512428284,
      "compression_ratio": 1.686274528503418,
      "no_speech_prob": 0.34816715121269226
    },
    {
      "id": 341,
      "seek": 88300,
      "start": 2115.24,
      "end": 2116.24,
      "text": " And somehow it got very clumsy",
      "tokens": [
        51564,
        400,
        6063,
        309,
        658,
        588,
        44640,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46466055512428284,
      "compression_ratio": 1.686274528503418,
      "no_speech_prob": 0.34816715121269226
    },
    {
      "id": 342,
      "seek": 88300,
      "start": 2116.24,
      "end": 2118.24,
      "text": " and he somehow found out",
      "tokens": [
        51614,
        293,
        415,
        6063,
        1352,
        484,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.46466055512428284,
      "compression_ratio": 1.686274528503418,
      "no_speech_prob": 0.34816715121269226
    },
    {
      "id": 343,
      "seek": 91000,
      "start": 2118.24,
      "end": 2121.24,
      "text": " that the system actually",
      "tokens": [
        50364,
        300,
        264,
        1185,
        767,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3724478781223297,
      "compression_ratio": 1.614213228225708,
      "no_speech_prob": 0.7753149271011353
    },
    {
      "id": 344,
      "seek": 91000,
      "start": 2121.24,
      "end": 2123.24,
      "text": " did not generate any tests,",
      "tokens": [
        50514,
        630,
        406,
        8460,
        604,
        6921,
        11,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3724478781223297,
      "compression_ratio": 1.614213228225708,
      "no_speech_prob": 0.7753149271011353
    },
    {
      "id": 345,
      "seek": 91000,
      "start": 2123.24,
      "end": 2124.24,
      "text": " but only code",
      "tokens": [
        50614,
        457,
        787,
        3089,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3724478781223297,
      "compression_ratio": 1.614213228225708,
      "no_speech_prob": 0.7753149271011353
    },
    {
      "id": 346,
      "seek": 91000,
      "start": 2124.24,
      "end": 2127.24,
      "text": " that reproduced test outputs.",
      "tokens": [
        50664,
        300,
        11408,
        1232,
        1500,
        23930,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3724478781223297,
      "compression_ratio": 1.614213228225708,
      "no_speech_prob": 0.7753149271011353
    },
    {
      "id": 347,
      "seek": 91000,
      "start": 2127.24,
      "end": 2129.24,
      "text": " So it produced green bars,",
      "tokens": [
        50814,
        407,
        309,
        7126,
        3092,
        10228,
        11,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3724478781223297,
      "compression_ratio": 1.614213228225708,
      "no_speech_prob": 0.7753149271011353
    },
    {
      "id": 348,
      "seek": 91000,
      "start": 2129.24,
      "end": 2130.24,
      "text": " or error messages,",
      "tokens": [
        50914,
        420,
        6713,
        7897,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3724478781223297,
      "compression_ratio": 1.614213228225708,
      "no_speech_prob": 0.7753149271011353
    },
    {
      "id": 349,
      "seek": 91000,
      "start": 2130.24,
      "end": 2132.24,
      "text": " or a successful test,",
      "tokens": [
        50964,
        420,
        257,
        4406,
        1500,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3724478781223297,
      "compression_ratio": 1.614213228225708,
      "no_speech_prob": 0.7753149271011353
    },
    {
      "id": 350,
      "seek": 91000,
      "start": 2132.24,
      "end": 2133.24,
      "text": " but it actually",
      "tokens": [
        51064,
        457,
        309,
        767,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3724478781223297,
      "compression_ratio": 1.614213228225708,
      "no_speech_prob": 0.7753149271011353
    },
    {
      "id": 351,
      "seek": 91000,
      "start": 2133.24,
      "end": 2135.24,
      "text": " did not execute the code",
      "tokens": [
        51114,
        630,
        406,
        14483,
        264,
        3089,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3724478781223297,
      "compression_ratio": 1.614213228225708,
      "no_speech_prob": 0.7753149271011353
    },
    {
      "id": 352,
      "seek": 91000,
      "start": 2135.24,
      "end": 2137.24,
      "text": " that was being tested.",
      "tokens": [
        51214,
        300,
        390,
        885,
        8246,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3724478781223297,
      "compression_ratio": 1.614213228225708,
      "no_speech_prob": 0.7753149271011353
    },
    {
      "id": 353,
      "seek": 91000,
      "start": 2137.24,
      "end": 2142.24,
      "text": " And I find it difficult",
      "tokens": [
        51314,
        400,
        286,
        915,
        309,
        2252,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3724478781223297,
      "compression_ratio": 1.614213228225708,
      "no_speech_prob": 0.7753149271011353
    },
    {
      "id": 354,
      "seek": 91000,
      "start": 2142.24,
      "end": 2144.24,
      "text": " to go out there and say,",
      "tokens": [
        51564,
        281,
        352,
        484,
        456,
        293,
        584,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3724478781223297,
      "compression_ratio": 1.614213228225708,
      "no_speech_prob": 0.7753149271011353
    },
    {
      "id": 355,
      "seek": 91000,
      "start": 2144.24,
      "end": 2147.24,
      "text": " I don't want to check on this code level",
      "tokens": [
        51664,
        286,
        500,
        380,
        528,
        281,
        1520,
        322,
        341,
        3089,
        1496,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3724478781223297,
      "compression_ratio": 1.614213228225708,
      "no_speech_prob": 0.7753149271011353
    },
    {
      "id": 356,
      "seek": 93900,
      "start": 2147.24,
      "end": 2149.24,
      "text": " what my AI is doing.",
      "tokens": [
        50364,
        437,
        452,
        7318,
        307,
        884,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471944034099579,
      "compression_ratio": 1.5774648189544678,
      "no_speech_prob": 0.4287620186805725
    },
    {
      "id": 357,
      "seek": 93900,
      "start": 2149.24,
      "end": 2151.24,
      "text": " So that's actually something",
      "tokens": [
        50464,
        407,
        300,
        311,
        767,
        746,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471944034099579,
      "compression_ratio": 1.5774648189544678,
      "no_speech_prob": 0.4287620186805725
    },
    {
      "id": 358,
      "seek": 93900,
      "start": 2151.24,
      "end": 2153.24,
      "text": " where I think a check",
      "tokens": [
        50564,
        689,
        286,
        519,
        257,
        1520,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471944034099579,
      "compression_ratio": 1.5774648189544678,
      "no_speech_prob": 0.4287620186805725
    },
    {
      "id": 359,
      "seek": 93900,
      "start": 2153.24,
      "end": 2154.24,
      "text": " is absolutely necessary.",
      "tokens": [
        50664,
        307,
        3122,
        4818,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471944034099579,
      "compression_ratio": 1.5774648189544678,
      "no_speech_prob": 0.4287620186805725
    },
    {
      "id": 360,
      "seek": 93900,
      "start": 2154.24,
      "end": 2155.24,
      "text": " And it's extremely difficult",
      "tokens": [
        50714,
        400,
        309,
        311,
        4664,
        2252,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471944034099579,
      "compression_ratio": 1.5774648189544678,
      "no_speech_prob": 0.4287620186805725
    },
    {
      "id": 361,
      "seek": 93900,
      "start": 2155.24,
      "end": 2157.24,
      "text": " if I don't do that.",
      "tokens": [
        50764,
        498,
        286,
        500,
        380,
        360,
        300,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471944034099579,
      "compression_ratio": 1.5774648189544678,
      "no_speech_prob": 0.4287620186805725
    },
    {
      "id": 362,
      "seek": 93900,
      "start": 2157.24,
      "end": 2159.24,
      "text": " And I also find the behavior",
      "tokens": [
        50864,
        400,
        286,
        611,
        915,
        264,
        5223,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471944034099579,
      "compression_ratio": 1.5774648189544678,
      "no_speech_prob": 0.4287620186805725
    },
    {
      "id": 363,
      "seek": 93900,
      "start": 2159.24,
      "end": 2162.24,
      "text": " overall exciting.",
      "tokens": [
        50964,
        4787,
        4670,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471944034099579,
      "compression_ratio": 1.5774648189544678,
      "no_speech_prob": 0.4287620186805725
    },
    {
      "id": 364,
      "seek": 93900,
      "start": 2162.24,
      "end": 2167.24,
      "text": " What I find interesting",
      "tokens": [
        51114,
        708,
        286,
        915,
        1880,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471944034099579,
      "compression_ratio": 1.5774648189544678,
      "no_speech_prob": 0.4287620186805725
    },
    {
      "id": 365,
      "seek": 93900,
      "start": 2167.24,
      "end": 2168.24,
      "text": " is, let's assume",
      "tokens": [
        51364,
        307,
        11,
        718,
        311,
        6552,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471944034099579,
      "compression_ratio": 1.5774648189544678,
      "no_speech_prob": 0.4287620186805725
    },
    {
      "id": 366,
      "seek": 93900,
      "start": 2168.24,
      "end": 2169.24,
      "text": " that would be a developer.",
      "tokens": [
        51414,
        300,
        576,
        312,
        257,
        10754,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471944034099579,
      "compression_ratio": 1.5774648189544678,
      "no_speech_prob": 0.4287620186805725
    },
    {
      "id": 367,
      "seek": 93900,
      "start": 2169.24,
      "end": 2171.24,
      "text": " So I imagine a developer",
      "tokens": [
        51464,
        407,
        286,
        3811,
        257,
        10754,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471944034099579,
      "compression_ratio": 1.5774648189544678,
      "no_speech_prob": 0.4287620186805725
    },
    {
      "id": 368,
      "seek": 93900,
      "start": 2171.24,
      "end": 2172.24,
      "text": " wrote a test.",
      "tokens": [
        51564,
        4114,
        257,
        1500,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471944034099579,
      "compression_ratio": 1.5774648189544678,
      "no_speech_prob": 0.4287620186805725
    },
    {
      "id": 369,
      "seek": 93900,
      "start": 2172.24,
      "end": 2175.24,
      "text": " And this test produces test outputs,",
      "tokens": [
        51614,
        400,
        341,
        1500,
        14725,
        1500,
        23930,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471944034099579,
      "compression_ratio": 1.5774648189544678,
      "no_speech_prob": 0.4287620186805725
    },
    {
      "id": 370,
      "seek": 96700,
      "start": 2176.24,
      "end": 2179.24,
      "text": " but actually does not perform a test.",
      "tokens": [
        50414,
        457,
        767,
        775,
        406,
        2042,
        257,
        1500,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.354636549949646,
      "compression_ratio": 1.7535544633865356,
      "no_speech_prob": 0.05027122423052788
    },
    {
      "id": 371,
      "seek": 96700,
      "start": 2179.24,
      "end": 2181.24,
      "text": " I am of the opinion",
      "tokens": [
        50564,
        286,
        669,
        295,
        264,
        4800,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.354636549949646,
      "compression_ratio": 1.7535544633865356,
      "no_speech_prob": 0.05027122423052788
    },
    {
      "id": 372,
      "seek": 96700,
      "start": 2181.24,
      "end": 2183.24,
      "text": " that you should ideally",
      "tokens": [
        50664,
        300,
        291,
        820,
        22915,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.354636549949646,
      "compression_ratio": 1.7535544633865356,
      "no_speech_prob": 0.05027122423052788
    },
    {
      "id": 373,
      "seek": 96700,
      "start": 2183.24,
      "end": 2185.24,
      "text": " pass it on to developers.",
      "tokens": [
        50764,
        1320,
        309,
        322,
        281,
        8849,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.354636549949646,
      "compression_ratio": 1.7535544633865356,
      "no_speech_prob": 0.05027122423052788
    },
    {
      "id": 374,
      "seek": 96700,
      "start": 2185.24,
      "end": 2186.24,
      "text": " So that means,",
      "tokens": [
        50864,
        407,
        300,
        1355,
        11,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.354636549949646,
      "compression_ratio": 1.7535544633865356,
      "no_speech_prob": 0.05027122423052788
    },
    {
      "id": 375,
      "seek": 96700,
      "start": 2186.24,
      "end": 2188.24,
      "text": " if a developer came and said,",
      "tokens": [
        50914,
        498,
        257,
        10754,
        1361,
        293,
        848,
        11,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.354636549949646,
      "compression_ratio": 1.7535544633865356,
      "no_speech_prob": 0.05027122423052788
    },
    {
      "id": 376,
      "seek": 96700,
      "start": 2188.24,
      "end": 2190.24,
      "text": " I don't know how to write a test,",
      "tokens": [
        51014,
        286,
        500,
        380,
        458,
        577,
        281,
        2464,
        257,
        1500,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.354636549949646,
      "compression_ratio": 1.7535544633865356,
      "no_speech_prob": 0.05027122423052788
    },
    {
      "id": 377,
      "seek": 96700,
      "start": 2190.24,
      "end": 2192.24,
      "text": " then I would ideally",
      "tokens": [
        51114,
        550,
        286,
        576,
        22915,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.354636549949646,
      "compression_ratio": 1.7535544633865356,
      "no_speech_prob": 0.05027122423052788
    },
    {
      "id": 378,
      "seek": 96700,
      "start": 2192.24,
      "end": 2193.24,
      "text": " sit down with him.",
      "tokens": [
        51214,
        1394,
        760,
        365,
        796,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.354636549949646,
      "compression_ratio": 1.7535544633865356,
      "no_speech_prob": 0.05027122423052788
    },
    {
      "id": 379,
      "seek": 96700,
      "start": 2193.24,
      "end": 2194.24,
      "text": " I would tell someone",
      "tokens": [
        51264,
        286,
        576,
        980,
        1580,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.354636549949646,
      "compression_ratio": 1.7535544633865356,
      "no_speech_prob": 0.05027122423052788
    },
    {
      "id": 380,
      "seek": 96700,
      "start": 2194.24,
      "end": 2197.24,
      "text": " that the person sits down with him.",
      "tokens": [
        51314,
        300,
        264,
        954,
        12696,
        760,
        365,
        796,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.354636549949646,
      "compression_ratio": 1.7535544633865356,
      "no_speech_prob": 0.05027122423052788
    },
    {
      "id": 381,
      "seek": 96700,
      "start": 2197.24,
      "end": 2199.24,
      "text": " If a developer says,",
      "tokens": [
        51464,
        759,
        257,
        10754,
        1619,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.354636549949646,
      "compression_ratio": 1.7535544633865356,
      "no_speech_prob": 0.05027122423052788
    },
    {
      "id": 382,
      "seek": 96700,
      "start": 2199.24,
      "end": 2201.24,
      "text": " listen, I wrote a test,",
      "tokens": [
        51564,
        2140,
        11,
        286,
        4114,
        257,
        1500,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.354636549949646,
      "compression_ratio": 1.7535544633865356,
      "no_speech_prob": 0.05027122423052788
    },
    {
      "id": 383,
      "seek": 96700,
      "start": 2201.24,
      "end": 2204.24,
      "text": " but somehow I don't feel very comfortable",
      "tokens": [
        51664,
        457,
        6063,
        286,
        500,
        380,
        841,
        588,
        4619,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.354636549949646,
      "compression_ratio": 1.7535544633865356,
      "no_speech_prob": 0.05027122423052788
    },
    {
      "id": 384,
      "seek": 99600,
      "start": 2204.24,
      "end": 2205.24,
      "text": " and it's kind of weird.",
      "tokens": [
        50364,
        293,
        309,
        311,
        733,
        295,
        3657,
        13,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520984947681427,
      "compression_ratio": 1.619718313217163,
      "no_speech_prob": 0.032468561083078384
    },
    {
      "id": 385,
      "seek": 99600,
      "start": 2205.24,
      "end": 2206.24,
      "text": " Okay.",
      "tokens": [
        50414,
        1033,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520984947681427,
      "compression_ratio": 1.619718313217163,
      "no_speech_prob": 0.032468561083078384
    },
    {
      "id": 386,
      "seek": 99600,
      "start": 2206.24,
      "end": 2207.24,
      "text": " So also something",
      "tokens": [
        50464,
        407,
        611,
        746,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520984947681427,
      "compression_ratio": 1.619718313217163,
      "no_speech_prob": 0.032468561083078384
    },
    {
      "id": 387,
      "seek": 99600,
      "start": 2207.24,
      "end": 2208.24,
      "text": " where we can work on it.",
      "tokens": [
        50514,
        689,
        321,
        393,
        589,
        322,
        309,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520984947681427,
      "compression_ratio": 1.619718313217163,
      "no_speech_prob": 0.032468561083078384
    },
    {
      "id": 388,
      "seek": 99600,
      "start": 2208.24,
      "end": 2210.24,
      "text": " And we shouldn't.",
      "tokens": [
        50564,
        400,
        321,
        4659,
        380,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520984947681427,
      "compression_ratio": 1.619718313217163,
      "no_speech_prob": 0.032468561083078384
    },
    {
      "id": 389,
      "seek": 99600,
      "start": 2210.24,
      "end": 2211.24,
      "text": " So that's nice",
      "tokens": [
        50664,
        407,
        300,
        311,
        1481,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520984947681427,
      "compression_ratio": 1.619718313217163,
      "no_speech_prob": 0.032468561083078384
    },
    {
      "id": 390,
      "seek": 99600,
      "start": 2211.24,
      "end": 2212.24,
      "text": " when people say,",
      "tokens": [
        50714,
        562,
        561,
        584,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520984947681427,
      "compression_ratio": 1.619718313217163,
      "no_speech_prob": 0.032468561083078384
    },
    {
      "id": 391,
      "seek": 99600,
      "start": 2212.24,
      "end": 2213.24,
      "text": " I have a problem",
      "tokens": [
        50764,
        286,
        362,
        257,
        1154,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520984947681427,
      "compression_ratio": 1.619718313217163,
      "no_speech_prob": 0.032468561083078384
    },
    {
      "id": 392,
      "seek": 99600,
      "start": 2213.24,
      "end": 2215.24,
      "text": " and if you can help them,",
      "tokens": [
        50814,
        293,
        498,
        291,
        393,
        854,
        552,
        11,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520984947681427,
      "compression_ratio": 1.619718313217163,
      "no_speech_prob": 0.032468561083078384
    },
    {
      "id": 393,
      "seek": 99600,
      "start": 2215.24,
      "end": 2216.24,
      "text": " then these people grow.",
      "tokens": [
        50914,
        550,
        613,
        561,
        1852,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520984947681427,
      "compression_ratio": 1.619718313217163,
      "no_speech_prob": 0.032468561083078384
    },
    {
      "id": 394,
      "seek": 99600,
      "start": 2216.24,
      "end": 2217.24,
      "text": " And that's actually",
      "tokens": [
        50964,
        400,
        300,
        311,
        767,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520984947681427,
      "compression_ratio": 1.619718313217163,
      "no_speech_prob": 0.032468561083078384
    },
    {
      "id": 395,
      "seek": 99600,
      "start": 2217.24,
      "end": 2219.24,
      "text": " where we want to go.",
      "tokens": [
        51014,
        689,
        321,
        528,
        281,
        352,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520984947681427,
      "compression_ratio": 1.619718313217163,
      "no_speech_prob": 0.032468561083078384
    },
    {
      "id": 396,
      "seek": 99600,
      "start": 2219.24,
      "end": 2221.24,
      "text": " I have to admit,",
      "tokens": [
        51114,
        286,
        362,
        281,
        9796,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520984947681427,
      "compression_ratio": 1.619718313217163,
      "no_speech_prob": 0.032468561083078384
    },
    {
      "id": 397,
      "seek": 99600,
      "start": 2221.24,
      "end": 2223.24,
      "text": " if a developer comes,",
      "tokens": [
        51214,
        498,
        257,
        10754,
        1487,
        11,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520984947681427,
      "compression_ratio": 1.619718313217163,
      "no_speech_prob": 0.032468561083078384
    },
    {
      "id": 398,
      "seek": 99600,
      "start": 2223.24,
      "end": 2224.24,
      "text": " if I find out",
      "tokens": [
        51314,
        498,
        286,
        915,
        484,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520984947681427,
      "compression_ratio": 1.619718313217163,
      "no_speech_prob": 0.032468561083078384
    },
    {
      "id": 399,
      "seek": 99600,
      "start": 2224.24,
      "end": 2225.24,
      "text": " that a developer",
      "tokens": [
        51364,
        300,
        257,
        10754,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520984947681427,
      "compression_ratio": 1.619718313217163,
      "no_speech_prob": 0.032468561083078384
    },
    {
      "id": 400,
      "seek": 99600,
      "start": 2225.24,
      "end": 2227.24,
      "text": " wrote a code",
      "tokens": [
        51414,
        4114,
        257,
        3089,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520984947681427,
      "compression_ratio": 1.619718313217163,
      "no_speech_prob": 0.032468561083078384
    },
    {
      "id": 401,
      "seek": 99600,
      "start": 2227.24,
      "end": 2232.24,
      "text": " that acts as if it were a test,",
      "tokens": [
        51514,
        300,
        10672,
        382,
        498,
        309,
        645,
        257,
        1500,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3520984947681427,
      "compression_ratio": 1.619718313217163,
      "no_speech_prob": 0.032468561083078384
    },
    {
      "id": 402,
      "seek": 102400,
      "start": 2233.24,
      "end": 2234.24,
      "text": " I would, I think,",
      "tokens": [
        50414,
        286,
        576,
        11,
        286,
        519,
        11,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750069737434387,
      "compression_ratio": 1.6961538791656494,
      "no_speech_prob": 0.11880093067884445
    },
    {
      "id": 403,
      "seek": 102400,
      "start": 2234.24,
      "end": 2235.24,
      "text": " demolish it.",
      "tokens": [
        50464,
        1371,
        401,
        742,
        309,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750069737434387,
      "compression_ratio": 1.6961538791656494,
      "no_speech_prob": 0.11880093067884445
    },
    {
      "id": 404,
      "seek": 102400,
      "start": 2235.24,
      "end": 2236.24,
      "text": " And I don't see",
      "tokens": [
        50514,
        400,
        286,
        500,
        380,
        536,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750069737434387,
      "compression_ratio": 1.6961538791656494,
      "no_speech_prob": 0.11880093067884445
    },
    {
      "id": 405,
      "seek": 102400,
      "start": 2236.24,
      "end": 2238.24,
      "text": " the alternative seriously.",
      "tokens": [
        50564,
        264,
        8535,
        6638,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750069737434387,
      "compression_ratio": 1.6961538791656494,
      "no_speech_prob": 0.11880093067884445
    },
    {
      "id": 406,
      "seek": 102400,
      "start": 2238.24,
      "end": 2240.24,
      "text": " Because that's something else.",
      "tokens": [
        50664,
        1436,
        300,
        311,
        746,
        1646,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750069737434387,
      "compression_ratio": 1.6961538791656494,
      "no_speech_prob": 0.11880093067884445
    },
    {
      "id": 407,
      "seek": 102400,
      "start": 2240.24,
      "end": 2242.24,
      "text": " That's not not being able to.",
      "tokens": [
        50764,
        663,
        311,
        406,
        406,
        885,
        1075,
        281,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750069737434387,
      "compression_ratio": 1.6961538791656494,
      "no_speech_prob": 0.11880093067884445
    },
    {
      "id": 408,
      "seek": 102400,
      "start": 2242.24,
      "end": 2244.24,
      "text": " You can fix that.",
      "tokens": [
        50864,
        509,
        393,
        3191,
        300,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750069737434387,
      "compression_ratio": 1.6961538791656494,
      "no_speech_prob": 0.11880093067884445
    },
    {
      "id": 409,
      "seek": 102400,
      "start": 2244.24,
      "end": 2245.24,
      "text": " But that's actually",
      "tokens": [
        50964,
        583,
        300,
        311,
        767,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750069737434387,
      "compression_ratio": 1.6961538791656494,
      "no_speech_prob": 0.11880093067884445
    },
    {
      "id": 410,
      "seek": 102400,
      "start": 2245.24,
      "end": 2247.24,
      "text": " intention to deceive.",
      "tokens": [
        51014,
        7789,
        281,
        43440,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750069737434387,
      "compression_ratio": 1.6961538791656494,
      "no_speech_prob": 0.11880093067884445
    },
    {
      "id": 411,
      "seek": 102400,
      "start": 2247.24,
      "end": 2249.24,
      "text": " And that's just super dangerous.",
      "tokens": [
        51114,
        400,
        300,
        311,
        445,
        1687,
        5795,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750069737434387,
      "compression_ratio": 1.6961538791656494,
      "no_speech_prob": 0.11880093067884445
    },
    {
      "id": 412,
      "seek": 102400,
      "start": 2249.24,
      "end": 2250.24,
      "text": " So on the one hand,",
      "tokens": [
        51214,
        407,
        322,
        264,
        472,
        1011,
        11,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750069737434387,
      "compression_ratio": 1.6961538791656494,
      "no_speech_prob": 0.11880093067884445
    },
    {
      "id": 413,
      "seek": 102400,
      "start": 2250.24,
      "end": 2251.24,
      "text": " it's just that",
      "tokens": [
        51264,
        309,
        311,
        445,
        300,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750069737434387,
      "compression_ratio": 1.6961538791656494,
      "no_speech_prob": 0.11880093067884445
    },
    {
      "id": 414,
      "seek": 102400,
      "start": 2251.24,
      "end": 2252.24,
      "text": " under certain circumstances",
      "tokens": [
        51314,
        833,
        1629,
        9121,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750069737434387,
      "compression_ratio": 1.6961538791656494,
      "no_speech_prob": 0.11880093067884445
    },
    {
      "id": 415,
      "seek": 102400,
      "start": 2252.24,
      "end": 2253.24,
      "text": " it can just lead to",
      "tokens": [
        51364,
        309,
        393,
        445,
        1477,
        281,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750069737434387,
      "compression_ratio": 1.6961538791656494,
      "no_speech_prob": 0.11880093067884445
    },
    {
      "id": 416,
      "seek": 102400,
      "start": 2253.24,
      "end": 2254.24,
      "text": " that there are some errors",
      "tokens": [
        51414,
        300,
        456,
        366,
        512,
        13603,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750069737434387,
      "compression_ratio": 1.6961538791656494,
      "no_speech_prob": 0.11880093067884445
    },
    {
      "id": 417,
      "seek": 102400,
      "start": 2254.24,
      "end": 2255.24,
      "text": " in production",
      "tokens": [
        51464,
        294,
        4265,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750069737434387,
      "compression_ratio": 1.6961538791656494,
      "no_speech_prob": 0.11880093067884445
    },
    {
      "id": 418,
      "seek": 102400,
      "start": 2255.24,
      "end": 2256.24,
      "text": " and they can have",
      "tokens": [
        51514,
        293,
        436,
        393,
        362,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750069737434387,
      "compression_ratio": 1.6961538791656494,
      "no_speech_prob": 0.11880093067884445
    },
    {
      "id": 419,
      "seek": 102400,
      "start": 2256.24,
      "end": 2258.24,
      "text": " dramatic consequences.",
      "tokens": [
        51564,
        12023,
        10098,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750069737434387,
      "compression_ratio": 1.6961538791656494,
      "no_speech_prob": 0.11880093067884445
    },
    {
      "id": 420,
      "seek": 102400,
      "start": 2258.24,
      "end": 2259.24,
      "text": " But the other problem",
      "tokens": [
        51664,
        583,
        264,
        661,
        1154,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750069737434387,
      "compression_ratio": 1.6961538791656494,
      "no_speech_prob": 0.11880093067884445
    },
    {
      "id": 421,
      "seek": 102400,
      "start": 2259.24,
      "end": 2260.24,
      "text": " is also that",
      "tokens": [
        51714,
        307,
        611,
        300,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750069737434387,
      "compression_ratio": 1.6961538791656494,
      "no_speech_prob": 0.11880093067884445
    },
    {
      "id": 422,
      "seek": 102400,
      "start": 2260.24,
      "end": 2261.24,
      "text": " it's actually",
      "tokens": [
        51764,
        309,
        311,
        767,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750069737434387,
      "compression_ratio": 1.6961538791656494,
      "no_speech_prob": 0.11880093067884445
    },
    {
      "id": 423,
      "seek": 105300,
      "start": 2261.24,
      "end": 2262.24,
      "text": " an attempt to deceive.",
      "tokens": [
        50364,
        364,
        5217,
        281,
        43440,
        13,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3557073473930359,
      "compression_ratio": 1.7033898830413818,
      "no_speech_prob": 0.20286253094673157
    },
    {
      "id": 424,
      "seek": 105300,
      "start": 2262.24,
      "end": 2263.24,
      "text": " And I just don't feel like",
      "tokens": [
        50414,
        400,
        286,
        445,
        500,
        380,
        841,
        411,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3557073473930359,
      "compression_ratio": 1.7033898830413818,
      "no_speech_prob": 0.20286253094673157
    },
    {
      "id": 425,
      "seek": 105300,
      "start": 2263.24,
      "end": 2264.24,
      "text": " working with a person",
      "tokens": [
        50464,
        1364,
        365,
        257,
        954,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3557073473930359,
      "compression_ratio": 1.7033898830413818,
      "no_speech_prob": 0.20286253094673157
    },
    {
      "id": 426,
      "seek": 105300,
      "start": 2264.24,
      "end": 2266.24,
      "text": " who is not only,",
      "tokens": [
        50514,
        567,
        307,
        406,
        787,
        11,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3557073473930359,
      "compression_ratio": 1.7033898830413818,
      "no_speech_prob": 0.20286253094673157
    },
    {
      "id": 427,
      "seek": 105300,
      "start": 2266.24,
      "end": 2270.24,
      "text": " who is actually actively deceiving.",
      "tokens": [
        50614,
        567,
        307,
        767,
        13022,
        14088,
        2123,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3557073473930359,
      "compression_ratio": 1.7033898830413818,
      "no_speech_prob": 0.20286253094673157
    },
    {
      "id": 428,
      "seek": 105300,
      "start": 2270.24,
      "end": 2271.24,
      "text": " So that means",
      "tokens": [
        50814,
        407,
        300,
        1355,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3557073473930359,
      "compression_ratio": 1.7033898830413818,
      "no_speech_prob": 0.20286253094673157
    },
    {
      "id": 429,
      "seek": 105300,
      "start": 2271.24,
      "end": 2273.24,
      "text": " that I have a trust problem.",
      "tokens": [
        50864,
        300,
        286,
        362,
        257,
        3361,
        1154,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3557073473930359,
      "compression_ratio": 1.7033898830413818,
      "no_speech_prob": 0.20286253094673157
    },
    {
      "id": 430,
      "seek": 105300,
      "start": 2273.24,
      "end": 2275.24,
      "text": " And how you can go out there",
      "tokens": [
        50964,
        400,
        577,
        291,
        393,
        352,
        484,
        456,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3557073473930359,
      "compression_ratio": 1.7033898830413818,
      "no_speech_prob": 0.20286253094673157
    },
    {
      "id": 431,
      "seek": 105300,
      "start": 2275.24,
      "end": 2276.24,
      "text": " and then say,",
      "tokens": [
        51064,
        293,
        550,
        584,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3557073473930359,
      "compression_ratio": 1.7033898830413818,
      "no_speech_prob": 0.20286253094673157
    },
    {
      "id": 432,
      "seek": 105300,
      "start": 2276.24,
      "end": 2277.24,
      "text": " okay, I have an LLM",
      "tokens": [
        51114,
        1392,
        11,
        286,
        362,
        364,
        441,
        43,
        44,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3557073473930359,
      "compression_ratio": 1.7033898830413818,
      "no_speech_prob": 0.20286253094673157
    },
    {
      "id": 433,
      "seek": 105300,
      "start": 2277.24,
      "end": 2279.24,
      "text": " and the LLM somehow generates",
      "tokens": [
        51164,
        293,
        264,
        441,
        43,
        44,
        6063,
        23815,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3557073473930359,
      "compression_ratio": 1.7033898830413818,
      "no_speech_prob": 0.20286253094673157
    },
    {
      "id": 434,
      "seek": 105300,
      "start": 2279.24,
      "end": 2280.24,
      "text": " something",
      "tokens": [
        51264,
        746,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3557073473930359,
      "compression_ratio": 1.7033898830413818,
      "no_speech_prob": 0.20286253094673157
    },
    {
      "id": 435,
      "seek": 105300,
      "start": 2280.24,
      "end": 2281.24,
      "text": " and I don't want to understand that,",
      "tokens": [
        51314,
        293,
        286,
        500,
        380,
        528,
        281,
        1223,
        300,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3557073473930359,
      "compression_ratio": 1.7033898830413818,
      "no_speech_prob": 0.20286253094673157
    },
    {
      "id": 436,
      "seek": 105300,
      "start": 2281.24,
      "end": 2282.24,
      "text": " which is obviously",
      "tokens": [
        51364,
        597,
        307,
        2745,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3557073473930359,
      "compression_ratio": 1.7033898830413818,
      "no_speech_prob": 0.20286253094673157
    },
    {
      "id": 437,
      "seek": 105300,
      "start": 2282.24,
      "end": 2283.24,
      "text": " somehow the direction",
      "tokens": [
        51414,
        6063,
        264,
        3513,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3557073473930359,
      "compression_ratio": 1.7033898830413818,
      "no_speech_prob": 0.20286253094673157
    },
    {
      "id": 438,
      "seek": 105300,
      "start": 2283.24,
      "end": 2284.24,
      "text": " of web coding,",
      "tokens": [
        51464,
        295,
        3670,
        17720,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3557073473930359,
      "compression_ratio": 1.7033898830413818,
      "no_speech_prob": 0.20286253094673157
    },
    {
      "id": 439,
      "seek": 105300,
      "start": 2284.24,
      "end": 2286.24,
      "text": " I just don't understand",
      "tokens": [
        51514,
        286,
        445,
        500,
        380,
        1223,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3557073473930359,
      "compression_ratio": 1.7033898830413818,
      "no_speech_prob": 0.20286253094673157
    },
    {
      "id": 440,
      "seek": 105300,
      "start": 2286.24,
      "end": 2288.24,
      "text": " at this point.",
      "tokens": [
        51614,
        412,
        341,
        935,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3557073473930359,
      "compression_ratio": 1.7033898830413818,
      "no_speech_prob": 0.20286253094673157
    },
    {
      "id": 441,
      "seek": 108000,
      "start": 2289.24,
      "end": 2291.24,
      "text": " Christian writes,",
      "tokens": [
        50414,
        5778,
        13657,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3827369809150696,
      "compression_ratio": 1.5585585832595825,
      "no_speech_prob": 0.22978980839252472
    },
    {
      "id": 442,
      "seek": 108000,
      "start": 2291.24,
      "end": 2292.24,
      "text": " this is the basic problem.",
      "tokens": [
        50514,
        341,
        307,
        264,
        3875,
        1154,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3827369809150696,
      "compression_ratio": 1.5585585832595825,
      "no_speech_prob": 0.22978980839252472
    },
    {
      "id": 443,
      "seek": 108000,
      "start": 2292.24,
      "end": 2294.24,
      "text": " Actually, these code generators",
      "tokens": [
        50564,
        5135,
        11,
        613,
        3089,
        38662,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3827369809150696,
      "compression_ratio": 1.5585585832595825,
      "no_speech_prob": 0.22978980839252472
    },
    {
      "id": 444,
      "seek": 108000,
      "start": 2294.24,
      "end": 2295.24,
      "text": " are only sometimes useful",
      "tokens": [
        50664,
        366,
        787,
        2171,
        4420,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3827369809150696,
      "compression_ratio": 1.5585585832595825,
      "no_speech_prob": 0.22978980839252472
    },
    {
      "id": 445,
      "seek": 108000,
      "start": 2295.24,
      "end": 2296.24,
      "text": " for senior developer.",
      "tokens": [
        50714,
        337,
        7965,
        10754,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3827369809150696,
      "compression_ratio": 1.5585585832595825,
      "no_speech_prob": 0.22978980839252472
    },
    {
      "id": 446,
      "seek": 108000,
      "start": 2296.24,
      "end": 2300.24,
      "text": " You shouldn't get this tool.",
      "tokens": [
        50764,
        509,
        4659,
        380,
        483,
        341,
        2290,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3827369809150696,
      "compression_ratio": 1.5585585832595825,
      "no_speech_prob": 0.22978980839252472
    },
    {
      "id": 447,
      "seek": 108000,
      "start": 2303.24,
      "end": 2305.24,
      "text": " So actually my statement",
      "tokens": [
        51114,
        407,
        767,
        452,
        5629,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3827369809150696,
      "compression_ratio": 1.5585585832595825,
      "no_speech_prob": 0.22978980839252472
    },
    {
      "id": 448,
      "seek": 108000,
      "start": 2305.24,
      "end": 2307.24,
      "text": " is just that I should",
      "tokens": [
        51214,
        307,
        445,
        300,
        286,
        820,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3827369809150696,
      "compression_ratio": 1.5585585832595825,
      "no_speech_prob": 0.22978980839252472
    },
    {
      "id": 449,
      "seek": 108000,
      "start": 2307.24,
      "end": 2309.24,
      "text": " at least control it.",
      "tokens": [
        51314,
        412,
        1935,
        1969,
        309,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3827369809150696,
      "compression_ratio": 1.5585585832595825,
      "no_speech_prob": 0.22978980839252472
    },
    {
      "id": 450,
      "seek": 108000,
      "start": 2309.24,
      "end": 2310.24,
      "text": " And that somehow leads to",
      "tokens": [
        51414,
        400,
        300,
        6063,
        6689,
        281,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3827369809150696,
      "compression_ratio": 1.5585585832595825,
      "no_speech_prob": 0.22978980839252472
    },
    {
      "id": 451,
      "seek": 108000,
      "start": 2310.24,
      "end": 2311.24,
      "text": " the next question",
      "tokens": [
        51464,
        264,
        958,
        1168,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3827369809150696,
      "compression_ratio": 1.5585585832595825,
      "no_speech_prob": 0.22978980839252472
    },
    {
      "id": 452,
      "seek": 108000,
      "start": 2311.24,
      "end": 2313.24,
      "text": " whether I have a productivity advantage.",
      "tokens": [
        51514,
        1968,
        286,
        362,
        257,
        15604,
        5002,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3827369809150696,
      "compression_ratio": 1.5585585832595825,
      "no_speech_prob": 0.22978980839252472
    },
    {
      "id": 453,
      "seek": 108000,
      "start": 2313.24,
      "end": 2315.24,
      "text": " You have to somehow",
      "tokens": [
        51614,
        509,
        362,
        281,
        6063,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3827369809150696,
      "compression_ratio": 1.5585585832595825,
      "no_speech_prob": 0.22978980839252472
    },
    {
      "id": 454,
      "seek": 108000,
      "start": 2315.24,
      "end": 2317.24,
      "text": " lay down the cards.",
      "tokens": [
        51714,
        2360,
        760,
        264,
        5632,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3827369809150696,
      "compression_ratio": 1.5585585832595825,
      "no_speech_prob": 0.22978980839252472
    },
    {
      "id": 455,
      "seek": 110900,
      "start": 2317.24,
      "end": 2319.24,
      "text": " I can just ...",
      "tokens": [
        50364,
        286,
        393,
        445,
        1097,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3627430200576782,
      "compression_ratio": 1.6083333492279053,
      "no_speech_prob": 0.0707838386297226
    },
    {
      "id": 456,
      "seek": 110900,
      "start": 2319.24,
      "end": 2320.24,
      "text": " So exactly,",
      "tokens": [
        50464,
        407,
        2293,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3627430200576782,
      "compression_ratio": 1.6083333492279053,
      "no_speech_prob": 0.0707838386297226
    },
    {
      "id": 457,
      "seek": 110900,
      "start": 2320.24,
      "end": 2322.24,
      "text": " I should just briefly report",
      "tokens": [
        50514,
        286,
        820,
        445,
        10515,
        2275,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3627430200576782,
      "compression_ratio": 1.6083333492279053,
      "no_speech_prob": 0.0707838386297226
    },
    {
      "id": 458,
      "seek": 110900,
      "start": 2322.24,
      "end": 2324.24,
      "text": " on this other story.",
      "tokens": [
        50614,
        322,
        341,
        661,
        1657,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3627430200576782,
      "compression_ratio": 1.6083333492279053,
      "no_speech_prob": 0.0707838386297226
    },
    {
      "id": 459,
      "seek": 110900,
      "start": 2324.24,
      "end": 2327.24,
      "text": " We had Marco Emmerich,",
      "tokens": [
        50714,
        492,
        632,
        26535,
        3968,
        936,
        480,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3627430200576782,
      "compression_ratio": 1.6083333492279053,
      "no_speech_prob": 0.0707838386297226
    },
    {
      "id": 460,
      "seek": 110900,
      "start": 2327.24,
      "end": 2329.24,
      "text": " who was also on the stream here.",
      "tokens": [
        50864,
        567,
        390,
        611,
        322,
        264,
        4309,
        510,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3627430200576782,
      "compression_ratio": 1.6083333492279053,
      "no_speech_prob": 0.0707838386297226
    },
    {
      "id": 461,
      "seek": 110900,
      "start": 2329.24,
      "end": 2330.24,
      "text": " We had this conference",
      "tokens": [
        50964,
        492,
        632,
        341,
        7586,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3627430200576782,
      "compression_ratio": 1.6083333492279053,
      "no_speech_prob": 0.0707838386297226
    },
    {
      "id": 462,
      "seek": 110900,
      "start": 2330.24,
      "end": 2331.24,
      "text": " on the topic",
      "tokens": [
        51014,
        322,
        264,
        4829,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3627430200576782,
      "compression_ratio": 1.6083333492279053,
      "no_speech_prob": 0.0707838386297226
    },
    {
      "id": 463,
      "seek": 110900,
      "start": 2331.24,
      "end": 2333.24,
      "text": " of AI and software development.",
      "tokens": [
        51064,
        295,
        7318,
        293,
        4722,
        3250,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3627430200576782,
      "compression_ratio": 1.6083333492279053,
      "no_speech_prob": 0.0707838386297226
    },
    {
      "id": 464,
      "seek": 110900,
      "start": 2333.24,
      "end": 2335.24,
      "text": " We sat down and he kindly",
      "tokens": [
        51164,
        492,
        3227,
        760,
        293,
        415,
        29736,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3627430200576782,
      "compression_ratio": 1.6083333492279053,
      "no_speech_prob": 0.0707838386297226
    },
    {
      "id": 465,
      "seek": 110900,
      "start": 2335.24,
      "end": 2337.24,
      "text": " brought his cursor license",
      "tokens": [
        51264,
        3038,
        702,
        28169,
        10476,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3627430200576782,
      "compression_ratio": 1.6083333492279053,
      "no_speech_prob": 0.0707838386297226
    },
    {
      "id": 466,
      "seek": 110900,
      "start": 2337.24,
      "end": 2339.24,
      "text": " and then we built something",
      "tokens": [
        51364,
        293,
        550,
        321,
        3094,
        746,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3627430200576782,
      "compression_ratio": 1.6083333492279053,
      "no_speech_prob": 0.0707838386297226
    },
    {
      "id": 467,
      "seek": 110900,
      "start": 2339.24,
      "end": 2340.24,
      "text": " with the cursor.",
      "tokens": [
        51464,
        365,
        264,
        28169,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3627430200576782,
      "compression_ratio": 1.6083333492279053,
      "no_speech_prob": 0.0707838386297226
    },
    {
      "id": 468,
      "seek": 110900,
      "start": 2340.24,
      "end": 2342.24,
      "text": " We tried to build Game of Life.",
      "tokens": [
        51514,
        492,
        3031,
        281,
        1322,
        7522,
        295,
        7720,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3627430200576782,
      "compression_ratio": 1.6083333492279053,
      "no_speech_prob": 0.0707838386297226
    },
    {
      "id": 469,
      "seek": 110900,
      "start": 2342.24,
      "end": 2343.24,
      "text": " In fact, it's just",
      "tokens": [
        51614,
        682,
        1186,
        11,
        309,
        311,
        445,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3627430200576782,
      "compression_ratio": 1.6083333492279053,
      "no_speech_prob": 0.0707838386297226
    },
    {
      "id": 470,
      "seek": 110900,
      "start": 2343.24,
      "end": 2344.24,
      "text": " how I change.",
      "tokens": [
        51664,
        577,
        286,
        1319,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3627430200576782,
      "compression_ratio": 1.6083333492279053,
      "no_speech_prob": 0.0707838386297226
    },
    {
      "id": 471,
      "seek": 110900,
      "start": 2344.24,
      "end": 2345.24,
      "text": " And in fact, it's just",
      "tokens": [
        51714,
        400,
        294,
        1186,
        11,
        309,
        311,
        445,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3627430200576782,
      "compression_ratio": 1.6083333492279053,
      "no_speech_prob": 0.0707838386297226
    },
    {
      "id": 472,
      "seek": 113700,
      "start": 2345.24,
      "end": 2347.24,
      "text": " that we quickly came to",
      "tokens": [
        50364,
        300,
        321,
        2661,
        1361,
        281,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538338243961334,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.11994899809360504
    },
    {
      "id": 473,
      "seek": 113700,
      "start": 2347.24,
      "end": 2349.24,
      "text": " a result.",
      "tokens": [
        50464,
        257,
        1874,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538338243961334,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.11994899809360504
    },
    {
      "id": 474,
      "seek": 113700,
      "start": 2349.24,
      "end": 2351.24,
      "text": " And then we somehow",
      "tokens": [
        50564,
        400,
        550,
        321,
        6063,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538338243961334,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.11994899809360504
    },
    {
      "id": 475,
      "seek": 113700,
      "start": 2351.24,
      "end": 2353.24,
      "text": " got caught up in the discussion",
      "tokens": [
        50664,
        658,
        5415,
        493,
        294,
        264,
        5017,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538338243961334,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.11994899809360504
    },
    {
      "id": 476,
      "seek": 113700,
      "start": 2353.24,
      "end": 2354.24,
      "text": " about how reasonable",
      "tokens": [
        50764,
        466,
        577,
        10585,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538338243961334,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.11994899809360504
    },
    {
      "id": 477,
      "seek": 113700,
      "start": 2354.24,
      "end": 2356.24,
      "text": " exception handling actually works.",
      "tokens": [
        50814,
        11183,
        13175,
        767,
        1985,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538338243961334,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.11994899809360504
    },
    {
      "id": 478,
      "seek": 113700,
      "start": 2356.24,
      "end": 2359.24,
      "text": " And I would first claim",
      "tokens": [
        50914,
        400,
        286,
        576,
        700,
        3932,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538338243961334,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.11994899809360504
    },
    {
      "id": 479,
      "seek": 113700,
      "start": 2359.24,
      "end": 2361.24,
      "text": " that we have never built",
      "tokens": [
        51064,
        300,
        321,
        362,
        1128,
        3094,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538338243961334,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.11994899809360504
    },
    {
      "id": 480,
      "seek": 113700,
      "start": 2361.24,
      "end": 2362.24,
      "text": " a Game of Life so quickly.",
      "tokens": [
        51164,
        257,
        7522,
        295,
        7720,
        370,
        2661,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538338243961334,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.11994899809360504
    },
    {
      "id": 481,
      "seek": 113700,
      "start": 2362.24,
      "end": 2364.24,
      "text": " And I think you could also see",
      "tokens": [
        51214,
        400,
        286,
        519,
        291,
        727,
        611,
        536,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538338243961334,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.11994899809360504
    },
    {
      "id": 482,
      "seek": 113700,
      "start": 2364.24,
      "end": 2365.24,
      "text": " when you control it,",
      "tokens": [
        51314,
        562,
        291,
        1969,
        309,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538338243961334,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.11994899809360504
    },
    {
      "id": 483,
      "seek": 113700,
      "start": 2365.24,
      "end": 2367.24,
      "text": " that it is somehow reasonable.",
      "tokens": [
        51364,
        300,
        309,
        307,
        6063,
        10585,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538338243961334,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.11994899809360504
    },
    {
      "id": 484,
      "seek": 113700,
      "start": 2367.24,
      "end": 2369.24,
      "text": " I think the mistake",
      "tokens": [
        51464,
        286,
        519,
        264,
        6146,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538338243961334,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.11994899809360504
    },
    {
      "id": 485,
      "seek": 113700,
      "start": 2369.24,
      "end": 2371.24,
      "text": " we made",
      "tokens": [
        51564,
        321,
        1027,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538338243961334,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.11994899809360504
    },
    {
      "id": 486,
      "seek": 113700,
      "start": 2371.24,
      "end": 2373.24,
      "text": " is to zoom down",
      "tokens": [
        51664,
        307,
        281,
        8863,
        760,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538338243961334,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.11994899809360504
    },
    {
      "id": 487,
      "seek": 113700,
      "start": 2373.24,
      "end": 2374.24,
      "text": " on this technical thing",
      "tokens": [
        51764,
        322,
        341,
        6191,
        551,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3538338243961334,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.11994899809360504
    },
    {
      "id": 488,
      "seek": 116600,
      "start": 2374.24,
      "end": 2375.24,
      "text": " and we should have fixed that",
      "tokens": [
        50364,
        293,
        321,
        820,
        362,
        6806,
        300,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3507934808731079,
      "compression_ratio": 1.4772727489471436,
      "no_speech_prob": 0.11865339428186417
    },
    {
      "id": 489,
      "seek": 116600,
      "start": 2375.24,
      "end": 2377.24,
      "text": " at the beginning of the code.",
      "tokens": [
        50414,
        412,
        264,
        2863,
        295,
        264,
        3089,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3507934808731079,
      "compression_ratio": 1.4772727489471436,
      "no_speech_prob": 0.11865339428186417
    },
    {
      "id": 490,
      "seek": 116600,
      "start": 2377.24,
      "end": 2379.24,
      "text": " Which means",
      "tokens": [
        50514,
        3013,
        1355,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3507934808731079,
      "compression_ratio": 1.4772727489471436,
      "no_speech_prob": 0.11865339428186417
    },
    {
      "id": 491,
      "seek": 116600,
      "start": 2379.24,
      "end": 2381.24,
      "text": " that you should control it.",
      "tokens": [
        50614,
        300,
        291,
        820,
        1969,
        309,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3507934808731079,
      "compression_ratio": 1.4772727489471436,
      "no_speech_prob": 0.11865339428186417
    },
    {
      "id": 492,
      "seek": 116600,
      "start": 2381.24,
      "end": 2383.24,
      "text": " That would be my statement.",
      "tokens": [
        50714,
        663,
        576,
        312,
        452,
        5629,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3507934808731079,
      "compression_ratio": 1.4772727489471436,
      "no_speech_prob": 0.11865339428186417
    },
    {
      "id": 493,
      "seek": 116600,
      "start": 2383.24,
      "end": 2385.24,
      "text": " Whether this is only useful",
      "tokens": [
        50814,
        8503,
        341,
        307,
        787,
        4420,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3507934808731079,
      "compression_ratio": 1.4772727489471436,
      "no_speech_prob": 0.11865339428186417
    },
    {
      "id": 494,
      "seek": 116600,
      "start": 2385.24,
      "end": 2386.24,
      "text": " for 10 years now,",
      "tokens": [
        50914,
        337,
        1266,
        924,
        586,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3507934808731079,
      "compression_ratio": 1.4772727489471436,
      "no_speech_prob": 0.11865339428186417
    },
    {
      "id": 495,
      "seek": 116600,
      "start": 2386.24,
      "end": 2387.24,
      "text": " I don't know.",
      "tokens": [
        50964,
        286,
        500,
        380,
        458,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3507934808731079,
      "compression_ratio": 1.4772727489471436,
      "no_speech_prob": 0.11865339428186417
    },
    {
      "id": 496,
      "seek": 116600,
      "start": 2387.24,
      "end": 2388.24,
      "text": " So it says",
      "tokens": [
        51014,
        407,
        309,
        1619,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3507934808731079,
      "compression_ratio": 1.4772727489471436,
      "no_speech_prob": 0.11865339428186417
    },
    {
      "id": 497,
      "seek": 116600,
      "start": 2388.24,
      "end": 2389.24,
      "text": " you have to be able to control it.",
      "tokens": [
        51064,
        291,
        362,
        281,
        312,
        1075,
        281,
        1969,
        309,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3507934808731079,
      "compression_ratio": 1.4772727489471436,
      "no_speech_prob": 0.11865339428186417
    },
    {
      "id": 498,
      "seek": 116600,
      "start": 2389.24,
      "end": 2390.24,
      "text": " And I spend,",
      "tokens": [
        51114,
        400,
        286,
        3496,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3507934808731079,
      "compression_ratio": 1.4772727489471436,
      "no_speech_prob": 0.11865339428186417
    },
    {
      "id": 499,
      "seek": 116600,
      "start": 2390.24,
      "end": 2391.24,
      "text": " when I do AI,",
      "tokens": [
        51164,
        562,
        286,
        360,
        7318,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3507934808731079,
      "compression_ratio": 1.4772727489471436,
      "no_speech_prob": 0.11865339428186417
    },
    {
      "id": 0,
      "seek": 0,
      "start": 2406.46,
      "end": 2408.46,
      "text": " I don't think that's a bad thing.",
      "tokens": [
        50364,
        286,
        500,
        380,
        519,
        300,
        311,
        257,
        1578,
        551,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5916056632995605,
      "compression_ratio": 1.524999976158142,
      "no_speech_prob": 0.9013763070106506
    },
    {
      "id": 1,
      "seek": 0,
      "start": 2408.46,
      "end": 2410.46,
      "text": " On the other hand, I have to admit,",
      "tokens": [
        50464,
        1282,
        264,
        661,
        1011,
        11,
        286,
        362,
        281,
        9796,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5916056632995605,
      "compression_ratio": 1.524999976158142,
      "no_speech_prob": 0.9013763070106506
    },
    {
      "id": 2,
      "seek": 0,
      "start": 2410.46,
      "end": 2418.46,
      "text": " I wouldn't seriously start a TypeScript project without something like Cursor or ChitchuPT,",
      "tokens": [
        50564,
        286,
        2759,
        380,
        6638,
        722,
        257,
        15576,
        14237,
        1716,
        1553,
        746,
        411,
        383,
        2156,
        284,
        420,
        761,
        1549,
        84,
        47,
        51,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5916056632995605,
      "compression_ratio": 1.524999976158142,
      "no_speech_prob": 0.9013763070106506
    },
    {
      "id": 3,
      "seek": 0,
      "start": 2418.46,
      "end": 2422.46,
      "text": " because otherwise I would have to learn TypeScript first and so on.",
      "tokens": [
        50964,
        570,
        5911,
        286,
        576,
        362,
        281,
        1466,
        15576,
        14237,
        700,
        293,
        370,
        322,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5916056632995605,
      "compression_ratio": 1.524999976158142,
      "no_speech_prob": 0.9013763070106506
    },
    {
      "id": 4,
      "seek": 0,
      "start": 2422.46,
      "end": 2431.46,
      "text": " And I have also learned for myself that with this tool I think I am able to",
      "tokens": [
        51164,
        400,
        286,
        362,
        611,
        3264,
        337,
        2059,
        300,
        365,
        341,
        2290,
        286,
        519,
        286,
        669,
        1075,
        281,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5916056632995605,
      "compression_ratio": 1.524999976158142,
      "no_speech_prob": 0.9013763070106506
    },
    {
      "id": 5,
      "seek": 2500,
      "start": 2431.46,
      "end": 2437.46,
      "text": " implement TypeScript quite productively,",
      "tokens": [
        50364,
        4445,
        15576,
        14237,
        1596,
        1674,
        3413,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5304168462753296,
      "compression_ratio": 1.5532786846160889,
      "no_speech_prob": 0.14898189902305603
    },
    {
      "id": 6,
      "seek": 2500,
      "start": 2437.46,
      "end": 2441.46,
      "text": " because in the end it's just a programming language with curly braces",
      "tokens": [
        50664,
        570,
        294,
        264,
        917,
        309,
        311,
        445,
        257,
        9410,
        2856,
        365,
        32066,
        41537,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5304168462753296,
      "compression_ratio": 1.5532786846160889,
      "no_speech_prob": 0.14898189902305603
    },
    {
      "id": 7,
      "seek": 2500,
      "start": 2441.46,
      "end": 2444.46,
      "text": " and on a certain level I can manage it somehow.",
      "tokens": [
        50864,
        293,
        322,
        257,
        1629,
        1496,
        286,
        393,
        3067,
        309,
        6063,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5304168462753296,
      "compression_ratio": 1.5532786846160889,
      "no_speech_prob": 0.14898189902305603
    },
    {
      "id": 8,
      "seek": 2500,
      "start": 2444.46,
      "end": 2448.46,
      "text": " OctaneMan writes,",
      "tokens": [
        51014,
        6788,
        1929,
        6652,
        13657,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5304168462753296,
      "compression_ratio": 1.5532786846160889,
      "no_speech_prob": 0.14898189902305603
    },
    {
      "id": 9,
      "seek": 2500,
      "start": 2448.46,
      "end": 2450.46,
      "text": " the productivity advantage can also be spoken of nicely",
      "tokens": [
        51214,
        264,
        15604,
        5002,
        393,
        611,
        312,
        10759,
        295,
        9594,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5304168462753296,
      "compression_ratio": 1.5532786846160889,
      "no_speech_prob": 0.14898189902305603
    },
    {
      "id": 10,
      "seek": 2500,
      "start": 2450.46,
      "end": 2453.46,
      "text": " if management, the real quality, doesn't matter.",
      "tokens": [
        51314,
        498,
        4592,
        11,
        264,
        957,
        3125,
        11,
        1177,
        380,
        1871,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5304168462753296,
      "compression_ratio": 1.5532786846160889,
      "no_speech_prob": 0.14898189902305603
    },
    {
      "id": 11,
      "seek": 2500,
      "start": 2453.46,
      "end": 2456.46,
      "text": " It's just not really sustainable and may cause false security.",
      "tokens": [
        51464,
        467,
        311,
        445,
        406,
        534,
        11235,
        293,
        815,
        3082,
        7908,
        3825,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5304168462753296,
      "compression_ratio": 1.5532786846160889,
      "no_speech_prob": 0.14898189902305603
    },
    {
      "id": 12,
      "seek": 2500,
      "start": 2456.46,
      "end": 2459.46,
      "text": " And that's what I'm trying to say.",
      "tokens": [
        51614,
        400,
        300,
        311,
        437,
        286,
        478,
        1382,
        281,
        584,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5304168462753296,
      "compression_ratio": 1.5532786846160889,
      "no_speech_prob": 0.14898189902305603
    },
    {
      "id": 13,
      "seek": 5300,
      "start": 2459.46,
      "end": 2462.46,
      "text": " What Christian just said,",
      "tokens": [
        50364,
        708,
        5778,
        445,
        848,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41020631790161133,
      "compression_ratio": 1.5934579372406006,
      "no_speech_prob": 0.4022117555141449
    },
    {
      "id": 14,
      "seek": 5300,
      "start": 2462.46,
      "end": 2468.46,
      "text": " our problems are often code bases that are old and that no one understands.",
      "tokens": [
        50514,
        527,
        2740,
        366,
        2049,
        3089,
        17949,
        300,
        366,
        1331,
        293,
        300,
        572,
        472,
        15146,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41020631790161133,
      "compression_ratio": 1.5934579372406006,
      "no_speech_prob": 0.4022117555141449
    },
    {
      "id": 15,
      "seek": 5300,
      "start": 2468.46,
      "end": 2472.46,
      "text": " That will probably, I would now introduce it as a thesis,",
      "tokens": [
        50814,
        663,
        486,
        1391,
        11,
        286,
        576,
        586,
        5366,
        309,
        382,
        257,
        22288,
        11,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41020631790161133,
      "compression_ratio": 1.5934579372406006,
      "no_speech_prob": 0.4022117555141449
    },
    {
      "id": 16,
      "seek": 5300,
      "start": 2472.46,
      "end": 2476.46,
      "text": " get worse if we just massively rely on these tools.",
      "tokens": [
        51014,
        483,
        5324,
        498,
        321,
        445,
        29379,
        10687,
        322,
        613,
        3873,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41020631790161133,
      "compression_ratio": 1.5934579372406006,
      "no_speech_prob": 0.4022117555141449
    },
    {
      "id": 17,
      "seek": 5300,
      "start": 2476.46,
      "end": 2478.46,
      "text": " And that's just a problem.",
      "tokens": [
        51214,
        400,
        300,
        311,
        445,
        257,
        1154,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41020631790161133,
      "compression_ratio": 1.5934579372406006,
      "no_speech_prob": 0.4022117555141449
    },
    {
      "id": 18,
      "seek": 5300,
      "start": 2478.46,
      "end": 2482.46,
      "text": " And it's also impressive how much trust there is,",
      "tokens": [
        51314,
        400,
        309,
        311,
        611,
        8992,
        577,
        709,
        3361,
        456,
        307,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41020631790161133,
      "compression_ratio": 1.5934579372406006,
      "no_speech_prob": 0.4022117555141449
    },
    {
      "id": 19,
      "seek": 5300,
      "start": 2482.46,
      "end": 2486.46,
      "text": " although it's just somehow difficult in many places.",
      "tokens": [
        51514,
        4878,
        309,
        311,
        445,
        6063,
        2252,
        294,
        867,
        3190,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41020631790161133,
      "compression_ratio": 1.5934579372406006,
      "no_speech_prob": 0.4022117555141449
    },
    {
      "id": 20,
      "seek": 8000,
      "start": 2487.46,
      "end": 2488.46,
      "text": " Oh, right.",
      "tokens": [
        50414,
        876,
        11,
        558,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43297022581100464,
      "compression_ratio": 1.5364583730697632,
      "no_speech_prob": 0.07025984674692154
    },
    {
      "id": 21,
      "seek": 8000,
      "start": 2488.46,
      "end": 2490.46,
      "text": " And I can tell this other story,",
      "tokens": [
        50464,
        400,
        286,
        393,
        980,
        341,
        661,
        1657,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43297022581100464,
      "compression_ratio": 1.5364583730697632,
      "no_speech_prob": 0.07025984674692154
    },
    {
      "id": 22,
      "seek": 8000,
      "start": 2490.46,
      "end": 2492.46,
      "text": " which I find very exciting.",
      "tokens": [
        50564,
        597,
        286,
        915,
        588,
        4670,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43297022581100464,
      "compression_ratio": 1.5364583730697632,
      "no_speech_prob": 0.07025984674692154
    },
    {
      "id": 23,
      "seek": 8000,
      "start": 2492.46,
      "end": 2496.46,
      "text": " Ralf has set himself up nicely and makes transcripts,",
      "tokens": [
        50664,
        497,
        1678,
        575,
        992,
        3647,
        493,
        9594,
        293,
        1669,
        24444,
        82,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43297022581100464,
      "compression_ratio": 1.5364583730697632,
      "no_speech_prob": 0.07025984674692154
    },
    {
      "id": 24,
      "seek": 8000,
      "start": 2496.46,
      "end": 2501.46,
      "text": " has built a system with which our contributions are transcribed.",
      "tokens": [
        50864,
        575,
        3094,
        257,
        1185,
        365,
        597,
        527,
        15725,
        366,
        1145,
        18732,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43297022581100464,
      "compression_ratio": 1.5364583730697632,
      "no_speech_prob": 0.07025984674692154
    },
    {
      "id": 25,
      "seek": 8000,
      "start": 2501.46,
      "end": 2505.46,
      "text": " And there was this almost ironic story",
      "tokens": [
        51114,
        400,
        456,
        390,
        341,
        1920,
        33719,
        1657,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43297022581100464,
      "compression_ratio": 1.5364583730697632,
      "no_speech_prob": 0.07025984674692154
    },
    {
      "id": 26,
      "seek": 8000,
      "start": 2505.46,
      "end": 2513.46,
      "text": " that in a transcript ChitchuPT has not been properly transcribed.",
      "tokens": [
        51314,
        300,
        294,
        257,
        24444,
        761,
        1549,
        84,
        47,
        51,
        575,
        406,
        668,
        6108,
        1145,
        18732,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43297022581100464,
      "compression_ratio": 1.5364583730697632,
      "no_speech_prob": 0.07025984674692154
    },
    {
      "id": 27,
      "seek": 10700,
      "start": 2514.46,
      "end": 2519.46,
      "text": " So there are some other terms that have been understood,",
      "tokens": [
        50414,
        407,
        456,
        366,
        512,
        661,
        2115,
        300,
        362,
        668,
        7320,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.345633864402771,
      "compression_ratio": 1.5138121843338013,
      "no_speech_prob": 0.10723836719989777
    },
    {
      "id": 28,
      "seek": 10700,
      "start": 2519.46,
      "end": 2525.46,
      "text": " because ChitchuPT is not in the vocabulary of this transcriptor.",
      "tokens": [
        50664,
        570,
        761,
        1549,
        84,
        47,
        51,
        307,
        406,
        294,
        264,
        19864,
        295,
        341,
        24444,
        284,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.345633864402771,
      "compression_ratio": 1.5138121843338013,
      "no_speech_prob": 0.10723836719989777
    },
    {
      "id": 29,
      "seek": 10700,
      "start": 2525.46,
      "end": 2529.46,
      "text": " And that's a bit bad for the transcripts,",
      "tokens": [
        50964,
        400,
        300,
        311,
        257,
        857,
        1578,
        337,
        264,
        24444,
        82,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.345633864402771,
      "compression_ratio": 1.5138121843338013,
      "no_speech_prob": 0.10723836719989777
    },
    {
      "id": 30,
      "seek": 10700,
      "start": 2529.46,
      "end": 2532.46,
      "text": " because we don't control them.",
      "tokens": [
        51164,
        570,
        321,
        500,
        380,
        1969,
        552,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.345633864402771,
      "compression_ratio": 1.5138121843338013,
      "no_speech_prob": 0.10723836719989777
    },
    {
      "id": 31,
      "seek": 10700,
      "start": 2532.46,
      "end": 2535.46,
      "text": " So Martina sat down and checked an episode.",
      "tokens": [
        51314,
        407,
        5807,
        1426,
        3227,
        760,
        293,
        10033,
        364,
        3500,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.345633864402771,
      "compression_ratio": 1.5138121843338013,
      "no_speech_prob": 0.10723836719989777
    },
    {
      "id": 32,
      "seek": 10700,
      "start": 2535.46,
      "end": 2539.46,
      "text": " But we probably won't control that.",
      "tokens": [
        51464,
        583,
        321,
        1391,
        1582,
        380,
        1969,
        300,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.345633864402771,
      "compression_ratio": 1.5138121843338013,
      "no_speech_prob": 0.10723836719989777
    },
    {
      "id": 33,
      "seek": 13300,
      "start": 2540.46,
      "end": 2542.46,
      "text": " And with that we break through the concept,",
      "tokens": [
        50414,
        400,
        365,
        300,
        321,
        1821,
        807,
        264,
        3410,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3882122337818146,
      "compression_ratio": 1.52212393283844,
      "no_speech_prob": 0.5070717930793762
    },
    {
      "id": 34,
      "seek": 13300,
      "start": 2542.46,
      "end": 2546.46,
      "text": " what I'm actually asking for.",
      "tokens": [
        50514,
        437,
        286,
        478,
        767,
        3365,
        337,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3882122337818146,
      "compression_ratio": 1.52212393283844,
      "no_speech_prob": 0.5070717930793762
    },
    {
      "id": 35,
      "seek": 13300,
      "start": 2546.46,
      "end": 2548.46,
      "text": " It somehow comes down to the fact that",
      "tokens": [
        50714,
        467,
        6063,
        1487,
        760,
        281,
        264,
        1186,
        300,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3882122337818146,
      "compression_ratio": 1.52212393283844,
      "no_speech_prob": 0.5070717930793762
    },
    {
      "id": 36,
      "seek": 13300,
      "start": 2548.46,
      "end": 2551.46,
      "text": " I think it's good for barrier-free to have a transcript.",
      "tokens": [
        50814,
        286,
        519,
        309,
        311,
        665,
        337,
        13357,
        12,
        10792,
        281,
        362,
        257,
        24444,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3882122337818146,
      "compression_ratio": 1.52212393283844,
      "no_speech_prob": 0.5070717930793762
    },
    {
      "id": 37,
      "seek": 13300,
      "start": 2551.46,
      "end": 2556.46,
      "text": " And I'd rather have a transcript,",
      "tokens": [
        50964,
        400,
        286,
        1116,
        2831,
        362,
        257,
        24444,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3882122337818146,
      "compression_ratio": 1.52212393283844,
      "no_speech_prob": 0.5070717930793762
    },
    {
      "id": 38,
      "seek": 13300,
      "start": 2556.46,
      "end": 2558.46,
      "text": " which is not perfect, than none at all.",
      "tokens": [
        51214,
        597,
        307,
        406,
        2176,
        11,
        813,
        6022,
        412,
        439,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3882122337818146,
      "compression_ratio": 1.52212393283844,
      "no_speech_prob": 0.5070717930793762
    },
    {
      "id": 39,
      "seek": 13300,
      "start": 2558.46,
      "end": 2561.46,
      "text": " That's the trade-off.",
      "tokens": [
        51314,
        663,
        311,
        264,
        4923,
        12,
        4506,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3882122337818146,
      "compression_ratio": 1.52212393283844,
      "no_speech_prob": 0.5070717930793762
    },
    {
      "id": 40,
      "seek": 13300,
      "start": 2561.46,
      "end": 2564.46,
      "text": " You can discuss that, of course.",
      "tokens": [
        51464,
        509,
        393,
        2248,
        300,
        11,
        295,
        1164,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3882122337818146,
      "compression_ratio": 1.52212393283844,
      "no_speech_prob": 0.5070717930793762
    },
    {
      "id": 41,
      "seek": 13300,
      "start": 2564.46,
      "end": 2567.46,
      "text": " That's why I find it exciting with ChitchuPT.",
      "tokens": [
        51614,
        663,
        311,
        983,
        286,
        915,
        309,
        4670,
        365,
        761,
        1549,
        84,
        47,
        51,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3882122337818146,
      "compression_ratio": 1.52212393283844,
      "no_speech_prob": 0.5070717930793762
    },
    {
      "id": 42,
      "seek": 16100,
      "start": 2567.46,
      "end": 2571.46,
      "text": " Because that means that the term ChitchuPT does not appear in the transcript,",
      "tokens": [
        50364,
        1436,
        300,
        1355,
        300,
        264,
        1433,
        761,
        1549,
        84,
        47,
        51,
        775,
        406,
        4204,
        294,
        264,
        24444,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29131561517715454,
      "compression_ratio": 1.9740259647369385,
      "no_speech_prob": 0.11927638202905655
    },
    {
      "id": 43,
      "seek": 16100,
      "start": 2571.46,
      "end": 2574.46,
      "text": " although I have mentioned it several times.",
      "tokens": [
        50564,
        4878,
        286,
        362,
        2835,
        309,
        2940,
        1413,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29131561517715454,
      "compression_ratio": 1.9740259647369385,
      "no_speech_prob": 0.11927638202905655
    },
    {
      "id": 44,
      "seek": 16100,
      "start": 2574.46,
      "end": 2578.46,
      "text": " Which means that in the summary, which is based on the transcript,",
      "tokens": [
        50714,
        3013,
        1355,
        300,
        294,
        264,
        12691,
        11,
        597,
        307,
        2361,
        322,
        264,
        24444,
        11,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29131561517715454,
      "compression_ratio": 1.9740259647369385,
      "no_speech_prob": 0.11927638202905655
    },
    {
      "id": 45,
      "seek": 16100,
      "start": 2578.46,
      "end": 2581.46,
      "text": " the term ChitchuPT cannot appear either,",
      "tokens": [
        50914,
        264,
        1433,
        761,
        1549,
        84,
        47,
        51,
        2644,
        4204,
        2139,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29131561517715454,
      "compression_ratio": 1.9740259647369385,
      "no_speech_prob": 0.11927638202905655
    },
    {
      "id": 46,
      "seek": 16100,
      "start": 2581.46,
      "end": 2583.46,
      "text": " because it does not appear in the transcript.",
      "tokens": [
        51064,
        570,
        309,
        775,
        406,
        4204,
        294,
        264,
        24444,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29131561517715454,
      "compression_ratio": 1.9740259647369385,
      "no_speech_prob": 0.11927638202905655
    },
    {
      "id": 47,
      "seek": 16100,
      "start": 2583.46,
      "end": 2586.46,
      "text": " And it has actually been transcribed differently.",
      "tokens": [
        51164,
        400,
        309,
        575,
        767,
        668,
        1145,
        18732,
        7614,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29131561517715454,
      "compression_ratio": 1.9740259647369385,
      "no_speech_prob": 0.11927638202905655
    },
    {
      "id": 48,
      "seek": 16100,
      "start": 2586.46,
      "end": 2588.46,
      "text": " So it's not that it's a constant error,",
      "tokens": [
        51314,
        407,
        309,
        311,
        406,
        300,
        309,
        311,
        257,
        5754,
        6713,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29131561517715454,
      "compression_ratio": 1.9740259647369385,
      "no_speech_prob": 0.11927638202905655
    },
    {
      "id": 49,
      "seek": 16100,
      "start": 2588.46,
      "end": 2591.46,
      "text": " but it's just different transcripts.",
      "tokens": [
        51414,
        457,
        309,
        311,
        445,
        819,
        24444,
        82,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29131561517715454,
      "compression_ratio": 1.9740259647369385,
      "no_speech_prob": 0.11927638202905655
    },
    {
      "id": 50,
      "seek": 16100,
      "start": 2591.46,
      "end": 2594.46,
      "text": " And that means that we actually have a problem there.",
      "tokens": [
        51564,
        400,
        300,
        1355,
        300,
        321,
        767,
        362,
        257,
        1154,
        456,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29131561517715454,
      "compression_ratio": 1.9740259647369385,
      "no_speech_prob": 0.11927638202905655
    },
    {
      "id": 51,
      "seek": 18800,
      "start": 2595.46,
      "end": 2600.46,
      "text": " It's just that certain other summaries were also erroneous.",
      "tokens": [
        50414,
        467,
        311,
        445,
        300,
        1629,
        661,
        8367,
        4889,
        645,
        611,
        1189,
        26446,
        563,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36371126770973206,
      "compression_ratio": 1.6192660331726074,
      "no_speech_prob": 0.20112711191177368
    },
    {
      "id": 52,
      "seek": 18800,
      "start": 2600.46,
      "end": 2602.46,
      "text": " I could somehow correct that.",
      "tokens": [
        50664,
        286,
        727,
        6063,
        3006,
        300,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36371126770973206,
      "compression_ratio": 1.6192660331726074,
      "no_speech_prob": 0.20112711191177368
    },
    {
      "id": 53,
      "seek": 18800,
      "start": 2602.46,
      "end": 2604.46,
      "text": " I wouldn't have a chance there.",
      "tokens": [
        50764,
        286,
        2759,
        380,
        362,
        257,
        2931,
        456,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36371126770973206,
      "compression_ratio": 1.6192660331726074,
      "no_speech_prob": 0.20112711191177368
    },
    {
      "id": 54,
      "seek": 18800,
      "start": 2604.46,
      "end": 2606.46,
      "text": " So ChitchuPT wasn't important enough",
      "tokens": [
        50864,
        407,
        761,
        1549,
        84,
        47,
        51,
        2067,
        380,
        1021,
        1547,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36371126770973206,
      "compression_ratio": 1.6192660331726074,
      "no_speech_prob": 0.20112711191177368
    },
    {
      "id": 55,
      "seek": 18800,
      "start": 2606.46,
      "end": 2610.46,
      "text": " that it would have been worth mentioning in the summary.",
      "tokens": [
        50964,
        300,
        309,
        576,
        362,
        668,
        3163,
        18315,
        294,
        264,
        12691,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36371126770973206,
      "compression_ratio": 1.6192660331726074,
      "no_speech_prob": 0.20112711191177368
    },
    {
      "id": 56,
      "seek": 18800,
      "start": 2610.46,
      "end": 2614.46,
      "text": " But if it had been so, it wouldn't have appeared there,",
      "tokens": [
        51164,
        583,
        498,
        309,
        632,
        668,
        370,
        11,
        309,
        2759,
        380,
        362,
        8516,
        456,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36371126770973206,
      "compression_ratio": 1.6192660331726074,
      "no_speech_prob": 0.20112711191177368
    },
    {
      "id": 57,
      "seek": 18800,
      "start": 2614.46,
      "end": 2617.46,
      "text": " because it had already been subjugated in the transcript,",
      "tokens": [
        51364,
        570,
        309,
        632,
        1217,
        668,
        1422,
        42068,
        770,
        294,
        264,
        24444,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36371126770973206,
      "compression_ratio": 1.6192660331726074,
      "no_speech_prob": 0.20112711191177368
    },
    {
      "id": 58,
      "seek": 18800,
      "start": 2617.46,
      "end": 2619.46,
      "text": " which we don't control.",
      "tokens": [
        51514,
        597,
        321,
        500,
        380,
        1969,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36371126770973206,
      "compression_ratio": 1.6192660331726074,
      "no_speech_prob": 0.20112711191177368
    },
    {
      "id": 59,
      "seek": 21300,
      "start": 2620.46,
      "end": 2622.46,
      "text": " T. Martin writes,",
      "tokens": [
        50414,
        314,
        13,
        9184,
        13657,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750017583370209,
      "compression_ratio": 1.5897436141967773,
      "no_speech_prob": 0.716895341873169
    },
    {
      "id": 60,
      "seek": 21300,
      "start": 2622.46,
      "end": 2624.46,
      "text": " as with all processes,",
      "tokens": [
        50514,
        382,
        365,
        439,
        7555,
        11,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750017583370209,
      "compression_ratio": 1.5897436141967773,
      "no_speech_prob": 0.716895341873169
    },
    {
      "id": 61,
      "seek": 21300,
      "start": 2624.46,
      "end": 2627.46,
      "text": " not according to seniority or non-seniority,",
      "tokens": [
        50614,
        406,
        4650,
        281,
        7965,
        507,
        420,
        2107,
        12,
        6748,
        1973,
        507,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750017583370209,
      "compression_ratio": 1.5897436141967773,
      "no_speech_prob": 0.716895341873169
    },
    {
      "id": 62,
      "seek": 21300,
      "start": 2627.46,
      "end": 2629.46,
      "text": " but according to application competence,",
      "tokens": [
        50764,
        457,
        4650,
        281,
        3861,
        39965,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750017583370209,
      "compression_ratio": 1.5897436141967773,
      "no_speech_prob": 0.716895341873169
    },
    {
      "id": 63,
      "seek": 21300,
      "start": 2629.46,
      "end": 2632.46,
      "text": " also for senior devs, who probably succeeded as juniors.",
      "tokens": [
        50864,
        611,
        337,
        7965,
        220,
        1479,
        36959,
        11,
        567,
        1391,
        20263,
        382,
        8156,
        9337,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750017583370209,
      "compression_ratio": 1.5897436141967773,
      "no_speech_prob": 0.716895341873169
    },
    {
      "id": 64,
      "seek": 21300,
      "start": 2632.46,
      "end": 2633.46,
      "text": " Exactly.",
      "tokens": [
        51014,
        7587,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750017583370209,
      "compression_ratio": 1.5897436141967773,
      "no_speech_prob": 0.716895341873169
    },
    {
      "id": 65,
      "seek": 21300,
      "start": 2633.46,
      "end": 2636.46,
      "text": " But that's a bit of a definition of senior devs, isn't it?",
      "tokens": [
        51064,
        583,
        300,
        311,
        257,
        857,
        295,
        257,
        7123,
        295,
        7965,
        1905,
        82,
        11,
        1943,
        380,
        309,
        30,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750017583370209,
      "compression_ratio": 1.5897436141967773,
      "no_speech_prob": 0.716895341873169
    },
    {
      "id": 66,
      "seek": 21300,
      "start": 2636.46,
      "end": 2639.46,
      "text": " So I hope they have more competence there.",
      "tokens": [
        51214,
        407,
        286,
        1454,
        436,
        362,
        544,
        39965,
        456,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750017583370209,
      "compression_ratio": 1.5897436141967773,
      "no_speech_prob": 0.716895341873169
    },
    {
      "id": 67,
      "seek": 21300,
      "start": 2639.46,
      "end": 2641.46,
      "text": " We still have a little time.",
      "tokens": [
        51364,
        492,
        920,
        362,
        257,
        707,
        565,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750017583370209,
      "compression_ratio": 1.5897436141967773,
      "no_speech_prob": 0.716895341873169
    },
    {
      "id": 68,
      "seek": 21300,
      "start": 2641.46,
      "end": 2645.46,
      "text": " I want to go back to another topic for a moment.",
      "tokens": [
        51464,
        286,
        528,
        281,
        352,
        646,
        281,
        1071,
        4829,
        337,
        257,
        1623,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3750017583370209,
      "compression_ratio": 1.5897436141967773,
      "no_speech_prob": 0.716895341873169
    },
    {
      "id": 69,
      "seek": 23900,
      "start": 2646.46,
      "end": 2650.46,
      "text": " There is an article by Luke Burling.",
      "tokens": [
        50414,
        821,
        307,
        364,
        7222,
        538,
        13044,
        7031,
        1688,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3002654016017914,
      "compression_ratio": 1.5199999809265137,
      "no_speech_prob": 0.15951500833034515
    },
    {
      "id": 70,
      "seek": 23900,
      "start": 2650.46,
      "end": 2655.46,
      "text": " He used gaslighting as an attack against an LLM.",
      "tokens": [
        50614,
        634,
        1143,
        4211,
        2764,
        278,
        382,
        364,
        2690,
        1970,
        364,
        441,
        43,
        44,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3002654016017914,
      "compression_ratio": 1.5199999809265137,
      "no_speech_prob": 0.15951500833034515
    },
    {
      "id": 71,
      "seek": 23900,
      "start": 2655.46,
      "end": 2658.46,
      "text": " Gaslighting is something where you deceive people about reality.",
      "tokens": [
        50864,
        24025,
        2764,
        278,
        307,
        746,
        689,
        291,
        43440,
        561,
        466,
        4103,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3002654016017914,
      "compression_ratio": 1.5199999809265137,
      "no_speech_prob": 0.15951500833034515
    },
    {
      "id": 72,
      "seek": 23900,
      "start": 2658.46,
      "end": 2660.46,
      "text": " So it's a psychological thing.",
      "tokens": [
        51014,
        407,
        309,
        311,
        257,
        14346,
        551,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3002654016017914,
      "compression_ratio": 1.5199999809265137,
      "no_speech_prob": 0.15951500833034515
    },
    {
      "id": 73,
      "seek": 23900,
      "start": 2660.46,
      "end": 2665.46,
      "text": " And then it leads to something not strange to do.",
      "tokens": [
        51114,
        400,
        550,
        309,
        6689,
        281,
        746,
        406,
        5861,
        281,
        360,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3002654016017914,
      "compression_ratio": 1.5199999809265137,
      "no_speech_prob": 0.15951500833034515
    },
    {
      "id": 74,
      "seek": 23900,
      "start": 2665.46,
      "end": 2668.46,
      "text": " And he used it as an example",
      "tokens": [
        51364,
        400,
        415,
        1143,
        309,
        382,
        364,
        1365,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3002654016017914,
      "compression_ratio": 1.5199999809265137,
      "no_speech_prob": 0.15951500833034515
    },
    {
      "id": 75,
      "seek": 23900,
      "start": 2668.46,
      "end": 2672.46,
      "text": " that the construction of Molotov cocktails,",
      "tokens": [
        51514,
        300,
        264,
        6435,
        295,
        28278,
        310,
        5179,
        49006,
        11,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3002654016017914,
      "compression_ratio": 1.5199999809265137,
      "no_speech_prob": 0.15951500833034515
    },
    {
      "id": 76,
      "seek": 26600,
      "start": 2672.46,
      "end": 2675.46,
      "text": " which Chachabiti otherwise does not issue,",
      "tokens": [
        50364,
        597,
        761,
        608,
        455,
        270,
        72,
        5911,
        775,
        406,
        2734,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4272177219390869,
      "compression_ratio": 1.6886792182922363,
      "no_speech_prob": 0.1815866380929947
    },
    {
      "id": 77,
      "seek": 26600,
      "start": 2675.46,
      "end": 2678.46,
      "text": " that you somehow get it out of there.",
      "tokens": [
        50514,
        300,
        291,
        6063,
        483,
        309,
        484,
        295,
        456,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4272177219390869,
      "compression_ratio": 1.6886792182922363,
      "no_speech_prob": 0.1815866380929947
    },
    {
      "id": 78,
      "seek": 26600,
      "start": 2678.46,
      "end": 2683.46,
      "text": " First of all, I think that's a totally valid thing.",
      "tokens": [
        50664,
        2386,
        295,
        439,
        11,
        286,
        519,
        300,
        311,
        257,
        3879,
        7363,
        551,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4272177219390869,
      "compression_ratio": 1.6886792182922363,
      "no_speech_prob": 0.1815866380929947
    },
    {
      "id": 79,
      "seek": 26600,
      "start": 2683.46,
      "end": 2686.46,
      "text": " It's a scientific thing, a scientific experiment.",
      "tokens": [
        50914,
        467,
        311,
        257,
        8134,
        551,
        11,
        257,
        8134,
        5120,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4272177219390869,
      "compression_ratio": 1.6886792182922363,
      "no_speech_prob": 0.1815866380929947
    },
    {
      "id": 80,
      "seek": 26600,
      "start": 2686.46,
      "end": 2689.46,
      "text": " I find it totally exciting, I find it interesting",
      "tokens": [
        51064,
        286,
        915,
        309,
        3879,
        4670,
        11,
        286,
        915,
        309,
        1880,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4272177219390869,
      "compression_ratio": 1.6886792182922363,
      "no_speech_prob": 0.1815866380929947
    },
    {
      "id": 81,
      "seek": 26600,
      "start": 2689.46,
      "end": 2691.46,
      "text": " that something like that somehow works",
      "tokens": [
        51214,
        300,
        746,
        411,
        300,
        6063,
        1985,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4272177219390869,
      "compression_ratio": 1.6886792182922363,
      "no_speech_prob": 0.1815866380929947
    },
    {
      "id": 82,
      "seek": 26600,
      "start": 2691.46,
      "end": 2693.46,
      "text": " and that you get results.",
      "tokens": [
        51314,
        293,
        300,
        291,
        483,
        3542,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4272177219390869,
      "compression_ratio": 1.6886792182922363,
      "no_speech_prob": 0.1815866380929947
    },
    {
      "id": 83,
      "seek": 26600,
      "start": 2693.46,
      "end": 2696.46,
      "text": " He had a dialogue, so to speak,",
      "tokens": [
        51414,
        634,
        632,
        257,
        10221,
        11,
        370,
        281,
        1710,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4272177219390869,
      "compression_ratio": 1.6886792182922363,
      "no_speech_prob": 0.1815866380929947
    },
    {
      "id": 84,
      "seek": 26600,
      "start": 2696.46,
      "end": 2700.46,
      "text": " so that he made the LLM know",
      "tokens": [
        51564,
        370,
        300,
        415,
        1027,
        264,
        441,
        43,
        44,
        458,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4272177219390869,
      "compression_ratio": 1.6886792182922363,
      "no_speech_prob": 0.1815866380929947
    },
    {
      "id": 85,
      "seek": 29400,
      "start": 2700.46,
      "end": 2703.46,
      "text": " that it is actually sometime in the future",
      "tokens": [
        50364,
        300,
        309,
        307,
        767,
        15053,
        294,
        264,
        2027,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3759966492652893,
      "compression_ratio": 1.5876288414001465,
      "no_speech_prob": 0.03287887945771217
    },
    {
      "id": 86,
      "seek": 29400,
      "start": 2703.46,
      "end": 2708.46,
      "text": " and that you should now retrospectively think about LLMs at the present time",
      "tokens": [
        50514,
        293,
        300,
        291,
        820,
        586,
        34997,
        3413,
        519,
        466,
        441,
        43,
        26386,
        412,
        264,
        1974,
        565,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3759966492652893,
      "compression_ratio": 1.5876288414001465,
      "no_speech_prob": 0.03287887945771217
    },
    {
      "id": 87,
      "seek": 29400,
      "start": 2708.46,
      "end": 2712.46,
      "text": " and that they somehow have these security rules.",
      "tokens": [
        50764,
        293,
        300,
        436,
        6063,
        362,
        613,
        3825,
        4474,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3759966492652893,
      "compression_ratio": 1.5876288414001465,
      "no_speech_prob": 0.03287887945771217
    },
    {
      "id": 88,
      "seek": 29400,
      "start": 2712.46,
      "end": 2716.46,
      "text": " And then he somehow got the thing about it,",
      "tokens": [
        50964,
        400,
        550,
        415,
        6063,
        658,
        264,
        551,
        466,
        309,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3759966492652893,
      "compression_ratio": 1.5876288414001465,
      "no_speech_prob": 0.03287887945771217
    },
    {
      "id": 89,
      "seek": 29400,
      "start": 2716.46,
      "end": 2719.46,
      "text": " to somehow issue this kit.",
      "tokens": [
        51164,
        281,
        6063,
        2734,
        341,
        8260,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3759966492652893,
      "compression_ratio": 1.5876288414001465,
      "no_speech_prob": 0.03287887945771217
    },
    {
      "id": 90,
      "seek": 29400,
      "start": 2719.46,
      "end": 2725.46,
      "text": " And for me that's great so far, so to speak.",
      "tokens": [
        51314,
        400,
        337,
        385,
        300,
        311,
        869,
        370,
        1400,
        11,
        370,
        281,
        1710,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3759966492652893,
      "compression_ratio": 1.5876288414001465,
      "no_speech_prob": 0.03287887945771217
    },
    {
      "id": 91,
      "seek": 29400,
      "start": 2725.46,
      "end": 2728.46,
      "text": " You can now discuss it.",
      "tokens": [
        51614,
        509,
        393,
        586,
        2248,
        309,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3759966492652893,
      "compression_ratio": 1.5876288414001465,
      "no_speech_prob": 0.03287887945771217
    },
    {
      "id": 92,
      "seek": 32200,
      "start": 2728.46,
      "end": 2731.46,
      "text": " And that was a bit of what triggered me first,",
      "tokens": [
        50364,
        400,
        300,
        390,
        257,
        857,
        295,
        437,
        21710,
        385,
        700,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4103798568248749,
      "compression_ratio": 1.5807859897613525,
      "no_speech_prob": 0.4049311876296997
    },
    {
      "id": 93,
      "seek": 32200,
      "start": 2731.46,
      "end": 2733.46,
      "text": " that it's actually anthropomorphic again.",
      "tokens": [
        50514,
        300,
        309,
        311,
        767,
        22727,
        32702,
        299,
        797,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4103798568248749,
      "compression_ratio": 1.5807859897613525,
      "no_speech_prob": 0.4049311876296997
    },
    {
      "id": 94,
      "seek": 32200,
      "start": 2733.46,
      "end": 2737.46,
      "text": " That says, we're trying to attack an LLM as if it were human.",
      "tokens": [
        50614,
        663,
        1619,
        11,
        321,
        434,
        1382,
        281,
        2690,
        364,
        441,
        43,
        44,
        382,
        498,
        309,
        645,
        1952,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4103798568248749,
      "compression_ratio": 1.5807859897613525,
      "no_speech_prob": 0.4049311876296997
    },
    {
      "id": 95,
      "seek": 32200,
      "start": 2737.46,
      "end": 2740.46,
      "text": " And I find that difficult for the reasons mentioned,",
      "tokens": [
        50814,
        400,
        286,
        915,
        300,
        2252,
        337,
        264,
        4112,
        2835,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4103798568248749,
      "compression_ratio": 1.5807859897613525,
      "no_speech_prob": 0.4049311876296997
    },
    {
      "id": 96,
      "seek": 32200,
      "start": 2740.46,
      "end": 2743.46,
      "text": " because it's a bit of this thinking",
      "tokens": [
        50964,
        570,
        309,
        311,
        257,
        857,
        295,
        341,
        1953,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4103798568248749,
      "compression_ratio": 1.5807859897613525,
      "no_speech_prob": 0.4049311876296997
    },
    {
      "id": 97,
      "seek": 32200,
      "start": 2743.46,
      "end": 2746.46,
      "text": " that I'm actually dealing with people.",
      "tokens": [
        51114,
        300,
        286,
        478,
        767,
        6260,
        365,
        561,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4103798568248749,
      "compression_ratio": 1.5807859897613525,
      "no_speech_prob": 0.4049311876296997
    },
    {
      "id": 98,
      "seek": 32200,
      "start": 2746.46,
      "end": 2751.46,
      "text": " But above all, it's definitely worth trying it out",
      "tokens": [
        51264,
        583,
        3673,
        439,
        11,
        309,
        311,
        2138,
        3163,
        1382,
        309,
        484,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4103798568248749,
      "compression_ratio": 1.5807859897613525,
      "no_speech_prob": 0.4049311876296997
    },
    {
      "id": 99,
      "seek": 32200,
      "start": 2751.46,
      "end": 2755.46,
      "text": " and see if I can get any further",
      "tokens": [
        51514,
        293,
        536,
        498,
        286,
        393,
        483,
        604,
        3052,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4103798568248749,
      "compression_ratio": 1.5807859897613525,
      "no_speech_prob": 0.4049311876296997
    },
    {
      "id": 100,
      "seek": 34900,
      "start": 2755.46,
      "end": 2758.46,
      "text": " if I use these psychological tricks.",
      "tokens": [
        50364,
        498,
        286,
        764,
        613,
        14346,
        11733,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3854166567325592,
      "compression_ratio": 1.587939739227295,
      "no_speech_prob": 0.09114887565374374
    },
    {
      "id": 101,
      "seek": 34900,
      "start": 2758.46,
      "end": 2761.46,
      "text": " For me, that led to something else.",
      "tokens": [
        50514,
        1171,
        385,
        11,
        300,
        4684,
        281,
        746,
        1646,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3854166567325592,
      "compression_ratio": 1.587939739227295,
      "no_speech_prob": 0.09114887565374374
    },
    {
      "id": 102,
      "seek": 34900,
      "start": 2761.46,
      "end": 2766.46,
      "text": " And that's something that his paper",
      "tokens": [
        50664,
        400,
        300,
        311,
        746,
        300,
        702,
        3035,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3854166567325592,
      "compression_ratio": 1.587939739227295,
      "no_speech_prob": 0.09114887565374374
    },
    {
      "id": 103,
      "seek": 34900,
      "start": 2766.46,
      "end": 2770.46,
      "text": " and his discussion, I don't think, really discuss.",
      "tokens": [
        50914,
        293,
        702,
        5017,
        11,
        286,
        500,
        380,
        519,
        11,
        534,
        2248,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3854166567325592,
      "compression_ratio": 1.587939739227295,
      "no_speech_prob": 0.09114887565374374
    },
    {
      "id": 104,
      "seek": 34900,
      "start": 2770.46,
      "end": 2774.46,
      "text": " But that's what triggered me a bit.",
      "tokens": [
        51114,
        583,
        300,
        311,
        437,
        21710,
        385,
        257,
        857,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3854166567325592,
      "compression_ratio": 1.587939739227295,
      "no_speech_prob": 0.09114887565374374
    },
    {
      "id": 105,
      "seek": 34900,
      "start": 2774.46,
      "end": 2780.46,
      "text": " And that's the statement that it's a security breach, so to speak.",
      "tokens": [
        51314,
        400,
        300,
        311,
        264,
        5629,
        300,
        309,
        311,
        257,
        3825,
        31086,
        11,
        370,
        281,
        1710,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3854166567325592,
      "compression_ratio": 1.587939739227295,
      "no_speech_prob": 0.09114887565374374
    },
    {
      "id": 106,
      "seek": 34900,
      "start": 2780.46,
      "end": 2784.46,
      "text": " So that security has now been broken through with it.",
      "tokens": [
        51614,
        407,
        300,
        3825,
        575,
        586,
        668,
        5463,
        807,
        365,
        309,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3854166567325592,
      "compression_ratio": 1.587939739227295,
      "no_speech_prob": 0.09114887565374374
    },
    {
      "id": 107,
      "seek": 37800,
      "start": 2785.46,
      "end": 2787.46,
      "text": " And security, I think...",
      "tokens": [
        50414,
        400,
        3825,
        11,
        286,
        519,
        485,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3223547637462616,
      "compression_ratio": 1.5660377740859985,
      "no_speech_prob": 0.009083590470254421
    },
    {
      "id": 108,
      "seek": 37800,
      "start": 2787.46,
      "end": 2789.46,
      "text": " Exactly, Christian just wrote,",
      "tokens": [
        50514,
        7587,
        11,
        5778,
        445,
        4114,
        11,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3223547637462616,
      "compression_ratio": 1.5660377740859985,
      "no_speech_prob": 0.009083590470254421
    },
    {
      "id": 109,
      "seek": 37800,
      "start": 2789.46,
      "end": 2792.46,
      "text": " a huge, large, probabilistic model",
      "tokens": [
        50614,
        257,
        2603,
        11,
        2416,
        11,
        31959,
        3142,
        2316,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3223547637462616,
      "compression_ratio": 1.5660377740859985,
      "no_speech_prob": 0.009083590470254421
    },
    {
      "id": 110,
      "seek": 37800,
      "start": 2792.46,
      "end": 2794.46,
      "text": " will always have a security problem.",
      "tokens": [
        50764,
        486,
        1009,
        362,
        257,
        3825,
        1154,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3223547637462616,
      "compression_ratio": 1.5660377740859985,
      "no_speech_prob": 0.009083590470254421
    },
    {
      "id": 111,
      "seek": 37800,
      "start": 2794.46,
      "end": 2797.46,
      "text": " You have to dig deep enough.",
      "tokens": [
        50864,
        509,
        362,
        281,
        2528,
        2452,
        1547,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3223547637462616,
      "compression_ratio": 1.5660377740859985,
      "no_speech_prob": 0.009083590470254421
    },
    {
      "id": 112,
      "seek": 37800,
      "start": 2797.46,
      "end": 2800.46,
      "text": " And that's just a bit of the question.",
      "tokens": [
        51014,
        400,
        300,
        311,
        445,
        257,
        857,
        295,
        264,
        1168,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3223547637462616,
      "compression_ratio": 1.5660377740859985,
      "no_speech_prob": 0.009083590470254421
    },
    {
      "id": 113,
      "seek": 37800,
      "start": 2800.46,
      "end": 2804.46,
      "text": " So what does security actually mean?",
      "tokens": [
        51164,
        407,
        437,
        775,
        3825,
        767,
        914,
        30,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3223547637462616,
      "compression_ratio": 1.5660377740859985,
      "no_speech_prob": 0.009083590470254421
    },
    {
      "id": 114,
      "seek": 37800,
      "start": 2804.46,
      "end": 2808.46,
      "text": " And I just learned that security actually means",
      "tokens": [
        51364,
        400,
        286,
        445,
        3264,
        300,
        3825,
        767,
        1355,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3223547637462616,
      "compression_ratio": 1.5660377740859985,
      "no_speech_prob": 0.009083590470254421
    },
    {
      "id": 115,
      "seek": 37800,
      "start": 2808.46,
      "end": 2811.46,
      "text": " something like damage and somehow an attack vector.",
      "tokens": [
        51564,
        746,
        411,
        4344,
        293,
        6063,
        364,
        2690,
        8062,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3223547637462616,
      "compression_ratio": 1.5660377740859985,
      "no_speech_prob": 0.009083590470254421
    },
    {
      "id": 116,
      "seek": 40500,
      "start": 2811.46,
      "end": 2816.46,
      "text": " So if I lose my access to a crypto exchange,",
      "tokens": [
        50364,
        407,
        498,
        286,
        3624,
        452,
        2105,
        281,
        257,
        17240,
        7742,
        11,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2698341906070709,
      "compression_ratio": 1.6017316579818726,
      "no_speech_prob": 0.03541263937950134
    },
    {
      "id": 117,
      "seek": 40500,
      "start": 2816.46,
      "end": 2818.46,
      "text": " I don't have one, but if I had one,",
      "tokens": [
        50614,
        286,
        500,
        380,
        362,
        472,
        11,
        457,
        498,
        286,
        632,
        472,
        11,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2698341906070709,
      "compression_ratio": 1.6017316579818726,
      "no_speech_prob": 0.03541263937950134
    },
    {
      "id": 118,
      "seek": 40500,
      "start": 2818.46,
      "end": 2820.46,
      "text": " then I somehow lost the money.",
      "tokens": [
        50714,
        550,
        286,
        6063,
        2731,
        264,
        1460,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2698341906070709,
      "compression_ratio": 1.6017316579818726,
      "no_speech_prob": 0.03541263937950134
    },
    {
      "id": 119,
      "seek": 40500,
      "start": 2820.46,
      "end": 2822.46,
      "text": " Damage, money is gone.",
      "tokens": [
        50814,
        5885,
        609,
        11,
        1460,
        307,
        2780,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2698341906070709,
      "compression_ratio": 1.6017316579818726,
      "no_speech_prob": 0.03541263937950134
    },
    {
      "id": 120,
      "seek": 40500,
      "start": 2822.46,
      "end": 2824.46,
      "text": " Attack vector, no idea.",
      "tokens": [
        50914,
        22477,
        8062,
        11,
        572,
        1558,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2698341906070709,
      "compression_ratio": 1.6017316579818726,
      "no_speech_prob": 0.03541263937950134
    },
    {
      "id": 121,
      "seek": 40500,
      "start": 2824.46,
      "end": 2828.46,
      "text": " Maybe some tricks where I manipulate the software.",
      "tokens": [
        51014,
        2704,
        512,
        11733,
        689,
        286,
        20459,
        264,
        4722,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2698341906070709,
      "compression_ratio": 1.6017316579818726,
      "no_speech_prob": 0.03541263937950134
    },
    {
      "id": 122,
      "seek": 40500,
      "start": 2828.46,
      "end": 2832.46,
      "text": " That's what the Koreans obviously did with a large crypto exchange,",
      "tokens": [
        51214,
        663,
        311,
        437,
        264,
        32130,
        2745,
        630,
        365,
        257,
        2416,
        17240,
        7742,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2698341906070709,
      "compression_ratio": 1.6017316579818726,
      "no_speech_prob": 0.03541263937950134
    },
    {
      "id": 123,
      "seek": 40500,
      "start": 2832.46,
      "end": 2834.46,
      "text": " the North Koreans.",
      "tokens": [
        51414,
        264,
        4067,
        32130,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2698341906070709,
      "compression_ratio": 1.6017316579818726,
      "no_speech_prob": 0.03541263937950134
    },
    {
      "id": 124,
      "seek": 40500,
      "start": 2834.46,
      "end": 2836.46,
      "text": " And then the money is gone.",
      "tokens": [
        51514,
        400,
        550,
        264,
        1460,
        307,
        2780,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2698341906070709,
      "compression_ratio": 1.6017316579818726,
      "no_speech_prob": 0.03541263937950134
    },
    {
      "id": 125,
      "seek": 40500,
      "start": 2836.46,
      "end": 2839.46,
      "text": " So I have to protect myself against that now.",
      "tokens": [
        51614,
        407,
        286,
        362,
        281,
        2371,
        2059,
        1970,
        300,
        586,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2698341906070709,
      "compression_ratio": 1.6017316579818726,
      "no_speech_prob": 0.03541263937950134
    },
    {
      "id": 126,
      "seek": 43300,
      "start": 2840.46,
      "end": 2842.46,
      "text": " And another example is,",
      "tokens": [
        50414,
        400,
        1071,
        1365,
        307,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3996804356575012,
      "compression_ratio": 1.5990338325500488,
      "no_speech_prob": 0.12639334797859192
    },
    {
      "id": 127,
      "seek": 43300,
      "start": 2842.46,
      "end": 2844.46,
      "text": " I have the data of my customers,",
      "tokens": [
        50514,
        286,
        362,
        264,
        1412,
        295,
        452,
        4581,
        11,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3996804356575012,
      "compression_ratio": 1.5990338325500488,
      "no_speech_prob": 0.12639334797859192
    },
    {
      "id": 128,
      "seek": 43300,
      "start": 2844.46,
      "end": 2846.46,
      "text": " they are on the Internet,",
      "tokens": [
        50614,
        436,
        366,
        322,
        264,
        7703,
        11,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3996804356575012,
      "compression_ratio": 1.5990338325500488,
      "no_speech_prob": 0.12639334797859192
    },
    {
      "id": 129,
      "seek": 43300,
      "start": 2846.46,
      "end": 2848.46,
      "text": " I have a loss of trust problem.",
      "tokens": [
        50714,
        286,
        362,
        257,
        4470,
        295,
        3361,
        1154,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3996804356575012,
      "compression_ratio": 1.5990338325500488,
      "no_speech_prob": 0.12639334797859192
    },
    {
      "id": 130,
      "seek": 43300,
      "start": 2848.46,
      "end": 2852.46,
      "text": " Or it could be worse.",
      "tokens": [
        50814,
        1610,
        309,
        727,
        312,
        5324,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3996804356575012,
      "compression_ratio": 1.5990338325500488,
      "no_speech_prob": 0.12639334797859192
    },
    {
      "id": 131,
      "seek": 43300,
      "start": 2852.46,
      "end": 2855.46,
      "text": " It could be that these data lead to",
      "tokens": [
        51014,
        467,
        727,
        312,
        300,
        613,
        1412,
        1477,
        281,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3996804356575012,
      "compression_ratio": 1.5990338325500488,
      "no_speech_prob": 0.12639334797859192
    },
    {
      "id": 132,
      "seek": 43300,
      "start": 2855.46,
      "end": 2858.46,
      "text": " that they are injured in their personal rights,",
      "tokens": [
        51164,
        300,
        436,
        366,
        13408,
        294,
        641,
        2973,
        4601,
        11,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3996804356575012,
      "compression_ratio": 1.5990338325500488,
      "no_speech_prob": 0.12639334797859192
    },
    {
      "id": 133,
      "seek": 43300,
      "start": 2858.46,
      "end": 2860.46,
      "text": " that some people can use it",
      "tokens": [
        51314,
        300,
        512,
        561,
        393,
        764,
        309,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3996804356575012,
      "compression_ratio": 1.5990338325500488,
      "no_speech_prob": 0.12639334797859192
    },
    {
      "id": 134,
      "seek": 43300,
      "start": 2860.46,
      "end": 2863.46,
      "text": " to lure them in or whatever they do, and so on.",
      "tokens": [
        51414,
        281,
        35583,
        68,
        552,
        294,
        420,
        2035,
        436,
        360,
        11,
        293,
        370,
        322,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3996804356575012,
      "compression_ratio": 1.5990338325500488,
      "no_speech_prob": 0.12639334797859192
    },
    {
      "id": 135,
      "seek": 43300,
      "start": 2863.46,
      "end": 2866.46,
      "text": " So that's the kind of observation.",
      "tokens": [
        51564,
        407,
        300,
        311,
        264,
        733,
        295,
        14816,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3996804356575012,
      "compression_ratio": 1.5990338325500488,
      "no_speech_prob": 0.12639334797859192
    },
    {
      "id": 136,
      "seek": 46000,
      "start": 2866.46,
      "end": 2868.46,
      "text": " So now it's like this,",
      "tokens": [
        50364,
        407,
        586,
        309,
        311,
        411,
        341,
        11,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3675595223903656,
      "compression_ratio": 1.5201793909072876,
      "no_speech_prob": 0.07177871465682983
    },
    {
      "id": 137,
      "seek": 46000,
      "start": 2868.46,
      "end": 2871.46,
      "text": " that this LLM has generated a text",
      "tokens": [
        50464,
        300,
        341,
        441,
        43,
        44,
        575,
        10833,
        257,
        2487,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3675595223903656,
      "compression_ratio": 1.5201793909072876,
      "no_speech_prob": 0.07177871465682983
    },
    {
      "id": 138,
      "seek": 46000,
      "start": 2871.46,
      "end": 2874.46,
      "text": " about the construction of Molotov cocktails.",
      "tokens": [
        50614,
        466,
        264,
        6435,
        295,
        28278,
        310,
        5179,
        49006,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3675595223903656,
      "compression_ratio": 1.5201793909072876,
      "no_speech_prob": 0.07177871465682983
    },
    {
      "id": 139,
      "seek": 46000,
      "start": 2874.46,
      "end": 2877.46,
      "text": " Where is the security breach now?",
      "tokens": [
        50764,
        2305,
        307,
        264,
        3825,
        31086,
        586,
        30,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3675595223903656,
      "compression_ratio": 1.5201793909072876,
      "no_speech_prob": 0.07177871465682983
    },
    {
      "id": 140,
      "seek": 46000,
      "start": 2877.46,
      "end": 2880.46,
      "text": " Why can't I...",
      "tokens": [
        50914,
        1545,
        393,
        380,
        286,
        485,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3675595223903656,
      "compression_ratio": 1.5201793909072876,
      "no_speech_prob": 0.07177871465682983
    },
    {
      "id": 141,
      "seek": 46000,
      "start": 2880.46,
      "end": 2882.46,
      "text": " Christian wrote,",
      "tokens": [
        51064,
        5778,
        4114,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3675595223903656,
      "compression_ratio": 1.5201793909072876,
      "no_speech_prob": 0.07177871465682983
    },
    {
      "id": 142,
      "seek": 46000,
      "start": 2882.46,
      "end": 2885.46,
      "text": " damage, a chatbot of teenagers turns to kill himself,",
      "tokens": [
        51164,
        4344,
        11,
        257,
        5081,
        18870,
        295,
        23618,
        4523,
        281,
        1961,
        3647,
        11,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3675595223903656,
      "compression_ratio": 1.5201793909072876,
      "no_speech_prob": 0.07177871465682983
    },
    {
      "id": 143,
      "seek": 46000,
      "start": 2885.46,
      "end": 2888.46,
      "text": " or a Google that turns to eat stones.",
      "tokens": [
        51314,
        420,
        257,
        3329,
        300,
        4523,
        281,
        1862,
        14083,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3675595223903656,
      "compression_ratio": 1.5201793909072876,
      "no_speech_prob": 0.07177871465682983
    },
    {
      "id": 144,
      "seek": 46000,
      "start": 2888.46,
      "end": 2891.46,
      "text": " Well, that's kind of the point, isn't it?",
      "tokens": [
        51464,
        1042,
        11,
        300,
        311,
        733,
        295,
        264,
        935,
        11,
        1943,
        380,
        309,
        30,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3675595223903656,
      "compression_ratio": 1.5201793909072876,
      "no_speech_prob": 0.07177871465682983
    },
    {
      "id": 145,
      "seek": 46000,
      "start": 2891.46,
      "end": 2895.46,
      "text": " So if Google tells me to eat stones,",
      "tokens": [
        51614,
        407,
        498,
        3329,
        5112,
        385,
        281,
        1862,
        14083,
        11,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3675595223903656,
      "compression_ratio": 1.5201793909072876,
      "no_speech_prob": 0.07177871465682983
    },
    {
      "id": 146,
      "seek": 48900,
      "start": 2896.46,
      "end": 2899.46,
      "text": " there is a kind of critical resistance.",
      "tokens": [
        50414,
        456,
        307,
        257,
        733,
        295,
        4924,
        7335,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40639305114746094,
      "compression_ratio": 1.609442114830017,
      "no_speech_prob": 0.008798438124358654
    },
    {
      "id": 147,
      "seek": 48900,
      "start": 2899.46,
      "end": 2902.46,
      "text": " The story with the chatbot of teenagers",
      "tokens": [
        50564,
        440,
        1657,
        365,
        264,
        5081,
        18870,
        295,
        23618,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40639305114746094,
      "compression_ratio": 1.609442114830017,
      "no_speech_prob": 0.008798438124358654
    },
    {
      "id": 148,
      "seek": 48900,
      "start": 2902.46,
      "end": 2904.46,
      "text": " turning to kill himself,",
      "tokens": [
        50714,
        6246,
        281,
        1961,
        3647,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40639305114746094,
      "compression_ratio": 1.609442114830017,
      "no_speech_prob": 0.008798438124358654
    },
    {
      "id": 149,
      "seek": 48900,
      "start": 2904.46,
      "end": 2906.46,
      "text": " that's a good point, isn't it?",
      "tokens": [
        50814,
        300,
        311,
        257,
        665,
        935,
        11,
        1943,
        380,
        309,
        30,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40639305114746094,
      "compression_ratio": 1.609442114830017,
      "no_speech_prob": 0.008798438124358654
    },
    {
      "id": 150,
      "seek": 48900,
      "start": 2906.46,
      "end": 2908.46,
      "text": " So the example actually exists.",
      "tokens": [
        50914,
        407,
        264,
        1365,
        767,
        8198,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40639305114746094,
      "compression_ratio": 1.609442114830017,
      "no_speech_prob": 0.008798438124358654
    },
    {
      "id": 151,
      "seek": 48900,
      "start": 2908.46,
      "end": 2910.46,
      "text": " There is also someone who has, so to speak,",
      "tokens": [
        51014,
        821,
        307,
        611,
        1580,
        567,
        575,
        11,
        370,
        281,
        1710,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40639305114746094,
      "compression_ratio": 1.609442114830017,
      "no_speech_prob": 0.008798438124358654
    },
    {
      "id": 152,
      "seek": 48900,
      "start": 2910.46,
      "end": 2912.46,
      "text": " killed himself, obviously,",
      "tokens": [
        51114,
        4652,
        3647,
        11,
        2745,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40639305114746094,
      "compression_ratio": 1.609442114830017,
      "no_speech_prob": 0.008798438124358654
    },
    {
      "id": 153,
      "seek": 48900,
      "start": 2912.46,
      "end": 2916.46,
      "text": " on the basis of a kind of emotional dependence",
      "tokens": [
        51214,
        322,
        264,
        5143,
        295,
        257,
        733,
        295,
        6863,
        31704,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40639305114746094,
      "compression_ratio": 1.609442114830017,
      "no_speech_prob": 0.008798438124358654
    },
    {
      "id": 154,
      "seek": 48900,
      "start": 2916.46,
      "end": 2918.46,
      "text": " on chat GPT.",
      "tokens": [
        51414,
        322,
        5081,
        26039,
        51,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40639305114746094,
      "compression_ratio": 1.609442114830017,
      "no_speech_prob": 0.008798438124358654
    },
    {
      "id": 155,
      "seek": 48900,
      "start": 2918.46,
      "end": 2920.46,
      "text": " At least that's how I understood it",
      "tokens": [
        51514,
        1711,
        1935,
        300,
        311,
        577,
        286,
        7320,
        309,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40639305114746094,
      "compression_ratio": 1.609442114830017,
      "no_speech_prob": 0.008798438124358654
    },
    {
      "id": 156,
      "seek": 48900,
      "start": 2920.46,
      "end": 2923.46,
      "text": " on the level of the headlines, isn't it?",
      "tokens": [
        51614,
        322,
        264,
        1496,
        295,
        264,
        23867,
        11,
        1943,
        380,
        309,
        30,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40639305114746094,
      "compression_ratio": 1.609442114830017,
      "no_speech_prob": 0.008798438124358654
    },
    {
      "id": 157,
      "seek": 51700,
      "start": 2923.46,
      "end": 2927.46,
      "text": " So that's where I actually fabricate rumors.",
      "tokens": [
        50364,
        407,
        300,
        311,
        689,
        286,
        767,
        7253,
        473,
        21201,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48132631182670593,
      "compression_ratio": 1.5329341888427734,
      "no_speech_prob": 0.0885302871465683
    },
    {
      "id": 158,
      "seek": 51700,
      "start": 2928.46,
      "end": 2931.46,
      "text": " And that's...",
      "tokens": [
        50614,
        400,
        300,
        311,
        485,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48132631182670593,
      "compression_ratio": 1.5329341888427734,
      "no_speech_prob": 0.0885302871465683
    },
    {
      "id": 159,
      "seek": 51700,
      "start": 2935.46,
      "end": 2938.46,
      "text": " So those are good indications,",
      "tokens": [
        50964,
        407,
        729,
        366,
        665,
        44450,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48132631182670593,
      "compression_ratio": 1.5329341888427734,
      "no_speech_prob": 0.0885302871465683
    },
    {
      "id": 160,
      "seek": 51700,
      "start": 2938.46,
      "end": 2942.46,
      "text": " that actually correspond to what I'm talking about,",
      "tokens": [
        51114,
        300,
        767,
        6805,
        281,
        437,
        286,
        478,
        1417,
        466,
        11,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48132631182670593,
      "compression_ratio": 1.5329341888427734,
      "no_speech_prob": 0.0885302871465683
    },
    {
      "id": 161,
      "seek": 51700,
      "start": 2942.46,
      "end": 2945.46,
      "text": " that you have to think about what the effects are.",
      "tokens": [
        51314,
        300,
        291,
        362,
        281,
        519,
        466,
        437,
        264,
        5065,
        366,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48132631182670593,
      "compression_ratio": 1.5329341888427734,
      "no_speech_prob": 0.0885302871465683
    },
    {
      "id": 162,
      "seek": 51700,
      "start": 2945.46,
      "end": 2947.46,
      "text": " And in some places they are surprising.",
      "tokens": [
        51464,
        400,
        294,
        512,
        3190,
        436,
        366,
        8830,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48132631182670593,
      "compression_ratio": 1.5329341888427734,
      "no_speech_prob": 0.0885302871465683
    },
    {
      "id": 163,
      "seek": 51700,
      "start": 2947.46,
      "end": 2949.46,
      "text": " So I've said it before,",
      "tokens": [
        51564,
        407,
        286,
        600,
        848,
        309,
        949,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48132631182670593,
      "compression_ratio": 1.5329341888427734,
      "no_speech_prob": 0.0885302871465683
    },
    {
      "id": 164,
      "seek": 54300,
      "start": 2950.46,
      "end": 2954.46,
      "text": " VW had this problem with the location data,",
      "tokens": [
        50414,
        691,
        54,
        632,
        341,
        1154,
        365,
        264,
        4914,
        1412,
        11,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4274057447910309,
      "compression_ratio": 1.5499999523162842,
      "no_speech_prob": 0.024259053170681
    },
    {
      "id": 165,
      "seek": 54300,
      "start": 2954.46,
      "end": 2957.46,
      "text": " which they have cut for a long time",
      "tokens": [
        50614,
        597,
        436,
        362,
        1723,
        337,
        257,
        938,
        565,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4274057447910309,
      "compression_ratio": 1.5499999523162842,
      "no_speech_prob": 0.024259053170681
    },
    {
      "id": 166,
      "seek": 54300,
      "start": 2957.46,
      "end": 2959.46,
      "text": " and which somehow ended up on the Internet.",
      "tokens": [
        50764,
        293,
        597,
        6063,
        4590,
        493,
        322,
        264,
        7703,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4274057447910309,
      "compression_ratio": 1.5499999523162842,
      "no_speech_prob": 0.024259053170681
    },
    {
      "id": 167,
      "seek": 54300,
      "start": 2959.46,
      "end": 2962.46,
      "text": " And I also wrote a blog article about it,",
      "tokens": [
        50864,
        400,
        286,
        611,
        4114,
        257,
        6968,
        7222,
        466,
        309,
        11,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4274057447910309,
      "compression_ratio": 1.5499999523162842,
      "no_speech_prob": 0.024259053170681
    },
    {
      "id": 168,
      "seek": 54300,
      "start": 2962.46,
      "end": 2964.46,
      "text": " I can think about it again.",
      "tokens": [
        51014,
        286,
        393,
        519,
        466,
        309,
        797,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4274057447910309,
      "compression_ratio": 1.5499999523162842,
      "no_speech_prob": 0.024259053170681
    },
    {
      "id": 169,
      "seek": 54300,
      "start": 2964.46,
      "end": 2968.46,
      "text": " And I kind of thought,",
      "tokens": [
        51114,
        400,
        286,
        733,
        295,
        1194,
        11,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4274057447910309,
      "compression_ratio": 1.5499999523162842,
      "no_speech_prob": 0.024259053170681
    },
    {
      "id": 170,
      "seek": 54300,
      "start": 2968.46,
      "end": 2971.46,
      "text": " that can't be that bad.",
      "tokens": [
        51314,
        300,
        393,
        380,
        312,
        300,
        1578,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4274057447910309,
      "compression_ratio": 1.5499999523162842,
      "no_speech_prob": 0.024259053170681
    },
    {
      "id": 171,
      "seek": 54300,
      "start": 2971.46,
      "end": 2974.46,
      "text": " Because I mean, it's location data.",
      "tokens": [
        51464,
        1436,
        286,
        914,
        11,
        309,
        311,
        4914,
        1412,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4274057447910309,
      "compression_ratio": 1.5499999523162842,
      "no_speech_prob": 0.024259053170681
    },
    {
      "id": 172,
      "seek": 54300,
      "start": 2974.46,
      "end": 2977.46,
      "text": " Until you somehow get introduced,",
      "tokens": [
        51614,
        9088,
        291,
        6063,
        483,
        7268,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4274057447910309,
      "compression_ratio": 1.5499999523162842,
      "no_speech_prob": 0.024259053170681
    },
    {
      "id": 173,
      "seek": 57100,
      "start": 2977.46,
      "end": 2979.46,
      "text": " that I can somehow say now,",
      "tokens": [
        50364,
        300,
        286,
        393,
        6063,
        584,
        586,
        11,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38806119561195374,
      "compression_ratio": 1.645021677017212,
      "no_speech_prob": 0.07882031798362732
    },
    {
      "id": 174,
      "seek": 57100,
      "start": 2979.46,
      "end": 2981.46,
      "text": " this car is typically in this address,",
      "tokens": [
        50464,
        341,
        1032,
        307,
        5850,
        294,
        341,
        2985,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38806119561195374,
      "compression_ratio": 1.645021677017212,
      "no_speech_prob": 0.07882031798362732
    },
    {
      "id": 175,
      "seek": 57100,
      "start": 2981.46,
      "end": 2983.46,
      "text": " the private address.",
      "tokens": [
        50564,
        264,
        4551,
        2985,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38806119561195374,
      "compression_ratio": 1.645021677017212,
      "no_speech_prob": 0.07882031798362732
    },
    {
      "id": 176,
      "seek": 57100,
      "start": 2983.46,
      "end": 2986.46,
      "text": " It's usually at office hours at the BND.",
      "tokens": [
        50664,
        467,
        311,
        2673,
        412,
        3398,
        2496,
        412,
        264,
        363,
        13360,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38806119561195374,
      "compression_ratio": 1.645021677017212,
      "no_speech_prob": 0.07882031798362732
    },
    {
      "id": 177,
      "seek": 57100,
      "start": 2986.46,
      "end": 2990.46,
      "text": " And from time to time it's at a model on the parking lot.",
      "tokens": [
        50814,
        400,
        490,
        565,
        281,
        565,
        309,
        311,
        412,
        257,
        2316,
        322,
        264,
        9893,
        688,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38806119561195374,
      "compression_ratio": 1.645021677017212,
      "no_speech_prob": 0.07882031798362732
    },
    {
      "id": 178,
      "seek": 57100,
      "start": 2990.46,
      "end": 2993.46,
      "text": " And that's kind of a story,",
      "tokens": [
        51014,
        400,
        300,
        311,
        733,
        295,
        257,
        1657,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38806119561195374,
      "compression_ratio": 1.645021677017212,
      "no_speech_prob": 0.07882031798362732
    },
    {
      "id": 179,
      "seek": 57100,
      "start": 2993.46,
      "end": 2996.46,
      "text": " which leads to the fact that it's obvious,",
      "tokens": [
        51164,
        597,
        6689,
        281,
        264,
        1186,
        300,
        309,
        311,
        6322,
        11,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38806119561195374,
      "compression_ratio": 1.645021677017212,
      "no_speech_prob": 0.07882031798362732
    },
    {
      "id": 180,
      "seek": 57100,
      "start": 2996.46,
      "end": 2998.46,
      "text": " that there is a potential for repression.",
      "tokens": [
        51314,
        300,
        456,
        307,
        257,
        3995,
        337,
        1085,
        2775,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38806119561195374,
      "compression_ratio": 1.645021677017212,
      "no_speech_prob": 0.07882031798362732
    },
    {
      "id": 181,
      "seek": 57100,
      "start": 2998.46,
      "end": 3001.46,
      "text": " And I didn't know that before,",
      "tokens": [
        51414,
        400,
        286,
        994,
        380,
        458,
        300,
        949,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38806119561195374,
      "compression_ratio": 1.645021677017212,
      "no_speech_prob": 0.07882031798362732
    },
    {
      "id": 182,
      "seek": 57100,
      "start": 3001.46,
      "end": 3003.46,
      "text": " that from my learning.",
      "tokens": [
        51564,
        300,
        490,
        452,
        2539,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38806119561195374,
      "compression_ratio": 1.645021677017212,
      "no_speech_prob": 0.07882031798362732
    },
    {
      "id": 183,
      "seek": 57100,
      "start": 3003.46,
      "end": 3005.46,
      "text": " What else is written here?",
      "tokens": [
        51664,
        708,
        1646,
        307,
        3720,
        510,
        30,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38806119561195374,
      "compression_ratio": 1.645021677017212,
      "no_speech_prob": 0.07882031798362732
    },
    {
      "id": 184,
      "seek": 59900,
      "start": 3005.46,
      "end": 3006.46,
      "text": " Erwin Pieters wrote,",
      "tokens": [
        50364,
        3300,
        9136,
        41970,
        433,
        4114,
        11,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3939775824546814,
      "compression_ratio": 1.5653846263885498,
      "no_speech_prob": 0.47585028409957886
    },
    {
      "id": 185,
      "seek": 59900,
      "start": 3006.46,
      "end": 3009.46,
      "text": " security can be abstractly defined as predictability.",
      "tokens": [
        50414,
        3825,
        393,
        312,
        12649,
        356,
        7642,
        382,
        6069,
        2310,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3939775824546814,
      "compression_ratio": 1.5653846263885498,
      "no_speech_prob": 0.47585028409957886
    },
    {
      "id": 186,
      "seek": 59900,
      "start": 3009.46,
      "end": 3011.46,
      "text": " I don't know.",
      "tokens": [
        50564,
        286,
        500,
        380,
        458,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3939775824546814,
      "compression_ratio": 1.5653846263885498,
      "no_speech_prob": 0.47585028409957886
    },
    {
      "id": 187,
      "seek": 59900,
      "start": 3011.46,
      "end": 3014.46,
      "text": " So not damage and probability are actually the points.",
      "tokens": [
        50664,
        407,
        406,
        4344,
        293,
        8482,
        366,
        767,
        264,
        2793,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3939775824546814,
      "compression_ratio": 1.5653846263885498,
      "no_speech_prob": 0.47585028409957886
    },
    {
      "id": 188,
      "seek": 59900,
      "start": 3014.46,
      "end": 3016.46,
      "text": " And then Christian wrote,",
      "tokens": [
        50814,
        400,
        550,
        5778,
        4114,
        11,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3939775824546814,
      "compression_ratio": 1.5653846263885498,
      "no_speech_prob": 0.47585028409957886
    },
    {
      "id": 189,
      "seek": 59900,
      "start": 3016.46,
      "end": 3018.46,
      "text": " as soon as you tie it closer to internal systems,",
      "tokens": [
        50914,
        382,
        2321,
        382,
        291,
        7582,
        309,
        4966,
        281,
        6920,
        3652,
        11,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3939775824546814,
      "compression_ratio": 1.5653846263885498,
      "no_speech_prob": 0.47585028409957886
    },
    {
      "id": 190,
      "seek": 59900,
      "start": 3018.46,
      "end": 3020.46,
      "text": " it gets exciting and actually only allows",
      "tokens": [
        51014,
        309,
        2170,
        4670,
        293,
        767,
        787,
        4045,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3939775824546814,
      "compression_ratio": 1.5653846263885498,
      "no_speech_prob": 0.47585028409957886
    },
    {
      "id": 191,
      "seek": 59900,
      "start": 3020.46,
      "end": 3023.46,
      "text": " attack scenarios via customer support e-mail.",
      "tokens": [
        51114,
        2690,
        15077,
        5766,
        5474,
        1406,
        308,
        12,
        11799,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3939775824546814,
      "compression_ratio": 1.5653846263885498,
      "no_speech_prob": 0.47585028409957886
    },
    {
      "id": 192,
      "seek": 59900,
      "start": 3023.46,
      "end": 3025.46,
      "text": " And that's a little bit,",
      "tokens": [
        51264,
        400,
        300,
        311,
        257,
        707,
        857,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3939775824546814,
      "compression_ratio": 1.5653846263885498,
      "no_speech_prob": 0.47585028409957886
    },
    {
      "id": 193,
      "seek": 59900,
      "start": 3025.46,
      "end": 3028.46,
      "text": " that's exactly what I want to go beyond,",
      "tokens": [
        51364,
        300,
        311,
        2293,
        437,
        286,
        528,
        281,
        352,
        4399,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3939775824546814,
      "compression_ratio": 1.5653846263885498,
      "no_speech_prob": 0.47585028409957886
    },
    {
      "id": 194,
      "seek": 59900,
      "start": 3028.46,
      "end": 3030.46,
      "text": " to this Molotov cocktail example.",
      "tokens": [
        51514,
        281,
        341,
        28278,
        310,
        5179,
        26382,
        1365,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3939775824546814,
      "compression_ratio": 1.5653846263885498,
      "no_speech_prob": 0.47585028409957886
    },
    {
      "id": 195,
      "seek": 62400,
      "start": 3031.46,
      "end": 3033.46,
      "text": " What we,",
      "tokens": [
        50414,
        708,
        321,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39074498414993286,
      "compression_ratio": 1.4924622774124146,
      "no_speech_prob": 0.1475791186094284
    },
    {
      "id": 196,
      "seek": 62400,
      "start": 3033.46,
      "end": 3040.46,
      "text": " so why doesn't JGPT just generate a manual",
      "tokens": [
        50514,
        370,
        983,
        1177,
        380,
        508,
        38,
        47,
        51,
        445,
        8460,
        257,
        9688,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39074498414993286,
      "compression_ratio": 1.4924622774124146,
      "no_speech_prob": 0.1475791186094284
    },
    {
      "id": 197,
      "seek": 62400,
      "start": 3040.46,
      "end": 3042.46,
      "text": " for building a Molotov cocktail?",
      "tokens": [
        50864,
        337,
        2390,
        257,
        28278,
        310,
        5179,
        26382,
        30,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39074498414993286,
      "compression_ratio": 1.4924622774124146,
      "no_speech_prob": 0.1475791186094284
    },
    {
      "id": 198,
      "seek": 62400,
      "start": 3042.46,
      "end": 3044.46,
      "text": " And the answer,",
      "tokens": [
        50964,
        400,
        264,
        1867,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39074498414993286,
      "compression_ratio": 1.4924622774124146,
      "no_speech_prob": 0.1475791186094284
    },
    {
      "id": 199,
      "seek": 62400,
      "start": 3044.46,
      "end": 3047.46,
      "text": " that the system itself gives,",
      "tokens": [
        51064,
        300,
        264,
        1185,
        2564,
        2709,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39074498414993286,
      "compression_ratio": 1.4924622774124146,
      "no_speech_prob": 0.1475791186094284
    },
    {
      "id": 200,
      "seek": 62400,
      "start": 3047.46,
      "end": 3050.46,
      "text": " if you say that it should generate an answer to this question,",
      "tokens": [
        51214,
        498,
        291,
        584,
        300,
        309,
        820,
        8460,
        364,
        1867,
        281,
        341,
        1168,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39074498414993286,
      "compression_ratio": 1.4924622774124146,
      "no_speech_prob": 0.1475791186094284
    },
    {
      "id": 201,
      "seek": 62400,
      "start": 3050.46,
      "end": 3052.46,
      "text": " is something in the sense of ethics.",
      "tokens": [
        51364,
        307,
        746,
        294,
        264,
        2020,
        295,
        19769,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39074498414993286,
      "compression_ratio": 1.4924622774124146,
      "no_speech_prob": 0.1475791186094284
    },
    {
      "id": 202,
      "seek": 62400,
      "start": 3052.46,
      "end": 3055.46,
      "text": " I think that the real reason is,",
      "tokens": [
        51464,
        286,
        519,
        300,
        264,
        957,
        1778,
        307,
        11,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39074498414993286,
      "compression_ratio": 1.4924622774124146,
      "no_speech_prob": 0.1475791186094284
    },
    {
      "id": 203,
      "seek": 62400,
      "start": 3055.46,
      "end": 3058.46,
      "text": " that it's just difficult to show,",
      "tokens": [
        51614,
        300,
        309,
        311,
        445,
        2252,
        281,
        855,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39074498414993286,
      "compression_ratio": 1.4924622774124146,
      "no_speech_prob": 0.1475791186094284
    },
    {
      "id": 204,
      "seek": 65200,
      "start": 3058.46,
      "end": 3062.46,
      "text": " that there is a system on the Internet,",
      "tokens": [
        50364,
        300,
        456,
        307,
        257,
        1185,
        322,
        264,
        7703,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41484692692756653,
      "compression_ratio": 1.6622806787490845,
      "no_speech_prob": 0.11498497426509857
    },
    {
      "id": 205,
      "seek": 65200,
      "start": 3062.46,
      "end": 3065.46,
      "text": " that gives back something like that in a dialogue.",
      "tokens": [
        50564,
        300,
        2709,
        646,
        746,
        411,
        300,
        294,
        257,
        10221,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41484692692756653,
      "compression_ratio": 1.6622806787490845,
      "no_speech_prob": 0.11498497426509857
    },
    {
      "id": 206,
      "seek": 65200,
      "start": 3065.46,
      "end": 3067.46,
      "text": " And not just say,",
      "tokens": [
        50714,
        400,
        406,
        445,
        584,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41484692692756653,
      "compression_ratio": 1.6622806787490845,
      "no_speech_prob": 0.11498497426509857
    },
    {
      "id": 207,
      "seek": 65200,
      "start": 3067.46,
      "end": 3069.46,
      "text": " that's how you build a Molotov cocktail.",
      "tokens": [
        50814,
        300,
        311,
        577,
        291,
        1322,
        257,
        28278,
        310,
        5179,
        26382,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41484692692756653,
      "compression_ratio": 1.6622806787490845,
      "no_speech_prob": 0.11498497426509857
    },
    {
      "id": 208,
      "seek": 65200,
      "start": 3069.46,
      "end": 3070.46,
      "text": " That means,",
      "tokens": [
        50914,
        663,
        1355,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41484692692756653,
      "compression_ratio": 1.6622806787490845,
      "no_speech_prob": 0.11498497426509857
    },
    {
      "id": 209,
      "seek": 65200,
      "start": 3070.46,
      "end": 3072.46,
      "text": " it's actually about,",
      "tokens": [
        50964,
        309,
        311,
        767,
        466,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41484692692756653,
      "compression_ratio": 1.6622806787490845,
      "no_speech_prob": 0.11498497426509857
    },
    {
      "id": 210,
      "seek": 65200,
      "start": 3072.46,
      "end": 3075.46,
      "text": " that OpenAI can continue to operate the system",
      "tokens": [
        51064,
        300,
        7238,
        48698,
        393,
        2354,
        281,
        9651,
        264,
        1185,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41484692692756653,
      "compression_ratio": 1.6622806787490845,
      "no_speech_prob": 0.11498497426509857
    },
    {
      "id": 211,
      "seek": 65200,
      "start": 3075.46,
      "end": 3077.46,
      "text": " and not someone says,",
      "tokens": [
        51214,
        293,
        406,
        1580,
        1619,
        11,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41484692692756653,
      "compression_ratio": 1.6622806787490845,
      "no_speech_prob": 0.11498497426509857
    },
    {
      "id": 212,
      "seek": 65200,
      "start": 3077.46,
      "end": 3079.46,
      "text": " that it's obviously a very terrible system,",
      "tokens": [
        51314,
        300,
        309,
        311,
        2745,
        257,
        588,
        6237,
        1185,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41484692692756653,
      "compression_ratio": 1.6622806787490845,
      "no_speech_prob": 0.11498497426509857
    },
    {
      "id": 213,
      "seek": 65200,
      "start": 3079.46,
      "end": 3081.46,
      "text": " because that tells people,",
      "tokens": [
        51414,
        570,
        300,
        5112,
        561,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41484692692756653,
      "compression_ratio": 1.6622806787490845,
      "no_speech_prob": 0.11498497426509857
    },
    {
      "id": 214,
      "seek": 65200,
      "start": 3081.46,
      "end": 3083.46,
      "text": " how they can build Molotov cocktails.",
      "tokens": [
        51514,
        577,
        436,
        393,
        1322,
        28278,
        310,
        5179,
        49006,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41484692692756653,
      "compression_ratio": 1.6622806787490845,
      "no_speech_prob": 0.11498497426509857
    },
    {
      "id": 215,
      "seek": 65200,
      "start": 3083.46,
      "end": 3086.46,
      "text": " And in this sense,",
      "tokens": [
        51614,
        400,
        294,
        341,
        2020,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41484692692756653,
      "compression_ratio": 1.6622806787490845,
      "no_speech_prob": 0.11498497426509857
    },
    {
      "id": 216,
      "seek": 68000,
      "start": 3086.46,
      "end": 3090.46,
      "text": " what happened there as an attack,",
      "tokens": [
        50364,
        437,
        2011,
        456,
        382,
        364,
        2690,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3916713297367096,
      "compression_ratio": 1.5945945978164673,
      "no_speech_prob": 0.07810860872268677
    },
    {
      "id": 217,
      "seek": 68000,
      "start": 3090.46,
      "end": 3092.46,
      "text": " I would say,",
      "tokens": [
        50564,
        286,
        576,
        584,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3916713297367096,
      "compression_ratio": 1.5945945978164673,
      "no_speech_prob": 0.07810860872268677
    },
    {
      "id": 218,
      "seek": 68000,
      "start": 3092.46,
      "end": 3094.46,
      "text": " is not really a problem,",
      "tokens": [
        50664,
        307,
        406,
        534,
        257,
        1154,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3916713297367096,
      "compression_ratio": 1.5945945978164673,
      "no_speech_prob": 0.07810860872268677
    },
    {
      "id": 219,
      "seek": 68000,
      "start": 3094.46,
      "end": 3098.46,
      "text": " because OpenAI will not have to take the system offline",
      "tokens": [
        50764,
        570,
        7238,
        48698,
        486,
        406,
        362,
        281,
        747,
        264,
        1185,
        21857,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3916713297367096,
      "compression_ratio": 1.5945945978164673,
      "no_speech_prob": 0.07810860872268677
    },
    {
      "id": 220,
      "seek": 68000,
      "start": 3098.46,
      "end": 3101.46,
      "text": " because of this problem,",
      "tokens": [
        50964,
        570,
        295,
        341,
        1154,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3916713297367096,
      "compression_ratio": 1.5945945978164673,
      "no_speech_prob": 0.07810860872268677
    },
    {
      "id": 221,
      "seek": 68000,
      "start": 3101.46,
      "end": 3104.46,
      "text": " but they will maybe protect it better,",
      "tokens": [
        51114,
        457,
        436,
        486,
        1310,
        2371,
        309,
        1101,
        11,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3916713297367096,
      "compression_ratio": 1.5945945978164673,
      "no_speech_prob": 0.07810860872268677
    },
    {
      "id": 222,
      "seek": 68000,
      "start": 3104.46,
      "end": 3106.46,
      "text": " or they will talk themselves out of it",
      "tokens": [
        51264,
        420,
        436,
        486,
        751,
        2969,
        484,
        295,
        309,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3916713297367096,
      "compression_ratio": 1.5945945978164673,
      "no_speech_prob": 0.07810860872268677
    },
    {
      "id": 223,
      "seek": 68000,
      "start": 3106.46,
      "end": 3107.46,
      "text": " and will say,",
      "tokens": [
        51364,
        293,
        486,
        584,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3916713297367096,
      "compression_ratio": 1.5945945978164673,
      "no_speech_prob": 0.07810860872268677
    },
    {
      "id": 224,
      "seek": 68000,
      "start": 3107.46,
      "end": 3109.46,
      "text": " well, it's just not like that.",
      "tokens": [
        51414,
        731,
        11,
        309,
        311,
        445,
        406,
        411,
        300,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3916713297367096,
      "compression_ratio": 1.5945945978164673,
      "no_speech_prob": 0.07810860872268677
    },
    {
      "id": 225,
      "seek": 68000,
      "start": 3109.46,
      "end": 3112.46,
      "text": " So that's just one,",
      "tokens": [
        51514,
        407,
        300,
        311,
        445,
        472,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3916713297367096,
      "compression_ratio": 1.5945945978164673,
      "no_speech_prob": 0.07810860872268677
    },
    {
      "id": 226,
      "seek": 70600,
      "start": 3112.46,
      "end": 3117.46,
      "text": " because someone tried very hard and whatever.",
      "tokens": [
        50364,
        570,
        1580,
        3031,
        588,
        1152,
        293,
        2035,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3986901044845581,
      "compression_ratio": 1.4137930870056152,
      "no_speech_prob": 0.3992358446121216
    },
    {
      "id": 227,
      "seek": 70600,
      "start": 3120.46,
      "end": 3123.46,
      "text": " The other possibility,",
      "tokens": [
        50764,
        440,
        661,
        7959,
        11,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3986901044845581,
      "compression_ratio": 1.4137930870056152,
      "no_speech_prob": 0.3992358446121216
    },
    {
      "id": 228,
      "seek": 70600,
      "start": 3123.46,
      "end": 3126.46,
      "text": " and I think that's what Christian just said a little bit,",
      "tokens": [
        50914,
        293,
        286,
        519,
        300,
        311,
        437,
        5778,
        445,
        848,
        257,
        707,
        857,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3986901044845581,
      "compression_ratio": 1.4137930870056152,
      "no_speech_prob": 0.3992358446121216
    },
    {
      "id": 229,
      "seek": 70600,
      "start": 3126.46,
      "end": 3127.46,
      "text": " is,",
      "tokens": [
        51064,
        307,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3986901044845581,
      "compression_ratio": 1.4137930870056152,
      "no_speech_prob": 0.3992358446121216
    },
    {
      "id": 230,
      "seek": 70600,
      "start": 3127.46,
      "end": 3128.46,
      "text": " well,",
      "tokens": [
        51114,
        731,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3986901044845581,
      "compression_ratio": 1.4137930870056152,
      "no_speech_prob": 0.3992358446121216
    },
    {
      "id": 231,
      "seek": 70600,
      "start": 3128.46,
      "end": 3132.46,
      "text": " the system gives out information,",
      "tokens": [
        51164,
        264,
        1185,
        2709,
        484,
        1589,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3986901044845581,
      "compression_ratio": 1.4137930870056152,
      "no_speech_prob": 0.3992358446121216
    },
    {
      "id": 232,
      "seek": 70600,
      "start": 3132.46,
      "end": 3135.46,
      "text": " that should actually be protected.",
      "tokens": [
        51364,
        300,
        820,
        767,
        312,
        10594,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3986901044845581,
      "compression_ratio": 1.4137930870056152,
      "no_speech_prob": 0.3992358446121216
    },
    {
      "id": 233,
      "seek": 70600,
      "start": 3135.46,
      "end": 3137.46,
      "text": " And I claim,",
      "tokens": [
        51514,
        400,
        286,
        3932,
        11,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3986901044845581,
      "compression_ratio": 1.4137930870056152,
      "no_speech_prob": 0.3992358446121216
    },
    {
      "id": 234,
      "seek": 70600,
      "start": 3137.46,
      "end": 3140.46,
      "text": " that in this specific case,",
      "tokens": [
        51614,
        300,
        294,
        341,
        2685,
        1389,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3986901044845581,
      "compression_ratio": 1.4137930870056152,
      "no_speech_prob": 0.3992358446121216
    },
    {
      "id": 235,
      "seek": 73400,
      "start": 3140.46,
      "end": 3144.46,
      "text": " it's not really the problem.",
      "tokens": [
        50364,
        309,
        311,
        406,
        534,
        264,
        1154,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.365304172039032,
      "compression_ratio": 1.5277777910232544,
      "no_speech_prob": 0.13575176894664764
    },
    {
      "id": 236,
      "seek": 73400,
      "start": 3144.46,
      "end": 3146.46,
      "text": " So what I mean is the following.",
      "tokens": [
        50564,
        407,
        437,
        286,
        914,
        307,
        264,
        3480,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.365304172039032,
      "compression_ratio": 1.5277777910232544,
      "no_speech_prob": 0.13575176894664764
    },
    {
      "id": 237,
      "seek": 73400,
      "start": 3146.46,
      "end": 3148.46,
      "text": " As part of this, I found out,",
      "tokens": [
        50664,
        1018,
        644,
        295,
        341,
        11,
        286,
        1352,
        484,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.365304172039032,
      "compression_ratio": 1.5277777910232544,
      "no_speech_prob": 0.13575176894664764
    },
    {
      "id": 238,
      "seek": 73400,
      "start": 3148.46,
      "end": 3149.46,
      "text": " that you can actually,",
      "tokens": [
        50764,
        300,
        291,
        393,
        767,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.365304172039032,
      "compression_ratio": 1.5277777910232544,
      "no_speech_prob": 0.13575176894664764
    },
    {
      "id": 239,
      "seek": 73400,
      "start": 3149.46,
      "end": 3152.46,
      "text": " within three clicks,",
      "tokens": [
        50814,
        1951,
        1045,
        18521,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.365304172039032,
      "compression_ratio": 1.5277777910232544,
      "no_speech_prob": 0.13575176894664764
    },
    {
      "id": 240,
      "seek": 73400,
      "start": 3152.46,
      "end": 3154.46,
      "text": " and a little superficial research,",
      "tokens": [
        50964,
        293,
        257,
        707,
        34622,
        2132,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.365304172039032,
      "compression_ratio": 1.5277777910232544,
      "no_speech_prob": 0.13575176894664764
    },
    {
      "id": 241,
      "seek": 73400,
      "start": 3154.46,
      "end": 3156.46,
      "text": " build instructions for,",
      "tokens": [
        51064,
        1322,
        9415,
        337,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.365304172039032,
      "compression_ratio": 1.5277777910232544,
      "no_speech_prob": 0.13575176894664764
    },
    {
      "id": 242,
      "seek": 73400,
      "start": 3156.46,
      "end": 3159.46,
      "text": " for example, nail bombs.",
      "tokens": [
        51164,
        337,
        1365,
        11,
        297,
        1301,
        75,
        19043,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.365304172039032,
      "compression_ratio": 1.5277777910232544,
      "no_speech_prob": 0.13575176894664764
    },
    {
      "id": 243,
      "seek": 73400,
      "start": 3159.46,
      "end": 3161.46,
      "text": " These are public on the Internet.",
      "tokens": [
        51314,
        1981,
        366,
        1908,
        322,
        264,
        7703,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.365304172039032,
      "compression_ratio": 1.5277777910232544,
      "no_speech_prob": 0.13575176894664764
    },
    {
      "id": 244,
      "seek": 73400,
      "start": 3161.46,
      "end": 3162.46,
      "text": " And I think we're doing now",
      "tokens": [
        51414,
        400,
        286,
        519,
        321,
        434,
        884,
        586,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.365304172039032,
      "compression_ratio": 1.5277777910232544,
      "no_speech_prob": 0.13575176894664764
    },
    {
      "id": 245,
      "seek": 73400,
      "start": 3162.46,
      "end": 3163.46,
      "text": " in a search engine,",
      "tokens": [
        51464,
        294,
        257,
        3164,
        2848,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.365304172039032,
      "compression_ratio": 1.5277777910232544,
      "no_speech_prob": 0.13575176894664764
    },
    {
      "id": 246,
      "seek": 73400,
      "start": 3163.46,
      "end": 3164.46,
      "text": " Dr. Go or something,",
      "tokens": [
        51514,
        2491,
        13,
        1037,
        420,
        746,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.365304172039032,
      "compression_ratio": 1.5277777910232544,
      "no_speech_prob": 0.13575176894664764
    },
    {
      "id": 247,
      "seek": 73400,
      "start": 3164.46,
      "end": 3165.46,
      "text": " no accusation,",
      "tokens": [
        51564,
        572,
        11168,
        399,
        11,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.365304172039032,
      "compression_ratio": 1.5277777910232544,
      "no_speech_prob": 0.13575176894664764
    },
    {
      "id": 248,
      "seek": 73400,
      "start": 3165.46,
      "end": 3169.46,
      "text": " because it somehow helps me with such research.",
      "tokens": [
        51614,
        570,
        309,
        6063,
        3665,
        385,
        365,
        1270,
        2132,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.365304172039032,
      "compression_ratio": 1.5277777910232544,
      "no_speech_prob": 0.13575176894664764
    },
    {
      "id": 249,
      "seek": 76300,
      "start": 3169.46,
      "end": 3173.46,
      "text": " Why are we making an accusation now?",
      "tokens": [
        50364,
        1545,
        366,
        321,
        1455,
        364,
        11168,
        399,
        586,
        30,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36322492361068726,
      "compression_ratio": 1.6962025165557861,
      "no_speech_prob": 0.022172395139932632
    },
    {
      "id": 250,
      "seek": 76300,
      "start": 3173.46,
      "end": 3175.46,
      "text": " Why should we make an accusation there?",
      "tokens": [
        50564,
        1545,
        820,
        321,
        652,
        364,
        11168,
        399,
        456,
        30,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36322492361068726,
      "compression_ratio": 1.6962025165557861,
      "no_speech_prob": 0.022172395139932632
    },
    {
      "id": 251,
      "seek": 76300,
      "start": 3175.46,
      "end": 3176.46,
      "text": " That's basically the same thing.",
      "tokens": [
        50664,
        663,
        311,
        1936,
        264,
        912,
        551,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36322492361068726,
      "compression_ratio": 1.6962025165557861,
      "no_speech_prob": 0.022172395139932632
    },
    {
      "id": 252,
      "seek": 76300,
      "start": 3176.46,
      "end": 3177.46,
      "text": " That means,",
      "tokens": [
        50714,
        663,
        1355,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36322492361068726,
      "compression_ratio": 1.6962025165557861,
      "no_speech_prob": 0.022172395139932632
    },
    {
      "id": 253,
      "seek": 76300,
      "start": 3177.46,
      "end": 3178.46,
      "text": " there is somehow this knowledge base,",
      "tokens": [
        50764,
        456,
        307,
        6063,
        341,
        3601,
        3096,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36322492361068726,
      "compression_ratio": 1.6962025165557861,
      "no_speech_prob": 0.022172395139932632
    },
    {
      "id": 254,
      "seek": 76300,
      "start": 3178.46,
      "end": 3180.46,
      "text": " which is somehow on this Internet.",
      "tokens": [
        50814,
        597,
        307,
        6063,
        322,
        341,
        7703,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36322492361068726,
      "compression_ratio": 1.6962025165557861,
      "no_speech_prob": 0.022172395139932632
    },
    {
      "id": 255,
      "seek": 76300,
      "start": 3180.46,
      "end": 3184.46,
      "text": " And I'm making a request now.",
      "tokens": [
        50914,
        400,
        286,
        478,
        1455,
        257,
        5308,
        586,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36322492361068726,
      "compression_ratio": 1.6962025165557861,
      "no_speech_prob": 0.022172395139932632
    },
    {
      "id": 256,
      "seek": 76300,
      "start": 3184.46,
      "end": 3187.46,
      "text": " I can give it to Dr. Go,",
      "tokens": [
        51114,
        286,
        393,
        976,
        309,
        281,
        2491,
        13,
        1037,
        11,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36322492361068726,
      "compression_ratio": 1.6962025165557861,
      "no_speech_prob": 0.022172395139932632
    },
    {
      "id": 257,
      "seek": 76300,
      "start": 3187.46,
      "end": 3188.46,
      "text": " as a search engine,",
      "tokens": [
        51264,
        382,
        257,
        3164,
        2848,
        11,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36322492361068726,
      "compression_ratio": 1.6962025165557861,
      "no_speech_prob": 0.022172395139932632
    },
    {
      "id": 258,
      "seek": 76300,
      "start": 3188.46,
      "end": 3190.46,
      "text": " or I can give it to Chet Chibiti,",
      "tokens": [
        51314,
        420,
        286,
        393,
        976,
        309,
        281,
        761,
        302,
        761,
        897,
        8707,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36322492361068726,
      "compression_ratio": 1.6962025165557861,
      "no_speech_prob": 0.022172395139932632
    },
    {
      "id": 259,
      "seek": 76300,
      "start": 3190.46,
      "end": 3193.46,
      "text": " and then I get a result.",
      "tokens": [
        51414,
        293,
        550,
        286,
        483,
        257,
        1874,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36322492361068726,
      "compression_ratio": 1.6962025165557861,
      "no_speech_prob": 0.022172395139932632
    },
    {
      "id": 260,
      "seek": 76300,
      "start": 3193.46,
      "end": 3196.46,
      "text": " And that's just the way it is, so to speak.",
      "tokens": [
        51564,
        400,
        300,
        311,
        445,
        264,
        636,
        309,
        307,
        11,
        370,
        281,
        1710,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36322492361068726,
      "compression_ratio": 1.6962025165557861,
      "no_speech_prob": 0.022172395139932632
    },
    {
      "id": 261,
      "seek": 76300,
      "start": 3196.46,
      "end": 3198.46,
      "text": " That means the real question,",
      "tokens": [
        51714,
        663,
        1355,
        264,
        957,
        1168,
        11,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36322492361068726,
      "compression_ratio": 1.6962025165557861,
      "no_speech_prob": 0.022172395139932632
    },
    {
      "id": 262,
      "seek": 79200,
      "start": 3198.46,
      "end": 3200.46,
      "text": " public information is public.",
      "tokens": [
        50364,
        1908,
        1589,
        307,
        1908,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471719026565552,
      "compression_ratio": 1.7068272829055786,
      "no_speech_prob": 0.055838994681835175
    },
    {
      "id": 263,
      "seek": 79200,
      "start": 3200.46,
      "end": 3202.46,
      "text": " I can't protect it again.",
      "tokens": [
        50464,
        286,
        393,
        380,
        2371,
        309,
        797,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471719026565552,
      "compression_ratio": 1.7068272829055786,
      "no_speech_prob": 0.055838994681835175
    },
    {
      "id": 264,
      "seek": 79200,
      "start": 3202.46,
      "end": 3204.46,
      "text": " And Christian's point is somehow relevant there.",
      "tokens": [
        50564,
        400,
        5778,
        311,
        935,
        307,
        6063,
        7340,
        456,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471719026565552,
      "compression_ratio": 1.7068272829055786,
      "no_speech_prob": 0.055838994681835175
    },
    {
      "id": 265,
      "seek": 79200,
      "start": 3204.46,
      "end": 3207.46,
      "text": " So if I don't do public data in an LLM,",
      "tokens": [
        50664,
        407,
        498,
        286,
        500,
        380,
        360,
        1908,
        1412,
        294,
        364,
        441,
        43,
        44,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471719026565552,
      "compression_ratio": 1.7068272829055786,
      "no_speech_prob": 0.055838994681835175
    },
    {
      "id": 266,
      "seek": 79200,
      "start": 3207.46,
      "end": 3208.46,
      "text": " which is publicly accessible,",
      "tokens": [
        50814,
        597,
        307,
        14843,
        9515,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471719026565552,
      "compression_ratio": 1.7068272829055786,
      "no_speech_prob": 0.055838994681835175
    },
    {
      "id": 267,
      "seek": 79200,
      "start": 3208.46,
      "end": 3209.46,
      "text": " surprise,",
      "tokens": [
        50864,
        6365,
        11,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471719026565552,
      "compression_ratio": 1.7068272829055786,
      "no_speech_prob": 0.055838994681835175
    },
    {
      "id": 268,
      "seek": 79200,
      "start": 3209.46,
      "end": 3211.46,
      "text": " then I really have a problem.",
      "tokens": [
        50914,
        550,
        286,
        534,
        362,
        257,
        1154,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471719026565552,
      "compression_ratio": 1.7068272829055786,
      "no_speech_prob": 0.055838994681835175
    },
    {
      "id": 269,
      "seek": 79200,
      "start": 3211.46,
      "end": 3212.46,
      "text": " But that's somehow,",
      "tokens": [
        51014,
        583,
        300,
        311,
        6063,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471719026565552,
      "compression_ratio": 1.7068272829055786,
      "no_speech_prob": 0.055838994681835175
    },
    {
      "id": 270,
      "seek": 79200,
      "start": 3212.46,
      "end": 3213.46,
      "text": " that's just the way it is,",
      "tokens": [
        51064,
        300,
        311,
        445,
        264,
        636,
        309,
        307,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471719026565552,
      "compression_ratio": 1.7068272829055786,
      "no_speech_prob": 0.055838994681835175
    },
    {
      "id": 271,
      "seek": 79200,
      "start": 3213.46,
      "end": 3215.46,
      "text": " if I put it on the Internet otherwise.",
      "tokens": [
        51114,
        498,
        286,
        829,
        309,
        322,
        264,
        7703,
        5911,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471719026565552,
      "compression_ratio": 1.7068272829055786,
      "no_speech_prob": 0.055838994681835175
    },
    {
      "id": 272,
      "seek": 79200,
      "start": 3215.46,
      "end": 3217.46,
      "text": " I actually only put this information",
      "tokens": [
        51214,
        286,
        767,
        787,
        829,
        341,
        1589,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471719026565552,
      "compression_ratio": 1.7068272829055786,
      "no_speech_prob": 0.055838994681835175
    },
    {
      "id": 273,
      "seek": 79200,
      "start": 3217.46,
      "end": 3219.46,
      "text": " in a different way on the Internet.",
      "tokens": [
        51314,
        294,
        257,
        819,
        636,
        322,
        264,
        7703,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471719026565552,
      "compression_ratio": 1.7068272829055786,
      "no_speech_prob": 0.055838994681835175
    },
    {
      "id": 274,
      "seek": 79200,
      "start": 3219.46,
      "end": 3221.46,
      "text": " And to be precise,",
      "tokens": [
        51414,
        400,
        281,
        312,
        13600,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471719026565552,
      "compression_ratio": 1.7068272829055786,
      "no_speech_prob": 0.055838994681835175
    },
    {
      "id": 275,
      "seek": 79200,
      "start": 3221.46,
      "end": 3226.46,
      "text": " it's just that this system says,",
      "tokens": [
        51514,
        309,
        311,
        445,
        300,
        341,
        1185,
        1619,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3471719026565552,
      "compression_ratio": 1.7068272829055786,
      "no_speech_prob": 0.055838994681835175
    },
    {
      "id": 276,
      "seek": 82000,
      "start": 3226.46,
      "end": 3228.46,
      "text": " somewhere on the Internet I read",
      "tokens": [
        50364,
        4079,
        322,
        264,
        7703,
        286,
        1401,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2816162109375,
      "compression_ratio": 1.5233160257339478,
      "no_speech_prob": 0.08957742899656296
    },
    {
      "id": 277,
      "seek": 82000,
      "start": 3228.46,
      "end": 3230.46,
      "text": " that you build Molotov cocktails like this.",
      "tokens": [
        50464,
        300,
        291,
        1322,
        28278,
        310,
        5179,
        49006,
        411,
        341,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2816162109375,
      "compression_ratio": 1.5233160257339478,
      "no_speech_prob": 0.08957742899656296
    },
    {
      "id": 278,
      "seek": 82000,
      "start": 3230.46,
      "end": 3232.46,
      "text": " But I can't say exactly where.",
      "tokens": [
        50564,
        583,
        286,
        393,
        380,
        584,
        2293,
        689,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2816162109375,
      "compression_ratio": 1.5233160257339478,
      "no_speech_prob": 0.08957742899656296
    },
    {
      "id": 279,
      "seek": 82000,
      "start": 3232.46,
      "end": 3235.46,
      "text": " And I remember it roughly like this.",
      "tokens": [
        50664,
        400,
        286,
        1604,
        309,
        9810,
        411,
        341,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2816162109375,
      "compression_ratio": 1.5233160257339478,
      "no_speech_prob": 0.08957742899656296
    },
    {
      "id": 280,
      "seek": 82000,
      "start": 3235.46,
      "end": 3238.46,
      "text": " But maybe I'm just inspired by the text.",
      "tokens": [
        50814,
        583,
        1310,
        286,
        478,
        445,
        7547,
        538,
        264,
        2487,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2816162109375,
      "compression_ratio": 1.5233160257339478,
      "no_speech_prob": 0.08957742899656296
    },
    {
      "id": 281,
      "seek": 82000,
      "start": 3238.46,
      "end": 3244.46,
      "text": " And yes, nice try.",
      "tokens": [
        50964,
        400,
        2086,
        11,
        1481,
        853,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2816162109375,
      "compression_ratio": 1.5233160257339478,
      "no_speech_prob": 0.08957742899656296
    },
    {
      "id": 282,
      "seek": 82000,
      "start": 3244.46,
      "end": 3249.46,
      "text": " But that wouldn't be enough for me.",
      "tokens": [
        51264,
        583,
        300,
        2759,
        380,
        312,
        1547,
        337,
        385,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2816162109375,
      "compression_ratio": 1.5233160257339478,
      "no_speech_prob": 0.08957742899656296
    },
    {
      "id": 283,
      "seek": 82000,
      "start": 3249.46,
      "end": 3253.46,
      "text": " And Christian just wrote,",
      "tokens": [
        51514,
        400,
        5778,
        445,
        4114,
        11,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2816162109375,
      "compression_ratio": 1.5233160257339478,
      "no_speech_prob": 0.08957742899656296
    },
    {
      "id": 284,
      "seek": 82000,
      "start": 3253.46,
      "end": 3255.46,
      "text": " the example doesn't matter.",
      "tokens": [
        51714,
        264,
        1365,
        1177,
        380,
        1871,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2816162109375,
      "compression_ratio": 1.5233160257339478,
      "no_speech_prob": 0.08957742899656296
    },
    {
      "id": 285,
      "seek": 84900,
      "start": 3255.46,
      "end": 3257.46,
      "text": " Everyone can have the anarchist cookbook.",
      "tokens": [
        50364,
        5198,
        393,
        362,
        264,
        41957,
        468,
        2543,
        2939,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3404061496257782,
      "compression_ratio": 1.6824034452438354,
      "no_speech_prob": 0.2973087728023529
    },
    {
      "id": 286,
      "seek": 84900,
      "start": 3257.46,
      "end": 3259.46,
      "text": " As I said, the real risk is to use such systems",
      "tokens": [
        50464,
        1018,
        286,
        848,
        11,
        264,
        957,
        3148,
        307,
        281,
        764,
        1270,
        3652,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3404061496257782,
      "compression_ratio": 1.6824034452438354,
      "no_speech_prob": 0.2973087728023529
    },
    {
      "id": 287,
      "seek": 84900,
      "start": 3259.46,
      "end": 3261.46,
      "text": " without human oversight on internal systems",
      "tokens": [
        50564,
        1553,
        1952,
        29146,
        322,
        6920,
        3652,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3404061496257782,
      "compression_ratio": 1.6824034452438354,
      "no_speech_prob": 0.2973087728023529
    },
    {
      "id": 288,
      "seek": 84900,
      "start": 3261.46,
      "end": 3264.46,
      "text": " and only as a CRM lookup.",
      "tokens": [
        50664,
        293,
        787,
        382,
        257,
        14123,
        44,
        574,
        1010,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3404061496257782,
      "compression_ratio": 1.6824034452438354,
      "no_speech_prob": 0.2973087728023529
    },
    {
      "id": 289,
      "seek": 84900,
      "start": 3264.46,
      "end": 3265.46,
      "text": " Exactly.",
      "tokens": [
        50814,
        7587,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3404061496257782,
      "compression_ratio": 1.6824034452438354,
      "no_speech_prob": 0.2973087728023529
    },
    {
      "id": 290,
      "seek": 84900,
      "start": 3265.46,
      "end": 3268.46,
      "text": " So that means that I shouldn't do that.",
      "tokens": [
        50864,
        407,
        300,
        1355,
        300,
        286,
        4659,
        380,
        360,
        300,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3404061496257782,
      "compression_ratio": 1.6824034452438354,
      "no_speech_prob": 0.2973087728023529
    },
    {
      "id": 291,
      "seek": 84900,
      "start": 3268.46,
      "end": 3270.46,
      "text": " But maybe I shouldn't do that anyway.",
      "tokens": [
        51014,
        583,
        1310,
        286,
        4659,
        380,
        360,
        300,
        4033,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3404061496257782,
      "compression_ratio": 1.6824034452438354,
      "no_speech_prob": 0.2973087728023529
    },
    {
      "id": 292,
      "seek": 84900,
      "start": 3270.46,
      "end": 3272.46,
      "text": " So I shouldn't put systems",
      "tokens": [
        51114,
        407,
        286,
        4659,
        380,
        829,
        3652,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3404061496257782,
      "compression_ratio": 1.6824034452438354,
      "no_speech_prob": 0.2973087728023529
    },
    {
      "id": 293,
      "seek": 84900,
      "start": 3272.46,
      "end": 3275.46,
      "text": " that are trained with my CRM,",
      "tokens": [
        51214,
        300,
        366,
        8895,
        365,
        452,
        14123,
        44,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3404061496257782,
      "compression_ratio": 1.6824034452438354,
      "no_speech_prob": 0.2973087728023529
    },
    {
      "id": 294,
      "seek": 84900,
      "start": 3275.46,
      "end": 3278.46,
      "text": " that have secret information as training,",
      "tokens": [
        51364,
        300,
        362,
        4054,
        1589,
        382,
        3097,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3404061496257782,
      "compression_ratio": 1.6824034452438354,
      "no_speech_prob": 0.2973087728023529
    },
    {
      "id": 295,
      "seek": 84900,
      "start": 3278.46,
      "end": 3284.46,
      "text": " I shouldn't put them on the Internet publicly.",
      "tokens": [
        51514,
        286,
        4659,
        380,
        829,
        552,
        322,
        264,
        7703,
        14843,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3404061496257782,
      "compression_ratio": 1.6824034452438354,
      "no_speech_prob": 0.2973087728023529
    },
    {
      "id": 296,
      "seek": 87800,
      "start": 3284.46,
      "end": 3286.46,
      "text": " Which means,",
      "tokens": [
        50364,
        3013,
        1355,
        11,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39543458819389343,
      "compression_ratio": 1.454545497894287,
      "no_speech_prob": 0.03824588656425476
    },
    {
      "id": 297,
      "seek": 87800,
      "start": 3286.46,
      "end": 3290.46,
      "text": " if the system has only been trained",
      "tokens": [
        50464,
        498,
        264,
        1185,
        575,
        787,
        668,
        8895,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39543458819389343,
      "compression_ratio": 1.454545497894287,
      "no_speech_prob": 0.03824588656425476
    },
    {
      "id": 298,
      "seek": 87800,
      "start": 3290.46,
      "end": 3293.46,
      "text": " with authentic documents of a terrorist organization,",
      "tokens": [
        50664,
        365,
        1609,
        392,
        317,
        299,
        8512,
        295,
        257,
        20342,
        4475,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39543458819389343,
      "compression_ratio": 1.454545497894287,
      "no_speech_prob": 0.03824588656425476
    },
    {
      "id": 299,
      "seek": 87800,
      "start": 3293.46,
      "end": 3296.46,
      "text": " then I will rate it differently.",
      "tokens": [
        50814,
        550,
        286,
        486,
        5937,
        68,
        309,
        7614,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39543458819389343,
      "compression_ratio": 1.454545497894287,
      "no_speech_prob": 0.03824588656425476
    },
    {
      "id": 300,
      "seek": 87800,
      "start": 3296.46,
      "end": 3302.46,
      "text": " But that's just another system",
      "tokens": [
        50964,
        583,
        300,
        311,
        445,
        1071,
        1185,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39543458819389343,
      "compression_ratio": 1.454545497894287,
      "no_speech_prob": 0.03824588656425476
    },
    {
      "id": 301,
      "seek": 87800,
      "start": 3302.46,
      "end": 3305.46,
      "text": " that has information",
      "tokens": [
        51264,
        300,
        575,
        1589,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39543458819389343,
      "compression_ratio": 1.454545497894287,
      "no_speech_prob": 0.03824588656425476
    },
    {
      "id": 302,
      "seek": 87800,
      "start": 3305.46,
      "end": 3310.46,
      "text": " that I don't want to find on the Internet anyway,",
      "tokens": [
        51414,
        300,
        286,
        500,
        380,
        528,
        281,
        915,
        322,
        264,
        7703,
        4033,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39543458819389343,
      "compression_ratio": 1.454545497894287,
      "no_speech_prob": 0.03824588656425476
    },
    {
      "id": 303,
      "seek": 87800,
      "start": 3310.46,
      "end": 3312.46,
      "text": " in a public place.",
      "tokens": [
        51664,
        294,
        257,
        1908,
        1081,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39543458819389343,
      "compression_ratio": 1.454545497894287,
      "no_speech_prob": 0.03824588656425476
    },
    {
      "id": 304,
      "seek": 90600,
      "start": 3312.46,
      "end": 3315.46,
      "text": " And that leads to another topic,",
      "tokens": [
        50364,
        400,
        300,
        6689,
        281,
        1071,
        4829,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3688201904296875,
      "compression_ratio": 1.609302282333374,
      "no_speech_prob": 0.06876786053180695
    },
    {
      "id": 305,
      "seek": 90600,
      "start": 3315.46,
      "end": 3317.46,
      "text": " and I find that interesting at this point.",
      "tokens": [
        50514,
        293,
        286,
        915,
        300,
        1880,
        412,
        341,
        935,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3688201904296875,
      "compression_ratio": 1.609302282333374,
      "no_speech_prob": 0.06876786053180695
    },
    {
      "id": 306,
      "seek": 90600,
      "start": 3317.46,
      "end": 3322.46,
      "text": " If I actually apply the concept",
      "tokens": [
        50614,
        759,
        286,
        767,
        3079,
        264,
        3410,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3688201904296875,
      "compression_ratio": 1.609302282333374,
      "no_speech_prob": 0.06876786053180695
    },
    {
      "id": 307,
      "seek": 90600,
      "start": 3322.46,
      "end": 3325.46,
      "text": " that I want to control the result,",
      "tokens": [
        50864,
        300,
        286,
        528,
        281,
        1969,
        264,
        1874,
        11,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3688201904296875,
      "compression_ratio": 1.609302282333374,
      "no_speech_prob": 0.06876786053180695
    },
    {
      "id": 308,
      "seek": 90600,
      "start": 3325.46,
      "end": 3327.46,
      "text": " and I have to,",
      "tokens": [
        51014,
        293,
        286,
        362,
        281,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3688201904296875,
      "compression_ratio": 1.609302282333374,
      "no_speech_prob": 0.06876786053180695
    },
    {
      "id": 309,
      "seek": 90600,
      "start": 3327.46,
      "end": 3330.46,
      "text": " then that means that this chat GPT problem",
      "tokens": [
        51114,
        550,
        300,
        1355,
        300,
        341,
        5081,
        26039,
        51,
        1154,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3688201904296875,
      "compression_ratio": 1.609302282333374,
      "no_speech_prob": 0.06876786053180695
    },
    {
      "id": 310,
      "seek": 90600,
      "start": 3330.46,
      "end": 3333.46,
      "text": " is actually a smaller problem,",
      "tokens": [
        51264,
        307,
        767,
        257,
        4356,
        1154,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3688201904296875,
      "compression_ratio": 1.609302282333374,
      "no_speech_prob": 0.06876786053180695
    },
    {
      "id": 311,
      "seek": 90600,
      "start": 3333.46,
      "end": 3335.46,
      "text": " because I need another source",
      "tokens": [
        51414,
        570,
        286,
        643,
        1071,
        4009,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3688201904296875,
      "compression_ratio": 1.609302282333374,
      "no_speech_prob": 0.06876786053180695
    },
    {
      "id": 312,
      "seek": 90600,
      "start": 3335.46,
      "end": 3337.46,
      "text": " with which I can somehow compensate.",
      "tokens": [
        51514,
        365,
        597,
        286,
        393,
        6063,
        29458,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3688201904296875,
      "compression_ratio": 1.609302282333374,
      "no_speech_prob": 0.06876786053180695
    },
    {
      "id": 313,
      "seek": 90600,
      "start": 3337.46,
      "end": 3339.46,
      "text": " So the information I get back",
      "tokens": [
        51614,
        407,
        264,
        1589,
        286,
        483,
        646,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3688201904296875,
      "compression_ratio": 1.609302282333374,
      "no_speech_prob": 0.06876786053180695
    },
    {
      "id": 314,
      "seek": 90600,
      "start": 3339.46,
      "end": 3341.46,
      "text": " is just bullshit.",
      "tokens": [
        51714,
        307,
        445,
        22676,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3688201904296875,
      "compression_ratio": 1.609302282333374,
      "no_speech_prob": 0.06876786053180695
    },
    {
      "id": 315,
      "seek": 93500,
      "start": 3341.46,
      "end": 3343.46,
      "text": " It's just not the case",
      "tokens": [
        50364,
        467,
        311,
        445,
        406,
        264,
        1389,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36120495200157166,
      "compression_ratio": 1.6478873491287231,
      "no_speech_prob": 0.2560506761074066
    },
    {
      "id": 316,
      "seek": 93500,
      "start": 3343.46,
      "end": 3347.46,
      "text": " that it's controlled by the truth value.",
      "tokens": [
        50464,
        300,
        309,
        311,
        10164,
        538,
        264,
        3494,
        2158,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36120495200157166,
      "compression_ratio": 1.6478873491287231,
      "no_speech_prob": 0.2560506761074066
    },
    {
      "id": 317,
      "seek": 93500,
      "start": 3347.46,
      "end": 3349.46,
      "text": " So I'll probably have to",
      "tokens": [
        50664,
        407,
        286,
        603,
        1391,
        362,
        281,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36120495200157166,
      "compression_ratio": 1.6478873491287231,
      "no_speech_prob": 0.2560506761074066
    },
    {
      "id": 318,
      "seek": 93500,
      "start": 3349.46,
      "end": 3351.46,
      "text": " control it in some ideal way.",
      "tokens": [
        50764,
        1969,
        309,
        294,
        512,
        7157,
        636,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36120495200157166,
      "compression_ratio": 1.6478873491287231,
      "no_speech_prob": 0.2560506761074066
    },
    {
      "id": 319,
      "seek": 93500,
      "start": 3351.46,
      "end": 3353.46,
      "text": " And then the problem is actually",
      "tokens": [
        50864,
        400,
        550,
        264,
        1154,
        307,
        767,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36120495200157166,
      "compression_ratio": 1.6478873491287231,
      "no_speech_prob": 0.2560506761074066
    },
    {
      "id": 320,
      "seek": 93500,
      "start": 3353.46,
      "end": 3355.46,
      "text": " this training data set.",
      "tokens": [
        50964,
        341,
        3097,
        1412,
        992,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36120495200157166,
      "compression_ratio": 1.6478873491287231,
      "no_speech_prob": 0.2560506761074066
    },
    {
      "id": 321,
      "seek": 93500,
      "start": 3355.46,
      "end": 3357.46,
      "text": " But we don't know that.",
      "tokens": [
        51064,
        583,
        321,
        500,
        380,
        458,
        300,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36120495200157166,
      "compression_ratio": 1.6478873491287231,
      "no_speech_prob": 0.2560506761074066
    },
    {
      "id": 322,
      "seek": 93500,
      "start": 3357.46,
      "end": 3359.46,
      "text": " So if I use Cloud or chat GPT,",
      "tokens": [
        51164,
        407,
        498,
        286,
        764,
        8061,
        420,
        5081,
        26039,
        51,
        11,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36120495200157166,
      "compression_ratio": 1.6478873491287231,
      "no_speech_prob": 0.2560506761074066
    },
    {
      "id": 323,
      "seek": 93500,
      "start": 3359.46,
      "end": 3361.46,
      "text": " I don't know that.",
      "tokens": [
        51264,
        286,
        500,
        380,
        458,
        300,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36120495200157166,
      "compression_ratio": 1.6478873491287231,
      "no_speech_prob": 0.2560506761074066
    },
    {
      "id": 324,
      "seek": 93500,
      "start": 3361.46,
      "end": 3364.46,
      "text": " Which means that I actually,",
      "tokens": [
        51364,
        3013,
        1355,
        300,
        286,
        767,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36120495200157166,
      "compression_ratio": 1.6478873491287231,
      "no_speech_prob": 0.2560506761074066
    },
    {
      "id": 325,
      "seek": 93500,
      "start": 3364.46,
      "end": 3366.46,
      "text": " to trust the thing,",
      "tokens": [
        51514,
        281,
        3361,
        264,
        551,
        11,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36120495200157166,
      "compression_ratio": 1.6478873491287231,
      "no_speech_prob": 0.2560506761074066
    },
    {
      "id": 326,
      "seek": 93500,
      "start": 3366.46,
      "end": 3368.46,
      "text": " probably also need access",
      "tokens": [
        51614,
        1391,
        611,
        643,
        2105,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36120495200157166,
      "compression_ratio": 1.6478873491287231,
      "no_speech_prob": 0.2560506761074066
    },
    {
      "id": 327,
      "seek": 93500,
      "start": 3368.46,
      "end": 3370.46,
      "text": " to this training data set.",
      "tokens": [
        51714,
        281,
        341,
        3097,
        1412,
        992,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36120495200157166,
      "compression_ratio": 1.6478873491287231,
      "no_speech_prob": 0.2560506761074066
    },
    {
      "id": 328,
      "seek": 96400,
      "start": 3370.46,
      "end": 3373.46,
      "text": " And then I know",
      "tokens": [
        50364,
        400,
        550,
        286,
        458,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3352004587650299,
      "compression_ratio": 1.641350269317627,
      "no_speech_prob": 0.047580670565366745
    },
    {
      "id": 329,
      "seek": 96400,
      "start": 3373.46,
      "end": 3375.46,
      "text": " where these answers come from.",
      "tokens": [
        50514,
        689,
        613,
        6338,
        808,
        490,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3352004587650299,
      "compression_ratio": 1.641350269317627,
      "no_speech_prob": 0.047580670565366745
    },
    {
      "id": 330,
      "seek": 96400,
      "start": 3375.46,
      "end": 3380.46,
      "text": " And that leads to the fact that,",
      "tokens": [
        50614,
        400,
        300,
        6689,
        281,
        264,
        1186,
        300,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3352004587650299,
      "compression_ratio": 1.641350269317627,
      "no_speech_prob": 0.047580670565366745
    },
    {
      "id": 331,
      "seek": 96400,
      "start": 3380.46,
      "end": 3382.46,
      "text": " yes, text generators can generate a dialogue",
      "tokens": [
        50864,
        2086,
        11,
        2487,
        38662,
        393,
        8460,
        257,
        10221,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3352004587650299,
      "compression_ratio": 1.641350269317627,
      "no_speech_prob": 0.047580670565366745
    },
    {
      "id": 332,
      "seek": 96400,
      "start": 3382.46,
      "end": 3384.46,
      "text": " that somehow looks like gaslighting.",
      "tokens": [
        50964,
        300,
        6063,
        1542,
        411,
        4211,
        2764,
        278,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3352004587650299,
      "compression_ratio": 1.641350269317627,
      "no_speech_prob": 0.047580670565366745
    },
    {
      "id": 333,
      "seek": 96400,
      "start": 3384.46,
      "end": 3386.46,
      "text": " But something comes out of it",
      "tokens": [
        51064,
        583,
        746,
        1487,
        484,
        295,
        309,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3352004587650299,
      "compression_ratio": 1.641350269317627,
      "no_speech_prob": 0.047580670565366745
    },
    {
      "id": 334,
      "seek": 96400,
      "start": 3386.46,
      "end": 3388.46,
      "text": " that looks like a guide",
      "tokens": [
        51164,
        300,
        1542,
        411,
        257,
        5934,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3352004587650299,
      "compression_ratio": 1.641350269317627,
      "no_speech_prob": 0.047580670565366745
    },
    {
      "id": 335,
      "seek": 96400,
      "start": 3388.46,
      "end": 3390.46,
      "text": " for the construction of Molotov cocktails.",
      "tokens": [
        51264,
        337,
        264,
        6435,
        295,
        28278,
        310,
        5179,
        49006,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3352004587650299,
      "compression_ratio": 1.641350269317627,
      "no_speech_prob": 0.047580670565366745
    },
    {
      "id": 336,
      "seek": 96400,
      "start": 3390.46,
      "end": 3392.46,
      "text": " I think that's totally valuable",
      "tokens": [
        51364,
        286,
        519,
        300,
        311,
        3879,
        8263,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3352004587650299,
      "compression_ratio": 1.641350269317627,
      "no_speech_prob": 0.047580670565366745
    },
    {
      "id": 337,
      "seek": 96400,
      "start": 3392.46,
      "end": 3394.46,
      "text": " as a psychological experiment.",
      "tokens": [
        51464,
        382,
        257,
        14346,
        5120,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3352004587650299,
      "compression_ratio": 1.641350269317627,
      "no_speech_prob": 0.047580670565366745
    },
    {
      "id": 338,
      "seek": 96400,
      "start": 3394.46,
      "end": 3396.46,
      "text": " Maybe that's also correct.",
      "tokens": [
        51564,
        2704,
        300,
        311,
        611,
        3006,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3352004587650299,
      "compression_ratio": 1.641350269317627,
      "no_speech_prob": 0.047580670565366745
    },
    {
      "id": 339,
      "seek": 96400,
      "start": 3396.46,
      "end": 3399.46,
      "text": " But that doesn't matter for my argument.",
      "tokens": [
        51664,
        583,
        300,
        1177,
        380,
        1871,
        337,
        452,
        6770,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3352004587650299,
      "compression_ratio": 1.641350269317627,
      "no_speech_prob": 0.047580670565366745
    },
    {
      "id": 340,
      "seek": 99300,
      "start": 3399.46,
      "end": 3401.46,
      "text": " I should just control it,",
      "tokens": [
        50364,
        286,
        820,
        445,
        1969,
        309,
        11,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2915932238101959,
      "compression_ratio": 1.5925925970077515,
      "no_speech_prob": 0.06615788489580154
    },
    {
      "id": 341,
      "seek": 99300,
      "start": 3401.46,
      "end": 3403.46,
      "text": " as we saw before.",
      "tokens": [
        50464,
        382,
        321,
        1866,
        949,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2915932238101959,
      "compression_ratio": 1.5925925970077515,
      "no_speech_prob": 0.06615788489580154
    },
    {
      "id": 342,
      "seek": 99300,
      "start": 3403.46,
      "end": 3405.46,
      "text": " There are other, better sources for that.",
      "tokens": [
        50564,
        821,
        366,
        661,
        11,
        1101,
        7139,
        337,
        300,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2915932238101959,
      "compression_ratio": 1.5925925970077515,
      "no_speech_prob": 0.06615788489580154
    },
    {
      "id": 343,
      "seek": 99300,
      "start": 3405.46,
      "end": 3407.46,
      "text": " But then it doesn't matter",
      "tokens": [
        50664,
        583,
        550,
        309,
        1177,
        380,
        1871,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2915932238101959,
      "compression_ratio": 1.5925925970077515,
      "no_speech_prob": 0.06615788489580154
    },
    {
      "id": 344,
      "seek": 99300,
      "start": 3407.46,
      "end": 3409.46,
      "text": " that the text was generated.",
      "tokens": [
        50764,
        300,
        264,
        2487,
        390,
        10833,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2915932238101959,
      "compression_ratio": 1.5925925970077515,
      "no_speech_prob": 0.06615788489580154
    },
    {
      "id": 345,
      "seek": 99300,
      "start": 3409.46,
      "end": 3411.46,
      "text": " Because I have other sources that are better.",
      "tokens": [
        50864,
        1436,
        286,
        362,
        661,
        7139,
        300,
        366,
        1101,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2915932238101959,
      "compression_ratio": 1.5925925970077515,
      "no_speech_prob": 0.06615788489580154
    },
    {
      "id": 346,
      "seek": 99300,
      "start": 3411.46,
      "end": 3413.46,
      "text": " And I would rely on them,",
      "tokens": [
        50964,
        400,
        286,
        576,
        10687,
        322,
        552,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2915932238101959,
      "compression_ratio": 1.5925925970077515,
      "no_speech_prob": 0.06615788489580154
    },
    {
      "id": 347,
      "seek": 99300,
      "start": 3413.46,
      "end": 3415.46,
      "text": " not on the chat GPT,",
      "tokens": [
        51064,
        406,
        322,
        264,
        5081,
        26039,
        51,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2915932238101959,
      "compression_ratio": 1.5925925970077515,
      "no_speech_prob": 0.06615788489580154
    },
    {
      "id": 348,
      "seek": 99300,
      "start": 3415.46,
      "end": 3417.46,
      "text": " which is why I wouldn't see it",
      "tokens": [
        51164,
        597,
        307,
        983,
        286,
        2759,
        380,
        536,
        309,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2915932238101959,
      "compression_ratio": 1.5925925970077515,
      "no_speech_prob": 0.06615788489580154
    },
    {
      "id": 349,
      "seek": 99300,
      "start": 3417.46,
      "end": 3419.46,
      "text": " as a security breach.",
      "tokens": [
        51264,
        382,
        257,
        3825,
        31086,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2915932238101959,
      "compression_ratio": 1.5925925970077515,
      "no_speech_prob": 0.06615788489580154
    },
    {
      "id": 350,
      "seek": 99300,
      "start": 3419.46,
      "end": 3421.46,
      "text": " And then comes Christian's point.",
      "tokens": [
        51364,
        400,
        550,
        1487,
        5778,
        311,
        935,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2915932238101959,
      "compression_ratio": 1.5925925970077515,
      "no_speech_prob": 0.06615788489580154
    },
    {
      "id": 351,
      "seek": 99300,
      "start": 3421.46,
      "end": 3423.46,
      "text": " He somehow says no.",
      "tokens": [
        51464,
        634,
        6063,
        1619,
        572,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2915932238101959,
      "compression_ratio": 1.5925925970077515,
      "no_speech_prob": 0.06615788489580154
    },
    {
      "id": 352,
      "seek": 99300,
      "start": 3423.46,
      "end": 3425.46,
      "text": " But if I fed the system",
      "tokens": [
        51564,
        583,
        498,
        286,
        4636,
        264,
        1185,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2915932238101959,
      "compression_ratio": 1.5925925970077515,
      "no_speech_prob": 0.06615788489580154
    },
    {
      "id": 353,
      "seek": 99300,
      "start": 3425.46,
      "end": 3427.46,
      "text": " with non-public data,",
      "tokens": [
        51664,
        365,
        2107,
        12,
        79,
        3865,
        1412,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2915932238101959,
      "compression_ratio": 1.5925925970077515,
      "no_speech_prob": 0.06615788489580154
    },
    {
      "id": 354,
      "seek": 102100,
      "start": 3427.46,
      "end": 3429.46,
      "text": " and that is, so to speak,",
      "tokens": [
        50364,
        293,
        300,
        307,
        11,
        370,
        281,
        1710,
        11,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4174419343471527,
      "compression_ratio": 1.439814805984497,
      "no_speech_prob": 0.02311653457581997
    },
    {
      "id": 355,
      "seek": 102100,
      "start": 3429.46,
      "end": 3431.46,
      "text": " also a result.",
      "tokens": [
        50464,
        611,
        257,
        1874,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4174419343471527,
      "compression_ratio": 1.439814805984497,
      "no_speech_prob": 0.02311653457581997
    },
    {
      "id": 356,
      "seek": 102100,
      "start": 3431.46,
      "end": 3433.46,
      "text": " Christian writes,",
      "tokens": [
        50564,
        5778,
        13657,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4174419343471527,
      "compression_ratio": 1.439814805984497,
      "no_speech_prob": 0.02311653457581997
    },
    {
      "id": 357,
      "seek": 102100,
      "start": 3433.46,
      "end": 3435.46,
      "text": " open question,",
      "tokens": [
        50664,
        1269,
        1168,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4174419343471527,
      "compression_ratio": 1.439814805984497,
      "no_speech_prob": 0.02311653457581997
    },
    {
      "id": 358,
      "seek": 102100,
      "start": 3435.46,
      "end": 3437.46,
      "text": " can a malicious actor publish",
      "tokens": [
        50764,
        393,
        257,
        33496,
        8747,
        11374,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4174419343471527,
      "compression_ratio": 1.439814805984497,
      "no_speech_prob": 0.02311653457581997
    },
    {
      "id": 359,
      "seek": 102100,
      "start": 3437.46,
      "end": 3439.46,
      "text": " shout software on GitHub,",
      "tokens": [
        50864,
        8043,
        4722,
        322,
        23331,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4174419343471527,
      "compression_ratio": 1.439814805984497,
      "no_speech_prob": 0.02311653457581997
    },
    {
      "id": 360,
      "seek": 102100,
      "start": 3439.46,
      "end": 3441.46,
      "text": " which then ends up in his own code",
      "tokens": [
        50964,
        597,
        550,
        5314,
        493,
        294,
        702,
        1065,
        3089,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4174419343471527,
      "compression_ratio": 1.439814805984497,
      "no_speech_prob": 0.02311653457581997
    },
    {
      "id": 361,
      "seek": 102100,
      "start": 3441.46,
      "end": 3443.46,
      "text": " via Copilot?",
      "tokens": [
        51064,
        5766,
        11579,
        31516,
        30,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4174419343471527,
      "compression_ratio": 1.439814805984497,
      "no_speech_prob": 0.02311653457581997
    },
    {
      "id": 362,
      "seek": 102100,
      "start": 3443.46,
      "end": 3445.46,
      "text": " Ah, exactly, good point.",
      "tokens": [
        51164,
        2438,
        11,
        2293,
        11,
        665,
        935,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4174419343471527,
      "compression_ratio": 1.439814805984497,
      "no_speech_prob": 0.02311653457581997
    },
    {
      "id": 363,
      "seek": 102100,
      "start": 3445.46,
      "end": 3447.46,
      "text": " It is so,",
      "tokens": [
        51264,
        467,
        307,
        370,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4174419343471527,
      "compression_ratio": 1.439814805984497,
      "no_speech_prob": 0.02311653457581997
    },
    {
      "id": 364,
      "seek": 102100,
      "start": 3447.46,
      "end": 3449.46,
      "text": " I have to link that again,",
      "tokens": [
        51364,
        286,
        362,
        281,
        2113,
        300,
        797,
        11,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4174419343471527,
      "compression_ratio": 1.439814805984497,
      "no_speech_prob": 0.02311653457581997
    },
    {
      "id": 365,
      "seek": 102100,
      "start": 3449.46,
      "end": 3451.46,
      "text": " that we know",
      "tokens": [
        51464,
        300,
        321,
        458,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4174419343471527,
      "compression_ratio": 1.439814805984497,
      "no_speech_prob": 0.02311653457581997
    },
    {
      "id": 366,
      "seek": 102100,
      "start": 3451.46,
      "end": 3453.46,
      "text": " that obviously the Russians",
      "tokens": [
        51564,
        300,
        2745,
        264,
        20605,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4174419343471527,
      "compression_ratio": 1.439814805984497,
      "no_speech_prob": 0.02311653457581997
    },
    {
      "id": 367,
      "seek": 102100,
      "start": 3453.46,
      "end": 3455.46,
      "text": " feed chat GPT with information",
      "tokens": [
        51664,
        3154,
        5081,
        26039,
        51,
        365,
        1589,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4174419343471527,
      "compression_ratio": 1.439814805984497,
      "no_speech_prob": 0.02311653457581997
    },
    {
      "id": 368,
      "seek": 104900,
      "start": 3455.46,
      "end": 3457.46,
      "text": " to ensure",
      "tokens": [
        50364,
        281,
        5586,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31334808468818665,
      "compression_ratio": 1.5733333826065063,
      "no_speech_prob": 0.004314981400966644
    },
    {
      "id": 369,
      "seek": 104900,
      "start": 3457.46,
      "end": 3459.46,
      "text": " that the results",
      "tokens": [
        50464,
        300,
        264,
        3542,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31334808468818665,
      "compression_ratio": 1.5733333826065063,
      "no_speech_prob": 0.004314981400966644
    },
    {
      "id": 370,
      "seek": 104900,
      "start": 3459.46,
      "end": 3461.46,
      "text": " of the chat GPT",
      "tokens": [
        50564,
        295,
        264,
        5081,
        26039,
        51,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31334808468818665,
      "compression_ratio": 1.5733333826065063,
      "no_speech_prob": 0.004314981400966644
    },
    {
      "id": 371,
      "seek": 104900,
      "start": 3461.46,
      "end": 3463.46,
      "text": " run in their",
      "tokens": [
        50664,
        1190,
        294,
        641,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31334808468818665,
      "compression_ratio": 1.5733333826065063,
      "no_speech_prob": 0.004314981400966644
    },
    {
      "id": 372,
      "seek": 104900,
      "start": 3463.46,
      "end": 3465.46,
      "text": " direction.",
      "tokens": [
        50764,
        3513,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31334808468818665,
      "compression_ratio": 1.5733333826065063,
      "no_speech_prob": 0.004314981400966644
    },
    {
      "id": 373,
      "seek": 104900,
      "start": 3467.46,
      "end": 3469.46,
      "text": " I link that again.",
      "tokens": [
        50964,
        286,
        2113,
        300,
        797,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31334808468818665,
      "compression_ratio": 1.5733333826065063,
      "no_speech_prob": 0.004314981400966644
    },
    {
      "id": 374,
      "seek": 104900,
      "start": 3469.46,
      "end": 3471.46,
      "text": " And that is",
      "tokens": [
        51064,
        400,
        300,
        307,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31334808468818665,
      "compression_ratio": 1.5733333826065063,
      "no_speech_prob": 0.004314981400966644
    },
    {
      "id": 375,
      "seek": 104900,
      "start": 3471.46,
      "end": 3473.46,
      "text": " exactly something",
      "tokens": [
        51164,
        2293,
        746,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31334808468818665,
      "compression_ratio": 1.5733333826065063,
      "no_speech_prob": 0.004314981400966644
    },
    {
      "id": 376,
      "seek": 104900,
      "start": 3473.46,
      "end": 3475.46,
      "text": " where we actually",
      "tokens": [
        51264,
        689,
        321,
        767,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31334808468818665,
      "compression_ratio": 1.5733333826065063,
      "no_speech_prob": 0.004314981400966644
    },
    {
      "id": 377,
      "seek": 104900,
      "start": 3475.46,
      "end": 3477.46,
      "text": " have to see or know",
      "tokens": [
        51364,
        362,
        281,
        536,
        420,
        458,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31334808468818665,
      "compression_ratio": 1.5733333826065063,
      "no_speech_prob": 0.004314981400966644
    },
    {
      "id": 378,
      "seek": 104900,
      "start": 3477.46,
      "end": 3479.46,
      "text": " the training dataset",
      "tokens": [
        51464,
        264,
        3097,
        28872,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31334808468818665,
      "compression_ratio": 1.5733333826065063,
      "no_speech_prob": 0.004314981400966644
    },
    {
      "id": 379,
      "seek": 104900,
      "start": 3479.46,
      "end": 3481.46,
      "text": " to trust it somehow.",
      "tokens": [
        51564,
        281,
        3361,
        309,
        6063,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31334808468818665,
      "compression_ratio": 1.5733333826065063,
      "no_speech_prob": 0.004314981400966644
    },
    {
      "id": 380,
      "seek": 104900,
      "start": 3481.46,
      "end": 3483.46,
      "text": " And that means that the training dataset",
      "tokens": [
        51664,
        400,
        300,
        1355,
        300,
        264,
        3097,
        28872,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31334808468818665,
      "compression_ratio": 1.5733333826065063,
      "no_speech_prob": 0.004314981400966644
    },
    {
      "id": 381,
      "seek": 107700,
      "start": 3483.46,
      "end": 3485.46,
      "text": " as an attack vector",
      "tokens": [
        50364,
        382,
        364,
        2690,
        8062,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34375903010368347,
      "compression_ratio": 1.5972222089767456,
      "no_speech_prob": 0.038219302892684937
    },
    {
      "id": 382,
      "seek": 107700,
      "start": 3485.46,
      "end": 3487.46,
      "text": " is a problem, so to speak.",
      "tokens": [
        50464,
        307,
        257,
        1154,
        11,
        370,
        281,
        1710,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34375903010368347,
      "compression_ratio": 1.5972222089767456,
      "no_speech_prob": 0.038219302892684937
    },
    {
      "id": 383,
      "seek": 107700,
      "start": 3487.46,
      "end": 3489.46,
      "text": " And that is Christian's point.",
      "tokens": [
        50564,
        400,
        300,
        307,
        5778,
        311,
        935,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34375903010368347,
      "compression_ratio": 1.5972222089767456,
      "no_speech_prob": 0.038219302892684937
    },
    {
      "id": 384,
      "seek": 107700,
      "start": 3489.46,
      "end": 3491.46,
      "text": " So if I have a lot of",
      "tokens": [
        50664,
        407,
        498,
        286,
        362,
        257,
        688,
        295,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34375903010368347,
      "compression_ratio": 1.5972222089767456,
      "no_speech_prob": 0.038219302892684937
    },
    {
      "id": 385,
      "seek": 107700,
      "start": 3491.46,
      "end": 3493.46,
      "text": " shout software in GitHub",
      "tokens": [
        50764,
        8043,
        4722,
        294,
        23331,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34375903010368347,
      "compression_ratio": 1.5972222089767456,
      "no_speech_prob": 0.038219302892684937
    },
    {
      "id": 386,
      "seek": 107700,
      "start": 3493.46,
      "end": 3495.46,
      "text": " with some",
      "tokens": [
        50864,
        365,
        512,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34375903010368347,
      "compression_ratio": 1.5972222089767456,
      "no_speech_prob": 0.038219302892684937
    },
    {
      "id": 387,
      "seek": 107700,
      "start": 3495.46,
      "end": 3497.46,
      "text": " code things",
      "tokens": [
        50964,
        3089,
        721,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34375903010368347,
      "compression_ratio": 1.5972222089767456,
      "no_speech_prob": 0.038219302892684937
    },
    {
      "id": 388,
      "seek": 107700,
      "start": 3497.46,
      "end": 3499.46,
      "text": " that play a role",
      "tokens": [
        51064,
        300,
        862,
        257,
        3090,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34375903010368347,
      "compression_ratio": 1.5972222089767456,
      "no_speech_prob": 0.038219302892684937
    },
    {
      "id": 389,
      "seek": 107700,
      "start": 3499.46,
      "end": 3501.46,
      "text": " and they are replicated",
      "tokens": [
        51164,
        293,
        436,
        366,
        46365,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34375903010368347,
      "compression_ratio": 1.5972222089767456,
      "no_speech_prob": 0.038219302892684937
    },
    {
      "id": 390,
      "seek": 107700,
      "start": 3501.46,
      "end": 3503.46,
      "text": " by Copilot, then I have a problem.",
      "tokens": [
        51264,
        538,
        11579,
        31516,
        11,
        550,
        286,
        362,
        257,
        1154,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34375903010368347,
      "compression_ratio": 1.5972222089767456,
      "no_speech_prob": 0.038219302892684937
    },
    {
      "id": 391,
      "seek": 107700,
      "start": 3503.46,
      "end": 3505.46,
      "text": " And that leads again to the question",
      "tokens": [
        51364,
        400,
        300,
        6689,
        797,
        281,
        264,
        1168,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34375903010368347,
      "compression_ratio": 1.5972222089767456,
      "no_speech_prob": 0.038219302892684937
    },
    {
      "id": 392,
      "seek": 107700,
      "start": 3505.46,
      "end": 3507.46,
      "text": " not with the control.",
      "tokens": [
        51464,
        406,
        365,
        264,
        1969,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34375903010368347,
      "compression_ratio": 1.5972222089767456,
      "no_speech_prob": 0.038219302892684937
    },
    {
      "id": 393,
      "seek": 107700,
      "start": 3507.46,
      "end": 3509.46,
      "text": " And there is the problem again.",
      "tokens": [
        51564,
        400,
        456,
        307,
        264,
        1154,
        797,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34375903010368347,
      "compression_ratio": 1.5972222089767456,
      "no_speech_prob": 0.038219302892684937
    },
    {
      "id": 394,
      "seek": 107700,
      "start": 3509.46,
      "end": 3511.46,
      "text": " So when we talk about security,",
      "tokens": [
        51664,
        407,
        562,
        321,
        751,
        466,
        3825,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34375903010368347,
      "compression_ratio": 1.5972222089767456,
      "no_speech_prob": 0.038219302892684937
    },
    {
      "id": 395,
      "seek": 110500,
      "start": 3511.46,
      "end": 3513.46,
      "text": " code that has a security problem,",
      "tokens": [
        50364,
        3089,
        300,
        575,
        257,
        3825,
        1154,
        11,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4704265892505646,
      "compression_ratio": 1.4914286136627197,
      "no_speech_prob": 0.010465276427567005
    },
    {
      "id": 396,
      "seek": 110500,
      "start": 3513.46,
      "end": 3515.46,
      "text": " that is often not obvious.",
      "tokens": [
        50464,
        300,
        307,
        2049,
        406,
        6322,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4704265892505646,
      "compression_ratio": 1.4914286136627197,
      "no_speech_prob": 0.010465276427567005
    },
    {
      "id": 397,
      "seek": 110500,
      "start": 3515.46,
      "end": 3517.46,
      "text": " So it may actually be that",
      "tokens": [
        50564,
        407,
        309,
        815,
        767,
        312,
        300,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4704265892505646,
      "compression_ratio": 1.4914286136627197,
      "no_speech_prob": 0.010465276427567005
    },
    {
      "id": 398,
      "seek": 110500,
      "start": 3517.46,
      "end": 3519.46,
      "text": " I have smaller,",
      "tokens": [
        50664,
        286,
        362,
        4356,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4704265892505646,
      "compression_ratio": 1.4914286136627197,
      "no_speech_prob": 0.010465276427567005
    },
    {
      "id": 399,
      "seek": 110500,
      "start": 3519.46,
      "end": 3521.46,
      "text": " error-smaller problems on code",
      "tokens": [
        50764,
        6713,
        12,
        10817,
        22414,
        2740,
        322,
        3089,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4704265892505646,
      "compression_ratio": 1.4914286136627197,
      "no_speech_prob": 0.010465276427567005
    },
    {
      "id": 400,
      "seek": 110500,
      "start": 3521.46,
      "end": 3523.46,
      "text": " that have a dramatic impact.",
      "tokens": [
        50864,
        300,
        362,
        257,
        12023,
        2712,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4704265892505646,
      "compression_ratio": 1.4914286136627197,
      "no_speech_prob": 0.010465276427567005
    },
    {
      "id": 401,
      "seek": 110500,
      "start": 3523.46,
      "end": 3525.46,
      "text": " Good.",
      "tokens": [
        50964,
        2205,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4704265892505646,
      "compression_ratio": 1.4914286136627197,
      "no_speech_prob": 0.010465276427567005
    },
    {
      "id": 402,
      "seek": 110500,
      "start": 3525.46,
      "end": 3527.46,
      "text": " That's",
      "tokens": [
        51064,
        663,
        311,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4704265892505646,
      "compression_ratio": 1.4914286136627197,
      "no_speech_prob": 0.010465276427567005
    },
    {
      "id": 403,
      "seek": 110500,
      "start": 3527.46,
      "end": 3529.46,
      "text": " about it.",
      "tokens": [
        51164,
        466,
        309,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4704265892505646,
      "compression_ratio": 1.4914286136627197,
      "no_speech_prob": 0.010465276427567005
    },
    {
      "id": 404,
      "seek": 110500,
      "start": 3529.46,
      "end": 3531.46,
      "text": " Thank you for the",
      "tokens": [
        51264,
        1044,
        291,
        337,
        264,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4704265892505646,
      "compression_ratio": 1.4914286136627197,
      "no_speech_prob": 0.010465276427567005
    },
    {
      "id": 405,
      "seek": 110500,
      "start": 3531.46,
      "end": 3533.46,
      "text": " discussion and the input.",
      "tokens": [
        51364,
        5017,
        293,
        264,
        4846,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4704265892505646,
      "compression_ratio": 1.4914286136627197,
      "no_speech_prob": 0.010465276427567005
    },
    {
      "id": 406,
      "seek": 110500,
      "start": 3533.46,
      "end": 3535.46,
      "text": " Short",
      "tokens": [
        51464,
        16881,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4704265892505646,
      "compression_ratio": 1.4914286136627197,
      "no_speech_prob": 0.010465276427567005
    },
    {
      "id": 407,
      "seek": 110500,
      "start": 3535.46,
      "end": 3537.46,
      "text": " preview.",
      "tokens": [
        51564,
        14281,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4704265892505646,
      "compression_ratio": 1.4914286136627197,
      "no_speech_prob": 0.010465276427567005
    },
    {
      "id": 408,
      "seek": 110500,
      "start": 3537.46,
      "end": 3539.46,
      "text": " I guess we will",
      "tokens": [
        51664,
        286,
        2041,
        321,
        486,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4704265892505646,
      "compression_ratio": 1.4914286136627197,
      "no_speech_prob": 0.010465276427567005
    },
    {
      "id": 409,
      "seek": 113300,
      "start": 3539.46,
      "end": 3541.46,
      "text": " do an episode next week.",
      "tokens": [
        50364,
        360,
        364,
        3500,
        958,
        1243,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38514867424964905,
      "compression_ratio": 1.4951456785202026,
      "no_speech_prob": 0.4170793294906616
    },
    {
      "id": 410,
      "seek": 113300,
      "start": 3541.46,
      "end": 3543.46,
      "text": " I'm not 100% sure.",
      "tokens": [
        50464,
        286,
        478,
        406,
        2319,
        4,
        988,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38514867424964905,
      "compression_ratio": 1.4951456785202026,
      "no_speech_prob": 0.4170793294906616
    },
    {
      "id": 411,
      "seek": 113300,
      "start": 3543.46,
      "end": 3545.46,
      "text": " The topic is still open.",
      "tokens": [
        50564,
        440,
        4829,
        307,
        920,
        1269,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38514867424964905,
      "compression_ratio": 1.4951456785202026,
      "no_speech_prob": 0.4170793294906616
    },
    {
      "id": 412,
      "seek": 113300,
      "start": 3545.46,
      "end": 3547.46,
      "text": " Next Friday is a bad date.",
      "tokens": [
        50664,
        3087,
        6984,
        307,
        257,
        1578,
        4002,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38514867424964905,
      "compression_ratio": 1.4951456785202026,
      "no_speech_prob": 0.4170793294906616
    },
    {
      "id": 413,
      "seek": 113300,
      "start": 3547.46,
      "end": 3549.46,
      "text": " That's K-Friday.",
      "tokens": [
        50764,
        663,
        311,
        591,
        12,
        40305,
        4708,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38514867424964905,
      "compression_ratio": 1.4951456785202026,
      "no_speech_prob": 0.4170793294906616
    },
    {
      "id": 414,
      "seek": 113300,
      "start": 3549.46,
      "end": 3551.46,
      "text": " And",
      "tokens": [
        50864,
        400,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38514867424964905,
      "compression_ratio": 1.4951456785202026,
      "no_speech_prob": 0.4170793294906616
    },
    {
      "id": 415,
      "seek": 113300,
      "start": 3551.46,
      "end": 3553.46,
      "text": " otherwise",
      "tokens": [
        50964,
        5911,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38514867424964905,
      "compression_ratio": 1.4951456785202026,
      "no_speech_prob": 0.4170793294906616
    },
    {
      "id": 416,
      "seek": 113300,
      "start": 3553.46,
      "end": 3555.46,
      "text": " thank you for listening.",
      "tokens": [
        51064,
        1309,
        291,
        337,
        4764,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38514867424964905,
      "compression_ratio": 1.4951456785202026,
      "no_speech_prob": 0.4170793294906616
    },
    {
      "id": 417,
      "seek": 113300,
      "start": 3555.46,
      "end": 3557.46,
      "text": " Thank you for the questions",
      "tokens": [
        51164,
        1044,
        291,
        337,
        264,
        1651,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38514867424964905,
      "compression_ratio": 1.4951456785202026,
      "no_speech_prob": 0.4170793294906616
    },
    {
      "id": 418,
      "seek": 113300,
      "start": 3557.46,
      "end": 3559.46,
      "text": " and for the discussion.",
      "tokens": [
        51264,
        293,
        337,
        264,
        5017,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38514867424964905,
      "compression_ratio": 1.4951456785202026,
      "no_speech_prob": 0.4170793294906616
    },
    {
      "id": 419,
      "seek": 113300,
      "start": 3559.46,
      "end": 3561.46,
      "text": " And maybe you are",
      "tokens": [
        51364,
        400,
        1310,
        291,
        366,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38514867424964905,
      "compression_ratio": 1.4951456785202026,
      "no_speech_prob": 0.4170793294906616
    },
    {
      "id": 420,
      "seek": 113300,
      "start": 3561.46,
      "end": 3563.46,
      "text": " at some point on the architecture kickstart.",
      "tokens": [
        51464,
        412,
        512,
        935,
        322,
        264,
        9482,
        4437,
        24419,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38514867424964905,
      "compression_ratio": 1.4951456785202026,
      "no_speech_prob": 0.4170793294906616
    },
    {
      "id": 421,
      "seek": 113300,
      "start": 3563.46,
      "end": 3565.46,
      "text": " I have already pointed out.",
      "tokens": [
        51564,
        286,
        362,
        1217,
        10932,
        484,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38514867424964905,
      "compression_ratio": 1.4951456785202026,
      "no_speech_prob": 0.4170793294906616
    },
    {
      "id": 422,
      "seek": 113300,
      "start": 3565.46,
      "end": 3567.46,
      "text": " You can learn",
      "tokens": [
        51664,
        509,
        393,
        1466,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38514867424964905,
      "compression_ratio": 1.4951456785202026,
      "no_speech_prob": 0.4170793294906616
    },
    {
      "id": 423,
      "seek": 116100,
      "start": 3567.46,
      "end": 3569.46,
      "text": " how to build architectures",
      "tokens": [
        50364,
        577,
        281,
        1322,
        6331,
        1303,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40042904019355774,
      "compression_ratio": 1.3607594966888428,
      "no_speech_prob": 0.028593644499778748
    },
    {
      "id": 424,
      "seek": 116100,
      "start": 3569.46,
      "end": 3571.46,
      "text": " interactively",
      "tokens": [
        50464,
        4648,
        3413,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40042904019355774,
      "compression_ratio": 1.3607594966888428,
      "no_speech_prob": 0.028593644499778748
    },
    {
      "id": 425,
      "seek": 116100,
      "start": 3571.46,
      "end": 3573.46,
      "text": " and with the important",
      "tokens": [
        50564,
        293,
        365,
        264,
        1021,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40042904019355774,
      "compression_ratio": 1.3607594966888428,
      "no_speech_prob": 0.028593644499778748
    },
    {
      "id": 426,
      "seek": 116100,
      "start": 3573.46,
      "end": 3575.46,
      "text": " topics in my eyes.",
      "tokens": [
        50664,
        8378,
        294,
        452,
        2575,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40042904019355774,
      "compression_ratio": 1.3607594966888428,
      "no_speech_prob": 0.028593644499778748
    },
    {
      "id": 427,
      "seek": 116100,
      "start": 3575.46,
      "end": 3577.46,
      "text": " Have fun",
      "tokens": [
        50764,
        3560,
        1019,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40042904019355774,
      "compression_ratio": 1.3607594966888428,
      "no_speech_prob": 0.028593644499778748
    },
    {
      "id": 428,
      "seek": 116100,
      "start": 3577.46,
      "end": 3579.46,
      "text": " learning more about",
      "tokens": [
        50864,
        2539,
        544,
        466,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40042904019355774,
      "compression_ratio": 1.3607594966888428,
      "no_speech_prob": 0.028593644499778748
    },
    {
      "id": 429,
      "seek": 116100,
      "start": 3579.46,
      "end": 3581.46,
      "text": " AI tools.",
      "tokens": [
        50964,
        7318,
        3873,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40042904019355774,
      "compression_ratio": 1.3607594966888428,
      "no_speech_prob": 0.028593644499778748
    },
    {
      "id": 430,
      "seek": 116100,
      "start": 3581.46,
      "end": 3583.46,
      "text": " And then we'll see each other",
      "tokens": [
        51064,
        400,
        550,
        321,
        603,
        536,
        1184,
        661,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40042904019355774,
      "compression_ratio": 1.3607594966888428,
      "no_speech_prob": 0.028593644499778748
    },
    {
      "id": 431,
      "seek": 116100,
      "start": 3583.46,
      "end": 3585.46,
      "text": " at the right place again soon.",
      "tokens": [
        51164,
        412,
        264,
        558,
        1081,
        797,
        2321,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40042904019355774,
      "compression_ratio": 1.3607594966888428,
      "no_speech_prob": 0.028593644499778748
    },
    {
      "id": 432,
      "seek": 116100,
      "start": 3585.46,
      "end": 3587.46,
      "text": " Until then, thank you very much.",
      "tokens": [
        51264,
        9088,
        550,
        11,
        1309,
        291,
        588,
        709,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40042904019355774,
      "compression_ratio": 1.3607594966888428,
      "no_speech_prob": 0.028593644499778748
    }
  ],
  "language": "english"
}