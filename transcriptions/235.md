# Folge 235 - Green Software Development mit Aydin Mir Mohammadi Geht es um das Thema Green Software Development mit Ideen.

Schön, dass du da bist.

Bevor wir da loslegen, noch so ein paar Hinweise.

## Einführung und Vorstellung

Die eine Sache, es gibt noch Plätze bei meinem Architektur Kickstart.

Das liegt mir so ein bisschen am Herzen, weil das eine Veranstaltung ist, die, glaube ich, irgendwie sehr interessant ist.

Da hat man in vier Wochen jeweils vier Stunden lang die wichtigsten Themen aus dem Bereich Software-Architektur, Baumel-Kontext, Strategic Domain-Driven Design, Umgang mit Legacy-Systemen und wie ich Qualitäten hinbekomme und das Ganze mit sehr wenig Folien, eigentlich gar keinen Folien und sehr interaktiv.

Das geht los ab dem 14.

November.

Das heißt, wenn ihr da noch Lust habt, euch zu registrieren, würde mich das freuen.

Jetzt aber tatsächlich zum eigentlichen Thema, Aydin, schön, dass du da bist.

Wie gesagt, möchtest du kurz was darüber sagen, wer du bist und was du so machst?

Ja, klar.

Erstmal danke für die Einladung.

### Persönliche Vorstellung

Ich heiße Aydin, Aydin Mir-Mohammadin, bin das Ergebnis einer deutsch-iranischen Liebe mit einem unschlagbaren Vorteil.

Wenn man weiß, wie man mich schreibt, gibt es nur einen Google-Treffer und da ist genau die Herausforderung.

### Beruflicher Hintergrund

Ich bin Software-Unternehmer, bin Gründer und Geschäftsführer von Bluehands, eine kleine Software-Firma hier im Süden, in Karlsruhe, mit ca.

24 Leuten in den Projekten und bin Community-getrieben.

Alles, was ich lerne, alles, was ich gelernt habe, kommt irgendwo aus der Community, aus Konferenzen.

Deswegen nenne ich mich auch Community-Enthusiast.

Das ist mein Background und wo ich mich gerade unheimlich stark mit beschäftige, neben meinem täglichen Job in der Software, in der Geschäftsführung, ist Green Software, Nachhaltigkeit in IT.

Damit sind wir gleich beim Thema.

Es geht um Green Software Development.

Was ist denn das überhaupt?

Sind meine Folien gerade sichtbar?

Noch nicht, aber das richte ich jetzt kurz ein.

Jetzt sind die Folien da, sorry.

Hier nochmal, wenn mich jemand anpingen will oder über LinkedIn.

Wir reden eigentlich über diese Zahl.

## CO2-Emissionen in der IT

Das sind 4% der globalen Emissionen, was unser Sektor, also der ITK-Bereich, der gesamte Sektor verursacht.

Die gesamte Emission, was unser Sektor, was wir verursachen, ist gerade massiv steigend, explodierend.

### Aktuelle Situation

Wir haben so ungefähr 8% des Stromverbrauchs in Europa.

Das ist eigentlich der Hintergrund, worum es geht.

Nämlich diese massiven steigenden Emissionen, die wir in der Softwareentwicklung anfragen, zu reduzieren, also wenigstens zu halten, aber eigentlich auch zu reduzieren.

Einfach mal zur Verdeutlichung, ich habe ein Bild mitgebracht.

Das ist ein Datacenter von Microsoft, ein Azure-Datacenter in Dublin.

Das sind einfach Riesendinger.

### Datacenter-Entwicklung

Microsoft baut alle drei Tage so ein Datacenter weltweit.

Das war 2023, 2024, 2025, 2026, wenn wir ein bisschen weniger machen.

Microsoft ist ja Nummer zwei, Amazon ist noch mehr und die ganzen anderen Rechenzentren.

Wir haben überall massiv riesende Dinger aus dem Boden.

Das ist immer ein Thema.

Es ist ja so, dass Software keine Emissionen hat.

Die Emissionen entstehen am Computer, an den Servern, an den Endgeräten.

Aber die Software ist am Anfang der Kette.

Es geht darum, wie wir innerhalb unserer Profession unseren Beitrag leisten können.

Tatsächlich sind schon zwei parallele, ähnliche Fragen aufgekommen.

Einmal über das Formular, das hat die Frage, spielen alle unsere Bemühungen nach Green Software überhaupt eine Rolle, wenn man sieht, dass wegen der KI alte Atomkraftwerke reanimiert werden?

Ich glaube, das ist dieses Ding in Philipsburg, wo es diesen Plan gab, das wieder zu reanimieren, wo es in den Enden der 70er die Kernschmerze gab.

Und sogar neu gebaut werden, ist das dann nicht nur ein Tröpfchen auf den heißen Stein.

Und die Frage zweierlei It Depends auf YouTube hat auch schon gefragt, hilft die Nutzung von KI eher die Tendenz an?

Ich glaube, das sind zwei verwandte Fragen.

Also einmal die Frage, hilft uns das überhaupt, wenn wir KI machen?

Und dann führt KI dazu, dass diese Sache noch schlimmer wird, also dass dieser Anteil noch schlimmer wird?

Also schlimmer wird es immer.

Also wie gesagt, es explodiert.

Und KI gehört ja auch zur Softwareentwicklung.

Also es ist ja erst mal kein Gesetz, dass diese LLMs so gigantische Energiemengen und Ressourcen verbrauchen.

Es geht auch anders.

Wir haben auch die kleinen Modelle.

Also das ist erst mal kein Naturgesetz, dass es so ist.

Und ja, wir haben auch Cryptomining.

Wir haben einen Haufen Katzenbilder im Netz.

Also TikTok und so, das kann man alles hinterfragen.

Aber das nützt nichts.

Also das ist immer sozusagen, ich kann dieses Herz- und Ohnmachtsgefühl.

Und tatsächlich ist es nicht so.

Also diese vier Prozent, da ist jetzt die KI noch nicht wirklich drin.

Also das steigt ja.

Und KI ist ja noch nicht wirklich da.

Also wir haben zwar massiv diesen Ausbau, aber diese drei, diese Rechenzentren, Tata und deswegen Business, das ist noch nicht KI.

Und insgesamt ist halt dann der Sektor IT verantwortlich, dass es halt weniger wird.

Und wenn wir bei der KI was machen müssen, machen wir es bei der KI.

Wenn wir im B2B was machen müssen, machen wir es im B2B.

Und wenn wir im B2C sind, machen wir es im B2C.

Also alle Bereiche sind dann.

Aber es geht immer um Software.

Und ich glaube so ein bisschen, aus unserem Vorgespräch erinnere ich auch, dass du gesagt hast, na ja, das ist der Bereich, den wir unmittelbar beeinflussen können.

Und ich glaube, das ist halt auch ein wichtiger Aspekt.

Und ich glaube, da ist auch so eine Assoziation drin, wenn man sagt Green Software Developer, Green Software, dass man ganz viel Augenmerk auf Code und Optimierung von Code hat.

Also auch in der Abgrenzung zum Beispiel zu Green IT, wo man sagt, mal so ein Fokus auf Hardware, dass man Hardware effizienter gestaltet oder refurbished und so.

Aber eigentlich ist es alles das Gleiche.

Also wenn man sagt Green IT, Green Coding, Green Software, Green Software Development, Green Software Design, das sind alles Stichworte, die im Prinzip alle am gleichen beginnen.

Nämlich der Anfang der Kette sind Anforderungen, die von der Software kommen.

Und Software selbst, wie gesagt, hat ja keine Mission, sondern ist am Rechner.

Und die Frage ist, wie betreiben wir denn eigentlich unsere Software?

Wie betreiben wir die KI und wie betreiben wir einfach alles?

Also am Ende geht es Software produzieren und dann Software betreiben.

Und wir haben da unheimlich viele Möglichkeiten.

Und dabei haben wir die Anforderungen noch gar nicht angesprochen.

Was will man denn haben?

Aber ich glaube, wenn man den Fokus mal ein bisschen wegnimmt von schleifenoptimieren, glaube ich, versteht man schon, warum sowohl KI als auch unsere normale Profession, sei es Architektur oder sowas, dann auch einspringt.

Also letztendlich ist es ein querschnittliches Thema, so ist mein Gefühl, wo es um Effizienzsteigerung geht.

Und man kann jetzt sagen, die Anforderungen in Richtung KI, dass man sowas haben möchte, die kann man jetzt schwerlich ignorieren.

Aber wir können eben versuchen, das effizienter zu gestalten.

Und dann ist das halt eher Ansporn, dass da irgendwie noch was passiert.

Da gibt es auch eine Bewegung zu.

Es ist nicht so, dass da Leute in Zwischenstimmung gehen.

Aber es ist auch teuer.

Jetzt noch eine Frage.

Ich finde die Fragen aus dem Chat immer ganz spannend.

Die ist so ein bisschen, wie soll ich sagen, überraschend für mich.

Ich weiß nicht, ob du sie gleich beantworten wirst.

Ist Open Source tendenziell die grünere Software?

Ich glaube, es geht um Geschäftsmodell.

Nicht um den Code.

Also erst mal nicht.

Nein.

Ich glaube, ich muss mal kurz ausruhen, was es geht.

Wenn wir einfach mal die Quellen der Emissionen anschauen, dann ist es so, dass wir auf einem, man kann das einfach teilen, ## Quellen der Emissionen

30, 50 Prozent oder sowas von den Emissionen, von den gesamten Emissionen von der Software, die sind schon entstanden.

### Hardware-Emissionen

Weil man Hardware zur Verfügung stellt, weil man Hardware gebaut hat.

Man hat Kabel produziert für die Netzwerke, die Switches, die Computer, die ganze Sache, Kühlung.

Und auf der anderen Seite haben wir dann noch mal so ### Betriebsemissionen

50, 70 Prozent von Emissionen, die dadurch entstehen, dass ich die Computer betreibe.

Die Rolle, die jetzt hier, auch wenn ich jetzt mal Open Source, ich würde einfach das Open Source jetzt mal als Quellenstil mitnehmen, die hat jetzt eigentlich damit zu tun, warum ich überhaupt Software betreibe.

Was ist denn der Hintergrund?

Und wenn man jetzt diese zwei Quellen im Blick hat und sagt, okay, ich möchte jetzt die Gesamtemissionen reduzieren, dann entstehen so Handlungsfelder.

Und diese Handlungsfelder, die kann man so unterteilen, da haben sich schlaue Leute Gedanken gemacht, um das so zu kategorisieren.

Man redet von Hardware und Energieeffizienz, komme ich gleich drauf.

Es geht um Dateneffizienz und um diese CO2-Intensität, die total spannend ist.

Und diese Kombination, also jeder einzelne von diesen Schritten, hat einen massiven Optimierungsbedarf.

Und hier sind ja lauter Experten und Expertinnen im Stream, Projekte, die da direkt draufgehen.

Aber wenn ich zum Beispiel die Hardwareeffizienz, da geht es darum, dass ich eine Hardware maximal ausnutze.

Das heißt, so viel wie möglich Software auf eine Hardware putzen.

Auf Deutsch Serverkonsolidierung und Lebensdauer verlängern.

Also wenn ich eine Hardware nehme und statt vier mache ich fünf oder sechs, also von vier zu sechs, halbiere ich eigentlich die gebundene Emission.

Wenn jetzt meine Open-Source-Software so fluffig ist, dass sie, also nehmen wir mal Nextcloud, also im Gegensatz zu Microsoft Office 365, wenn Nextcloud in jeder seiner Versionen darauf achtet, dass es mit der alten Hardware noch funktioniert, dann ist es grüner, als wenn neue Versionen rauskommen und die Hardware mehr Leistung bringen muss.

Das hängt jetzt nicht notwendigerweise am Open-Source, sondern halt an, was ist da drin.

Und ja, zum Beispiel LibreOffice, OpenOffice ist sparsamer als ein Microsoft Office, weil ganz viel Geschäftsmodell in einem Microsoft Office auch Werbung und Tracking ist.

Macht dann wieder Performance oder irgendwelche Features, die da nicht drin sind.

Also kann man bewerten, ich würde es nicht pauschalisieren wollen.

Aber unabhängig davon, Nextcloud oder Office 365, also wir reden über Server-Konsolidierung oder die Server-Optimisation hochpumpen und es ist jetzt gar nichts geholfen, wenn ich jetzt eine Server nehme und da Nextcloud drauflaufen lasse und der Server langweilt sich.

Und was ich machen muss, ich muss so viel wie möglich draufpumpen.

Und wenn ich jetzt eine Software habe, die kommerziell und Close-Source ist und die ist kontainerisiert und die kann total gepackt werden, dann ist die wieder grüner als eine Software, die da ist.

Also ich würde sagen, das ist es nicht notwendigerweise, ob das jetzt Open-Source ist oder nicht, sondern wie betreibe ich die Software?

Und wenn ich jetzt diese Server-Konsolidierung machen kann, indem ich zum Beispiel Kubernetes mache, statt Bare-Metal eine Applikation, dann habe ich gigantisch gewonnen.

Also ich finde, dieses Bild zeigt schon, wie viel Emissionen reduziert werden pro Applikation, wenn ich das da überpacke.

Und meine Erfahrung zeigt ganz viel, die Server sind nicht ausgelastet.

Genau, was du da im Vorgespräch auch sagtest, sind eben diese Hot-Standby-Server, die per Definition nicht ausgelastet sind.

Die kommen auch noch mal dazu.

Also wir haben normal nicht ausgelastet.

Und dazu kommt ja noch, dass wir nochmal Hot-Standby machen.

Und auch noch vielleicht für diese Effizienz-Thematik, wir spielen alles das Gleiche rein, um auch da ein Verständnis zu bekommen, wir haben, wenn ich einen Computer, wenn ich einen Server einschalte, dann verbraucht er Energie.

Das heißt, er läuft, aber eigentlich schafft er nichts.

Oder er schafft und tut nichts.

Also wie du willst.

Das ist einfach Blindleistung.

Und diesen Idle-Gap, den muss ich auf ganz viele Applikationen verteilen.

Und wenn man jetzt so mit Coden kommt, dann meint man dann vielleicht, okay, rede ich jetzt, kann es, wenn ich jetzt meine Server, meine CPU-Ausleistung irgendwo hier in der Gegend ist, und ich dann das jetzt durch geschipptes Programmieren reduziere, dann ist das zwar super, aber eigentlich ist das für diese 100 Watt, die ich da verbraucht habe, egal.

Genau, also kurz vielleicht, die Grafik sagt halt, wenn man den Rechner einschaltet, den Server verbraucht er bereits 100 Watt.

Bei 50 Prozent 180 Watt und bei 100 Prozent 200 Watt.

Das heißt also, zwischen 50 und 100 Prozent liegen 20 Watt.

Und der verbraucht schon 100 Watt, wenn er überhaupt eingeschaltet ist.

Was also bedeutet, dass ich das Ding eigentlich unter Volllast betreiben will.

Und was du jetzt sagst, das ist ein netter Versuch, wenn ich 5 oder 10 Prozent Auslastung optimiere, also von 10 auf 5 Prozent komme, ich will eigentlich das Ding auf einer ganz anderen Ebene auslasten.

Genau, dazu muss ich dann wieder mehr Applikationen draufbringen.

Und es gibt ein Gerücht, dass bei Google Alarme losgehen, unter 98 Prozent.

Ob das stimmt, weiß ich nicht.

Aber es ist ein Gerücht.

Und da auch wieder, wenn ich die Open Source wieder reinnehme, die Frage, also ja, vielleicht ist ein Open Source effizienter programmiert.

Irgendein Open Source Tool.

Aber vielleicht dann egal.

Ja.

Also deswegen, was halt schon eine spannende Sache ist, ist dann auch diese Daten effizient.

Sorry, vielleicht noch kurz zu dem Punkt.

Das, was ja gerade Google genannt, das, was ja so ein bisschen jetzt als Frage und wir hatten auch gerade das diskutiert mit den Hot Stand Bys, wenn ich also jetzt in einem Rechenzentrum bin, da gibt es Rechner, die nicht ausgelastet sind und halt nur laufen, weil sie eben Hot Stand By sind.

Das heißt also, oder es wäre halt die Frage, soll ich denn nicht einfach in die Cloud gehen?

Also in der Cloud habe ich ja eh jemanden, der sich professionell darum kümmert, möglichst wenig Server, möglichst effizient auszunutzen.

Da gibt es ja irgendwie Serverless.

Das ist halt auch ein Konzept, was halt genau für Ausnutzung, für Last gut ist und so weiter und so weiter.

Also die Cloud, also ich würde sagen ja.

Und zwar Cloud im Sinne von Plattform as a Service.

Also wenn ich sage, ich mache Cloud im Sinne von Infrastruktur as a Service, das heißt ich tue eigentlich meine 4Ms, die ich an Prem habe, an Cloud laufen lasse, dann habe ich einen Vorteil, weil in der Regel die Power, Usage, Effectiveness von den Rechenzentren besser sind, als meine, also Microsoft und AWS und so.

Die sind alle so irgendwo groß in Ordnung 1,1, 1,2.

Also die zweite Kommastelle unterscheidet sich bei denen und da ist immer eine 1 davor.

Und wenn ich auf normale Rechenzentren dann kann ja auch mal eine 2 davorstehen.

Also das ist, also die sind deutlich effizienter, deutlich besser.

Aber wenn ich trotzdem meine CPU-Kerne reserviere und meinen RAM reserviere, dann habe ich eigentlich aus der Sicht nicht wirklich viel gewonnen, außer die PoE.

Aber wenn ich in dem Augenblick diese Hardware-Effizienz und Energie-Effizienz ausnutze, indem ich Plattform as a Service mache, Serverless, diese ganzen App-Services, also ich, AWS kenne ich nicht so gut aus, aber in Azure, wenn man da jetzt Functions nimmt, manage Kubernetes und so, dann sorgt der Betreiber schon dafür, dass es massiv gepackt ist.

Und das ist unschlagbar.

Funktioniert aber auch On-Prem.

Also so ist es nicht.

Aber meistens macht man es nicht.

Meistens sind die On-Prem-Rechenzentren einfach vor einem hingeployed und die Applikationen laufen auch vor einem.

Das ist so das andere, was mir hat auch beim Vorgespräch hochgekommen, ist sozusagen, ich habe ja mal früher für eine Firma namens VMware gearbeitet und habe am Rande mitbekommen, was deren Modell ist.

Und das ist im Prinzip das, was du gerade erläuterst.

Du schmeißt irgendwie Server raus, konsolidierst durch Virtualisierung, du gewinnst halt Geld.

Kann man irgendwie einfach ausrechnen.

Sodass wir da ja vielleicht schon länger eigentlich diese Story erzählen.

Aus dem anderen Grund, also da eben aus dem Grund, dass man irgendwie Kosten reduzieren möchte.

Also das Schöne an dem Green-Software-Thema ist, dass eine klimafreundliche, ressourcenschonende Software im Betrieb eigentlich immer kostengünstiger ist.

Also die Effizienz macht einfach Euros.

Das ist super.

Das heißt, wenn ich eine grüne Software habe, werde ich auch meistens eine kostengünstige Software.

Die Neues bei uns in der IT kostet nicht der Treiber.

Was wir ja in der Softwareentwicklung eher als Treiber haben, sind Features.

Dass wir Geschäftsmodelle entwickeln, dass wir das Team voranbringen, Nutzen generieren.

Und wenn da halt Kosten höher sind, dann sind sie halt höher.

Also bis sie halt irgendwann nicht mehr tragbar sind und dann passiert mal wieder eine Konsolidierung.

Aber eigentlich ist es eher so, dass wir auf einer anderen Ebene gehen.

Ich würde aber gerne noch mal kurz die Dateneffizienz mitnehmen und auch noch mal diese Open-Source-Frage reinschmeißen, weil wir haben jetzt im Augenblick ist der blaue Engel Zwei oder drei, es depends.

Auf YouTube gibt es eine DIN-Norm für sowas.

Der hat 14001 zitiert, Umweltmanagement-Systeme.

Du sagst, es gibt einen blauen Engel für Software.

Das scheint denn sowas ähnliches zu sein.

Also keine Norm, sondern ein Siegel halt.

Also wir haben auch eine Norm.

Da würde ich gleich Bades vielleicht ansprechen.

Zuerst zum Siegel.

Also der blaue Engel ist vom Umweltbundesamt, also das Umweltsiegel eigentlich in Deutschland und weltweit.

Und den gibt es jetzt auch für Software.

Also ganz frisch rausgekommen.

Und was der blaue Engel für Software macht, ist, der spezifiziert und verlangt Transparenz.

Das ist eigentlich das Wichtigste.

Er sagt noch nicht, dass du energieeffizient sein musst.

Er sagt nur, du musst das dokumentieren und aufzeigen für alle Nutzungsszenarien, die es so gibt.

Plus Nutzungsautonomie.

Da kommt das Open-Sourcen-Spiel.

Das heißt, du hast keinen Vendor-Log.

Du kannst deine Daten da raus holen.

Und das muss sichergestellt werden und Tracking frei.

Und die Daten hauen ganz schön rein in der CO2.

Weil wir reden hier, es ist eigentlich nicht die Datenmenge, sondern eigentlich Bandbreite-Latenzen.

Weil die Kabel, die Glasfaser, die sind alle unter Strom.

Die Switches sind unter Strom.

Die laufen alle.

Also passt egal, was wir rein modellieren.

Aber wenn das, was wir übertragen, nicht mehr reinpasst, muss man es noch mal machen.

Wir reden hier sehr stark von Verfügbarkeiten.

Es gilt, die Verfügbarkeit runterzuschrauben.

Eigentlich haben wir aber ganz viele Geschäftsmodelle im Internet oder überhaupt in unserer Welt, die auf Werbung und Tracking basiert.

Wenn mein Geschäftsmodell jetzt nicht auf Werbung und Tracking basiert, dann habe ich auch deutlich weniger Daten.

Im Allgemeinen.

Zu der anderen Frage mit der Norm.

Der blaue Hengel ist ein Siegel.

Es gibt noch Siegel bezüglich Webseiten, wo man auch Webseiten optimieren kann.

Da kann ich Cleaner Web empfehlen, die das machen.

Ich kann mal die Webseite aufmachen.

Du sprachst von der Green Web Foundation.

Das sind Kollegen und Kolleginnen aus München.

Die helfen beim Optimieren.

Die haben auch einen Siegel.

Die Green Web Foundation kümmert sich genau um das Thema Webseiten.

Da kann man auch ein Framework, ein Tool, CO2-JS, wo ich das messen kann.

Hier ist es so, dass man eine Korrelation herstellen kann zwischen Datenübertragung und CO2-Emissionen.

Das ist eine Korrelation.

Mehr hat man nicht, was man messen kann.

Das funktioniert dann recht gut.

Hier ist auch noch ein Siegel.

Dann gibt es den von der Green Software Foundation.

Da gibt es die STI, die Software Carbon Intensity.

Das ist ein ISO-Standard.

Das legt fest, wie ich die Emissionen von Software bemessen kann.

Um mal vollständig zu sein, würde ich gerne das mal zeigen.

Die Frage kommt eigentlich immer.

Ich werde die Links auch entsprechend in die Beschreibung von dem Podcast und dem Video reinpacken.

Ich habe hier eine Grafik für diejenigen, die das nur hören.

Der Software Carbon Intensity ist eine Zahl, die den CO2-Emissionen von Software beschreibt.

Man nimmt die Energie, die die Software verbraucht, also den Stromverbrauch, multipliziert das mit dem Emissionsfaktor des Stromnetzes, das ist die CO2-Intensität des Stromnetzes, und addiert dazu die gebundenen Emissionen, also die Hardware-Emissionen.

Damit bekomme ich eine Gesamtmenge von CO2.

Um das zu bewerten, kann ich eine funktionale Einheit dazu machen.

Ich kann sagen, pro Bestellvorgang, pro eingeloggten Benutzer, Benutzerin, pro Nutzungszenario, was man da hat.

Dann kriege ich eine Zahl.

Das ist eine gemittelte Zahl.

Wenn ich möchte, kann ich das auch detaillierter machen.

Das ist relativ gut zu messen und relativ gut zu dokumentieren.

Ich und alle anderen versuchen, wenn wir Software produzieren, dass wir diese Software Carbon Intensity auch publizieren.

Der Frage 2 der EtiPens hat gefragt, ob du das R nochmal genau beschreiben kannst.

Das hast du aber gerade.

Ist das Hardware oder Software pro Request oder pro Auftrag?

Oh, man darf das definieren.

Da will der blaue Engel das machen, dass Software vielleicht vergleichbar wird irgendwann.

Das ist eher im Konsumbereich wahrscheinlich möglich.

Schwierig, aber auf jeden Fall Transparenz.

Wenn ich Transparenz habe, dann kann ich auch Entscheidungen treffen.

So habe ich keine Transparenz.

Okay, das heißt, ich nehme an, dass ich mich hinsetze und schaue, wie viel Energie verbrauche ich.

Du hattest jetzt Bestellvorgänge gesagt.

Da multipliziere ich das mit der CO2 Intensität.

Da gab es diese Electricity Map, die du auch schon mal genannt hast.

Dann schaue ich noch, wie viele Server daran beteiligt sind.

Dann sage ich, dieses System erzeugt so und so viel CO2.

Dann dividiere ich das durch die Anzahl der Bestellungen, die da durchgehen.

Dann kriege ich heraus, was eine Bestellung kostet.

Wenn man jetzt konsumorientiert schauen möchte, kann ich sagen, was die Minute Zoom an CO2 kostet.

Was kostet eine Minute Jitsi und was kostet eine Minute Teams zum Beispiel.

Das wäre eine funktionale Einheit, Video pro Sekunde.

Genau.

Der Gromio auf YouTube hat gefragt, welche Tools würdet ihr empfehlen, um die einzelnen Effizienzmetriken auf eigener Hardware oder auch in der Cloud zu messen?

Was du ja schon gesagt hast, ist, dass die Daten, die rein und raus gehen, ein guter Indikator sind.

Fand ich spannend.

Ich würde gerne kurz ausholen, zu schauen, wie kann man das abschätzen und wie kann man es messen.

Das Abschätzen ist eigentlich das, was meistens gemacht wird, vor allem, wenn man in der Cloud ist.

Man kann ja kein Messgerät an einen Server anschließen.

Das ist das von Etsy erfundene Cloud Jewels.

Hier zeige ich ein Bild, was ich habe.

Ein Cloud besteht immer aus Compute, Storage, Netzwerk und Speicher, also Memory.

Das sind die vier Kernkomponenten einer Cloud, egal, was darauf gesetzt wird.

Diese einzelnen Kernkomponente kann ich zählen.

Ich weiß, wie viele CPU-Stunden, also wie viele Core-Stunden ich habe.

Ich weiß, wie viele Gigabyte pro Stunde ich irgendwo ablege.

Ich weiß, wie viele Megabyte pro Sekunde Netzwerk und so weiter.

Ich kann das alles zählen, nenne ich es mal.

Für jedes von diesen Dingen haben wir einen Emissionsfaktor.

Es gibt ganz viele fleißige Händchen, die das zusammengetragen haben.

Die Kollegen von Sourcework haben da gigantische Arbeit gemacht.

Ich habe dann Compute-Stunden mit dem Emissionsfaktor, multipliziere es mit der Energieeffizienz, mit der Power-Usage-Effektivnis, multipliziere es noch mit der Energie.

Dann nehme ich die Energie und rechne daraus die CO2 aus, indem ich gucke, wie viel die Kreditintensität ist und bekomme es dann.

Wir reduzieren das Messproblem darauf, indem wir gucken, wie viele Compute-Stunden ich habe.

Das Schöne an Cloud und überall Rechenzentren ist, wenn es ein bisschen managed ist, das steht auf der Rechnung.

Man stellt mir das in Rechnung.

Das ist zwar ein bisschen gemittelt, weil die CPU-Auslastung zum Beispiel nicht drin ist.

Die könnte ich noch nachholen, aber gut genug.

Dann kann ich das ausrechnen.

Da gibt es ein Tool.

Das Ding heißt Cloud Carbon Footprint.

Das ist Open Source, liegt auf GitHub, ist vornehmlich von Sourcework gemacht worden.

Das geht auch für On-Prem.

Damit kann man das machen.

Wenn man richtig messen möchte, vor allem auch für blaue Hänge, dann gibt es die Green Coding Solutions in Berlin, der Arne.

Die haben die sogenannten Green Matrix Tools.

Die haben ganz viele Tools.

Die haben da ein Tool, das sich Green Sock Matrix und das misst mir meine Software basierend auf den tatsächlichen Energieverbrauch, was ich von der CPU über RAPL hole.

RAPL ist ein Interface, was bei Laptops benutzt wird?

Genau, als Server.

Das ist eine Spezifikation.

Ich glaube, es ist auch ein Chip, wo der Energieverbrauch von allen Komponenten, die auf so einem Mindbar drauf sind, rauskommt.

So kann man das messen.

Wie kann ich es messen?

Ich kann es messen und ich kann es abladen und damit haben wir eigentlich alles hinter uns.

Wenn es für dich okay ist, könnte ich ein neues Thema, was sich aus der Frage ergibt, kurz anschneiden.

Das ist von dem Marco Wesselmann.

Der hat gefragt, wie sieht es mit kleinzeitigen Emissionen oder Stromverbrauch aus, der zum Beispiel durch Rechenzeit mit JavaScript im Browser auftritt?

Sollten Apps lieber auf so etwas verzichten?

Ich behaupte, es ist nicht wirklich relevant.

Man muss es in seiner Dimension sehen.

Wenn ich jetzt eine Webapplikation habe und auf dem Server läuft, also ich habe irgendwo ein Backend, da laufen ein paar Server, dann werden Daten übertragen.

Das ist das typische Angular-Modell.

Da ist eine Datenbank, ein Backend-Server, ein paar Services und dann habe ich vorne dran.

Da stellt sich die Frage, ob ich eine Server-Seite generiert mache oder eine kleinzeitige Applikation.

Im Gesamtsystem ist das Backend das Entscheidende.

Auf dem Endgerät haben wir die Datenübertragung.

Ich behaupte, es ist wahrscheinlich ähnlich.

Dann habe ich das Endgerät.

Jetzt rede ich darüber, wie viele Emissionen ich auf dem Endgerät habe.

Da ist Monitor das Thema.

Der Laptop macht doch nichts.

Dann rede ich an der Stelle wieder an einer Mikro-Optimierung.

Wenn ich aber meine Datenbank-Abfragen besser machen kann, vielleicht kann ich die cachen, dann hole ich da wieder mehr raus.

Das ist aber kein Freifahrtschein, weil das alles eine Frage von Scale ist.

Wenn ich jetzt Applikationen habe, vor allem Webseiten oder Web-Applikationen, die unheimlich hohen Scale haben, dann ist es natürlich sehr effizient, wenn ich zum Beispiel die Menge an Datenübertragung reduziere.

Mein JSON vielleicht geschickter mache, mein Bundle geschickter mache, vielleicht muss ich nicht alles holen und so weiter.

Da geht viel.

Was dann vielleicht eher bedeutet, dass man mit einem intelligenten Backend sogar besser aussieht.

Genau, könnte noch mehr sein.

Dann hat Happy Tree auf YouTube gefragt, auch eine Frage, die glaube ich so ein bisschen in die andere Richtung geht.

Der oder die hat gefragt, wenn man nun durch welche Maßnahmen auch immer die Energie drückt, kommt man dann nicht direkt in den Rebound-Effekt, dass dann einfach der Einsprung genutzt wird, um etwas anderes laufen zu lassen.

Das ist ja wie diese Geschichte.

Immer das Gleiche.

Gehe voll mit, selbstverständlich.

Wir reden jetzt teilweise auch gesellschaftspolitisch.

Ich bin jetzt aber in meiner Profession, was kann ich als Softwareentwickler, als Architekt tun?

Das ist, reduziere nun mal die CO2-Emissionen deiner Software.

Und zwar vom Coden angefangen bis zum Betrieb.

Aber ja, dann hat man halt wieder mehr Rebound.

Das ist zum Beispiel eine Kritik an dieser Norm, dass es hier eine funktionale Einheit gibt bei dem Software Carbon Intensity.

Also wo ich sage, ich habe eine Emission pro Bestellvorgang.

Wenn jetzt die Anzahl der Bestellungen hochgehen, dann geht eigentlich die CO2-Emission in mein Gesamtsystem hoch.

Aber mein Software Carbon Intensity, der könnte konstant bleiben oder sogar vielleicht ein bisschen runtergehen.

Und jetzt kommt hier der Rebound.

Also es sieht alles gut aus.

Also der Energieverbrauch ist super.

Aber insgesamt ist es höher.

Das heißt, die Effizienz, die ich drin hatte, die ist gefressen worden durch Wachstum.

Und ich muss eigentlich, um eine konstante CO2- Emission zu behalten, muss ich meine Effizienz stärker steigern als mein Wachstum.

Das ist ein Effekt, den hat man bei Lampen, mal der früher diese Glühbirnen gehabt.

Und dann hat man die getauscht durch LEDs, in der Hoffnung, dass der Energieverbrauch für die Beleuchtung runtergeht.

Genau andersrum passiert.

Der Energieverbrauch für die Beleuchtung geht höher, weil man jetzt überall LED-Lampen hat.

Dann ist jetzt natürlich der Verbrauch pro Lampe geringer geworden, aber man hat jetzt viel mehr.

Das ist ja tatsächlich der Rebound-Effekt.

Also das, was du gerade gesagt hast, dass ich irgendwie sage, ich habe jetzt pro Lampe weniger Verbrauch, aber ich beleuchte jetzt Dinge, die ich vorher nicht beleuchtet habe, weil ich mir das plötzlich leisten kann.

Und das mit den Bestellungen, ist das tatsächlich dieser Rebound-Effekt?

Also es bedeutet ja nur, dass ich wirtschaftlich erfolgreich bin und mehr Bestellungen habe.

Rebound wäre ja, wenn ich jetzt sage, okay, ich habe jetzt Effizienzsteigerung im Bezug auf, meinetwegen Bestellprozesse und jetzt fange ich an und digitalisiere den Rest halt auch, weil ich jetzt irgendwie Ressourcen frei habe, die ich nutzen kann für weitere Dinge.

Und das kann ich mir eigentlich nicht vorstellen, oder?

Missverständlich ausgedrückt.

Der Rebound kommt eigentlich daher, dass man denkt, man ist gut.

Also die LED-Lampe, die kostet jetzt nichts, sozusagen Energie.

Dann mache ich es noch ein bisschen schöner oder lasse es laufen.

Und dann passiert es.

Dann haut es mir ab, weil ich das gar nicht mehr mitbekomme.

Und wenn ich jetzt meine Emissionen in so einem Faktor habe, dann bekomme ich das nicht mit.

Und deswegen sagen viele, dass man auch immer das Gesamtsystem monitoren muss, um genau diesen Rebound-Effekt zu vermeiden, weil es aus dem Blick ist.

Okay, das heißt, du sagst, diese Zahl pro Einheit ist halt irgendwie trügerisch, weil wenn die Einheiten wachsen, dann habe ich halt insgesamt ein Problem und muss mich stärker noch anstrengen.

Da sind jetzt noch diverse Fragen.

Also hier ist nochmal die Frage, kannst du deine Definition von Funktionseinheit nochmal nennen?

Ist eine Computernetz oder ein Service eine Funktionseinheit?

Ich glaube, das haben wir mit der Bestellung eigentlich geklärt.

Also man versucht es meistens fachlich zu betreiben.

Man kann natürlich auch sagen pro Request oder sowas, aber auf einer technischen Ebene versucht man es fachlich zu betreiben.

Also pro Bestellung, pro Steuerbescheid, den ich ausstelle oder was auch immer.

Dann hat der Frage zweiter E-Depends gefragt, bringt mir der blaue Engel für meine Software oder mein Netzwerk einen Marktvorteil?

Hoffentlich.

Du sagtest ja gerade, das ist wahnsinnig frisch.

Also für Klopapier, für Drucker, also bei Drucker ist es ja ganz viel oder Papier.

Du gehst hin und sagst, ich mach einen blauen Engel.

Mir ist es bewusst, ich weiß, ich bin Teil des Problems, aber ich bin auch Teil der Lösung.

Und dann hat der auch noch geschrieben, wird sowas, ich nehme an, das ist dieser blaue Engel, wird das auditiert?

Ja, also das ist tatsächlich nicht so, dass irgendjemand es vergibt, sondern da gibt es dann Auditoren, die müssen beim Umweltbundesamt akkreditiert sein.

Es gibt auch eine Prüfung, also nicht einfach sagen, was ich will.

Vor allem gibt es Kriterien.

Es ist so richtig, wie eine Behörde einen Siegel macht.

Genau, so wie wir uns das hier in diesem Land vorstellen.

Genau.

Genau.

Noch eine Frage im Chat, weil ich würde unheimlich gerne noch ein Thema loswerden.

Ich glaube, wir haben es damit tatsächlich so ein bisschen aufgearbeitet.

Wir hatten ja insgesamt diese Effizienz, diese Handlungsfelder.

Und ich möchte zwei Sachen auf jeden Fall teasern.

Das eine ist, wenn ich dann jetzt irgendwann in der Cloud bin und so, was unheimlich stark hilft, ist Abschalten.

Also Strategie Nummer eins, Schalte des Zeugs ab.

Wir haben erfahrungsgemäß unheimlich viele Testsysteme, CI, CD-Systeme, Kundenabbildungssysteme und die Dinge laufen.

Laufen und laufen, obwohl man sie nicht braucht.

Also man kann das alles abschalten.

Und ja, es ist jetzt so, wie soll ich sagen, ein bisschen plakativ.

Das Abschalten ist das Problem.

Es ist einmal das Einschalten.

Und da geht aber ganz viel.

Also man könnte irgendwelche Systeme bauen, wo man die Dinger wieder hochfährt.

Man schickt eine Mail und dann fertig ist einfach tausend Sachen.

Also wir haben schon ganz viel ausprobiert.

Was halt auch sehr stark, sehr gut funktioniert, sind solche On-Demand.

Also wenn ich zum Beispiel in Container-Apps bin, dann kann ich einfach eine Request draufsetzen und dann fährt das System dann selber hoch, weil ein Notbalance da vorne dran ist.

Also es geht ganz viel.

Abschalten, Zeugs abschalten.

Man kann auch was vermeiden.

Also irgendwelche Reports produzieren, die keiner liest, brauche ich eh nicht.

Und auf manches Ankommen auch verzichten.

Muss jede Wetter-App eine Hochverfügbarkeit von 9,9999 Prozent haben, muss ich überall trotzdem beimachen.

Also da kann man Sachen vermeiden, man kann was verzichten, man kann Sachen nicht hinterfragen, man kann drauf und abschalten.

Das sind massive Lohengänge.

Also das kann man sich gar nicht vorstellen.

Da brauchen wir noch gar nicht anfangen zu coden.

Aber wenn wir dann...

Natürlich spielt alles auf diese maximale Server-Utilisation ein, also Container, Paths und so weiter.

Was...

Und diese...

Sorry.

Was...

Wo unheimlich viel drin ist, ist dynamisches Skalieren.

Also hier Architektur-Stream.

Also alle wissen, wie es geht.

Wir haben unsere typischerweise unsere Software-Systeme haben die eine zeitlich abhängige Last.

Und ich habe jetzt hier eine Grafik.

Also die Last ist jetzt abhängig von der Zeit, geht so mal peaks mit hoch und runter.

Und ich brauche dann mehrere Compute-Einheiten, um diese Last abzubilden.

Also vielleicht drei Server, drei Compute-Einheiten, nennen wir es mal so, in der Spitze.

Und eine Compute-Einheit für nachzunehmen.

Und Industriestandard ist ja im Wesentlichen, dass wir für maximal Last provisionieren.

Und dann laufen immer die ganzen drei Server.

Aber ich könnte dynamisch skalieren.

Das heißt, wenn meine Last steigt, tue ich Compute-Einheiten dazuschalten und dann wieder wegschalten.

Und auch den Computer tatsächlich dann ausschalten, wenn es geht, in On-Prem oder in der Cloud kann ich die Ressource freigeben.

Und dann ist tatsächlich die Emission weg von diesem Hardware.

Sowohl Energie als auch gebundene Emissionen.

Und wenn man da mal das Ersparte auch so sich überlegt, dann sind da locker 30, 40, 50 Prozent an CO2-Emissionen drin.

Bloß, weil man in Kubernetes einen Horizontal-Scaler eingeschaltet hat.

Bloß, weil man halt den Node dann am Ende freigibt.

Das ist aus einer technischen Sicht ein No-Brainer.

Go read a book, wenn du es nicht weißt.

Und das haut total rein.

Das würde ich unheimlich gerne mitgeben, weil ich sehe ganz viele Systeme.

Es ist wirklich Industriestandard, auf Maximallast zu provisionieren.

Weil man sozusagen ausgründen.

Also es ist nicht immer ausgründen.

Und unser Job als Techie besteht ja eigentlich darin, diese Ausgründen zu ändern.

Natürlich ist ein System so, wie es ist.

Das System hat auch ein Qualitätsproblem, weil es so ist.

Das fällt ja auch nicht vom Himmel.

Und das andere ist die CO2-Intensität.

Das ist nämlich etwas, was wir nicht im Blick haben.

Und das ist der Zusammenhang zwischen Energie, also Strom, und CO2.

## CO2-Intensität

Die CO2-Intensität, also die CO2-Erzeugung vom Strom, hängt davon ab, wie viele erneuerbare Energien ich habe.

In dem Augenblick.

Deutschland hat jetzt im Schnitt so ungefähr 60%.

Aber das ändert sich am Tag.

Und ich habe hier eine Webseite, die heißt Electricity Maps, für alle diejenigen, die nur zuhören können.

Da sieht man, wie im Augenblick die einzelnen Netze, also Deutschland, Luxemburg zum Beispiel, oder Norwegen, Frankreich, wie hoch da die CO2-Intensität ist.

Also wir haben jetzt Stand 10 Uhr.

Es ist immer ein bisschen verzögert.

### Regionale Unterschiede

In Deutschland 436 Gramm CO2 pro Kilowattstunde.

In Norwegen haben wir zu dem gleichen Zeitpunkt 30 Gramm CO2.

Weil Norwegen hat unheimlich viel Wasserkraft.

Polen hat ganz viel Kohle.

Da ist es jetzt 558 Gramm.

Wir haben in Frankreich, das darf man jetzt werten, wie man möchte, aber die haben unheimlich viel Atom.

Die haben 30% regenerativ.

Der Rest ist Atom, im Wesentlichen.

Wenn ich jetzt statische Sachen habe, kann ich mir überlegen, okay, also Number Crunch oder sowas.

Ich mache das in einer Region, die hat immer grünen Strom.

Oder dadurch, dass der Strom über die Zeit hinweg, der Anteil der erneuerbaren Energien schwankt.

Jetzt habe ich hier eine Webseite von dem Fraunhofer-Institut.

Das ist der Stromampel.

Und da sieht man, dass der Anteil der Erneuerbaren über den Tag heute schwankt.

### Zeitliche Schwankungen

Also wir haben typischerweise über Mittag gut.

Und heute weht kein Wind.

Deswegen ist heute Nachmittag um 17 Uhr schlecht.

Und dann wird es wieder besser.

Da gibt es Vorhersagen.

Und die Idee besteht darin, dass man ähnlich wie bei Elektroautoladen oder anderen Sachen immer dann den Strom verbraucht, wenn er durch erneuerbare Energien erzeugt wird.

Also ich schiebe die Last von meiner Software zu Zeiten, also berechne das zu Zeiten, wo ich wenig CO2 im Strom habe.

Dazu gibt es einen Haufen Tools.

Auch die Basis bildet wieder die Green Software Foundation.

Da geht es um Carbon-Aware-STK.

Und ich habe das genommen, ein bisschen in Tooling reingebaut und mit den Fraunhofern ein Projekt gemacht, um Vorhersagen zu bekommen über die CO2-Intensität des Stromnetzes in den nächsten 24 Stunden.

Da kam jetzt von Frage 2,3, ob das jetzt der erste Ansatz?

Kann ich so etwas als ersten Ansatz wählen, um zu optimieren?

Also das, was wir jetzt gerade sehen?

Ja, also okay, wir sind in der Software.

Es fängt immer davon ab.

## Optimierungsstrategien

Also wenn ich dir Punkte mitgeben darf, schalte das Zeug ab, was du nicht brauchst.

### Abschalten

Also diese ganzen Testsysteme muss bei jedem Komet, muss da die ganze Maschinerie laufen und dann mache ich es nur beim Merge Request.

Kann ich irgendwelche Systeme abschalten, wirklich abschalten?

Müssen meine Dinge nachts laufen?

Also das Abschalten hilft.

Nummer zwei, was total super läuft, ist dynamisches Skalieren.

### Dynamische Skalierung

Ein total low-hanging, unheimlich effizient.

Und Nummer drei ist Carbon-Aware Computing, also dieses Timeshifting, wo man sagt, okay, ich schiebe es da.

Und je mehr Badges du hast, desto besser ist es zu schieben.

Und das ist natürlich jetzt der Anfang, weil wir müssen auch noch andere Ressourcen mitnehmen.

Wir optimieren eigentlich hier Ressourcen, und zwar Compute-Ressourcen und CO2.

Die Zahl, die wir haben, ist im Augenblick CO2.

Aber wenn ich in der Cloud bin, zum Beispiel, und ich Badge-Shops habe, dann kann ich das kombinieren mit Spot VMs.

Das sind im Prinzip die VM-Abwärme von so einem Rechenzentrum, und die kombiniere ich mit.

Und damit habe ich ohne Aufwand, sage ich mal, so ein Maximal.

Genau.

Willst du kurz noch erklären, was Spot VMs sind?

Ich bin mir nicht sicher, ob das allen mitzumachen ist.

Also die großen Hyperscaler, wenn die zu viele Compute-Ressourcen haben, also freie Compute-Ressourcen, dann kann man eine Art VM bestellen.

Die bekommt man irgendwann, und die wird einem auch wieder weggenommen, wenn sie die Ressource brauchen.

Aber ich habe so eine freie Zeit, da kann ich die VM benutzen.

Und zwar, die ist auch deutlich kostengünstiger.

Also ich nehme so Rest ab, Rest-Compute ab.

Genau, wenn ich das richtig entsinne, also korrigiere mich, ist es so, dass ich sage, ich bezahle so und so viele Euro für dieses Ding.

Und wenn der Preis darunter ist, dann wird mir diese Ressource gegeben, und dann läuft die halt einige Zeit, und irgendwann wird sie mir dann auch wieder entzogen.

Das ist sozusagen das Beta-Modell.

Bei Microsoft kannst du zum Beispiel, da gibt es dieses Azure Badge als Dienst.

Da kannst du sagen, ich hätte gern Spot VMs, dann kriegst du die einfach irgendwann.

Und die sind dann 30, 40 Prozent billiger.

Und ich glaube, irgendwo anders kannst du auch bieten.

Ja, das war halt AWS, aber das ist halt auch schon wieder zehn Jahre her oder so.

Da habe ich genau das gemacht.

Und habe halt auch festgestellt, dass die Dinger dann einfach irgendwann weg sind.

Einfach so.

Die sind ja unter dem Hintern weg sozusagen.

Ja, genau.

Also da muss man halt die Software dementsprechend.

Aber um die Frage.

Also ja, es ist auf jeden Fall sehr valide.

Und vor allem, wenn man auch schaut, die CO2-Intensität, die schwankt halt auch mal von 600 oder 700 Gramm CO2 pro Kilowattstunde zu 50.

Also das haut schon rein, wenn du eine Stunde reingerechnet hast, dann ist es gut.

Genau, das Faktor von zehn, nicht?

Also das ist interessant.

Das haut schon rein.

Und es gibt Tooling.

Also das ist auch total einfach.

Hier auf der Webseite gibt es Jobs und PowerShell und Web und APIs und alles.

Genau, also das würde ich unheimlich gerne noch mitgeben, weil das sind so tatsächlich insgesamt alles Low-Hanging Foods.

Und wenn ich dann hingehe und sage, okay, ich habe meine Low-Hanging abgeerntet, dann kann ich wieder in die Software gehen, kann weitere Optimierungen machen.

Um einmal auf diese einzelnen Handlungsfelder einzuzahlen, kann man dann überlegen, was geht.

Genau, das ist eigentlich ein ganz hervorragender Punkt.

Ich glaube, du hast es nicht explizit gesagt, aber der kommt implizit raus.

Es geht eigentlich in Anführungsstrichen nur darum, wie ich die Software betreibe.

Also wir haben noch gar nicht darüber gesprochen.

Ich weiß gar nicht, war da nicht noch eine Frage?

Lass mich mal kurz schauen.

Also beziehungsweise das ist ja eines von den Themen, was halt immer durch die Gegend wabert, welche Programmiersprache soll ich jetzt benutzen?

Und das haben wir eigentlich gar nicht diskutiert.

Wäre halt so ein bisschen die Frage.

Also ist das denn überhaupt ein Thema?

Also ja, nein.

Also akademisch würde ich sagen.

Also erstmal eine Benenzialie-Programmiersprache, die für uns ein Pluton ist.

Also was soll ich den Leuten sagen?

Mach kein Python, mach RASP.

Aber so schlimm ist es auch nicht, weil Python benutzt natürlich die C-Bibliotheken am Ende.

Oder Java oder .NET oder irgendwas.

Naja, es hängt auch von der Laufzeitumgebung ab.

Also mache ich .NET-Code, mache ich .NET-Framework, mache ich Java mit irgendwelchen Enterprise Beans oder schlank.

Nehme ich, habe ich einen Spring dabei oder nicht?

Also es ist meiner Meinung nach nicht die Programmiersprache.

Wenn, dann ist es die Laufzeitumgebung und die Frameworks, die man dazu macht.

Ich denke aber, es ist vor allem das Mindset.

Also es ist Software-Engineering.

Es ist einfach normales Software-Engineering.

Das können wir alle.

Wir wissen, wie das geht.

Wenn wir es nicht wissen, dann werden wir es gleich lernen.

Es sind die ähnlichen Praktiken.

Und beim Software-Engineering haben wir unser Fokus auf Evolvierbarkeit.

Und bei Green Software, bei Green Coding benutzen wir die gleichen Werkzeuge mit dem Fokus auf Klimafreundlichkeit.

Und dabei sparen wir aller Voraussicht nach auch Geld.

Und das ist eben tatsächlich etwas, wo man direkt aktiv werden kann, wie du ja sehr deutlich gesagt hast.

Eine Sache, ich muss mal schauen, ob ich das vielleicht raussuche.

Ich weiß nicht, ob du darüber auch gestolpert bist, weil wir gerade über diesen Programmiersprachen waren.

Es gibt ein neues Paper, was irgendwie sagt, die vorherigen Betrachtungen darüber, dass Programmiersprachen erheblich was bringen, sind deswegen verfälscht, weil Programmiersprachen typischerweise benutzt werden für bestimmte Problemfelder.

Und in Wirklichkeit sind die Problemfelder das, was eben unterschiedliche Effizienz hat, erzeugt.

Das hier hat Spannung für mich.

Das selber kenne ich nicht, aber würde ich bestätigen.

Und was, glaube ich, noch nicht kam, aber zum Beispiel auch immer, ob ich mit statischer Code-Analyse da weiterkomme.

Es gibt das Umweltcampus Trier.

Und in der Umweltanalyse Birkenfeld heißt das.

Und da war zum Beispiel eine Masterarbeit, die das untersucht hat.

Und tatsächlich ist es so, dass wir über statische Code-Analyse natürlich Performance-Probleme kriegen, aber mehr als...

Also die Performance-Analyse machen können, was wir über statische Code-Analyse machen können, aber so richtig...

Also das macht den Code auch nicht fett.

Also es wird nicht besser...

Also wir kriegen nicht bessere Programmierparadigmen her, die über die Performance hinweg gehen.

Also profiler Land muss jetzt nicht zu uns kommen.

Ich glaube, das hast du auch sehr schön gesagt.

Also einmal diese sehr schöne Grafik, wo du ja gezeigt hast, okay, wenn ich halt dynamisch skaliere, dann speichert sehr viel, dass eben die Server-Auslastung auch tatsächlich sehr wichtig ist, also dass eben der Leerlauf so teuer ist.

Und eben auch diese Geschichte, dass eben CO2, je nachdem, wo ich halt das CO2 erzeuge oder wo ich den Strom leer bekomme, sehr unterschiedlich ist.

Und da sind halt offensichtlich die großen Faktoren.

Du hast auch diese CO2 Challenge in Karlsruhe, richtig?

Ja, danke.

Die Frage ist ja, was kann ich denn alles tun?

Also A, ich kann in meiner Profession bleiben und ich sage das immer reinschmuggeln.

Und als Unternehmer, also wir haben hier in Karlsruhe ein großes Unternehmensnetzwerk, eigentlich einer der größten in Europa.

Und wir haben jetzt eine Kampagne gestartet, wo Unternehmen sich committen, dass sie die CO2-Emissionen ihrer Softwareprodukte um 40 Prozent reduzieren, innerhalb eines Jahres.

Da gibt es Mentoren dazu, also Leute, Experten aus dem Netzwerk, sind ehrenamtlich dabei.

Also wenn jetzt jemand im Stream ist und Experte ist, bitte melden, Expertin.

Oder Leute in Karlsruhe entgegen sind, also da sind auch die Großen dabei, wie zum Beispiel Teamviewer, eine EnBW, Februar kennt man vielleicht.

Und auch ein paar Kleine, es fehlen noch ein bisschen welche, wie ich gerade sehe.

Die machen alle zusammen.

Und du übernimmst im Prinzip die Verantwortung für deine Produkte.

Das finde ich das Schöne an dieser Kampagne.

Ja, hört sich auf jeden Fall super an.

Noch irgendwas, was du loswerden wollen würdest?

Wir sind ja hier aus der Community getrieben.

Es gibt bundesweit einige Mieter inzwischen zum Thema Green Software.

Also Karlsruhe natürlich, München, Düsseldorf, Stuttgart, Frankfurt, ab und zu Hamburg und Berlin, wo dann auch noch was passiert.

Jetzt Nürnberg frisch dazugekommen.

Also wir haben überall.

Und manchmal kann man das auch, also in Karlsruhe kann man das auch hybrid machen.

Und es gibt dann noch von der Green Software Foundation auch so Sachen.

Also dieses, was wir vor 15 Jahren gestartet haben, die Agilität mit Software Craftmanship, die gleiche Bewegung funktioniert jetzt, geht jetzt los mit Green.

Also im Sinne einer Roots-Bewegung meinst du?

Ja, genau.

Und vielleicht noch eine Sache, also ich weiß nicht, ob das offensichtlich ist, aber du sparst ja auch Betriebskosten dadurch relativ offensichtlich.

Und man kann jetzt über die Menge diskutieren, aber es ist ja nicht so, dass man investiert und nur CO2-Sparzellen im Hochgeld...

Es wird nicht teurer.

Es wird besser.

Und wir sind ja in einem optimierten System im Augenblick.

Also gerade wir sorgen ja immer für Optimum.

Das ist ja unser Job.

Mach's besser, mach's gut.

Und was wir jetzt tun, ist, dass wir noch einen weiteren Aspekt in unsere Profession reinkriegen.

Also das, was wir bisher immer mit...

Wir hatten Agilität, wir hatten Software Craftmanship und jetzt kommt halt das Klima dazu.

Und dadurch braucht es eine Art Aktivierungsenergie.

Aber das nächste Optimum, was wir produzieren, das ist besser als das, was wir hatten.

Oder es ist günstiger.

Und wir müssen halt das nur machen.

Dann würde ich sagen, wir sind so ein bisschen am Ende der Zeit.

Ob von dir noch Themen sind?

Ich könnte noch stundenlang darüber reden.

Aber ich glaube, das ist gut.

Also wenn Fragen sind, auch im Nachgang, einfach anpingen, auf LinkedIn connecten.

Ja, genau.

Ich verlinke auf jeden Fall noch mal dein LinkedIn-Profil.

Und wir werden sowieso eine ganze Menge an Dings haben.

Dann würde ich sagen, vielen Dank an dich.

Und schön, dass du dir die Zeit genommen hast.

Ich fand es sehr spannend.

Und ich finde es auch ein total wichtiges Thema.

Kurze Vorschau auf das nächste Mal.

Das nächste Mal ist wieder nächsten Freitag.

Und das ist das Thema Code Retreat.

Das heißt, wir werden, also Marco Emmerich und ich werden uns gemeinsam an den Rechner setzen.

Also Marco darf tatsächlich am Rechner sitzen und coden.

Und wir werden halt gemeinsam mal zeigen, wie so ein Code Retreat funktioniert.

Das ist so eine Geschichte aus dem Bereich Software Craftmanship, wo es halt darum geht, System Development, Refactoring und diese ganzen Geschichten halt zu üben.

Und das ist so ein bisschen die Vorschau auf den Global Day of Code Retreat, der am 8.11. ist.

Das heißt, das ist so ein bisschen ein Appetizer dafür.

Genau.

Dann würde ich sagen, vielen Dank und bis dahin.