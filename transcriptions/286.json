{
  "text": "Hallo, ich bin Eberhard Wolff. Freitags mache ich oder Lisa Moritz einen Livestream zum Thema Software-Architektur, oft zusammen mit Gästen. Dieser Podcast ist das Audio des Streams. Weitere Folgen, Sketchnotes und vieles mehr findet ihr unter software-architektur.tv. So, herzlich willkommen zu einer weiteren Episode von Software-Architektur im Stream. Bevor wir jetzt mit dem tatsächlichen Thema loslegen, einen Hinweis. Für unsere Special Episode live von den IT-Tagen zum Thema Diversity in der IT suchen wir persönliche Erfahrungsberichte von Menschen, die in der Tech-Branche schon unterrepräsentiert sind oder sich dort nicht mehr willkommen gefühlt haben. Da wäre es super, wenn wir noch mehr Submissions bekommen, findet man unter software-architektur.tv. Wir sind auf eure Submissions gespannt. Jetzt zum Thema. Ralf und ich werden die Episode bestreiten. Ralf, schön, dass du da bist. Danke, dass ich da sein darf. Ja, sehr gerne und danke für die vielen Episoden. Ich glaube, wir sparen uns eine Vorstellung, du hast ja schon ganz viele Episoden gemacht. Ziel ist eigentlich, einmal darauf hinzuweisen, was wir bei der Webseite des Streams noch umgesetzt haben. Denn diese Features sind im Moment unterbenutzt, wie wir festgestellt haben. Und zum anderen ist es so, dass wir da ein paar Erfahrungen gesammelt haben, wie man mit AI Software entwickeln kann. Und das wollten wir, glaube ich, selber eh mal besprechen. Weil du, Ralf, hast ja so ein bisschen die Implementierung gemacht und ich bin irgendwie die Person, die tatsächlich ganz viel so inhaltlich an der Webseite rumeditiert. Und da hatten wir uns dann gedacht, dann sprechen wir auch öffentlich darüber. Genau, du hast ja noch hingeschrieben, dass das Ganze ein Experiment war, aus deiner Sicht. Ja, es war aus meiner Sicht insofern ein Experiment, als dass ich gesagt habe, Mensch, ich probiere so viel aus mit KI, ich erzähle so viel über KI. Und ich wollte halt tatsächlich mal ein Projekt machen, was in der Öffentlichkeit ist, wo man tatsächlich die Fähigkeiten von der KI auf verschiedenen Ebenen ausprobiert. Und da hatte ich mir gedacht, Mensch, wäre doch eigentlich ganz gut, wenn wir ordentliche Transcriptions haben für Softwarearchitektur im Stream. Es gibt ja schon so Web-Services, wo man YouTube-URL reingeben kann. Und dann baut der mit KI nicht nur die Transcription, sondern eben auch Zusammenfassungen und eine Topic-Übersicht, so eine Mindmap und solche Geschichten. Und das dachte ich mir, könnte man auch machen. Und habe es einfach mal ausprobiert. Ja, und da hatte ich dann von da eigentlich den Ansatz, ja, Web-Coding. Ich glaube, damals, als ich es angefangen habe, da habe ich noch das als Prompt-Driven-Development bezeichnet. Und es war, glaube ich, Claude Code genommen. Und Claude hat gesagt, du, ich möchte hier mal Transcriptions haben. Hier ist eine Website, da findest du die ganzen MP3-Files. Ja, und dann ging es los. Dann ging erst mal die Coding-Session los. Und ja, soll ich gleich mal so ganz ausführlich erzählen, wie das abgelaufen ist? Ja, sehr gerne. Vielleicht noch ein, zwei Hinweise vorab. Also, wie du schon sagtest, das sind Transkriptenzusammenfassung und Stichpunkt und noch LinkedIn-Post. Und diese Transkripte sind, glaube ich, für mich war das immer so ein blinder Fleck, weil das eben alleine wegen Barrierefreiheit, aber auch wegen Durchsuchen der Inhalte, glaube ich, eine ganz wichtige Sache ist. Und wir, das wäre noch der Benutzungshinweis, also wir reviewen die Transkripte nicht. Deswegen freuen wir uns über Pull-Requests, wenn da irgendjemandem irgendwas auffällt. Das kann man jetzt auf der Website auch direkt machen. Umgekehrt ist es halt so, dass wir die Zusammenfassung und die Stichpunkte tatsächlich noch mal reviewen. Also die reviewe ich und editiere sie dann halt. Und das ist sozusagen die Benutzungssicht. Aber ich erzähle gerne, wie du es sozusagen gebaut hast oder hast es gebaut lassen. Also meine Idee war halt, die Videos von YouTube herunterzuladen. Das geht ja nicht so einfach. Aber wir hatten ja die MP3-Files und mir war klar, dass OpenAI die Whisper-API hat, die eben transkribieren kann. Und da habe ich einfach gesagt, Claude, kannst du mir nicht ein bisschen Code schreiben? Ich dachte, das wären so zehn Zeilen, dass ich die API nutze, das MP3-File reingebe und dann schon mal die Transkription rausbekomme. Hat sich aber etwas schwieriger herausgestellt, weil Claude hat ausprobiert und das fand ich sehr gut. Claude hat eigenständig gearbeitet und hat da eben das MP3-File reingeworfen und hat Fehler bekommen. Ja, ist leider zu groß zur Verarbeitung. Und dann hat aber Claude gleich selbstständig weitergedacht. Und ich habe von diesen Transkriptions und Audio-Verarbeitung ehrlich gesagt überhaupt keine Ahnung. Aber die Art und Weise, wie Claude mich unterstützt hat, das war ein richtiges Enablement. Weil Claude hat dann gesagt, okay, das File ist zu groß, dann können wir es vielleicht über FFM-Pack modifizieren. Hat es analysiert, hat gesehen, ist es Stereo? Da können wir Mono draus machen, dann hat es schon mal nur die halbe Größe. Dann war es immer noch zu groß. Dann hat er gesagt, okay, dann nehmen wir eben die Audio-Auflösung runter. Du guckst gerade schon so. Ja, weil das Audio ist sehr sicher Mono. Also ich wäre jetzt extrem überrascht, wenn es das nicht wäre. Das typische Audio ist 50 oder 60 Megabyte für eine Stunde. Eigentlich hatte ich das auch mal zusammen optimiert. Ich muss es jetzt nachgucken. Wir sind bei podcaster.de, die ich übrigens sehr empfehlen kann. Das ist ein sehr netter Laden. Und auch ein deutscher Laden. Da ist es so, dass man 250 Megabyte pro Monat bekommt. So dass ein Incentive da ist, möglichst das klein zu halten. Und ich glaube, wir sind bei 50 oder 60 Megabyte und deswegen auch Mono. Und deswegen hat auch nicht so wahnsinnig viel Auflösung eigentlich. Also das ist jetzt schon wieder sehr spannend. Das war mir alles gar nicht bewusst. Ich weiß nicht, ob da Claude einfach gesagt hat, na ja, wahrscheinlich ist es Stereo. Und hat es einfach mal, keine Ahnung. Aber das zeigt auch schon wieder, dass ich, der ich jetzt wenig Ahnung davon hatte, einfach an das Problem rangegangen bin. Mit ein bisschen mehr Ahnung, wie es eben da bei uns auf dem Server liegt. Mit deiner Ahnung hätte man es eben wahrscheinlich ganz anders angehen können. Aber ich fand, ich war begeistert. Er hat sich da durchgekämpft. Es war dann zum Schluss immer noch zu groß. Ich glaube, es war. Ich muss überlegen. Ich glaube, er hat dann irgendwann gesagt, die Input Größe ist jetzt okay. Aber es ist zu groß für die Output Größe. Und dann ist Claude hergegangen und hat gesagt, ja gut, dann zerlegen wir das Ganze. Also ist nicht stupide mit der Audioauflösung runtergegangen, bis man nichts mehr versteht. Hat dann gesagt, jetzt zerlegen wir das. Hat vorgeschlagen, dass wir nach Pausen suchen. Und dann habe ich mir schon gedacht, ja, jetzt wird irgendwie so ein Mist kommen, dass er irgendwie die zwei ersten Pausen nimmt. Und die Stücke dann komplett unterschiedlich groß sind. Nein, er hat gesagt, er sucht mal nach allen Pausen, um es dann in ungefähr gleich große, drei gleich große Stücke zu zerlegen. Hat das gemacht und kam somit schon sehr gut voran, dass er eben die Transcription bekommen hat. Wobei man muss dazu sagen, bei der Transcription mit Whisper kann man ja so ein paar Wörter mitgeben. Auf die er achten soll, die er eben besser erkennen soll, dass er die richtige Schreibweise hat. Aber Whisper tut sich da anscheinend schwer. Also mir kommt so vor, dass Whisper nur versucht, die Wörter zu erkennen und nicht mit dem Kontext arbeitet. Jemand von InnoCue hat sowas ähnliches, glaube ich, gemacht. Und die haben, glaube ich, das GPT-4.0-Modell genommen, was aus meiner Sicht dann wahrscheinlich den Kontext tatsächlich verwendet und damit die Begriffe besser versteht. Aber ich hatte dann eben schon so gesehen, manche Begriffe hat er falsch aufgenommen oder so. Ich habe dann immer die Überschrift mit reingegeben, dass er zumindest den Namen des Gastes richtig hat. Hat nicht immer funktioniert. Aber es war dann halt eben auch so ein Ding, wo ich gesagt habe, wenn wir das jetzt irgendwie zusammenfassen in Blogposts, in die Key Takeaways, dann fällt es ja wahrscheinlich raus. Genau, da gibt es tatsächlich einige lustige Anekdoten. Tatsächlich ist es so, dass teilweise die Namen von dem Gast nicht richtig geschrieben worden sind. Das kann man auch alles in der GitHub-Historie nachgucken. Das Ding steht ja Pull Request und das ist das ursprüngliche Transcript. Und wenn da irgendjemand was in dem Transcript manuell ändert, kann man das halt sehen. Also Gästenamen sind halt auffällig. Dann ein besonderes Highlight war Chat-GPT. Also der Begriff Chat-GPT ist dem System nicht bekannt. Was dann dazu führt, dass da irgendwelche Worte rausgekommen sind. Und auch unterschiedliche, sodass ein Search and Replace nicht mehr ausreicht. Und bei einer der letzten Folgen war es Wortly Maps. Was tatsächlich das Thema der Folge war. Die bekannten Sachen sind daraus editiert, aber ich halte es für sehr wahrscheinlich, dass da noch welche drin sind. Du hattest ja auch in dem Kontext die Transkripte nochmal Reviewen lassen durch GitHub Copilot. Was ich halt lustig fand, weil dann irgendwie nicht eine AI eine AI kontrolliert. Und GitHub Copilot hat dann tatsächlich solche Sachen gemacht und hat dann gesagt, also aus dem Kontext ergibt sich halt folgendes. Und deswegen glaube ich, dass hier folgendes eigentlich hingehört. Genau, das fand ich total faszinierend, weil als es dann auf der Pull Request auf GitHub war, konnte ich halt den GitHub Copilot dem das zum Review geben. Und der hat halt direkt gesagt, ja, ihr redet hier über Wortly Maps. Ihr habt aber den Simon Wortley falsch geschrieben. Und dieses Kontextverständnis, das hat da zum Review geholfen. Und das ist auch das, warum ich denke, dass das Whisper Modell eben den Kontext nicht mitnimmt, sondern einfach nur ein Wortverständnis macht oder Worterkennung macht. Und das war faszinierend. So fast phonetisch, nicht so was in dem Dreh. Genau, aber das zeigt jetzt schon, dass wir schon Beieben von KI drin haben. Einmal zum Entwickeln des, wie man heutzutage sagen würde, herablassend Wipe Coding. Also da habe ich mir tatsächlich wenig Mühe gegeben. Und dann aber eben auch den GitHub Copilot für das Review. Wir haben ihn, glaube ich, nicht verwendet, um es zu modifizieren, sondern das haben wir dann manuell gemacht. Also ich kann ja dem Copilot auch ein Issue zuweisen. Aber in dem Fall haben wir es noch nicht gemacht. Genau, also GitHub Copilot hat ja irgendwelche Reviews. Und ich erinnere mich, dass ich dann auf Basis dessen das halt editiert habe und das dann manchmal halt auch Unsinn produziert hat. Übrigens, der, so war ich nicht, der oder die, hat gerade im Chat geschrieben, er, sie, wie bestimmt man das Geschlecht des KI-Modells? Und da sind wir wieder bei der Anthropomorphisierung von KI. Also dass es ja eigentlich eine Maschine ist. Und wir eben dazu neigen, von dieser Maschine sozusagen wie von einem Menschen. Und das ist tatsächlich ein Problem. Mir war das auch, ehrlich gesagt, so als Gedanke durch den Kopf gegangen, bevor Sava das anmerkte. Ja, keine Ahnung. Die Antwort ist, irgendwie muss man da eigentlich aufpassen. Ich merke, dass ich das halt nicht gut auf die Reihe bekomme. Und im Übrigen ist es halt so, dass wir in Deutsch ja viele, viele Dinge haben, die wir halt eindeutsch nicht. Es ist zum Beispiel offensichtlich ja der Computer. Und da ist dann ja auch die Frage, wie man dem ein Geschlecht zuweist. Und ich glaube, das ist bei den AI-Systemen möglicherweise ähnlich. Aber nicht, whatever. Ja, also ich würde da... Nicht guter Hinweis. Ist ein guter Hinweis. Allerdings, ich gebe da auch für meine Kommunikation selbst nicht mehr viel drauf, weil Haustiere, ja, wenn man es so will, vermenschlicht man auch. Beziehungsweise, ja, ich könnte jetzt immer von dem LLM sprechen, neutral. Aber wenn ich dann eben auf Claude und auf Copilot gehe und so, dann sind es halt wieder irgendwie das Copilot. Weiß nicht. Also seht mir das nach. Ich habe es, ehrlich gesagt, einfach aufgegeben. Ja, ich glaube, also mir fällt das halt auch auf im Dialog mit so etwas wie JGPT, dass das eigentlich intendiert zu sein scheint. Also das benimmt sich halt so, als sei es eben ein Mensch. Und eigentlich müsste man das anders machen, wäre wahrscheinlich irgendwie das Vertrauen in das System geringer und das ist natürlich nicht das, was die wollen. Von daher ist es eben tatsächlich ein Problem. Also ich denke, zum einen alles, was sich der menschlichen Sprache bedient, kommt menschlich irgendwo rüber. Aber du hast schon recht, man hat bei OpenAI schon das Gefühl, dass man es darauf anlegt, dass da die Menschlichkeit rüberkommt in der Art des Tonfalls. Aber auch, ja, ich meine, mich nervt das total, wenn Claude mir auf die Schulter klopft und sagt, hey, das hast du aber gut gemacht, da wäre ich selbst nicht drauf gekommen. Wow, das bringt uns jetzt hier richtig voran. Wo ich echt sage, weiß auch nicht, mag ich nicht, versuche ich immer abzutrainieren. Genau, also Savai hat noch geschrieben, sorry für die kätzerische Frage, aber er kam mittendrin dazu und war verwirrt, weil Ralf immer von R sprach. Also kein Grund, sich zu entschuldigen, ich fand das halt tatsächlich, also wie gesagt, ich hatte schon einen innigen Gedanken. Ja, es ist definitiv eine Problematik, weil man eben die KI vermenschlicht und somit dabei auch Fehler macht, dass man ihr zu viel zutraut und vielleicht die Ergebnisse nicht mehr überprüft. Ergebnisse überprüfen ist, glaube ich, echt ein Problem. Also human in the loop zu behalten, dafür sind wir Menschen zu faul, dass wir irgendwann sagen, nee, also das kontrolliere ich jetzt nicht mehr. Genau, da haben wir halt die Grenze gezogen bei den Transkripten und eben bei den Zusammenfassungen halt irgendwie nicht. Also die reviewen wir, also reviewe ich manuell. Also ich weiß nicht genau, wie sie entstehen, aber das ist vielleicht ein guter Übergang, um sozusagen zu dem Thema zu kommen. Ich fand das nämlich eigentlich ein relatives Highlight und das ist irgendwie eine von den Sachen, wo ich so ein bisschen überrascht bin, dass es eben so wenig genutzt wird, weil man eben auf wenigen Absätzen tatsächlich eine Idee davon bekommt, was halt in dieser Episode drinsteht oder da passiert. Und da sind die Ergebnisse meiner Ansicht nach tatsächlich sehr schön und gut. Es gibt jetzt eine Ausnahme, die mir jetzt über den Weg gelaufen ist, nachdem wir tatsächlich auch darüber gesprochen haben, diese Episode zu machen, die wir jetzt gerade machen. Du, Ralf, gehst ja jetzt irgendwie vor und gehst halt sozusagen schrittweise die alten Folgen durch. Und wir sind irgendwie angekommen bei dieser Dunbar-Folge, wo es halt um diese Dunbar-Zahl geht. Also die Zahl, die eben 150 ist und angeblich irgendwie die Menge an Menschen definiert, mit denen man halt ein gutes Vertrauensverhältnis haben kann. Und der Inhalt der Episode ist, dass das genau nicht stimmt. Also eigentlich ist die Aussage der Episode, diese Zahl ist eben gerade keine Aussage über die I-Date-Größe von Gruppen. Und das ist tatsächlich etwas, wo ich das erste Mal in meiner Erinnerung eine Zusammenfassung halt deutlich editiert habe, nämlich weg von, das ist halt die Dunbar-Zahl, das ist halt eine Gruppengröße hinzu. Nee, ist es halt irgendwie gerade nicht. Und das andere Beispiel, das war eine Kleinigkeit, das war die Episode mit meiner Kollegin Tanja Friedl. Da ging es halt irgendwie um Produktmanagement. Und da hatte sie gesagt, wenn ich zum Beispiel ein stark konfigurierbares Produkt habe, dann habe ich ja das Problem, dass es halt stark konfigurierbar ist. Ich muss also den Konfigurator bauen. Es sei denn, ich habe einen Versicherungsfall, ein Produkt ist beschädigt worden und ich will exakt nochmal dasselbe ausliefern. Daraus hat die Zusammenfassung gemacht, es ist ein System zur Bearbeitung von Versicherungsschäden entstanden. Und das ist halt tatsächlich falsch. Bei mir hinterlässt das so ein bisschen, also du hast es gerade gesagt mit Human in the Loop, so ein bisschen indifferentes, also wie soll ich sagen, das sind jetzt glaube ich tatsächlich die einzigen beiden Beispiele, die mir so einfallen. Und das, ich weiß nicht, wieviel... Die du befunden hast und dir einfallen. Genau. Ich weiß nicht, wieviel Episoden eigentlich transkribiert jetzt sind. Ich glaube, es sind so 50, 60. Hätte ich jetzt auch gedacht. Es scheint das erstmal eine niedrige Fehlerrate zu sein, aber du hast es halt selber schon gesagt, ich auch selber neige dazu, die Sachen halt irgendwie sozusagen durchzuwinken. Und das führt irgendwie zu der Frage, wie viele von den Dingen da halt sozusagen komisch sind, ohne dass wir da sie gefunden haben. Ich glaube, wir haben keine krass sinnentstellenden Zusammenfassungen, das würde mich tatsächlich glaube ich überraschen. Und ich glaube, dass halt der Wert sehr hoch ist, auch wenn es halt im Moment nicht so wahnsinnig viel benutzt wird, weil man sich erstmal angucken kann, okay, was ist da eigentlich grob der Plan, was steht da so grob drin. Und ich glaube, da sind sozusagen die Fehler auch akzeptabel in gewisser Weise, weil ja das Original eben da ist. Also es ist ja nur ein Hinweis auf das Original und sollte dann irgendwie dazu dienen zu sagen, okay, ich höre mir jetzt irgendwie das ganze Ding nochmal an oder ich sehe es mir halt irgendwie an. Und deswegen glaube ich, dass es halt akzeptabel ist. Apropos Fehler, ich habe jetzt gerade nachgeguckt, ich habe ja MP3s auf der SSD, also es ist definitiv ein Ein-Kanal-Mono-MP3 und die werden alle gleich produziert, das muss also identisch sein. Und es hat 121 Kilobit mit 48 KHz Auflösung und 121 Kilobit ist nicht so wahnsinnig viel, also das ist halt eigentlich eher auf der niedrigen Seite, deswegen sind die halt auch so klein. Aber anyways, da ist halt eine Gefahr, eine klassische KI-Gefahr, dass bei der Zusammenfassung jetzt sozusagen Fehler sind. Aber auch das ist ja wieder faszinierend, weil ich kann mich echt daran erinnern, dass die KI gesagt hat, das ist Stereo, wir mixen das jetzt auf Mono ab. Und das bedeutet ja, dass die KI da quasi wieder einen Fehler gemacht hat. Einen Fehler, der so what, ist ja egal. Also auch das muss man berücksichtigen, dass viele Fehler einfach so verschwinden, weil unwichtig. Genau, und das andere, was sehr interessant ist, wir diskutieren ja im Stream, dass Softwareentwicklung eigentlich ein Team-Effort sein soll, dass man miteinander reden soll. Wenn wir vorher drüber geredet hätten, dann hätten wir es halt herausgefunden und hätten da ein Ergebnis produzieren können. Aber ich fand das nur lustig, weil, wie du ja richtig sagst, wenn wir sozusagen vorher drüber geredet hätten, wäre es vielleicht aufgefallen. Nicht aber, wie das halt so ist. Also du bist ja alleine losgelaufen und ich fand das ja auch super, dass du halt die Features gebaut hast, aber da wäre dann eben ein Meeting hilfreich gewesen wahrscheinlich. Aber da würde ich ganz gern nochmal drauf eingehen, diesen Aufwand, den wir haben, um das zu reviewen. Weil du hast ja gerade eben ganz richtig gesagt, ich bin da allein losgelaufen. Ich habe einfach mal gemacht, ich brauchte ein paar Daten, irgendein Real-World-Projekt und hey, ist ja jetzt hier alles öffentlich. Da konnte ich mir die Daten einfach schnappen. Und als das dann soweit war und du drüber geguckt hast und gesagt hast, da muss man aber über alle Folgen drüber gucken, müssen wir reviewen.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 6.5,
      "text": " Hallo, ich bin Eberhard Wolff. Freitags mache ich oder Lisa Moritz einen Livestream zum Thema Software-Architektur, oft zusammen mit Gästen.",
      "tokens": [
        50364,
        21242,
        11,
        1893,
        5171,
        462,
        607,
        21491,
        19925,
        602,
        13,
        6142,
        270,
        12109,
        28289,
        1893,
        4513,
        12252,
        5146,
        6862,
        4891,
        31738,
        377,
        1572,
        5919,
        16306,
        27428,
        12,
        10683,
        339,
        642,
        2320,
        374,
        11,
        11649,
        14311,
        2194,
        460,
        737,
        6266,
        13,
        50689
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26005762815475464,
      "compression_ratio": 1.4853556156158447,
      "no_speech_prob": 0.06800535321235657
    },
    {
      "id": 1,
      "seek": 0,
      "start": 6.5,
      "end": 16.0,
      "text": " Dieser Podcast ist das Audio des Streams. Weitere Folgen, Sketchnotes und vieles mehr findet ihr unter software-architektur.tv.",
      "tokens": [
        50689,
        39609,
        29972,
        1418,
        1482,
        25706,
        730,
        24904,
        82,
        13,
        492,
        270,
        323,
        15255,
        1766,
        11,
        49245,
        2247,
        279,
        674,
        5891,
        279,
        5417,
        27752,
        5553,
        8662,
        4722,
        12,
        1178,
        642,
        2320,
        374,
        13,
        24641,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26005762815475464,
      "compression_ratio": 1.4853556156158447,
      "no_speech_prob": 0.06800535321235657
    },
    {
      "id": 2,
      "seek": 0,
      "start": 22.0,
      "end": 25.5,
      "text": " So, herzlich willkommen zu einer weiteren Episode von Software-Architektur im Stream.",
      "tokens": [
        51464,
        407,
        11,
        45919,
        46439,
        2164,
        6850,
        44036,
        19882,
        2957,
        27428,
        12,
        10683,
        339,
        642,
        2320,
        374,
        566,
        24904,
        13,
        51639
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26005762815475464,
      "compression_ratio": 1.4853556156158447,
      "no_speech_prob": 0.06800535321235657
    },
    {
      "id": 3,
      "seek": 2550,
      "start": 25.5,
      "end": 35.5,
      "text": " Bevor wir jetzt mit dem tatsächlichen Thema loslegen, einen Hinweis. Für unsere Special Episode live von den IT-Tagen zum Thema Diversity in der IT suchen wir persönliche Erfahrungsberichte von Menschen,",
      "tokens": [
        50364,
        879,
        8453,
        1987,
        4354,
        2194,
        1371,
        256,
        1720,
        10168,
        10193,
        16306,
        1750,
        22936,
        11,
        4891,
        29571,
        35033,
        13,
        14990,
        14339,
        11863,
        19882,
        1621,
        2957,
        1441,
        6783,
        12,
        51,
        4698,
        5919,
        16306,
        44187,
        294,
        1163,
        6783,
        44470,
        1987,
        31228,
        10185,
        34137,
        5846,
        607,
        18972,
        2957,
        8397,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2341334968805313,
      "compression_ratio": 1.4964028596878052,
      "no_speech_prob": 0.20591896772384644
    },
    {
      "id": 4,
      "seek": 2550,
      "start": 35.5,
      "end": 40.5,
      "text": " die in der Tech-Branche schon unterrepräsentiert sind oder sich dort nicht mehr willkommen gefühlt haben.",
      "tokens": [
        50864,
        978,
        294,
        1163,
        13795,
        12,
        33,
        4257,
        1876,
        4981,
        8662,
        265,
        1424,
        13555,
        317,
        4859,
        3290,
        4513,
        3041,
        15775,
        1979,
        5417,
        46439,
        11271,
        7254,
        2282,
        3084,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2341334968805313,
      "compression_ratio": 1.4964028596878052,
      "no_speech_prob": 0.20591896772384644
    },
    {
      "id": 5,
      "seek": 2550,
      "start": 40.5,
      "end": 46.5,
      "text": " Da wäre es super, wenn wir noch mehr Submissions bekommen, findet man unter software-architektur.tv.",
      "tokens": [
        51114,
        3933,
        14558,
        785,
        1687,
        11,
        4797,
        1987,
        3514,
        5417,
        8511,
        76,
        7922,
        19256,
        11,
        27752,
        587,
        8662,
        4722,
        12,
        1178,
        642,
        2320,
        374,
        13,
        24641,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2341334968805313,
      "compression_ratio": 1.4964028596878052,
      "no_speech_prob": 0.20591896772384644
    },
    {
      "id": 6,
      "seek": 4650,
      "start": 47.5,
      "end": 50.5,
      "text": " Wir sind auf eure Submissions gespannt.",
      "tokens": [
        50414,
        4347,
        3290,
        2501,
        32845,
        8511,
        76,
        7922,
        47355,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3034168481826782,
      "compression_ratio": 1.4497607946395874,
      "no_speech_prob": 0.15782791376113892
    },
    {
      "id": 7,
      "seek": 4650,
      "start": 52.5,
      "end": 59.5,
      "text": " Jetzt zum Thema. Ralf und ich werden die Episode bestreiten. Ralf, schön, dass du da bist.",
      "tokens": [
        50664,
        12592,
        5919,
        16306,
        13,
        497,
        1678,
        674,
        1893,
        4604,
        978,
        19882,
        1151,
        265,
        6009,
        13,
        497,
        1678,
        11,
        13527,
        11,
        2658,
        1581,
        1120,
        18209,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3034168481826782,
      "compression_ratio": 1.4497607946395874,
      "no_speech_prob": 0.15782791376113892
    },
    {
      "id": 8,
      "seek": 4650,
      "start": 59.5,
      "end": 62.5,
      "text": " Danke, dass ich da sein darf.",
      "tokens": [
        51014,
        26508,
        11,
        2658,
        1893,
        1120,
        6195,
        19374,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3034168481826782,
      "compression_ratio": 1.4497607946395874,
      "no_speech_prob": 0.15782791376113892
    },
    {
      "id": 9,
      "seek": 4650,
      "start": 62.5,
      "end": 65.5,
      "text": " Ja, sehr gerne und danke für die vielen Episoden.",
      "tokens": [
        51164,
        3530,
        11,
        5499,
        15689,
        674,
        46434,
        2959,
        978,
        19885,
        9970,
        271,
        33482,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3034168481826782,
      "compression_ratio": 1.4497607946395874,
      "no_speech_prob": 0.15782791376113892
    },
    {
      "id": 10,
      "seek": 4650,
      "start": 65.5,
      "end": 70.5,
      "text": " Ich glaube, wir sparen uns eine Vorstellung, du hast ja schon ganz viele Episoden gemacht.",
      "tokens": [
        51314,
        3141,
        13756,
        11,
        1987,
        637,
        4484,
        2693,
        3018,
        12231,
        30016,
        11,
        1581,
        6581,
        2784,
        4981,
        6312,
        9693,
        9970,
        271,
        33482,
        12293,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3034168481826782,
      "compression_ratio": 1.4497607946395874,
      "no_speech_prob": 0.15782791376113892
    },
    {
      "id": 11,
      "seek": 7050,
      "start": 71.5,
      "end": 81.5,
      "text": " Ziel ist eigentlich, einmal darauf hinzuweisen, was wir bei der Webseite des Streams noch umgesetzt haben.",
      "tokens": [
        50414,
        25391,
        1418,
        10926,
        11,
        11078,
        18654,
        14102,
        11728,
        40196,
        11,
        390,
        1987,
        4643,
        1163,
        9573,
        405,
        642,
        730,
        24904,
        82,
        3514,
        1105,
        42283,
        3084,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.231573686003685,
      "compression_ratio": 1.4682927131652832,
      "no_speech_prob": 0.10353536158800125
    },
    {
      "id": 12,
      "seek": 7050,
      "start": 81.5,
      "end": 85.5,
      "text": " Denn diese Features sind im Moment unterbenutzt, wie wir festgestellt haben.",
      "tokens": [
        50914,
        19027,
        6705,
        3697,
        3377,
        3290,
        566,
        19093,
        8662,
        1799,
        325,
        2682,
        11,
        3355,
        1987,
        6633,
        26293,
        3084,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.231573686003685,
      "compression_ratio": 1.4682927131652832,
      "no_speech_prob": 0.10353536158800125
    },
    {
      "id": 13,
      "seek": 7050,
      "start": 85.5,
      "end": 94.5,
      "text": " Und zum anderen ist es so, dass wir da ein paar Erfahrungen gesammelt haben, wie man mit AI Software entwickeln kann.",
      "tokens": [
        51114,
        2719,
        5919,
        11122,
        1418,
        785,
        370,
        11,
        2658,
        1987,
        1120,
        1343,
        16509,
        34137,
        5084,
        5019,
        5136,
        2018,
        3084,
        11,
        3355,
        587,
        2194,
        7318,
        27428,
        28449,
        32099,
        4028,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.231573686003685,
      "compression_ratio": 1.4682927131652832,
      "no_speech_prob": 0.10353536158800125
    },
    {
      "id": 14,
      "seek": 9450,
      "start": 95.5,
      "end": 99.5,
      "text": " Und das wollten wir, glaube ich, selber eh mal besprechen.",
      "tokens": [
        50414,
        2719,
        1482,
        46019,
        1987,
        11,
        13756,
        1893,
        11,
        23888,
        7670,
        2806,
        4097,
        38951,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26564186811447144,
      "compression_ratio": 1.6305084228515625,
      "no_speech_prob": 0.040810726583004
    },
    {
      "id": 15,
      "seek": 9450,
      "start": 99.5,
      "end": 103.5,
      "text": " Weil du, Ralf, hast ja so ein bisschen die Implementierung gemacht und ich bin irgendwie die Person,",
      "tokens": [
        50614,
        18665,
        1581,
        11,
        497,
        1678,
        11,
        6581,
        2784,
        370,
        1343,
        10763,
        978,
        4331,
        43704,
        11651,
        12293,
        674,
        1893,
        5171,
        20759,
        978,
        8443,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26564186811447144,
      "compression_ratio": 1.6305084228515625,
      "no_speech_prob": 0.040810726583004
    },
    {
      "id": 16,
      "seek": 9450,
      "start": 103.5,
      "end": 107.5,
      "text": " die tatsächlich ganz viel so inhaltlich an der Webseite rumeditiert.",
      "tokens": [
        50814,
        978,
        20796,
        6312,
        5891,
        370,
        294,
        20731,
        1739,
        364,
        1163,
        9573,
        405,
        642,
        8347,
        292,
        270,
        4859,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26564186811447144,
      "compression_ratio": 1.6305084228515625,
      "no_speech_prob": 0.040810726583004
    },
    {
      "id": 17,
      "seek": 9450,
      "start": 107.5,
      "end": 111.5,
      "text": " Und da hatten wir uns dann gedacht, dann sprechen wir auch öffentlich darüber.",
      "tokens": [
        51014,
        2719,
        1120,
        20441,
        1987,
        2693,
        3594,
        33296,
        11,
        3594,
        27853,
        1987,
        2168,
        34603,
        21737,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26564186811447144,
      "compression_ratio": 1.6305084228515625,
      "no_speech_prob": 0.040810726583004
    },
    {
      "id": 18,
      "seek": 9450,
      "start": 111.5,
      "end": 116.5,
      "text": " Genau, du hast ja noch hingeschrieben, dass das Ganze ein Experiment war, aus deiner Sicht.",
      "tokens": [
        51214,
        22340,
        11,
        1581,
        6581,
        2784,
        3514,
        24895,
        22320,
        24027,
        11,
        2658,
        1482,
        35206,
        1343,
        37933,
        1516,
        11,
        3437,
        368,
        4564,
        36615,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26564186811447144,
      "compression_ratio": 1.6305084228515625,
      "no_speech_prob": 0.040810726583004
    },
    {
      "id": 19,
      "seek": 9450,
      "start": 116.5,
      "end": 120.5,
      "text": " Ja, es war aus meiner Sicht insofern ein Experiment, als dass ich gesagt habe,",
      "tokens": [
        51464,
        3530,
        11,
        785,
        1516,
        3437,
        20529,
        36615,
        294,
        539,
        28958,
        1343,
        37933,
        11,
        3907,
        2658,
        1893,
        12260,
        6015,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26564186811447144,
      "compression_ratio": 1.6305084228515625,
      "no_speech_prob": 0.040810726583004
    },
    {
      "id": 20,
      "seek": 12050,
      "start": 120.5,
      "end": 127.5,
      "text": " Mensch, ich probiere so viel aus mit KI, ich erzähle so viel über KI.",
      "tokens": [
        50364,
        27773,
        11,
        1893,
        1239,
        14412,
        370,
        5891,
        3437,
        2194,
        47261,
        11,
        1893,
        28337,
        306,
        370,
        5891,
        4502,
        47261,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15697422623634338,
      "compression_ratio": 1.5390625,
      "no_speech_prob": 0.05408705770969391
    },
    {
      "id": 21,
      "seek": 12050,
      "start": 127.5,
      "end": 133.5,
      "text": " Und ich wollte halt tatsächlich mal ein Projekt machen, was in der Öffentlichkeit ist,",
      "tokens": [
        50714,
        2719,
        1893,
        24509,
        12479,
        20796,
        2806,
        1343,
        34804,
        7069,
        11,
        390,
        294,
        1163,
        9158,
        22805,
        9238,
        1418,
        11,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15697422623634338,
      "compression_ratio": 1.5390625,
      "no_speech_prob": 0.05408705770969391
    },
    {
      "id": 22,
      "seek": 12050,
      "start": 133.5,
      "end": 138.5,
      "text": " wo man tatsächlich die Fähigkeiten von der KI auf verschiedenen Ebenen ausprobiert.",
      "tokens": [
        51014,
        6020,
        587,
        20796,
        978,
        479,
        6860,
        37545,
        2957,
        1163,
        47261,
        2501,
        41043,
        462,
        1799,
        268,
        3437,
        41990,
        4859,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15697422623634338,
      "compression_ratio": 1.5390625,
      "no_speech_prob": 0.05408705770969391
    },
    {
      "id": 23,
      "seek": 12050,
      "start": 138.5,
      "end": 141.5,
      "text": " Und da hatte ich mir gedacht, Mensch, wäre doch eigentlich ganz gut,",
      "tokens": [
        51264,
        2719,
        1120,
        13299,
        1893,
        3149,
        33296,
        11,
        27773,
        11,
        14558,
        9243,
        10926,
        6312,
        5228,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15697422623634338,
      "compression_ratio": 1.5390625,
      "no_speech_prob": 0.05408705770969391
    },
    {
      "id": 24,
      "seek": 12050,
      "start": 141.5,
      "end": 147.5,
      "text": " wenn wir ordentliche Transcriptions haben für Softwarearchitektur im Stream.",
      "tokens": [
        51414,
        4797,
        1987,
        4792,
        7698,
        68,
        6531,
        34173,
        3084,
        2959,
        27428,
        1178,
        642,
        2320,
        374,
        566,
        24904,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15697422623634338,
      "compression_ratio": 1.5390625,
      "no_speech_prob": 0.05408705770969391
    },
    {
      "id": 25,
      "seek": 14750,
      "start": 147.5,
      "end": 152.5,
      "text": " Es gibt ja schon so Web-Services, wo man YouTube-URL reingeben kann.",
      "tokens": [
        50364,
        2313,
        6089,
        2784,
        4981,
        370,
        9573,
        12,
        50,
        47480,
        11,
        6020,
        587,
        3088,
        12,
        7932,
        43,
        319,
        8735,
        1799,
        4028,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21892817318439484,
      "compression_ratio": 1.4331797361373901,
      "no_speech_prob": 0.017429130151867867
    },
    {
      "id": 26,
      "seek": 14750,
      "start": 152.5,
      "end": 158.5,
      "text": " Und dann baut der mit KI nicht nur die Transcription, sondern eben auch Zusammenfassungen",
      "tokens": [
        50614,
        2719,
        3594,
        272,
        1375,
        1163,
        2194,
        47261,
        1979,
        4343,
        978,
        6531,
        12432,
        11,
        11465,
        11375,
        2168,
        29442,
        69,
        640,
        5084,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21892817318439484,
      "compression_ratio": 1.4331797361373901,
      "no_speech_prob": 0.017429130151867867
    },
    {
      "id": 27,
      "seek": 14750,
      "start": 158.5,
      "end": 164.5,
      "text": " und eine Topic-Übersicht, so eine Mindmap und solche Geschichten.",
      "tokens": [
        50914,
        674,
        3018,
        8840,
        299,
        12,
        12272,
        1616,
        1405,
        11,
        370,
        3018,
        13719,
        24223,
        674,
        29813,
        14241,
        24681,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21892817318439484,
      "compression_ratio": 1.4331797361373901,
      "no_speech_prob": 0.017429130151867867
    },
    {
      "id": 28,
      "seek": 14750,
      "start": 164.5,
      "end": 167.5,
      "text": " Und das dachte ich mir, könnte man auch machen.",
      "tokens": [
        51214,
        2719,
        1482,
        39775,
        1893,
        3149,
        11,
        17646,
        587,
        2168,
        7069,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21892817318439484,
      "compression_ratio": 1.4331797361373901,
      "no_speech_prob": 0.017429130151867867
    },
    {
      "id": 29,
      "seek": 14750,
      "start": 167.5,
      "end": 170.5,
      "text": " Und habe es einfach mal ausprobiert.",
      "tokens": [
        51364,
        2719,
        6015,
        785,
        7281,
        2806,
        3437,
        41990,
        4859,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21892817318439484,
      "compression_ratio": 1.4331797361373901,
      "no_speech_prob": 0.017429130151867867
    },
    {
      "id": 30,
      "seek": 17050,
      "start": 171.5,
      "end": 176.5,
      "text": " Ja, und da hatte ich dann von da eigentlich den Ansatz, ja, Web-Coding.",
      "tokens": [
        50414,
        3530,
        11,
        674,
        1120,
        13299,
        1893,
        3594,
        2957,
        1120,
        10926,
        1441,
        14590,
        10300,
        11,
        2784,
        11,
        9573,
        12,
        34,
        8616,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25310981273651123,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.06835898011922836
    },
    {
      "id": 31,
      "seek": 17050,
      "start": 176.5,
      "end": 182.5,
      "text": " Ich glaube, damals, als ich es angefangen habe, da habe ich noch das als Prompt-Driven-Development bezeichnet.",
      "tokens": [
        50664,
        3141,
        13756,
        11,
        26067,
        11,
        3907,
        1893,
        785,
        43907,
        10784,
        6015,
        11,
        1120,
        6015,
        1893,
        3514,
        1482,
        3907,
        15833,
        662,
        12,
        35,
        470,
        553,
        12,
        11089,
        1388,
        518,
        312,
        32338,
        7129,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25310981273651123,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.06835898011922836
    },
    {
      "id": 32,
      "seek": 17050,
      "start": 182.5,
      "end": 186.5,
      "text": " Und es war, glaube ich, Claude Code genommen.",
      "tokens": [
        50964,
        2719,
        785,
        1516,
        11,
        13756,
        1893,
        11,
        12947,
        2303,
        15549,
        38715,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25310981273651123,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.06835898011922836
    },
    {
      "id": 33,
      "seek": 17050,
      "start": 186.5,
      "end": 191.5,
      "text": " Und Claude hat gesagt, du, ich möchte hier mal Transcriptions haben.",
      "tokens": [
        51164,
        2719,
        12947,
        2303,
        2385,
        12260,
        11,
        1581,
        11,
        1893,
        14570,
        3296,
        2806,
        6531,
        34173,
        3084,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25310981273651123,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.06835898011922836
    },
    {
      "id": 34,
      "seek": 17050,
      "start": 191.5,
      "end": 196.5,
      "text": " Hier ist eine Website, da findest du die ganzen MP3-Files.",
      "tokens": [
        51414,
        10886,
        1418,
        3018,
        45347,
        642,
        11,
        1120,
        915,
        377,
        1581,
        978,
        23966,
        14146,
        18,
        12,
        37,
        4680,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25310981273651123,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.06835898011922836
    },
    {
      "id": 35,
      "seek": 19650,
      "start": 196.5,
      "end": 198.5,
      "text": " Ja, und dann ging es los.",
      "tokens": [
        50364,
        3530,
        11,
        674,
        3594,
        21924,
        785,
        1750,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21282829344272614,
      "compression_ratio": 1.5037593841552734,
      "no_speech_prob": 0.024403108283877373
    },
    {
      "id": 36,
      "seek": 19650,
      "start": 198.5,
      "end": 201.5,
      "text": " Dann ging erst mal die Coding-Session los.",
      "tokens": [
        50464,
        7455,
        21924,
        11301,
        2806,
        978,
        383,
        8616,
        12,
        50,
        4311,
        1750,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21282829344272614,
      "compression_ratio": 1.5037593841552734,
      "no_speech_prob": 0.024403108283877373
    },
    {
      "id": 37,
      "seek": 19650,
      "start": 201.5,
      "end": 208.5,
      "text": " Und ja, soll ich gleich mal so ganz ausführlich erzählen, wie das abgelaufen ist?",
      "tokens": [
        50614,
        2719,
        2784,
        11,
        7114,
        1893,
        11699,
        2806,
        370,
        6312,
        3437,
        29189,
        1739,
        28337,
        6698,
        11,
        3355,
        1482,
        410,
        10345,
        20748,
        1418,
        30,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21282829344272614,
      "compression_ratio": 1.5037593841552734,
      "no_speech_prob": 0.024403108283877373
    },
    {
      "id": 38,
      "seek": 19650,
      "start": 208.5,
      "end": 209.5,
      "text": " Ja, sehr gerne.",
      "tokens": [
        50964,
        3530,
        11,
        5499,
        15689,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21282829344272614,
      "compression_ratio": 1.5037593841552734,
      "no_speech_prob": 0.024403108283877373
    },
    {
      "id": 39,
      "seek": 19650,
      "start": 209.5,
      "end": 211.5,
      "text": " Vielleicht noch ein, zwei Hinweise vorab.",
      "tokens": [
        51014,
        29838,
        3514,
        1343,
        11,
        12002,
        29571,
        13109,
        4245,
        455,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21282829344272614,
      "compression_ratio": 1.5037593841552734,
      "no_speech_prob": 0.024403108283877373
    },
    {
      "id": 40,
      "seek": 19650,
      "start": 211.5,
      "end": 217.5,
      "text": " Also, wie du schon sagtest, das sind Transkriptenzusammenfassung und Stichpunkt und noch LinkedIn-Post.",
      "tokens": [
        51114,
        2743,
        11,
        3355,
        1581,
        4981,
        15764,
        377,
        11,
        1482,
        3290,
        6531,
        74,
        470,
        662,
        11368,
        301,
        11248,
        69,
        40828,
        674,
        745,
        480,
        31744,
        674,
        3514,
        20657,
        12,
        47,
        555,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21282829344272614,
      "compression_ratio": 1.5037593841552734,
      "no_speech_prob": 0.024403108283877373
    },
    {
      "id": 41,
      "seek": 19650,
      "start": 217.5,
      "end": 222.5,
      "text": " Und diese Transkripte sind, glaube ich, für mich war das immer so ein blinder Fleck,",
      "tokens": [
        51414,
        2719,
        6705,
        6531,
        74,
        470,
        662,
        68,
        3290,
        11,
        13756,
        1893,
        11,
        2959,
        6031,
        1516,
        1482,
        5578,
        370,
        1343,
        888,
        5669,
        18612,
        547,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21282829344272614,
      "compression_ratio": 1.5037593841552734,
      "no_speech_prob": 0.024403108283877373
    },
    {
      "id": 42,
      "seek": 22250,
      "start": 222.5,
      "end": 228.5,
      "text": " weil das eben alleine wegen Barrierefreiheit, aber auch wegen Durchsuchen der Inhalte, glaube ich, eine ganz wichtige Sache ist.",
      "tokens": [
        50364,
        7689,
        1482,
        11375,
        37780,
        32855,
        4156,
        470,
        323,
        42072,
        8480,
        11,
        4340,
        2168,
        32855,
        28557,
        82,
        11285,
        1163,
        682,
        4947,
        975,
        11,
        13756,
        1893,
        11,
        3018,
        6312,
        46276,
        31452,
        1418,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2098592072725296,
      "compression_ratio": 1.6024844646453857,
      "no_speech_prob": 0.15988992154598236
    },
    {
      "id": 43,
      "seek": 22250,
      "start": 228.5,
      "end": 234.5,
      "text": " Und wir, das wäre noch der Benutzungshinweis, also wir reviewen die Transkripte nicht.",
      "tokens": [
        50664,
        2719,
        1987,
        11,
        1482,
        14558,
        3514,
        1163,
        3964,
        12950,
        1063,
        2716,
        259,
        35033,
        11,
        611,
        1987,
        3131,
        268,
        978,
        6531,
        74,
        470,
        662,
        68,
        1979,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2098592072725296,
      "compression_ratio": 1.6024844646453857,
      "no_speech_prob": 0.15988992154598236
    },
    {
      "id": 44,
      "seek": 22250,
      "start": 234.5,
      "end": 238.5,
      "text": " Deswegen freuen wir uns über Pull-Requests, wenn da irgendjemandem irgendwas auffällt.",
      "tokens": [
        50964,
        24864,
        41913,
        1987,
        2693,
        4502,
        15074,
        12,
        8524,
        358,
        4409,
        11,
        4797,
        1120,
        11093,
        73,
        18941,
        443,
        47090,
        257,
        1245,
        25333,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2098592072725296,
      "compression_ratio": 1.6024844646453857,
      "no_speech_prob": 0.15988992154598236
    },
    {
      "id": 45,
      "seek": 22250,
      "start": 238.5,
      "end": 241.5,
      "text": " Das kann man jetzt auf der Website auch direkt machen.",
      "tokens": [
        51164,
        2846,
        4028,
        587,
        4354,
        2501,
        1163,
        45347,
        642,
        2168,
        20315,
        7069,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2098592072725296,
      "compression_ratio": 1.6024844646453857,
      "no_speech_prob": 0.15988992154598236
    },
    {
      "id": 46,
      "seek": 22250,
      "start": 241.5,
      "end": 246.5,
      "text": " Umgekehrt ist es halt so, dass wir die Zusammenfassung und die Stichpunkte tatsächlich noch mal reviewen.",
      "tokens": [
        51314,
        3301,
        432,
        22833,
        83,
        1418,
        785,
        12479,
        370,
        11,
        2658,
        1987,
        978,
        29442,
        69,
        40828,
        674,
        978,
        745,
        480,
        27133,
        975,
        20796,
        3514,
        2806,
        3131,
        268,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2098592072725296,
      "compression_ratio": 1.6024844646453857,
      "no_speech_prob": 0.15988992154598236
    },
    {
      "id": 47,
      "seek": 22250,
      "start": 246.5,
      "end": 249.5,
      "text": " Also die reviewe ich und editiere sie dann halt.",
      "tokens": [
        51564,
        2743,
        978,
        3131,
        68,
        1893,
        674,
        8129,
        14412,
        2804,
        3594,
        12479,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2098592072725296,
      "compression_ratio": 1.6024844646453857,
      "no_speech_prob": 0.15988992154598236
    },
    {
      "id": 48,
      "seek": 24950,
      "start": 250.5,
      "end": 253.5,
      "text": " Und das ist sozusagen die Benutzungssicht.",
      "tokens": [
        50414,
        2719,
        1482,
        1418,
        33762,
        978,
        3964,
        12950,
        1063,
        3810,
        1405,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2440529316663742,
      "compression_ratio": 1.5379061698913574,
      "no_speech_prob": 0.1110081896185875
    },
    {
      "id": 49,
      "seek": 24950,
      "start": 253.5,
      "end": 258.5,
      "text": " Aber ich erzähle gerne, wie du es sozusagen gebaut hast oder hast es gebaut lassen.",
      "tokens": [
        50564,
        5992,
        1893,
        28337,
        306,
        15689,
        11,
        3355,
        1581,
        785,
        370,
        89,
        301,
        4698,
        49203,
        6581,
        4513,
        6581,
        785,
        49203,
        16168,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2440529316663742,
      "compression_ratio": 1.5379061698913574,
      "no_speech_prob": 0.1110081896185875
    },
    {
      "id": 50,
      "seek": 24950,
      "start": 258.5,
      "end": 262.5,
      "text": " Also meine Idee war halt, die Videos von YouTube herunterzuladen.",
      "tokens": [
        50814,
        2743,
        10946,
        32651,
        1516,
        12479,
        11,
        978,
        25903,
        2957,
        3088,
        720,
        21777,
        89,
        425,
        14771,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2440529316663742,
      "compression_ratio": 1.5379061698913574,
      "no_speech_prob": 0.1110081896185875
    },
    {
      "id": 51,
      "seek": 24950,
      "start": 262.5,
      "end": 264.5,
      "text": " Das geht ja nicht so einfach.",
      "tokens": [
        51014,
        2846,
        7095,
        2784,
        1979,
        370,
        7281,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2440529316663742,
      "compression_ratio": 1.5379061698913574,
      "no_speech_prob": 0.1110081896185875
    },
    {
      "id": 52,
      "seek": 24950,
      "start": 264.5,
      "end": 272.5,
      "text": " Aber wir hatten ja die MP3-Files und mir war klar, dass OpenAI die Whisper-API hat, die eben transkribieren kann.",
      "tokens": [
        51114,
        5992,
        1987,
        20441,
        2784,
        978,
        14146,
        18,
        12,
        37,
        4680,
        674,
        3149,
        1516,
        14743,
        11,
        2658,
        7238,
        48698,
        978,
        41132,
        610,
        12,
        4715,
        40,
        2385,
        11,
        978,
        11375,
        1145,
        74,
        2024,
        5695,
        4028,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2440529316663742,
      "compression_ratio": 1.5379061698913574,
      "no_speech_prob": 0.1110081896185875
    },
    {
      "id": 53,
      "seek": 24950,
      "start": 272.5,
      "end": 276.5,
      "text": " Und da habe ich einfach gesagt, Claude, kannst du mir nicht ein bisschen Code schreiben?",
      "tokens": [
        51514,
        2719,
        1120,
        6015,
        1893,
        7281,
        12260,
        11,
        12947,
        2303,
        11,
        20853,
        1581,
        3149,
        1979,
        1343,
        10763,
        15549,
        48546,
        30,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2440529316663742,
      "compression_ratio": 1.5379061698913574,
      "no_speech_prob": 0.1110081896185875
    },
    {
      "id": 54,
      "seek": 27650,
      "start": 276.5,
      "end": 284.5,
      "text": " Ich dachte, das wären so zehn Zeilen, dass ich die API nutze, das MP3-File reingebe und dann schon mal die Transkription rausbekomme.",
      "tokens": [
        50364,
        3141,
        39775,
        11,
        1482,
        43933,
        370,
        33975,
        4853,
        17471,
        11,
        2658,
        1893,
        978,
        9362,
        5393,
        1381,
        11,
        1482,
        14146,
        18,
        12,
        37,
        794,
        319,
        8735,
        650,
        674,
        3594,
        4981,
        2806,
        978,
        6531,
        74,
        470,
        1695,
        17202,
        25714,
        15117,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1755659431219101,
      "compression_ratio": 1.6263736486434937,
      "no_speech_prob": 0.020637867972254753
    },
    {
      "id": 55,
      "seek": 27650,
      "start": 284.5,
      "end": 290.5,
      "text": " Hat sich aber etwas schwieriger herausgestellt, weil Claude hat ausprobiert und das fand ich sehr gut.",
      "tokens": [
        50764,
        15867,
        3041,
        4340,
        9569,
        27546,
        4810,
        25089,
        26293,
        11,
        7689,
        12947,
        2303,
        2385,
        3437,
        41990,
        4859,
        674,
        1482,
        38138,
        1893,
        5499,
        5228,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1755659431219101,
      "compression_ratio": 1.6263736486434937,
      "no_speech_prob": 0.020637867972254753
    },
    {
      "id": 56,
      "seek": 27650,
      "start": 290.5,
      "end": 298.5,
      "text": " Claude hat eigenständig gearbeitet und hat da eben das MP3-File reingeworfen und hat Fehler bekommen.",
      "tokens": [
        51064,
        12947,
        2303,
        2385,
        10446,
        16913,
        328,
        7394,
        32401,
        674,
        2385,
        1120,
        11375,
        1482,
        14146,
        18,
        12,
        37,
        794,
        319,
        278,
        1023,
        284,
        6570,
        674,
        2385,
        48101,
        19256,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1755659431219101,
      "compression_ratio": 1.6263736486434937,
      "no_speech_prob": 0.020637867972254753
    },
    {
      "id": 57,
      "seek": 27650,
      "start": 298.5,
      "end": 300.5,
      "text": " Ja, ist leider zu groß zur Verarbeitung.",
      "tokens": [
        51464,
        3530,
        11,
        1418,
        29115,
        2164,
        17253,
        7147,
        4281,
        24024,
        1063,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1755659431219101,
      "compression_ratio": 1.6263736486434937,
      "no_speech_prob": 0.020637867972254753
    },
    {
      "id": 58,
      "seek": 27650,
      "start": 300.5,
      "end": 304.5,
      "text": " Und dann hat aber Claude gleich selbstständig weitergedacht.",
      "tokens": [
        51564,
        2719,
        3594,
        2385,
        4340,
        12947,
        2303,
        11699,
        13053,
        16913,
        328,
        8988,
        3004,
        3589,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1755659431219101,
      "compression_ratio": 1.6263736486434937,
      "no_speech_prob": 0.020637867972254753
    },
    {
      "id": 59,
      "seek": 30450,
      "start": 304.5,
      "end": 309.5,
      "text": " Und ich habe von diesen Transkriptions und Audio-Verarbeitung ehrlich gesagt überhaupt keine Ahnung.",
      "tokens": [
        50364,
        2719,
        1893,
        6015,
        2957,
        12862,
        6531,
        74,
        470,
        9799,
        674,
        25706,
        12,
        36929,
        24024,
        1063,
        40872,
        12260,
        20023,
        9252,
        2438,
        15539,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24868835508823395,
      "compression_ratio": 1.437751054763794,
      "no_speech_prob": 0.07796730846166611
    },
    {
      "id": 60,
      "seek": 30450,
      "start": 309.5,
      "end": 314.5,
      "text": " Aber die Art und Weise, wie Claude mich unterstützt hat, das war ein richtiges Enablement.",
      "tokens": [
        50614,
        5992,
        978,
        5735,
        674,
        41947,
        11,
        3355,
        12947,
        2303,
        6031,
        30007,
        2682,
        2385,
        11,
        1482,
        1516,
        1343,
        13129,
        279,
        2193,
        712,
        518,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24868835508823395,
      "compression_ratio": 1.437751054763794,
      "no_speech_prob": 0.07796730846166611
    },
    {
      "id": 61,
      "seek": 30450,
      "start": 314.5,
      "end": 324.5,
      "text": " Weil Claude hat dann gesagt, okay, das File ist zu groß, dann können wir es vielleicht über FFM-Pack modifizieren.",
      "tokens": [
        50864,
        18665,
        12947,
        2303,
        2385,
        3594,
        12260,
        11,
        1392,
        11,
        1482,
        26196,
        1418,
        2164,
        17253,
        11,
        3594,
        6310,
        1987,
        785,
        12547,
        4502,
        479,
        37,
        44,
        12,
        47,
        501,
        1072,
        351,
        590,
        5695,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24868835508823395,
      "compression_ratio": 1.437751054763794,
      "no_speech_prob": 0.07796730846166611
    },
    {
      "id": 62,
      "seek": 30450,
      "start": 324.5,
      "end": 328.5,
      "text": " Hat es analysiert, hat gesehen, ist es Stereo?",
      "tokens": [
        51364,
        15867,
        785,
        23014,
        4859,
        11,
        2385,
        21535,
        11,
        1418,
        785,
        745,
        323,
        78,
        30,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24868835508823395,
      "compression_ratio": 1.437751054763794,
      "no_speech_prob": 0.07796730846166611
    },
    {
      "id": 63,
      "seek": 32850,
      "start": 328.5,
      "end": 333.5,
      "text": " Da können wir Mono draus machen, dann hat es schon mal nur die halbe Größe.",
      "tokens": [
        50364,
        3933,
        6310,
        1987,
        4713,
        78,
        1617,
        301,
        7069,
        11,
        3594,
        2385,
        785,
        4981,
        2806,
        4343,
        978,
        7523,
        650,
        45778,
        11451,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25216782093048096,
      "compression_ratio": 1.4590909481048584,
      "no_speech_prob": 0.22507093846797943
    },
    {
      "id": 64,
      "seek": 32850,
      "start": 333.5,
      "end": 335.5,
      "text": " Dann war es immer noch zu groß.",
      "tokens": [
        50614,
        7455,
        1516,
        785,
        5578,
        3514,
        2164,
        17253,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25216782093048096,
      "compression_ratio": 1.4590909481048584,
      "no_speech_prob": 0.22507093846797943
    },
    {
      "id": 65,
      "seek": 32850,
      "start": 335.5,
      "end": 342.5,
      "text": " Dann hat er gesagt, okay, dann nehmen wir eben die Audio-Auflösung runter.",
      "tokens": [
        50714,
        7455,
        2385,
        1189,
        12260,
        11,
        1392,
        11,
        3594,
        19905,
        1987,
        11375,
        978,
        25706,
        12,
        32,
        2947,
        75,
        11310,
        1063,
        33295,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25216782093048096,
      "compression_ratio": 1.4590909481048584,
      "no_speech_prob": 0.22507093846797943
    },
    {
      "id": 66,
      "seek": 32850,
      "start": 342.5,
      "end": 344.5,
      "text": " Du guckst gerade schon so.",
      "tokens": [
        51064,
        5153,
        695,
        547,
        372,
        12117,
        4981,
        370,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25216782093048096,
      "compression_ratio": 1.4590909481048584,
      "no_speech_prob": 0.22507093846797943
    },
    {
      "id": 67,
      "seek": 32850,
      "start": 344.5,
      "end": 350.5,
      "text": " Ja, weil das Audio ist sehr sicher Mono.",
      "tokens": [
        51164,
        3530,
        11,
        7689,
        1482,
        25706,
        1418,
        5499,
        18623,
        4713,
        78,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25216782093048096,
      "compression_ratio": 1.4590909481048584,
      "no_speech_prob": 0.22507093846797943
    },
    {
      "id": 68,
      "seek": 32850,
      "start": 350.5,
      "end": 353.5,
      "text": " Also ich wäre jetzt extrem überrascht, wenn es das nicht wäre.",
      "tokens": [
        51464,
        2743,
        1893,
        14558,
        4354,
        4040,
        4502,
        3906,
        4701,
        11,
        4797,
        785,
        1482,
        1979,
        14558,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25216782093048096,
      "compression_ratio": 1.4590909481048584,
      "no_speech_prob": 0.22507093846797943
    },
    {
      "id": 69,
      "seek": 35350,
      "start": 354.5,
      "end": 359.5,
      "text": " Das typische Audio ist 50 oder 60 Megabyte für eine Stunde.",
      "tokens": [
        50414,
        2846,
        2125,
        7864,
        25706,
        1418,
        2625,
        4513,
        4060,
        9986,
        34529,
        2959,
        3018,
        42781,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2879537343978882,
      "compression_ratio": 1.4298245906829834,
      "no_speech_prob": 0.4790676236152649
    },
    {
      "id": 70,
      "seek": 35350,
      "start": 359.5,
      "end": 364.5,
      "text": " Eigentlich hatte ich das auch mal zusammen optimiert.",
      "tokens": [
        50664,
        40561,
        7698,
        13299,
        1893,
        1482,
        2168,
        2806,
        14311,
        5028,
        4859,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2879537343978882,
      "compression_ratio": 1.4298245906829834,
      "no_speech_prob": 0.4790676236152649
    },
    {
      "id": 71,
      "seek": 35350,
      "start": 364.5,
      "end": 366.5,
      "text": " Ich muss es jetzt nachgucken.",
      "tokens": [
        50914,
        3141,
        6425,
        785,
        4354,
        5168,
        70,
        49720,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2879537343978882,
      "compression_ratio": 1.4298245906829834,
      "no_speech_prob": 0.4790676236152649
    },
    {
      "id": 72,
      "seek": 35350,
      "start": 366.5,
      "end": 371.5,
      "text": " Wir sind bei podcaster.de, die ich übrigens sehr empfehlen kann.",
      "tokens": [
        51014,
        4347,
        3290,
        4643,
        2497,
        42640,
        13,
        1479,
        11,
        978,
        1893,
        38215,
        5499,
        4012,
        33865,
        6698,
        4028,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2879537343978882,
      "compression_ratio": 1.4298245906829834,
      "no_speech_prob": 0.4790676236152649
    },
    {
      "id": 73,
      "seek": 35350,
      "start": 371.5,
      "end": 373.5,
      "text": " Das ist ein sehr netter Laden.",
      "tokens": [
        51264,
        2846,
        1418,
        1343,
        5499,
        2533,
        391,
        45555,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2879537343978882,
      "compression_ratio": 1.4298245906829834,
      "no_speech_prob": 0.4790676236152649
    },
    {
      "id": 74,
      "seek": 35350,
      "start": 373.5,
      "end": 376.5,
      "text": " Und auch ein deutscher Laden.",
      "tokens": [
        51364,
        2719,
        2168,
        1343,
        23004,
        6759,
        45555,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2879537343978882,
      "compression_ratio": 1.4298245906829834,
      "no_speech_prob": 0.4790676236152649
    },
    {
      "id": 75,
      "seek": 35350,
      "start": 376.5,
      "end": 381.5,
      "text": " Da ist es so, dass man 250 Megabyte pro Monat bekommt.",
      "tokens": [
        51514,
        3933,
        1418,
        785,
        370,
        11,
        2658,
        587,
        11650,
        9986,
        34529,
        447,
        4713,
        267,
        33429,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2879537343978882,
      "compression_ratio": 1.4298245906829834,
      "no_speech_prob": 0.4790676236152649
    },
    {
      "id": 76,
      "seek": 38150,
      "start": 381.5,
      "end": 384.5,
      "text": " So dass ein Incentive da ist, möglichst das klein zu halten.",
      "tokens": [
        50364,
        407,
        2658,
        1343,
        682,
        2207,
        488,
        1120,
        1418,
        11,
        44850,
        1482,
        29231,
        2164,
        27184,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2810257375240326,
      "compression_ratio": 1.6188925504684448,
      "no_speech_prob": 0.09935598820447922
    },
    {
      "id": 77,
      "seek": 38150,
      "start": 384.5,
      "end": 388.5,
      "text": " Und ich glaube, wir sind bei 50 oder 60 Megabyte und deswegen auch Mono.",
      "tokens": [
        50514,
        2719,
        1893,
        13756,
        11,
        1987,
        3290,
        4643,
        2625,
        4513,
        4060,
        9986,
        34529,
        674,
        26482,
        2168,
        4713,
        78,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2810257375240326,
      "compression_ratio": 1.6188925504684448,
      "no_speech_prob": 0.09935598820447922
    },
    {
      "id": 78,
      "seek": 38150,
      "start": 388.5,
      "end": 392.5,
      "text": " Und deswegen hat auch nicht so wahnsinnig viel Auflösung eigentlich.",
      "tokens": [
        50714,
        2719,
        26482,
        2385,
        2168,
        1979,
        370,
        31979,
        46134,
        328,
        5891,
        9462,
        75,
        11310,
        1063,
        10926,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2810257375240326,
      "compression_ratio": 1.6188925504684448,
      "no_speech_prob": 0.09935598820447922
    },
    {
      "id": 79,
      "seek": 38150,
      "start": 392.5,
      "end": 394.5,
      "text": " Also das ist jetzt schon wieder sehr spannend.",
      "tokens": [
        50914,
        2743,
        1482,
        1418,
        4354,
        4981,
        6216,
        5499,
        49027,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2810257375240326,
      "compression_ratio": 1.6188925504684448,
      "no_speech_prob": 0.09935598820447922
    },
    {
      "id": 80,
      "seek": 38150,
      "start": 394.5,
      "end": 396.5,
      "text": " Das war mir alles gar nicht bewusst.",
      "tokens": [
        51014,
        2846,
        1516,
        3149,
        7874,
        3691,
        1979,
        46221,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2810257375240326,
      "compression_ratio": 1.6188925504684448,
      "no_speech_prob": 0.09935598820447922
    },
    {
      "id": 81,
      "seek": 38150,
      "start": 396.5,
      "end": 401.5,
      "text": " Ich weiß nicht, ob da Claude einfach gesagt hat, na ja, wahrscheinlich ist es Stereo.",
      "tokens": [
        51114,
        3141,
        13385,
        1979,
        11,
        1111,
        1120,
        12947,
        2303,
        7281,
        12260,
        2385,
        11,
        1667,
        2784,
        11,
        30957,
        1418,
        785,
        745,
        323,
        78,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2810257375240326,
      "compression_ratio": 1.6188925504684448,
      "no_speech_prob": 0.09935598820447922
    },
    {
      "id": 82,
      "seek": 38150,
      "start": 401.5,
      "end": 404.5,
      "text": " Und hat es einfach mal, keine Ahnung.",
      "tokens": [
        51364,
        2719,
        2385,
        785,
        7281,
        2806,
        11,
        9252,
        2438,
        15539,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2810257375240326,
      "compression_ratio": 1.6188925504684448,
      "no_speech_prob": 0.09935598820447922
    },
    {
      "id": 83,
      "seek": 38150,
      "start": 404.5,
      "end": 409.5,
      "text": " Aber das zeigt auch schon wieder, dass ich, der ich jetzt wenig Ahnung davon hatte,",
      "tokens": [
        51514,
        5992,
        1482,
        29250,
        2168,
        4981,
        6216,
        11,
        2658,
        1893,
        11,
        1163,
        1893,
        4354,
        20911,
        2438,
        15539,
        18574,
        13299,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2810257375240326,
      "compression_ratio": 1.6188925504684448,
      "no_speech_prob": 0.09935598820447922
    },
    {
      "id": 84,
      "seek": 40950,
      "start": 409.5,
      "end": 412.5,
      "text": " einfach an das Problem rangegangen bin.",
      "tokens": [
        50364,
        7281,
        364,
        1482,
        11676,
        3613,
        47152,
        5171,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2076699584722519,
      "compression_ratio": 1.5418181419372559,
      "no_speech_prob": 0.006588582415133715
    },
    {
      "id": 85,
      "seek": 40950,
      "start": 412.5,
      "end": 416.5,
      "text": " Mit ein bisschen mehr Ahnung, wie es eben da bei uns auf dem Server liegt.",
      "tokens": [
        50514,
        10821,
        1343,
        10763,
        5417,
        2438,
        15539,
        11,
        3355,
        785,
        11375,
        1120,
        4643,
        2693,
        2501,
        1371,
        25684,
        22421,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2076699584722519,
      "compression_ratio": 1.5418181419372559,
      "no_speech_prob": 0.006588582415133715
    },
    {
      "id": 86,
      "seek": 40950,
      "start": 416.5,
      "end": 419.5,
      "text": " Mit deiner Ahnung hätte man es eben wahrscheinlich ganz anders angehen können.",
      "tokens": [
        50714,
        10821,
        368,
        4564,
        2438,
        15539,
        20041,
        587,
        785,
        11375,
        30957,
        6312,
        17999,
        15495,
        2932,
        6310,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2076699584722519,
      "compression_ratio": 1.5418181419372559,
      "no_speech_prob": 0.006588582415133715
    },
    {
      "id": 87,
      "seek": 40950,
      "start": 419.5,
      "end": 422.5,
      "text": " Aber ich fand, ich war begeistert.",
      "tokens": [
        50864,
        5992,
        1893,
        38138,
        11,
        1893,
        1516,
        41832,
        1964,
        83,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2076699584722519,
      "compression_ratio": 1.5418181419372559,
      "no_speech_prob": 0.006588582415133715
    },
    {
      "id": 88,
      "seek": 40950,
      "start": 422.5,
      "end": 424.5,
      "text": " Er hat sich da durchgekämpft.",
      "tokens": [
        51014,
        3300,
        2385,
        3041,
        1120,
        7131,
        432,
        21036,
        2455,
        844,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2076699584722519,
      "compression_ratio": 1.5418181419372559,
      "no_speech_prob": 0.006588582415133715
    },
    {
      "id": 89,
      "seek": 40950,
      "start": 424.5,
      "end": 427.5,
      "text": " Es war dann zum Schluss immer noch zu groß.",
      "tokens": [
        51114,
        2313,
        1516,
        3594,
        5919,
        36573,
        5578,
        3514,
        2164,
        17253,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2076699584722519,
      "compression_ratio": 1.5418181419372559,
      "no_speech_prob": 0.006588582415133715
    },
    {
      "id": 90,
      "seek": 40950,
      "start": 427.5,
      "end": 429.5,
      "text": " Ich glaube, es war.",
      "tokens": [
        51264,
        3141,
        13756,
        11,
        785,
        1516,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2076699584722519,
      "compression_ratio": 1.5418181419372559,
      "no_speech_prob": 0.006588582415133715
    },
    {
      "id": 91,
      "seek": 40950,
      "start": 429.5,
      "end": 430.5,
      "text": " Ich muss überlegen.",
      "tokens": [
        51364,
        3141,
        6425,
        4502,
        22936,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2076699584722519,
      "compression_ratio": 1.5418181419372559,
      "no_speech_prob": 0.006588582415133715
    },
    {
      "id": 92,
      "seek": 40950,
      "start": 430.5,
      "end": 435.5,
      "text": " Ich glaube, er hat dann irgendwann gesagt, die Input Größe ist jetzt okay.",
      "tokens": [
        51414,
        3141,
        13756,
        11,
        1189,
        2385,
        3594,
        34313,
        12260,
        11,
        978,
        682,
        2582,
        45778,
        11451,
        1418,
        4354,
        1392,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2076699584722519,
      "compression_ratio": 1.5418181419372559,
      "no_speech_prob": 0.006588582415133715
    },
    {
      "id": 93,
      "seek": 43550,
      "start": 436.5,
      "end": 439.5,
      "text": " Aber es ist zu groß für die Output Größe.",
      "tokens": [
        50414,
        5992,
        785,
        1418,
        2164,
        17253,
        2959,
        978,
        5925,
        2582,
        45778,
        11451,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19026976823806763,
      "compression_ratio": 1.643122673034668,
      "no_speech_prob": 0.03159734606742859
    },
    {
      "id": 94,
      "seek": 43550,
      "start": 439.5,
      "end": 444.5,
      "text": " Und dann ist Claude hergegangen und hat gesagt, ja gut, dann zerlegen wir das Ganze.",
      "tokens": [
        50564,
        2719,
        3594,
        1418,
        12947,
        2303,
        720,
        432,
        47152,
        674,
        2385,
        12260,
        11,
        2784,
        5228,
        11,
        3594,
        44746,
        22936,
        1987,
        1482,
        35206,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19026976823806763,
      "compression_ratio": 1.643122673034668,
      "no_speech_prob": 0.03159734606742859
    },
    {
      "id": 95,
      "seek": 43550,
      "start": 444.5,
      "end": 449.5,
      "text": " Also ist nicht stupide mit der Audioauflösung runtergegangen, bis man nichts mehr versteht.",
      "tokens": [
        50814,
        2743,
        1418,
        1979,
        342,
        1010,
        482,
        2194,
        1163,
        25706,
        1459,
        3423,
        11310,
        1063,
        33295,
        432,
        47152,
        11,
        7393,
        587,
        13004,
        5417,
        22442,
        357,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19026976823806763,
      "compression_ratio": 1.643122673034668,
      "no_speech_prob": 0.03159734606742859
    },
    {
      "id": 96,
      "seek": 43550,
      "start": 449.5,
      "end": 452.5,
      "text": " Hat dann gesagt, jetzt zerlegen wir das.",
      "tokens": [
        51064,
        15867,
        3594,
        12260,
        11,
        4354,
        44746,
        22936,
        1987,
        1482,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19026976823806763,
      "compression_ratio": 1.643122673034668,
      "no_speech_prob": 0.03159734606742859
    },
    {
      "id": 97,
      "seek": 43550,
      "start": 452.5,
      "end": 455.5,
      "text": " Hat vorgeschlagen, dass wir nach Pausen suchen.",
      "tokens": [
        51214,
        15867,
        4245,
        2880,
        44496,
        11,
        2658,
        1987,
        5168,
        3426,
        301,
        268,
        44470,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19026976823806763,
      "compression_ratio": 1.643122673034668,
      "no_speech_prob": 0.03159734606742859
    },
    {
      "id": 98,
      "seek": 43550,
      "start": 455.5,
      "end": 458.5,
      "text": " Und dann habe ich mir schon gedacht, ja, jetzt wird irgendwie so ein Mist kommen,",
      "tokens": [
        51364,
        2719,
        3594,
        6015,
        1893,
        3149,
        4981,
        33296,
        11,
        2784,
        11,
        4354,
        4578,
        20759,
        370,
        1343,
        20166,
        11729,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19026976823806763,
      "compression_ratio": 1.643122673034668,
      "no_speech_prob": 0.03159734606742859
    },
    {
      "id": 99,
      "seek": 43550,
      "start": 458.5,
      "end": 460.5,
      "text": " dass er irgendwie die zwei ersten Pausen nimmt.",
      "tokens": [
        51514,
        2658,
        1189,
        20759,
        978,
        12002,
        17324,
        3426,
        301,
        268,
        38891,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19026976823806763,
      "compression_ratio": 1.643122673034668,
      "no_speech_prob": 0.03159734606742859
    },
    {
      "id": 100,
      "seek": 46050,
      "start": 460.5,
      "end": 465.5,
      "text": " Und die Stücke dann komplett unterschiedlich groß sind.",
      "tokens": [
        50364,
        2719,
        978,
        745,
        37383,
        3594,
        32261,
        30058,
        1739,
        17253,
        3290,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18389892578125,
      "compression_ratio": 1.5685484409332275,
      "no_speech_prob": 0.25354599952697754
    },
    {
      "id": 101,
      "seek": 46050,
      "start": 465.5,
      "end": 471.5,
      "text": " Nein, er hat gesagt, er sucht mal nach allen Pausen, um es dann in ungefähr gleich große,",
      "tokens": [
        50614,
        18878,
        11,
        1189,
        2385,
        12260,
        11,
        1189,
        1270,
        83,
        2806,
        5168,
        18440,
        3426,
        301,
        268,
        11,
        1105,
        785,
        3594,
        294,
        41285,
        11699,
        19691,
        11,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18389892578125,
      "compression_ratio": 1.5685484409332275,
      "no_speech_prob": 0.25354599952697754
    },
    {
      "id": 102,
      "seek": 46050,
      "start": 471.5,
      "end": 474.5,
      "text": " drei gleich große Stücke zu zerlegen.",
      "tokens": [
        50914,
        16809,
        11699,
        19691,
        745,
        37383,
        2164,
        44746,
        22936,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18389892578125,
      "compression_ratio": 1.5685484409332275,
      "no_speech_prob": 0.25354599952697754
    },
    {
      "id": 103,
      "seek": 46050,
      "start": 474.5,
      "end": 481.5,
      "text": " Hat das gemacht und kam somit schon sehr gut voran, dass er eben die Transcription bekommen hat.",
      "tokens": [
        51064,
        15867,
        1482,
        12293,
        674,
        9727,
        3307,
        270,
        4981,
        5499,
        5228,
        4245,
        282,
        11,
        2658,
        1189,
        11375,
        978,
        6531,
        12432,
        19256,
        2385,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18389892578125,
      "compression_ratio": 1.5685484409332275,
      "no_speech_prob": 0.25354599952697754
    },
    {
      "id": 104,
      "seek": 46050,
      "start": 481.5,
      "end": 489.5,
      "text": " Wobei man muss dazu sagen, bei der Transcription mit Whisper kann man ja so ein paar Wörter mitgeben.",
      "tokens": [
        51414,
        6622,
        21845,
        587,
        6425,
        13034,
        8360,
        11,
        4643,
        1163,
        6531,
        12432,
        2194,
        41132,
        610,
        4028,
        587,
        2784,
        370,
        1343,
        16509,
        343,
        2311,
        391,
        2194,
        16702,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18389892578125,
      "compression_ratio": 1.5685484409332275,
      "no_speech_prob": 0.25354599952697754
    },
    {
      "id": 105,
      "seek": 48950,
      "start": 490.5,
      "end": 495.5,
      "text": " Auf die er achten soll, die er eben besser erkennen soll, dass er die richtige Schreibweise hat.",
      "tokens": [
        50414,
        9462,
        978,
        1189,
        2800,
        1147,
        7114,
        11,
        978,
        1189,
        11375,
        18021,
        45720,
        7114,
        11,
        2658,
        1189,
        978,
        41569,
        2065,
        38606,
        13109,
        2385,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21017511188983917,
      "compression_ratio": 1.5120773315429688,
      "no_speech_prob": 0.006589282304048538
    },
    {
      "id": 106,
      "seek": 48950,
      "start": 495.5,
      "end": 499.5,
      "text": " Aber Whisper tut sich da anscheinend schwer.",
      "tokens": [
        50664,
        5992,
        41132,
        610,
        3672,
        3041,
        1120,
        1567,
        1876,
        259,
        521,
        23809,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21017511188983917,
      "compression_ratio": 1.5120773315429688,
      "no_speech_prob": 0.006589282304048538
    },
    {
      "id": 107,
      "seek": 48950,
      "start": 499.5,
      "end": 508.5,
      "text": " Also mir kommt so vor, dass Whisper nur versucht, die Wörter zu erkennen und nicht mit dem Kontext arbeitet.",
      "tokens": [
        50864,
        2743,
        3149,
        10047,
        370,
        4245,
        11,
        2658,
        41132,
        610,
        4343,
        36064,
        11,
        978,
        343,
        2311,
        391,
        2164,
        45720,
        674,
        1979,
        2194,
        1371,
        20629,
        3828,
        49907,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21017511188983917,
      "compression_ratio": 1.5120773315429688,
      "no_speech_prob": 0.006589282304048538
    },
    {
      "id": 108,
      "seek": 48950,
      "start": 508.5,
      "end": 513.5,
      "text": " Jemand von InnoCue hat sowas ähnliches, glaube ich, gemacht.",
      "tokens": [
        51314,
        508,
        18941,
        2957,
        682,
        1771,
        34,
        622,
        2385,
        19766,
        296,
        49696,
        279,
        11,
        13756,
        1893,
        11,
        12293,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21017511188983917,
      "compression_ratio": 1.5120773315429688,
      "no_speech_prob": 0.006589282304048538
    },
    {
      "id": 109,
      "seek": 51350,
      "start": 513.5,
      "end": 521.5,
      "text": " Und die haben, glaube ich, das GPT-4.0-Modell genommen, was aus meiner Sicht dann wahrscheinlich den Kontext tatsächlich verwendet",
      "tokens": [
        50364,
        2719,
        978,
        3084,
        11,
        13756,
        1893,
        11,
        1482,
        26039,
        51,
        12,
        19,
        13,
        15,
        12,
        44,
        378,
        898,
        38715,
        11,
        390,
        3437,
        20529,
        36615,
        3594,
        30957,
        1441,
        20629,
        3828,
        20796,
        1306,
        20128,
        302,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1920650601387024,
      "compression_ratio": 1.5305343866348267,
      "no_speech_prob": 0.17988725006580353
    },
    {
      "id": 110,
      "seek": 51350,
      "start": 521.5,
      "end": 525.5,
      "text": " und damit die Begriffe besser versteht.",
      "tokens": [
        50764,
        674,
        9479,
        978,
        879,
        861,
        31387,
        18021,
        22442,
        357,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1920650601387024,
      "compression_ratio": 1.5305343866348267,
      "no_speech_prob": 0.17988725006580353
    },
    {
      "id": 111,
      "seek": 51350,
      "start": 525.5,
      "end": 530.5,
      "text": " Aber ich hatte dann eben schon so gesehen, manche Begriffe hat er falsch aufgenommen oder so.",
      "tokens": [
        50964,
        5992,
        1893,
        13299,
        3594,
        11375,
        4981,
        370,
        21535,
        11,
        587,
        1876,
        879,
        861,
        31387,
        2385,
        1189,
        43340,
        2501,
        29270,
        4513,
        370,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1920650601387024,
      "compression_ratio": 1.5305343866348267,
      "no_speech_prob": 0.17988725006580353
    },
    {
      "id": 112,
      "seek": 51350,
      "start": 530.5,
      "end": 536.5,
      "text": " Ich habe dann immer die Überschrift mit reingegeben, dass er zumindest den Namen des Gastes richtig hat.",
      "tokens": [
        51214,
        3141,
        6015,
        3594,
        5578,
        978,
        10713,
        1616,
        339,
        35742,
        2194,
        319,
        278,
        2828,
        1799,
        11,
        2658,
        1189,
        38082,
        1441,
        38771,
        730,
        31988,
        279,
        13129,
        2385,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1920650601387024,
      "compression_ratio": 1.5305343866348267,
      "no_speech_prob": 0.17988725006580353
    },
    {
      "id": 113,
      "seek": 51350,
      "start": 536.5,
      "end": 538.5,
      "text": " Hat nicht immer funktioniert.",
      "tokens": [
        51514,
        15867,
        1979,
        5578,
        26160,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1920650601387024,
      "compression_ratio": 1.5305343866348267,
      "no_speech_prob": 0.17988725006580353
    },
    {
      "id": 114,
      "seek": 53850,
      "start": 538.5,
      "end": 547.5,
      "text": " Aber es war dann halt eben auch so ein Ding, wo ich gesagt habe, wenn wir das jetzt irgendwie zusammenfassen in Blogposts, in die Key Takeaways,",
      "tokens": [
        50364,
        5992,
        785,
        1516,
        3594,
        12479,
        11375,
        2168,
        370,
        1343,
        20558,
        11,
        6020,
        1893,
        12260,
        6015,
        11,
        4797,
        1987,
        1482,
        4354,
        20759,
        14311,
        69,
        8356,
        294,
        46693,
        23744,
        82,
        11,
        294,
        978,
        12759,
        3664,
        27545,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2391095906496048,
      "compression_ratio": 1.5267175436019897,
      "no_speech_prob": 0.2277221381664276
    },
    {
      "id": 115,
      "seek": 53850,
      "start": 547.5,
      "end": 550.5,
      "text": " dann fällt es ja wahrscheinlich raus.",
      "tokens": [
        50814,
        3594,
        42870,
        785,
        2784,
        30957,
        17202,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2391095906496048,
      "compression_ratio": 1.5267175436019897,
      "no_speech_prob": 0.2277221381664276
    },
    {
      "id": 116,
      "seek": 53850,
      "start": 550.5,
      "end": 554.5,
      "text": " Genau, da gibt es tatsächlich einige lustige Anekdoten.",
      "tokens": [
        50964,
        22340,
        11,
        1120,
        6089,
        785,
        20796,
        28338,
        24672,
        3969,
        316,
        23255,
        67,
        21990,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2391095906496048,
      "compression_ratio": 1.5267175436019897,
      "no_speech_prob": 0.2277221381664276
    },
    {
      "id": 117,
      "seek": 53850,
      "start": 554.5,
      "end": 559.5,
      "text": " Tatsächlich ist es so, dass teilweise die Namen von dem Gast nicht richtig geschrieben worden sind.",
      "tokens": [
        51164,
        314,
        19579,
        1418,
        785,
        370,
        11,
        2658,
        46748,
        978,
        38771,
        2957,
        1371,
        31988,
        1979,
        13129,
        47397,
        14054,
        3290,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2391095906496048,
      "compression_ratio": 1.5267175436019897,
      "no_speech_prob": 0.2277221381664276
    },
    {
      "id": 118,
      "seek": 53850,
      "start": 559.5,
      "end": 562.5,
      "text": " Das kann man auch alles in der GitHub-Historie nachgucken.",
      "tokens": [
        51414,
        2846,
        4028,
        587,
        2168,
        7874,
        294,
        1163,
        23331,
        12,
        39,
        468,
        17473,
        5168,
        70,
        49720,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2391095906496048,
      "compression_ratio": 1.5267175436019897,
      "no_speech_prob": 0.2277221381664276
    },
    {
      "id": 119,
      "seek": 56250,
      "start": 563.5,
      "end": 567.5,
      "text": " Das Ding steht ja Pull Request und das ist das ursprüngliche Transcript.",
      "tokens": [
        50414,
        2846,
        20558,
        16361,
        2784,
        15074,
        1300,
        20343,
        674,
        1482,
        1418,
        1482,
        4038,
        18193,
        36216,
        10185,
        6531,
        5944,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25597578287124634,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.3622382581233978
    },
    {
      "id": 120,
      "seek": 56250,
      "start": 567.5,
      "end": 573.5,
      "text": " Und wenn da irgendjemand was in dem Transcript manuell ändert, kann man das halt sehen.",
      "tokens": [
        50614,
        2719,
        4797,
        1120,
        11093,
        73,
        18941,
        390,
        294,
        1371,
        6531,
        5944,
        587,
        13789,
        24981,
        911,
        11,
        4028,
        587,
        1482,
        12479,
        11333,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25597578287124634,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.3622382581233978
    },
    {
      "id": 121,
      "seek": 56250,
      "start": 573.5,
      "end": 577.5,
      "text": " Also Gästenamen sind halt auffällig.",
      "tokens": [
        50914,
        2743,
        460,
        737,
        6266,
        22403,
        3290,
        12479,
        257,
        1245,
        10053,
        328,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25597578287124634,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.3622382581233978
    },
    {
      "id": 122,
      "seek": 56250,
      "start": 577.5,
      "end": 579.5,
      "text": " Dann ein besonderes Highlight war Chat-GPT.",
      "tokens": [
        51114,
        7455,
        1343,
        4097,
        8548,
        279,
        5229,
        2764,
        1516,
        27503,
        12,
        38,
        47,
        51,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25597578287124634,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.3622382581233978
    },
    {
      "id": 123,
      "seek": 56250,
      "start": 579.5,
      "end": 584.5,
      "text": " Also der Begriff Chat-GPT ist dem System nicht bekannt.",
      "tokens": [
        51214,
        2743,
        1163,
        879,
        32783,
        27503,
        12,
        38,
        47,
        51,
        1418,
        1371,
        8910,
        1979,
        39167,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25597578287124634,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.3622382581233978
    },
    {
      "id": 124,
      "seek": 56250,
      "start": 584.5,
      "end": 589.5,
      "text": " Was dann dazu führt, dass da irgendwelche Worte rausgekommen sind.",
      "tokens": [
        51464,
        3027,
        3594,
        13034,
        39671,
        11,
        2658,
        1120,
        26455,
        338,
        1876,
        343,
        12752,
        17202,
        432,
        13675,
        3290,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25597578287124634,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.3622382581233978
    },
    {
      "id": 125,
      "seek": 58950,
      "start": 589.5,
      "end": 593.5,
      "text": " Und auch unterschiedliche, sodass ein Search and Replace nicht mehr ausreicht.",
      "tokens": [
        50364,
        2719,
        2168,
        30058,
        10185,
        11,
        15047,
        640,
        1343,
        17180,
        293,
        1300,
        6742,
        1979,
        5417,
        3437,
        265,
        1405,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2320478856563568,
      "compression_ratio": 1.482758641242981,
      "no_speech_prob": 0.05177604779601097
    },
    {
      "id": 126,
      "seek": 58950,
      "start": 593.5,
      "end": 597.5,
      "text": " Und bei einer der letzten Folgen war es Wortly Maps.",
      "tokens": [
        50564,
        2719,
        4643,
        6850,
        1163,
        18226,
        15255,
        1766,
        1516,
        785,
        22748,
        356,
        28978,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2320478856563568,
      "compression_ratio": 1.482758641242981,
      "no_speech_prob": 0.05177604779601097
    },
    {
      "id": 127,
      "seek": 58950,
      "start": 597.5,
      "end": 600.5,
      "text": " Was tatsächlich das Thema der Folge war.",
      "tokens": [
        50764,
        3027,
        20796,
        1482,
        16306,
        1163,
        43597,
        1516,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2320478856563568,
      "compression_ratio": 1.482758641242981,
      "no_speech_prob": 0.05177604779601097
    },
    {
      "id": 128,
      "seek": 58950,
      "start": 600.5,
      "end": 612.5,
      "text": " Die bekannten Sachen sind daraus editiert, aber ich halte es für sehr wahrscheinlich, dass da noch welche drin sind.",
      "tokens": [
        50914,
        3229,
        312,
        5225,
        14970,
        26074,
        3290,
        274,
        46483,
        8129,
        4859,
        11,
        4340,
        1893,
        7523,
        975,
        785,
        2959,
        5499,
        30957,
        11,
        2658,
        1120,
        3514,
        24311,
        24534,
        3290,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2320478856563568,
      "compression_ratio": 1.482758641242981,
      "no_speech_prob": 0.05177604779601097
    },
    {
      "id": 129,
      "seek": 58950,
      "start": 612.5,
      "end": 617.5,
      "text": " Du hattest ja auch in dem Kontext die Transkripte nochmal Reviewen lassen durch GitHub Copilot.",
      "tokens": [
        51514,
        5153,
        276,
        1591,
        377,
        2784,
        2168,
        294,
        1371,
        20629,
        3828,
        978,
        6531,
        74,
        470,
        662,
        68,
        26509,
        19954,
        268,
        16168,
        7131,
        23331,
        11579,
        31516,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2320478856563568,
      "compression_ratio": 1.482758641242981,
      "no_speech_prob": 0.05177604779601097
    },
    {
      "id": 130,
      "seek": 61750,
      "start": 617.5,
      "end": 621.5,
      "text": " Was ich halt lustig fand, weil dann irgendwie nicht eine AI eine AI kontrolliert.",
      "tokens": [
        50364,
        3027,
        1893,
        12479,
        24672,
        328,
        38138,
        11,
        7689,
        3594,
        20759,
        1979,
        3018,
        7318,
        3018,
        7318,
        47107,
        4859,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2785087823867798,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.09385043382644653
    },
    {
      "id": 131,
      "seek": 61750,
      "start": 621.5,
      "end": 625.5,
      "text": " Und GitHub Copilot hat dann tatsächlich solche Sachen gemacht und hat dann gesagt,",
      "tokens": [
        50564,
        2719,
        23331,
        11579,
        31516,
        2385,
        3594,
        20796,
        29813,
        26074,
        12293,
        674,
        2385,
        3594,
        12260,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2785087823867798,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.09385043382644653
    },
    {
      "id": 132,
      "seek": 61750,
      "start": 625.5,
      "end": 631.5,
      "text": " also aus dem Kontext ergibt sich halt folgendes.",
      "tokens": [
        50764,
        611,
        3437,
        1371,
        20629,
        3828,
        26585,
        13651,
        3041,
        7523,
        83,
        3339,
        9395,
        279,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2785087823867798,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.09385043382644653
    },
    {
      "id": 133,
      "seek": 61750,
      "start": 631.5,
      "end": 635.5,
      "text": " Und deswegen glaube ich, dass hier folgendes eigentlich hingehört.",
      "tokens": [
        51064,
        2719,
        26482,
        13756,
        1893,
        11,
        2658,
        3296,
        3339,
        9395,
        279,
        10926,
        28822,
        71,
        11454,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2785087823867798,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.09385043382644653
    },
    {
      "id": 134,
      "seek": 61750,
      "start": 635.5,
      "end": 641.5,
      "text": " Genau, das fand ich total faszinierend, weil als es dann auf der Pull Request auf GitHub war,",
      "tokens": [
        51264,
        22340,
        11,
        1482,
        38138,
        1893,
        3217,
        283,
        19601,
        259,
        811,
        521,
        11,
        7689,
        3907,
        785,
        3594,
        2501,
        1163,
        15074,
        1300,
        20343,
        2501,
        23331,
        1516,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2785087823867798,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.09385043382644653
    },
    {
      "id": 135,
      "seek": 61750,
      "start": 641.5,
      "end": 646.5,
      "text": " konnte ich halt den GitHub Copilot dem das zum Review geben.",
      "tokens": [
        51564,
        24058,
        1893,
        12479,
        1441,
        23331,
        11579,
        31516,
        1371,
        1482,
        5919,
        19954,
        17191,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2785087823867798,
      "compression_ratio": 1.6428571939468384,
      "no_speech_prob": 0.09385043382644653
    },
    {
      "id": 136,
      "seek": 64650,
      "start": 646.5,
      "end": 650.5,
      "text": " Und der hat halt direkt gesagt, ja, ihr redet hier über Wortly Maps.",
      "tokens": [
        50364,
        2719,
        1163,
        2385,
        12479,
        20315,
        12260,
        11,
        2784,
        11,
        5553,
        2182,
        302,
        3296,
        4502,
        22748,
        356,
        28978,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20760580897331238,
      "compression_ratio": 1.5573770999908447,
      "no_speech_prob": 0.0061923242174088955
    },
    {
      "id": 137,
      "seek": 64650,
      "start": 650.5,
      "end": 653.5,
      "text": " Ihr habt aber den Simon Wortley falsch geschrieben.",
      "tokens": [
        50564,
        14773,
        23660,
        4340,
        1441,
        13193,
        22748,
        3420,
        43340,
        47397,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20760580897331238,
      "compression_ratio": 1.5573770999908447,
      "no_speech_prob": 0.0061923242174088955
    },
    {
      "id": 138,
      "seek": 64650,
      "start": 653.5,
      "end": 657.5,
      "text": " Und dieses Kontextverständnis, das hat da zum Review geholfen.",
      "tokens": [
        50714,
        2719,
        12113,
        20629,
        3828,
        36068,
        10661,
        11,
        1482,
        2385,
        1120,
        5919,
        19954,
        1519,
        5449,
        6570,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20760580897331238,
      "compression_ratio": 1.5573770999908447,
      "no_speech_prob": 0.0061923242174088955
    },
    {
      "id": 139,
      "seek": 64650,
      "start": 657.5,
      "end": 662.5,
      "text": " Und das ist auch das, warum ich denke, dass das Whisper Modell eben den Kontext nicht mitnimmt,",
      "tokens": [
        50914,
        2719,
        1482,
        1418,
        2168,
        1482,
        11,
        24331,
        1893,
        27245,
        11,
        2658,
        1482,
        41132,
        610,
        6583,
        898,
        11375,
        1441,
        20629,
        3828,
        1979,
        2194,
        77,
        15314,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20760580897331238,
      "compression_ratio": 1.5573770999908447,
      "no_speech_prob": 0.0061923242174088955
    },
    {
      "id": 140,
      "seek": 64650,
      "start": 662.5,
      "end": 668.5,
      "text": " sondern einfach nur ein Wortverständnis macht oder Worterkennung macht.",
      "tokens": [
        51164,
        11465,
        7281,
        4343,
        1343,
        22748,
        36068,
        10661,
        10857,
        4513,
        22748,
        10608,
        1857,
        1063,
        10857,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20760580897331238,
      "compression_ratio": 1.5573770999908447,
      "no_speech_prob": 0.0061923242174088955
    },
    {
      "id": 141,
      "seek": 64650,
      "start": 668.5,
      "end": 671.5,
      "text": " Und das war faszinierend.",
      "tokens": [
        51464,
        2719,
        1482,
        1516,
        283,
        19601,
        259,
        811,
        521,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20760580897331238,
      "compression_ratio": 1.5573770999908447,
      "no_speech_prob": 0.0061923242174088955
    },
    {
      "id": 142,
      "seek": 67150,
      "start": 671.5,
      "end": 675.5,
      "text": " So fast phonetisch, nicht so was in dem Dreh.",
      "tokens": [
        50364,
        407,
        2370,
        30754,
        302,
        5494,
        11,
        1979,
        370,
        390,
        294,
        1371,
        413,
        9017,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2541399598121643,
      "compression_ratio": 1.4606741666793823,
      "no_speech_prob": 0.14585384726524353
    },
    {
      "id": 143,
      "seek": 67150,
      "start": 675.5,
      "end": 681.5,
      "text": " Genau, aber das zeigt jetzt schon, dass wir schon Beieben von KI drin haben.",
      "tokens": [
        50564,
        22340,
        11,
        4340,
        1482,
        29250,
        4354,
        4981,
        11,
        2658,
        1987,
        4981,
        879,
        414,
        1799,
        2957,
        47261,
        24534,
        3084,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2541399598121643,
      "compression_ratio": 1.4606741666793823,
      "no_speech_prob": 0.14585384726524353
    },
    {
      "id": 144,
      "seek": 67150,
      "start": 681.5,
      "end": 688.5,
      "text": " Einmal zum Entwickeln des, wie man heutzutage sagen würde, herablassend Wipe Coding.",
      "tokens": [
        50864,
        6391,
        5579,
        5919,
        3951,
        22295,
        32099,
        730,
        11,
        3355,
        587,
        415,
        12950,
        325,
        609,
        8360,
        11942,
        11,
        720,
        455,
        14549,
        521,
        343,
        6527,
        383,
        8616,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2541399598121643,
      "compression_ratio": 1.4606741666793823,
      "no_speech_prob": 0.14585384726524353
    },
    {
      "id": 145,
      "seek": 67150,
      "start": 688.5,
      "end": 691.5,
      "text": " Also da habe ich mir tatsächlich wenig Mühe gegeben.",
      "tokens": [
        51214,
        2743,
        1120,
        6015,
        1893,
        3149,
        20796,
        20911,
        21295,
        675,
        32572,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2541399598121643,
      "compression_ratio": 1.4606741666793823,
      "no_speech_prob": 0.14585384726524353
    },
    {
      "id": 146,
      "seek": 67150,
      "start": 691.5,
      "end": 696.5,
      "text": " Und dann aber eben auch den GitHub Copilot für das Review.",
      "tokens": [
        51364,
        2719,
        3594,
        4340,
        11375,
        2168,
        1441,
        23331,
        11579,
        31516,
        2959,
        1482,
        19954,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2541399598121643,
      "compression_ratio": 1.4606741666793823,
      "no_speech_prob": 0.14585384726524353
    },
    {
      "id": 147,
      "seek": 67150,
      "start": 696.5,
      "end": 700.5,
      "text": " Wir haben ihn, glaube ich, nicht verwendet, um es zu modifizieren,",
      "tokens": [
        51614,
        4347,
        3084,
        14534,
        11,
        13756,
        1893,
        11,
        1979,
        1306,
        20128,
        302,
        11,
        1105,
        785,
        2164,
        1072,
        351,
        590,
        5695,
        11,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2541399598121643,
      "compression_ratio": 1.4606741666793823,
      "no_speech_prob": 0.14585384726524353
    },
    {
      "id": 148,
      "seek": 70050,
      "start": 700.5,
      "end": 702.5,
      "text": " sondern das haben wir dann manuell gemacht.",
      "tokens": [
        50364,
        11465,
        1482,
        3084,
        1987,
        3594,
        587,
        13789,
        12293,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2583571970462799,
      "compression_ratio": 1.6403162479400635,
      "no_speech_prob": 0.007009526714682579
    },
    {
      "id": 149,
      "seek": 70050,
      "start": 702.5,
      "end": 706.5,
      "text": " Also ich kann ja dem Copilot auch ein Issue zuweisen.",
      "tokens": [
        50464,
        2743,
        1893,
        4028,
        2784,
        1371,
        11579,
        31516,
        2168,
        1343,
        38195,
        622,
        2164,
        40196,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2583571970462799,
      "compression_ratio": 1.6403162479400635,
      "no_speech_prob": 0.007009526714682579
    },
    {
      "id": 150,
      "seek": 70050,
      "start": 706.5,
      "end": 709.5,
      "text": " Aber in dem Fall haben wir es noch nicht gemacht.",
      "tokens": [
        50664,
        5992,
        294,
        1371,
        7465,
        3084,
        1987,
        785,
        3514,
        1979,
        12293,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2583571970462799,
      "compression_ratio": 1.6403162479400635,
      "no_speech_prob": 0.007009526714682579
    },
    {
      "id": 151,
      "seek": 70050,
      "start": 709.5,
      "end": 713.5,
      "text": " Genau, also GitHub Copilot hat ja irgendwelche Reviews.",
      "tokens": [
        50814,
        22340,
        11,
        611,
        23331,
        11579,
        31516,
        2385,
        2784,
        3418,
        432,
        273,
        45512,
        1876,
        19954,
        82,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2583571970462799,
      "compression_ratio": 1.6403162479400635,
      "no_speech_prob": 0.007009526714682579
    },
    {
      "id": 152,
      "seek": 70050,
      "start": 713.5,
      "end": 716.5,
      "text": " Und ich erinnere mich, dass ich dann auf Basis dessen das halt editiert habe",
      "tokens": [
        51014,
        2719,
        1893,
        1189,
        7729,
        323,
        6031,
        11,
        2658,
        1893,
        3594,
        2501,
        5859,
        271,
        6874,
        268,
        1482,
        12479,
        8129,
        4859,
        6015,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2583571970462799,
      "compression_ratio": 1.6403162479400635,
      "no_speech_prob": 0.007009526714682579
    },
    {
      "id": 153,
      "seek": 70050,
      "start": 716.5,
      "end": 719.5,
      "text": " und das dann manchmal halt auch Unsinn produziert hat.",
      "tokens": [
        51164,
        674,
        1482,
        3594,
        32092,
        12479,
        2168,
        25017,
        7729,
        28093,
        4859,
        2385,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2583571970462799,
      "compression_ratio": 1.6403162479400635,
      "no_speech_prob": 0.007009526714682579
    },
    {
      "id": 154,
      "seek": 70050,
      "start": 719.5,
      "end": 727.5,
      "text": " Übrigens, der, so war ich nicht, der oder die, hat gerade im Chat geschrieben,",
      "tokens": [
        51314,
        10713,
        21674,
        694,
        11,
        1163,
        11,
        370,
        1516,
        1893,
        1979,
        11,
        1163,
        4513,
        978,
        11,
        2385,
        12117,
        566,
        27503,
        47397,
        11,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2583571970462799,
      "compression_ratio": 1.6403162479400635,
      "no_speech_prob": 0.007009526714682579
    },
    {
      "id": 155,
      "seek": 72750,
      "start": 727.5,
      "end": 731.5,
      "text": " er, sie, wie bestimmt man das Geschlecht des KI-Modells?",
      "tokens": [
        50364,
        1189,
        11,
        2804,
        11,
        3355,
        46871,
        587,
        1482,
        14241,
        306,
        4701,
        730,
        47261,
        12,
        44,
        378,
        13677,
        30,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.237660214304924,
      "compression_ratio": 1.5366795063018799,
      "no_speech_prob": 0.33356818556785583
    },
    {
      "id": 156,
      "seek": 72750,
      "start": 731.5,
      "end": 735.5,
      "text": " Und da sind wir wieder bei der Anthropomorphisierung von KI.",
      "tokens": [
        50564,
        2719,
        1120,
        3290,
        1987,
        6216,
        4643,
        1163,
        5130,
        71,
        1513,
        32702,
        32531,
        2957,
        47261,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.237660214304924,
      "compression_ratio": 1.5366795063018799,
      "no_speech_prob": 0.33356818556785583
    },
    {
      "id": 157,
      "seek": 72750,
      "start": 735.5,
      "end": 737.5,
      "text": " Also dass es ja eigentlich eine Maschine ist.",
      "tokens": [
        50764,
        2743,
        2658,
        785,
        2784,
        10926,
        3018,
        5224,
        36675,
        1418,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.237660214304924,
      "compression_ratio": 1.5366795063018799,
      "no_speech_prob": 0.33356818556785583
    },
    {
      "id": 158,
      "seek": 72750,
      "start": 737.5,
      "end": 742.5,
      "text": " Und wir eben dazu neigen, von dieser Maschine sozusagen wie von einem Menschen.",
      "tokens": [
        50864,
        2719,
        1987,
        11375,
        13034,
        408,
        3213,
        11,
        2957,
        9053,
        5224,
        36675,
        370,
        16236,
        64,
        1766,
        3355,
        2957,
        6827,
        8397,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.237660214304924,
      "compression_ratio": 1.5366795063018799,
      "no_speech_prob": 0.33356818556785583
    },
    {
      "id": 159,
      "seek": 72750,
      "start": 742.5,
      "end": 743.5,
      "text": " Und das ist tatsächlich ein Problem.",
      "tokens": [
        51114,
        2719,
        1482,
        1418,
        20796,
        1343,
        11676,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.237660214304924,
      "compression_ratio": 1.5366795063018799,
      "no_speech_prob": 0.33356818556785583
    },
    {
      "id": 160,
      "seek": 72750,
      "start": 743.5,
      "end": 748.5,
      "text": " Mir war das auch, ehrlich gesagt, so als Gedanke durch den Kopf gegangen,",
      "tokens": [
        51164,
        9421,
        1516,
        1482,
        2168,
        11,
        40872,
        12260,
        11,
        370,
        3907,
        28166,
        282,
        330,
        7131,
        1441,
        28231,
        44415,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.237660214304924,
      "compression_ratio": 1.5366795063018799,
      "no_speech_prob": 0.33356818556785583
    },
    {
      "id": 161,
      "seek": 72750,
      "start": 748.5,
      "end": 753.5,
      "text": " bevor Sava das anmerkte.",
      "tokens": [
        51414,
        37591,
        318,
        4061,
        1482,
        364,
        936,
        18844,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.237660214304924,
      "compression_ratio": 1.5366795063018799,
      "no_speech_prob": 0.33356818556785583
    },
    {
      "id": 162,
      "seek": 72750,
      "start": 753.5,
      "end": 755.5,
      "text": " Ja, keine Ahnung.",
      "tokens": [
        51664,
        3530,
        11,
        9252,
        2438,
        15539,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.237660214304924,
      "compression_ratio": 1.5366795063018799,
      "no_speech_prob": 0.33356818556785583
    },
    {
      "id": 163,
      "seek": 75550,
      "start": 755.5,
      "end": 757.5,
      "text": " Die Antwort ist, irgendwie muss man da eigentlich aufpassen.",
      "tokens": [
        50364,
        3229,
        34693,
        1418,
        11,
        20759,
        6425,
        587,
        1120,
        10926,
        2501,
        44270,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24740521609783173,
      "compression_ratio": 1.6476190090179443,
      "no_speech_prob": 0.048032406717538834
    },
    {
      "id": 164,
      "seek": 75550,
      "start": 757.5,
      "end": 761.5,
      "text": " Ich merke, dass ich das halt nicht gut auf die Reihe bekomme.",
      "tokens": [
        50464,
        3141,
        3551,
        330,
        11,
        2658,
        1893,
        1482,
        12479,
        1979,
        5228,
        2501,
        978,
        34549,
        675,
        9393,
        15117,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24740521609783173,
      "compression_ratio": 1.6476190090179443,
      "no_speech_prob": 0.048032406717538834
    },
    {
      "id": 165,
      "seek": 75550,
      "start": 761.5,
      "end": 765.5,
      "text": " Und im Übrigen ist es halt so, dass wir in Deutsch ja viele, viele Dinge haben,",
      "tokens": [
        50664,
        2719,
        566,
        10713,
        1443,
        3213,
        1418,
        785,
        12479,
        370,
        11,
        2658,
        1987,
        294,
        12699,
        2784,
        9693,
        11,
        9693,
        25102,
        3084,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24740521609783173,
      "compression_ratio": 1.6476190090179443,
      "no_speech_prob": 0.048032406717538834
    },
    {
      "id": 166,
      "seek": 75550,
      "start": 765.5,
      "end": 766.5,
      "text": " die wir halt eindeutsch nicht.",
      "tokens": [
        50864,
        978,
        1987,
        12479,
        308,
        8274,
        325,
        6145,
        1979,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24740521609783173,
      "compression_ratio": 1.6476190090179443,
      "no_speech_prob": 0.048032406717538834
    },
    {
      "id": 167,
      "seek": 75550,
      "start": 766.5,
      "end": 769.5,
      "text": " Es ist zum Beispiel offensichtlich ja der Computer.",
      "tokens": [
        50914,
        2313,
        1418,
        5919,
        13772,
        766,
        694,
        41971,
        2784,
        1163,
        22289,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24740521609783173,
      "compression_ratio": 1.6476190090179443,
      "no_speech_prob": 0.048032406717538834
    },
    {
      "id": 168,
      "seek": 75550,
      "start": 769.5,
      "end": 773.5,
      "text": " Und da ist dann ja auch die Frage, wie man dem ein Geschlecht zuweist.",
      "tokens": [
        51064,
        2719,
        1120,
        1418,
        3594,
        2784,
        2168,
        978,
        13685,
        11,
        3355,
        587,
        1371,
        1343,
        14241,
        306,
        4701,
        2164,
        826,
        468,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24740521609783173,
      "compression_ratio": 1.6476190090179443,
      "no_speech_prob": 0.048032406717538834
    },
    {
      "id": 169,
      "seek": 75550,
      "start": 773.5,
      "end": 776.5,
      "text": " Und ich glaube, das ist bei den AI-Systemen möglicherweise ähnlich.",
      "tokens": [
        51264,
        2719,
        1893,
        13756,
        11,
        1482,
        1418,
        4643,
        1441,
        7318,
        12,
        50,
        9321,
        268,
        16294,
        44071,
        49696,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24740521609783173,
      "compression_ratio": 1.6476190090179443,
      "no_speech_prob": 0.048032406717538834
    },
    {
      "id": 170,
      "seek": 75550,
      "start": 776.5,
      "end": 779.5,
      "text": " Aber nicht, whatever.",
      "tokens": [
        51414,
        5992,
        1979,
        11,
        2035,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24740521609783173,
      "compression_ratio": 1.6476190090179443,
      "no_speech_prob": 0.048032406717538834
    },
    {
      "id": 171,
      "seek": 75550,
      "start": 779.5,
      "end": 780.5,
      "text": " Ja, also ich würde da...",
      "tokens": [
        51564,
        3530,
        11,
        611,
        1893,
        11942,
        1120,
        485,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24740521609783173,
      "compression_ratio": 1.6476190090179443,
      "no_speech_prob": 0.048032406717538834
    },
    {
      "id": 172,
      "seek": 75550,
      "start": 780.5,
      "end": 782.5,
      "text": " Nicht guter Hinweis.",
      "tokens": [
        51614,
        22629,
        5228,
        260,
        29571,
        35033,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24740521609783173,
      "compression_ratio": 1.6476190090179443,
      "no_speech_prob": 0.048032406717538834
    },
    {
      "id": 173,
      "seek": 75550,
      "start": 782.5,
      "end": 784.5,
      "text": " Ist ein guter Hinweis.",
      "tokens": [
        51714,
        12810,
        1343,
        5228,
        260,
        29571,
        35033,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24740521609783173,
      "compression_ratio": 1.6476190090179443,
      "no_speech_prob": 0.048032406717538834
    },
    {
      "id": 174,
      "seek": 78450,
      "start": 784.5,
      "end": 788.5,
      "text": " Allerdings, ich gebe da auch für meine Kommunikation selbst nicht mehr viel drauf,",
      "tokens": [
        50364,
        1057,
        28519,
        11,
        1893,
        29073,
        1120,
        2168,
        2959,
        10946,
        28832,
        1035,
        399,
        13053,
        1979,
        5417,
        5891,
        22763,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20830297470092773,
      "compression_ratio": 1.4893616437911987,
      "no_speech_prob": 0.0063856965862214565
    },
    {
      "id": 175,
      "seek": 78450,
      "start": 788.5,
      "end": 794.5,
      "text": " weil Haustiere, ja, wenn man es so will, vermenschlicht man auch.",
      "tokens": [
        50564,
        7689,
        4064,
        381,
        14412,
        11,
        2784,
        11,
        4797,
        587,
        785,
        370,
        486,
        11,
        26319,
        26590,
        20238,
        587,
        2168,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20830297470092773,
      "compression_ratio": 1.4893616437911987,
      "no_speech_prob": 0.0063856965862214565
    },
    {
      "id": 176,
      "seek": 78450,
      "start": 794.5,
      "end": 800.5,
      "text": " Beziehungsweise, ja, ich könnte jetzt immer von dem LLM sprechen, neutral.",
      "tokens": [
        50864,
        879,
        28213,
        5846,
        13109,
        11,
        2784,
        11,
        1893,
        17646,
        4354,
        5578,
        2957,
        1371,
        441,
        43,
        44,
        27853,
        11,
        10598,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20830297470092773,
      "compression_ratio": 1.4893616437911987,
      "no_speech_prob": 0.0063856965862214565
    },
    {
      "id": 177,
      "seek": 78450,
      "start": 800.5,
      "end": 805.5,
      "text": " Aber wenn ich dann eben auf Claude und auf Copilot gehe und so,",
      "tokens": [
        51164,
        5992,
        4797,
        1893,
        3594,
        11375,
        2501,
        12947,
        2303,
        674,
        2501,
        11579,
        31516,
        34252,
        674,
        370,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20830297470092773,
      "compression_ratio": 1.4893616437911987,
      "no_speech_prob": 0.0063856965862214565
    },
    {
      "id": 178,
      "seek": 78450,
      "start": 805.5,
      "end": 810.5,
      "text": " dann sind es halt wieder irgendwie das Copilot.",
      "tokens": [
        51414,
        3594,
        3290,
        785,
        12479,
        6216,
        20759,
        1482,
        11579,
        31516,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20830297470092773,
      "compression_ratio": 1.4893616437911987,
      "no_speech_prob": 0.0063856965862214565
    },
    {
      "id": 179,
      "seek": 78450,
      "start": 810.5,
      "end": 812.5,
      "text": " Weiß nicht.",
      "tokens": [
        51664,
        492,
        6230,
        1979,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20830297470092773,
      "compression_ratio": 1.4893616437911987,
      "no_speech_prob": 0.0063856965862214565
    },
    {
      "id": 180,
      "seek": 81250,
      "start": 812.5,
      "end": 817.5,
      "text": " Also seht mir das nach.",
      "tokens": [
        50364,
        2743,
        369,
        357,
        3149,
        1482,
        5168,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25339755415916443,
      "compression_ratio": 1.4879226684570312,
      "no_speech_prob": 0.010163754224777222
    },
    {
      "id": 181,
      "seek": 81250,
      "start": 817.5,
      "end": 821.5,
      "text": " Ich habe es, ehrlich gesagt, einfach aufgegeben.",
      "tokens": [
        50614,
        3141,
        6015,
        785,
        11,
        40872,
        12260,
        11,
        7281,
        35031,
        16702,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25339755415916443,
      "compression_ratio": 1.4879226684570312,
      "no_speech_prob": 0.010163754224777222
    },
    {
      "id": 182,
      "seek": 81250,
      "start": 821.5,
      "end": 827.5,
      "text": " Ja, ich glaube, also mir fällt das halt auch auf im Dialog mit so etwas wie JGPT,",
      "tokens": [
        50814,
        3530,
        11,
        1893,
        13756,
        11,
        611,
        3149,
        42870,
        1482,
        12479,
        2168,
        2501,
        566,
        29658,
        664,
        2194,
        370,
        9569,
        3355,
        508,
        38,
        47,
        51,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25339755415916443,
      "compression_ratio": 1.4879226684570312,
      "no_speech_prob": 0.010163754224777222
    },
    {
      "id": 183,
      "seek": 81250,
      "start": 827.5,
      "end": 831.5,
      "text": " dass das eigentlich intendiert zu sein scheint.",
      "tokens": [
        51114,
        2658,
        1482,
        10926,
        19759,
        4859,
        2164,
        6195,
        47906,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25339755415916443,
      "compression_ratio": 1.4879226684570312,
      "no_speech_prob": 0.010163754224777222
    },
    {
      "id": 184,
      "seek": 81250,
      "start": 831.5,
      "end": 835.5,
      "text": " Also das benimmt sich halt so, als sei es eben ein Mensch.",
      "tokens": [
        51314,
        2743,
        1482,
        3271,
        15314,
        3041,
        12479,
        370,
        11,
        3907,
        10842,
        785,
        11375,
        1343,
        27773,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25339755415916443,
      "compression_ratio": 1.4879226684570312,
      "no_speech_prob": 0.010163754224777222
    },
    {
      "id": 185,
      "seek": 81250,
      "start": 835.5,
      "end": 839.5,
      "text": " Und eigentlich müsste man das anders machen,",
      "tokens": [
        51514,
        2719,
        10926,
        42962,
        587,
        1482,
        17999,
        7069,
        11,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25339755415916443,
      "compression_ratio": 1.4879226684570312,
      "no_speech_prob": 0.010163754224777222
    },
    {
      "id": 186,
      "seek": 83950,
      "start": 839.5,
      "end": 844.5,
      "text": " wäre wahrscheinlich irgendwie das Vertrauen in das System geringer",
      "tokens": [
        50364,
        14558,
        30957,
        20759,
        1482,
        21044,
        46640,
        294,
        1482,
        8910,
        290,
        1794,
        260,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2171335220336914,
      "compression_ratio": 1.5133928060531616,
      "no_speech_prob": 0.02296462096273899
    },
    {
      "id": 187,
      "seek": 83950,
      "start": 844.5,
      "end": 847.5,
      "text": " und das ist natürlich nicht das, was die wollen.",
      "tokens": [
        50614,
        674,
        1482,
        1418,
        8762,
        1979,
        1482,
        11,
        390,
        978,
        11253,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2171335220336914,
      "compression_ratio": 1.5133928060531616,
      "no_speech_prob": 0.02296462096273899
    },
    {
      "id": 188,
      "seek": 83950,
      "start": 847.5,
      "end": 849.5,
      "text": " Von daher ist es eben tatsächlich ein Problem.",
      "tokens": [
        50764,
        20700,
        36971,
        1418,
        785,
        11375,
        20796,
        1343,
        11676,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2171335220336914,
      "compression_ratio": 1.5133928060531616,
      "no_speech_prob": 0.02296462096273899
    },
    {
      "id": 189,
      "seek": 83950,
      "start": 849.5,
      "end": 855.5,
      "text": " Also ich denke, zum einen alles, was sich der menschlichen Sprache bedient,",
      "tokens": [
        50864,
        2743,
        1893,
        27245,
        11,
        5919,
        4891,
        7874,
        11,
        390,
        3041,
        1163,
        10923,
        339,
        10193,
        7702,
        6000,
        2901,
        1196,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2171335220336914,
      "compression_ratio": 1.5133928060531616,
      "no_speech_prob": 0.02296462096273899
    },
    {
      "id": 190,
      "seek": 83950,
      "start": 855.5,
      "end": 858.5,
      "text": " kommt menschlich irgendwo rüber.",
      "tokens": [
        51164,
        10047,
        10923,
        339,
        1739,
        40865,
        367,
        12670,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2171335220336914,
      "compression_ratio": 1.5133928060531616,
      "no_speech_prob": 0.02296462096273899
    },
    {
      "id": 191,
      "seek": 83950,
      "start": 858.5,
      "end": 862.5,
      "text": " Aber du hast schon recht, man hat bei OpenAI schon das Gefühl,",
      "tokens": [
        51314,
        5992,
        1581,
        6581,
        4981,
        24261,
        11,
        587,
        2385,
        4643,
        7238,
        48698,
        4981,
        1482,
        29715,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2171335220336914,
      "compression_ratio": 1.5133928060531616,
      "no_speech_prob": 0.02296462096273899
    },
    {
      "id": 192,
      "seek": 86250,
      "start": 862.5,
      "end": 868.5,
      "text": " dass man es darauf anlegt, dass da die Menschlichkeit rüberkommt",
      "tokens": [
        50364,
        2658,
        587,
        785,
        18654,
        364,
        22745,
        11,
        2658,
        1120,
        978,
        27773,
        41096,
        367,
        12670,
        74,
        22230,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20842160284519196,
      "compression_ratio": 1.55078125,
      "no_speech_prob": 0.0222790390253067
    },
    {
      "id": 193,
      "seek": 86250,
      "start": 868.5,
      "end": 872.5,
      "text": " in der Art des Tonfalls.",
      "tokens": [
        50664,
        294,
        1163,
        5735,
        730,
        11385,
        18542,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20842160284519196,
      "compression_ratio": 1.55078125,
      "no_speech_prob": 0.0222790390253067
    },
    {
      "id": 194,
      "seek": 86250,
      "start": 872.5,
      "end": 876.5,
      "text": " Aber auch, ja, ich meine, mich nervt das total,",
      "tokens": [
        50864,
        5992,
        2168,
        11,
        2784,
        11,
        1893,
        10946,
        11,
        6031,
        5724,
        83,
        1482,
        3217,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20842160284519196,
      "compression_ratio": 1.55078125,
      "no_speech_prob": 0.0222790390253067
    },
    {
      "id": 195,
      "seek": 86250,
      "start": 876.5,
      "end": 879.5,
      "text": " wenn Claude mir auf die Schulter klopft und sagt,",
      "tokens": [
        51064,
        4797,
        12947,
        2303,
        3149,
        2501,
        978,
        21223,
        391,
        9671,
        404,
        844,
        674,
        15764,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20842160284519196,
      "compression_ratio": 1.55078125,
      "no_speech_prob": 0.0222790390253067
    },
    {
      "id": 196,
      "seek": 86250,
      "start": 879.5,
      "end": 882.5,
      "text": " hey, das hast du aber gut gemacht, da wäre ich selbst nicht drauf gekommen.",
      "tokens": [
        51214,
        4177,
        11,
        1482,
        6581,
        1581,
        4340,
        5228,
        12293,
        11,
        1120,
        14558,
        1893,
        13053,
        1979,
        22763,
        32732,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20842160284519196,
      "compression_ratio": 1.55078125,
      "no_speech_prob": 0.0222790390253067
    },
    {
      "id": 197,
      "seek": 86250,
      "start": 882.5,
      "end": 885.5,
      "text": " Wow, das bringt uns jetzt hier richtig voran.",
      "tokens": [
        51364,
        3153,
        11,
        1482,
        36008,
        2693,
        4354,
        3296,
        13129,
        4245,
        282,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20842160284519196,
      "compression_ratio": 1.55078125,
      "no_speech_prob": 0.0222790390253067
    },
    {
      "id": 198,
      "seek": 86250,
      "start": 885.5,
      "end": 891.5,
      "text": " Wo ich echt sage, weiß auch nicht, mag ich nicht, versuche ich immer abzutrainieren.",
      "tokens": [
        51514,
        6622,
        1893,
        13972,
        19721,
        11,
        13385,
        2168,
        1979,
        11,
        2258,
        1893,
        1979,
        11,
        1774,
        17545,
        1893,
        5578,
        410,
        89,
        325,
        7146,
        5695,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20842160284519196,
      "compression_ratio": 1.55078125,
      "no_speech_prob": 0.0222790390253067
    },
    {
      "id": 199,
      "seek": 89150,
      "start": 892.5,
      "end": 895.5,
      "text": " Genau, also Savai hat noch geschrieben, sorry für die kätzerische Frage,",
      "tokens": [
        50414,
        22340,
        11,
        611,
        12346,
        1301,
        2385,
        3514,
        47397,
        11,
        2597,
        2959,
        978,
        350,
        3628,
        4527,
        7864,
        13685,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2447916716337204,
      "compression_ratio": 1.5090252161026,
      "no_speech_prob": 0.033526983112096786
    },
    {
      "id": 200,
      "seek": 89150,
      "start": 895.5,
      "end": 901.5,
      "text": " aber er kam mittendrin dazu und war verwirrt, weil Ralf immer von R sprach.",
      "tokens": [
        50564,
        4340,
        1189,
        9727,
        19130,
        521,
        12629,
        13034,
        674,
        1516,
        24615,
        347,
        17721,
        11,
        7689,
        497,
        1678,
        5578,
        2957,
        497,
        6103,
        608,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2447916716337204,
      "compression_ratio": 1.5090252161026,
      "no_speech_prob": 0.033526983112096786
    },
    {
      "id": 201,
      "seek": 89150,
      "start": 901.5,
      "end": 905.5,
      "text": " Also kein Grund, sich zu entschuldigen, ich fand das halt tatsächlich,",
      "tokens": [
        50864,
        2743,
        13424,
        13941,
        11,
        3041,
        2164,
        12834,
        339,
        13432,
        3213,
        11,
        1893,
        38138,
        1482,
        12479,
        20796,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2447916716337204,
      "compression_ratio": 1.5090252161026,
      "no_speech_prob": 0.033526983112096786
    },
    {
      "id": 202,
      "seek": 89150,
      "start": 905.5,
      "end": 908.5,
      "text": " also wie gesagt, ich hatte schon einen innigen Gedanken.",
      "tokens": [
        51064,
        611,
        3355,
        12260,
        11,
        1893,
        13299,
        4981,
        4891,
        7714,
        3213,
        44612,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2447916716337204,
      "compression_ratio": 1.5090252161026,
      "no_speech_prob": 0.033526983112096786
    },
    {
      "id": 203,
      "seek": 89150,
      "start": 908.5,
      "end": 913.5,
      "text": " Ja, es ist definitiv eine Problematik, weil man eben die KI vermenschlicht",
      "tokens": [
        51214,
        3530,
        11,
        785,
        1418,
        28781,
        592,
        3018,
        11676,
        267,
        1035,
        11,
        7689,
        587,
        11375,
        978,
        47261,
        1306,
        76,
        26590,
        20238,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2447916716337204,
      "compression_ratio": 1.5090252161026,
      "no_speech_prob": 0.033526983112096786
    },
    {
      "id": 204,
      "seek": 89150,
      "start": 913.5,
      "end": 919.5,
      "text": " und somit dabei auch Fehler macht, dass man ihr zu viel zutraut",
      "tokens": [
        51464,
        674,
        3307,
        270,
        14967,
        2168,
        48101,
        10857,
        11,
        2658,
        587,
        5553,
        2164,
        5891,
        710,
        325,
        424,
        325,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2447916716337204,
      "compression_ratio": 1.5090252161026,
      "no_speech_prob": 0.033526983112096786
    },
    {
      "id": 205,
      "seek": 91950,
      "start": 919.5,
      "end": 922.5,
      "text": " und vielleicht die Ergebnisse nicht mehr überprüft.",
      "tokens": [
        50364,
        674,
        12547,
        978,
        34657,
        31481,
        1979,
        5417,
        4502,
        48715,
        844,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18863904476165771,
      "compression_ratio": 1.5899581909179688,
      "no_speech_prob": 0.025929009541869164
    },
    {
      "id": 206,
      "seek": 91950,
      "start": 922.5,
      "end": 925.5,
      "text": " Ergebnisse überprüfen ist, glaube ich, echt ein Problem.",
      "tokens": [
        50514,
        34657,
        31481,
        4502,
        48715,
        6570,
        1418,
        11,
        13756,
        1893,
        11,
        13972,
        1343,
        11676,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18863904476165771,
      "compression_ratio": 1.5899581909179688,
      "no_speech_prob": 0.025929009541869164
    },
    {
      "id": 207,
      "seek": 91950,
      "start": 925.5,
      "end": 931.5,
      "text": " Also human in the loop zu behalten, dafür sind wir Menschen zu faul,",
      "tokens": [
        50664,
        2743,
        1952,
        294,
        264,
        6367,
        2164,
        1540,
        23276,
        11,
        13747,
        3290,
        1987,
        8397,
        2164,
        2050,
        425,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18863904476165771,
      "compression_ratio": 1.5899581909179688,
      "no_speech_prob": 0.025929009541869164
    },
    {
      "id": 208,
      "seek": 91950,
      "start": 931.5,
      "end": 936.5,
      "text": " dass wir irgendwann sagen, nee, also das kontrolliere ich jetzt nicht mehr.",
      "tokens": [
        50964,
        2658,
        1987,
        34313,
        8360,
        11,
        41694,
        11,
        611,
        1482,
        47107,
        14412,
        1893,
        4354,
        1979,
        5417,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18863904476165771,
      "compression_ratio": 1.5899581909179688,
      "no_speech_prob": 0.025929009541869164
    },
    {
      "id": 209,
      "seek": 91950,
      "start": 936.5,
      "end": 940.5,
      "text": " Genau, da haben wir halt die Grenze gezogen bei den Transkripten",
      "tokens": [
        51214,
        22340,
        11,
        1120,
        3084,
        1987,
        12479,
        978,
        24913,
        1381,
        18110,
        8799,
        4643,
        1441,
        6531,
        74,
        470,
        662,
        268,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18863904476165771,
      "compression_ratio": 1.5899581909179688,
      "no_speech_prob": 0.025929009541869164
    },
    {
      "id": 210,
      "seek": 91950,
      "start": 940.5,
      "end": 943.5,
      "text": " und eben bei den Zusammenfassungen halt irgendwie nicht.",
      "tokens": [
        51414,
        674,
        11375,
        4643,
        1441,
        29442,
        69,
        640,
        5084,
        12479,
        20759,
        1979,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18863904476165771,
      "compression_ratio": 1.5899581909179688,
      "no_speech_prob": 0.025929009541869164
    },
    {
      "id": 211,
      "seek": 94350,
      "start": 944.5,
      "end": 949.5,
      "text": " Also die reviewen wir, also reviewe ich manuell.",
      "tokens": [
        50414,
        2743,
        978,
        3131,
        268,
        1987,
        11,
        611,
        3131,
        68,
        1893,
        587,
        13789,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2062372863292694,
      "compression_ratio": 1.5685484409332275,
      "no_speech_prob": 0.05098659172654152
    },
    {
      "id": 212,
      "seek": 94350,
      "start": 952.5,
      "end": 954.5,
      "text": " Also ich weiß nicht genau, wie sie entstehen,",
      "tokens": [
        50814,
        2743,
        1893,
        13385,
        1979,
        12535,
        11,
        3355,
        2804,
        35955,
        2932,
        11,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2062372863292694,
      "compression_ratio": 1.5685484409332275,
      "no_speech_prob": 0.05098659172654152
    },
    {
      "id": 213,
      "seek": 94350,
      "start": 954.5,
      "end": 957.5,
      "text": " aber das ist vielleicht ein guter Übergang, um sozusagen zu dem Thema zu kommen.",
      "tokens": [
        50914,
        4340,
        1482,
        1418,
        12547,
        1343,
        5228,
        260,
        10713,
        6873,
        656,
        11,
        1105,
        33762,
        2164,
        1371,
        16306,
        2164,
        11729,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2062372863292694,
      "compression_ratio": 1.5685484409332275,
      "no_speech_prob": 0.05098659172654152
    },
    {
      "id": 214,
      "seek": 94350,
      "start": 957.5,
      "end": 960.5,
      "text": " Ich fand das nämlich eigentlich ein relatives Highlight",
      "tokens": [
        51064,
        3141,
        38138,
        1482,
        21219,
        10926,
        1343,
        21960,
        279,
        5229,
        2764,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2062372863292694,
      "compression_ratio": 1.5685484409332275,
      "no_speech_prob": 0.05098659172654152
    },
    {
      "id": 215,
      "seek": 94350,
      "start": 960.5,
      "end": 964.5,
      "text": " und das ist irgendwie eine von den Sachen, wo ich so ein bisschen überrascht bin,",
      "tokens": [
        51214,
        674,
        1482,
        1418,
        20759,
        3018,
        2957,
        1441,
        26074,
        11,
        6020,
        1893,
        370,
        1343,
        10763,
        4502,
        3906,
        4701,
        5171,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2062372863292694,
      "compression_ratio": 1.5685484409332275,
      "no_speech_prob": 0.05098659172654152
    },
    {
      "id": 216,
      "seek": 94350,
      "start": 964.5,
      "end": 968.5,
      "text": " dass es eben so wenig genutzt wird, weil man eben auf wenigen Absätzen",
      "tokens": [
        51414,
        2658,
        785,
        11375,
        370,
        20911,
        1049,
        325,
        2682,
        4578,
        11,
        7689,
        587,
        11375,
        2501,
        11472,
        3213,
        5813,
        45721,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2062372863292694,
      "compression_ratio": 1.5685484409332275,
      "no_speech_prob": 0.05098659172654152
    },
    {
      "id": 217,
      "seek": 96850,
      "start": 968.5,
      "end": 973.5,
      "text": " tatsächlich eine Idee davon bekommt, was halt in dieser Episode drinsteht",
      "tokens": [
        50364,
        20796,
        3018,
        32651,
        18574,
        33429,
        11,
        390,
        12479,
        294,
        9053,
        19882,
        24534,
        2941,
        357,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22904986143112183,
      "compression_ratio": 1.5777777433395386,
      "no_speech_prob": 0.004536347463726997
    },
    {
      "id": 218,
      "seek": 96850,
      "start": 973.5,
      "end": 975.5,
      "text": " oder da passiert.",
      "tokens": [
        50614,
        4513,
        1120,
        21671,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22904986143112183,
      "compression_ratio": 1.5777777433395386,
      "no_speech_prob": 0.004536347463726997
    },
    {
      "id": 219,
      "seek": 96850,
      "start": 976.5,
      "end": 984.5,
      "text": " Und da sind die Ergebnisse meiner Ansicht nach tatsächlich sehr schön und gut.",
      "tokens": [
        50764,
        2719,
        1120,
        3290,
        978,
        34657,
        31481,
        20529,
        14590,
        1405,
        5168,
        20796,
        5499,
        13527,
        674,
        5228,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22904986143112183,
      "compression_ratio": 1.5777777433395386,
      "no_speech_prob": 0.004536347463726997
    },
    {
      "id": 220,
      "seek": 96850,
      "start": 987.5,
      "end": 990.5,
      "text": " Es gibt jetzt eine Ausnahme, die mir jetzt über den Weg gelaufen ist,",
      "tokens": [
        51314,
        2313,
        6089,
        4354,
        3018,
        9039,
        32796,
        11,
        978,
        3149,
        4354,
        4502,
        1441,
        18919,
        4087,
        20748,
        1418,
        11,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22904986143112183,
      "compression_ratio": 1.5777777433395386,
      "no_speech_prob": 0.004536347463726997
    },
    {
      "id": 221,
      "seek": 96850,
      "start": 990.5,
      "end": 993.5,
      "text": " nachdem wir tatsächlich auch darüber gesprochen haben,",
      "tokens": [
        51464,
        5168,
        10730,
        1987,
        20796,
        2168,
        21737,
        42714,
        3084,
        11,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22904986143112183,
      "compression_ratio": 1.5777777433395386,
      "no_speech_prob": 0.004536347463726997
    },
    {
      "id": 222,
      "seek": 96850,
      "start": 993.5,
      "end": 996.5,
      "text": " diese Episode zu machen, die wir jetzt gerade machen.",
      "tokens": [
        51614,
        6705,
        19882,
        2164,
        7069,
        11,
        978,
        1987,
        4354,
        12117,
        7069,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22904986143112183,
      "compression_ratio": 1.5777777433395386,
      "no_speech_prob": 0.004536347463726997
    },
    {
      "id": 223,
      "seek": 99650,
      "start": 996.5,
      "end": 999.5,
      "text": " Du, Ralf, gehst ja jetzt irgendwie vor und gehst halt sozusagen",
      "tokens": [
        50364,
        5153,
        11,
        497,
        1678,
        11,
        13218,
        372,
        2784,
        4354,
        20759,
        4245,
        674,
        13218,
        372,
        12479,
        33762,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19795101881027222,
      "compression_ratio": 1.636690616607666,
      "no_speech_prob": 0.004903669469058514
    },
    {
      "id": 224,
      "seek": 99650,
      "start": 999.5,
      "end": 1001.5,
      "text": " schrittweise die alten Folgen durch.",
      "tokens": [
        50514,
        956,
        18579,
        13109,
        978,
        41217,
        15255,
        1766,
        7131,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19795101881027222,
      "compression_ratio": 1.636690616607666,
      "no_speech_prob": 0.004903669469058514
    },
    {
      "id": 225,
      "seek": 99650,
      "start": 1001.5,
      "end": 1003.5,
      "text": " Und wir sind irgendwie angekommen bei dieser Dunbar-Folge,",
      "tokens": [
        50614,
        2719,
        1987,
        3290,
        20759,
        15495,
        13675,
        4643,
        9053,
        11959,
        5356,
        12,
        37,
        401,
        432,
        11,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19795101881027222,
      "compression_ratio": 1.636690616607666,
      "no_speech_prob": 0.004903669469058514
    },
    {
      "id": 226,
      "seek": 99650,
      "start": 1003.5,
      "end": 1005.5,
      "text": " wo es halt um diese Dunbar-Zahl geht.",
      "tokens": [
        50714,
        6020,
        785,
        12479,
        1105,
        6705,
        11959,
        5356,
        12,
        57,
        10722,
        7095,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19795101881027222,
      "compression_ratio": 1.636690616607666,
      "no_speech_prob": 0.004903669469058514
    },
    {
      "id": 227,
      "seek": 99650,
      "start": 1006.5,
      "end": 1011.5,
      "text": " Also die Zahl, die eben 150 ist und angeblich irgendwie die Menge an Menschen definiert,",
      "tokens": [
        50864,
        2743,
        978,
        42592,
        11,
        978,
        11375,
        8451,
        1418,
        674,
        364,
        10848,
        1739,
        20759,
        978,
        40723,
        364,
        8397,
        1561,
        4859,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19795101881027222,
      "compression_ratio": 1.636690616607666,
      "no_speech_prob": 0.004903669469058514
    },
    {
      "id": 228,
      "seek": 99650,
      "start": 1011.5,
      "end": 1014.5,
      "text": " mit denen man halt ein gutes Vertrauensverhältnis haben kann.",
      "tokens": [
        51114,
        2194,
        19998,
        587,
        12479,
        1343,
        45859,
        21044,
        48907,
        694,
        331,
        28068,
        10661,
        3084,
        4028,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19795101881027222,
      "compression_ratio": 1.636690616607666,
      "no_speech_prob": 0.004903669469058514
    },
    {
      "id": 229,
      "seek": 99650,
      "start": 1015.5,
      "end": 1018.5,
      "text": " Und der Inhalt der Episode ist, dass das genau nicht stimmt.",
      "tokens": [
        51314,
        2719,
        1163,
        682,
        20731,
        1163,
        19882,
        1418,
        11,
        2658,
        1482,
        12535,
        1979,
        37799,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19795101881027222,
      "compression_ratio": 1.636690616607666,
      "no_speech_prob": 0.004903669469058514
    },
    {
      "id": 230,
      "seek": 99650,
      "start": 1019.5,
      "end": 1022.5,
      "text": " Also eigentlich ist die Aussage der Episode,",
      "tokens": [
        51514,
        2743,
        10926,
        1418,
        978,
        21286,
        609,
        1163,
        19882,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19795101881027222,
      "compression_ratio": 1.636690616607666,
      "no_speech_prob": 0.004903669469058514
    },
    {
      "id": 231,
      "seek": 102250,
      "start": 1022.5,
      "end": 1026.5,
      "text": " diese Zahl ist eben gerade keine Aussage über die I-Date-Größe von Gruppen.",
      "tokens": [
        50364,
        6705,
        42592,
        1418,
        11375,
        12117,
        9252,
        21286,
        609,
        4502,
        978,
        286,
        12,
        35,
        473,
        12,
        20038,
        973,
        11451,
        2957,
        10459,
        21278,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24289773404598236,
      "compression_ratio": 1.565573811531067,
      "no_speech_prob": 0.0009252806194126606
    },
    {
      "id": 232,
      "seek": 102250,
      "start": 1027.5,
      "end": 1034.5,
      "text": " Und das ist tatsächlich etwas, wo ich das erste Mal in meiner Erinnerung",
      "tokens": [
        50614,
        2719,
        1482,
        1418,
        20796,
        9569,
        11,
        6020,
        1893,
        1482,
        20951,
        5746,
        294,
        20529,
        3300,
        19166,
        1063,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24289773404598236,
      "compression_ratio": 1.565573811531067,
      "no_speech_prob": 0.0009252806194126606
    },
    {
      "id": 233,
      "seek": 102250,
      "start": 1034.5,
      "end": 1037.5,
      "text": " eine Zusammenfassung halt deutlich editiert habe,",
      "tokens": [
        50964,
        3018,
        29442,
        69,
        40828,
        12479,
        24344,
        8129,
        4859,
        6015,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24289773404598236,
      "compression_ratio": 1.565573811531067,
      "no_speech_prob": 0.0009252806194126606
    },
    {
      "id": 234,
      "seek": 102250,
      "start": 1037.5,
      "end": 1040.5,
      "text": " nämlich weg von, das ist halt die Dunbar-Zahl,",
      "tokens": [
        51114,
        21219,
        15565,
        2957,
        11,
        1482,
        1418,
        12479,
        978,
        11959,
        5356,
        12,
        57,
        10722,
        11,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24289773404598236,
      "compression_ratio": 1.565573811531067,
      "no_speech_prob": 0.0009252806194126606
    },
    {
      "id": 235,
      "seek": 102250,
      "start": 1040.5,
      "end": 1043.5,
      "text": " das ist halt eine Gruppengröße hinzu.",
      "tokens": [
        51264,
        1482,
        1418,
        12479,
        3018,
        10459,
        21278,
        861,
        973,
        11451,
        14102,
        11728,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24289773404598236,
      "compression_ratio": 1.565573811531067,
      "no_speech_prob": 0.0009252806194126606
    },
    {
      "id": 236,
      "seek": 102250,
      "start": 1043.5,
      "end": 1045.5,
      "text": " Nee, ist es halt irgendwie gerade nicht.",
      "tokens": [
        51414,
        22067,
        11,
        1418,
        785,
        12479,
        20759,
        12117,
        1979,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24289773404598236,
      "compression_ratio": 1.565573811531067,
      "no_speech_prob": 0.0009252806194126606
    },
    {
      "id": 237,
      "seek": 102250,
      "start": 1045.5,
      "end": 1050.5,
      "text": " Und das andere Beispiel, das war eine Kleinigkeit,",
      "tokens": [
        51514,
        2719,
        1482,
        10490,
        13772,
        11,
        1482,
        1516,
        3018,
        33327,
        16626,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24289773404598236,
      "compression_ratio": 1.565573811531067,
      "no_speech_prob": 0.0009252806194126606
    },
    {
      "id": 238,
      "seek": 105050,
      "start": 1051.5,
      "end": 1055.5,
      "text": " das war die Episode mit meiner Kollegin Tanja Friedl.",
      "tokens": [
        50414,
        1482,
        1516,
        978,
        19882,
        2194,
        20529,
        46632,
        17046,
        2938,
        17605,
        75,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23018449544906616,
      "compression_ratio": 1.601374626159668,
      "no_speech_prob": 0.0005111957434564829
    },
    {
      "id": 239,
      "seek": 105050,
      "start": 1055.5,
      "end": 1057.5,
      "text": " Da ging es halt irgendwie um Produktmanagement.",
      "tokens": [
        50614,
        3933,
        21924,
        785,
        12479,
        20759,
        1105,
        44599,
        1601,
        11129,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23018449544906616,
      "compression_ratio": 1.601374626159668,
      "no_speech_prob": 0.0005111957434564829
    },
    {
      "id": 240,
      "seek": 105050,
      "start": 1057.5,
      "end": 1062.5,
      "text": " Und da hatte sie gesagt, wenn ich zum Beispiel ein stark konfigurierbares Produkt habe,",
      "tokens": [
        50714,
        2719,
        1120,
        13299,
        2804,
        12260,
        11,
        4797,
        1893,
        5919,
        13772,
        1343,
        17417,
        5897,
        20646,
        374,
        811,
        4231,
        495,
        44599,
        6015,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23018449544906616,
      "compression_ratio": 1.601374626159668,
      "no_speech_prob": 0.0005111957434564829
    },
    {
      "id": 241,
      "seek": 105050,
      "start": 1063.5,
      "end": 1065.5,
      "text": " dann habe ich ja das Problem, dass es halt stark konfigurierbar ist.",
      "tokens": [
        51014,
        3594,
        6015,
        1893,
        2784,
        1482,
        11676,
        11,
        2658,
        785,
        12479,
        17417,
        5897,
        20646,
        374,
        811,
        5356,
        1418,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23018449544906616,
      "compression_ratio": 1.601374626159668,
      "no_speech_prob": 0.0005111957434564829
    },
    {
      "id": 242,
      "seek": 105050,
      "start": 1065.5,
      "end": 1067.5,
      "text": " Ich muss also den Konfigurator bauen.",
      "tokens": [
        51114,
        3141,
        6425,
        611,
        1441,
        12718,
        20646,
        374,
        1639,
        43787,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23018449544906616,
      "compression_ratio": 1.601374626159668,
      "no_speech_prob": 0.0005111957434564829
    },
    {
      "id": 243,
      "seek": 105050,
      "start": 1067.5,
      "end": 1070.5,
      "text": " Es sei denn, ich habe einen Versicherungsfall,",
      "tokens": [
        51214,
        2313,
        10842,
        10471,
        11,
        1893,
        6015,
        4891,
        12226,
        14934,
        5846,
        6691,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23018449544906616,
      "compression_ratio": 1.601374626159668,
      "no_speech_prob": 0.0005111957434564829
    },
    {
      "id": 244,
      "seek": 105050,
      "start": 1070.5,
      "end": 1074.5,
      "text": " ein Produkt ist beschädigt worden und ich will exakt nochmal dasselbe ausliefern.",
      "tokens": [
        51364,
        1343,
        44599,
        1418,
        17498,
        16837,
        5828,
        14054,
        674,
        1893,
        486,
        454,
        5886,
        26509,
        2658,
        338,
        650,
        3437,
        6302,
        28958,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23018449544906616,
      "compression_ratio": 1.601374626159668,
      "no_speech_prob": 0.0005111957434564829
    },
    {
      "id": 245,
      "seek": 105050,
      "start": 1075.5,
      "end": 1077.5,
      "text": " Daraus hat die Zusammenfassung gemacht,",
      "tokens": [
        51614,
        413,
        46483,
        2385,
        978,
        29442,
        69,
        40828,
        12293,
        11,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23018449544906616,
      "compression_ratio": 1.601374626159668,
      "no_speech_prob": 0.0005111957434564829
    },
    {
      "id": 246,
      "seek": 107750,
      "start": 1077.5,
      "end": 1082.5,
      "text": " es ist ein System zur Bearbeitung von Versicherungsschäden entstanden.",
      "tokens": [
        50364,
        785,
        1418,
        1343,
        8910,
        7147,
        19836,
        9407,
        1063,
        2957,
        12226,
        48659,
        3810,
        339,
        737,
        1556,
        948,
        33946,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3221994638442993,
      "compression_ratio": 1.6074379682540894,
      "no_speech_prob": 0.012230085209012032
    },
    {
      "id": 247,
      "seek": 107750,
      "start": 1082.5,
      "end": 1085.5,
      "text": " Und das ist halt tatsächlich falsch.",
      "tokens": [
        50614,
        2719,
        1482,
        1418,
        12479,
        20796,
        43340,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3221994638442993,
      "compression_ratio": 1.6074379682540894,
      "no_speech_prob": 0.012230085209012032
    },
    {
      "id": 248,
      "seek": 107750,
      "start": 1086.5,
      "end": 1089.5,
      "text": " Bei mir hinterlässt das so ein bisschen,",
      "tokens": [
        50814,
        16188,
        3149,
        23219,
        75,
        13555,
        372,
        1482,
        370,
        1343,
        10763,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3221994638442993,
      "compression_ratio": 1.6074379682540894,
      "no_speech_prob": 0.012230085209012032
    },
    {
      "id": 249,
      "seek": 107750,
      "start": 1090.5,
      "end": 1093.5,
      "text": " also du hast es gerade gesagt mit Human in the Loop,",
      "tokens": [
        51014,
        611,
        1581,
        6581,
        785,
        12117,
        12260,
        2194,
        10294,
        294,
        264,
        45660,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3221994638442993,
      "compression_ratio": 1.6074379682540894,
      "no_speech_prob": 0.012230085209012032
    },
    {
      "id": 250,
      "seek": 107750,
      "start": 1094.5,
      "end": 1096.5,
      "text": " so ein bisschen indifferentes,",
      "tokens": [
        51214,
        370,
        1343,
        10763,
        1016,
        12612,
        9240,
        11,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3221994638442993,
      "compression_ratio": 1.6074379682540894,
      "no_speech_prob": 0.012230085209012032
    },
    {
      "id": 251,
      "seek": 107750,
      "start": 1098.5,
      "end": 1101.5,
      "text": " also wie soll ich sagen, das sind jetzt glaube ich tatsächlich die einzigen beiden Beispiele,",
      "tokens": [
        51414,
        611,
        3355,
        7114,
        1893,
        8360,
        11,
        1482,
        3290,
        4354,
        13756,
        1893,
        20796,
        978,
        21586,
        3213,
        23446,
        879,
        7631,
        15949,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3221994638442993,
      "compression_ratio": 1.6074379682540894,
      "no_speech_prob": 0.012230085209012032
    },
    {
      "id": 252,
      "seek": 107750,
      "start": 1101.5,
      "end": 1102.5,
      "text": " die mir so einfallen.",
      "tokens": [
        51564,
        978,
        3149,
        370,
        1343,
        24425,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3221994638442993,
      "compression_ratio": 1.6074379682540894,
      "no_speech_prob": 0.012230085209012032
    },
    {
      "id": 253,
      "seek": 107750,
      "start": 1102.5,
      "end": 1104.5,
      "text": " Und das, ich weiß nicht, wieviel...",
      "tokens": [
        51614,
        2719,
        1482,
        11,
        1893,
        13385,
        1979,
        11,
        3355,
        85,
        1187,
        485,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3221994638442993,
      "compression_ratio": 1.6074379682540894,
      "no_speech_prob": 0.012230085209012032
    },
    {
      "id": 254,
      "seek": 110450,
      "start": 1104.5,
      "end": 1107.5,
      "text": " Die du befunden hast und dir einfallen.",
      "tokens": [
        50364,
        3229,
        1581,
        21312,
        10028,
        6581,
        674,
        4746,
        1343,
        24425,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30986037850379944,
      "compression_ratio": 1.4937238693237305,
      "no_speech_prob": 0.0912989154458046
    },
    {
      "id": 255,
      "seek": 110450,
      "start": 1108.5,
      "end": 1109.5,
      "text": " Genau.",
      "tokens": [
        50564,
        22340,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30986037850379944,
      "compression_ratio": 1.4937238693237305,
      "no_speech_prob": 0.0912989154458046
    },
    {
      "id": 256,
      "seek": 110450,
      "start": 1110.5,
      "end": 1113.5,
      "text": " Ich weiß nicht, wieviel Episoden eigentlich transkribiert jetzt sind.",
      "tokens": [
        50664,
        3141,
        13385,
        1979,
        11,
        3355,
        85,
        1187,
        9970,
        271,
        33482,
        10926,
        1145,
        74,
        2024,
        4859,
        4354,
        3290,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30986037850379944,
      "compression_ratio": 1.4937238693237305,
      "no_speech_prob": 0.0912989154458046
    },
    {
      "id": 257,
      "seek": 110450,
      "start": 1113.5,
      "end": 1115.5,
      "text": " Ich glaube, es sind so 50, 60.",
      "tokens": [
        50814,
        3141,
        13756,
        11,
        785,
        3290,
        370,
        2625,
        11,
        4060,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30986037850379944,
      "compression_ratio": 1.4937238693237305,
      "no_speech_prob": 0.0912989154458046
    },
    {
      "id": 258,
      "seek": 110450,
      "start": 1115.5,
      "end": 1117.5,
      "text": " Hätte ich jetzt auch gedacht.",
      "tokens": [
        50914,
        389,
        34229,
        1893,
        4354,
        2168,
        33296,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30986037850379944,
      "compression_ratio": 1.4937238693237305,
      "no_speech_prob": 0.0912989154458046
    },
    {
      "id": 259,
      "seek": 110450,
      "start": 1121.5,
      "end": 1124.5,
      "text": " Es scheint das erstmal eine niedrige Fehlerrate zu sein,",
      "tokens": [
        51214,
        2313,
        47906,
        1482,
        38607,
        3018,
        32488,
        81,
        3969,
        48101,
        4404,
        2164,
        6195,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30986037850379944,
      "compression_ratio": 1.4937238693237305,
      "no_speech_prob": 0.0912989154458046
    },
    {
      "id": 260,
      "seek": 110450,
      "start": 1124.5,
      "end": 1127.5,
      "text": " aber du hast es halt selber schon gesagt,",
      "tokens": [
        51364,
        4340,
        1581,
        6581,
        785,
        12479,
        23888,
        4981,
        12260,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30986037850379944,
      "compression_ratio": 1.4937238693237305,
      "no_speech_prob": 0.0912989154458046
    },
    {
      "id": 261,
      "seek": 110450,
      "start": 1127.5,
      "end": 1131.5,
      "text": " ich auch selber neige dazu, die Sachen halt irgendwie sozusagen durchzuwinken.",
      "tokens": [
        51514,
        1893,
        2168,
        23888,
        408,
        3969,
        13034,
        11,
        978,
        26074,
        12479,
        20759,
        33762,
        7131,
        11728,
        86,
        35061,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30986037850379944,
      "compression_ratio": 1.4937238693237305,
      "no_speech_prob": 0.0912989154458046
    },
    {
      "id": 262,
      "seek": 113150,
      "start": 1131.5,
      "end": 1133.5,
      "text": " Und das führt irgendwie zu der Frage,",
      "tokens": [
        50364,
        2719,
        1482,
        39671,
        20759,
        2164,
        1163,
        13685,
        11,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20644432306289673,
      "compression_ratio": 1.5583332777023315,
      "no_speech_prob": 0.0009109444799833
    },
    {
      "id": 263,
      "seek": 113150,
      "start": 1133.5,
      "end": 1137.5,
      "text": " wie viele von den Dingen da halt sozusagen komisch sind,",
      "tokens": [
        50464,
        3355,
        9693,
        2957,
        1441,
        49351,
        1120,
        12479,
        33762,
        5207,
        5494,
        3290,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20644432306289673,
      "compression_ratio": 1.5583332777023315,
      "no_speech_prob": 0.0009109444799833
    },
    {
      "id": 264,
      "seek": 113150,
      "start": 1137.5,
      "end": 1142.5,
      "text": " ohne dass wir da sie gefunden haben.",
      "tokens": [
        50664,
        15716,
        2658,
        1987,
        1120,
        2804,
        36923,
        3084,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20644432306289673,
      "compression_ratio": 1.5583332777023315,
      "no_speech_prob": 0.0009109444799833
    },
    {
      "id": 265,
      "seek": 113150,
      "start": 1143.5,
      "end": 1148.5,
      "text": " Ich glaube, wir haben keine krass sinnentstellenden Zusammenfassungen,",
      "tokens": [
        50964,
        3141,
        13756,
        11,
        1987,
        3084,
        9252,
        15913,
        640,
        47066,
        317,
        17816,
        8896,
        29442,
        69,
        640,
        5084,
        11,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20644432306289673,
      "compression_ratio": 1.5583332777023315,
      "no_speech_prob": 0.0009109444799833
    },
    {
      "id": 266,
      "seek": 113150,
      "start": 1148.5,
      "end": 1151.5,
      "text": " das würde mich tatsächlich glaube ich überraschen.",
      "tokens": [
        51214,
        1482,
        11942,
        6031,
        20796,
        13756,
        1893,
        4502,
        3906,
        2470,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20644432306289673,
      "compression_ratio": 1.5583332777023315,
      "no_speech_prob": 0.0009109444799833
    },
    {
      "id": 267,
      "seek": 113150,
      "start": 1152.5,
      "end": 1157.5,
      "text": " Und ich glaube, dass halt der Wert sehr hoch ist,",
      "tokens": [
        51414,
        2719,
        1893,
        13756,
        11,
        2658,
        12479,
        1163,
        37205,
        5499,
        19783,
        1418,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20644432306289673,
      "compression_ratio": 1.5583332777023315,
      "no_speech_prob": 0.0009109444799833
    },
    {
      "id": 268,
      "seek": 113150,
      "start": 1157.5,
      "end": 1160.5,
      "text": " auch wenn es halt im Moment nicht so wahnsinnig viel benutzt wird,",
      "tokens": [
        51664,
        2168,
        4797,
        785,
        12479,
        566,
        19093,
        1979,
        370,
        31979,
        46134,
        328,
        5891,
        38424,
        2682,
        4578,
        11,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20644432306289673,
      "compression_ratio": 1.5583332777023315,
      "no_speech_prob": 0.0009109444799833
    },
    {
      "id": 269,
      "seek": 116050,
      "start": 1160.5,
      "end": 1162.5,
      "text": " weil man sich erstmal angucken kann,",
      "tokens": [
        50364,
        7689,
        587,
        3041,
        38607,
        2562,
        49720,
        4028,
        11,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24781908094882965,
      "compression_ratio": 1.7416974306106567,
      "no_speech_prob": 0.0012447420740500093
    },
    {
      "id": 270,
      "seek": 116050,
      "start": 1162.5,
      "end": 1165.5,
      "text": " okay, was ist da eigentlich grob der Plan, was steht da so grob drin.",
      "tokens": [
        50464,
        1392,
        11,
        390,
        1418,
        1120,
        10926,
        4634,
        65,
        1163,
        8112,
        11,
        390,
        16361,
        1120,
        370,
        4634,
        65,
        24534,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24781908094882965,
      "compression_ratio": 1.7416974306106567,
      "no_speech_prob": 0.0012447420740500093
    },
    {
      "id": 271,
      "seek": 116050,
      "start": 1166.5,
      "end": 1170.5,
      "text": " Und ich glaube, da sind sozusagen die Fehler auch akzeptabel in gewisser Weise,",
      "tokens": [
        50664,
        2719,
        1893,
        13756,
        11,
        1120,
        3290,
        33762,
        978,
        48101,
        2168,
        9308,
        32082,
        18657,
        294,
        6906,
        23714,
        41947,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24781908094882965,
      "compression_ratio": 1.7416974306106567,
      "no_speech_prob": 0.0012447420740500093
    },
    {
      "id": 272,
      "seek": 116050,
      "start": 1171.5,
      "end": 1173.5,
      "text": " weil ja das Original eben da ist.",
      "tokens": [
        50914,
        7689,
        2784,
        1482,
        30022,
        11375,
        1120,
        1418,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24781908094882965,
      "compression_ratio": 1.7416974306106567,
      "no_speech_prob": 0.0012447420740500093
    },
    {
      "id": 273,
      "seek": 116050,
      "start": 1173.5,
      "end": 1176.5,
      "text": " Also es ist ja nur ein Hinweis auf das Original",
      "tokens": [
        51014,
        2743,
        785,
        1418,
        2784,
        4343,
        1343,
        29571,
        35033,
        2501,
        1482,
        30022,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24781908094882965,
      "compression_ratio": 1.7416974306106567,
      "no_speech_prob": 0.0012447420740500093
    },
    {
      "id": 274,
      "seek": 116050,
      "start": 1176.5,
      "end": 1179.5,
      "text": " und sollte dann irgendwie dazu dienen zu sagen,",
      "tokens": [
        51164,
        674,
        18042,
        3594,
        20759,
        13034,
        1026,
        20317,
        2164,
        8360,
        11,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24781908094882965,
      "compression_ratio": 1.7416974306106567,
      "no_speech_prob": 0.0012447420740500093
    },
    {
      "id": 275,
      "seek": 116050,
      "start": 1179.5,
      "end": 1182.5,
      "text": " okay, ich höre mir jetzt irgendwie das ganze Ding nochmal an",
      "tokens": [
        51314,
        1392,
        11,
        1893,
        13531,
        265,
        3149,
        4354,
        20759,
        1482,
        18898,
        20558,
        26509,
        364,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24781908094882965,
      "compression_ratio": 1.7416974306106567,
      "no_speech_prob": 0.0012447420740500093
    },
    {
      "id": 276,
      "seek": 116050,
      "start": 1182.5,
      "end": 1184.5,
      "text": " oder ich sehe es mir halt irgendwie an.",
      "tokens": [
        51464,
        4513,
        1893,
        35995,
        785,
        3149,
        12479,
        20759,
        364,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24781908094882965,
      "compression_ratio": 1.7416974306106567,
      "no_speech_prob": 0.0012447420740500093
    },
    {
      "id": 277,
      "seek": 116050,
      "start": 1184.5,
      "end": 1188.5,
      "text": " Und deswegen glaube ich, dass es halt akzeptabel ist.",
      "tokens": [
        51564,
        2719,
        26482,
        13756,
        1893,
        11,
        2658,
        785,
        12479,
        9308,
        32082,
        18657,
        1418,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24781908094882965,
      "compression_ratio": 1.7416974306106567,
      "no_speech_prob": 0.0012447420740500093
    },
    {
      "id": 278,
      "seek": 118850,
      "start": 1188.5,
      "end": 1190.5,
      "text": " Apropos Fehler, ich habe jetzt gerade nachgeguckt,",
      "tokens": [
        50364,
        8723,
        1513,
        329,
        48101,
        11,
        1893,
        6015,
        4354,
        12117,
        5168,
        432,
        70,
        47800,
        11,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24395690858364105,
      "compression_ratio": 1.5098813772201538,
      "no_speech_prob": 0.12383761256933212
    },
    {
      "id": 279,
      "seek": 118850,
      "start": 1190.5,
      "end": 1192.5,
      "text": " ich habe ja MP3s auf der SSD,",
      "tokens": [
        50464,
        1893,
        6015,
        2784,
        14146,
        18,
        82,
        2501,
        1163,
        30262,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24395690858364105,
      "compression_ratio": 1.5098813772201538,
      "no_speech_prob": 0.12383761256933212
    },
    {
      "id": 280,
      "seek": 118850,
      "start": 1192.5,
      "end": 1199.5,
      "text": " also es ist definitiv ein Ein-Kanal-Mono-MP3",
      "tokens": [
        50564,
        611,
        785,
        1418,
        28781,
        592,
        1343,
        6391,
        12,
        42,
        29702,
        12,
        44,
        8957,
        12,
        12224,
        18,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24395690858364105,
      "compression_ratio": 1.5098813772201538,
      "no_speech_prob": 0.12383761256933212
    },
    {
      "id": 281,
      "seek": 118850,
      "start": 1200.5,
      "end": 1203.5,
      "text": " und die werden alle gleich produziert, das muss also identisch sein.",
      "tokens": [
        50964,
        674,
        978,
        4604,
        5430,
        11699,
        28093,
        4859,
        11,
        1482,
        6425,
        611,
        2473,
        5494,
        6195,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24395690858364105,
      "compression_ratio": 1.5098813772201538,
      "no_speech_prob": 0.12383761256933212
    },
    {
      "id": 282,
      "seek": 118850,
      "start": 1203.5,
      "end": 1207.5,
      "text": " Und es hat 121 Kilobit mit 48 KHz Auflösung",
      "tokens": [
        51114,
        2719,
        785,
        2385,
        2272,
        16,
        591,
        10720,
        5260,
        2194,
        11174,
        591,
        21409,
        9462,
        75,
        11310,
        1063,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24395690858364105,
      "compression_ratio": 1.5098813772201538,
      "no_speech_prob": 0.12383761256933212
    },
    {
      "id": 283,
      "seek": 118850,
      "start": 1207.5,
      "end": 1209.5,
      "text": " und 121 Kilobit ist nicht so wahnsinnig viel,",
      "tokens": [
        51314,
        674,
        2272,
        16,
        591,
        10720,
        5260,
        1418,
        1979,
        370,
        31979,
        46134,
        328,
        5891,
        11,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24395690858364105,
      "compression_ratio": 1.5098813772201538,
      "no_speech_prob": 0.12383761256933212
    },
    {
      "id": 284,
      "seek": 118850,
      "start": 1209.5,
      "end": 1212.5,
      "text": " also das ist halt eigentlich eher auf der niedrigen Seite,",
      "tokens": [
        51414,
        611,
        1482,
        1418,
        12479,
        10926,
        24332,
        2501,
        1163,
        32488,
        81,
        3213,
        19748,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24395690858364105,
      "compression_ratio": 1.5098813772201538,
      "no_speech_prob": 0.12383761256933212
    },
    {
      "id": 285,
      "seek": 118850,
      "start": 1212.5,
      "end": 1214.5,
      "text": " deswegen sind die halt auch so klein.",
      "tokens": [
        51564,
        26482,
        3290,
        978,
        12479,
        2168,
        370,
        29231,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24395690858364105,
      "compression_ratio": 1.5098813772201538,
      "no_speech_prob": 0.12383761256933212
    },
    {
      "id": 286,
      "seek": 121450,
      "start": 1214.5,
      "end": 1216.5,
      "text": " Aber anyways, da ist halt eine Gefahr,",
      "tokens": [
        50364,
        5992,
        13448,
        11,
        1120,
        1418,
        12479,
        3018,
        17873,
        5398,
        11,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.231110081076622,
      "compression_ratio": 1.6564885377883911,
      "no_speech_prob": 0.08614557981491089
    },
    {
      "id": 287,
      "seek": 121450,
      "start": 1216.5,
      "end": 1218.5,
      "text": " eine klassische KI-Gefahr,",
      "tokens": [
        50464,
        3018,
        42917,
        7864,
        47261,
        12,
        38,
        5666,
        5398,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.231110081076622,
      "compression_ratio": 1.6564885377883911,
      "no_speech_prob": 0.08614557981491089
    },
    {
      "id": 288,
      "seek": 121450,
      "start": 1218.5,
      "end": 1221.5,
      "text": " dass bei der Zusammenfassung jetzt sozusagen Fehler sind.",
      "tokens": [
        50564,
        2658,
        4643,
        1163,
        29442,
        69,
        40828,
        4354,
        33762,
        48101,
        3290,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.231110081076622,
      "compression_ratio": 1.6564885377883911,
      "no_speech_prob": 0.08614557981491089
    },
    {
      "id": 289,
      "seek": 121450,
      "start": 1221.5,
      "end": 1223.5,
      "text": " Aber auch das ist ja wieder faszinierend,",
      "tokens": [
        50714,
        5992,
        2168,
        1482,
        1418,
        2784,
        6216,
        283,
        19601,
        259,
        811,
        521,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.231110081076622,
      "compression_ratio": 1.6564885377883911,
      "no_speech_prob": 0.08614557981491089
    },
    {
      "id": 290,
      "seek": 121450,
      "start": 1223.5,
      "end": 1225.5,
      "text": " weil ich kann mich echt daran erinnern,",
      "tokens": [
        50814,
        7689,
        1893,
        4028,
        6031,
        13972,
        24520,
        1189,
        19166,
        77,
        11,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.231110081076622,
      "compression_ratio": 1.6564885377883911,
      "no_speech_prob": 0.08614557981491089
    },
    {
      "id": 291,
      "seek": 121450,
      "start": 1225.5,
      "end": 1228.5,
      "text": " dass die KI gesagt hat, das ist Stereo,",
      "tokens": [
        50914,
        2658,
        978,
        47261,
        12260,
        2385,
        11,
        1482,
        1418,
        745,
        323,
        78,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.231110081076622,
      "compression_ratio": 1.6564885377883911,
      "no_speech_prob": 0.08614557981491089
    },
    {
      "id": 292,
      "seek": 121450,
      "start": 1228.5,
      "end": 1230.5,
      "text": " wir mixen das jetzt auf Mono ab.",
      "tokens": [
        51064,
        1987,
        2890,
        268,
        1482,
        4354,
        2501,
        4713,
        78,
        410,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.231110081076622,
      "compression_ratio": 1.6564885377883911,
      "no_speech_prob": 0.08614557981491089
    },
    {
      "id": 293,
      "seek": 121450,
      "start": 1231.5,
      "end": 1235.5,
      "text": " Und das bedeutet ja, dass die KI da quasi wieder einen Fehler gemacht hat.",
      "tokens": [
        51214,
        2719,
        1482,
        27018,
        2784,
        11,
        2658,
        978,
        47261,
        1120,
        20954,
        6216,
        4891,
        48101,
        12293,
        2385,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.231110081076622,
      "compression_ratio": 1.6564885377883911,
      "no_speech_prob": 0.08614557981491089
    },
    {
      "id": 294,
      "seek": 121450,
      "start": 1236.5,
      "end": 1240.5,
      "text": " Einen Fehler, der so what, ist ja egal.",
      "tokens": [
        51464,
        462,
        5636,
        48101,
        11,
        1163,
        370,
        437,
        11,
        1418,
        2784,
        31528,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.231110081076622,
      "compression_ratio": 1.6564885377883911,
      "no_speech_prob": 0.08614557981491089
    },
    {
      "id": 295,
      "seek": 121450,
      "start": 1240.5,
      "end": 1243.5,
      "text": " Also auch das muss man berücksichtigen,",
      "tokens": [
        51664,
        2743,
        2168,
        1482,
        6425,
        587,
        5948,
        41687,
        1405,
        3213,
        11,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.231110081076622,
      "compression_ratio": 1.6564885377883911,
      "no_speech_prob": 0.08614557981491089
    },
    {
      "id": 296,
      "seek": 124350,
      "start": 1243.5,
      "end": 1247.5,
      "text": " dass viele Fehler einfach so verschwinden, weil unwichtig.",
      "tokens": [
        50364,
        2658,
        9693,
        48101,
        7281,
        370,
        20563,
        86,
        10291,
        11,
        7689,
        14853,
        7334,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21943430602550507,
      "compression_ratio": 1.693333387374878,
      "no_speech_prob": 0.001016057562083006
    },
    {
      "id": 297,
      "seek": 124350,
      "start": 1248.5,
      "end": 1250.5,
      "text": " Genau, und das andere, was sehr interessant ist,",
      "tokens": [
        50614,
        22340,
        11,
        674,
        1482,
        10490,
        11,
        390,
        5499,
        37748,
        1418,
        11,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21943430602550507,
      "compression_ratio": 1.693333387374878,
      "no_speech_prob": 0.001016057562083006
    },
    {
      "id": 298,
      "seek": 124350,
      "start": 1250.5,
      "end": 1252.5,
      "text": " wir diskutieren ja im Stream,",
      "tokens": [
        50714,
        1987,
        36760,
        5695,
        2784,
        566,
        24904,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21943430602550507,
      "compression_ratio": 1.693333387374878,
      "no_speech_prob": 0.001016057562083006
    },
    {
      "id": 299,
      "seek": 124350,
      "start": 1252.5,
      "end": 1255.5,
      "text": " dass Softwareentwicklung eigentlich ein Team-Effort sein soll,",
      "tokens": [
        50814,
        2658,
        27428,
        317,
        16038,
        17850,
        10926,
        1343,
        7606,
        12,
        36,
        602,
        477,
        6195,
        7114,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21943430602550507,
      "compression_ratio": 1.693333387374878,
      "no_speech_prob": 0.001016057562083006
    },
    {
      "id": 300,
      "seek": 124350,
      "start": 1255.5,
      "end": 1257.5,
      "text": " dass man miteinander reden soll.",
      "tokens": [
        50964,
        2658,
        587,
        43127,
        26447,
        7114,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21943430602550507,
      "compression_ratio": 1.693333387374878,
      "no_speech_prob": 0.001016057562083006
    },
    {
      "id": 301,
      "seek": 124350,
      "start": 1257.5,
      "end": 1259.5,
      "text": " Wenn wir vorher drüber geredet hätten,",
      "tokens": [
        51064,
        7899,
        1987,
        29195,
        1224,
        12670,
        290,
        4073,
        302,
        33278,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21943430602550507,
      "compression_ratio": 1.693333387374878,
      "no_speech_prob": 0.001016057562083006
    },
    {
      "id": 302,
      "seek": 124350,
      "start": 1259.5,
      "end": 1261.5,
      "text": " dann hätten wir es halt herausgefunden",
      "tokens": [
        51164,
        3594,
        33278,
        1987,
        785,
        12479,
        25089,
        13529,
        10028,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21943430602550507,
      "compression_ratio": 1.693333387374878,
      "no_speech_prob": 0.001016057562083006
    },
    {
      "id": 303,
      "seek": 124350,
      "start": 1261.5,
      "end": 1263.5,
      "text": " und hätten da ein Ergebnis produzieren können.",
      "tokens": [
        51264,
        674,
        33278,
        1120,
        1343,
        46229,
        28093,
        5695,
        6310,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21943430602550507,
      "compression_ratio": 1.693333387374878,
      "no_speech_prob": 0.001016057562083006
    },
    {
      "id": 304,
      "seek": 124350,
      "start": 1263.5,
      "end": 1268.5,
      "text": " Aber ich fand das nur lustig, weil, wie du ja richtig sagst,",
      "tokens": [
        51364,
        5992,
        1893,
        38138,
        1482,
        4343,
        24672,
        328,
        11,
        7689,
        11,
        3355,
        1581,
        2784,
        13129,
        15274,
        372,
        11,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21943430602550507,
      "compression_ratio": 1.693333387374878,
      "no_speech_prob": 0.001016057562083006
    },
    {
      "id": 305,
      "seek": 124350,
      "start": 1268.5,
      "end": 1270.5,
      "text": " wenn wir sozusagen vorher drüber geredet hätten,",
      "tokens": [
        51614,
        4797,
        1987,
        33762,
        29195,
        1224,
        12670,
        290,
        4073,
        302,
        33278,
        11,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21943430602550507,
      "compression_ratio": 1.693333387374878,
      "no_speech_prob": 0.001016057562083006
    },
    {
      "id": 306,
      "seek": 124350,
      "start": 1270.5,
      "end": 1272.5,
      "text": " wäre es vielleicht aufgefallen.",
      "tokens": [
        51714,
        14558,
        785,
        12547,
        35031,
        24425,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21943430602550507,
      "compression_ratio": 1.693333387374878,
      "no_speech_prob": 0.001016057562083006
    },
    {
      "id": 307,
      "seek": 127250,
      "start": 1272.5,
      "end": 1275.5,
      "text": " Nicht aber, wie das halt so ist.",
      "tokens": [
        50364,
        22629,
        4340,
        11,
        3355,
        1482,
        12479,
        370,
        1418,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22975793480873108,
      "compression_ratio": 1.6360543966293335,
      "no_speech_prob": 0.015179606154561043
    },
    {
      "id": 308,
      "seek": 127250,
      "start": 1275.5,
      "end": 1277.5,
      "text": " Also du bist ja alleine losgelaufen",
      "tokens": [
        50514,
        2743,
        1581,
        18209,
        2784,
        37780,
        1750,
        10345,
        20748,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22975793480873108,
      "compression_ratio": 1.6360543966293335,
      "no_speech_prob": 0.015179606154561043
    },
    {
      "id": 309,
      "seek": 127250,
      "start": 1277.5,
      "end": 1278.5,
      "text": " und ich fand das ja auch super,",
      "tokens": [
        50614,
        674,
        1893,
        38138,
        1482,
        2784,
        2168,
        1687,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22975793480873108,
      "compression_ratio": 1.6360543966293335,
      "no_speech_prob": 0.015179606154561043
    },
    {
      "id": 310,
      "seek": 127250,
      "start": 1278.5,
      "end": 1279.5,
      "text": " dass du halt die Features gebaut hast,",
      "tokens": [
        50664,
        2658,
        1581,
        12479,
        978,
        3697,
        3377,
        49203,
        6581,
        11,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22975793480873108,
      "compression_ratio": 1.6360543966293335,
      "no_speech_prob": 0.015179606154561043
    },
    {
      "id": 311,
      "seek": 127250,
      "start": 1279.5,
      "end": 1283.5,
      "text": " aber da wäre dann eben ein Meeting hilfreich gewesen wahrscheinlich.",
      "tokens": [
        50714,
        4340,
        1120,
        14558,
        3594,
        11375,
        1343,
        33217,
        28315,
        69,
        12594,
        27653,
        30957,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22975793480873108,
      "compression_ratio": 1.6360543966293335,
      "no_speech_prob": 0.015179606154561043
    },
    {
      "id": 312,
      "seek": 127250,
      "start": 1283.5,
      "end": 1286.5,
      "text": " Aber da würde ich ganz gern nochmal drauf eingehen,",
      "tokens": [
        50914,
        5992,
        1120,
        11942,
        1893,
        6312,
        38531,
        26509,
        22763,
        30061,
        2932,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22975793480873108,
      "compression_ratio": 1.6360543966293335,
      "no_speech_prob": 0.015179606154561043
    },
    {
      "id": 313,
      "seek": 127250,
      "start": 1286.5,
      "end": 1290.5,
      "text": " diesen Aufwand, den wir haben, um das zu reviewen.",
      "tokens": [
        51064,
        12862,
        9462,
        33114,
        11,
        1441,
        1987,
        3084,
        11,
        1105,
        1482,
        2164,
        3698,
        1093,
        268,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22975793480873108,
      "compression_ratio": 1.6360543966293335,
      "no_speech_prob": 0.015179606154561043
    },
    {
      "id": 314,
      "seek": 127250,
      "start": 1290.5,
      "end": 1292.5,
      "text": " Weil du hast ja gerade eben ganz richtig gesagt,",
      "tokens": [
        51264,
        18665,
        1581,
        6581,
        2784,
        12117,
        11375,
        6312,
        13129,
        12260,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22975793480873108,
      "compression_ratio": 1.6360543966293335,
      "no_speech_prob": 0.015179606154561043
    },
    {
      "id": 315,
      "seek": 127250,
      "start": 1292.5,
      "end": 1294.5,
      "text": " ich bin da allein losgelaufen.",
      "tokens": [
        51364,
        1893,
        5171,
        1120,
        37673,
        1750,
        10345,
        20748,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22975793480873108,
      "compression_ratio": 1.6360543966293335,
      "no_speech_prob": 0.015179606154561043
    },
    {
      "id": 316,
      "seek": 127250,
      "start": 1294.5,
      "end": 1296.5,
      "text": " Ich habe einfach mal gemacht,",
      "tokens": [
        51464,
        3141,
        6015,
        7281,
        2806,
        12293,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22975793480873108,
      "compression_ratio": 1.6360543966293335,
      "no_speech_prob": 0.015179606154561043
    },
    {
      "id": 317,
      "seek": 127250,
      "start": 1296.5,
      "end": 1299.5,
      "text": " ich brauchte ein paar Daten, irgendein Real-World-Projekt",
      "tokens": [
        51564,
        1893,
        45522,
        975,
        1343,
        16509,
        31126,
        11,
        3418,
        27429,
        259,
        8467,
        12,
        37881,
        12,
        12681,
        14930,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22975793480873108,
      "compression_ratio": 1.6360543966293335,
      "no_speech_prob": 0.015179606154561043
    },
    {
      "id": 318,
      "seek": 129950,
      "start": 1299.5,
      "end": 1302.5,
      "text": " und hey, ist ja jetzt hier alles öffentlich.",
      "tokens": [
        50364,
        674,
        4177,
        11,
        1418,
        2784,
        4354,
        3296,
        7874,
        34603,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2133692502975464,
      "compression_ratio": 1.399999976158142,
      "no_speech_prob": 0.04139919951558113
    },
    {
      "id": 319,
      "seek": 129950,
      "start": 1302.5,
      "end": 1305.5,
      "text": " Da konnte ich mir die Daten einfach schnappen.",
      "tokens": [
        50514,
        3933,
        24058,
        1893,
        3149,
        978,
        31126,
        7281,
        956,
        629,
        21278,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2133692502975464,
      "compression_ratio": 1.399999976158142,
      "no_speech_prob": 0.04139919951558113
    },
    {
      "id": 320,
      "seek": 129950,
      "start": 1305.5,
      "end": 1308.5,
      "text": " Und als das dann soweit war",
      "tokens": [
        50664,
        2719,
        3907,
        1482,
        3594,
        262,
        6880,
        270,
        1516,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2133692502975464,
      "compression_ratio": 1.399999976158142,
      "no_speech_prob": 0.04139919951558113
    },
    {
      "id": 321,
      "seek": 129950,
      "start": 1308.5,
      "end": 1311.5,
      "text": " und du drüber geguckt hast und gesagt hast,",
      "tokens": [
        50814,
        674,
        1581,
        1224,
        12670,
        23982,
        47800,
        6581,
        674,
        12260,
        6581,
        11,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2133692502975464,
      "compression_ratio": 1.399999976158142,
      "no_speech_prob": 0.04139919951558113
    },
    {
      "id": 322,
      "seek": 129950,
      "start": 1311.5,
      "end": 1314.5,
      "text": " da muss man aber über alle Folgen drüber gucken,",
      "tokens": [
        50964,
        1120,
        6425,
        587,
        4340,
        4502,
        5430,
        15255,
        1766,
        1224,
        12670,
        33135,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2133692502975464,
      "compression_ratio": 1.399999976158142,
      "no_speech_prob": 0.04139919951558113
    },
    {
      "id": 323,
      "seek": 129950,
      "start": 1314.5,
      "end": 1315.5,
      "text": " müssen wir reviewen.",
      "tokens": [
        51114,
        9013,
        1987,
        3698,
        1093,
        268,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2133692502975464,
      "compression_ratio": 1.399999976158142,
      "no_speech_prob": 0.04139919951558113
    }
  ],
  "language": "german"
}