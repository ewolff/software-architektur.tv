{
  "text": "Vielleicht erinnerst du dich noch, dann habe ich gesagt, ja gut, dann lassen wir es bleiben, weil mehr Aufwand wollte ich nicht erzeugen. Und das finde ich so spannend, weil momentan sucht jeder in der Wirtschaft nach dem KI-Use-Case, mit dem man Einsparungen erzielen kann. Und hier war das für mich so wichtig, weil ja, wir wollten ja eigentlich nicht mehr Aufwand haben. Aber du hast dann gesagt, dass der Mehrwert so hoch ist, dass es sich eben lohnt, diesen Mehraufwand reinzusetzen. Das heißt, die KI hat uns hier enabled, etwas zu erzeugen, was wir vorher nicht konnten. Und es hat diesen Wert, dass wir bereit sind, den Mehraufwand für das Laufenlassen, den Review und sowas zu investieren. Und das fand ich für mich auch nochmal ein Schlüsselmoment, weil es muss nicht unbedingt irgendwie sein, dass ich das gegenüber dem Status Quo was spare, sondern dieses Enablement durch die KI finde ich wichtig. Ja, also zwei Sachen dazu. Die eine Sache ist halt das Reviewen dieser Episoden. Also wahrscheinlich kann man das auch an den GitHub-Historien sich anschauen. Das sind halt eine Zusammenfassung und Stichworte. Fünf Minuten, zehn Minuten, das ist halt kein echter Aufwand. Dann kommt halt das Transkript dazu. Das ist halt diese Geschichte mit dem Anfang abschneiden. Das ist halt das MP3 und das MP3 hat ein Intro. Da haben wir auch nur zwei Runden drüber gedreht, wo erst die Idee war, das Intro abzuschneiden in der Pipeline. Wo wir dann gesagt haben, wir lassen das halt drin und benotieren es halt raus. Und dann halt irgendwie noch in dem Transkript Sachen ändern, falls da Dinge sind, die aufgefallen sind und das halt irgendwie zu lösen. So, das heißt der Aufwand ist gering. Und der Grund, warum ich das… Also die Transkripte sind einfach für Gehörlose, glaube ich, offensichtlich wichtig. Die brauchen halt sowas. Und deswegen fand ich das eben wichtig, sowas auf die Reihe zu bekommen. Und wir hätten es sonst nicht hinbekommen. Ich hatte ja das Vergnügen, aus der Nähe zu sehen, wie der InnoCube-Podcast entsteht. Da sind halt Menschen gewesen, die das Transkriptieren. Dann ist halt noch jemand drüber gegangen und hat es irgendwie nacheditiert, weil die übrigens auch ähnliche Schwierigkeiten haben. Also wenn da Begriffe sind, die die Menschen nicht kennen, dann ist das halt ein Problem und das muss im Manuell nachgearbeitet werden. Und den Aufwand können wir halt nicht leisten. Niemand von uns kann sich hinsetzen und das Ding anhören und darunter schreiben. Und wir können eigentlich auch nicht ernsthaft jemanden dafür bezahlen, weil wir im Prinzip kein Budget haben. Und deswegen ist das die einzige Möglichkeit, Transkripte zu bekommen. Und das ist eben auch tatsächlich wichtig. Und bei den Zusammenfassungen habe ich eben selber gemerkt, dass die… Also ich empfinde sie zumindest als nützlich, weil ich da nochmal eine Idee davon habe, was in der Episode passiert ist. Und deswegen fand ich das halt gut. Und das ist ja auch vielleicht das Allgemeine. Ich habe darüber auch bei Heise mal so einen Artikel geschrieben, eben auch in Bezug auf AI. Wenn wir jetzt also mehr Produktivität haben, was auch immer das bedeutet. Also wir haben jetzt ja die Möglichkeit, mit wenig Aufwand eben diese Sachen zu erzeugen mit AI. Und dadurch sind wir halt in dem Bereich produktiver. Also wenn ich jetzt die Zusammenfassung schreiben würde oder die Stichworte, wenn wir die schreiben würden, das würde halt viel länger dauern. Und dadurch machen wir halt mehr. Und da gibt es einen Begriff für Rebound-Effekt. Ich glaube, so heißt der. Rebound. Genau. Wo du halt sagst, wenn etwas billiger wird, einfacher wird, dann wird es irgendwie für neue Sachen genutzt und halt mehr genutzt. Und wenn also Sachen eben stromeffizienter werden, dann nutzt man halt mehr davon. Und das ist glaube ich das, was wir hier beobachten in gewisser Weise. Und das ist auch das, was ich in diesem heißen Blogpost geschrieben habe, weil ich eben nicht erwarten würde, dass, also wenn wir tatsächlich höher Produktivität durch AI haben, ist meiner Ansicht nach eine offene Frage, aber das ist eine andere Diskussion, dann ist die nächste Frage, ob das durchschlägt zu weniger Menschen, die halt arbeiten. Mindestens in der Softwareentwicklung ist es so, dass wir halt hoffentlich, glaube ich, die ganze Zeit Produktivitätsvorteile haben. Und ich würde behaupten, jetzt oder vor einiger Zeit, also bevor irgendwie dieser Downturn bei uns war, in unserer Branche, zu dem Zeitpunkt gab es halt die meisten EntwicklerInnen. Trotzdem, dass die halt viel produktiver sind als die vor zehn Jahren oder so. Und deswegen bin ich halt sehr unsicher, ob wir dann tatsächlich sozusagen Massenarbeitslosigkeit haben werden. Ich würde eher erwarten, dass wir halt andere Sachen halt dann noch produzieren. Und hier haben wir im Prinzip genau das, wie du gerade sagtest, als kleines Beispiel. Ja, definitiv. Das ist auch bei mir, das Pendel schwingt hin und her. Und ich sehe, dass manche Sachen die KI gut machen kann. Sie kann mich enablen, sie kann mich unterstützen. Und andere Sachen, die klappen irgendwie ganz schlecht. Also die Transcriptions, die lagen eine Weile dann so rum, weil das Problem war, ja, ich hatte das Skript, aber ich musste dann immer es laufen lassen. Das hat irgendwie acht bis zehn Minuten gebraucht. Dann musste ich ein Pull-Request erstellen und habe mir gedacht, eigentlich müsste ich es automatisieren. Und das war dann nämlich so der nächste Aha-Effekt, weil wir kennen das ja mit den Pipelines, die dann irgendwie nur auf dem Server laufen, die man irgendwie schlecht lokal ausprobieren kann und so. Und ich glaube, ich hatte da einen gemischten Ansatz, dass ich einmal den GitHub Copilot mit Issues gefüttert habe, direkt auf GitHub.com und einmal, dass ich es lokal gemacht habe und meiner KI Zugriff über das Command-Line-Tool GH auf die Workflows gegeben habe, dass es eben gucken konnte, wie sie laufen. Und ehrlich gesagt, es war eine Katastrophe. Also da hat er sich total schwer getan. Ich habe auch das Gefühl, ich habe den Code nicht reviewed. Ja, das lief alles irgendwie nebenbei. Mach mal und teste mal und schau mal, ob es funktioniert. Und ich habe die Befürchtung, dass er viel Code dupliziert hat. Also er hat angefangen. Es war irgendwie so eine Zeit, wo die Modelle sehr gern Bug-Files angelegt haben, Backup-Files oder neue Versionen von den Files, obwohl ich immer gesagt habe, du bist hier unter Versionskontrolle, musst du nicht machen. Und er hatte eben auch Probleme mit den Berechtigungen, dass er halt von meinem Repository in das Software-Architektur im Stream Repository das Ganze pushen kann. Und da war ich sehr froh, als es dann irgendwann lief. Aber es kam mir fragil vor. Das Code weiß nicht. Also die Code-Basis ist da glaube ich nicht mehr so gut. Läuft, aber fragil. Und da bin ich dann noch zu einem Moment gekommen, wo ich gemerkt habe, geht so gar nicht. Weil irgendwann, ich wollte die Transkription anschmeißen und er lief auf einen Berechtigungsfehler und nichts ging. Ich habe die KI angeschmissen, habe gesagt, guck mal da Fehler, fix das. Ich war mir nicht so sicher, ob ich da noch irgendwie mit der KI was geändert hatte, das dadurch broken war. Und die KI so, ach ja, klar, warum hast du hier einen Personal Access Token? Können wir doch rausschmeißen, weil du hast ja hier Berechtigung in der Action und hat das rausgeschmissen. Und dann haben wir es ausprobiert und dann ist weiter unten ein Berechtigungsfehler passiert. Und da ist mir auf einmal ein Licht aufgegangen. Er wollte dann schon anfangen und weiter unten den Berechtigungsfehler auch beheben. Aber das eigentliche Problem war ein ganz anderes, denn ich hatte ein temporäres Personal Access Token gesetzt und diese Berechtigung war ausgelaufen. Das hätte er eigentlich erkennen müssen. Aber er hat eben da rumgefummelt am Code, hat nicht den eigentlichen Grund gefunden und hätte den Code jetzt komplett umgeschmissen und sich in komischen Sachen verrannt. Das Ding ist, im ersten Stück reichen die normalen Berechtigungen aus, Open Source Repository Pull. Im zweiten Bereich braucht es das Personal Access Token, um zu pushen oder den Pull Request zu stellen. Und das war ihm nicht aufgefallen. Und da habe ich gemerkt, dass er eben in diesem relativ kleinen Stück Code anscheinend den Überblick verloren hat, das mentale Modell über seinen eigenen Code nicht mehr bewahrt hat und deswegen das nicht editieren oder fixen konnte. Genau, also nochmal ein Reminder sozusagen. Nicht die Dinger sind Textgeneratoren, sodass sie auf Basis von dem, was sie reinbekommen hat, irgendwelchen Text generieren. Ich würde behaupten, es gibt da kein mentales Modell. Aber nicht die Type. Das andere ist, wir kommen ja noch dazu, wie wir es auf die Webseite tun. Und was ich mittlerweile bei mir, wenn ich irgendwelche Sachen mache, wie zum Beispiel jetzt die Webseite editieren, was mir da zugutekommt, ist, dass ich mit ChitchiPT die Möglichkeit habe, zu sagen, okay, sagt mir mal, wie ich dieses oder jenes auf die Reihe bekomme. Da kommen gute Vorschläge. Das bedeutet aber, dass ich mir im Prinzip Webrecherche nur spare. Das, was du ja beschreibst, ist eigentlich, mach mal und implementiere mal. Und das, was du jetzt gerade beschreibst, ist ein gutes Beispiel, um es platt zu sagen, das funktioniert eigentlich nicht. Denn was an irgendeiner Stelle dann immer wieder passiert, ist genau das, was wir jetzt hier gerade sehen. Du fängst an und sagst, naja, das funktioniert ja so und so und so. Und da sind folgende Themen, also ein Security-Thema an dieser Stelle. Das müssen wir fixen. Und dann musst du halt in diese Abstraktion reingreifen. Du bist jetzt nicht mehr auf dieser Ebene, dass du sagst, mach mal und löse mal. Mir egal. Ich will nicht verstehen, wie es funktioniert. Sondern du musst dir verstehen, es gibt halt GitHub. GitHub hat irgendwelche Security-Tokens. Da gibt es offensichtlich Lokale und andere. Und irgendwie ist da etwas schief. Und deswegen muss ich das halt fixen. Was bedeutet, ich komme eben nicht auf die höhere Abstraktionsschicht, sondern an bestimmten Stellen bricht es eben und ich muss irgendwie reingreifen. Das beobachte ich an extrem vielen Stellen, was eben dazu führt, dass ich mir überhaupt gar nicht vorstellen kann, wie halt Nicht-EntwicklerInnen damit irgendetwas auf die Reihe bekommen sollen. Weil an der Stelle werden sie halt gescheitert. Und dann ist halt Schluss. Weil eben solche Menschen dann da nicht reingreifen können und sagen können, ach so, ja klar, das funktioniert ja folgendermaßen. Eben nicht Security-Token, so funktioniert die Security, das ist halt GitHub. Sondern die können das dann eben auf der Ebene nicht mehr verfolgen und dann ist eben Schluss. Absolut. Und du hattest gerade eben schon gesagt, ja, das Modell kann ja kein mentales Modell aufbauen. Und wir hatten die Vermenschlichung. Aber ich habe mich jetzt seit ein paar Wochen mit dem mentalen Modell nach Peter Nauer beschäftigt. 1985 war das, glaube ich, als er das so beschrieben hat. Und das Witzige ist, also das mentale Modell beschreibt halt, was man als Entwickler so aufbaut beim Programmieren, um eben auch die Frage nach dem Warum im Code beantworten zu können. Warum wird da ein Personal Access Token und nicht einfach der Access Key, den man in der Action hat, verwendet, zum Beispiel. Und das Faszinierende ist, dass die Modelle dieses Konzept, mentales Modell nach Nauer kennen und dann wissen, was sie zu tun haben, also was es bedeutet. Und die ganzen Toolhersteller haben schon angefangen. Man kennt das ja, diese Cloud.md oder Agent.md Files, die immer im Root liegen, wo die KI mal über das Repository rübergegangen ist und zumindest sich wichtige Sachen wie Technology Stack und die Fallstruktur und sowas rausgeschrieben hat. Gehört auch zum mentalen Modell. Ich behaupte, dass wenn man eben auch so ein bisschen an dieses Warum geht, wenn man jetzt eben zum Beispiel da das hinterlassen würde, wir benutzen hier Personal Access Token, weil erster Weg ohne Personal Access Token hat nicht funktioniert. Deswegen, wenn man das hinterlässt, dann könnte die KI da besser werden. Und das zeigt eben auch, dass ja, du sagst ja selbst, wenn man, wenn man jetzt das Programmieren noch nicht gewöhnt ist, es nicht jahrelang trainiert hat, dann fallen einem diese Sachen nicht auf. Und dann ist die Frage, ob man es schafft, das Modell richtig zu besprechen, sag ich mal. Ja, also die Prompts richtig zu wählen. Und das macht einen großen Unterschied aus. Genau. Also vielleicht noch zwei Worte dazu. Es ist halt ganz spannend, weil der Sebastian Hans hat mich vor fünf Tagen, so sagt Mastodon, auf dieses Paper hingewiesen, Programming as Theory Building. Und ich hatte mir irgendwie sozusagen vorgenommen, das nochmal genauer durchzulesen, weil ich halt vermutet hatte, dass das halt im Prinzip bedeutet, dass man eben als Menschenteam ein gemeinsames mentales Modell entwickelt und dass sich im Code das eben nur ausdrückt. Ich hatte das irgendwie, genau, ich hatte irgendwie die ersten Seiten überflogen und da war irgendwie so eine Geschichte, von wegen irgendein Team hat halt einen Compiler gebaut oder irgendwas. Dann hat ein anderes Team versucht, den halt zu erweitern. Und daraufhin hat das ursprüngliche Team, hat man das dem ursprünglichen Team gegeben und hat halt gesagt, also das ursprüngliche Team, was den Compiler ursprünglich gebaut hat, hat gesagt, das ist ein netter Versuch, aber das zerstört halt die ganze Struktur des Systems. Und hier ist ein viel einfacherer Weg. Und das hängt eben damit zusammen, dass eben das ursprüngliche Team halt diese Theorie verstanden hat und das neue Team nicht. So jedenfalls meine Wahrnehmung. Also das, was du beschreibst, bedeutet ja nur, dass man den Texten etwas hinschreibt. Das ist kein mentales Modell. Und das ist was anderes, aber nicht, dass, also darüber muss man offensichtlich, das wäre dann sozusagen die nächste Episode, die man nochmal planen könnte und machen könnte. Absolut. Der Begriff mentales Modell ist da vielleicht auch ein bisschen schwierig, aber ich habe halt gemerkt, da ist was dran an diesem mentalen Modell. Und wie du ja gesagt hast, die KI nimmt Text und produziert Text. Das heißt, man muss irgendwo, wenn man es schaffen will, im Text abbilden. Aber das Faszinierende daran ist auch, wenn man dieses Konzept betrachtet und jetzt zum Beispiel Legacy Modernization machen möchte mit der KI und sagt, warum ist dieser Code eigentlich Legacy? Weil die Entwickler sagen alle, muss neu geschrieben werden. Warum muss er neu geschrieben werden? Weil das mentale Modell fehlt, weil das Warum fehlt. Und wenn ich dann mit der KI es umschreiben lasse, in eine moderne Sprache, habe ich dann das mentale Modell. Kann dann der Entwickler weiterarbeiten? Das finde ich so faszinierend, eine interessante Erkenntnis. Meiner Ansicht nach ist das Grundproblem dabei, dass man an der Stelle nicht wahrhaben will, dass Softwareentwicklung ein sozialer Prozess ist. Und das ist das, was ich glaubte, was man aus diesem Paper, was ich eben nicht gelesen habe, vielleicht rauslesen kann, dass eben dieses soziale Modell im Code Ausdruck findet. Und das ist dann halt trivial, wenn ich eine AI ansetze, dass das eben dieses mentale Modell und den sozialen Prozess nicht abbildet. Und dann ist halt Schluss. Das ist eine Fehlkonzeption. Und das ist eine von den Sachen, die mich so ärgert. In diesem AI-Bereich ist eine Fehlkonzeption über Softwareentwicklung. Softwareentwicklung ist ein sozialer Prozess. Und die fundamentalen Schwierigkeiten sind meiner Ansicht nach sozial. Und das wird nicht dadurch besser, dass ich eine Maschine da reinsetze, aber ein anderes Thema. Wir sollten offensichtlich noch eine Episode mindestens planen. Wollen wir sprechen, wie du es auf die Webseite bekommen hast? Ich würde ganz gern jetzt schon mal auf die andere Idee eingehen, wegen dem sozialen Prozess, weil ich das so faszinierend fand. Ich kam dann irgendwie auf die Idee, dass man ja auch mal die Folgen nach Gast sortieren könnte und auf die Seite bringen könnte. War irgendwie so eine Idee, könnte man doch mal machen. Und die Idee dabei war halt, also ich finde diese verschiedenen Ebenen, wie man die KI verwendet. Und wir haben jetzt zum Beispiel bei dem Transkriptionsprozess habe ich mit KI gecodet. Mit KI machen wir ein Review. Und in dem Prozess, die Zusammenfassung, läuft ja selbst auch mit KI. Da müssen wir gleich auch dran denken. Da gibt es ja jetzt ein aktuelles Problem, was wir haben. Und so habe ich dann eben auch gedacht, Mensch, wir haben jetzt diese ganzen 180 Folgen. Wow, da hat sich was angesammelt. Und da ist überall irgendwo unstrukturiert der Gast mit genannt. Und das könnte man ja jetzt mit der KI rausziehen. Und ich habe einfach mal die KI drauf angesetzt. Habe gesagt, guck mal, hier ist das Repository und mach dir mal Gedanken, wie könnte man das rausziehen. Iterier mal drüber. Da war es schon mal faszinierend, weil ich gesagt habe, du KI, kannst du bitte drüber iterieren? Und die KI hat gesagt, ja, ich mache mir mal einen Plan. Und der Plan sind eigentlich maximal fünf Schritte bei Claude. Das heißt, erster Schritt, erste Episode, Gast rausziehen. Zweite Episode, Gast rausziehen. Dritte Episode, Gast rausziehen. Vierte Episode, Gast rausziehen. Aus den anderen Episoden, Gast rausziehen. Und genau so hat das Modell dann gearbeitet. Mit den ersten vier Episoden ist es gut klargekommen. Und dann ist es abgedriftet und konnte nicht mehr iterieren. Da habe ich dann gemerkt, es könnte ja ein Programm schreiben, ein Skript, was iteriert. Und dann in dem Skript habe ich aber die KI wieder nicht mehr zur Verfügung, um es zu extrahieren. Das war so ein Ding, was ich dann da angegangen bin. Aber viel faszinierender fand ich es, als das Ganze irgendwo stand, mehr oder weniger fertig war. Ja, da waren viele Fehler drin. Aber du dann drüber geguckt hast und ich irgendwie gemerkt habe, dass du mir freundlich sagen wolltest, Ralf, das, was da rausgekommen ist, das ist totaler Käse, weil das passt überhaupt nicht zur bestehenden Architektur. War so. Richtig? Soll ich kurz ausruhen? Die eine Sache war, wir haben ja eine Jekyll-basierte Webseite. Das heißt, wir haben im Prinzip Markdown-Files, die gerendert werden mit Ruby-Skripten. Und im Prinzip ist das ja ein CMS. Das heißt, ich habe Content, der ist als MD-Files da und dann wird er gerendert. Was jetzt rausgekommen ist, in deinem Fall war eine MD-Seite, die aber in Wirklichkeit HTML hatte. In Markdown kann ich HTML einbetten und JavaScript-Code. Und wo dann im Prinzip alle Gäste rausgesammelt wurden aus irgendeiner Datenquelle, YAML-File oder so. Und wenn ich dann etwas gesucht habe, hat das der JavaScript-Code auf dem Client gemacht. Das ist wahrscheinlich die einzige Möglichkeit, wie man das hinbekommen kann. Meine Intuition wäre, ich will eigentlich irgendwo einen Server haben, der sucht. Das können wir nicht, weil wir GitHub-Pages nur haben. Und deswegen ist das wahrscheinlich der einzige Weg. Was sich da in meiner Erinnerung aber so gezeigt hat, ist, dass das so aufgepfropft wird. Wir haben CSS-Files, wie sich das gehört. Und ich würde jetzt erwarten, dass diese CSS-Sachen wiederverwendet werden. Werden halt nicht wiederverwendet, da ist halt irgendwie eigener Kram drin. Solche Sachen. Es ist halt was Eigenes, was halt getrennt ist von dem Rest, zum Beispiel in Bezug auf CSS oder nicht eigene JavaScript-Dateien oder so. Und das andere ist halt, also das hat mich dazu gerade angestiftet, das sozusagen deutlich zu sagen, Die Implementierung war erschreckend. Einmal ist es so, man konnte einen Gast auswählen, da gibt es dann die Episode, dann klickt man halt drauf, kriegt einen 404. Okay, das ist die Basis-Funktionalität. Und zwar, ich weiß nicht mehr, irgendwas stimmt an dem Link nicht. Ich glaube, das ist mit Underbar Post und dem Datum, also nicht 2025 und so weiter und so weiter. Da war irgendwas schief. Irgendwie Verzeihnis fehlt oder so. Aber in der Entwicklerin, die mir sowas abliefert, da würde ich zumindest ein Fragezeichen machen, weil ich hätte erwartet, dass die Person mal drauf klickt. Es können immer Fehler passieren, aber das ist halt weird. Das andere war dann, es gab internationale Sprecherinnen. Beispiel, meine jetzt Kollegin Diana Günther. Hört sich jetzt nicht so international an, die ist auch tatsächlich nicht Deutsche, wohnt halt in Berlin. Und warum ist das so, warum ist das eine internationale Sprecherin? Weil sie halt damals bei der einen Episode war, zu Agile Meets Architecture und das war eine englischsprachige Episode und dann hat das System irgendwie gesagt, also nicht hat die AI irgendwie etwas generiert, was hat gesagt, Leute, die in englischsprachigen Episoden sind, sind internationale Gäste und das ist halt Quatsch. Am Ende ist jetzt eben das Feature nicht live. Ich weiß auch nicht, ob das ein wichtiges Feature ist. Ihr könnt euch jetzt melden und sagen, das brauchen wir halt unbedingt. Ich weiß nicht, wie wichtig das wirklich ist, ich fand das mit den Zusammenfassungen halt sehr wichtig. Mit den Gästen bin ich mir nicht so sicher, da kann man ja auch Volltext-Suche machen auf der Webseite mit allen Episoden, aber das Ergebnis war halt einfach, also unterirdisch, ist halt so nicht zu benutzen, Null. Was ich daran faszinierend fand, war… Und dann war halt wieder dieses Transkriptionsproblem, dass nämlich irgendwelche Sprecherinhalte nicht vernünftig extrahiert worden sind und wir haben jetzt 260 Episoden oder so, 80, 280, weiß nicht, also wahnsinnig viele Episoden, sodass man da das Mindestzeit-Reviewen müssen wahrscheinlich sogar explizit reineditieren müssen, also die Sprecher irgendwie auflisten müssen und das ist halt irgendwie auch wahnsinnig viel Aufwand. Was ich faszinierend fand, war, weil du eben auch von Software-Erstellung ist, was Soziales auch gesprochen hast, wäre das mein Code gewesen, dann hättest du echt Probleme gehabt, mir den um die Ohren zu hauen, wie sage ich es richtig und vielleicht kennt auch der ein oder andere dieses Problem, man merkt, dass jemand im Team an seinem Code hängt, an seinen Ideen hängt, an seiner Technologie, die er reingebracht hat und in dem Fall fand ich das so klasse. Ich selbst habe überhaupt keine Verbindung zu dem Code gehabt, ich habe einfach gesagt, gut, ist bescheuert der Code, löschen wir ihn, hat ein paar Token gekostet, keine Ahnung, 60 Cent, weg und das finde ich super, weil mir das einfach mehr Entscheidungsfreiheit gibt, dass ich einfach ein Proof-of-Concept machen kann und einfach sagen kann, nee, das war nichts, weg damit. Diese Bindung zum Code ist weg, ich bin auf einer anderen Ebene. Mein Problem ist, faire Betrachtung und ich fand das auch nicht offensichtlich, mein Learning oder meine Frage, die sich irgendwie daraus ergibt, ist, bei aller Freundschaft, aber Software-Ethik zum Streamen ist eine triviale Webseite, die ist wirklich trivial eigentlich. Wenn wir da so etwas schon nicht hinbekommen und auf dieser Ebene fehlen, verstehe ich nicht, vielleicht gibt es ja irgendwo einen Technologiesprung, das kann immer mal passieren und die sind schwer vorhersehbar, aber im Prinzip ist das ein Desaster, was da produziert wird und ich verstehe nicht, wo dieser Hype herkommt, der hat besagt, dass man nicht mehr entwickeln lernen soll, das ist mit den Ergebnissen, die ich da zumindest auch wieder gesehen habe und ich sehe auch keine anderen Ergebnisse, ist das nicht rechtfertigbar. Ich habe auch gerade eine Umfrage bei Mastodon und bei LinkedIn laufen, wo die Menschen sagen können, wie viel Produktivitätsvorteil sie eigentlich bei Coding tatsächlich jetzt sehen und da gibt es wahnsinnig wenig Antwortmöglichkeiten, sind halt ein Decrease, also Abnahme der jetzigen Produktivität, dann 1 bis 2, also dass man maximal doppelt so schnell wird, das ist die andere Kategorie, dann 2 bis 5 und ich glaube ich mehr als 5 und ich kann mal gucken, ich hatte vorhin die auch irgendwie rumgeschickt, genau also bei Mastodon ist es halt so, dass 40 Prozent sagen, es gibt eine Abnahme, 50 Prozent haben 1 bis 2, 8 Prozent haben 2 bis 5 und 2 Prozent haben mehr als 5, also mehr als Faktor 5, also nicht 40 Prozent sagen, es wird langsamer, bei LinkedIn sind es 13 Prozent Abnahme, 58 Prozent 1 bis 2 mal, also Faktor 1 bis 2, 19 Prozent 2 bis 5 und dann 9 Prozent mehr als 5, das bedeutet, das was wir hier beobachten, ist meiner Ansicht nach nicht außergewöhnlich, also das ist halt eher eine Erfahrung, die wir teilen als Branche, das war für mich auch die Motivation, die Umfrage zu machen, also nicht Urauslöser war halt, dass es diese Paper gab, von wegen Majority View on AI, wo halt im Prinzip das drin stand, dass also die meisten Leute AI-pessimistisch sind, dann hatte ich eine Diskussion auf Mastodon mit dem Johannes Link, der mir gesagt hat, naja, also ich sehe jetzt wieder andere Leute und das hatte dann den Aufschlag gegeben, halt diese Umfrage zu machen und die sagt eigentlich, also ich habe es ja vorhin auch gesagt und vielleicht kommen wir noch dazu in den letzten 10 Minuten, also wenn ich hätte, es war etwas nicht, wie wir alles an der Webseite machen, ich kenne Jackal nicht besonders gut, mir hilft JetGPT dabei halt massiv. Es gibt also einen, meiner Ansicht nach, einen Vorteil, aber das andere, was wir halt beobachten und für mich persönlich ist der Vorteil vor allem, ich wage mich da halt ran und ich kriege halt Dinge schneller gelöst in System, die ich halt irgendwie nicht besonders gut verstehe, aber zu glauben, dass so ein System Software entwickeln kann und das halt irgendwie hinbekommt, ist im Moment durch nichts gedeckt. Absolut, also ich finde es auch schwierig, das Pendel schwingt hin und her, ja, anfangs waren wir alle begeistert, hey, das Teil, ich sage ihm, programmier mir einen Taschenrechner in HTML mit JavaScript und CSS und pump, ist der Taschenrechner da, dass der nach iOS aussieht, daran haben wir uns nicht gestört, aber es ist halt ein Anzeichen, dass es irgendwo aus einem Merkmalsraum runterlädt, ja und JavaScript, HTML, Python, da sind die LLMs sehr gut und momentan schwingt das Pendel so ein bisschen zurück, weil wir dann doch merken, ja, wir wollen vielleicht was mit Java machen und da habe ich mich letztens auch mit der KI unterhalten, sie hat sich 70 Paper runtergeladen und ich weiß nicht, wie tragfähig die Zahlen sind, ja, aber bei Python ist so die Erfolgswahrscheinlichkeit, Lösungswahrscheinlichkeit, keine Ahnung, was es genau ist, so bei 90 Prozent, ja, hört sich gut an, bei Java wird dann so, ich sage mal 82 ausgegeben, wo man sagt, kann ich noch mit leben und dann habe ich gesagt, du, wie sieht denn das mit den Java-Versionen aus, da hat er gesagt, ja, also bei Java 8 bin ich sogar bei 90 Prozent, Java 21 knall ich runter 50, jetzt sind wir bei Java 25, ja, das sind dann so Sachen, wo man auf einmal gegen Wände läuft, die man nicht sieht und ich finde es wichtig, dass wir diese Wände identifizieren, verstehen und gucken können, was wir besser machen können, um da noch mal zurückzukommen auf das Problem mit der Gästeliste, die KI, die arbeitet gern mit JavaScript und deswegen hat die mit JavaScript das implementiert, das ist ihre implizite Architektur und jetzt sind wir hier bei Software-Architektur im Stream, wo ist die Architektur, wer gibt der Maschine eine Architektur mit und ich glaube, wenn wir das besser erarbeiten würden, dass wir der Maschine sagen würden, du, hier ist Jekyll, hier sind deine Constraints, bitte nicht einfach ins Markdown JavaScript einbauen, ja, ich glaube, damit könnten wir weiterkommen. Also bei der Gästeliste ist es halt so, also wenn jemand zu mir gekommen wäre und gesagt hätte, wir bauen mal so eine Gästeliste, ich hätte halt wahrscheinlich ein großes Markdown-Fall gemacht, wenn diese Person mir dann gesagt hätte, nee, ich will, dass es halt irgendwie gesucht wird, vielleicht wäre ich auf die Idee gekommen, das mit JavaScript zu machen, aber ich bin mir nicht sicher, es kann sehr gut sein, dass ich einfach nicht da einen blinden Fleck gehabt hätte und es halt irgendwie nicht gemacht hätte und ich glaube, das ist sozusagen die richtige Lösung, aber vielleicht spannender ist dann tatsächlich die Integration in die Webseite, also wir haben ja jetzt dieses Transcript, die Zusammenfassung und die Stichpunkte und da war die Frage, wie wir es halt in die Webseite bekommen und da hattest du ja auch dann Cloud Code, glaube ich, irgendwie losgeschickt und gesagt, mach mal. Willst du erzählen, wie da die erste Lösung aussah? Ich glaube, du kannst dich da noch besser daran erinnern. Ich glaube, er hat irgendwie ein Datafile aufgebaut, ein YAML-File. Ja, genau, also was da passiert ist und das ist also der Grund, warum ich die Lösung halt erstmal schwierig fand, war, weil es halt irgendwie so ein Alien war und das ist ein bisschen nachvollziehbar und das hatten wir vorhin ja auch schon mal diskutiert und das ist ja auch nur Ästhetik, aber es war irgendwie ein eigenes Verzeichnis und dann sind da diese Geschichten passiert. Ich muss ja jetzt wissen, für welche der Episoden es überhaupt eine Transkription gibt, weil sonst kann ich die ja nicht rendern. Die Lösung, die dort implementiert worden ist, es gibt einen YAML-File, wo das drinsteht. Das fand ich weird, weil das ist das erste YAML-File gewesen, was wir da drin hatten und dann war halt das Zweite. Für mich hat sich das auch komisch angeführt und dann gab es halt irgendwie die andere Geschichte und das war, wie kriege ich jetzt dieses Transcript überhaupt auf die Webseite. Was da passiert ist, ist, dass es die Episodenseite gab. Die gibt es ja eh für alle Episoden, auch für die, die ich transkriptierten und dann ist eine Lösung entstanden, wo in diese Seite die anderen drei Dateien inkludiert worden sind und dann Anchor gebaut worden sind. Was also dazu führt, dass ich eine Episodenseite habe. Das ist oben das Video auf PeerTube, das Video auf YouTube, der Podcast. Dann die Zusammenfassung, Stichpunkte und dann die Transkription, was dazu führt, dass diese Webseite plötzlich wahnsinnig lang ist und im Wesentlichen aus dem Transkription besteht, weil dieses Ding eben natürlich die meisten Worte enthält. Also wie soll ich sagen, nicht Software-Editor im Stream war oder ist, glaube ich, möglicherweise immer noch in diesem 512 Kilobyte Club. Meine persönliche Webseite möglicherweise auch. Eigentlich ist das eine Webseite, die so kleine Webseiten hat, kleine Webpages hat und das war eigentlich eine Sache, die ich irgendwie ganz gut fand und ich fand das da halt irgendwie weird und auch unnötig aufgeblasen. Und es hat sich dann herausgestellt, das haben wir glaube ich tatsächlich erst zu der Diskussion zu dieser Folge herausgefunden, dass du, Claude, gesagt hast, man braucht etwas minimal Invasives. Das war das, was du gesagt hast. Und das ist in gewisser Weise passiert, weil die Markdown-Files für die Episoden sind unverändert. Das Template hat sich geändert. Das Template guckt jetzt in dem YAML nach, ob es die Übersetzung gibt und inkludiert die. Also war das in gewisser Weise nicht zielerreicht. Das fand ich lustig, weil ich hatte gedacht, naja, das ist eine Implementierungsvariante, die aus irgendwelchen Gründen von der AI gekommen ist und das ist problematisch. Und was dann passiert ist in der Folge, ist, dass ich mich mal hingesetzt habe und einmal das Ding deutlich umgestellt habe. Und jetzt ist es halt so, dass es diese drei Dateien gibt. Da gibt es irgendwie Links dazwischen und diese Links werden gerendert, wenn die Dateien vorhanden sind. Das heißt also, dass das Template von der Episode sagt, ich gucke jetzt nach, sind die Dateien da für die Zusammenfassung, für die Transkription und so weiter. Dann rendere ich diese Links da rein, sonst nicht. Das YAML-File ist damit eliminiert. Ich musste, um diese Links zu rendern, in den Dateien die Episoden-Nummer aufnehmen. Das heißt, ich habe letztendlich alle Episoden einmal automatisiert durchgeackert und habe da die Episoden-Nummer reingepackt. Also ein Skript hat das getan. Und dadurch haben wir jetzt eben diese vier Links. Und im Rahmen dieser Aktion sind noch diverse andere Sachen entstanden. Also zum Beispiel haben wir das jetzt mit YouTube und PeerTube so gemacht, dass man erstmal sagen muss, dass die Sachen tatsächlich embeddet sein sollen. Ich habe ein paar Sachen hübscher gemacht, den Überblick hübscher und so weiter. Und dadurch ist eben auch dieses Alien und die eigenen CSS-Dateien und so das komplett eliminiert. Das hätte ich vielleicht hinbekommen ohne GTPT-Unterstützung, aber dann hätte es länger gedauert. Das heißt, ich kann mir nicht vorstellen, solche Sachen zu entwickeln, ohne auf ein LLM zurückzugreifen. Und die andere Seite, die spannend ist, ist nicht dieser Constraint, der dazu geführt hat, dass diese Lösung tatsächlich problematisch ist. Der ist eigentlich von draußen reingekommen. Und das Spannende, was du jetzt erzählt hast von der Lösung ist, da ist eine grundlegende Entscheidung getroffen worden in der Umsetzung und durch die Constraints von Jekyll zieht es einiges nach sich. Denn als ich das umgesetzt habe, ist es reingekommen, dass wir gesagt haben, ja, okay, wir haben schon die Videos, wir haben schon den Podcast drin, wir haben den MP3 untereinander, wir haben den Abstract noch da drin. Setz mal die anderen Sachen drunter. Und das heißt, wir mussten inkludieren und ein Include geht nur auf das Include-Verzeichnis, nicht auf irgendwelche anderen Summaries-Verzeichnisse oder so. Und deswegen mussten eben diese Summaries und die Transkription auch in das Include-Verzeichnis, wo eigentlich Header, Footer und sowas drin ist und CSS, total hässlich. Und dadurch, dass bei deiner Umsetzung die Entscheidung getroffen worden ist, kommen wir setzen das auf eigene Seiten. Wir haben da Links. War das dann auf einmal möglich, das sauber in die Folder aufzuteilen? Genau. Und das ist halt so ein bisschen der Punkt. Ich glaube, du hast es gerade sehr gut gesagt. Die Lösung hat partiell eigentlich gegen Jekyll und dieses System gearbeitet. Und das ist eine Lösung, die irgendwie funktioniert, aber sie arbeitet dagegen. Und da ist die zweite Iteration dann irgendwie anders. Da ist auch die Frage, wie soll ich sagen, ich weiß nicht, ob ich exakt diese Lösung umgesetzt hätte, wenn es nicht die erste Lösung gegeben hätte, also evolutionäre Architekturentwicklung. Aber ja, ich will noch eine Sache loswerden. Also der Ingo Eichhorst, der war ja auch schon hier im Stream, hat hier einen Kommentar hinterlassen. In meinen Augen eine ganz normale Technologie-Adaptionskurve. Erstmal geht es nach unten und dann gibt es Produktivitätsgewinne auf lange Sicht. Also ich habe das erste deutschsprachige Spring-Buch geschrieben und ich habe auch das erste deutschsprachige Buch geschrieben über Microservices. Bei Spring war es so, dass von Anfang an sofort deutlich offensichtlich war, zumindest für mich, dass das die Lösung ist, die ich Java I vorziehen würde. Und ich will das gar nicht im Produktivitätsgewinne sozusagen ausdrücken, das ist halt schwierig, das ist halt ein Framework. Aber die Vorteile waren halt evident. Und also mindestens mit dem Stand, also nicht Java I, hat sich auf gut Rund dessen weiterentwickelt und ist heute was anderes als damals. Aber das war klar und das hat dort auch viele Leute überzeugt. Bei Microservices kann man darüber diskutieren. Meiner Ansicht nach ist das eine Lösung für einige spezielle Punkte. Ich fand es interessant für bestimmte Sachen, das war was anderes. Eine Technologie, die kein Produktivitätsgewinn, also dass das jetzt keine Produktivitätsgewinne verspricht oder keine großen, da scheinen wir uns ja einig zu sein. Ich verstehe nicht, woher der Optimismus kommt, dass es einen Produktivitätsgewinn auf lange Sicht geben soll. Denn dafür gibt es halt im Moment keinen Hinweis. Es ist extrem schwer, die Zukunft hier zu sagen, also aus offensichtlichen Gründen. Deswegen muss man das abwarten und nicht, keine Ahnung, vielleicht ist es halt so, dass wir dahin kommen, dass es da irgendetwas gibt, aber das ist halt im Moment nicht absehbar. Und nur nochmal, um es deutlich zu sagen, mindestens die Leute in der Mastodon-Community sagen, dass halt bei Coding eine Abnahme der Produktivität durch AI-Systeme stattfindet. Und das sind 40 Prozent. 50 Prozent haben einen Faktor von 1 bis 2. Das ist für mich ein überraschendes Ergebnis und das ist auch nichts, was bei LinkedIn halt reproduzierbar ist. Also es hängt sehr sicher von der sozialen Gruppe ab. Aber das ist nichts, worauf man jetzt irgendwie sagen kann, wir möchten noch zwei, drei Sachen ändern und dann ist es besser. Keine Ahnung. Also muss man darüber diskutieren. Ich habe mir bewusst überlegt, ob ich die Frage stelle, also welche Vorteile erwartet ihr über die Zukunft. Ich habe das halt gelassen, weil ich glaube, das bringt halt nichts. Also es bringt deswegen nichts, weil das ist halt ein totales Glaskugellesen. Da kann man halt irgendwelche Zahlen schießen und das ist ja beliebig. Wir müssen uns aber tatsächlich eben in die Augen gucken und halt sehen, dass im Moment mindestens die Mastodon-Community, ich unterstelle, dass die irgendwie technischer ist. Keine Ahnung, wie ich das ausdrücken soll. Und es sind auch meine Follower, also das ist eine gewisse Auslese. Aber diese 40 Prozent ist halt irgendwie krass. Also das hätte ich auch nicht erwartet. Wir haben da glaube ich noch viele spannende Sachen vor uns. Jetzt gucke ich mal kurz auf die Planung. Nächste Woche ist die Episode am 6. Das ist der Donnerstag. Da spricht Lisa mit Aino darüber, ob… Moment, erstmal ist es auf Englisch. Und es geht um das Thema Teamwork. Do we still need to talk about it? Und das wird dann, glaube ich, eine besonders spannende Folge. Also wie gesagt, nächste Woche dann tatsächlich am Donnerstag zur gewohnten Zeit, also um 13 Uhr, nicht am Freitag. Und dann mit Lisa und Aino. Vielen Dank an dich, Ralf. Vielen Dank an die ZuschauerInnen. Und vielleicht sehen wir uns dann bei einer der folgenden Folgen. Bis dann. Danke für die spannende Diskussion. Tschau.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 1315.41,
      "end": 1320.8500000572205,
      "text": " Vielleicht erinnerst du dich noch, dann habe ich gesagt, ja gut, dann lassen wir es bleiben,",
      "tokens": [
        50364,
        29838,
        1189,
        19166,
        372,
        1581,
        10390,
        3514,
        11,
        3594,
        6015,
        1893,
        12260,
        11,
        2784,
        5228,
        11,
        3594,
        16168,
        1987,
        785,
        24912,
        11,
        50636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25977033376693726,
      "compression_ratio": 1.6118143796920776,
      "no_speech_prob": 0.908920168876648
    },
    {
      "id": 1,
      "seek": 0,
      "start": 1320.8500000572205,
      "end": 1327.5900003051759,
      "text": " weil mehr Aufwand wollte ich nicht erzeugen. Und das finde ich so spannend, weil momentan",
      "tokens": [
        50636,
        7689,
        5417,
        9462,
        33114,
        24509,
        1893,
        1979,
        1189,
        19303,
        268,
        13,
        2719,
        1482,
        17841,
        1893,
        370,
        49027,
        11,
        7689,
        1623,
        282,
        50973
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25977033376693726,
      "compression_ratio": 1.6118143796920776,
      "no_speech_prob": 0.908920168876648
    },
    {
      "id": 2,
      "seek": 0,
      "start": 1327.5900003051759,
      "end": 1334.6100007629395,
      "text": " sucht jeder in der Wirtschaft nach dem KI-Use-Case, mit dem man Einsparungen erzielen kann. Und hier",
      "tokens": [
        50973,
        1270,
        83,
        19610,
        294,
        1163,
        29412,
        5168,
        1371,
        47261,
        12,
        52,
        405,
        12,
        34,
        651,
        11,
        2194,
        1371,
        587,
        22790,
        2181,
        5084,
        1189,
        89,
        12844,
        4028,
        13,
        2719,
        3296,
        51324
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25977033376693726,
      "compression_ratio": 1.6118143796920776,
      "no_speech_prob": 0.908920168876648
    },
    {
      "id": 3,
      "seek": 0,
      "start": 1334.6100007629395,
      "end": 1342.2899991607667,
      "text": " war das für mich so wichtig, weil ja, wir wollten ja eigentlich nicht mehr Aufwand haben. Aber du",
      "tokens": [
        51324,
        1516,
        1482,
        2959,
        6031,
        370,
        13621,
        11,
        7689,
        2784,
        11,
        1987,
        46019,
        2784,
        10926,
        1979,
        5417,
        9462,
        33114,
        3084,
        13,
        5992,
        1581,
        51708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25977033376693726,
      "compression_ratio": 1.6118143796920776,
      "no_speech_prob": 0.908920168876648
    },
    {
      "id": 4,
      "seek": 2688,
      "start": 1342.2899991607667,
      "end": 1348.1699983215333,
      "text": " hast dann gesagt, dass der Mehrwert so hoch ist, dass es sich eben lohnt, diesen Mehraufwand",
      "tokens": [
        50364,
        6581,
        3594,
        12260,
        11,
        2658,
        1163,
        30782,
        26521,
        370,
        19783,
        1418,
        11,
        2658,
        785,
        3041,
        11375,
        46957,
        580,
        11,
        12862,
        30782,
        9507,
        33114,
        50658
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2485523223876953,
      "compression_ratio": 1.5833333730697632,
      "no_speech_prob": 0.02928757667541504
    },
    {
      "id": 5,
      "seek": 2688,
      "start": 1348.1699983215333,
      "end": 1354.7299996948243,
      "text": " reinzusetzen. Das heißt, die KI hat uns hier enabled, etwas zu erzeugen, was wir vorher nicht",
      "tokens": [
        50658,
        6561,
        16236,
        24797,
        13,
        2846,
        13139,
        11,
        978,
        47261,
        2385,
        2693,
        3296,
        15172,
        11,
        9569,
        2164,
        1189,
        19303,
        268,
        11,
        390,
        1987,
        29195,
        1979,
        50986
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2485523223876953,
      "compression_ratio": 1.5833333730697632,
      "no_speech_prob": 0.02928757667541504
    },
    {
      "id": 6,
      "seek": 2688,
      "start": 1354.7299996948243,
      "end": 1361.9300004577638,
      "text": " konnten. Und es hat diesen Wert, dass wir bereit sind, den Mehraufwand für das Laufenlassen,",
      "tokens": [
        50986,
        38216,
        13,
        2719,
        785,
        2385,
        12862,
        37205,
        11,
        2658,
        1987,
        38758,
        3290,
        11,
        1441,
        29337,
        424,
        2947,
        33114,
        2959,
        1482,
        441,
        20748,
        44898,
        11,
        51346
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2485523223876953,
      "compression_ratio": 1.5833333730697632,
      "no_speech_prob": 0.02928757667541504
    },
    {
      "id": 7,
      "seek": 2688,
      "start": 1361.9300004577638,
      "end": 1367.0499993896485,
      "text": " den Review und sowas zu investieren. Und das fand ich für mich auch nochmal ein Schlüsselmoment,",
      "tokens": [
        51346,
        1441,
        19954,
        674,
        19766,
        296,
        2164,
        1963,
        5695,
        13,
        2719,
        1482,
        38138,
        1893,
        2959,
        6031,
        2168,
        26509,
        1343,
        16420,
        37838,
        42544,
        317,
        11,
        51602
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2485523223876953,
      "compression_ratio": 1.5833333730697632,
      "no_speech_prob": 0.02928757667541504
    },
    {
      "id": 8,
      "seek": 5164,
      "start": 1367.0499993896485,
      "end": 1373.2099992370606,
      "text": " weil es muss nicht unbedingt irgendwie sein, dass ich das gegenüber dem Status Quo was spare,",
      "tokens": [
        50364,
        7689,
        785,
        6425,
        1979,
        41211,
        20759,
        6195,
        11,
        2658,
        1893,
        1482,
        41830,
        1371,
        47409,
        2326,
        78,
        390,
        13798,
        11,
        50672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3244977593421936,
      "compression_ratio": 1.563829779624939,
      "no_speech_prob": 0.05028244107961655
    },
    {
      "id": 9,
      "seek": 5164,
      "start": 1373.2099992370606,
      "end": 1376.689998779297,
      "text": " sondern dieses Enablement durch die KI finde ich wichtig.",
      "tokens": [
        50672,
        11465,
        12113,
        2193,
        712,
        518,
        7131,
        978,
        47261,
        17841,
        1893,
        13621,
        13,
        50846
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3244977593421936,
      "compression_ratio": 1.563829779624939,
      "no_speech_prob": 0.05028244107961655
    },
    {
      "id": 10,
      "seek": 5164,
      "start": 1376.689998779297,
      "end": 1383.41,
      "text": " Ja, also zwei Sachen dazu. Die eine Sache ist halt das Reviewen dieser Episoden. Also wahrscheinlich",
      "tokens": [
        50846,
        3530,
        11,
        611,
        12002,
        26074,
        13034,
        13,
        3229,
        3018,
        31452,
        1418,
        12479,
        1482,
        19954,
        268,
        9053,
        9970,
        271,
        33482,
        13,
        2743,
        30957,
        51182
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3244977593421936,
      "compression_ratio": 1.563829779624939,
      "no_speech_prob": 0.05028244107961655
    },
    {
      "id": 11,
      "seek": 5164,
      "start": 1383.41,
      "end": 1388.689998779297,
      "text": " kann man das auch an den GitHub-Historien sich anschauen. Das sind halt eine Zusammenfassung",
      "tokens": [
        51182,
        4028,
        587,
        1482,
        2168,
        364,
        1441,
        23331,
        12,
        39,
        23882,
        1053,
        3041,
        31508,
        11715,
        13,
        2846,
        3290,
        12479,
        3018,
        29442,
        69,
        40828,
        51446
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3244977593421936,
      "compression_ratio": 1.563829779624939,
      "no_speech_prob": 0.05028244107961655
    },
    {
      "id": 12,
      "seek": 5164,
      "start": 1388.689998779297,
      "end": 1394.3299981689454,
      "text": " und Stichworte. Fünf Minuten, zehn Minuten, das ist halt kein echter Aufwand. Dann kommt halt",
      "tokens": [
        51446,
        674,
        745,
        480,
        86,
        12752,
        13,
        479,
        26292,
        27593,
        11,
        33975,
        27593,
        11,
        1482,
        1418,
        12479,
        13424,
        308,
        26690,
        9462,
        33114,
        13,
        7455,
        10047,
        12479,
        51728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3244977593421936,
      "compression_ratio": 1.563829779624939,
      "no_speech_prob": 0.05028244107961655
    },
    {
      "id": 13,
      "seek": 7892,
      "start": 1394.6099969482423,
      "end": 1400.810001525879,
      "text": " das Transkript dazu. Das ist halt diese Geschichte mit dem Anfang abschneiden. Das ist halt das MP3",
      "tokens": [
        50378,
        1482,
        6531,
        74,
        470,
        662,
        13034,
        13,
        2846,
        1418,
        12479,
        6705,
        28896,
        2194,
        1371,
        25856,
        1950,
        339,
        716,
        4380,
        13,
        2846,
        1418,
        12479,
        1482,
        14146,
        18,
        50688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3790550231933594,
      "compression_ratio": 1.4974619150161743,
      "no_speech_prob": 0.0004802812763955444
    },
    {
      "id": 14,
      "seek": 7892,
      "start": 1400.810001525879,
      "end": 1410.0099984741212,
      "text": " und das MP3 hat ein Intro. Da haben wir auch nur zwei Runden drüber gedreht, wo erst die Idee war,",
      "tokens": [
        50688,
        674,
        1482,
        14146,
        18,
        2385,
        1343,
        47406,
        13,
        3933,
        3084,
        1987,
        2168,
        4343,
        12002,
        497,
        10028,
        1224,
        12670,
        19238,
        265,
        357,
        11,
        6020,
        11301,
        978,
        32651,
        1516,
        11,
        51148
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3790550231933594,
      "compression_ratio": 1.4974619150161743,
      "no_speech_prob": 0.0004802812763955444
    },
    {
      "id": 15,
      "seek": 7892,
      "start": 1410.0099984741212,
      "end": 1416.7700006103516,
      "text": " das Intro abzuschneiden in der Pipeline. Wo wir dann gesagt haben, wir lassen das halt drin und",
      "tokens": [
        51148,
        1482,
        47406,
        410,
        16236,
        339,
        716,
        4380,
        294,
        1163,
        35396,
        5440,
        13,
        6622,
        1987,
        3594,
        12260,
        3084,
        11,
        1987,
        16168,
        1482,
        12479,
        24534,
        674,
        51486
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3790550231933594,
      "compression_ratio": 1.4974619150161743,
      "no_speech_prob": 0.0004802812763955444
    },
    {
      "id": 16,
      "seek": 10136,
      "start": 1416.7700006103516,
      "end": 1423.3299981689454,
      "text": " benotieren es halt raus. Und dann halt irgendwie noch in dem Transkript Sachen ändern, falls da",
      "tokens": [
        50364,
        3271,
        310,
        5695,
        785,
        12479,
        17202,
        13,
        2719,
        3594,
        12479,
        20759,
        3514,
        294,
        1371,
        6531,
        74,
        470,
        662,
        26074,
        47775,
        11,
        8804,
        1120,
        50692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35238561034202576,
      "compression_ratio": 1.5440000295639038,
      "no_speech_prob": 0.3272985517978668
    },
    {
      "id": 17,
      "seek": 10136,
      "start": 1423.3299981689454,
      "end": 1429.289997253418,
      "text": " Dinge sind, die aufgefallen sind und das halt irgendwie zu lösen. So, das heißt der Aufwand",
      "tokens": [
        50692,
        25102,
        3290,
        11,
        978,
        35031,
        24425,
        3290,
        674,
        1482,
        12479,
        20759,
        2164,
        25209,
        6748,
        13,
        407,
        11,
        1482,
        13139,
        1163,
        9462,
        33114,
        50990
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35238561034202576,
      "compression_ratio": 1.5440000295639038,
      "no_speech_prob": 0.3272985517978668
    },
    {
      "id": 18,
      "seek": 10136,
      "start": 1429.289997253418,
      "end": 1435.5700036621095,
      "text": " ist gering. Und der Grund, warum ich das… Also die Transkripte sind einfach für Gehörlose,",
      "tokens": [
        50990,
        1418,
        290,
        1794,
        13,
        2719,
        1163,
        13941,
        11,
        24331,
        1893,
        1482,
        1260,
        2743,
        978,
        6531,
        74,
        470,
        662,
        68,
        3290,
        7281,
        2959,
        2876,
        71,
        2311,
        75,
        541,
        11,
        51304
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35238561034202576,
      "compression_ratio": 1.5440000295639038,
      "no_speech_prob": 0.3272985517978668
    },
    {
      "id": 19,
      "seek": 10136,
      "start": 1435.5700036621095,
      "end": 1443.210003051758,
      "text": " glaube ich, offensichtlich wichtig. Die brauchen halt sowas. Und deswegen fand ich das eben wichtig,",
      "tokens": [
        51304,
        13756,
        1893,
        11,
        766,
        694,
        41971,
        13621,
        13,
        3229,
        19543,
        12479,
        19766,
        296,
        13,
        2719,
        26482,
        38138,
        1893,
        1482,
        11375,
        13621,
        11,
        51686
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35238561034202576,
      "compression_ratio": 1.5440000295639038,
      "no_speech_prob": 0.3272985517978668
    },
    {
      "id": 20,
      "seek": 12780,
      "start": 1443.210003051758,
      "end": 1453.5299951171876,
      "text": " sowas auf die Reihe zu bekommen. Und wir hätten es sonst nicht hinbekommen. Ich hatte ja das",
      "tokens": [
        50364,
        19766,
        296,
        2501,
        978,
        34549,
        675,
        2164,
        19256,
        13,
        2719,
        1987,
        33278,
        785,
        26309,
        1979,
        14102,
        650,
        13675,
        13,
        3141,
        13299,
        2784,
        1482,
        50880
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31204530596733093,
      "compression_ratio": 1.5993376970291138,
      "no_speech_prob": 0.005553507711738348
    },
    {
      "id": 21,
      "seek": 12780,
      "start": 1453.5299951171876,
      "end": 1457.3700067138673,
      "text": " Vergnügen, aus der Nähe zu sehen, wie der InnoCube-Podcast entsteht. Da sind halt Menschen",
      "tokens": [
        50880,
        4281,
        4568,
        45336,
        11,
        3437,
        1163,
        32731,
        675,
        2164,
        11333,
        11,
        3355,
        1163,
        682,
        1771,
        34,
        1977,
        12,
        40742,
        3734,
        35955,
        357,
        13,
        3933,
        3290,
        12479,
        8397,
        51072
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31204530596733093,
      "compression_ratio": 1.5993376970291138,
      "no_speech_prob": 0.005553507711738348
    },
    {
      "id": 22,
      "seek": 12780,
      "start": 1457.3700067138673,
      "end": 1460.8099938964845,
      "text": " gewesen, die das Transkriptieren. Dann ist halt noch jemand drüber gegangen und hat es irgendwie",
      "tokens": [
        51072,
        27653,
        11,
        978,
        1482,
        6531,
        74,
        470,
        662,
        5695,
        13,
        7455,
        1418,
        12479,
        3514,
        21717,
        1224,
        12670,
        44415,
        674,
        2385,
        785,
        20759,
        51244
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31204530596733093,
      "compression_ratio": 1.5993376970291138,
      "no_speech_prob": 0.005553507711738348
    },
    {
      "id": 23,
      "seek": 12780,
      "start": 1460.8099938964845,
      "end": 1464.8899957275391,
      "text": " nacheditiert, weil die übrigens auch ähnliche Schwierigkeiten haben. Also wenn da Begriffe sind,",
      "tokens": [
        51244,
        5168,
        292,
        270,
        4859,
        11,
        7689,
        978,
        38215,
        2168,
        3078,
        12071,
        10185,
        17576,
        811,
        37545,
        3084,
        13,
        2743,
        4797,
        1120,
        879,
        861,
        31387,
        3290,
        11,
        51448
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31204530596733093,
      "compression_ratio": 1.5993376970291138,
      "no_speech_prob": 0.005553507711738348
    },
    {
      "id": 24,
      "seek": 12780,
      "start": 1464.8899957275391,
      "end": 1469.8899957275391,
      "text": " die die Menschen nicht kennen, dann ist das halt ein Problem und das muss im Manuell nachgearbeitet",
      "tokens": [
        51448,
        978,
        978,
        8397,
        1979,
        28445,
        11,
        3594,
        1418,
        1482,
        12479,
        1343,
        11676,
        674,
        1482,
        6425,
        566,
        2458,
        13789,
        5168,
        432,
        24024,
        302,
        51698
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31204530596733093,
      "compression_ratio": 1.5993376970291138,
      "no_speech_prob": 0.005553507711738348
    },
    {
      "id": 25,
      "seek": 15448,
      "start": 1469.8899957275391,
      "end": 1476.7700006103516,
      "text": " werden. Und den Aufwand können wir halt nicht leisten. Niemand von uns kann sich hinsetzen und",
      "tokens": [
        50364,
        4604,
        13,
        2719,
        1441,
        9462,
        33114,
        6310,
        1987,
        12479,
        1979,
        47013,
        13,
        426,
        39362,
        2957,
        2693,
        4028,
        3041,
        276,
        1292,
        24797,
        674,
        50708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2823503613471985,
      "compression_ratio": 1.6789772510528564,
      "no_speech_prob": 0.01223819237202406
    },
    {
      "id": 26,
      "seek": 15448,
      "start": 1476.7700006103516,
      "end": 1481.0499993896485,
      "text": " das Ding anhören und darunter schreiben. Und wir können eigentlich auch nicht ernsthaft jemanden",
      "tokens": [
        50708,
        1482,
        20558,
        18931,
        26377,
        674,
        4072,
        21777,
        48546,
        13,
        2719,
        1987,
        6310,
        10926,
        2168,
        1979,
        43412,
        25127,
        21717,
        268,
        50922
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2823503613471985,
      "compression_ratio": 1.6789772510528564,
      "no_speech_prob": 0.01223819237202406
    },
    {
      "id": 27,
      "seek": 15448,
      "start": 1481.0499993896485,
      "end": 1486.3299981689454,
      "text": " dafür bezahlen, weil wir im Prinzip kein Budget haben. Und deswegen ist das die einzige Möglichkeit,",
      "tokens": [
        50922,
        13747,
        10782,
        21128,
        11,
        7689,
        1987,
        566,
        47572,
        13424,
        33751,
        3084,
        13,
        2719,
        26482,
        1418,
        1482,
        978,
        47743,
        30662,
        11,
        51186
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2823503613471985,
      "compression_ratio": 1.6789772510528564,
      "no_speech_prob": 0.01223819237202406
    },
    {
      "id": 28,
      "seek": 15448,
      "start": 1486.3299981689454,
      "end": 1490.6500054931641,
      "text": " Transkripte zu bekommen. Und das ist eben auch tatsächlich wichtig. Und bei den Zusammenfassungen",
      "tokens": [
        51186,
        6531,
        74,
        470,
        662,
        68,
        2164,
        19256,
        13,
        2719,
        1482,
        1418,
        11375,
        2168,
        20796,
        13621,
        13,
        2719,
        4643,
        1441,
        29442,
        69,
        640,
        5084,
        51402
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2823503613471985,
      "compression_ratio": 1.6789772510528564,
      "no_speech_prob": 0.01223819237202406
    },
    {
      "id": 29,
      "seek": 15448,
      "start": 1490.6500054931641,
      "end": 1494.6500054931641,
      "text": " habe ich eben selber gemerkt, dass die… Also ich empfinde sie zumindest als nützlich, weil ich da",
      "tokens": [
        51402,
        6015,
        1893,
        11375,
        23888,
        7173,
        49015,
        11,
        2658,
        978,
        1260,
        2743,
        1893,
        4012,
        69,
        8274,
        2804,
        38082,
        3907,
        297,
        7695,
        16813,
        11,
        7689,
        1893,
        1120,
        51602
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2823503613471985,
      "compression_ratio": 1.6789772510528564,
      "no_speech_prob": 0.01223819237202406
    },
    {
      "id": 30,
      "seek": 15448,
      "start": 1494.6500054931641,
      "end": 1498.7700006103516,
      "text": " nochmal eine Idee davon habe, was in der Episode passiert ist. Und deswegen fand ich das halt",
      "tokens": [
        51602,
        26509,
        3018,
        32651,
        18574,
        6015,
        11,
        390,
        294,
        1163,
        19882,
        21671,
        1418,
        13,
        2719,
        26482,
        38138,
        1893,
        1482,
        12479,
        51808
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2823503613471985,
      "compression_ratio": 1.6789772510528564,
      "no_speech_prob": 0.01223819237202406
    },
    {
      "id": 31,
      "seek": 18336,
      "start": 1498.930004272461,
      "end": 1503.6500054931641,
      "text": " gut. Und das ist ja auch vielleicht das Allgemeine. Ich habe darüber auch bei Heise mal so einen",
      "tokens": [
        50372,
        5228,
        13,
        2719,
        1482,
        1418,
        2784,
        2168,
        12547,
        1482,
        1057,
        31964,
        533,
        13,
        3141,
        6015,
        21737,
        2168,
        4643,
        634,
        908,
        2806,
        370,
        4891,
        50608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2972771227359772,
      "compression_ratio": 1.6208053827285767,
      "no_speech_prob": 0.007229631766676903
    },
    {
      "id": 32,
      "seek": 18336,
      "start": 1503.6500054931641,
      "end": 1510.930004272461,
      "text": " Artikel geschrieben, eben auch in Bezug auf AI. Wenn wir jetzt also mehr Produktivität haben,",
      "tokens": [
        50608,
        5735,
        41486,
        47397,
        11,
        11375,
        2168,
        294,
        879,
        29742,
        2501,
        7318,
        13,
        7899,
        1987,
        4354,
        611,
        5417,
        44599,
        592,
        14053,
        3084,
        11,
        50972
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2972771227359772,
      "compression_ratio": 1.6208053827285767,
      "no_speech_prob": 0.007229631766676903
    },
    {
      "id": 33,
      "seek": 18336,
      "start": 1510.930004272461,
      "end": 1517.2900048828126,
      "text": " was auch immer das bedeutet. Also wir haben jetzt ja die Möglichkeit, mit wenig Aufwand eben diese",
      "tokens": [
        50972,
        390,
        2168,
        5578,
        1482,
        27018,
        13,
        2743,
        1987,
        3084,
        4354,
        2784,
        978,
        30662,
        11,
        2194,
        20911,
        9462,
        33114,
        11375,
        6705,
        51290
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2972771227359772,
      "compression_ratio": 1.6208053827285767,
      "no_speech_prob": 0.007229631766676903
    },
    {
      "id": 34,
      "seek": 18336,
      "start": 1517.2900048828126,
      "end": 1522.4900018310548,
      "text": " Sachen zu erzeugen mit AI. Und dadurch sind wir halt in dem Bereich produktiver. Also wenn ich",
      "tokens": [
        51290,
        26074,
        2164,
        1189,
        19303,
        268,
        2194,
        7318,
        13,
        2719,
        35472,
        3290,
        1987,
        12479,
        294,
        1371,
        26489,
        42816,
        1837,
        13,
        2743,
        4797,
        1893,
        51550
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2972771227359772,
      "compression_ratio": 1.6208053827285767,
      "no_speech_prob": 0.007229631766676903
    },
    {
      "id": 35,
      "seek": 18336,
      "start": 1522.4900018310548,
      "end": 1525.8099938964845,
      "text": " jetzt die Zusammenfassung schreiben würde oder die Stichworte, wenn wir die schreiben würden,",
      "tokens": [
        51550,
        4354,
        978,
        29442,
        69,
        40828,
        48546,
        11942,
        4513,
        978,
        745,
        480,
        86,
        12752,
        11,
        4797,
        1987,
        978,
        48546,
        27621,
        11,
        51716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2972771227359772,
      "compression_ratio": 1.6208053827285767,
      "no_speech_prob": 0.007229631766676903
    },
    {
      "id": 36,
      "seek": 21040,
      "start": 1525.8099938964845,
      "end": 1532.41,
      "text": " das würde halt viel länger dauern. Und dadurch machen wir halt mehr. Und da gibt es einen Begriff",
      "tokens": [
        50364,
        1482,
        11942,
        12479,
        5891,
        40935,
        37359,
        1248,
        13,
        2719,
        35472,
        7069,
        1987,
        12479,
        5417,
        13,
        2719,
        1120,
        6089,
        785,
        4891,
        879,
        32783,
        50694
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27272728085517883,
      "compression_ratio": 1.7028985023498535,
      "no_speech_prob": 0.04461643099784851
    },
    {
      "id": 37,
      "seek": 21040,
      "start": 1532.41,
      "end": 1540.3299981689454,
      "text": " für Rebound-Effekt. Ich glaube, so heißt der. Rebound. Genau. Wo du halt sagst, wenn etwas",
      "tokens": [
        50694,
        2959,
        1300,
        18767,
        12,
        36,
        602,
        8192,
        13,
        3141,
        13756,
        11,
        370,
        13139,
        1163,
        13,
        1300,
        18767,
        13,
        22340,
        13,
        6622,
        1581,
        12479,
        15274,
        372,
        11,
        4797,
        9569,
        51090
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27272728085517883,
      "compression_ratio": 1.7028985023498535,
      "no_speech_prob": 0.04461643099784851
    },
    {
      "id": 38,
      "seek": 21040,
      "start": 1540.3299981689454,
      "end": 1544.169994506836,
      "text": " billiger wird, einfacher wird, dann wird es irgendwie für neue Sachen genutzt und halt mehr",
      "tokens": [
        51090,
        2961,
        4810,
        4578,
        11,
        38627,
        4062,
        4578,
        11,
        3594,
        4578,
        785,
        20759,
        2959,
        16842,
        26074,
        1049,
        325,
        2682,
        674,
        12479,
        5417,
        51282
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27272728085517883,
      "compression_ratio": 1.7028985023498535,
      "no_speech_prob": 0.04461643099784851
    },
    {
      "id": 39,
      "seek": 21040,
      "start": 1544.169994506836,
      "end": 1551.2499963378907,
      "text": " genutzt. Und wenn also Sachen eben stromeffizienter werden, dann nutzt man halt mehr davon. Und das",
      "tokens": [
        51282,
        1049,
        325,
        2682,
        13,
        2719,
        4797,
        611,
        26074,
        11375,
        1056,
        423,
        602,
        590,
        1196,
        260,
        4604,
        11,
        3594,
        5393,
        2682,
        587,
        12479,
        5417,
        18574,
        13,
        2719,
        1482,
        51636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27272728085517883,
      "compression_ratio": 1.7028985023498535,
      "no_speech_prob": 0.04461643099784851
    },
    {
      "id": 40,
      "seek": 21040,
      "start": 1551.2499963378907,
      "end": 1554.2900048828126,
      "text": " ist glaube ich das, was wir hier beobachten in gewisser Weise. Und das ist auch das,",
      "tokens": [
        51636,
        1418,
        13756,
        1893,
        1482,
        11,
        390,
        1987,
        3296,
        312,
        996,
        20806,
        294,
        6906,
        23714,
        41947,
        13,
        2719,
        1482,
        1418,
        2168,
        1482,
        11,
        51788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27272728085517883,
      "compression_ratio": 1.7028985023498535,
      "no_speech_prob": 0.04461643099784851
    },
    {
      "id": 41,
      "seek": 23888,
      "start": 1554.2900048828126,
      "end": 1559.1300012207032,
      "text": " was ich in diesem heißen Blogpost geschrieben habe, weil ich eben nicht erwarten würde,",
      "tokens": [
        50364,
        390,
        1893,
        294,
        10975,
        39124,
        268,
        46693,
        23744,
        47397,
        6015,
        11,
        7689,
        1893,
        11375,
        1979,
        21715,
        11719,
        11942,
        11,
        50606
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3427937924861908,
      "compression_ratio": 1.53515625,
      "no_speech_prob": 0.021590137854218483
    },
    {
      "id": 42,
      "seek": 23888,
      "start": 1559.1300012207032,
      "end": 1570.169994506836,
      "text": " dass, also wenn wir tatsächlich höher Produktivität durch AI haben, ist meiner Ansicht nach eine offene",
      "tokens": [
        50606,
        2658,
        11,
        611,
        4797,
        1987,
        20796,
        48045,
        44599,
        592,
        14053,
        7131,
        7318,
        3084,
        11,
        1418,
        20529,
        14590,
        1405,
        5168,
        3018,
        766,
        1450,
        51158
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3427937924861908,
      "compression_ratio": 1.53515625,
      "no_speech_prob": 0.021590137854218483
    },
    {
      "id": 43,
      "seek": 23888,
      "start": 1570.169994506836,
      "end": 1574.6100122070313,
      "text": " Frage, aber das ist eine andere Diskussion, dann ist die nächste Frage, ob das durchschlägt zu",
      "tokens": [
        51158,
        13685,
        11,
        4340,
        1482,
        1418,
        3018,
        10490,
        45963,
        313,
        11,
        3594,
        1418,
        978,
        30661,
        13685,
        11,
        1111,
        1482,
        7131,
        6145,
        22882,
        10463,
        2164,
        51380
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3427937924861908,
      "compression_ratio": 1.53515625,
      "no_speech_prob": 0.021590137854218483
    },
    {
      "id": 44,
      "seek": 23888,
      "start": 1574.6100122070313,
      "end": 1580.41,
      "text": " weniger Menschen, die halt arbeiten. Mindestens in der Softwareentwicklung ist es so, dass wir halt",
      "tokens": [
        51380,
        23224,
        8397,
        11,
        978,
        12479,
        23162,
        13,
        13719,
        42624,
        294,
        1163,
        27428,
        317,
        16038,
        17850,
        1418,
        785,
        370,
        11,
        2658,
        1987,
        12479,
        51670
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3427937924861908,
      "compression_ratio": 1.53515625,
      "no_speech_prob": 0.021590137854218483
    },
    {
      "id": 45,
      "seek": 26500,
      "start": 1580.450008544922,
      "end": 1585.5700036621095,
      "text": " hoffentlich, glaube ich, die ganze Zeit Produktivitätsvorteile haben. Und ich würde",
      "tokens": [
        50366,
        1106,
        22805,
        11,
        13756,
        1893,
        11,
        978,
        18898,
        9394,
        44599,
        592,
        13187,
        1373,
        85,
        12752,
        794,
        3084,
        13,
        2719,
        1893,
        11942,
        50622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2922001779079437,
      "compression_ratio": 1.5510203838348389,
      "no_speech_prob": 0.012804139405488968
    },
    {
      "id": 46,
      "seek": 26500,
      "start": 1585.5700036621095,
      "end": 1590.2099877929688,
      "text": " behaupten, jetzt oder vor einiger Zeit, also bevor irgendwie dieser Downturn bei uns war,",
      "tokens": [
        50622,
        1540,
        13343,
        268,
        11,
        4354,
        4513,
        4245,
        1343,
        4810,
        9394,
        11,
        611,
        37591,
        20759,
        9053,
        44386,
        925,
        4643,
        2693,
        1516,
        11,
        50854
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2922001779079437,
      "compression_ratio": 1.5510203838348389,
      "no_speech_prob": 0.012804139405488968
    },
    {
      "id": 47,
      "seek": 26500,
      "start": 1590.2099877929688,
      "end": 1594.689998779297,
      "text": " in unserer Branche, zu dem Zeitpunkt gab es halt die meisten EntwicklerInnen. Trotzdem,",
      "tokens": [
        50854,
        294,
        20965,
        1603,
        22806,
        11,
        2164,
        1371,
        9394,
        31744,
        17964,
        785,
        12479,
        978,
        29708,
        29397,
        1918,
        4575,
        2866,
        13,
        1765,
        23934,
        11,
        51078
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2922001779079437,
      "compression_ratio": 1.5510203838348389,
      "no_speech_prob": 0.012804139405488968
    },
    {
      "id": 48,
      "seek": 26500,
      "start": 1594.689998779297,
      "end": 1600.1300012207032,
      "text": " dass die halt viel produktiver sind als die vor zehn Jahren oder so. Und deswegen bin ich halt",
      "tokens": [
        51078,
        2658,
        978,
        12479,
        5891,
        42816,
        1837,
        3290,
        3907,
        978,
        4245,
        33975,
        13080,
        4513,
        370,
        13,
        2719,
        26482,
        5171,
        1893,
        12479,
        51350
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2922001779079437,
      "compression_ratio": 1.5510203838348389,
      "no_speech_prob": 0.012804139405488968
    },
    {
      "id": 49,
      "seek": 26500,
      "start": 1600.1300012207032,
      "end": 1607.0500146484376,
      "text": " sehr unsicher, ob wir dann tatsächlich sozusagen Massenarbeitslosigkeit haben werden. Ich würde",
      "tokens": [
        51350,
        5499,
        2693,
        14934,
        11,
        1111,
        1987,
        3594,
        20796,
        33762,
        376,
        8356,
        289,
        21604,
        9389,
        16626,
        3084,
        4604,
        13,
        3141,
        11942,
        51696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2922001779079437,
      "compression_ratio": 1.5510203838348389,
      "no_speech_prob": 0.012804139405488968
    },
    {
      "id": 50,
      "seek": 29164,
      "start": 1607.0500146484376,
      "end": 1610.9699975585938,
      "text": " eher erwarten, dass wir halt andere Sachen halt dann noch produzieren. Und hier haben wir im",
      "tokens": [
        50364,
        24332,
        21715,
        11719,
        11,
        2658,
        1987,
        12479,
        10490,
        26074,
        12479,
        3594,
        3514,
        28093,
        5695,
        13,
        2719,
        3296,
        3084,
        1987,
        566,
        50560
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2819364666938782,
      "compression_ratio": 1.587499976158142,
      "no_speech_prob": 0.1419447511434555
    },
    {
      "id": 51,
      "seek": 29164,
      "start": 1610.9699975585938,
      "end": 1617.3699914550782,
      "text": " Prinzip genau das, wie du gerade sagtest, als kleines Beispiel. Ja, definitiv. Das ist auch",
      "tokens": [
        50560,
        47572,
        12535,
        1482,
        11,
        3355,
        1581,
        12117,
        15764,
        377,
        11,
        3907,
        9318,
        1652,
        13772,
        13,
        3530,
        11,
        28781,
        592,
        13,
        2846,
        1418,
        2168,
        50880
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2819364666938782,
      "compression_ratio": 1.587499976158142,
      "no_speech_prob": 0.1419447511434555
    },
    {
      "id": 52,
      "seek": 29164,
      "start": 1617.3699914550782,
      "end": 1624.1300012207032,
      "text": " bei mir, das Pendel schwingt hin und her. Und ich sehe, dass manche Sachen die KI gut machen kann.",
      "tokens": [
        50880,
        4643,
        3149,
        11,
        1482,
        38048,
        338,
        956,
        7904,
        83,
        14102,
        674,
        720,
        13,
        2719,
        1893,
        35995,
        11,
        2658,
        587,
        1876,
        26074,
        978,
        47261,
        5228,
        7069,
        4028,
        13,
        51218
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2819364666938782,
      "compression_ratio": 1.587499976158142,
      "no_speech_prob": 0.1419447511434555
    },
    {
      "id": 53,
      "seek": 29164,
      "start": 1624.1300012207032,
      "end": 1630.3300134277345,
      "text": " Sie kann mich enablen, sie kann mich unterstützen. Und andere Sachen, die klappen irgendwie ganz",
      "tokens": [
        51218,
        3559,
        4028,
        6031,
        9528,
        77,
        11,
        2804,
        4028,
        6031,
        43081,
        13,
        2719,
        10490,
        26074,
        11,
        978,
        33337,
        21278,
        20759,
        6312,
        51528
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2819364666938782,
      "compression_ratio": 1.587499976158142,
      "no_speech_prob": 0.1419447511434555
    },
    {
      "id": 54,
      "seek": 31492,
      "start": 1630.3699914550782,
      "end": 1636.2099877929688,
      "text": " schlecht. Also die Transcriptions, die lagen eine Weile dann so rum, weil das Problem war,",
      "tokens": [
        50366,
        32427,
        13,
        2743,
        978,
        6531,
        34173,
        11,
        978,
        287,
        4698,
        3018,
        492,
        794,
        3594,
        370,
        8347,
        11,
        7689,
        1482,
        11676,
        1516,
        11,
        50658
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2677774727344513,
      "compression_ratio": 1.5040322542190552,
      "no_speech_prob": 0.23874273896217346
    },
    {
      "id": 55,
      "seek": 31492,
      "start": 1636.2099877929688,
      "end": 1642.6100122070313,
      "text": " ja, ich hatte das Skript, aber ich musste dann immer es laufen lassen. Das hat irgendwie acht",
      "tokens": [
        50658,
        2784,
        11,
        1893,
        13299,
        1482,
        7324,
        470,
        662,
        11,
        4340,
        1893,
        34497,
        3594,
        5578,
        785,
        41647,
        16168,
        13,
        2846,
        2385,
        20759,
        43048,
        50978
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2677774727344513,
      "compression_ratio": 1.5040322542190552,
      "no_speech_prob": 0.23874273896217346
    },
    {
      "id": 56,
      "seek": 31492,
      "start": 1642.6100122070313,
      "end": 1649.450008544922,
      "text": " bis zehn Minuten gebraucht. Dann musste ich ein Pull-Request erstellen und habe mir gedacht,",
      "tokens": [
        50978,
        7393,
        33975,
        27593,
        1519,
        6198,
        10084,
        13,
        7455,
        34497,
        1893,
        1343,
        15074,
        12,
        8524,
        20343,
        11301,
        8581,
        674,
        6015,
        3149,
        33296,
        11,
        51320
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2677774727344513,
      "compression_ratio": 1.5040322542190552,
      "no_speech_prob": 0.23874273896217346
    },
    {
      "id": 57,
      "seek": 31492,
      "start": 1649.450008544922,
      "end": 1654.929989013672,
      "text": " eigentlich müsste ich es automatisieren. Und das war dann nämlich so der nächste Aha-Effekt,",
      "tokens": [
        51320,
        10926,
        42962,
        1893,
        785,
        28034,
        271,
        5695,
        13,
        2719,
        1482,
        1516,
        3594,
        21219,
        370,
        1163,
        30661,
        27448,
        12,
        36,
        602,
        8192,
        11,
        51594
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2677774727344513,
      "compression_ratio": 1.5040322542190552,
      "no_speech_prob": 0.23874273896217346
    },
    {
      "id": 58,
      "seek": 33952,
      "start": 1654.929989013672,
      "end": 1660.5299951171876,
      "text": " weil wir kennen das ja mit den Pipelines, die dann irgendwie nur auf dem Server laufen,",
      "tokens": [
        50364,
        7689,
        1987,
        28445,
        1482,
        2784,
        2194,
        1441,
        35396,
        9173,
        11,
        978,
        3594,
        20759,
        4343,
        2501,
        1371,
        25684,
        41647,
        11,
        50644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24663469195365906,
      "compression_ratio": 1.5365853309631348,
      "no_speech_prob": 0.014691673219203949
    },
    {
      "id": 59,
      "seek": 33952,
      "start": 1660.5299951171876,
      "end": 1665.41,
      "text": " die man irgendwie schlecht lokal ausprobieren kann und so. Und ich glaube, ich hatte da einen",
      "tokens": [
        50644,
        978,
        587,
        20759,
        32427,
        450,
        19990,
        3437,
        41990,
        5695,
        4028,
        674,
        370,
        13,
        2719,
        1893,
        13756,
        11,
        1893,
        13299,
        1120,
        4891,
        50888
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24663469195365906,
      "compression_ratio": 1.5365853309631348,
      "no_speech_prob": 0.014691673219203949
    },
    {
      "id": 60,
      "seek": 33952,
      "start": 1665.41,
      "end": 1671.450008544922,
      "text": " gemischten Ansatz, dass ich einmal den GitHub Copilot mit Issues gefüttert habe, direkt auf",
      "tokens": [
        50888,
        7173,
        5494,
        1147,
        14590,
        10300,
        11,
        2658,
        1893,
        11078,
        1441,
        23331,
        11579,
        31516,
        2194,
        38195,
        1247,
        11271,
        7695,
        391,
        83,
        6015,
        11,
        20315,
        2501,
        51190
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24663469195365906,
      "compression_ratio": 1.5365853309631348,
      "no_speech_prob": 0.014691673219203949
    },
    {
      "id": 61,
      "seek": 33952,
      "start": 1671.450008544922,
      "end": 1681.0899926757813,
      "text": " GitHub.com und einmal, dass ich es lokal gemacht habe und meiner KI Zugriff über das Command-Line-Tool",
      "tokens": [
        51190,
        23331,
        13,
        1112,
        674,
        11078,
        11,
        2658,
        1893,
        785,
        450,
        19990,
        12293,
        6015,
        674,
        20529,
        47261,
        34722,
        81,
        3661,
        4502,
        1482,
        17901,
        12,
        43,
        533,
        12,
        51,
        1092,
        51672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24663469195365906,
      "compression_ratio": 1.5365853309631348,
      "no_speech_prob": 0.014691673219203949
    },
    {
      "id": 62,
      "seek": 36568,
      "start": 1681.2099877929688,
      "end": 1688.2499963378907,
      "text": " GH auf die Workflows gegeben habe, dass es eben gucken konnte, wie sie laufen. Und ehrlich gesagt,",
      "tokens": [
        50370,
        40690,
        2501,
        978,
        6603,
        33229,
        32572,
        6015,
        11,
        2658,
        785,
        11375,
        33135,
        24058,
        11,
        3355,
        2804,
        41647,
        13,
        2719,
        40872,
        12260,
        11,
        50722
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32838451862335205,
      "compression_ratio": 1.422885537147522,
      "no_speech_prob": 0.09643307328224182
    },
    {
      "id": 63,
      "seek": 36568,
      "start": 1688.2499963378907,
      "end": 1697.3300134277345,
      "text": " es war eine Katastrophe. Also da hat er sich total schwer getan. Ich habe auch das Gefühl,",
      "tokens": [
        50722,
        785,
        1516,
        3018,
        8365,
        525,
        27194,
        13,
        2743,
        1120,
        2385,
        1189,
        3041,
        3217,
        23809,
        45599,
        13,
        3141,
        6015,
        2168,
        1482,
        29715,
        11,
        51176
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32838451862335205,
      "compression_ratio": 1.422885537147522,
      "no_speech_prob": 0.09643307328224182
    },
    {
      "id": 64,
      "seek": 36568,
      "start": 1697.3300134277345,
      "end": 1703.929989013672,
      "text": " ich habe den Code nicht reviewed. Ja, das lief alles irgendwie nebenbei. Mach mal und teste mal",
      "tokens": [
        51176,
        1893,
        6015,
        1441,
        15549,
        1979,
        3698,
        1093,
        292,
        13,
        3530,
        11,
        1482,
        4544,
        69,
        7874,
        20759,
        36098,
        21845,
        13,
        12089,
        2806,
        674,
        49586,
        2806,
        51506
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32838451862335205,
      "compression_ratio": 1.422885537147522,
      "no_speech_prob": 0.09643307328224182
    },
    {
      "id": 65,
      "seek": 38852,
      "start": 1704.0500146484376,
      "end": 1712.2099877929688,
      "text": " und schau mal, ob es funktioniert. Und ich habe die Befürchtung, dass er viel Code dupliziert hat.",
      "tokens": [
        50370,
        674,
        956,
        1459,
        2806,
        11,
        1111,
        785,
        26160,
        13,
        2719,
        1893,
        6015,
        978,
        879,
        12474,
        4701,
        1063,
        11,
        2658,
        1189,
        5891,
        15549,
        1581,
        564,
        43590,
        2385,
        13,
        50778
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25610119104385376,
      "compression_ratio": 1.5161290168762207,
      "no_speech_prob": 0.1496187001466751
    },
    {
      "id": 66,
      "seek": 38852,
      "start": 1712.2099877929688,
      "end": 1721.6100122070313,
      "text": " Also er hat angefangen. Es war irgendwie so eine Zeit, wo die Modelle sehr gern Bug-Files angelegt",
      "tokens": [
        50778,
        2743,
        1189,
        2385,
        43907,
        10784,
        13,
        2313,
        1516,
        20759,
        370,
        3018,
        9394,
        11,
        6020,
        978,
        6583,
        4434,
        5499,
        38531,
        23821,
        12,
        37,
        4680,
        15495,
        22745,
        51248
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25610119104385376,
      "compression_ratio": 1.5161290168762207,
      "no_speech_prob": 0.1496187001466751
    },
    {
      "id": 67,
      "seek": 38852,
      "start": 1721.6100122070313,
      "end": 1726.3699914550782,
      "text": " haben, Backup-Files oder neue Versionen von den Files, obwohl ich immer gesagt habe,",
      "tokens": [
        51248,
        3084,
        11,
        5833,
        1010,
        12,
        37,
        4680,
        4513,
        16842,
        12226,
        17068,
        2957,
        1441,
        479,
        4680,
        11,
        48428,
        1893,
        5578,
        12260,
        6015,
        11,
        51486
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25610119104385376,
      "compression_ratio": 1.5161290168762207,
      "no_speech_prob": 0.1496187001466751
    },
    {
      "id": 68,
      "seek": 38852,
      "start": 1726.3699914550782,
      "end": 1732.2900048828126,
      "text": " du bist hier unter Versionskontrolle, musst du nicht machen. Und er hatte eben auch Probleme",
      "tokens": [
        51486,
        1581,
        18209,
        3296,
        8662,
        12226,
        626,
        74,
        896,
        45344,
        11,
        31716,
        1581,
        1979,
        7069,
        13,
        2719,
        1189,
        13299,
        11375,
        2168,
        32891,
        51782
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25610119104385376,
      "compression_ratio": 1.5161290168762207,
      "no_speech_prob": 0.1496187001466751
    },
    {
      "id": 69,
      "seek": 41688,
      "start": 1732.3300134277345,
      "end": 1740.3699914550782,
      "text": " mit den Berechtigungen, dass er halt von meinem Repository in das Software-Architektur im Stream",
      "tokens": [
        50366,
        2194,
        1441,
        17684,
        4701,
        328,
        5084,
        11,
        2658,
        1189,
        12479,
        2957,
        24171,
        3696,
        9598,
        827,
        294,
        1482,
        27428,
        12,
        10683,
        339,
        642,
        2320,
        374,
        566,
        24904,
        50768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27237582206726074,
      "compression_ratio": 1.424390196800232,
      "no_speech_prob": 0.011677074246108532
    },
    {
      "id": 70,
      "seek": 41688,
      "start": 1740.3699914550782,
      "end": 1751.0100061035157,
      "text": " Repository das Ganze pushen kann. Und da war ich sehr froh, als es dann irgendwann lief. Aber es",
      "tokens": [
        50768,
        3696,
        9598,
        827,
        1482,
        35206,
        2944,
        268,
        4028,
        13,
        2719,
        1120,
        1516,
        1893,
        5499,
        9795,
        71,
        11,
        3907,
        785,
        3594,
        34313,
        4544,
        69,
        13,
        5992,
        785,
        51300
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27237582206726074,
      "compression_ratio": 1.424390196800232,
      "no_speech_prob": 0.011677074246108532
    },
    {
      "id": 71,
      "seek": 41688,
      "start": 1751.0100061035157,
      "end": 1759.2099877929688,
      "text": " kam mir fragil vor. Das Code weiß nicht. Also die Code-Basis ist da glaube ich nicht mehr so gut.",
      "tokens": [
        51300,
        9727,
        3149,
        9241,
        388,
        4245,
        13,
        2846,
        15549,
        13385,
        1979,
        13,
        2743,
        978,
        15549,
        12,
        33,
        26632,
        1418,
        1120,
        13756,
        1893,
        1979,
        5417,
        370,
        5228,
        13,
        51710
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27237582206726074,
      "compression_ratio": 1.424390196800232,
      "no_speech_prob": 0.011677074246108532
    },
    {
      "id": 72,
      "seek": 44380,
      "start": 1759.3699914550782,
      "end": 1767.3300134277345,
      "text": " Läuft, aber fragil. Und da bin ich dann noch zu einem Moment gekommen, wo ich gemerkt habe,",
      "tokens": [
        50372,
        441,
        737,
        25005,
        11,
        4340,
        9241,
        388,
        13,
        2719,
        1120,
        5171,
        1893,
        3594,
        3514,
        2164,
        6827,
        19093,
        32732,
        11,
        6020,
        1893,
        7173,
        49015,
        6015,
        11,
        50770
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2485259473323822,
      "compression_ratio": 1.5291666984558105,
      "no_speech_prob": 0.019115379080176353
    },
    {
      "id": 73,
      "seek": 44380,
      "start": 1767.3300134277345,
      "end": 1775.7699853515626,
      "text": " geht so gar nicht. Weil irgendwann, ich wollte die Transkription anschmeißen und er lief auf",
      "tokens": [
        50770,
        7095,
        370,
        3691,
        1979,
        13,
        18665,
        34313,
        11,
        1893,
        24509,
        978,
        6531,
        74,
        470,
        1695,
        31508,
        1398,
        6230,
        268,
        674,
        1189,
        4544,
        69,
        2501,
        51192
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2485259473323822,
      "compression_ratio": 1.5291666984558105,
      "no_speech_prob": 0.019115379080176353
    },
    {
      "id": 74,
      "seek": 44380,
      "start": 1775.7699853515626,
      "end": 1782.5700036621095,
      "text": " einen Berechtigungsfehler und nichts ging. Ich habe die KI angeschmissen, habe gesagt,",
      "tokens": [
        51192,
        4891,
        17684,
        4701,
        328,
        5846,
        33865,
        1918,
        674,
        13004,
        21924,
        13,
        3141,
        6015,
        978,
        47261,
        2562,
        22320,
        76,
        10987,
        11,
        6015,
        12260,
        11,
        51532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2485259473323822,
      "compression_ratio": 1.5291666984558105,
      "no_speech_prob": 0.019115379080176353
    },
    {
      "id": 75,
      "seek": 44380,
      "start": 1782.5700036621095,
      "end": 1788.3300134277345,
      "text": " guck mal da Fehler, fix das. Ich war mir nicht so sicher, ob ich da noch irgendwie mit der KI",
      "tokens": [
        51532,
        695,
        547,
        2806,
        1120,
        48101,
        11,
        3191,
        1482,
        13,
        3141,
        1516,
        3149,
        1979,
        370,
        18623,
        11,
        1111,
        1893,
        1120,
        3514,
        20759,
        2194,
        1163,
        47261,
        51820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2485259473323822,
      "compression_ratio": 1.5291666984558105,
      "no_speech_prob": 0.019115379080176353
    },
    {
      "id": 76,
      "seek": 47292,
      "start": 1788.450008544922,
      "end": 1794.450008544922,
      "text": " was geändert hatte, das dadurch broken war. Und die KI so, ach ja, klar, warum hast du hier",
      "tokens": [
        50370,
        390,
        1519,
        34945,
        13299,
        11,
        1482,
        35472,
        738,
        8406,
        1516,
        13,
        2719,
        978,
        47261,
        370,
        11,
        2800,
        2784,
        11,
        14743,
        11,
        24331,
        6581,
        1581,
        3296,
        50670
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2676526606082916,
      "compression_ratio": 1.7021276950836182,
      "no_speech_prob": 0.010983268730342388
    },
    {
      "id": 77,
      "seek": 47292,
      "start": 1794.450008544922,
      "end": 1798.649990234375,
      "text": " einen Personal Access Token? Können wir doch rausschmeißen, weil du hast ja hier Berechtigung",
      "tokens": [
        50670,
        4891,
        25317,
        17166,
        314,
        8406,
        30,
        29077,
        2866,
        1987,
        9243,
        3342,
        2023,
        339,
        1398,
        6230,
        268,
        11,
        7689,
        1581,
        6581,
        2784,
        3296,
        17684,
        4701,
        21034,
        50880
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2676526606082916,
      "compression_ratio": 1.7021276950836182,
      "no_speech_prob": 0.010983268730342388
    },
    {
      "id": 78,
      "seek": 47292,
      "start": 1798.649990234375,
      "end": 1807.0899926757813,
      "text": " in der Action und hat das rausgeschmissen. Und dann haben wir es ausprobiert und dann ist weiter",
      "tokens": [
        50880,
        294,
        1163,
        16261,
        674,
        2385,
        1482,
        17202,
        23378,
        76,
        10987,
        13,
        2719,
        3594,
        3084,
        1987,
        785,
        3437,
        41990,
        4859,
        674,
        3594,
        1418,
        8988,
        51302
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2676526606082916,
      "compression_ratio": 1.7021276950836182,
      "no_speech_prob": 0.010983268730342388
    },
    {
      "id": 79,
      "seek": 47292,
      "start": 1807.0899926757813,
      "end": 1811.929989013672,
      "text": " unten ein Berechtigungsfehler passiert. Und da ist mir auf einmal ein Licht aufgegangen. Er wollte",
      "tokens": [
        51302,
        25693,
        1343,
        17684,
        4701,
        328,
        5846,
        33865,
        1918,
        21671,
        13,
        2719,
        1120,
        1418,
        3149,
        2501,
        11078,
        1343,
        32917,
        35031,
        47152,
        13,
        3300,
        24509,
        51544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2676526606082916,
      "compression_ratio": 1.7021276950836182,
      "no_speech_prob": 0.010983268730342388
    },
    {
      "id": 80,
      "seek": 47292,
      "start": 1811.929989013672,
      "end": 1817.7699853515626,
      "text": " dann schon anfangen und weiter unten den Berechtigungsfehler auch beheben. Aber das eigentliche",
      "tokens": [
        51544,
        3594,
        4981,
        33709,
        10784,
        674,
        8988,
        25693,
        1441,
        17684,
        4701,
        328,
        5846,
        33865,
        1918,
        2168,
        312,
        675,
        1799,
        13,
        5992,
        1482,
        10926,
        68,
        51836
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2676526606082916,
      "compression_ratio": 1.7021276950836182,
      "no_speech_prob": 0.010983268730342388
    },
    {
      "id": 81,
      "seek": 50236,
      "start": 1817.7699853515626,
      "end": 1824.9699975585938,
      "text": " Problem war ein ganz anderes, denn ich hatte ein temporäres Personal Access Token gesetzt und",
      "tokens": [
        50364,
        11676,
        1516,
        1343,
        6312,
        31426,
        11,
        10471,
        1893,
        13299,
        1343,
        8219,
        737,
        495,
        25317,
        17166,
        314,
        8406,
        5019,
        3524,
        674,
        50724
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2125997394323349,
      "compression_ratio": 1.573770523071289,
      "no_speech_prob": 0.0022516073659062386
    },
    {
      "id": 82,
      "seek": 50236,
      "start": 1824.9699975585938,
      "end": 1830.4900170898438,
      "text": " diese Berechtigung war ausgelaufen. Das hätte er eigentlich erkennen müssen. Aber er hat eben da",
      "tokens": [
        50724,
        6705,
        17684,
        4701,
        21034,
        1516,
        3437,
        10345,
        20748,
        13,
        2846,
        20041,
        1189,
        10926,
        45720,
        9013,
        13,
        5992,
        1189,
        2385,
        11375,
        1120,
        51000
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2125997394323349,
      "compression_ratio": 1.573770523071289,
      "no_speech_prob": 0.0022516073659062386
    },
    {
      "id": 83,
      "seek": 50236,
      "start": 1830.4900170898438,
      "end": 1837.3700219726563,
      "text": " rumgefummelt am Code, hat nicht den eigentlichen Grund gefunden und hätte den Code jetzt komplett",
      "tokens": [
        51000,
        8347,
        13529,
        40879,
        2018,
        669,
        15549,
        11,
        2385,
        1979,
        1441,
        10926,
        268,
        13941,
        36923,
        674,
        20041,
        1441,
        15549,
        4354,
        32261,
        51344
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2125997394323349,
      "compression_ratio": 1.573770523071289,
      "no_speech_prob": 0.0022516073659062386
    },
    {
      "id": 84,
      "seek": 50236,
      "start": 1837.3700219726563,
      "end": 1845.5299951171876,
      "text": " umgeschmissen und sich in komischen Sachen verrannt. Das Ding ist, im ersten Stück reichen",
      "tokens": [
        51344,
        1105,
        23378,
        76,
        10987,
        674,
        3041,
        294,
        5207,
        6282,
        26074,
        1306,
        4257,
        580,
        13,
        2846,
        20558,
        1418,
        11,
        566,
        17324,
        31146,
        319,
        18613,
        51752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2125997394323349,
      "compression_ratio": 1.573770523071289,
      "no_speech_prob": 0.0022516073659062386
    },
    {
      "id": 85,
      "seek": 53012,
      "start": 1845.5299951171876,
      "end": 1851.0500146484376,
      "text": " die normalen Berechtigungen aus, Open Source Repository Pull. Im zweiten Bereich braucht es das",
      "tokens": [
        50364,
        978,
        2710,
        268,
        17684,
        4701,
        328,
        5084,
        3437,
        11,
        7238,
        29629,
        3696,
        9598,
        827,
        15074,
        13,
        4331,
        39943,
        26489,
        22623,
        785,
        1482,
        50640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.255247563123703,
      "compression_ratio": 1.50390625,
      "no_speech_prob": 0.004680812358856201
    },
    {
      "id": 86,
      "seek": 53012,
      "start": 1851.0500146484376,
      "end": 1857.7300073242188,
      "text": " Personal Access Token, um zu pushen oder den Pull Request zu stellen. Und das war ihm nicht",
      "tokens": [
        50640,
        25317,
        17166,
        314,
        8406,
        11,
        1105,
        2164,
        2944,
        268,
        4513,
        1441,
        15074,
        1300,
        20343,
        2164,
        24407,
        13,
        2719,
        1482,
        1516,
        16021,
        1979,
        50974
      ],
      "temperature": 0.0,
      "avg_logprob": -0.255247563123703,
      "compression_ratio": 1.50390625,
      "no_speech_prob": 0.004680812358856201
    },
    {
      "id": 87,
      "seek": 53012,
      "start": 1857.7300073242188,
      "end": 1864.3700219726563,
      "text": " aufgefallen. Und da habe ich gemerkt, dass er eben in diesem relativ kleinen Stück Code anscheinend",
      "tokens": [
        50974,
        35031,
        24425,
        13,
        2719,
        1120,
        6015,
        1893,
        7173,
        49015,
        11,
        2658,
        1189,
        11375,
        294,
        10975,
        21960,
        26512,
        31146,
        15549,
        1567,
        1876,
        259,
        521,
        51306
      ],
      "temperature": 0.0,
      "avg_logprob": -0.255247563123703,
      "compression_ratio": 1.50390625,
      "no_speech_prob": 0.004680812358856201
    },
    {
      "id": 88,
      "seek": 53012,
      "start": 1864.3700219726563,
      "end": 1870.7300073242188,
      "text": " den Überblick verloren hat, das mentale Modell über seinen eigenen Code nicht mehr bewahrt hat",
      "tokens": [
        51306,
        1441,
        18086,
        38263,
        44884,
        2385,
        11,
        1482,
        3074,
        1220,
        6583,
        898,
        4502,
        24427,
        28702,
        15549,
        1979,
        5417,
        17897,
        5398,
        83,
        2385,
        51624
      ],
      "temperature": 0.0,
      "avg_logprob": -0.255247563123703,
      "compression_ratio": 1.50390625,
      "no_speech_prob": 0.004680812358856201
    },
    {
      "id": 89,
      "seek": 55532,
      "start": 1870.7300073242188,
      "end": 1878.5699731445313,
      "text": " und deswegen das nicht editieren oder fixen konnte. Genau, also nochmal ein Reminder sozusagen.",
      "tokens": [
        50364,
        674,
        26482,
        1482,
        1979,
        8129,
        5695,
        4513,
        3191,
        268,
        24058,
        13,
        22340,
        11,
        611,
        26509,
        1343,
        4080,
        5669,
        33762,
        13,
        50756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41161659359931946,
      "compression_ratio": 1.4126213788986206,
      "no_speech_prob": 0.130990132689476
    },
    {
      "id": 90,
      "seek": 55532,
      "start": 1878.5699731445313,
      "end": 1883.129970703125,
      "text": " Nicht die Dinger sind Textgeneratoren, sodass sie auf Basis von dem, was sie reinbekommen hat,",
      "tokens": [
        50756,
        22629,
        978,
        413,
        6911,
        3290,
        18643,
        21848,
        267,
        10948,
        11,
        262,
        378,
        640,
        2804,
        2501,
        5859,
        271,
        2957,
        1371,
        11,
        390,
        2804,
        6561,
        650,
        13675,
        2385,
        11,
        50984
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41161659359931946,
      "compression_ratio": 1.4126213788986206,
      "no_speech_prob": 0.130990132689476
    },
    {
      "id": 91,
      "seek": 55532,
      "start": 1883.129970703125,
      "end": 1889.41,
      "text": " irgendwelchen Text generieren. Ich würde behaupten, es gibt da kein mentales Modell. Aber nicht die",
      "tokens": [
        50984,
        3418,
        432,
        273,
        45512,
        2470,
        18643,
        1337,
        5695,
        13,
        3141,
        11942,
        1540,
        13343,
        268,
        11,
        785,
        6089,
        1120,
        13424,
        3074,
        4229,
        6583,
        898,
        13,
        5992,
        1979,
        978,
        51298
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41161659359931946,
      "compression_ratio": 1.4126213788986206,
      "no_speech_prob": 0.130990132689476
    },
    {
      "id": 92,
      "seek": 57400,
      "start": 1889.41,
      "end": 1904.0099755859376,
      "text": " Type. Das andere ist, wir kommen ja noch dazu, wie wir es auf die Webseite tun. Und was ich",
      "tokens": [
        50364,
        15576,
        13,
        2846,
        10490,
        1418,
        11,
        1987,
        11729,
        2784,
        3514,
        13034,
        11,
        3355,
        1987,
        785,
        2501,
        978,
        9573,
        405,
        642,
        4267,
        13,
        2719,
        390,
        1893,
        51094
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41306817531585693,
      "compression_ratio": 1.5555555820465088,
      "no_speech_prob": 0.2970787286758423
    },
    {
      "id": 93,
      "seek": 57400,
      "start": 1904.0099755859376,
      "end": 1908.7300073242188,
      "text": " mittlerweile bei mir, wenn ich irgendwelche Sachen mache, wie zum Beispiel jetzt die Webseite",
      "tokens": [
        51094,
        41999,
        4643,
        3149,
        11,
        4797,
        1893,
        26455,
        338,
        1876,
        26074,
        28289,
        11,
        3355,
        5919,
        13772,
        4354,
        978,
        9573,
        405,
        642,
        51330
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41306817531585693,
      "compression_ratio": 1.5555555820465088,
      "no_speech_prob": 0.2970787286758423
    },
    {
      "id": 94,
      "seek": 57400,
      "start": 1908.7300073242188,
      "end": 1914.0500146484376,
      "text": " editieren, was mir da zugutekommt, ist, dass ich mit ChitchiPT die Möglichkeit habe, zu sagen,",
      "tokens": [
        51330,
        8129,
        5695,
        11,
        390,
        3149,
        1120,
        33507,
        325,
        916,
        22230,
        11,
        1418,
        11,
        2658,
        1893,
        2194,
        761,
        1549,
        72,
        47,
        51,
        978,
        30662,
        6015,
        11,
        2164,
        8360,
        11,
        51596
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41306817531585693,
      "compression_ratio": 1.5555555820465088,
      "no_speech_prob": 0.2970787286758423
    },
    {
      "id": 95,
      "seek": 57400,
      "start": 1914.0500146484376,
      "end": 1918.0099755859376,
      "text": " okay, sagt mir mal, wie ich dieses oder jenes auf die Reihe bekomme. Da kommen gute Vorschläge.",
      "tokens": [
        51596,
        1392,
        11,
        15764,
        3149,
        2806,
        11,
        3355,
        1893,
        12113,
        4513,
        361,
        25973,
        2501,
        978,
        34549,
        675,
        9393,
        15117,
        13,
        3933,
        11729,
        21476,
        31438,
        11439,
        737,
        432,
        13,
        51794
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41306817531585693,
      "compression_ratio": 1.5555555820465088,
      "no_speech_prob": 0.2970787286758423
    },
    {
      "id": 96,
      "seek": 60260,
      "start": 1918.129970703125,
      "end": 1924.2099877929688,
      "text": " Das bedeutet aber, dass ich mir im Prinzip Webrecherche nur spare. Das, was du ja beschreibst,",
      "tokens": [
        50370,
        2846,
        27018,
        4340,
        11,
        2658,
        1893,
        3149,
        566,
        47572,
        9573,
        265,
        6759,
        1876,
        4343,
        13798,
        13,
        2846,
        11,
        390,
        1581,
        2784,
        17498,
        38606,
        372,
        11,
        50674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29560330510139465,
      "compression_ratio": 1.6666666269302368,
      "no_speech_prob": 0.004133511800318956
    },
    {
      "id": 97,
      "seek": 60260,
      "start": 1924.2099877929688,
      "end": 1930.0899926757813,
      "text": " ist eigentlich, mach mal und implementiere mal. Und das, was du jetzt gerade beschreibst,",
      "tokens": [
        50674,
        1418,
        10926,
        11,
        2246,
        2806,
        674,
        4445,
        14412,
        2806,
        13,
        2719,
        1482,
        11,
        390,
        1581,
        4354,
        12117,
        17498,
        38606,
        372,
        11,
        50968
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29560330510139465,
      "compression_ratio": 1.6666666269302368,
      "no_speech_prob": 0.004133511800318956
    },
    {
      "id": 98,
      "seek": 60260,
      "start": 1930.0899926757813,
      "end": 1939.2099877929688,
      "text": " ist ein gutes Beispiel, um es platt zu sagen, das funktioniert eigentlich nicht. Denn was an",
      "tokens": [
        50968,
        1418,
        1343,
        45859,
        13772,
        11,
        1105,
        785,
        499,
        1591,
        2164,
        8360,
        11,
        1482,
        26160,
        10926,
        1979,
        13,
        19027,
        390,
        364,
        51424
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29560330510139465,
      "compression_ratio": 1.6666666269302368,
      "no_speech_prob": 0.004133511800318956
    },
    {
      "id": 99,
      "seek": 60260,
      "start": 1939.2099877929688,
      "end": 1944.2900048828126,
      "text": " irgendeiner Stelle dann immer wieder passiert, ist genau das, was wir jetzt hier gerade sehen. Du",
      "tokens": [
        51424,
        3418,
        27429,
        4564,
        26629,
        3594,
        5578,
        6216,
        21671,
        11,
        1418,
        12535,
        1482,
        11,
        390,
        1987,
        4354,
        3296,
        12117,
        11333,
        13,
        5153,
        51678
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29560330510139465,
      "compression_ratio": 1.6666666269302368,
      "no_speech_prob": 0.004133511800318956
    },
    {
      "id": 100,
      "seek": 62888,
      "start": 1944.41,
      "end": 1948.4900170898438,
      "text": " fängst an und sagst, naja, das funktioniert ja so und so und so. Und da sind folgende Themen,",
      "tokens": [
        50370,
        283,
        9935,
        372,
        364,
        674,
        15274,
        372,
        11,
        1667,
        2938,
        11,
        1482,
        26160,
        2784,
        370,
        674,
        370,
        674,
        370,
        13,
        2719,
        1120,
        3290,
        3339,
        27429,
        39229,
        11,
        50574
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31717878580093384,
      "compression_ratio": 1.6666666269302368,
      "no_speech_prob": 0.06945303827524185
    },
    {
      "id": 101,
      "seek": 62888,
      "start": 1948.4900170898438,
      "end": 1954.0899926757813,
      "text": " also ein Security-Thema an dieser Stelle. Das müssen wir fixen. Und dann musst du halt in",
      "tokens": [
        50574,
        611,
        1343,
        11164,
        12,
        2434,
        5619,
        364,
        9053,
        26629,
        13,
        2846,
        9013,
        1987,
        3191,
        268,
        13,
        2719,
        3594,
        31716,
        1581,
        12479,
        294,
        50854
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31717878580093384,
      "compression_ratio": 1.6666666269302368,
      "no_speech_prob": 0.06945303827524185
    },
    {
      "id": 102,
      "seek": 62888,
      "start": 1954.0899926757813,
      "end": 1959.5299951171876,
      "text": " diese Abstraktion reingreifen. Du bist jetzt nicht mehr auf dieser Ebene, dass du sagst,",
      "tokens": [
        50854,
        6705,
        2847,
        19639,
        9780,
        319,
        278,
        265,
        25076,
        13,
        5153,
        18209,
        4354,
        1979,
        5417,
        2501,
        9053,
        20418,
        1450,
        11,
        2658,
        1581,
        15274,
        372,
        11,
        51126
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31717878580093384,
      "compression_ratio": 1.6666666269302368,
      "no_speech_prob": 0.06945303827524185
    },
    {
      "id": 103,
      "seek": 62888,
      "start": 1959.5299951171876,
      "end": 1964.5299951171876,
      "text": " mach mal und löse mal. Mir egal. Ich will nicht verstehen, wie es funktioniert. Sondern du musst",
      "tokens": [
        51126,
        2246,
        2806,
        674,
        25209,
        405,
        2806,
        13,
        9421,
        31528,
        13,
        3141,
        486,
        1979,
        37352,
        11,
        3355,
        785,
        26160,
        13,
        318,
        10881,
        1581,
        31716,
        51376
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31717878580093384,
      "compression_ratio": 1.6666666269302368,
      "no_speech_prob": 0.06945303827524185
    },
    {
      "id": 104,
      "seek": 62888,
      "start": 1964.5299951171876,
      "end": 1970.3299829101563,
      "text": " dir verstehen, es gibt halt GitHub. GitHub hat irgendwelche Security-Tokens. Da gibt es",
      "tokens": [
        51376,
        4746,
        37352,
        11,
        785,
        6089,
        12479,
        23331,
        13,
        23331,
        2385,
        26455,
        338,
        1876,
        11164,
        12,
        18797,
        694,
        13,
        3933,
        6089,
        785,
        51666
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31717878580093384,
      "compression_ratio": 1.6666666269302368,
      "no_speech_prob": 0.06945303827524185
    },
    {
      "id": 105,
      "seek": 65492,
      "start": 1970.3299829101563,
      "end": 1974.7300073242188,
      "text": " offensichtlich Lokale und andere. Und irgendwie ist da etwas schief. Und deswegen muss ich das",
      "tokens": [
        50364,
        766,
        694,
        41971,
        46278,
        1220,
        674,
        10490,
        13,
        2719,
        20759,
        1418,
        1120,
        9569,
        956,
        2521,
        13,
        2719,
        26482,
        6425,
        1893,
        1482,
        50584
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31327882409095764,
      "compression_ratio": 1.6435985565185547,
      "no_speech_prob": 0.12747406959533691
    },
    {
      "id": 106,
      "seek": 65492,
      "start": 1974.7300073242188,
      "end": 1980.4499780273438,
      "text": " halt fixen. Was bedeutet, ich komme eben nicht auf die höhere Abstraktionsschicht, sondern an",
      "tokens": [
        50584,
        12479,
        3191,
        268,
        13,
        3027,
        27018,
        11,
        1893,
        31194,
        11375,
        1979,
        2501,
        978,
        13531,
        6703,
        2847,
        19639,
        2320,
        626,
        6145,
        1405,
        11,
        11465,
        364,
        50870
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31327882409095764,
      "compression_ratio": 1.6435985565185547,
      "no_speech_prob": 0.12747406959533691
    },
    {
      "id": 107,
      "seek": 65492,
      "start": 1980.4499780273438,
      "end": 1986.8500024414063,
      "text": " bestimmten Stellen bricht es eben und ich muss irgendwie reingreifen. Das beobachte ich an",
      "tokens": [
        50870,
        35180,
        1147,
        41893,
        738,
        1405,
        785,
        11375,
        674,
        1893,
        6425,
        20759,
        319,
        278,
        265,
        25076,
        13,
        2846,
        312,
        996,
        26136,
        1893,
        364,
        51190
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31327882409095764,
      "compression_ratio": 1.6435985565185547,
      "no_speech_prob": 0.12747406959533691
    },
    {
      "id": 108,
      "seek": 65492,
      "start": 1986.8500024414063,
      "end": 1994.0500146484376,
      "text": " extrem vielen Stellen, was eben dazu führt, dass ich mir überhaupt gar nicht vorstellen kann,",
      "tokens": [
        51190,
        4040,
        19885,
        41893,
        11,
        390,
        11375,
        13034,
        39671,
        11,
        2658,
        1893,
        3149,
        20023,
        3691,
        1979,
        34346,
        4028,
        11,
        51550
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31327882409095764,
      "compression_ratio": 1.6435985565185547,
      "no_speech_prob": 0.12747406959533691
    },
    {
      "id": 109,
      "seek": 65492,
      "start": 1994.0500146484376,
      "end": 1998.7699853515626,
      "text": " wie halt Nicht-EntwicklerInnen damit irgendetwas auf die Reihe bekommen sollen. Weil an der Stelle",
      "tokens": [
        51550,
        3355,
        12479,
        22629,
        12,
        42837,
        16038,
        1918,
        4575,
        2866,
        9479,
        11093,
        302,
        6569,
        2501,
        978,
        34549,
        675,
        19256,
        24713,
        13,
        18665,
        364,
        1163,
        26629,
        51786
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31327882409095764,
      "compression_ratio": 1.6435985565185547,
      "no_speech_prob": 0.12747406959533691
    },
    {
      "id": 110,
      "seek": 68336,
      "start": 1998.8100244140626,
      "end": 2004.690029296875,
      "text": " werden sie halt gescheitert. Und dann ist halt Schluss. Weil eben solche Menschen dann da nicht",
      "tokens": [
        50366,
        4604,
        2804,
        12479,
        5019,
        1876,
        270,
        911,
        13,
        2719,
        3594,
        1418,
        12479,
        36573,
        13,
        18665,
        11375,
        29813,
        8397,
        3594,
        1120,
        1979,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.326904296875,
      "compression_ratio": 1.7619047164916992,
      "no_speech_prob": 0.007344512268900871
    },
    {
      "id": 111,
      "seek": 68336,
      "start": 2004.690029296875,
      "end": 2008.0099755859376,
      "text": " reingreifen können und sagen können, ach so, ja klar, das funktioniert ja folgendermaßen.",
      "tokens": [
        50660,
        319,
        278,
        265,
        25076,
        6310,
        674,
        8360,
        6310,
        11,
        2800,
        370,
        11,
        2784,
        14743,
        11,
        1482,
        26160,
        2784,
        3339,
        9395,
        39994,
        8989,
        13,
        50826
      ],
      "temperature": 0.0,
      "avg_logprob": -0.326904296875,
      "compression_ratio": 1.7619047164916992,
      "no_speech_prob": 0.007344512268900871
    },
    {
      "id": 112,
      "seek": 68336,
      "start": 2008.0099755859376,
      "end": 2015.5699731445313,
      "text": " Eben nicht Security-Token, so funktioniert die Security, das ist halt GitHub. Sondern die können",
      "tokens": [
        50826,
        462,
        1799,
        1979,
        11164,
        12,
        51,
        8406,
        11,
        370,
        26160,
        978,
        11164,
        11,
        1482,
        1418,
        12479,
        23331,
        13,
        318,
        10881,
        978,
        6310,
        51204
      ],
      "temperature": 0.0,
      "avg_logprob": -0.326904296875,
      "compression_ratio": 1.7619047164916992,
      "no_speech_prob": 0.007344512268900871
    },
    {
      "id": 113,
      "seek": 68336,
      "start": 2015.5699731445313,
      "end": 2021.93001953125,
      "text": " das dann eben auf der Ebene nicht mehr verfolgen und dann ist eben Schluss. Absolut. Und du hattest",
      "tokens": [
        51204,
        1482,
        3594,
        11375,
        2501,
        1163,
        20418,
        1450,
        1979,
        5417,
        1306,
        7082,
        1766,
        674,
        3594,
        1418,
        11375,
        36573,
        13,
        5813,
        2308,
        13,
        2719,
        1581,
        276,
        1591,
        377,
        51522
      ],
      "temperature": 0.0,
      "avg_logprob": -0.326904296875,
      "compression_ratio": 1.7619047164916992,
      "no_speech_prob": 0.007344512268900871
    },
    {
      "id": 114,
      "seek": 68336,
      "start": 2021.93001953125,
      "end": 2027.0899926757813,
      "text": " gerade eben schon gesagt, ja, das Modell kann ja kein mentales Modell aufbauen. Und wir hatten",
      "tokens": [
        51522,
        12117,
        11375,
        4981,
        12260,
        11,
        2784,
        11,
        1482,
        6583,
        898,
        4028,
        2784,
        13424,
        4973,
        279,
        6583,
        898,
        2501,
        65,
        11715,
        13,
        2719,
        1987,
        20441,
        51780
      ],
      "temperature": 0.0,
      "avg_logprob": -0.326904296875,
      "compression_ratio": 1.7619047164916992,
      "no_speech_prob": 0.007344512268900871
    },
    {
      "id": 115,
      "seek": 71168,
      "start": 2027.2500268554688,
      "end": 2033.2900048828126,
      "text": " die Vermenschlichung. Aber ich habe mich jetzt seit ein paar Wochen mit dem mentalen Modell nach",
      "tokens": [
        50372,
        978,
        691,
        966,
        26590,
        1739,
        1063,
        13,
        5992,
        1893,
        6015,
        6031,
        4354,
        16452,
        1343,
        16509,
        23126,
        2194,
        1371,
        4973,
        268,
        6583,
        898,
        5168,
        50674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28021442890167236,
      "compression_ratio": 1.4320387840270996,
      "no_speech_prob": 0.035118818283081055
    },
    {
      "id": 116,
      "seek": 71168,
      "start": 2033.2900048828126,
      "end": 2041.170009765625,
      "text": " Peter Nauer beschäftigt. 1985 war das, glaube ich, als er das so beschrieben hat. Und das Witzige ist,",
      "tokens": [
        50674,
        6508,
        426,
        18120,
        38768,
        5828,
        13,
        28962,
        1516,
        1482,
        11,
        13756,
        1893,
        11,
        3907,
        1189,
        1482,
        370,
        17498,
        24027,
        2385,
        13,
        2719,
        1482,
        343,
        6862,
        3969,
        1418,
        11,
        51068
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28021442890167236,
      "compression_ratio": 1.4320387840270996,
      "no_speech_prob": 0.035118818283081055
    },
    {
      "id": 117,
      "seek": 71168,
      "start": 2041.170009765625,
      "end": 2051.170009765625,
      "text": " also das mentale Modell beschreibt halt, was man als Entwickler so aufbaut beim Programmieren,",
      "tokens": [
        51068,
        611,
        1482,
        3074,
        1220,
        6583,
        898,
        17498,
        31174,
        12479,
        11,
        390,
        587,
        3907,
        29397,
        1918,
        370,
        2501,
        65,
        1375,
        13922,
        48244,
        5695,
        11,
        51568
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28021442890167236,
      "compression_ratio": 1.4320387840270996,
      "no_speech_prob": 0.035118818283081055
    },
    {
      "id": 118,
      "seek": 73576,
      "start": 2051.170009765625,
      "end": 2058.4499780273436,
      "text": " um eben auch die Frage nach dem Warum im Code beantworten zu können. Warum wird da ein Personal",
      "tokens": [
        50364,
        1105,
        11375,
        2168,
        978,
        13685,
        5168,
        1371,
        25541,
        566,
        15549,
        312,
        21655,
        268,
        2164,
        6310,
        13,
        25541,
        4578,
        1120,
        1343,
        25317,
        50728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2990629971027374,
      "compression_ratio": 1.4723618030548096,
      "no_speech_prob": 0.0674368217587471
    },
    {
      "id": 119,
      "seek": 73576,
      "start": 2058.4499780273436,
      "end": 2065.170009765625,
      "text": " Access Token und nicht einfach der Access Key, den man in der Action hat, verwendet, zum Beispiel.",
      "tokens": [
        50728,
        17166,
        314,
        8406,
        674,
        1979,
        7281,
        1163,
        17166,
        12759,
        11,
        1441,
        587,
        294,
        1163,
        16261,
        2385,
        11,
        1306,
        20128,
        302,
        11,
        5919,
        13772,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2990629971027374,
      "compression_ratio": 1.4723618030548096,
      "no_speech_prob": 0.0674368217587471
    },
    {
      "id": 120,
      "seek": 73576,
      "start": 2065.170009765625,
      "end": 2075.41,
      "text": " Und das Faszinierende ist, dass die Modelle dieses Konzept, mentales Modell nach Nauer kennen und",
      "tokens": [
        51064,
        2719,
        1482,
        479,
        19601,
        259,
        811,
        5445,
        1418,
        11,
        2658,
        978,
        6583,
        4434,
        12113,
        12718,
        32082,
        11,
        4973,
        279,
        6583,
        898,
        5168,
        426,
        18120,
        28445,
        674,
        51576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2990629971027374,
      "compression_ratio": 1.4723618030548096,
      "no_speech_prob": 0.0674368217587471
    },
    {
      "id": 121,
      "seek": 76000,
      "start": 2075.41,
      "end": 2082.5299951171874,
      "text": " dann wissen, was sie zu tun haben, also was es bedeutet. Und die ganzen Toolhersteller haben",
      "tokens": [
        50364,
        3594,
        16331,
        11,
        390,
        2804,
        2164,
        4267,
        3084,
        11,
        611,
        390,
        785,
        27018,
        13,
        2719,
        978,
        23966,
        15934,
        511,
        372,
        14983,
        3084,
        50720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2909989058971405,
      "compression_ratio": 1.4221105575561523,
      "no_speech_prob": 0.23318195343017578
    },
    {
      "id": 122,
      "seek": 76000,
      "start": 2082.5299951171874,
      "end": 2092.690029296875,
      "text": " schon angefangen. Man kennt das ja, diese Cloud.md oder Agent.md Files, die immer im Root liegen,",
      "tokens": [
        50720,
        4981,
        43907,
        10784,
        13,
        2458,
        37682,
        1482,
        2784,
        11,
        6705,
        8061,
        13,
        76,
        67,
        4513,
        27174,
        13,
        76,
        67,
        479,
        4680,
        11,
        978,
        5578,
        566,
        3101,
        310,
        35100,
        11,
        51228
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2909989058971405,
      "compression_ratio": 1.4221105575561523,
      "no_speech_prob": 0.23318195343017578
    },
    {
      "id": 123,
      "seek": 76000,
      "start": 2092.690029296875,
      "end": 2100.2099877929686,
      "text": " wo die KI mal über das Repository rübergegangen ist und zumindest sich wichtige Sachen wie",
      "tokens": [
        51228,
        6020,
        978,
        47261,
        2806,
        4502,
        1482,
        3696,
        9598,
        827,
        367,
        12670,
        432,
        47152,
        1418,
        674,
        38082,
        3041,
        46276,
        26074,
        3355,
        51604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2909989058971405,
      "compression_ratio": 1.4221105575561523,
      "no_speech_prob": 0.23318195343017578
    },
    {
      "id": 124,
      "seek": 78480,
      "start": 2100.2099877929686,
      "end": 2105.4900170898436,
      "text": " Technology Stack und die Fallstruktur und sowas rausgeschrieben hat. Gehört auch zum",
      "tokens": [
        50364,
        15037,
        37649,
        674,
        978,
        7465,
        372,
        31543,
        674,
        19766,
        296,
        17202,
        23378,
        24027,
        2385,
        13,
        2876,
        71,
        11454,
        2168,
        5919,
        50628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2977582812309265,
      "compression_ratio": 1.50632905960083,
      "no_speech_prob": 0.04334024339914322
    },
    {
      "id": 125,
      "seek": 78480,
      "start": 2105.4900170898436,
      "end": 2113.2500268554686,
      "text": " mentalen Modell. Ich behaupte, dass wenn man eben auch so ein bisschen an dieses Warum geht,",
      "tokens": [
        50628,
        4973,
        268,
        6583,
        898,
        13,
        3141,
        1540,
        13343,
        68,
        11,
        2658,
        4797,
        587,
        11375,
        2168,
        370,
        1343,
        10763,
        364,
        12113,
        25541,
        7095,
        11,
        51016
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2977582812309265,
      "compression_ratio": 1.50632905960083,
      "no_speech_prob": 0.04334024339914322
    },
    {
      "id": 126,
      "seek": 78480,
      "start": 2113.2500268554686,
      "end": 2119.569973144531,
      "text": " wenn man jetzt eben zum Beispiel da das hinterlassen würde, wir benutzen hier Personal",
      "tokens": [
        51016,
        4797,
        587,
        4354,
        11375,
        5919,
        13772,
        1120,
        1482,
        23219,
        44898,
        11942,
        11,
        1987,
        38424,
        2904,
        3296,
        25317,
        51332
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2977582812309265,
      "compression_ratio": 1.50632905960083,
      "no_speech_prob": 0.04334024339914322
    },
    {
      "id": 127,
      "seek": 78480,
      "start": 2119.569973144531,
      "end": 2124.850002441406,
      "text": " Access Token, weil erster Weg ohne Personal Access Token hat nicht funktioniert. Deswegen,",
      "tokens": [
        51332,
        17166,
        314,
        8406,
        11,
        7689,
        1189,
        3120,
        18919,
        15716,
        25317,
        17166,
        314,
        8406,
        2385,
        1979,
        26160,
        13,
        24864,
        11,
        51596
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2977582812309265,
      "compression_ratio": 1.50632905960083,
      "no_speech_prob": 0.04334024339914322
    },
    {
      "id": 128,
      "seek": 80944,
      "start": 2125.850002441406,
      "end": 2132.8100244140624,
      "text": " wenn man das hinterlässt, dann könnte die KI da besser werden. Und das zeigt eben auch,",
      "tokens": [
        50414,
        4797,
        587,
        1482,
        23219,
        75,
        13555,
        372,
        11,
        3594,
        17646,
        978,
        47261,
        1120,
        18021,
        4604,
        13,
        2719,
        1482,
        29250,
        11375,
        2168,
        11,
        50762
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26622024178504944,
      "compression_ratio": 1.5606694221496582,
      "no_speech_prob": 0.000345985172316432
    },
    {
      "id": 129,
      "seek": 80944,
      "start": 2132.8100244140624,
      "end": 2138.9699975585936,
      "text": " dass ja, du sagst ja selbst, wenn man, wenn man jetzt das Programmieren noch nicht gewöhnt ist,",
      "tokens": [
        50762,
        2658,
        2784,
        11,
        1581,
        15274,
        372,
        2784,
        13053,
        11,
        4797,
        587,
        11,
        4797,
        587,
        4354,
        1482,
        48244,
        5695,
        3514,
        1979,
        6906,
        23817,
        580,
        1418,
        11,
        51070
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26622024178504944,
      "compression_ratio": 1.5606694221496582,
      "no_speech_prob": 0.000345985172316432
    },
    {
      "id": 130,
      "seek": 80944,
      "start": 2138.9699975585936,
      "end": 2146.370021972656,
      "text": " es nicht jahrelang trainiert hat, dann fallen einem diese Sachen nicht auf. Und dann ist die",
      "tokens": [
        51070,
        785,
        1979,
        361,
        545,
        4419,
        656,
        3847,
        4859,
        2385,
        11,
        3594,
        11547,
        6827,
        6705,
        26074,
        1979,
        2501,
        13,
        2719,
        3594,
        1418,
        978,
        51440
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26622024178504944,
      "compression_ratio": 1.5606694221496582,
      "no_speech_prob": 0.000345985172316432
    },
    {
      "id": 131,
      "seek": 80944,
      "start": 2146.370021972656,
      "end": 2153.4499780273436,
      "text": " Frage, ob man es schafft, das Modell richtig zu besprechen, sag ich mal. Ja, also die Prompts",
      "tokens": [
        51440,
        13685,
        11,
        1111,
        587,
        785,
        956,
        29445,
        11,
        1482,
        6583,
        898,
        13129,
        2164,
        4097,
        38951,
        11,
        15274,
        1893,
        2806,
        13,
        3530,
        11,
        611,
        978,
        15833,
        39280,
        51794
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26622024178504944,
      "compression_ratio": 1.5606694221496582,
      "no_speech_prob": 0.000345985172316432
    },
    {
      "id": 132,
      "seek": 83804,
      "start": 2153.4499780273436,
      "end": 2158.4499780273436,
      "text": " richtig zu wählen. Und das macht einen großen Unterschied aus.",
      "tokens": [
        50364,
        13129,
        2164,
        24787,
        6698,
        13,
        2719,
        1482,
        10857,
        4891,
        23076,
        41414,
        3437,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3340741991996765,
      "compression_ratio": 1.426829218864441,
      "no_speech_prob": 0.05576732009649277
    },
    {
      "id": 133,
      "seek": 83804,
      "start": 2158.4499780273436,
      "end": 2165.690029296875,
      "text": " Genau. Also vielleicht noch zwei Worte dazu. Es ist halt ganz spannend, weil der Sebastian Hans",
      "tokens": [
        50614,
        22340,
        13,
        2743,
        12547,
        3514,
        12002,
        343,
        12752,
        13034,
        13,
        2313,
        1418,
        12479,
        6312,
        49027,
        11,
        7689,
        1163,
        31102,
        17926,
        50976
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3340741991996765,
      "compression_ratio": 1.426829218864441,
      "no_speech_prob": 0.05576732009649277
    },
    {
      "id": 134,
      "seek": 83804,
      "start": 2165.690029296875,
      "end": 2172.2900048828124,
      "text": " hat mich vor fünf Tagen, so sagt Mastodon, auf dieses Paper hingewiesen, Programming as Theory",
      "tokens": [
        50976,
        2385,
        6031,
        4245,
        28723,
        41721,
        11,
        370,
        15764,
        376,
        525,
        378,
        266,
        11,
        2501,
        12113,
        24990,
        24895,
        1023,
        30383,
        11,
        8338,
        2810,
        382,
        29009,
        51306
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3340741991996765,
      "compression_ratio": 1.426829218864441,
      "no_speech_prob": 0.05576732009649277
    },
    {
      "id": 135,
      "seek": 83804,
      "start": 2172.2900048828124,
      "end": 2180.0099755859374,
      "text": " Building. Und ich hatte mir irgendwie sozusagen vorgenommen, das nochmal genauer durchzulesen,",
      "tokens": [
        51306,
        18974,
        13,
        2719,
        1893,
        13299,
        3149,
        20759,
        33762,
        4245,
        29270,
        11,
        1482,
        26509,
        12535,
        260,
        7131,
        89,
        3473,
        268,
        11,
        51692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3340741991996765,
      "compression_ratio": 1.426829218864441,
      "no_speech_prob": 0.05576732009649277
    },
    {
      "id": 136,
      "seek": 86460,
      "start": 2180.129970703125,
      "end": 2186.089992675781,
      "text": " weil ich halt vermutet hatte, dass das halt im Prinzip bedeutet, dass man eben als Menschenteam",
      "tokens": [
        50370,
        7689,
        1893,
        12479,
        26319,
        20364,
        13299,
        11,
        2658,
        1482,
        12479,
        566,
        47572,
        27018,
        11,
        2658,
        587,
        11375,
        3907,
        27773,
        1576,
        335,
        50668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.320719450712204,
      "compression_ratio": 1.6879432201385498,
      "no_speech_prob": 0.0064827329479157925
    },
    {
      "id": 137,
      "seek": 86460,
      "start": 2186.089992675781,
      "end": 2193.5299951171874,
      "text": " ein gemeinsames mentales Modell entwickelt und dass sich im Code das eben nur ausdrückt. Ich",
      "tokens": [
        50668,
        1343,
        22971,
        1632,
        4973,
        279,
        6583,
        898,
        43208,
        674,
        2658,
        3041,
        566,
        15549,
        1482,
        11375,
        4343,
        3437,
        16753,
        37532,
        13,
        3141,
        51040
      ],
      "temperature": 0.0,
      "avg_logprob": -0.320719450712204,
      "compression_ratio": 1.6879432201385498,
      "no_speech_prob": 0.0064827329479157925
    },
    {
      "id": 138,
      "seek": 86460,
      "start": 2193.5299951171874,
      "end": 2197.41,
      "text": " hatte das irgendwie, genau, ich hatte irgendwie die ersten Seiten überflogen und da war irgendwie",
      "tokens": [
        51040,
        13299,
        1482,
        20759,
        11,
        12535,
        11,
        1893,
        13299,
        20759,
        978,
        17324,
        45200,
        4502,
        3423,
        8799,
        674,
        1120,
        1516,
        20759,
        51234
      ],
      "temperature": 0.0,
      "avg_logprob": -0.320719450712204,
      "compression_ratio": 1.6879432201385498,
      "no_speech_prob": 0.0064827329479157925
    },
    {
      "id": 139,
      "seek": 86460,
      "start": 2197.41,
      "end": 2201.7300073242186,
      "text": " so eine Geschichte, von wegen irgendein Team hat halt einen Compiler gebaut oder irgendwas. Dann",
      "tokens": [
        51234,
        370,
        3018,
        28896,
        11,
        2957,
        32855,
        3418,
        27429,
        259,
        7606,
        2385,
        12479,
        4891,
        6620,
        5441,
        49203,
        4513,
        47090,
        13,
        7455,
        51450
      ],
      "temperature": 0.0,
      "avg_logprob": -0.320719450712204,
      "compression_ratio": 1.6879432201385498,
      "no_speech_prob": 0.0064827329479157925
    },
    {
      "id": 140,
      "seek": 86460,
      "start": 2201.7300073242186,
      "end": 2205.370021972656,
      "text": " hat ein anderes Team versucht, den halt zu erweitern. Und daraufhin hat das ursprüngliche",
      "tokens": [
        51450,
        2385,
        1343,
        31426,
        7606,
        36064,
        11,
        1441,
        12479,
        2164,
        1189,
        28019,
        1248,
        13,
        2719,
        18654,
        10876,
        2385,
        1482,
        4038,
        18193,
        36216,
        10185,
        51632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.320719450712204,
      "compression_ratio": 1.6879432201385498,
      "no_speech_prob": 0.0064827329479157925
    },
    {
      "id": 141,
      "seek": 88996,
      "start": 2205.4900170898436,
      "end": 2210.170009765625,
      "text": " Team, hat man das dem ursprünglichen Team gegeben und hat halt gesagt, also das ursprüngliche Team,",
      "tokens": [
        50370,
        7606,
        11,
        2385,
        587,
        1482,
        1371,
        4038,
        18193,
        36216,
        10193,
        7606,
        32572,
        674,
        2385,
        12479,
        12260,
        11,
        611,
        1482,
        4038,
        18193,
        36216,
        10185,
        7606,
        11,
        50604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.252118319272995,
      "compression_ratio": 1.761732816696167,
      "no_speech_prob": 0.06270678341388702
    },
    {
      "id": 142,
      "seek": 88996,
      "start": 2210.170009765625,
      "end": 2214.370021972656,
      "text": " was den Compiler ursprünglich gebaut hat, hat gesagt, das ist ein netter Versuch, aber das",
      "tokens": [
        50604,
        390,
        1441,
        6620,
        5441,
        4038,
        18193,
        36216,
        1739,
        49203,
        2385,
        11,
        2385,
        12260,
        11,
        1482,
        1418,
        1343,
        2533,
        391,
        12226,
        625,
        11,
        4340,
        1482,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.252118319272995,
      "compression_ratio": 1.761732816696167,
      "no_speech_prob": 0.06270678341388702
    },
    {
      "id": 143,
      "seek": 88996,
      "start": 2214.370021972656,
      "end": 2220.329982910156,
      "text": " zerstört halt die ganze Struktur des Systems. Und hier ist ein viel einfacherer Weg. Und das hängt",
      "tokens": [
        50814,
        710,
        16398,
        11454,
        12479,
        978,
        18898,
        745,
        31543,
        730,
        27059,
        13,
        2719,
        3296,
        1418,
        1343,
        5891,
        38627,
        4062,
        260,
        18919,
        13,
        2719,
        1482,
        276,
        29670,
        51112
      ],
      "temperature": 0.0,
      "avg_logprob": -0.252118319272995,
      "compression_ratio": 1.761732816696167,
      "no_speech_prob": 0.06270678341388702
    },
    {
      "id": 144,
      "seek": 88996,
      "start": 2220.329982910156,
      "end": 2223.610012207031,
      "text": " eben damit zusammen, dass eben das ursprüngliche Team halt diese Theorie verstanden hat und das",
      "tokens": [
        51112,
        11375,
        9479,
        14311,
        11,
        2658,
        11375,
        1482,
        4038,
        18193,
        36216,
        10185,
        7606,
        12479,
        6705,
        440,
        17473,
        1306,
        33946,
        2385,
        674,
        1482,
        51276
      ],
      "temperature": 0.0,
      "avg_logprob": -0.252118319272995,
      "compression_ratio": 1.761732816696167,
      "no_speech_prob": 0.06270678341388702
    },
    {
      "id": 145,
      "seek": 88996,
      "start": 2223.610012207031,
      "end": 2232.370021972656,
      "text": " neue Team nicht. So jedenfalls meine Wahrnehmung. Also das, was du beschreibst, bedeutet ja nur,",
      "tokens": [
        51276,
        16842,
        7606,
        1979,
        13,
        407,
        12906,
        18542,
        10946,
        36357,
        716,
        8587,
        1063,
        13,
        2743,
        1482,
        11,
        390,
        1581,
        17498,
        38606,
        372,
        11,
        27018,
        2784,
        4343,
        11,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.252118319272995,
      "compression_ratio": 1.761732816696167,
      "no_speech_prob": 0.06270678341388702
    },
    {
      "id": 146,
      "seek": 91696,
      "start": 2232.4499780273436,
      "end": 2238.649990234375,
      "text": " dass man den Texten etwas hinschreibt. Das ist kein mentales Modell. Und das ist was anderes,",
      "tokens": [
        50368,
        2658,
        587,
        1441,
        18643,
        268,
        9569,
        276,
        1292,
        339,
        31174,
        13,
        2846,
        1418,
        13424,
        4973,
        279,
        6583,
        898,
        13,
        2719,
        1482,
        1418,
        390,
        31426,
        11,
        50678
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32978302240371704,
      "compression_ratio": 1.5022624731063843,
      "no_speech_prob": 0.08869905769824982
    },
    {
      "id": 147,
      "seek": 91696,
      "start": 2238.649990234375,
      "end": 2244.7699853515624,
      "text": " aber nicht, dass, also darüber muss man offensichtlich, das wäre dann sozusagen die",
      "tokens": [
        50678,
        4340,
        1979,
        11,
        2658,
        11,
        611,
        21737,
        6425,
        587,
        766,
        694,
        41971,
        11,
        1482,
        14558,
        3594,
        33762,
        978,
        50984
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32978302240371704,
      "compression_ratio": 1.5022624731063843,
      "no_speech_prob": 0.08869905769824982
    },
    {
      "id": 148,
      "seek": 91696,
      "start": 2244.7699853515624,
      "end": 2247.170009765625,
      "text": " nächste Episode, die man nochmal planen könnte und machen könnte.",
      "tokens": [
        50984,
        30661,
        19882,
        11,
        978,
        587,
        26509,
        1393,
        268,
        17646,
        674,
        7069,
        17646,
        13,
        51104
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32978302240371704,
      "compression_ratio": 1.5022624731063843,
      "no_speech_prob": 0.08869905769824982
    },
    {
      "id": 149,
      "seek": 91696,
      "start": 2247.170009765625,
      "end": 2256.089992675781,
      "text": " Absolut. Der Begriff mentales Modell ist da vielleicht auch ein bisschen schwierig,",
      "tokens": [
        51104,
        5813,
        2308,
        13,
        5618,
        879,
        32783,
        3074,
        4229,
        6583,
        898,
        1418,
        1120,
        12547,
        2168,
        1343,
        10763,
        37845,
        11,
        51550
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32978302240371704,
      "compression_ratio": 1.5022624731063843,
      "no_speech_prob": 0.08869905769824982
    },
    {
      "id": 150,
      "seek": 94068,
      "start": 2256.089992675781,
      "end": 2262.2900048828124,
      "text": " aber ich habe halt gemerkt, da ist was dran an diesem mentalen Modell. Und wie du ja gesagt",
      "tokens": [
        50364,
        4340,
        1893,
        6015,
        12479,
        7173,
        49015,
        11,
        1120,
        1418,
        390,
        32801,
        364,
        10975,
        4973,
        268,
        6583,
        898,
        13,
        2719,
        3355,
        1581,
        2784,
        12260,
        50674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22080177068710327,
      "compression_ratio": 1.4803149700164795,
      "no_speech_prob": 0.05909186974167824
    },
    {
      "id": 151,
      "seek": 94068,
      "start": 2262.2900048828124,
      "end": 2269.370021972656,
      "text": " hast, die KI nimmt Text und produziert Text. Das heißt, man muss irgendwo, wenn man es schaffen",
      "tokens": [
        50674,
        6581,
        11,
        978,
        47261,
        38891,
        18643,
        674,
        28093,
        4859,
        18643,
        13,
        2846,
        13139,
        11,
        587,
        6425,
        40865,
        11,
        4797,
        587,
        785,
        30888,
        51028
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22080177068710327,
      "compression_ratio": 1.4803149700164795,
      "no_speech_prob": 0.05909186974167824
    },
    {
      "id": 152,
      "seek": 94068,
      "start": 2269.370021972656,
      "end": 2277.2500268554686,
      "text": " will, im Text abbilden. Aber das Faszinierende daran ist auch, wenn man dieses Konzept betrachtet",
      "tokens": [
        51028,
        486,
        11,
        566,
        18643,
        410,
        16248,
        268,
        13,
        5992,
        1482,
        479,
        19601,
        259,
        811,
        5445,
        24520,
        1418,
        2168,
        11,
        4797,
        587,
        12113,
        12718,
        32082,
        778,
        81,
        48833,
        51422
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22080177068710327,
      "compression_ratio": 1.4803149700164795,
      "no_speech_prob": 0.05909186974167824
    },
    {
      "id": 153,
      "seek": 94068,
      "start": 2277.2500268554686,
      "end": 2284.370021972656,
      "text": " und jetzt zum Beispiel Legacy Modernization machen möchte mit der KI und sagt, warum ist",
      "tokens": [
        51422,
        674,
        4354,
        5919,
        13772,
        42838,
        19814,
        2144,
        7069,
        14570,
        2194,
        1163,
        47261,
        674,
        15764,
        11,
        24331,
        1418,
        51778
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22080177068710327,
      "compression_ratio": 1.4803149700164795,
      "no_speech_prob": 0.05909186974167824
    },
    {
      "id": 154,
      "seek": 96896,
      "start": 2284.370021972656,
      "end": 2290.370021972656,
      "text": " dieser Code eigentlich Legacy? Weil die Entwickler sagen alle, muss neu geschrieben werden. Warum muss",
      "tokens": [
        50364,
        9053,
        15549,
        10926,
        42838,
        30,
        18665,
        978,
        29397,
        1918,
        8360,
        5430,
        11,
        6425,
        22510,
        47397,
        4604,
        13,
        25541,
        6425,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26443415880203247,
      "compression_ratio": 1.7205240726470947,
      "no_speech_prob": 0.022266371175646782
    },
    {
      "id": 155,
      "seek": 96896,
      "start": 2290.370021972656,
      "end": 2296.41,
      "text": " er neu geschrieben werden? Weil das mentale Modell fehlt, weil das Warum fehlt. Und wenn ich dann mit",
      "tokens": [
        50664,
        1189,
        22510,
        47397,
        4604,
        30,
        18665,
        1482,
        3074,
        1220,
        6583,
        898,
        47994,
        11,
        7689,
        1482,
        25541,
        47994,
        13,
        2719,
        4797,
        1893,
        3594,
        2194,
        50966
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26443415880203247,
      "compression_ratio": 1.7205240726470947,
      "no_speech_prob": 0.022266371175646782
    },
    {
      "id": 156,
      "seek": 96896,
      "start": 2296.41,
      "end": 2302.93001953125,
      "text": " der KI es umschreiben lasse, in eine moderne Sprache, habe ich dann das mentale Modell. Kann",
      "tokens": [
        50966,
        1163,
        47261,
        785,
        1105,
        6145,
        25946,
        2439,
        405,
        11,
        294,
        3018,
        10494,
        716,
        7702,
        6000,
        11,
        6015,
        1893,
        3594,
        1482,
        3074,
        1220,
        6583,
        898,
        13,
        29074,
        51292
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26443415880203247,
      "compression_ratio": 1.7205240726470947,
      "no_speech_prob": 0.022266371175646782
    },
    {
      "id": 157,
      "seek": 96896,
      "start": 2302.93001953125,
      "end": 2309.0500146484374,
      "text": " dann der Entwickler weiterarbeiten? Das finde ich so faszinierend, eine interessante Erkenntnis.",
      "tokens": [
        51292,
        3594,
        1163,
        29397,
        1918,
        8988,
        43918,
        30,
        2846,
        17841,
        1893,
        370,
        283,
        19601,
        259,
        811,
        521,
        11,
        3018,
        24372,
        3300,
        41838,
        10661,
        13,
        51598
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26443415880203247,
      "compression_ratio": 1.7205240726470947,
      "no_speech_prob": 0.022266371175646782
    },
    {
      "id": 158,
      "seek": 99364,
      "start": 2309.5299951171874,
      "end": 2316.0099755859374,
      "text": " Meiner Ansicht nach ist das Grundproblem dabei, dass man an der Stelle nicht wahrhaben will,",
      "tokens": [
        50388,
        1923,
        4564,
        14590,
        1405,
        5168,
        1418,
        1482,
        13941,
        47419,
        14967,
        11,
        2658,
        587,
        364,
        1163,
        26629,
        1979,
        21628,
        7821,
        268,
        486,
        11,
        50712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30824336409568787,
      "compression_ratio": 1.787401556968689,
      "no_speech_prob": 0.10634089261293411
    },
    {
      "id": 159,
      "seek": 99364,
      "start": 2316.0099755859374,
      "end": 2321.690029296875,
      "text": " dass Softwareentwicklung ein sozialer Prozess ist. Und das ist das, was ich glaubte,",
      "tokens": [
        50712,
        2658,
        27428,
        317,
        16038,
        17850,
        1343,
        31541,
        260,
        1705,
        37575,
        1418,
        13,
        2719,
        1482,
        1418,
        1482,
        11,
        390,
        1893,
        23210,
        975,
        11,
        50996
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30824336409568787,
      "compression_ratio": 1.787401556968689,
      "no_speech_prob": 0.10634089261293411
    },
    {
      "id": 160,
      "seek": 99364,
      "start": 2321.690029296875,
      "end": 2325.0500146484374,
      "text": " was man aus diesem Paper, was ich eben nicht gelesen habe, vielleicht rauslesen kann,",
      "tokens": [
        50996,
        390,
        587,
        3437,
        10975,
        24990,
        11,
        390,
        1893,
        11375,
        1979,
        4087,
        17403,
        6015,
        11,
        12547,
        17202,
        904,
        268,
        4028,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30824336409568787,
      "compression_ratio": 1.787401556968689,
      "no_speech_prob": 0.10634089261293411
    },
    {
      "id": 161,
      "seek": 99364,
      "start": 2325.0500146484374,
      "end": 2330.93001953125,
      "text": " dass eben dieses soziale Modell im Code Ausdruck findet. Und das ist dann halt trivial, wenn ich",
      "tokens": [
        51164,
        2658,
        11375,
        12113,
        31541,
        68,
        6583,
        898,
        566,
        15549,
        9039,
        67,
        8161,
        27752,
        13,
        2719,
        1482,
        1418,
        3594,
        12479,
        26703,
        11,
        4797,
        1893,
        51458
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30824336409568787,
      "compression_ratio": 1.787401556968689,
      "no_speech_prob": 0.10634089261293411
    },
    {
      "id": 162,
      "seek": 99364,
      "start": 2330.93001953125,
      "end": 2335.2500268554686,
      "text": " eine AI ansetze, dass das eben dieses mentale Modell und den sozialen Prozess nicht abbildet.",
      "tokens": [
        51458,
        3018,
        7318,
        1567,
        302,
        1381,
        11,
        2658,
        1482,
        11375,
        12113,
        3074,
        1220,
        6583,
        898,
        674,
        1441,
        31541,
        268,
        1705,
        37575,
        1979,
        410,
        16248,
        302,
        13,
        51674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30824336409568787,
      "compression_ratio": 1.787401556968689,
      "no_speech_prob": 0.10634089261293411
    },
    {
      "id": 163,
      "seek": 101984,
      "start": 2335.2500268554686,
      "end": 2341.5299951171874,
      "text": " Und dann ist halt Schluss. Das ist eine Fehlkonzeption. Und das ist eine von den",
      "tokens": [
        50364,
        2719,
        3594,
        1418,
        12479,
        36573,
        13,
        2846,
        1418,
        3018,
        3697,
        22950,
        18295,
        32082,
        313,
        13,
        2719,
        1482,
        1418,
        3018,
        2957,
        1441,
        50678
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2978801131248474,
      "compression_ratio": 1.6447876691818237,
      "no_speech_prob": 0.0573430135846138
    },
    {
      "id": 164,
      "seek": 101984,
      "start": 2341.5299951171874,
      "end": 2345.84994140625,
      "text": " Sachen, die mich so ärgert. In diesem AI-Bereich ist eine Fehlkonzeption über",
      "tokens": [
        50678,
        26074,
        11,
        978,
        6031,
        370,
        3775,
        70,
        911,
        13,
        682,
        10975,
        7318,
        12,
        33,
        323,
        480,
        1418,
        3018,
        3697,
        22950,
        18295,
        32082,
        313,
        4502,
        50894
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2978801131248474,
      "compression_ratio": 1.6447876691818237,
      "no_speech_prob": 0.0573430135846138
    },
    {
      "id": 165,
      "seek": 101984,
      "start": 2345.84994140625,
      "end": 2352.129970703125,
      "text": " Softwareentwicklung. Softwareentwicklung ist ein sozialer Prozess. Und die fundamentalen",
      "tokens": [
        50894,
        27428,
        317,
        16038,
        17850,
        13,
        27428,
        317,
        16038,
        17850,
        1418,
        1343,
        31541,
        260,
        1705,
        37575,
        13,
        2719,
        978,
        8088,
        268,
        51208
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2978801131248474,
      "compression_ratio": 1.6447876691818237,
      "no_speech_prob": 0.0573430135846138
    },
    {
      "id": 166,
      "seek": 101984,
      "start": 2352.129970703125,
      "end": 2354.88998046875,
      "text": " Schwierigkeiten sind meiner Ansicht nach sozial. Und das wird nicht dadurch besser,",
      "tokens": [
        51208,
        17576,
        811,
        37545,
        3290,
        20529,
        14590,
        1405,
        5168,
        31541,
        13,
        2719,
        1482,
        4578,
        1979,
        35472,
        18021,
        11,
        51346
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2978801131248474,
      "compression_ratio": 1.6447876691818237,
      "no_speech_prob": 0.0573430135846138
    },
    {
      "id": 167,
      "seek": 101984,
      "start": 2354.88998046875,
      "end": 2360.690029296875,
      "text": " dass ich eine Maschine da reinsetze, aber ein anderes Thema. Wir sollten offensichtlich noch",
      "tokens": [
        51346,
        2658,
        1893,
        3018,
        5224,
        36675,
        1120,
        47200,
        302,
        1381,
        11,
        4340,
        1343,
        31426,
        16306,
        13,
        4347,
        29096,
        766,
        694,
        41971,
        3514,
        51636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2978801131248474,
      "compression_ratio": 1.6447876691818237,
      "no_speech_prob": 0.0573430135846138
    },
    {
      "id": 168,
      "seek": 104528,
      "start": 2360.690029296875,
      "end": 2367.129970703125,
      "text": " eine Episode mindestens planen. Wollen wir sprechen, wie du es auf die Webseite bekommen hast?",
      "tokens": [
        50364,
        3018,
        19882,
        1575,
        42624,
        1393,
        268,
        13,
        343,
        26669,
        1987,
        27853,
        11,
        3355,
        1581,
        785,
        2501,
        978,
        9573,
        405,
        642,
        19256,
        6581,
        30,
        50686
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2747790515422821,
      "compression_ratio": 1.5933610200881958,
      "no_speech_prob": 0.3549747169017792
    },
    {
      "id": 169,
      "seek": 104528,
      "start": 2367.129970703125,
      "end": 2376.170009765625,
      "text": " Ich würde ganz gern jetzt schon mal auf die andere Idee eingehen, wegen dem sozialen Prozess,",
      "tokens": [
        50686,
        3141,
        11942,
        6312,
        38531,
        4354,
        4981,
        2806,
        2501,
        978,
        10490,
        32651,
        30061,
        2932,
        11,
        32855,
        1371,
        31541,
        268,
        1705,
        37575,
        11,
        51138
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2747790515422821,
      "compression_ratio": 1.5933610200881958,
      "no_speech_prob": 0.3549747169017792
    },
    {
      "id": 170,
      "seek": 104528,
      "start": 2376.170009765625,
      "end": 2382.97005859375,
      "text": " weil ich das so faszinierend fand. Ich kam dann irgendwie auf die Idee, dass man ja auch mal die",
      "tokens": [
        51138,
        7689,
        1893,
        1482,
        370,
        283,
        19601,
        259,
        811,
        521,
        38138,
        13,
        3141,
        9727,
        3594,
        20759,
        2501,
        978,
        32651,
        11,
        2658,
        587,
        2784,
        2168,
        2806,
        978,
        51478
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2747790515422821,
      "compression_ratio": 1.5933610200881958,
      "no_speech_prob": 0.3549747169017792
    },
    {
      "id": 171,
      "seek": 104528,
      "start": 2382.97005859375,
      "end": 2390.2900048828124,
      "text": " Folgen nach Gast sortieren könnte und auf die Seite bringen könnte. War irgendwie so eine Idee,",
      "tokens": [
        51478,
        15255,
        1766,
        5168,
        31988,
        1333,
        5695,
        17646,
        674,
        2501,
        978,
        19748,
        27519,
        17646,
        13,
        3630,
        20759,
        370,
        3018,
        32651,
        11,
        51844
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2747790515422821,
      "compression_ratio": 1.5933610200881958,
      "no_speech_prob": 0.3549747169017792
    },
    {
      "id": 172,
      "seek": 107488,
      "start": 2390.4500390625,
      "end": 2396.2900048828124,
      "text": " könnte man doch mal machen. Und die Idee dabei war halt, also ich finde diese verschiedenen Ebenen,",
      "tokens": [
        50372,
        17646,
        587,
        9243,
        2806,
        7069,
        13,
        2719,
        978,
        32651,
        14967,
        1516,
        12479,
        11,
        611,
        1893,
        17841,
        6705,
        41043,
        462,
        1799,
        268,
        11,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3072551190853119,
      "compression_ratio": 1.5426356792449951,
      "no_speech_prob": 0.002018886851146817
    },
    {
      "id": 173,
      "seek": 107488,
      "start": 2396.2900048828124,
      "end": 2401.88998046875,
      "text": " wie man die KI verwendet. Und wir haben jetzt zum Beispiel bei dem Transkriptionsprozess habe",
      "tokens": [
        50664,
        3355,
        587,
        978,
        47261,
        1306,
        20128,
        302,
        13,
        2719,
        1987,
        3084,
        4354,
        5919,
        13772,
        4643,
        1371,
        6531,
        74,
        470,
        9799,
        4318,
        37575,
        6015,
        50944
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3072551190853119,
      "compression_ratio": 1.5426356792449951,
      "no_speech_prob": 0.002018886851146817
    },
    {
      "id": 174,
      "seek": 107488,
      "start": 2401.88998046875,
      "end": 2411.84994140625,
      "text": " ich mit KI gecodet. Mit KI machen wir ein Review. Und in dem Prozess, die Zusammenfassung, läuft ja",
      "tokens": [
        50944,
        1893,
        2194,
        47261,
        1519,
        26560,
        302,
        13,
        10821,
        47261,
        7069,
        1987,
        1343,
        19954,
        13,
        2719,
        294,
        1371,
        1705,
        37575,
        11,
        978,
        29442,
        69,
        40828,
        11,
        31807,
        2784,
        51442
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3072551190853119,
      "compression_ratio": 1.5426356792449951,
      "no_speech_prob": 0.002018886851146817
    },
    {
      "id": 175,
      "seek": 107488,
      "start": 2411.84994140625,
      "end": 2415.84994140625,
      "text": " selbst auch mit KI. Da müssen wir gleich auch dran denken. Da gibt es ja jetzt ein aktuelles Problem,",
      "tokens": [
        51442,
        13053,
        2168,
        2194,
        47261,
        13,
        3933,
        9013,
        1987,
        11699,
        2168,
        32801,
        28780,
        13,
        3933,
        6089,
        785,
        2784,
        4354,
        1343,
        36267,
        279,
        11676,
        11,
        51642
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3072551190853119,
      "compression_ratio": 1.5426356792449951,
      "no_speech_prob": 0.002018886851146817
    },
    {
      "id": 176,
      "seek": 110044,
      "start": 2416.0500146484374,
      "end": 2423.2499658203124,
      "text": " was wir haben. Und so habe ich dann eben auch gedacht, Mensch, wir haben jetzt diese ganzen",
      "tokens": [
        50374,
        390,
        1987,
        3084,
        13,
        2719,
        370,
        6015,
        1893,
        3594,
        11375,
        2168,
        33296,
        11,
        27773,
        11,
        1987,
        3084,
        4354,
        6705,
        23966,
        50734
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28315818309783936,
      "compression_ratio": 1.471794843673706,
      "no_speech_prob": 0.03619295731186867
    },
    {
      "id": 177,
      "seek": 110044,
      "start": 2423.2499658203124,
      "end": 2431.0500146484374,
      "text": " 180 Folgen. Wow, da hat sich was angesammelt. Und da ist überall irgendwo unstrukturiert der Gast",
      "tokens": [
        50734,
        11971,
        15255,
        1766,
        13,
        3153,
        11,
        1120,
        2385,
        3041,
        390,
        31138,
        5136,
        2018,
        13,
        2719,
        1120,
        1418,
        38035,
        40865,
        18799,
        31543,
        4859,
        1163,
        31988,
        51124
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28315818309783936,
      "compression_ratio": 1.471794843673706,
      "no_speech_prob": 0.03619295731186867
    },
    {
      "id": 178,
      "seek": 110044,
      "start": 2431.0500146484374,
      "end": 2438.97005859375,
      "text": " mit genannt. Und das könnte man ja jetzt mit der KI rausziehen. Und ich habe einfach mal die KI",
      "tokens": [
        51124,
        2194,
        1049,
        39878,
        13,
        2719,
        1482,
        17646,
        587,
        2784,
        4354,
        2194,
        1163,
        47261,
        17202,
        28768,
        13,
        2719,
        1893,
        6015,
        7281,
        2806,
        978,
        47261,
        51520
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28315818309783936,
      "compression_ratio": 1.471794843673706,
      "no_speech_prob": 0.03619295731186867
    },
    {
      "id": 179,
      "seek": 112356,
      "start": 2438.97005859375,
      "end": 2444.2900048828124,
      "text": " drauf angesetzt. Habe gesagt, guck mal, hier ist das Repository und mach dir mal Gedanken,",
      "tokens": [
        50364,
        22763,
        31138,
        3524,
        13,
        389,
        4488,
        12260,
        11,
        695,
        547,
        2806,
        11,
        3296,
        1418,
        1482,
        3696,
        9598,
        827,
        674,
        2246,
        4746,
        2806,
        44612,
        11,
        50630
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2669355273246765,
      "compression_ratio": 1.524999976158142,
      "no_speech_prob": 0.1579323559999466
    },
    {
      "id": 180,
      "seek": 112356,
      "start": 2444.2900048828124,
      "end": 2450.93001953125,
      "text": " wie könnte man das rausziehen. Iterier mal drüber. Da war es schon mal faszinierend,",
      "tokens": [
        50630,
        3355,
        17646,
        587,
        1482,
        17202,
        28768,
        13,
        286,
        391,
        811,
        2806,
        1224,
        12670,
        13,
        3933,
        1516,
        785,
        4981,
        2806,
        283,
        19601,
        259,
        811,
        521,
        11,
        50962
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2669355273246765,
      "compression_ratio": 1.524999976158142,
      "no_speech_prob": 0.1579323559999466
    },
    {
      "id": 181,
      "seek": 112356,
      "start": 2450.93001953125,
      "end": 2455.649990234375,
      "text": " weil ich gesagt habe, du KI, kannst du bitte drüber iterieren? Und die KI hat gesagt, ja,",
      "tokens": [
        50962,
        7689,
        1893,
        12260,
        6015,
        11,
        1581,
        47261,
        11,
        20853,
        1581,
        23231,
        1224,
        12670,
        17138,
        5695,
        30,
        2719,
        978,
        47261,
        2385,
        12260,
        11,
        2784,
        11,
        51198
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2669355273246765,
      "compression_ratio": 1.524999976158142,
      "no_speech_prob": 0.1579323559999466
    },
    {
      "id": 182,
      "seek": 112356,
      "start": 2455.649990234375,
      "end": 2463.3300439453124,
      "text": " ich mache mir mal einen Plan. Und der Plan sind eigentlich maximal fünf Schritte bei Claude. Das",
      "tokens": [
        51198,
        1893,
        28289,
        3149,
        2806,
        4891,
        8112,
        13,
        2719,
        1163,
        8112,
        3290,
        10926,
        49336,
        28723,
        46191,
        9786,
        4643,
        12947,
        2303,
        13,
        2846,
        51582
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2669355273246765,
      "compression_ratio": 1.524999976158142,
      "no_speech_prob": 0.1579323559999466
    },
    {
      "id": 183,
      "seek": 114792,
      "start": 2463.3300439453124,
      "end": 2469.5299951171874,
      "text": " heißt, erster Schritt, erste Episode, Gast rausziehen. Zweite Episode, Gast rausziehen.",
      "tokens": [
        50364,
        13139,
        11,
        1189,
        3120,
        33062,
        11,
        20951,
        19882,
        11,
        31988,
        17202,
        28768,
        13,
        32475,
        642,
        19882,
        11,
        31988,
        17202,
        28768,
        13,
        50674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2634899616241455,
      "compression_ratio": 1.90816330909729,
      "no_speech_prob": 0.10953155905008316
    },
    {
      "id": 184,
      "seek": 114792,
      "start": 2469.5299951171874,
      "end": 2474.690029296875,
      "text": " Dritte Episode, Gast rausziehen. Vierte Episode, Gast rausziehen. Aus den anderen Episoden,",
      "tokens": [
        50674,
        2491,
        9786,
        19882,
        11,
        31988,
        17202,
        28768,
        13,
        691,
        23123,
        19882,
        11,
        31988,
        17202,
        28768,
        13,
        9039,
        1441,
        11122,
        9970,
        271,
        33482,
        11,
        50932
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2634899616241455,
      "compression_ratio": 1.90816330909729,
      "no_speech_prob": 0.10953155905008316
    },
    {
      "id": 185,
      "seek": 114792,
      "start": 2474.690029296875,
      "end": 2481.93001953125,
      "text": " Gast rausziehen. Und genau so hat das Modell dann gearbeitet. Mit den ersten vier Episoden ist es",
      "tokens": [
        50932,
        31988,
        17202,
        28768,
        13,
        2719,
        12535,
        370,
        2385,
        1482,
        6583,
        898,
        3594,
        7394,
        32401,
        13,
        10821,
        1441,
        17324,
        17634,
        9970,
        271,
        33482,
        1418,
        785,
        51294
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2634899616241455,
      "compression_ratio": 1.90816330909729,
      "no_speech_prob": 0.10953155905008316
    },
    {
      "id": 186,
      "seek": 114792,
      "start": 2481.93001953125,
      "end": 2489.2499658203124,
      "text": " gut klargekommen. Und dann ist es abgedriftet und konnte nicht mehr iterieren. Da habe ich dann",
      "tokens": [
        51294,
        5228,
        14743,
        432,
        13675,
        13,
        2719,
        3594,
        1418,
        785,
        410,
        3004,
        35742,
        302,
        674,
        24058,
        1979,
        5417,
        17138,
        5695,
        13,
        3933,
        6015,
        1893,
        3594,
        51660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2634899616241455,
      "compression_ratio": 1.90816330909729,
      "no_speech_prob": 0.10953155905008316
    },
    {
      "id": 187,
      "seek": 117384,
      "start": 2489.2499658203124,
      "end": 2495.0500146484374,
      "text": " gemerkt, es könnte ja ein Programm schreiben, ein Skript, was iteriert. Und dann in dem Skript",
      "tokens": [
        50364,
        7173,
        49015,
        11,
        785,
        17646,
        2784,
        1343,
        48244,
        48546,
        11,
        1343,
        7324,
        470,
        662,
        11,
        390,
        17138,
        4859,
        13,
        2719,
        3594,
        294,
        1371,
        7324,
        470,
        662,
        50654
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23938967287540436,
      "compression_ratio": 1.51260507106781,
      "no_speech_prob": 0.0495658777654171
    },
    {
      "id": 188,
      "seek": 117384,
      "start": 2495.0500146484374,
      "end": 2499.210048828125,
      "text": " habe ich aber die KI wieder nicht mehr zur Verfügung, um es zu extrahieren. Das war so",
      "tokens": [
        50654,
        6015,
        1893,
        4340,
        978,
        47261,
        6216,
        1979,
        5417,
        7147,
        43026,
        11,
        1105,
        785,
        2164,
        2857,
        71,
        5695,
        13,
        2846,
        1516,
        370,
        50862
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23938967287540436,
      "compression_ratio": 1.51260507106781,
      "no_speech_prob": 0.0495658777654171
    },
    {
      "id": 189,
      "seek": 117384,
      "start": 2499.210048828125,
      "end": 2504.2499658203124,
      "text": " ein Ding, was ich dann da angegangen bin. Aber viel faszinierender fand ich es,",
      "tokens": [
        50862,
        1343,
        20558,
        11,
        390,
        1893,
        3594,
        1120,
        15495,
        47152,
        5171,
        13,
        5992,
        5891,
        283,
        19601,
        259,
        811,
        3216,
        38138,
        1893,
        785,
        11,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23938967287540436,
      "compression_ratio": 1.51260507106781,
      "no_speech_prob": 0.0495658777654171
    },
    {
      "id": 190,
      "seek": 117384,
      "start": 2504.2499658203124,
      "end": 2514.93001953125,
      "text": " als das Ganze irgendwo stand, mehr oder weniger fertig war. Ja, da waren viele Fehler drin. Aber",
      "tokens": [
        51114,
        3907,
        1482,
        35206,
        40865,
        1463,
        11,
        5417,
        4513,
        23224,
        31362,
        1516,
        13,
        3530,
        11,
        1120,
        11931,
        9693,
        48101,
        24534,
        13,
        5992,
        51648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23938967287540436,
      "compression_ratio": 1.51260507106781,
      "no_speech_prob": 0.0495658777654171
    },
    {
      "id": 191,
      "seek": 119952,
      "start": 2514.97005859375,
      "end": 2521.88998046875,
      "text": " du dann drüber geguckt hast und ich irgendwie gemerkt habe, dass du mir freundlich sagen",
      "tokens": [
        50366,
        1581,
        3594,
        1224,
        12670,
        23982,
        47800,
        6581,
        674,
        1893,
        20759,
        7173,
        49015,
        6015,
        11,
        2658,
        1581,
        3149,
        2130,
        997,
        1739,
        8360,
        50712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3439731001853943,
      "compression_ratio": 1.386597990989685,
      "no_speech_prob": 0.17303870618343353
    },
    {
      "id": 192,
      "seek": 119952,
      "start": 2521.88998046875,
      "end": 2528.609951171875,
      "text": " wolltest, Ralf, das, was da rausgekommen ist, das ist totaler Käse, weil das passt überhaupt",
      "tokens": [
        50712,
        8181,
        31636,
        11,
        497,
        1678,
        11,
        1482,
        11,
        390,
        1120,
        17202,
        432,
        13675,
        1418,
        11,
        1482,
        1418,
        3217,
        260,
        40502,
        405,
        11,
        7689,
        1482,
        37154,
        20023,
        51048
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3439731001853943,
      "compression_ratio": 1.386597990989685,
      "no_speech_prob": 0.17303870618343353
    },
    {
      "id": 193,
      "seek": 119952,
      "start": 2528.609951171875,
      "end": 2540.3300439453124,
      "text": " nicht zur bestehenden Architektur. War so. Richtig? Soll ich kurz ausruhen? Die eine",
      "tokens": [
        51048,
        1979,
        7147,
        1151,
        13301,
        8896,
        10984,
        642,
        2320,
        374,
        13,
        3630,
        370,
        13,
        497,
        7334,
        30,
        407,
        285,
        1893,
        20465,
        3437,
        894,
        2932,
        30,
        3229,
        3018,
        51634
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3439731001853943,
      "compression_ratio": 1.386597990989685,
      "no_speech_prob": 0.17303870618343353
    },
    {
      "id": 194,
      "seek": 122492,
      "start": 2540.3300439453124,
      "end": 2546.0099755859374,
      "text": " Sache war, wir haben ja eine Jekyll-basierte Webseite. Das heißt, wir haben im Prinzip",
      "tokens": [
        50364,
        31452,
        1516,
        11,
        1987,
        3084,
        2784,
        3018,
        508,
        916,
        34353,
        12,
        16342,
        23123,
        9573,
        405,
        642,
        13,
        2846,
        13139,
        11,
        1987,
        3084,
        566,
        47572,
        50648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37776979804039,
      "compression_ratio": 1.540772557258606,
      "no_speech_prob": 0.32354578375816345
    },
    {
      "id": 195,
      "seek": 122492,
      "start": 2546.0099755859374,
      "end": 2556.170009765625,
      "text": " Markdown-Files, die gerendert werden mit Ruby-Skripten. Und im Prinzip ist das ja ein CMS.",
      "tokens": [
        50648,
        3934,
        5093,
        12,
        37,
        4680,
        11,
        978,
        5713,
        521,
        911,
        4604,
        2194,
        19907,
        12,
        50,
        74,
        470,
        662,
        268,
        13,
        2719,
        566,
        47572,
        1418,
        1482,
        2784,
        1343,
        33124,
        13,
        51156
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37776979804039,
      "compression_ratio": 1.540772557258606,
      "no_speech_prob": 0.32354578375816345
    },
    {
      "id": 196,
      "seek": 122492,
      "start": 2556.170009765625,
      "end": 2563.0900537109374,
      "text": " Das heißt, ich habe Content, der ist als MD-Files da und dann wird er gerendert. Was",
      "tokens": [
        51156,
        2846,
        13139,
        11,
        1893,
        6015,
        30078,
        11,
        1163,
        1418,
        3907,
        22521,
        12,
        37,
        4680,
        1120,
        674,
        3594,
        4578,
        1189,
        5713,
        521,
        911,
        13,
        3027,
        51502
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37776979804039,
      "compression_ratio": 1.540772557258606,
      "no_speech_prob": 0.32354578375816345
    },
    {
      "id": 197,
      "seek": 122492,
      "start": 2563.0900537109374,
      "end": 2569.0500146484374,
      "text": " jetzt rausgekommen ist, in deinem Fall war eine MD-Seite, die aber in Wirklichkeit HTML hatte.",
      "tokens": [
        51502,
        4354,
        17202,
        432,
        13675,
        1418,
        11,
        294,
        25641,
        443,
        7465,
        1516,
        3018,
        22521,
        12,
        10637,
        642,
        11,
        978,
        4340,
        294,
        4347,
        9056,
        9238,
        17995,
        13299,
        13,
        51800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37776979804039,
      "compression_ratio": 1.540772557258606,
      "no_speech_prob": 0.32354578375816345
    },
    {
      "id": 198,
      "seek": 125364,
      "start": 2569.3699609375,
      "end": 2575.4899560546874,
      "text": " In Markdown kann ich HTML einbetten und JavaScript-Code. Und wo dann im Prinzip alle",
      "tokens": [
        50380,
        682,
        3934,
        5093,
        4028,
        1893,
        17995,
        1343,
        10671,
        1147,
        674,
        15778,
        12,
        34,
        1429,
        13,
        2719,
        6020,
        3594,
        566,
        47572,
        5430,
        50686
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3115869462490082,
      "compression_ratio": 1.470355749130249,
      "no_speech_prob": 0.009555934928357601
    },
    {
      "id": 199,
      "seek": 125364,
      "start": 2575.4899560546874,
      "end": 2581.5700341796874,
      "text": " Gäste rausgesammelt wurden aus irgendeiner Datenquelle, YAML-File oder so. Und wenn ich",
      "tokens": [
        50686,
        460,
        737,
        2941,
        17202,
        2880,
        5136,
        2018,
        21105,
        3437,
        3418,
        27429,
        4564,
        31126,
        32743,
        11,
        398,
        2865,
        43,
        12,
        37,
        794,
        4513,
        370,
        13,
        2719,
        4797,
        1893,
        50990
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3115869462490082,
      "compression_ratio": 1.470355749130249,
      "no_speech_prob": 0.009555934928357601
    },
    {
      "id": 200,
      "seek": 125364,
      "start": 2581.5700341796874,
      "end": 2590.2499658203124,
      "text": " dann etwas gesucht habe, hat das der JavaScript-Code auf dem Client gemacht. Das ist wahrscheinlich die",
      "tokens": [
        50990,
        3594,
        9569,
        5019,
        10084,
        6015,
        11,
        2385,
        1482,
        1163,
        15778,
        12,
        34,
        1429,
        2501,
        1371,
        2033,
        1196,
        12293,
        13,
        2846,
        1418,
        30957,
        978,
        51424
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3115869462490082,
      "compression_ratio": 1.470355749130249,
      "no_speech_prob": 0.009555934928357601
    },
    {
      "id": 201,
      "seek": 125364,
      "start": 2590.2499658203124,
      "end": 2596.129970703125,
      "text": " einzige Möglichkeit, wie man das hinbekommen kann. Meine Intuition wäre, ich will eigentlich",
      "tokens": [
        51424,
        47743,
        30662,
        11,
        3355,
        587,
        1482,
        14102,
        650,
        13675,
        4028,
        13,
        22258,
        5681,
        19080,
        14558,
        11,
        1893,
        486,
        10926,
        51718
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3115869462490082,
      "compression_ratio": 1.470355749130249,
      "no_speech_prob": 0.009555934928357601
    },
    {
      "id": 202,
      "seek": 128072,
      "start": 2596.3300439453124,
      "end": 2600.7299462890624,
      "text": " irgendwo einen Server haben, der sucht. Das können wir nicht, weil wir GitHub-Pages nur haben.",
      "tokens": [
        50374,
        40865,
        4891,
        25684,
        3084,
        11,
        1163,
        1270,
        83,
        13,
        2846,
        6310,
        1987,
        1979,
        11,
        7689,
        1987,
        23331,
        12,
        47,
        1660,
        4343,
        3084,
        13,
        50594
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33502906560897827,
      "compression_ratio": 1.6458333730697632,
      "no_speech_prob": 0.15175138413906097
    },
    {
      "id": 203,
      "seek": 128072,
      "start": 2600.7299462890624,
      "end": 2609.93001953125,
      "text": " Und deswegen ist das wahrscheinlich der einzige Weg. Was sich da in meiner Erinnerung aber so",
      "tokens": [
        50594,
        2719,
        26482,
        1418,
        1482,
        30957,
        1163,
        47743,
        18919,
        13,
        3027,
        3041,
        1120,
        294,
        20529,
        3300,
        19166,
        1063,
        4340,
        370,
        51054
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33502906560897827,
      "compression_ratio": 1.6458333730697632,
      "no_speech_prob": 0.15175138413906097
    },
    {
      "id": 204,
      "seek": 128072,
      "start": 2609.93001953125,
      "end": 2616.129970703125,
      "text": " gezeigt hat, ist, dass das so aufgepfropft wird. Wir haben CSS-Files, wie sich das gehört. Und",
      "tokens": [
        51054,
        48661,
        2385,
        11,
        1418,
        11,
        2658,
        1482,
        370,
        35031,
        25302,
        1513,
        844,
        4578,
        13,
        4347,
        3084,
        24387,
        12,
        37,
        4680,
        11,
        3355,
        3041,
        1482,
        21544,
        13,
        2719,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33502906560897827,
      "compression_ratio": 1.6458333730697632,
      "no_speech_prob": 0.15175138413906097
    },
    {
      "id": 205,
      "seek": 128072,
      "start": 2616.129970703125,
      "end": 2619.97005859375,
      "text": " ich würde jetzt erwarten, dass diese CSS-Sachen wiederverwendet werden. Werden halt nicht",
      "tokens": [
        51364,
        1893,
        11942,
        4354,
        21715,
        11719,
        11,
        2658,
        6705,
        24387,
        12,
        50,
        11646,
        6216,
        331,
        20128,
        302,
        4604,
        13,
        14255,
        1556,
        12479,
        1979,
        51556
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33502906560897827,
      "compression_ratio": 1.6458333730697632,
      "no_speech_prob": 0.15175138413906097
    },
    {
      "id": 206,
      "seek": 128072,
      "start": 2619.97005859375,
      "end": 2624.129970703125,
      "text": " wiederverwendet, da ist halt irgendwie eigener Kram drin. Solche Sachen. Es ist halt was Eigenes,",
      "tokens": [
        51556,
        6216,
        331,
        20128,
        302,
        11,
        1120,
        1418,
        12479,
        20759,
        10446,
        260,
        591,
        2356,
        24534,
        13,
        7026,
        1876,
        26074,
        13,
        2313,
        1418,
        12479,
        390,
        30586,
        279,
        11,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33502906560897827,
      "compression_ratio": 1.6458333730697632,
      "no_speech_prob": 0.15175138413906097
    },
    {
      "id": 207,
      "seek": 130872,
      "start": 2624.129970703125,
      "end": 2628.649990234375,
      "text": " was halt getrennt ist von dem Rest, zum Beispiel in Bezug auf CSS oder nicht eigene",
      "tokens": [
        50364,
        390,
        12479,
        483,
        1095,
        580,
        1418,
        2957,
        1371,
        13094,
        11,
        5919,
        13772,
        294,
        879,
        29742,
        2501,
        24387,
        4513,
        1979,
        38549,
        50590
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44686225056648254,
      "compression_ratio": 1.3766233921051025,
      "no_speech_prob": 0.00581727409735322
    },
    {
      "id": 208,
      "seek": 130872,
      "start": 2628.649990234375,
      "end": 2636.41,
      "text": " JavaScript-Dateien oder so. Und das andere ist halt, also das hat mich dazu gerade angestiftet,",
      "tokens": [
        50590,
        15778,
        12,
        35,
        473,
        1053,
        4513,
        370,
        13,
        2719,
        1482,
        10490,
        1418,
        12479,
        11,
        611,
        1482,
        2385,
        6031,
        13034,
        12117,
        2562,
        377,
        2008,
        302,
        11,
        50978
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44686225056648254,
      "compression_ratio": 1.3766233921051025,
      "no_speech_prob": 0.00581727409735322
    },
    {
      "id": 209,
      "seek": 130872,
      "start": 2636.41,
      "end": 2639.2499658203124,
      "text": " das sozusagen deutlich zu sagen,",
      "tokens": [
        50978,
        1482,
        370,
        16236,
        64,
        1766,
        24344,
        2164,
        8360,
        11,
        51120
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44686225056648254,
      "compression_ratio": 1.3766233921051025,
      "no_speech_prob": 0.00581727409735322
    },
    {
      "id": 0,
      "seek": 0,
      "start": 2639.54,
      "end": 2643.9800000572204,
      "text": " Die Implementierung war erschreckend.",
      "tokens": [
        50364,
        3229,
        4331,
        43704,
        11651,
        1516,
        41673,
        14954,
        521,
        13,
        50586
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47697368264198303,
      "compression_ratio": 1.537366509437561,
      "no_speech_prob": 0.9267382025718689
    },
    {
      "id": 1,
      "seek": 0,
      "start": 2643.9800000572204,
      "end": 2648.0600004577636,
      "text": " Einmal ist es so, man konnte einen Gast auswählen, da gibt es dann die Episode, dann klickt man",
      "tokens": [
        50586,
        6391,
        5579,
        1418,
        785,
        370,
        11,
        587,
        24058,
        4891,
        31988,
        3437,
        86,
        6860,
        6698,
        11,
        1120,
        6089,
        785,
        3594,
        978,
        19882,
        11,
        3594,
        9671,
        40522,
        587,
        50790
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47697368264198303,
      "compression_ratio": 1.537366509437561,
      "no_speech_prob": 0.9267382025718689
    },
    {
      "id": 2,
      "seek": 0,
      "start": 2648.0600004577636,
      "end": 2649.859999694824,
      "text": " halt drauf, kriegt einen 404.",
      "tokens": [
        50790,
        12479,
        22763,
        11,
        25766,
        10463,
        4891,
        3356,
        19,
        13,
        50880
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47697368264198303,
      "compression_ratio": 1.537366509437561,
      "no_speech_prob": 0.9267382025718689
    },
    {
      "id": 3,
      "seek": 0,
      "start": 2649.859999694824,
      "end": 2654.659999885559,
      "text": " Okay, das ist die Basis-Funktionalität.",
      "tokens": [
        50880,
        1033,
        11,
        1482,
        1418,
        978,
        5859,
        271,
        12,
        37,
        14797,
        1966,
        14053,
        13,
        51120
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47697368264198303,
      "compression_ratio": 1.537366509437561,
      "no_speech_prob": 0.9267382025718689
    },
    {
      "id": 4,
      "seek": 0,
      "start": 2654.659999885559,
      "end": 2659.619999923706,
      "text": " Und zwar, ich weiß nicht mehr, irgendwas stimmt an dem Link nicht.",
      "tokens": [
        51120,
        2719,
        19054,
        11,
        1893,
        13385,
        1979,
        5417,
        11,
        47090,
        37799,
        364,
        1371,
        8466,
        1979,
        13,
        51368
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47697368264198303,
      "compression_ratio": 1.537366509437561,
      "no_speech_prob": 0.9267382025718689
    },
    {
      "id": 5,
      "seek": 0,
      "start": 2659.619999923706,
      "end": 2665.699999847412,
      "text": " Ich glaube, das ist mit Underbar Post und dem Datum, also nicht 2025 und so weiter und",
      "tokens": [
        51368,
        3141,
        13756,
        11,
        1482,
        1418,
        2194,
        6974,
        5356,
        10223,
        674,
        1371,
        9315,
        449,
        11,
        611,
        1979,
        39209,
        674,
        370,
        8988,
        674,
        51672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47697368264198303,
      "compression_ratio": 1.537366509437561,
      "no_speech_prob": 0.9267382025718689
    },
    {
      "id": 6,
      "seek": 0,
      "start": 2665.699999847412,
      "end": 2666.699999847412,
      "text": " so weiter.",
      "tokens": [
        51672,
        370,
        8988,
        13,
        51722
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47697368264198303,
      "compression_ratio": 1.537366509437561,
      "no_speech_prob": 0.9267382025718689
    },
    {
      "id": 7,
      "seek": 0,
      "start": 2666.699999847412,
      "end": 2667.699999847412,
      "text": " Da war irgendwas schief.",
      "tokens": [
        51722,
        3933,
        1516,
        47090,
        956,
        2521,
        13,
        51772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47697368264198303,
      "compression_ratio": 1.537366509437561,
      "no_speech_prob": 0.9267382025718689
    },
    {
      "id": 8,
      "seek": 0,
      "start": 2667.699999847412,
      "end": 2668.699999847412,
      "text": " Irgendwie Verzeihnis fehlt oder so.",
      "tokens": [
        51772,
        9151,
        9395,
        8699,
        4281,
        1381,
        4247,
        10661,
        47994,
        4513,
        370,
        13,
        51822
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47697368264198303,
      "compression_ratio": 1.537366509437561,
      "no_speech_prob": 0.9267382025718689
    },
    {
      "id": 9,
      "seek": 2916,
      "start": 2668.699999847412,
      "end": 2673.979998626709,
      "text": " Aber in der Entwicklerin, die mir sowas abliefert, da würde ich zumindest ein Fragezeichen machen,",
      "tokens": [
        50364,
        5992,
        294,
        1163,
        29397,
        1918,
        259,
        11,
        978,
        3149,
        19766,
        296,
        410,
        6302,
        34784,
        11,
        1120,
        11942,
        1893,
        38082,
        1343,
        13685,
        1381,
        18613,
        7069,
        11,
        50628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40959715843200684,
      "compression_ratio": 1.6393442153930664,
      "no_speech_prob": 0.04270026832818985
    },
    {
      "id": 10,
      "seek": 2916,
      "start": 2673.979998626709,
      "end": 2676.54,
      "text": " weil ich hätte erwartet, dass die Person mal drauf klickt.",
      "tokens": [
        50628,
        7689,
        1893,
        20041,
        21715,
        32347,
        11,
        2658,
        978,
        8443,
        2806,
        22763,
        9671,
        40522,
        13,
        50756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40959715843200684,
      "compression_ratio": 1.6393442153930664,
      "no_speech_prob": 0.04270026832818985
    },
    {
      "id": 11,
      "seek": 2916,
      "start": 2676.54,
      "end": 2679.100001373291,
      "text": " Es können immer Fehler passieren, aber das ist halt weird.",
      "tokens": [
        50756,
        2313,
        6310,
        5578,
        48101,
        46223,
        11,
        4340,
        1482,
        1418,
        12479,
        3657,
        13,
        50884
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40959715843200684,
      "compression_ratio": 1.6393442153930664,
      "no_speech_prob": 0.04270026832818985
    },
    {
      "id": 12,
      "seek": 2916,
      "start": 2679.100001373291,
      "end": 2682.7800016784668,
      "text": " Das andere war dann, es gab internationale Sprecherinnen.",
      "tokens": [
        50884,
        2846,
        10490,
        1516,
        3594,
        11,
        785,
        17964,
        19257,
        1220,
        1738,
        265,
        6759,
        11399,
        13,
        51068
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40959715843200684,
      "compression_ratio": 1.6393442153930664,
      "no_speech_prob": 0.04270026832818985
    },
    {
      "id": 13,
      "seek": 2916,
      "start": 2682.7800016784668,
      "end": 2687.2200003051757,
      "text": " Beispiel, meine jetzt Kollegin Diana Günther.",
      "tokens": [
        51068,
        13772,
        11,
        10946,
        4354,
        46632,
        21470,
        50225,
        616,
        13,
        51290
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40959715843200684,
      "compression_ratio": 1.6393442153930664,
      "no_speech_prob": 0.04270026832818985
    },
    {
      "id": 14,
      "seek": 2916,
      "start": 2687.2200003051757,
      "end": 2692.420001068115,
      "text": " Hört sich jetzt nicht so international an, die ist auch tatsächlich nicht Deutsche,",
      "tokens": [
        51290,
        389,
        11454,
        3041,
        4354,
        1979,
        370,
        5058,
        364,
        11,
        978,
        1418,
        2168,
        20796,
        1979,
        45567,
        11,
        51550
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40959715843200684,
      "compression_ratio": 1.6393442153930664,
      "no_speech_prob": 0.04270026832818985
    },
    {
      "id": 15,
      "seek": 2916,
      "start": 2692.420001068115,
      "end": 2693.420001068115,
      "text": " wohnt halt in Berlin.",
      "tokens": [
        51550,
        48471,
        580,
        12479,
        294,
        13848,
        13,
        51600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40959715843200684,
      "compression_ratio": 1.6393442153930664,
      "no_speech_prob": 0.04270026832818985
    },
    {
      "id": 16,
      "seek": 2916,
      "start": 2693.420001068115,
      "end": 2697.420001068115,
      "text": " Und warum ist das so, warum ist das eine internationale Sprecherin?",
      "tokens": [
        51600,
        2719,
        24331,
        1418,
        1482,
        370,
        11,
        24331,
        1418,
        1482,
        3018,
        19257,
        1220,
        1738,
        265,
        6759,
        259,
        30,
        51800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40959715843200684,
      "compression_ratio": 1.6393442153930664,
      "no_speech_prob": 0.04270026832818985
    },
    {
      "id": 17,
      "seek": 5788,
      "start": 2697.420001068115,
      "end": 2703.139998474121,
      "text": " Weil sie halt damals bei der einen Episode war, zu Agile Meets Architecture und das war",
      "tokens": [
        50364,
        18665,
        2804,
        12479,
        26067,
        4643,
        1163,
        4891,
        19882,
        1516,
        11,
        2164,
        2725,
        794,
        1923,
        1385,
        43049,
        674,
        1482,
        1516,
        50650
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35793179273605347,
      "compression_ratio": 1.6889764070510864,
      "no_speech_prob": 0.24419648945331573
    },
    {
      "id": 18,
      "seek": 5788,
      "start": 2703.139998474121,
      "end": 2707.660002746582,
      "text": " eine englischsprachige Episode und dann hat das System irgendwie gesagt, also nicht hat",
      "tokens": [
        50650,
        3018,
        1741,
        75,
        5494,
        18193,
        608,
        3969,
        19882,
        674,
        3594,
        2385,
        1482,
        8910,
        20759,
        12260,
        11,
        611,
        1979,
        2385,
        50876
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35793179273605347,
      "compression_ratio": 1.6889764070510864,
      "no_speech_prob": 0.24419648945331573
    },
    {
      "id": 19,
      "seek": 5788,
      "start": 2707.660002746582,
      "end": 2711.940001525879,
      "text": " die AI irgendwie etwas generiert, was hat gesagt, Leute, die in englischsprachigen Episoden",
      "tokens": [
        50876,
        978,
        7318,
        20759,
        9569,
        1337,
        4859,
        11,
        390,
        2385,
        12260,
        11,
        13495,
        11,
        978,
        294,
        1741,
        75,
        5494,
        18193,
        608,
        3213,
        9970,
        271,
        33482,
        51090
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35793179273605347,
      "compression_ratio": 1.6889764070510864,
      "no_speech_prob": 0.24419648945331573
    },
    {
      "id": 20,
      "seek": 5788,
      "start": 2711.940001525879,
      "end": 2717.0999975585937,
      "text": " sind, sind internationale Gäste und das ist halt Quatsch.",
      "tokens": [
        51090,
        3290,
        11,
        3290,
        19257,
        1220,
        460,
        737,
        2941,
        674,
        1482,
        1418,
        12479,
        2326,
        1720,
        339,
        13,
        51348
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35793179273605347,
      "compression_ratio": 1.6889764070510864,
      "no_speech_prob": 0.24419648945331573
    },
    {
      "id": 21,
      "seek": 5788,
      "start": 2717.0999975585937,
      "end": 2720.7799978637695,
      "text": " Am Ende ist jetzt eben das Feature nicht live.",
      "tokens": [
        51348,
        2012,
        15152,
        1418,
        4354,
        11375,
        1482,
        3697,
        1503,
        1979,
        1621,
        13,
        51532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35793179273605347,
      "compression_ratio": 1.6889764070510864,
      "no_speech_prob": 0.24419648945331573
    },
    {
      "id": 22,
      "seek": 5788,
      "start": 2720.7799978637695,
      "end": 2725.419997253418,
      "text": " Ich weiß auch nicht, ob das ein wichtiges Feature ist.",
      "tokens": [
        51532,
        3141,
        13385,
        2168,
        1979,
        11,
        1111,
        1482,
        1343,
        13621,
        279,
        3697,
        1503,
        1418,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35793179273605347,
      "compression_ratio": 1.6889764070510864,
      "no_speech_prob": 0.24419648945331573
    },
    {
      "id": 23,
      "seek": 8588,
      "start": 2725.419997253418,
      "end": 2728.139998474121,
      "text": " Ihr könnt euch jetzt melden und sagen, das brauchen wir halt unbedingt.",
      "tokens": [
        50364,
        14773,
        22541,
        10403,
        4354,
        4795,
        1556,
        674,
        8360,
        11,
        1482,
        19543,
        1987,
        12479,
        41211,
        13,
        50500
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4543473422527313,
      "compression_ratio": 1.530035376548767,
      "no_speech_prob": 0.27423450350761414
    },
    {
      "id": 24,
      "seek": 8588,
      "start": 2728.139998474121,
      "end": 2731.340003051758,
      "text": " Ich weiß nicht, wie wichtig das wirklich ist, ich fand das mit den Zusammenfassungen",
      "tokens": [
        50500,
        3141,
        13385,
        1979,
        11,
        3355,
        13621,
        1482,
        9696,
        1418,
        11,
        1893,
        38138,
        1482,
        2194,
        1441,
        29442,
        69,
        640,
        5084,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4543473422527313,
      "compression_ratio": 1.530035376548767,
      "no_speech_prob": 0.27423450350761414
    },
    {
      "id": 25,
      "seek": 8588,
      "start": 2731.340003051758,
      "end": 2732.340003051758,
      "text": " halt sehr wichtig.",
      "tokens": [
        50660,
        12479,
        5499,
        13621,
        13,
        50710
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4543473422527313,
      "compression_ratio": 1.530035376548767,
      "no_speech_prob": 0.27423450350761414
    },
    {
      "id": 26,
      "seek": 8588,
      "start": 2732.340003051758,
      "end": 2737.0599966430664,
      "text": " Mit den Gästen bin ich mir nicht so sicher, da kann man ja auch Volltext-Suche machen",
      "tokens": [
        50710,
        10821,
        1441,
        460,
        737,
        6266,
        5171,
        1893,
        3149,
        1979,
        370,
        18623,
        11,
        1120,
        4028,
        587,
        2784,
        2168,
        39602,
        25111,
        12,
        50,
        17545,
        7069,
        50946
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4543473422527313,
      "compression_ratio": 1.530035376548767,
      "no_speech_prob": 0.27423450350761414
    },
    {
      "id": 27,
      "seek": 8588,
      "start": 2737.0599966430664,
      "end": 2744.940001525879,
      "text": " auf der Webseite mit allen Episoden, aber das Ergebnis war halt einfach, also unterirdisch,",
      "tokens": [
        50946,
        2501,
        1163,
        9573,
        405,
        642,
        2194,
        18440,
        9970,
        271,
        33482,
        11,
        4340,
        1482,
        46229,
        1516,
        12479,
        7281,
        11,
        611,
        8662,
        1271,
        5494,
        11,
        51340
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4543473422527313,
      "compression_ratio": 1.530035376548767,
      "no_speech_prob": 0.27423450350761414
    },
    {
      "id": 28,
      "seek": 8588,
      "start": 2744.940001525879,
      "end": 2748.0599966430664,
      "text": " ist halt so nicht zu benutzen, Null.",
      "tokens": [
        51340,
        1418,
        12479,
        370,
        1979,
        2164,
        38424,
        2904,
        11,
        426,
        858,
        13,
        51496
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4543473422527313,
      "compression_ratio": 1.530035376548767,
      "no_speech_prob": 0.27423450350761414
    },
    {
      "id": 29,
      "seek": 8588,
      "start": 2748.0599966430664,
      "end": 2751.1799993896484,
      "text": " Was ich daran faszinierend fand, war…",
      "tokens": [
        51496,
        3027,
        1893,
        24520,
        283,
        19601,
        259,
        811,
        521,
        38138,
        11,
        1516,
        1260,
        51652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4543473422527313,
      "compression_ratio": 1.530035376548767,
      "no_speech_prob": 0.27423450350761414
    },
    {
      "id": 30,
      "seek": 11164,
      "start": 2752.1799993896484,
      "end": 2757.3799963378906,
      "text": " Und dann war halt wieder dieses Transkriptionsproblem, dass nämlich irgendwelche Sprecherinhalte",
      "tokens": [
        50414,
        2719,
        3594,
        1516,
        12479,
        6216,
        12113,
        6531,
        74,
        470,
        9799,
        47419,
        11,
        2658,
        297,
        9559,
        1739,
        26455,
        338,
        1876,
        1738,
        265,
        6759,
        259,
        4947,
        975,
        50674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38502705097198486,
      "compression_ratio": 1.6066176891326904,
      "no_speech_prob": 0.6960509419441223
    },
    {
      "id": 31,
      "seek": 11164,
      "start": 2757.3799963378906,
      "end": 2763.340003051758,
      "text": " nicht vernünftig extrahiert worden sind und wir haben jetzt 260 Episoden oder so, 80,",
      "tokens": [
        50674,
        1979,
        35793,
        3412,
        34765,
        2857,
        71,
        4859,
        14054,
        3290,
        674,
        1987,
        3084,
        4354,
        44624,
        9970,
        271,
        33482,
        4513,
        370,
        11,
        4688,
        11,
        50972
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38502705097198486,
      "compression_ratio": 1.6066176891326904,
      "no_speech_prob": 0.6960509419441223
    },
    {
      "id": 32,
      "seek": 11164,
      "start": 2763.340003051758,
      "end": 2769.3799963378906,
      "text": " 280, weiß nicht, also wahnsinnig viele Episoden, sodass man da das Mindestzeit-Reviewen müssen",
      "tokens": [
        50972,
        41229,
        11,
        13385,
        1979,
        11,
        611,
        31979,
        46134,
        328,
        9693,
        9970,
        271,
        33482,
        11,
        15047,
        640,
        587,
        1120,
        1482,
        13719,
        377,
        13712,
        12,
        8524,
        1759,
        268,
        9013,
        51274
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38502705097198486,
      "compression_ratio": 1.6066176891326904,
      "no_speech_prob": 0.6960509419441223
    },
    {
      "id": 33,
      "seek": 11164,
      "start": 2769.3799963378906,
      "end": 2774.9000006103515,
      "text": " wahrscheinlich sogar explizit reineditieren müssen, also die Sprecher irgendwie auflisten",
      "tokens": [
        51274,
        30957,
        19485,
        1490,
        590,
        270,
        6561,
        292,
        270,
        5695,
        9013,
        11,
        611,
        978,
        1738,
        265,
        6759,
        20759,
        2501,
        75,
        4821,
        51550
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38502705097198486,
      "compression_ratio": 1.6066176891326904,
      "no_speech_prob": 0.6960509419441223
    },
    {
      "id": 34,
      "seek": 11164,
      "start": 2774.9000006103515,
      "end": 2777.819998779297,
      "text": " müssen und das ist halt irgendwie auch wahnsinnig viel Aufwand.",
      "tokens": [
        51550,
        9013,
        674,
        1482,
        1418,
        12479,
        20759,
        2168,
        31979,
        46134,
        328,
        5891,
        9462,
        33114,
        13,
        51696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38502705097198486,
      "compression_ratio": 1.6066176891326904,
      "no_speech_prob": 0.6960509419441223
    },
    {
      "id": 35,
      "seek": 13828,
      "start": 2778.819998779297,
      "end": 2784.739996948242,
      "text": " Was ich faszinierend fand, war, weil du eben auch von Software-Erstellung ist, was Soziales",
      "tokens": [
        50414,
        3027,
        1893,
        283,
        19601,
        259,
        811,
        521,
        38138,
        11,
        1516,
        11,
        7689,
        1581,
        11375,
        2168,
        2957,
        27428,
        12,
        28135,
        30016,
        1418,
        11,
        390,
        36867,
        279,
        50710
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2974497973918915,
      "compression_ratio": 1.5536481142044067,
      "no_speech_prob": 0.02552654966711998
    },
    {
      "id": 36,
      "seek": 13828,
      "start": 2784.739996948242,
      "end": 2793.819998779297,
      "text": " auch gesprochen hast, wäre das mein Code gewesen, dann hättest du echt Probleme gehabt,",
      "tokens": [
        50710,
        2168,
        42714,
        6581,
        11,
        14558,
        1482,
        10777,
        15549,
        27653,
        11,
        3594,
        276,
        11567,
        377,
        1581,
        13972,
        32891,
        37092,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2974497973918915,
      "compression_ratio": 1.5536481142044067,
      "no_speech_prob": 0.02552654966711998
    },
    {
      "id": 37,
      "seek": 13828,
      "start": 2793.819998779297,
      "end": 2800.0999975585937,
      "text": " mir den um die Ohren zu hauen, wie sage ich es richtig und vielleicht kennt auch der ein",
      "tokens": [
        51164,
        3149,
        1441,
        1105,
        978,
        876,
        1095,
        2164,
        324,
        7801,
        11,
        3355,
        19721,
        1893,
        785,
        13129,
        674,
        12547,
        37682,
        2168,
        1163,
        1343,
        51478
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2974497973918915,
      "compression_ratio": 1.5536481142044067,
      "no_speech_prob": 0.02552654966711998
    },
    {
      "id": 38,
      "seek": 13828,
      "start": 2800.0999975585937,
      "end": 2806.340003051758,
      "text": " oder andere dieses Problem, man merkt, dass jemand im Team an seinem Code hängt, an seinen",
      "tokens": [
        51478,
        4513,
        10490,
        12113,
        11676,
        11,
        587,
        3551,
        2320,
        11,
        2658,
        21717,
        566,
        7606,
        364,
        29187,
        15549,
        276,
        29670,
        11,
        364,
        24427,
        51790
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2974497973918915,
      "compression_ratio": 1.5536481142044067,
      "no_speech_prob": 0.02552654966711998
    },
    {
      "id": 39,
      "seek": 16680,
      "start": 2806.340003051758,
      "end": 2813.54,
      "text": " Ideen hängt, an seiner Technologie, die er reingebracht hat und in dem Fall fand ich",
      "tokens": [
        50364,
        13090,
        268,
        276,
        29670,
        11,
        364,
        23114,
        8337,
        20121,
        11,
        978,
        1189,
        319,
        8735,
        23404,
        2385,
        674,
        294,
        1371,
        7465,
        38138,
        1893,
        50724
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31642505526542664,
      "compression_ratio": 1.4285714626312256,
      "no_speech_prob": 0.2505375146865845
    },
    {
      "id": 40,
      "seek": 16680,
      "start": 2813.54,
      "end": 2814.54,
      "text": " das so klasse.",
      "tokens": [
        50724,
        1482,
        370,
        350,
        40255,
        13,
        50774
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31642505526542664,
      "compression_ratio": 1.4285714626312256,
      "no_speech_prob": 0.2505375146865845
    },
    {
      "id": 41,
      "seek": 16680,
      "start": 2814.54,
      "end": 2820.4599981689453,
      "text": " Ich selbst habe überhaupt keine Verbindung zu dem Code gehabt, ich habe einfach gesagt,",
      "tokens": [
        50774,
        3141,
        13053,
        6015,
        20023,
        9252,
        27034,
        41442,
        2164,
        1371,
        15549,
        37092,
        11,
        1893,
        6015,
        7281,
        12260,
        11,
        51070
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31642505526542664,
      "compression_ratio": 1.4285714626312256,
      "no_speech_prob": 0.2505375146865845
    },
    {
      "id": 42,
      "seek": 16680,
      "start": 2820.4599981689453,
      "end": 2828.780005493164,
      "text": " gut, ist bescheuert der Code, löschen wir ihn, hat ein paar Token gekostet, keine Ahnung,",
      "tokens": [
        51070,
        5228,
        11,
        1418,
        4097,
        1876,
        84,
        911,
        1163,
        15549,
        11,
        25209,
        6145,
        268,
        1987,
        14534,
        11,
        2385,
        1343,
        16509,
        314,
        8406,
        14037,
        555,
        302,
        11,
        9252,
        2438,
        15539,
        11,
        51486
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31642505526542664,
      "compression_ratio": 1.4285714626312256,
      "no_speech_prob": 0.2505375146865845
    },
    {
      "id": 43,
      "seek": 18924,
      "start": 2828.780005493164,
      "end": 2838.340003051758,
      "text": " 60 Cent, weg und das finde ich super, weil mir das einfach mehr Entscheidungsfreiheit",
      "tokens": [
        50364,
        4060,
        3408,
        11,
        15565,
        674,
        1482,
        17841,
        1893,
        1687,
        11,
        7689,
        3149,
        1482,
        7281,
        5417,
        30862,
        5846,
        42072,
        8480,
        50842
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3952450454235077,
      "compression_ratio": 1.4802260398864746,
      "no_speech_prob": 0.5876632928848267
    },
    {
      "id": 44,
      "seek": 18924,
      "start": 2838.340003051758,
      "end": 2844.54,
      "text": " gibt, dass ich einfach ein Proof-of-Concept machen kann und einfach sagen kann, nee, das",
      "tokens": [
        50842,
        6089,
        11,
        2658,
        1893,
        7281,
        1343,
        1705,
        2670,
        12,
        2670,
        12,
        9838,
        1336,
        7069,
        4028,
        674,
        7281,
        8360,
        4028,
        11,
        41694,
        11,
        1482,
        51152
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3952450454235077,
      "compression_ratio": 1.4802260398864746,
      "no_speech_prob": 0.5876632928848267
    },
    {
      "id": 45,
      "seek": 18924,
      "start": 2844.54,
      "end": 2845.54,
      "text": " war nichts, weg damit.",
      "tokens": [
        51152,
        1516,
        13004,
        11,
        15565,
        9479,
        13,
        51202
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3952450454235077,
      "compression_ratio": 1.4802260398864746,
      "no_speech_prob": 0.5876632928848267
    },
    {
      "id": 46,
      "seek": 18924,
      "start": 2845.54,
      "end": 2853.060004272461,
      "text": " Diese Bindung zum Code ist weg, ich bin auf einer anderen Ebene.",
      "tokens": [
        51202,
        18993,
        363,
        41442,
        5919,
        15549,
        1418,
        15565,
        11,
        1893,
        5171,
        2501,
        6850,
        11122,
        20418,
        1450,
        13,
        51578
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3952450454235077,
      "compression_ratio": 1.4802260398864746,
      "no_speech_prob": 0.5876632928848267
    },
    {
      "id": 47,
      "seek": 21352,
      "start": 2854.060004272461,
      "end": 2861.579993286133,
      "text": " Mein Problem ist, faire Betrachtung und ich fand das auch nicht offensichtlich, mein Learning",
      "tokens": [
        50414,
        18382,
        11676,
        1418,
        11,
        283,
        1301,
        265,
        6279,
        81,
        3589,
        1063,
        674,
        1893,
        38138,
        1482,
        2168,
        1979,
        766,
        694,
        41971,
        11,
        10777,
        15205,
        50790
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4916163384914398,
      "compression_ratio": 1.5541125535964966,
      "no_speech_prob": 0.22223202884197235
    },
    {
      "id": 48,
      "seek": 21352,
      "start": 2861.579993286133,
      "end": 2865.980002441406,
      "text": " oder meine Frage, die sich irgendwie daraus ergibt, ist, bei aller Freundschaft, aber",
      "tokens": [
        50790,
        4513,
        10946,
        13685,
        11,
        978,
        3041,
        20759,
        274,
        46483,
        26585,
        13651,
        11,
        1418,
        11,
        4643,
        8722,
        29685,
        37363,
        11,
        4340,
        51010
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4916163384914398,
      "compression_ratio": 1.5541125535964966,
      "no_speech_prob": 0.22223202884197235
    },
    {
      "id": 49,
      "seek": 21352,
      "start": 2865.980002441406,
      "end": 2869.980002441406,
      "text": " Software-Ethik zum Streamen ist eine triviale Webseite, die ist wirklich trivial eigentlich.",
      "tokens": [
        51010,
        27428,
        12,
        36,
        392,
        1035,
        5919,
        24904,
        268,
        1418,
        3018,
        26703,
        68,
        9573,
        405,
        642,
        11,
        978,
        1418,
        9696,
        26703,
        10926,
        13,
        51210
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4916163384914398,
      "compression_ratio": 1.5541125535964966,
      "no_speech_prob": 0.22223202884197235
    },
    {
      "id": 50,
      "seek": 21352,
      "start": 2869.980002441406,
      "end": 2878.9399938964843,
      "text": " Wenn wir da so etwas schon nicht hinbekommen und auf dieser Ebene fehlen, verstehe ich",
      "tokens": [
        51210,
        7899,
        1987,
        1120,
        370,
        9569,
        4981,
        1979,
        14102,
        650,
        13675,
        674,
        2501,
        9053,
        20418,
        1450,
        34741,
        6698,
        11,
        22442,
        675,
        1893,
        51658
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4916163384914398,
      "compression_ratio": 1.5541125535964966,
      "no_speech_prob": 0.22223202884197235
    },
    {
      "id": 51,
      "seek": 23940,
      "start": 2878.9399938964843,
      "end": 2883.9399938964843,
      "text": " nicht, vielleicht gibt es ja irgendwo einen Technologiesprung, das kann immer mal passieren",
      "tokens": [
        50364,
        1979,
        11,
        12547,
        6089,
        785,
        2784,
        40865,
        4891,
        8337,
        1132,
        530,
        1424,
        1063,
        11,
        1482,
        4028,
        5578,
        2806,
        46223,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33210572600364685,
      "compression_ratio": 1.6505576372146606,
      "no_speech_prob": 0.32013487815856934
    },
    {
      "id": 52,
      "seek": 23940,
      "start": 2883.9399938964843,
      "end": 2888.4599981689453,
      "text": " und die sind schwer vorhersehbar, aber im Prinzip ist das ein Desaster, was da produziert",
      "tokens": [
        50614,
        674,
        978,
        3290,
        23809,
        29195,
        405,
        71,
        5356,
        11,
        4340,
        566,
        47572,
        1418,
        1482,
        1343,
        3885,
        1727,
        11,
        390,
        1120,
        28093,
        4859,
        50840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33210572600364685,
      "compression_ratio": 1.6505576372146606,
      "no_speech_prob": 0.32013487815856934
    },
    {
      "id": 53,
      "seek": 23940,
      "start": 2888.4599981689453,
      "end": 2897.059989013672,
      "text": " wird und ich verstehe nicht, wo dieser Hype herkommt, der hat besagt, dass man nicht mehr",
      "tokens": [
        50840,
        4578,
        674,
        1893,
        22442,
        675,
        1979,
        11,
        6020,
        9053,
        5701,
        494,
        720,
        74,
        22230,
        11,
        1163,
        2385,
        4097,
        7665,
        11,
        2658,
        587,
        1979,
        5417,
        51270
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33210572600364685,
      "compression_ratio": 1.6505576372146606,
      "no_speech_prob": 0.32013487815856934
    },
    {
      "id": 54,
      "seek": 23940,
      "start": 2897.059989013672,
      "end": 2903.4200048828125,
      "text": " entwickeln lernen soll, das ist mit den Ergebnissen, die ich da zumindest auch wieder gesehen habe",
      "tokens": [
        51270,
        28449,
        32099,
        36082,
        7114,
        11,
        1482,
        1418,
        2194,
        1441,
        34657,
        77,
        10987,
        11,
        978,
        1893,
        1120,
        5919,
        72,
        273,
        377,
        2168,
        6216,
        21535,
        6015,
        51588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33210572600364685,
      "compression_ratio": 1.6505576372146606,
      "no_speech_prob": 0.32013487815856934
    },
    {
      "id": 55,
      "seek": 23940,
      "start": 2903.4200048828125,
      "end": 2906.8999853515625,
      "text": " und ich sehe auch keine anderen Ergebnisse, ist das nicht rechtfertigbar.",
      "tokens": [
        51588,
        674,
        1893,
        35995,
        2168,
        9252,
        11122,
        34657,
        31481,
        11,
        1418,
        1482,
        1979,
        24261,
        34784,
        328,
        5356,
        13,
        51762
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33210572600364685,
      "compression_ratio": 1.6505576372146606,
      "no_speech_prob": 0.32013487815856934
    },
    {
      "id": 56,
      "seek": 26736,
      "start": 2907.8999853515625,
      "end": 2914.0999975585937,
      "text": " Ich habe auch gerade eine Umfrage bei Mastodon und bei LinkedIn laufen, wo die Menschen sagen",
      "tokens": [
        50414,
        3141,
        6015,
        2168,
        12117,
        3018,
        3301,
        40449,
        4643,
        376,
        525,
        378,
        266,
        674,
        4643,
        20657,
        41647,
        11,
        6020,
        978,
        8397,
        8360,
        50724
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3720698356628418,
      "compression_ratio": 1.4077669382095337,
      "no_speech_prob": 0.11886918544769287
    },
    {
      "id": 57,
      "seek": 26736,
      "start": 2914.0999975585937,
      "end": 2920.7000036621093,
      "text": " können, wie viel Produktivitätsvorteil sie eigentlich bei Coding tatsächlich jetzt sehen",
      "tokens": [
        50724,
        6310,
        11,
        3355,
        5891,
        44599,
        592,
        13187,
        1373,
        85,
        12752,
        388,
        2804,
        10926,
        4643,
        383,
        8616,
        20796,
        4354,
        11333,
        51054
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3720698356628418,
      "compression_ratio": 1.4077669382095337,
      "no_speech_prob": 0.11886918544769287
    },
    {
      "id": 58,
      "seek": 26736,
      "start": 2920.7000036621093,
      "end": 2933.0999975585937,
      "text": " und da gibt es wahnsinnig wenig Antwortmöglichkeiten, sind halt ein Decrease, also Abnahme der jetzigen",
      "tokens": [
        51054,
        674,
        1120,
        6089,
        785,
        31979,
        46134,
        328,
        20911,
        34693,
        76,
        16277,
        21049,
        11,
        3290,
        12479,
        1343,
        12427,
        265,
        651,
        11,
        611,
        2847,
        32796,
        1163,
        361,
        10074,
        3213,
        51674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3720698356628418,
      "compression_ratio": 1.4077669382095337,
      "no_speech_prob": 0.11886918544769287
    },
    {
      "id": 59,
      "seek": 29356,
      "start": 2933.260001220703,
      "end": 2938.4200048828125,
      "text": " Produktivität, dann 1 bis 2, also dass man maximal doppelt so schnell wird, das ist die",
      "tokens": [
        50372,
        44599,
        592,
        14053,
        11,
        3594,
        502,
        7393,
        568,
        11,
        611,
        2658,
        587,
        49336,
        44862,
        2018,
        370,
        17589,
        4578,
        11,
        1482,
        1418,
        978,
        50630
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3440527021884918,
      "compression_ratio": 1.4568527936935425,
      "no_speech_prob": 0.15188068151474
    },
    {
      "id": 60,
      "seek": 29356,
      "start": 2938.4200048828125,
      "end": 2947.219992675781,
      "text": " andere Kategorie, dann 2 bis 5 und ich glaube ich mehr als 5 und ich kann mal gucken, ich hatte",
      "tokens": [
        50630,
        10490,
        591,
        2968,
        17473,
        11,
        3594,
        568,
        7393,
        1025,
        674,
        1893,
        13756,
        1893,
        5417,
        3907,
        1025,
        674,
        1893,
        4028,
        2806,
        33135,
        11,
        1893,
        13299,
        51070
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3440527021884918,
      "compression_ratio": 1.4568527936935425,
      "no_speech_prob": 0.15188068151474
    },
    {
      "id": 61,
      "seek": 29356,
      "start": 2947.219992675781,
      "end": 2958.020010986328,
      "text": " vorhin die auch irgendwie rumgeschickt, genau also bei Mastodon ist es halt so, dass 40 Prozent sagen,",
      "tokens": [
        51070,
        4245,
        10876,
        978,
        2168,
        20759,
        8347,
        23378,
        40522,
        11,
        12535,
        611,
        4643,
        376,
        525,
        378,
        266,
        1418,
        785,
        12479,
        370,
        11,
        2658,
        3356,
        29726,
        8360,
        11,
        51610
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3440527021884918,
      "compression_ratio": 1.4568527936935425,
      "no_speech_prob": 0.15188068151474
    },
    {
      "id": 62,
      "seek": 31848,
      "start": 2958.020010986328,
      "end": 2963.740012207031,
      "text": " es gibt eine Abnahme, 50 Prozent haben 1 bis 2, 8 Prozent haben 2 bis 5 und 2 Prozent haben",
      "tokens": [
        50364,
        785,
        6089,
        3018,
        2847,
        32796,
        11,
        2625,
        29726,
        3084,
        502,
        7393,
        568,
        11,
        1649,
        29726,
        3084,
        568,
        7393,
        1025,
        674,
        568,
        29726,
        3084,
        50650
      ],
      "temperature": 0.0,
      "avg_logprob": -0.250822514295578,
      "compression_ratio": 1.7948718070983887,
      "no_speech_prob": 0.10064414888620377
    },
    {
      "id": 63,
      "seek": 31848,
      "start": 2963.740012207031,
      "end": 2973.260001220703,
      "text": " mehr als 5, also mehr als Faktor 5, also nicht 40 Prozent sagen, es wird langsamer, bei LinkedIn",
      "tokens": [
        50650,
        5417,
        3907,
        1025,
        11,
        611,
        5417,
        3907,
        479,
        5886,
        284,
        1025,
        11,
        611,
        1979,
        3356,
        29726,
        8360,
        11,
        785,
        4578,
        2265,
        82,
        13530,
        11,
        4643,
        20657,
        51126
      ],
      "temperature": 0.0,
      "avg_logprob": -0.250822514295578,
      "compression_ratio": 1.7948718070983887,
      "no_speech_prob": 0.10064414888620377
    },
    {
      "id": 64,
      "seek": 31848,
      "start": 2973.260001220703,
      "end": 2981.4200048828125,
      "text": " sind es 13 Prozent Abnahme, 58 Prozent 1 bis 2 mal, also Faktor 1 bis 2, 19 Prozent 2 bis 5",
      "tokens": [
        51126,
        3290,
        785,
        3705,
        29726,
        2847,
        32796,
        11,
        21786,
        29726,
        502,
        7393,
        568,
        2806,
        11,
        611,
        479,
        5886,
        284,
        502,
        7393,
        568,
        11,
        1294,
        29726,
        568,
        7393,
        1025,
        51534
      ],
      "temperature": 0.0,
      "avg_logprob": -0.250822514295578,
      "compression_ratio": 1.7948718070983887,
      "no_speech_prob": 0.10064414888620377
    },
    {
      "id": 65,
      "seek": 34188,
      "start": 2981.4200048828125,
      "end": 2989.4600134277343,
      "text": " und dann 9 Prozent mehr als 5, das bedeutet, das was wir hier beobachten, ist meiner Ansicht nach",
      "tokens": [
        50364,
        674,
        3594,
        1722,
        29726,
        5417,
        3907,
        1025,
        11,
        1482,
        27018,
        11,
        1482,
        390,
        1987,
        3296,
        312,
        996,
        20806,
        11,
        1418,
        20529,
        14590,
        1405,
        5168,
        50766
      ],
      "temperature": 0.0,
      "avg_logprob": -0.323638916015625,
      "compression_ratio": 1.441624402999878,
      "no_speech_prob": 0.21701668202877045
    },
    {
      "id": 66,
      "seek": 34188,
      "start": 2989.4600134277343,
      "end": 2997.4200048828125,
      "text": " nicht außergewöhnlich, also das ist halt eher eine Erfahrung, die wir teilen als Branche,",
      "tokens": [
        50766,
        1979,
        39428,
        21306,
        973,
        35646,
        11,
        611,
        1482,
        1418,
        12479,
        24332,
        3018,
        49318,
        11,
        978,
        1987,
        535,
        17471,
        3907,
        1603,
        22806,
        11,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.323638916015625,
      "compression_ratio": 1.441624402999878,
      "no_speech_prob": 0.21701668202877045
    },
    {
      "id": 67,
      "seek": 34188,
      "start": 2997.4200048828125,
      "end": 3007.300009765625,
      "text": " das war für mich auch die Motivation, die Umfrage zu machen, also nicht Urauslöser war halt,",
      "tokens": [
        51164,
        1482,
        1516,
        2959,
        6031,
        2168,
        978,
        8956,
        592,
        399,
        11,
        978,
        3301,
        40449,
        2164,
        7069,
        11,
        611,
        1979,
        9533,
        8463,
        75,
        11310,
        260,
        1516,
        12479,
        11,
        51658
      ],
      "temperature": 0.0,
      "avg_logprob": -0.323638916015625,
      "compression_ratio": 1.441624402999878,
      "no_speech_prob": 0.21701668202877045
    },
    {
      "id": 68,
      "seek": 36776,
      "start": 3007.4600134277343,
      "end": 3014.9399938964843,
      "text": " dass es diese Paper gab, von wegen Majority View on AI, wo halt im Prinzip das drin stand,",
      "tokens": [
        50372,
        2658,
        785,
        6705,
        24990,
        17964,
        11,
        2957,
        32855,
        15581,
        507,
        13909,
        322,
        7318,
        11,
        6020,
        12479,
        566,
        47572,
        1482,
        24534,
        1463,
        11,
        50746
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3539125919342041,
      "compression_ratio": 1.6338982582092285,
      "no_speech_prob": 0.06609652191400528
    },
    {
      "id": 69,
      "seek": 36776,
      "start": 3014.9399938964843,
      "end": 3020.6199865722656,
      "text": " dass also die meisten Leute AI-pessimistisch sind, dann hatte ich eine Diskussion auf Mastodon mit",
      "tokens": [
        50746,
        2658,
        611,
        978,
        29708,
        13495,
        7318,
        12,
        79,
        442,
        332,
        468,
        5494,
        3290,
        11,
        3594,
        13299,
        1893,
        3018,
        45963,
        313,
        2501,
        376,
        525,
        378,
        266,
        2194,
        51030
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3539125919342041,
      "compression_ratio": 1.6338982582092285,
      "no_speech_prob": 0.06609652191400528
    },
    {
      "id": 70,
      "seek": 36776,
      "start": 3020.6199865722656,
      "end": 3026.54,
      "text": " dem Johannes Link, der mir gesagt hat, naja, also ich sehe jetzt wieder andere Leute und das hatte",
      "tokens": [
        51030,
        1371,
        48455,
        8466,
        11,
        1163,
        3149,
        12260,
        2385,
        11,
        1667,
        2938,
        11,
        611,
        1893,
        35995,
        4354,
        6216,
        10490,
        13495,
        674,
        1482,
        13299,
        51326
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3539125919342041,
      "compression_ratio": 1.6338982582092285,
      "no_speech_prob": 0.06609652191400528
    },
    {
      "id": 71,
      "seek": 36776,
      "start": 3026.54,
      "end": 3031.260001220703,
      "text": " dann den Aufschlag gegeben, halt diese Umfrage zu machen und die sagt eigentlich, also ich habe es",
      "tokens": [
        51326,
        3594,
        1441,
        9462,
        6145,
        27298,
        32572,
        11,
        12479,
        6705,
        3301,
        40449,
        2164,
        7069,
        674,
        978,
        15764,
        10926,
        11,
        611,
        1893,
        6015,
        785,
        51562
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3539125919342041,
      "compression_ratio": 1.6338982582092285,
      "no_speech_prob": 0.06609652191400528
    },
    {
      "id": 72,
      "seek": 36776,
      "start": 3031.260001220703,
      "end": 3035.7000036621093,
      "text": " ja vorhin auch gesagt und vielleicht kommen wir noch dazu in den letzten 10 Minuten, also wenn",
      "tokens": [
        51562,
        2784,
        4245,
        10876,
        2168,
        12260,
        674,
        12547,
        11729,
        1987,
        3514,
        13034,
        294,
        1441,
        18226,
        1266,
        27593,
        11,
        611,
        4797,
        51784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3539125919342041,
      "compression_ratio": 1.6338982582092285,
      "no_speech_prob": 0.06609652191400528
    },
    {
      "id": 73,
      "seek": 39616,
      "start": 3035.7000036621093,
      "end": 3039.4600134277343,
      "text": " ich hätte, es war etwas nicht, wie wir alles an der Webseite machen, ich kenne Jackal nicht",
      "tokens": [
        50364,
        1893,
        20041,
        11,
        785,
        1516,
        9569,
        1979,
        11,
        3355,
        1987,
        7874,
        364,
        1163,
        9573,
        405,
        642,
        7069,
        11,
        1893,
        350,
        13295,
        4718,
        304,
        1979,
        50552
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397177457809448,
      "compression_ratio": 1.6484642028808594,
      "no_speech_prob": 0.06443607062101364
    },
    {
      "id": 74,
      "seek": 39616,
      "start": 3039.4600134277343,
      "end": 3046.020010986328,
      "text": " besonders gut, mir hilft JetGPT dabei halt massiv. Es gibt also einen, meiner Ansicht nach, einen",
      "tokens": [
        50552,
        25258,
        5228,
        11,
        3149,
        42493,
        28730,
        38,
        47,
        51,
        14967,
        12479,
        2758,
        592,
        13,
        2313,
        6089,
        611,
        4891,
        11,
        20529,
        14590,
        1405,
        5168,
        11,
        4891,
        50880
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397177457809448,
      "compression_ratio": 1.6484642028808594,
      "no_speech_prob": 0.06443607062101364
    },
    {
      "id": 75,
      "seek": 39616,
      "start": 3046.020010986328,
      "end": 3052.580008544922,
      "text": " Vorteil, aber das andere, was wir halt beobachten und für mich persönlich ist der Vorteil vor allem,",
      "tokens": [
        50880,
        46968,
        388,
        11,
        4340,
        1482,
        10490,
        11,
        390,
        1987,
        12479,
        312,
        996,
        20806,
        674,
        2959,
        6031,
        42699,
        1418,
        1163,
        46968,
        388,
        4245,
        17585,
        11,
        51208
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397177457809448,
      "compression_ratio": 1.6484642028808594,
      "no_speech_prob": 0.06443607062101364
    },
    {
      "id": 76,
      "seek": 39616,
      "start": 3052.580008544922,
      "end": 3057.059989013672,
      "text": " ich wage mich da halt ran und ich kriege halt Dinge schneller gelöst in System, die ich halt",
      "tokens": [
        51208,
        1893,
        15444,
        6031,
        1120,
        12479,
        5872,
        674,
        1893,
        25766,
        432,
        12479,
        25102,
        43865,
        4087,
        36995,
        294,
        8910,
        11,
        978,
        1893,
        12479,
        51432
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397177457809448,
      "compression_ratio": 1.6484642028808594,
      "no_speech_prob": 0.06443607062101364
    },
    {
      "id": 77,
      "seek": 39616,
      "start": 3057.059989013672,
      "end": 3063.580008544922,
      "text": " irgendwie nicht besonders gut verstehe, aber zu glauben, dass so ein System Software entwickeln",
      "tokens": [
        51432,
        20759,
        1979,
        25258,
        5228,
        22442,
        675,
        11,
        4340,
        2164,
        47139,
        11,
        2658,
        370,
        1343,
        8910,
        27428,
        28449,
        32099,
        51758
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3397177457809448,
      "compression_ratio": 1.6484642028808594,
      "no_speech_prob": 0.06443607062101364
    },
    {
      "id": 78,
      "seek": 42404,
      "start": 3063.580008544922,
      "end": 3071.1800146484375,
      "text": " kann und das halt irgendwie hinbekommt, ist im Moment durch nichts gedeckt. Absolut, also ich",
      "tokens": [
        50364,
        4028,
        674,
        1482,
        12479,
        20759,
        14102,
        25714,
        22230,
        11,
        1418,
        566,
        19093,
        7131,
        13004,
        290,
        4858,
        19951,
        13,
        5813,
        2308,
        11,
        611,
        1893,
        50744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25616487860679626,
      "compression_ratio": 1.5396825075149536,
      "no_speech_prob": 0.02796287275850773
    },
    {
      "id": 79,
      "seek": 42404,
      "start": 3071.1800146484375,
      "end": 3076.9399938964843,
      "text": " finde es auch schwierig, das Pendel schwingt hin und her, ja, anfangs waren wir alle begeistert,",
      "tokens": [
        50744,
        17841,
        785,
        2168,
        37845,
        11,
        1482,
        38048,
        338,
        956,
        7904,
        83,
        14102,
        674,
        720,
        11,
        2784,
        11,
        364,
        19134,
        82,
        11931,
        1987,
        5430,
        41832,
        1964,
        83,
        11,
        51032
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25616487860679626,
      "compression_ratio": 1.5396825075149536,
      "no_speech_prob": 0.02796287275850773
    },
    {
      "id": 80,
      "seek": 42404,
      "start": 3076.9399938964843,
      "end": 3083.3399877929687,
      "text": " hey, das Teil, ich sage ihm, programmier mir einen Taschenrechner in HTML mit JavaScript und CSS und",
      "tokens": [
        51032,
        4177,
        11,
        1482,
        16357,
        11,
        1893,
        19721,
        16021,
        11,
        37648,
        811,
        3149,
        4891,
        27293,
        2470,
        265,
        339,
        1193,
        294,
        17995,
        2194,
        15778,
        674,
        24387,
        674,
        51352
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25616487860679626,
      "compression_ratio": 1.5396825075149536,
      "no_speech_prob": 0.02796287275850773
    },
    {
      "id": 81,
      "seek": 42404,
      "start": 3083.3399877929687,
      "end": 3088.059989013672,
      "text": " pump, ist der Taschenrechner da, dass der nach iOS aussieht, daran haben wir uns nicht gestört,",
      "tokens": [
        51352,
        48842,
        79,
        11,
        1418,
        1163,
        27293,
        2470,
        265,
        339,
        1193,
        1120,
        11,
        2658,
        1163,
        5168,
        17430,
        5730,
        39850,
        11,
        24520,
        3084,
        1987,
        2693,
        1979,
        7219,
        11454,
        11,
        51588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25616487860679626,
      "compression_ratio": 1.5396825075149536,
      "no_speech_prob": 0.02796287275850773
    },
    {
      "id": 82,
      "seek": 44852,
      "start": 3088.219992675781,
      "end": 3093.6199865722656,
      "text": " aber es ist halt ein Anzeichen, dass es irgendwo aus einem Merkmalsraum runterlädt, ja und",
      "tokens": [
        50372,
        4340,
        785,
        1418,
        12479,
        1343,
        1107,
        1381,
        18613,
        11,
        2658,
        785,
        40865,
        3437,
        6827,
        6124,
        17950,
        1124,
        31502,
        33295,
        22882,
        39488,
        11,
        2784,
        674,
        50642
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2648809552192688,
      "compression_ratio": 1.4828897714614868,
      "no_speech_prob": 0.136244535446167
    },
    {
      "id": 83,
      "seek": 44852,
      "start": 3093.6199865722656,
      "end": 3102.779990234375,
      "text": " JavaScript, HTML, Python, da sind die LLMs sehr gut und momentan schwingt das Pendel so ein bisschen",
      "tokens": [
        50642,
        15778,
        11,
        17995,
        11,
        15329,
        11,
        1120,
        3290,
        978,
        441,
        43,
        26386,
        5499,
        5228,
        674,
        1623,
        282,
        956,
        7904,
        83,
        1482,
        38048,
        338,
        370,
        1343,
        10763,
        51100
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2648809552192688,
      "compression_ratio": 1.4828897714614868,
      "no_speech_prob": 0.136244535446167
    },
    {
      "id": 84,
      "seek": 44852,
      "start": 3102.779990234375,
      "end": 3109.499991455078,
      "text": " zurück, weil wir dann doch merken, ja, wir wollen vielleicht was mit Java machen und da habe ich",
      "tokens": [
        51100,
        15089,
        11,
        7689,
        1987,
        3594,
        9243,
        3551,
        2653,
        11,
        2784,
        11,
        1987,
        11253,
        12547,
        390,
        2194,
        10745,
        7069,
        674,
        1120,
        6015,
        1893,
        51436
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2648809552192688,
      "compression_ratio": 1.4828897714614868,
      "no_speech_prob": 0.136244535446167
    },
    {
      "id": 85,
      "seek": 44852,
      "start": 3109.499991455078,
      "end": 3116.4600134277343,
      "text": " mich letztens auch mit der KI unterhalten, sie hat sich 70 Paper runtergeladen und ich weiß nicht,",
      "tokens": [
        51436,
        6031,
        35262,
        694,
        2168,
        2194,
        1163,
        47261,
        8662,
        15022,
        11,
        2804,
        2385,
        3041,
        5285,
        24990,
        33295,
        10345,
        14771,
        674,
        1893,
        13385,
        1979,
        11,
        51784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2648809552192688,
      "compression_ratio": 1.4828897714614868,
      "no_speech_prob": 0.136244535446167
    },
    {
      "id": 86,
      "seek": 47692,
      "start": 3116.4600134277343,
      "end": 3121.580008544922,
      "text": " wie tragfähig die Zahlen sind, ja, aber bei Python ist so die Erfolgswahrscheinlichkeit,",
      "tokens": [
        50364,
        3355,
        38282,
        44616,
        328,
        978,
        44096,
        3290,
        11,
        2784,
        11,
        4340,
        4643,
        15329,
        1418,
        370,
        978,
        3300,
        7082,
        21559,
        86,
        5398,
        25553,
        9238,
        11,
        50620
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2527603805065155,
      "compression_ratio": 1.534482717514038,
      "no_speech_prob": 0.024041978642344475
    },
    {
      "id": 87,
      "seek": 47692,
      "start": 3121.580008544922,
      "end": 3127.980002441406,
      "text": " Lösungswahrscheinlichkeit, keine Ahnung, was es genau ist, so bei 90 Prozent, ja,",
      "tokens": [
        50620,
        34642,
        5846,
        86,
        5398,
        25553,
        9238,
        11,
        9252,
        2438,
        15539,
        11,
        390,
        785,
        12535,
        1418,
        11,
        370,
        4643,
        4289,
        29726,
        11,
        2784,
        11,
        50940
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2527603805065155,
      "compression_ratio": 1.534482717514038,
      "no_speech_prob": 0.024041978642344475
    },
    {
      "id": 88,
      "seek": 47692,
      "start": 3127.980002441406,
      "end": 3135.6199865722656,
      "text": " hört sich gut an, bei Java wird dann so, ich sage mal 82 ausgegeben, wo man sagt,",
      "tokens": [
        50940,
        42243,
        3041,
        5228,
        364,
        11,
        4643,
        10745,
        4578,
        3594,
        370,
        11,
        1893,
        19721,
        2806,
        29097,
        31899,
        16702,
        11,
        6020,
        587,
        15764,
        11,
        51322
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2527603805065155,
      "compression_ratio": 1.534482717514038,
      "no_speech_prob": 0.024041978642344475
    },
    {
      "id": 89,
      "seek": 47692,
      "start": 3135.6199865722656,
      "end": 3140.54,
      "text": " kann ich noch mit leben und dann habe ich gesagt, du, wie sieht denn das mit den Java-Versionen aus,",
      "tokens": [
        51322,
        4028,
        1893,
        3514,
        2194,
        26392,
        674,
        3594,
        6015,
        1893,
        12260,
        11,
        1581,
        11,
        3355,
        14289,
        10471,
        1482,
        2194,
        1441,
        10745,
        12,
        53,
        433,
        17068,
        3437,
        11,
        51568
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2527603805065155,
      "compression_ratio": 1.534482717514038,
      "no_speech_prob": 0.024041978642344475
    },
    {
      "id": 90,
      "seek": 50100,
      "start": 3140.54,
      "end": 3147.7000036621093,
      "text": " da hat er gesagt, ja, also bei Java 8 bin ich sogar bei 90 Prozent, Java 21 knall ich runter",
      "tokens": [
        50364,
        1120,
        2385,
        1189,
        12260,
        11,
        2784,
        11,
        611,
        4643,
        10745,
        1649,
        5171,
        1893,
        19485,
        4643,
        4289,
        29726,
        11,
        10745,
        5080,
        444,
        336,
        1893,
        33295,
        50722
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2694546580314636,
      "compression_ratio": 1.5520000457763672,
      "no_speech_prob": 0.016399407759308815
    },
    {
      "id": 91,
      "seek": 50100,
      "start": 3147.7000036621093,
      "end": 3156.1800146484375,
      "text": " 50, jetzt sind wir bei Java 25, ja, das sind dann so Sachen, wo man auf einmal gegen Wände läuft,",
      "tokens": [
        50722,
        2625,
        11,
        4354,
        3290,
        1987,
        4643,
        10745,
        3552,
        11,
        2784,
        11,
        1482,
        3290,
        3594,
        370,
        26074,
        11,
        6020,
        587,
        2501,
        11078,
        13953,
        343,
        26973,
        31807,
        11,
        51146
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2694546580314636,
      "compression_ratio": 1.5520000457763672,
      "no_speech_prob": 0.016399407759308815
    },
    {
      "id": 92,
      "seek": 50100,
      "start": 3156.1800146484375,
      "end": 3163.820029296875,
      "text": " die man nicht sieht und ich finde es wichtig, dass wir diese Wände identifizieren, verstehen und",
      "tokens": [
        51146,
        978,
        587,
        1979,
        14289,
        674,
        1893,
        17841,
        785,
        13621,
        11,
        2658,
        1987,
        6705,
        343,
        26973,
        2473,
        351,
        590,
        5695,
        11,
        37352,
        674,
        51528
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2694546580314636,
      "compression_ratio": 1.5520000457763672,
      "no_speech_prob": 0.016399407759308815
    },
    {
      "id": 93,
      "seek": 50100,
      "start": 3163.820029296875,
      "end": 3168.9400244140625,
      "text": " gucken können, was wir besser machen können, um da noch mal zurückzukommen auf das Problem mit",
      "tokens": [
        51528,
        33135,
        6310,
        11,
        390,
        1987,
        18021,
        7069,
        6310,
        11,
        1105,
        1120,
        3514,
        2806,
        15089,
        43994,
        5132,
        2501,
        1482,
        11676,
        2194,
        51784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2694546580314636,
      "compression_ratio": 1.5520000457763672,
      "no_speech_prob": 0.016399407759308815
    },
    {
      "id": 94,
      "seek": 52940,
      "start": 3168.9400244140625,
      "end": 3177.6200170898437,
      "text": " der Gästeliste, die KI, die arbeitet gern mit JavaScript und deswegen hat die mit JavaScript",
      "tokens": [
        50364,
        1163,
        460,
        737,
        372,
        338,
        8375,
        11,
        978,
        47261,
        11,
        978,
        49907,
        38531,
        2194,
        15778,
        674,
        26482,
        2385,
        978,
        2194,
        15778,
        50798
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21796318888664246,
      "compression_ratio": 1.6022099256515503,
      "no_speech_prob": 0.009706071577966213
    },
    {
      "id": 95,
      "seek": 52940,
      "start": 3177.6200170898437,
      "end": 3184.740012207031,
      "text": " das implementiert, das ist ihre implizite Architektur und jetzt sind wir hier bei Software-Architektur",
      "tokens": [
        50798,
        1482,
        4445,
        4859,
        11,
        1482,
        1418,
        14280,
        8484,
        590,
        642,
        10984,
        642,
        2320,
        374,
        674,
        4354,
        3290,
        1987,
        3296,
        4643,
        27428,
        12,
        10683,
        339,
        642,
        2320,
        374,
        51154
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21796318888664246,
      "compression_ratio": 1.6022099256515503,
      "no_speech_prob": 0.009706071577966213
    },
    {
      "id": 96,
      "seek": 52940,
      "start": 3184.740012207031,
      "end": 3192.9400244140625,
      "text": " im Stream, wo ist die Architektur, wer gibt der Maschine eine Architektur mit und ich glaube,",
      "tokens": [
        51154,
        566,
        24904,
        11,
        6020,
        1418,
        978,
        10984,
        642,
        2320,
        374,
        11,
        2612,
        6089,
        1163,
        5224,
        36675,
        3018,
        10984,
        642,
        2320,
        374,
        2194,
        674,
        1893,
        13756,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21796318888664246,
      "compression_ratio": 1.6022099256515503,
      "no_speech_prob": 0.009706071577966213
    },
    {
      "id": 97,
      "seek": 55340,
      "start": 3192.980002441406,
      "end": 3199.459982910156,
      "text": " wenn wir das besser erarbeiten würden, dass wir der Maschine sagen würden, du, hier ist",
      "tokens": [
        50366,
        4797,
        1987,
        1482,
        18021,
        1189,
        43918,
        27621,
        11,
        2658,
        1987,
        1163,
        5224,
        36675,
        8360,
        27621,
        11,
        1581,
        11,
        3296,
        1418,
        50690
      ],
      "temperature": 0.0,
      "avg_logprob": -0.265625,
      "compression_ratio": 1.6164875030517578,
      "no_speech_prob": 0.04018482193350792
    },
    {
      "id": 98,
      "seek": 55340,
      "start": 3199.459982910156,
      "end": 3207.6200170898437,
      "text": " Jekyll, hier sind deine Constraints, bitte nicht einfach ins Markdown JavaScript einbauen,",
      "tokens": [
        50690,
        508,
        916,
        34353,
        11,
        3296,
        3290,
        28395,
        8574,
        424,
        8654,
        11,
        23231,
        1979,
        7281,
        1028,
        3934,
        5093,
        15778,
        1343,
        65,
        11715,
        11,
        51098
      ],
      "temperature": 0.0,
      "avg_logprob": -0.265625,
      "compression_ratio": 1.6164875030517578,
      "no_speech_prob": 0.04018482193350792
    },
    {
      "id": 99,
      "seek": 55340,
      "start": 3207.6200170898437,
      "end": 3214.300009765625,
      "text": " ja, ich glaube, damit könnten wir weiterkommen. Also bei der Gästeliste ist es halt so,",
      "tokens": [
        51098,
        2784,
        11,
        1893,
        13756,
        11,
        9479,
        37411,
        1987,
        8988,
        13675,
        13,
        2743,
        4643,
        1163,
        460,
        737,
        372,
        338,
        8375,
        1418,
        785,
        12479,
        370,
        11,
        51432
      ],
      "temperature": 0.0,
      "avg_logprob": -0.265625,
      "compression_ratio": 1.6164875030517578,
      "no_speech_prob": 0.04018482193350792
    },
    {
      "id": 100,
      "seek": 55340,
      "start": 3214.300009765625,
      "end": 3219.219992675781,
      "text": " also wenn jemand zu mir gekommen wäre und gesagt hätte, wir bauen mal so eine Gästeliste,",
      "tokens": [
        51432,
        611,
        4797,
        21717,
        2164,
        3149,
        32732,
        14558,
        674,
        12260,
        20041,
        11,
        1987,
        43787,
        2806,
        370,
        3018,
        460,
        737,
        372,
        338,
        8375,
        11,
        51678
      ],
      "temperature": 0.0,
      "avg_logprob": -0.265625,
      "compression_ratio": 1.6164875030517578,
      "no_speech_prob": 0.04018482193350792
    },
    {
      "id": 101,
      "seek": 55340,
      "start": 3219.219992675781,
      "end": 3222.3800268554687,
      "text": " ich hätte halt wahrscheinlich ein großes Markdown-Fall gemacht, wenn diese Person mir",
      "tokens": [
        51678,
        1893,
        20041,
        12479,
        30957,
        1343,
        48875,
        3934,
        5093,
        12,
        37,
        336,
        12293,
        11,
        4797,
        6705,
        8443,
        3149,
        51836
      ],
      "temperature": 0.0,
      "avg_logprob": -0.265625,
      "compression_ratio": 1.6164875030517578,
      "no_speech_prob": 0.04018482193350792
    },
    {
      "id": 102,
      "seek": 58284,
      "start": 3222.3800268554687,
      "end": 3226.259970703125,
      "text": " dann gesagt hätte, nee, ich will, dass es halt irgendwie gesucht wird, vielleicht wäre ich auf",
      "tokens": [
        50364,
        3594,
        12260,
        20041,
        11,
        41694,
        11,
        1893,
        486,
        11,
        2658,
        785,
        12479,
        20759,
        5019,
        10084,
        4578,
        11,
        12547,
        14558,
        1893,
        2501,
        50558
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30177921056747437,
      "compression_ratio": 1.7808642387390137,
      "no_speech_prob": 0.011502115055918694
    },
    {
      "id": 103,
      "seek": 58284,
      "start": 3226.259970703125,
      "end": 3229.9400244140625,
      "text": " die Idee gekommen, das mit JavaScript zu machen, aber ich bin mir nicht sicher, es kann sehr gut",
      "tokens": [
        50558,
        978,
        32651,
        32732,
        11,
        1482,
        2194,
        15778,
        2164,
        7069,
        11,
        4340,
        1893,
        5171,
        3149,
        1979,
        18623,
        11,
        785,
        4028,
        5499,
        5228,
        50742
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30177921056747437,
      "compression_ratio": 1.7808642387390137,
      "no_speech_prob": 0.011502115055918694
    },
    {
      "id": 104,
      "seek": 58284,
      "start": 3229.9400244140625,
      "end": 3236.3399877929687,
      "text": " sein, dass ich einfach nicht da einen blinden Fleck gehabt hätte und es halt irgendwie nicht",
      "tokens": [
        50742,
        6195,
        11,
        2658,
        1893,
        7281,
        1979,
        1120,
        4891,
        6865,
        268,
        18612,
        547,
        37092,
        20041,
        674,
        785,
        12479,
        20759,
        1979,
        51062
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30177921056747437,
      "compression_ratio": 1.7808642387390137,
      "no_speech_prob": 0.011502115055918694
    },
    {
      "id": 105,
      "seek": 58284,
      "start": 3236.3399877929687,
      "end": 3241.6599951171875,
      "text": " gemacht hätte und ich glaube, das ist sozusagen die richtige Lösung, aber vielleicht spannender",
      "tokens": [
        51062,
        12293,
        20041,
        674,
        1893,
        13756,
        11,
        1482,
        1418,
        33762,
        978,
        41569,
        46934,
        11,
        4340,
        12547,
        33360,
        3216,
        51328
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30177921056747437,
      "compression_ratio": 1.7808642387390137,
      "no_speech_prob": 0.011502115055918694
    },
    {
      "id": 106,
      "seek": 58284,
      "start": 3241.6599951171875,
      "end": 3246.0999975585937,
      "text": " ist dann tatsächlich die Integration in die Webseite, also wir haben ja jetzt dieses Transcript,",
      "tokens": [
        51328,
        1418,
        3594,
        20796,
        978,
        47713,
        294,
        978,
        9573,
        405,
        642,
        11,
        611,
        1987,
        3084,
        2784,
        4354,
        12113,
        6531,
        5944,
        11,
        51550
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30177921056747437,
      "compression_ratio": 1.7808642387390137,
      "no_speech_prob": 0.011502115055918694
    },
    {
      "id": 107,
      "seek": 58284,
      "start": 3246.0999975585937,
      "end": 3250.6599951171875,
      "text": " die Zusammenfassung und die Stichpunkte und da war die Frage, wie wir es halt in die Webseite",
      "tokens": [
        51550,
        978,
        29442,
        69,
        40828,
        674,
        978,
        745,
        480,
        27133,
        975,
        674,
        1120,
        1516,
        978,
        13685,
        11,
        3355,
        1987,
        785,
        12479,
        294,
        978,
        9573,
        405,
        642,
        51778
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30177921056747437,
      "compression_ratio": 1.7808642387390137,
      "no_speech_prob": 0.011502115055918694
    },
    {
      "id": 108,
      "seek": 61112,
      "start": 3250.6599951171875,
      "end": 3254.9400244140625,
      "text": " bekommen und da hattest du ja auch dann Cloud Code, glaube ich, irgendwie losgeschickt und",
      "tokens": [
        50364,
        19256,
        674,
        1120,
        276,
        1591,
        377,
        1581,
        2784,
        2168,
        3594,
        8061,
        15549,
        11,
        13756,
        1893,
        11,
        20759,
        1750,
        23378,
        40522,
        674,
        50578
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33024999499320984,
      "compression_ratio": 1.6487455368041992,
      "no_speech_prob": 0.04880954697728157
    },
    {
      "id": 109,
      "seek": 61112,
      "start": 3254.9400244140625,
      "end": 3260.740012207031,
      "text": " gesagt, mach mal. Willst du erzählen, wie da die erste Lösung aussah? Ich glaube,",
      "tokens": [
        50578,
        12260,
        11,
        2246,
        2806,
        13,
        3099,
        372,
        1581,
        28337,
        6698,
        11,
        3355,
        1120,
        978,
        20951,
        46934,
        5730,
        545,
        30,
        3141,
        13756,
        11,
        50868
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33024999499320984,
      "compression_ratio": 1.6487455368041992,
      "no_speech_prob": 0.04880954697728157
    },
    {
      "id": 110,
      "seek": 61112,
      "start": 3260.740012207031,
      "end": 3266.0999975585937,
      "text": " du kannst dich da noch besser daran erinnern. Ich glaube, er hat irgendwie ein Datafile aufgebaut,",
      "tokens": [
        50868,
        1581,
        20853,
        10390,
        1120,
        3514,
        18021,
        24520,
        1189,
        19166,
        77,
        13,
        3141,
        13756,
        11,
        1189,
        2385,
        20759,
        1343,
        9315,
        2792,
        794,
        2501,
        42858,
        11,
        51136
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33024999499320984,
      "compression_ratio": 1.6487455368041992,
      "no_speech_prob": 0.04880954697728157
    },
    {
      "id": 111,
      "seek": 61112,
      "start": 3266.0999975585937,
      "end": 3273.300009765625,
      "text": " ein YAML-File. Ja, genau, also was da passiert ist und das ist also der Grund, warum ich die",
      "tokens": [
        51136,
        1343,
        398,
        2865,
        43,
        12,
        37,
        794,
        13,
        3530,
        11,
        12535,
        11,
        611,
        390,
        1120,
        21671,
        1418,
        674,
        1482,
        1418,
        611,
        1163,
        13941,
        11,
        24331,
        1893,
        978,
        51496
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33024999499320984,
      "compression_ratio": 1.6487455368041992,
      "no_speech_prob": 0.04880954697728157
    },
    {
      "id": 112,
      "seek": 61112,
      "start": 3273.300009765625,
      "end": 3278.6599951171875,
      "text": " Lösung halt erstmal schwierig fand, war, weil es halt irgendwie so ein Alien war und das ist",
      "tokens": [
        51496,
        46934,
        12479,
        38607,
        37845,
        38138,
        11,
        1516,
        11,
        7689,
        785,
        12479,
        20759,
        370,
        1343,
        32396,
        1516,
        674,
        1482,
        1418,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33024999499320984,
      "compression_ratio": 1.6487455368041992,
      "no_speech_prob": 0.04880954697728157
    },
    {
      "id": 113,
      "seek": 63912,
      "start": 3278.6599951171875,
      "end": 3286.980002441406,
      "text": " ein bisschen nachvollziehbar und das hatten wir vorhin ja auch schon mal diskutiert und das ist",
      "tokens": [
        50364,
        1343,
        10763,
        5168,
        20654,
        28213,
        5356,
        674,
        1482,
        20441,
        1987,
        4245,
        10876,
        2784,
        2168,
        4981,
        2806,
        36760,
        4859,
        674,
        1482,
        1418,
        50780
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23919901251792908,
      "compression_ratio": 1.5077519416809082,
      "no_speech_prob": 0.016893742606043816
    },
    {
      "id": 114,
      "seek": 63912,
      "start": 3286.980002441406,
      "end": 3291.259970703125,
      "text": " ja auch nur Ästhetik, aber es war irgendwie ein eigenes Verzeichnis und dann sind da diese",
      "tokens": [
        50780,
        2784,
        2168,
        4343,
        13700,
        372,
        9092,
        1035,
        11,
        4340,
        785,
        1516,
        20759,
        1343,
        10446,
        279,
        4281,
        32338,
        10661,
        674,
        3594,
        3290,
        1120,
        6705,
        50994
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23919901251792908,
      "compression_ratio": 1.5077519416809082,
      "no_speech_prob": 0.016893742606043816
    },
    {
      "id": 115,
      "seek": 63912,
      "start": 3291.259970703125,
      "end": 3298.9400244140625,
      "text": " Geschichten passiert. Ich muss ja jetzt wissen, für welche der Episoden es überhaupt eine Transkription",
      "tokens": [
        50994,
        14241,
        24681,
        21671,
        13,
        3141,
        6425,
        2784,
        4354,
        16331,
        11,
        2959,
        24311,
        1163,
        9970,
        271,
        33482,
        785,
        20023,
        3018,
        6531,
        74,
        470,
        1695,
        51378
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23919901251792908,
      "compression_ratio": 1.5077519416809082,
      "no_speech_prob": 0.016893742606043816
    },
    {
      "id": 116,
      "seek": 63912,
      "start": 3298.9400244140625,
      "end": 3305.699973144531,
      "text": " gibt, weil sonst kann ich die ja nicht rendern. Die Lösung, die dort implementiert worden ist,",
      "tokens": [
        51378,
        6089,
        11,
        7689,
        26309,
        4028,
        1893,
        978,
        2784,
        1979,
        6125,
        1248,
        13,
        3229,
        46934,
        11,
        978,
        15775,
        4445,
        4859,
        14054,
        1418,
        11,
        51716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23919901251792908,
      "compression_ratio": 1.5077519416809082,
      "no_speech_prob": 0.016893742606043816
    },
    {
      "id": 117,
      "seek": 66616,
      "start": 3305.8600073242187,
      "end": 3313.01998046875,
      "text": " es gibt einen YAML-File, wo das drinsteht. Das fand ich weird, weil das ist das erste YAML-File gewesen,",
      "tokens": [
        50372,
        785,
        6089,
        4891,
        398,
        2865,
        43,
        12,
        37,
        794,
        11,
        6020,
        1482,
        24534,
        2941,
        357,
        13,
        2846,
        38138,
        1893,
        3657,
        11,
        7689,
        1482,
        1418,
        1482,
        20951,
        398,
        2865,
        43,
        12,
        37,
        794,
        27653,
        11,
        50730
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3422476053237915,
      "compression_ratio": 1.5696202516555786,
      "no_speech_prob": 0.020634224638342857
    },
    {
      "id": 118,
      "seek": 66616,
      "start": 3313.01998046875,
      "end": 3322.820029296875,
      "text": " was wir da drin hatten und dann war halt das Zweite. Für mich hat sich das auch komisch",
      "tokens": [
        50730,
        390,
        1987,
        1120,
        24534,
        20441,
        674,
        3594,
        1516,
        12479,
        1482,
        32475,
        642,
        13,
        14990,
        6031,
        2385,
        3041,
        1482,
        2168,
        5207,
        5494,
        51220
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3422476053237915,
      "compression_ratio": 1.5696202516555786,
      "no_speech_prob": 0.020634224638342857
    },
    {
      "id": 119,
      "seek": 66616,
      "start": 3322.820029296875,
      "end": 3327.1399755859375,
      "text": " angeführt und dann gab es halt irgendwie die andere Geschichte und das war, wie kriege ich",
      "tokens": [
        51220,
        43907,
        19647,
        674,
        3594,
        17964,
        785,
        12479,
        20759,
        978,
        10490,
        28896,
        674,
        1482,
        1516,
        11,
        3355,
        25766,
        432,
        1893,
        51436
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3422476053237915,
      "compression_ratio": 1.5696202516555786,
      "no_speech_prob": 0.020634224638342857
    },
    {
      "id": 120,
      "seek": 66616,
      "start": 3327.1399755859375,
      "end": 3331.8999853515625,
      "text": " jetzt dieses Transcript überhaupt auf die Webseite. Was da passiert ist, ist, dass es",
      "tokens": [
        51436,
        4354,
        12113,
        6531,
        5944,
        20023,
        2501,
        978,
        9573,
        405,
        642,
        13,
        3027,
        1120,
        21671,
        1418,
        11,
        1418,
        11,
        2658,
        785,
        51674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3422476053237915,
      "compression_ratio": 1.5696202516555786,
      "no_speech_prob": 0.020634224638342857
    },
    {
      "id": 121,
      "seek": 69236,
      "start": 3332.219992675781,
      "end": 3339.6200170898437,
      "text": " die Episodenseite gab. Die gibt es ja eh für alle Episoden, auch für die, die ich transkriptierten",
      "tokens": [
        50380,
        978,
        9970,
        271,
        378,
        1288,
        642,
        17964,
        13,
        3229,
        6089,
        785,
        2784,
        7670,
        2959,
        5430,
        9970,
        271,
        33482,
        11,
        2168,
        2959,
        978,
        11,
        978,
        1893,
        1145,
        74,
        470,
        79,
        25402,
        1147,
        50750
      ],
      "temperature": 0.0,
      "avg_logprob": -0.345126748085022,
      "compression_ratio": 1.643478274345398,
      "no_speech_prob": 0.0574035719037056
    },
    {
      "id": 122,
      "seek": 69236,
      "start": 3339.6200170898437,
      "end": 3345.0999975585937,
      "text": " und dann ist eine Lösung entstanden, wo in diese Seite die anderen drei Dateien inkludiert",
      "tokens": [
        50750,
        674,
        3594,
        1418,
        3018,
        46934,
        948,
        33946,
        11,
        6020,
        294,
        6705,
        19748,
        978,
        11122,
        16809,
        31805,
        1053,
        11276,
        1471,
        4859,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.345126748085022,
      "compression_ratio": 1.643478274345398,
      "no_speech_prob": 0.0574035719037056
    },
    {
      "id": 123,
      "seek": 69236,
      "start": 3345.0999975585937,
      "end": 3350.0999975585937,
      "text": " worden sind und dann Anchor gebaut worden sind. Was also dazu führt, dass ich eine Episodenseite",
      "tokens": [
        51024,
        14054,
        3290,
        674,
        3594,
        39547,
        284,
        49203,
        14054,
        3290,
        13,
        3027,
        611,
        13034,
        39671,
        11,
        2658,
        1893,
        3018,
        9970,
        271,
        378,
        1288,
        642,
        51274
      ],
      "temperature": 0.0,
      "avg_logprob": -0.345126748085022,
      "compression_ratio": 1.643478274345398,
      "no_speech_prob": 0.0574035719037056
    },
    {
      "id": 124,
      "seek": 69236,
      "start": 3350.0999975585937,
      "end": 3357.4200048828125,
      "text": " habe. Das ist oben das Video auf PeerTube, das Video auf YouTube, der Podcast. Dann die",
      "tokens": [
        51274,
        6015,
        13,
        2846,
        1418,
        21279,
        1482,
        9777,
        2501,
        2396,
        260,
        41173,
        11,
        1482,
        9777,
        2501,
        3088,
        11,
        1163,
        29972,
        13,
        7455,
        978,
        51640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.345126748085022,
      "compression_ratio": 1.643478274345398,
      "no_speech_prob": 0.0574035719037056
    },
    {
      "id": 125,
      "seek": 71788,
      "start": 3357.4200048828125,
      "end": 3361.500021972656,
      "text": " Zusammenfassung, Stichpunkte und dann die Transkription, was dazu führt, dass diese",
      "tokens": [
        50364,
        29442,
        69,
        40828,
        11,
        745,
        480,
        27133,
        975,
        674,
        3594,
        978,
        6531,
        74,
        470,
        1695,
        11,
        390,
        13034,
        39671,
        11,
        2658,
        6705,
        50568
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34712108969688416,
      "compression_ratio": 1.4771784543991089,
      "no_speech_prob": 0.1478879153728485
    },
    {
      "id": 126,
      "seek": 71788,
      "start": 3361.500021972656,
      "end": 3366.4200048828125,
      "text": " Webseite plötzlich wahnsinnig lang ist und im Wesentlichen aus dem Transkription besteht,",
      "tokens": [
        50568,
        9573,
        405,
        642,
        499,
        12082,
        89,
        2081,
        339,
        31979,
        46134,
        328,
        2265,
        1418,
        674,
        566,
        23843,
        7698,
        268,
        3437,
        1371,
        6531,
        74,
        470,
        1695,
        43680,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34712108969688416,
      "compression_ratio": 1.4771784543991089,
      "no_speech_prob": 0.1478879153728485
    },
    {
      "id": 127,
      "seek": 71788,
      "start": 3366.4200048828125,
      "end": 3375.259970703125,
      "text": " weil dieses Ding eben natürlich die meisten Worte enthält. Also wie soll ich sagen,",
      "tokens": [
        50814,
        7689,
        12113,
        20558,
        11375,
        8762,
        978,
        29708,
        343,
        12752,
        948,
        28068,
        13,
        2743,
        3355,
        7114,
        1893,
        8360,
        11,
        51256
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34712108969688416,
      "compression_ratio": 1.4771784543991089,
      "no_speech_prob": 0.1478879153728485
    },
    {
      "id": 128,
      "seek": 71788,
      "start": 3375.259970703125,
      "end": 3380.300009765625,
      "text": " nicht Software-Editor im Stream war oder ist, glaube ich, möglicherweise immer noch in diesem",
      "tokens": [
        51256,
        1979,
        27428,
        12,
        27061,
        3029,
        566,
        24904,
        1516,
        4513,
        1418,
        11,
        13756,
        1893,
        11,
        16294,
        44071,
        5578,
        3514,
        294,
        10975,
        51508
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34712108969688416,
      "compression_ratio": 1.4771784543991089,
      "no_speech_prob": 0.1478879153728485
    },
    {
      "id": 129,
      "seek": 74076,
      "start": 3380.300009765625,
      "end": 3388.4200048828125,
      "text": " 512 Kilobyte Club. Meine persönliche Webseite möglicherweise auch. Eigentlich ist das eine",
      "tokens": [
        50364,
        1025,
        4762,
        23912,
        13944,
        975,
        11288,
        13,
        22258,
        31228,
        10185,
        9573,
        405,
        642,
        16294,
        44071,
        2168,
        13,
        40561,
        7698,
        1418,
        1482,
        3018,
        50770
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3262466788291931,
      "compression_ratio": 1.618025779724121,
      "no_speech_prob": 0.44059106707572937
    },
    {
      "id": 130,
      "seek": 74076,
      "start": 3388.4200048828125,
      "end": 3394.5799780273437,
      "text": " Webseite, die so kleine Webseiten hat, kleine Webpages hat und das war eigentlich eine Sache,",
      "tokens": [
        50770,
        9573,
        405,
        642,
        11,
        978,
        370,
        22278,
        9573,
        405,
        6009,
        2385,
        11,
        22278,
        9573,
        79,
        1660,
        2385,
        674,
        1482,
        1516,
        10926,
        3018,
        31452,
        11,
        51078
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3262466788291931,
      "compression_ratio": 1.618025779724121,
      "no_speech_prob": 0.44059106707572937
    },
    {
      "id": 131,
      "seek": 74076,
      "start": 3394.5799780273437,
      "end": 3399.3800268554687,
      "text": " die ich irgendwie ganz gut fand und ich fand das da halt irgendwie weird und auch unnötig",
      "tokens": [
        51078,
        978,
        1893,
        20759,
        6312,
        5228,
        38138,
        674,
        1893,
        38138,
        1482,
        1120,
        12479,
        20759,
        3657,
        674,
        2168,
        517,
        77,
        12082,
        328,
        51318
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3262466788291931,
      "compression_ratio": 1.618025779724121,
      "no_speech_prob": 0.44059106707572937
    },
    {
      "id": 132,
      "seek": 74076,
      "start": 3399.3800268554687,
      "end": 3405.5799780273437,
      "text": " aufgeblasen. Und es hat sich dann herausgestellt, das haben wir glaube ich tatsächlich erst zu der",
      "tokens": [
        51318,
        35031,
        5199,
        296,
        268,
        13,
        2719,
        785,
        2385,
        3041,
        3594,
        25089,
        26293,
        11,
        1482,
        3084,
        1987,
        13756,
        1893,
        20796,
        11301,
        2164,
        1163,
        51628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3262466788291931,
      "compression_ratio": 1.618025779724121,
      "no_speech_prob": 0.44059106707572937
    },
    {
      "id": 133,
      "seek": 76604,
      "start": 3406.06001953125,
      "end": 3415.1800146484375,
      "text": " Diskussion zu dieser Folge herausgefunden, dass du, Claude, gesagt hast, man braucht etwas minimal",
      "tokens": [
        50388,
        45963,
        313,
        2164,
        9053,
        43597,
        25089,
        13529,
        10028,
        11,
        2658,
        1581,
        11,
        12947,
        2303,
        11,
        12260,
        6581,
        11,
        587,
        22623,
        9569,
        13206,
        50844
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2971698045730591,
      "compression_ratio": 1.4820717573165894,
      "no_speech_prob": 0.02553405612707138
    },
    {
      "id": 134,
      "seek": 76604,
      "start": 3415.1800146484375,
      "end": 3423.1399755859375,
      "text": " Invasives. Das war das, was du gesagt hast. Und das ist in gewisser Weise passiert,",
      "tokens": [
        50844,
        682,
        7967,
        1539,
        13,
        2846,
        1516,
        1482,
        11,
        390,
        1581,
        12260,
        6581,
        13,
        2719,
        1482,
        1418,
        294,
        6906,
        23714,
        41947,
        21671,
        11,
        51242
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2971698045730591,
      "compression_ratio": 1.4820717573165894,
      "no_speech_prob": 0.02553405612707138
    },
    {
      "id": 135,
      "seek": 76604,
      "start": 3423.1399755859375,
      "end": 3430.259970703125,
      "text": " weil die Markdown-Files für die Episoden sind unverändert. Das Template hat sich geändert. Das",
      "tokens": [
        51242,
        7689,
        978,
        3934,
        5093,
        12,
        37,
        4680,
        2959,
        978,
        9970,
        271,
        33482,
        3290,
        517,
        331,
        34945,
        13,
        2846,
        39563,
        473,
        2385,
        3041,
        1519,
        34945,
        13,
        2846,
        51598
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2971698045730591,
      "compression_ratio": 1.4820717573165894,
      "no_speech_prob": 0.02553405612707138
    },
    {
      "id": 136,
      "seek": 76604,
      "start": 3430.259970703125,
      "end": 3435.3399877929687,
      "text": " Template guckt jetzt in dem YAML nach, ob es die Übersetzung gibt und inkludiert die. Also",
      "tokens": [
        51598,
        39563,
        473,
        695,
        19951,
        4354,
        294,
        1371,
        398,
        2865,
        43,
        5168,
        11,
        1111,
        785,
        978,
        10713,
        1616,
        38584,
        6089,
        674,
        11276,
        1471,
        4859,
        978,
        13,
        2743,
        51852
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2971698045730591,
      "compression_ratio": 1.4820717573165894,
      "no_speech_prob": 0.02553405612707138
    },
    {
      "id": 137,
      "seek": 79580,
      "start": 3435.980002441406,
      "end": 3442.6200170898437,
      "text": " war das in gewisser Weise nicht zielerreicht. Das fand ich lustig, weil ich hatte gedacht,",
      "tokens": [
        50396,
        1516,
        1482,
        294,
        6906,
        23714,
        41947,
        1979,
        710,
        1187,
        260,
        265,
        1405,
        13,
        2846,
        38138,
        1893,
        24672,
        328,
        11,
        7689,
        1893,
        13299,
        33296,
        11,
        50728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32282713055610657,
      "compression_ratio": 1.4550000429153442,
      "no_speech_prob": 0.002433206420391798
    },
    {
      "id": 138,
      "seek": 79580,
      "start": 3442.6200170898437,
      "end": 3448.9400244140625,
      "text": " naja, das ist eine Implementierungsvariante, die aus irgendwelchen Gründen von der AI gekommen ist",
      "tokens": [
        50728,
        1667,
        2938,
        11,
        1482,
        1418,
        3018,
        4331,
        43704,
        40908,
        34033,
        2879,
        11,
        978,
        3437,
        3418,
        1766,
        67,
        45512,
        2470,
        2606,
        27687,
        2957,
        1163,
        7318,
        32732,
        1418,
        51044
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32282713055610657,
      "compression_ratio": 1.4550000429153442,
      "no_speech_prob": 0.002433206420391798
    },
    {
      "id": 139,
      "seek": 79580,
      "start": 3448.9400244140625,
      "end": 3459.1800146484375,
      "text": " und das ist problematisch. Und was dann passiert ist in der Folge, ist, dass ich mich mal hingesetzt",
      "tokens": [
        51044,
        674,
        1482,
        1418,
        1154,
        267,
        5494,
        13,
        2719,
        390,
        3594,
        21671,
        1418,
        294,
        1163,
        43597,
        11,
        1418,
        11,
        2658,
        1893,
        6031,
        2806,
        46686,
        3524,
        51556
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32282713055610657,
      "compression_ratio": 1.4550000429153442,
      "no_speech_prob": 0.002433206420391798
    },
    {
      "id": 140,
      "seek": 81964,
      "start": 3459.300009765625,
      "end": 3465.4200048828125,
      "text": " habe und einmal das Ding deutlich umgestellt habe. Und jetzt ist es halt so, dass es diese drei",
      "tokens": [
        50370,
        6015,
        674,
        11078,
        1482,
        20558,
        24344,
        1105,
        26293,
        6015,
        13,
        2719,
        4354,
        1418,
        785,
        12479,
        370,
        11,
        2658,
        785,
        6705,
        16809,
        50676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2489042729139328,
      "compression_ratio": 1.663082480430603,
      "no_speech_prob": 0.23049885034561157
    },
    {
      "id": 141,
      "seek": 81964,
      "start": 3465.4200048828125,
      "end": 3470.6200170898437,
      "text": " Dateien gibt. Da gibt es irgendwie Links dazwischen und diese Links werden gerendert,",
      "tokens": [
        50676,
        31805,
        1053,
        6089,
        13,
        3933,
        6089,
        785,
        20759,
        37156,
        274,
        921,
        86,
        6282,
        674,
        6705,
        37156,
        4604,
        5713,
        521,
        911,
        11,
        50936
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2489042729139328,
      "compression_ratio": 1.663082480430603,
      "no_speech_prob": 0.23049885034561157
    },
    {
      "id": 142,
      "seek": 81964,
      "start": 3470.6200170898437,
      "end": 3475.0999975585937,
      "text": " wenn die Dateien vorhanden sind. Das heißt also, dass das Template von der Episode sagt,",
      "tokens": [
        50936,
        4797,
        978,
        31805,
        1053,
        4245,
        5543,
        268,
        3290,
        13,
        2846,
        13139,
        611,
        11,
        2658,
        1482,
        39563,
        473,
        2957,
        1163,
        19882,
        15764,
        11,
        51160
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2489042729139328,
      "compression_ratio": 1.663082480430603,
      "no_speech_prob": 0.23049885034561157
    },
    {
      "id": 143,
      "seek": 81964,
      "start": 3475.0999975585937,
      "end": 3480.820029296875,
      "text": " ich gucke jetzt nach, sind die Dateien da für die Zusammenfassung, für die Transkription und so",
      "tokens": [
        51160,
        1893,
        695,
        18627,
        4354,
        5168,
        11,
        3290,
        978,
        31805,
        1053,
        1120,
        2959,
        978,
        29442,
        69,
        40828,
        11,
        2959,
        978,
        6531,
        74,
        470,
        1695,
        674,
        370,
        51446
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2489042729139328,
      "compression_ratio": 1.663082480430603,
      "no_speech_prob": 0.23049885034561157
    },
    {
      "id": 144,
      "seek": 81964,
      "start": 3480.820029296875,
      "end": 3486.459982910156,
      "text": " weiter. Dann rendere ich diese Links da rein, sonst nicht. Das YAML-File ist damit eliminiert.",
      "tokens": [
        51446,
        8988,
        13,
        7455,
        6125,
        323,
        1893,
        6705,
        37156,
        1120,
        6561,
        11,
        26309,
        1979,
        13,
        2846,
        398,
        2865,
        43,
        12,
        37,
        794,
        1418,
        9479,
        7892,
        4859,
        13,
        51728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2489042729139328,
      "compression_ratio": 1.663082480430603,
      "no_speech_prob": 0.23049885034561157
    },
    {
      "id": 145,
      "seek": 84692,
      "start": 3486.5799780273437,
      "end": 3494.8600073242187,
      "text": " Ich musste, um diese Links zu rendern, in den Dateien die Episoden-Nummer aufnehmen. Das heißt,",
      "tokens": [
        50370,
        3141,
        34497,
        11,
        1105,
        6705,
        37156,
        2164,
        6125,
        1248,
        11,
        294,
        1441,
        31805,
        1053,
        978,
        9970,
        271,
        33482,
        12,
        45,
        30906,
        2501,
        14669,
        13,
        2846,
        13139,
        11,
        50784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2686946392059326,
      "compression_ratio": 1.573770523071289,
      "no_speech_prob": 0.0012448233319446445
    },
    {
      "id": 146,
      "seek": 84692,
      "start": 3494.8600073242187,
      "end": 3500.1800146484375,
      "text": " ich habe letztendlich alle Episoden einmal automatisiert durchgeackert und habe da die",
      "tokens": [
        50784,
        1893,
        6015,
        35262,
        521,
        1739,
        5430,
        9970,
        271,
        33482,
        11078,
        28034,
        42266,
        7131,
        432,
        501,
        911,
        674,
        6015,
        1120,
        978,
        51050
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2686946392059326,
      "compression_ratio": 1.573770523071289,
      "no_speech_prob": 0.0012448233319446445
    },
    {
      "id": 147,
      "seek": 84692,
      "start": 3500.1800146484375,
      "end": 3508.4200048828125,
      "text": " Episoden-Nummer reingepackt. Also ein Skript hat das getan. Und dadurch haben wir jetzt eben diese",
      "tokens": [
        51050,
        9970,
        271,
        33482,
        12,
        45,
        30906,
        319,
        278,
        595,
        501,
        83,
        13,
        2743,
        1343,
        7324,
        470,
        662,
        2385,
        1482,
        45599,
        13,
        2719,
        35472,
        3084,
        1987,
        4354,
        11375,
        6705,
        51462
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2686946392059326,
      "compression_ratio": 1.573770523071289,
      "no_speech_prob": 0.0012448233319446445
    },
    {
      "id": 148,
      "seek": 84692,
      "start": 3508.4200048828125,
      "end": 3513.459982910156,
      "text": " vier Links. Und im Rahmen dieser Aktion sind noch diverse andere Sachen entstanden. Also zum Beispiel",
      "tokens": [
        51462,
        17634,
        37156,
        13,
        2719,
        566,
        39070,
        9053,
        316,
        9780,
        3290,
        3514,
        9521,
        10490,
        26074,
        948,
        33946,
        13,
        2743,
        5919,
        13772,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2686946392059326,
      "compression_ratio": 1.573770523071289,
      "no_speech_prob": 0.0012448233319446445
    },
    {
      "id": 149,
      "seek": 87392,
      "start": 3513.459982910156,
      "end": 3517.3399877929687,
      "text": " haben wir das jetzt mit YouTube und PeerTube so gemacht, dass man erstmal sagen muss, dass die",
      "tokens": [
        50364,
        3084,
        1987,
        1482,
        4354,
        2194,
        3088,
        674,
        2396,
        260,
        41173,
        370,
        12293,
        11,
        2658,
        587,
        38607,
        8360,
        6425,
        11,
        2658,
        978,
        50558
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3267596960067749,
      "compression_ratio": 1.5232558250427246,
      "no_speech_prob": 0.012050306424498558
    },
    {
      "id": 150,
      "seek": 87392,
      "start": 3517.3399877929687,
      "end": 3523.3800268554687,
      "text": " Sachen tatsächlich embeddet sein sollen. Ich habe ein paar Sachen hübscher gemacht, den Überblick",
      "tokens": [
        50558,
        26074,
        20796,
        308,
        2504,
        292,
        17863,
        6195,
        24713,
        13,
        3141,
        6015,
        1343,
        16509,
        26074,
        276,
        774,
        929,
        6759,
        12293,
        11,
        1441,
        18086,
        38263,
        50860
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3267596960067749,
      "compression_ratio": 1.5232558250427246,
      "no_speech_prob": 0.012050306424498558
    },
    {
      "id": 151,
      "seek": 87392,
      "start": 3523.3800268554687,
      "end": 3530.740012207031,
      "text": " hübscher und so weiter. Und dadurch ist eben auch dieses Alien und die eigenen CSS-Dateien und so",
      "tokens": [
        50860,
        276,
        774,
        929,
        6759,
        674,
        370,
        8988,
        13,
        2719,
        35472,
        1418,
        11375,
        2168,
        12113,
        32396,
        674,
        978,
        28702,
        24387,
        12,
        35,
        473,
        1053,
        674,
        370,
        51228
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3267596960067749,
      "compression_ratio": 1.5232558250427246,
      "no_speech_prob": 0.012050306424498558
    },
    {
      "id": 152,
      "seek": 87392,
      "start": 3530.740012207031,
      "end": 3540.6200170898437,
      "text": " das komplett eliminiert. Das hätte ich vielleicht hinbekommen ohne GTPT-Unterstützung, aber dann",
      "tokens": [
        51228,
        1482,
        32261,
        7892,
        4859,
        13,
        2846,
        20041,
        1893,
        12547,
        14102,
        650,
        13675,
        15716,
        460,
        16804,
        51,
        12,
        12405,
        391,
        21836,
        27667,
        11,
        4340,
        3594,
        51722
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3267596960067749,
      "compression_ratio": 1.5232558250427246,
      "no_speech_prob": 0.012050306424498558
    },
    {
      "id": 153,
      "seek": 90108,
      "start": 3540.6599951171875,
      "end": 3548.459982910156,
      "text": " hätte es länger gedauert. Das heißt, ich kann mir nicht vorstellen, solche Sachen zu entwickeln,",
      "tokens": [
        50366,
        20041,
        785,
        40935,
        19238,
        1459,
        911,
        13,
        2846,
        13139,
        11,
        1893,
        4028,
        3149,
        1979,
        34346,
        11,
        29813,
        26074,
        2164,
        28449,
        32099,
        11,
        50756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3064204454421997,
      "compression_ratio": 1.4784313440322876,
      "no_speech_prob": 0.053375981748104095
    },
    {
      "id": 154,
      "seek": 90108,
      "start": 3548.459982910156,
      "end": 3553.06001953125,
      "text": " ohne auf ein LLM zurückzugreifen. Und die andere Seite, die spannend ist, ist nicht dieser",
      "tokens": [
        50756,
        15716,
        2501,
        1343,
        441,
        43,
        44,
        15089,
        29742,
        265,
        25076,
        13,
        2719,
        978,
        10490,
        19748,
        11,
        978,
        49027,
        1418,
        11,
        1418,
        1979,
        9053,
        50986
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3064204454421997,
      "compression_ratio": 1.4784313440322876,
      "no_speech_prob": 0.053375981748104095
    },
    {
      "id": 155,
      "seek": 90108,
      "start": 3553.06001953125,
      "end": 3557.9400244140625,
      "text": " Constraint, der dazu geführt hat, dass diese Lösung tatsächlich problematisch ist. Der ist",
      "tokens": [
        50986,
        8574,
        424,
        686,
        11,
        1163,
        13034,
        11271,
        19647,
        2385,
        11,
        2658,
        6705,
        46934,
        20796,
        1154,
        267,
        5494,
        1418,
        13,
        5618,
        1418,
        51230
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3064204454421997,
      "compression_ratio": 1.4784313440322876,
      "no_speech_prob": 0.053375981748104095
    },
    {
      "id": 156,
      "seek": 90108,
      "start": 3557.9400244140625,
      "end": 3564.740012207031,
      "text": " eigentlich von draußen reingekommen. Und das Spannende, was du jetzt erzählt hast von der",
      "tokens": [
        51230,
        10926,
        2957,
        44602,
        319,
        278,
        916,
        5132,
        13,
        2719,
        1482,
        1738,
        969,
        5445,
        11,
        390,
        1581,
        4354,
        47110,
        6581,
        2957,
        1163,
        51570
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3064204454421997,
      "compression_ratio": 1.4784313440322876,
      "no_speech_prob": 0.053375981748104095
    },
    {
      "id": 157,
      "seek": 92520,
      "start": 3564.740012207031,
      "end": 3572.6200170898437,
      "text": " Lösung ist, da ist eine grundlegende Entscheidung getroffen worden in der Umsetzung und durch die",
      "tokens": [
        50364,
        46934,
        1418,
        11,
        1120,
        1418,
        3018,
        30886,
        6363,
        5445,
        44667,
        483,
        30594,
        14054,
        294,
        1163,
        46963,
        38584,
        674,
        7131,
        978,
        50758
      ],
      "temperature": 0.0,
      "avg_logprob": -0.293154776096344,
      "compression_ratio": 1.6276150941848755,
      "no_speech_prob": 0.08750796318054199
    },
    {
      "id": 158,
      "seek": 92520,
      "start": 3572.6200170898437,
      "end": 3585.3399877929687,
      "text": " Constraints von Jekyll zieht es einiges nach sich. Denn als ich das umgesetzt habe, ist es reingekommen,",
      "tokens": [
        50758,
        8574,
        424,
        8654,
        2957,
        508,
        916,
        34353,
        16503,
        357,
        785,
        1343,
        20609,
        5168,
        3041,
        13,
        19027,
        3907,
        1893,
        1482,
        1105,
        42283,
        6015,
        11,
        1418,
        785,
        319,
        278,
        916,
        5132,
        11,
        51394
      ],
      "temperature": 0.0,
      "avg_logprob": -0.293154776096344,
      "compression_ratio": 1.6276150941848755,
      "no_speech_prob": 0.08750796318054199
    },
    {
      "id": 159,
      "seek": 92520,
      "start": 3585.3399877929687,
      "end": 3589.3800268554687,
      "text": " dass wir gesagt haben, ja, okay, wir haben schon die Videos, wir haben schon den Podcast drin,",
      "tokens": [
        51394,
        2658,
        1987,
        12260,
        3084,
        11,
        2784,
        11,
        1392,
        11,
        1987,
        3084,
        4981,
        978,
        25903,
        11,
        1987,
        3084,
        4981,
        1441,
        29972,
        24534,
        11,
        51596
      ],
      "temperature": 0.0,
      "avg_logprob": -0.293154776096344,
      "compression_ratio": 1.6276150941848755,
      "no_speech_prob": 0.08750796318054199
    },
    {
      "id": 160,
      "seek": 92520,
      "start": 3589.3800268554687,
      "end": 3594.259970703125,
      "text": " wir haben den MP3 untereinander, wir haben den Abstract noch da drin. Setz mal die anderen",
      "tokens": [
        51596,
        1987,
        3084,
        1441,
        14146,
        18,
        1701,
        323,
        20553,
        11,
        1987,
        3084,
        1441,
        46853,
        1897,
        3514,
        1120,
        24534,
        13,
        8928,
        89,
        2806,
        978,
        11122,
        51840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.293154776096344,
      "compression_ratio": 1.6276150941848755,
      "no_speech_prob": 0.08750796318054199
    },
    {
      "id": 161,
      "seek": 95472,
      "start": 3594.259970703125,
      "end": 3603.01998046875,
      "text": " Sachen drunter. Und das heißt, wir mussten inkludieren und ein Include geht nur auf das",
      "tokens": [
        50364,
        26074,
        1224,
        21777,
        13,
        2719,
        1482,
        13139,
        11,
        1987,
        1038,
        6266,
        11276,
        1471,
        5695,
        674,
        1343,
        7779,
        32334,
        7095,
        4343,
        2501,
        1482,
        50802
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25163689255714417,
      "compression_ratio": 1.663636326789856,
      "no_speech_prob": 0.001754562370479107
    },
    {
      "id": 162,
      "seek": 95472,
      "start": 3603.01998046875,
      "end": 3610.1399755859375,
      "text": " Include-Verzeichnis, nicht auf irgendwelche anderen Summaries-Verzeichnisse oder so. Und",
      "tokens": [
        50802,
        7779,
        32334,
        12,
        36929,
        32338,
        10661,
        11,
        1979,
        2501,
        26455,
        338,
        1876,
        11122,
        8626,
        76,
        4889,
        12,
        36929,
        32338,
        31481,
        4513,
        370,
        13,
        2719,
        51158
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25163689255714417,
      "compression_ratio": 1.663636326789856,
      "no_speech_prob": 0.001754562370479107
    },
    {
      "id": 163,
      "seek": 95472,
      "start": 3610.1399755859375,
      "end": 3616.6200170898437,
      "text": " deswegen mussten eben diese Summaries und die Transkription auch in das Include-Verzeichnis,",
      "tokens": [
        51158,
        26482,
        1038,
        6266,
        11375,
        6705,
        8626,
        76,
        4889,
        674,
        978,
        6531,
        74,
        470,
        1695,
        2168,
        294,
        1482,
        7779,
        32334,
        12,
        36929,
        32338,
        10661,
        11,
        51482
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25163689255714417,
      "compression_ratio": 1.663636326789856,
      "no_speech_prob": 0.001754562370479107
    },
    {
      "id": 164,
      "seek": 95472,
      "start": 3616.6200170898437,
      "end": 3623.699973144531,
      "text": " wo eigentlich Header, Footer und sowas drin ist und CSS, total hässlich. Und dadurch, dass bei",
      "tokens": [
        51482,
        6020,
        10926,
        634,
        8312,
        11,
        20989,
        260,
        674,
        19766,
        296,
        24534,
        1418,
        674,
        24387,
        11,
        3217,
        24054,
        3810,
        1739,
        13,
        2719,
        35472,
        11,
        2658,
        4643,
        51836
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25163689255714417,
      "compression_ratio": 1.663636326789856,
      "no_speech_prob": 0.001754562370479107
    },
    {
      "id": 165,
      "seek": 98416,
      "start": 3623.699973144531,
      "end": 3627.8999853515625,
      "text": " deiner Umsetzung die Entscheidung getroffen worden ist, kommen wir setzen das auf eigene",
      "tokens": [
        50364,
        368,
        4564,
        46963,
        38584,
        978,
        44667,
        483,
        30594,
        14054,
        1418,
        11,
        11729,
        1987,
        35877,
        1482,
        2501,
        38549,
        50574
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3032103180885315,
      "compression_ratio": 1.4158415794372559,
      "no_speech_prob": 0.029724610969424248
    },
    {
      "id": 166,
      "seek": 98416,
      "start": 3627.8999853515625,
      "end": 3636.259970703125,
      "text": " Seiten. Wir haben da Links. War das dann auf einmal möglich, das sauber in die Folder aufzuteilen?",
      "tokens": [
        50574,
        45200,
        13,
        4347,
        3084,
        1120,
        37156,
        13,
        3630,
        1482,
        3594,
        2501,
        11078,
        16294,
        11,
        1482,
        601,
        10261,
        294,
        978,
        24609,
        260,
        2501,
        89,
        1169,
        17471,
        30,
        50992
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3032103180885315,
      "compression_ratio": 1.4158415794372559,
      "no_speech_prob": 0.029724610969424248
    },
    {
      "id": 167,
      "seek": 98416,
      "start": 3636.259970703125,
      "end": 3643.500021972656,
      "text": " Genau. Und das ist halt so ein bisschen der Punkt. Ich glaube, du hast es gerade sehr gut gesagt.",
      "tokens": [
        50992,
        22340,
        13,
        2719,
        1482,
        1418,
        12479,
        370,
        1343,
        10763,
        1163,
        25487,
        13,
        3141,
        13756,
        11,
        1581,
        6581,
        785,
        12117,
        5499,
        5228,
        12260,
        13,
        51354
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3032103180885315,
      "compression_ratio": 1.4158415794372559,
      "no_speech_prob": 0.029724610969424248
    },
    {
      "id": 168,
      "seek": 100396,
      "start": 3643.779990234375,
      "end": 3654.3800268554687,
      "text": " Die Lösung hat partiell eigentlich gegen Jekyll und dieses System gearbeitet. Und das ist eine",
      "tokens": [
        50378,
        3229,
        46934,
        2385,
        17465,
        285,
        10926,
        13953,
        508,
        916,
        34353,
        674,
        12113,
        8910,
        1519,
        24024,
        302,
        13,
        2719,
        1482,
        1418,
        3018,
        50908
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34927648305892944,
      "compression_ratio": 1.6457399129867554,
      "no_speech_prob": 0.3032121956348419
    },
    {
      "id": 169,
      "seek": 100396,
      "start": 3654.3800268554687,
      "end": 3661.259970703125,
      "text": " Lösung, die irgendwie funktioniert, aber sie arbeitet dagegen. Und da ist die zweite",
      "tokens": [
        50908,
        46934,
        11,
        978,
        20759,
        26160,
        11,
        4340,
        2804,
        49907,
        45387,
        13,
        2719,
        1120,
        1418,
        978,
        37456,
        51252
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34927648305892944,
      "compression_ratio": 1.6457399129867554,
      "no_speech_prob": 0.3032121956348419
    },
    {
      "id": 170,
      "seek": 100396,
      "start": 3661.259970703125,
      "end": 3667.54,
      "text": " Iteration dann irgendwie anders. Da ist auch die Frage, wie soll ich sagen, ich weiß nicht,",
      "tokens": [
        51252,
        286,
        391,
        399,
        3594,
        20759,
        17999,
        13,
        3933,
        1418,
        2168,
        978,
        13685,
        11,
        3355,
        7114,
        1893,
        8360,
        11,
        1893,
        13385,
        1979,
        11,
        51566
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34927648305892944,
      "compression_ratio": 1.6457399129867554,
      "no_speech_prob": 0.3032121956348419
    },
    {
      "id": 171,
      "seek": 100396,
      "start": 3667.54,
      "end": 3671.01998046875,
      "text": " ob ich exakt diese Lösung umgesetzt hätte, wenn es nicht die erste Lösung gegeben hätte,",
      "tokens": [
        51566,
        1111,
        1893,
        454,
        5886,
        6705,
        46934,
        1105,
        42283,
        20041,
        11,
        4797,
        785,
        1979,
        978,
        20951,
        46934,
        32572,
        20041,
        11,
        51740
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34927648305892944,
      "compression_ratio": 1.6457399129867554,
      "no_speech_prob": 0.3032121956348419
    },
    {
      "id": 172,
      "seek": 103148,
      "start": 3671.1800146484375,
      "end": 3677.8599462890625,
      "text": " also evolutionäre Architekturentwicklung. Aber ja, ich will noch eine Sache loswerden.",
      "tokens": [
        50372,
        611,
        1073,
        2308,
        313,
        12277,
        10984,
        642,
        2320,
        374,
        317,
        16038,
        17850,
        13,
        5992,
        2784,
        11,
        1893,
        486,
        3514,
        3018,
        31452,
        1750,
        1554,
        1556,
        13,
        50706
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32899999618530273,
      "compression_ratio": 1.6064982414245605,
      "no_speech_prob": 0.02193378284573555
    },
    {
      "id": 173,
      "seek": 103148,
      "start": 3677.8599462890625,
      "end": 3681.820029296875,
      "text": " Also der Ingo Eichhorst, der war ja auch schon hier im Stream, hat hier einen Kommentar hinterlassen.",
      "tokens": [
        50706,
        2743,
        1163,
        682,
        1571,
        462,
        480,
        2335,
        372,
        11,
        1163,
        1516,
        2784,
        2168,
        4981,
        3296,
        566,
        24904,
        11,
        2385,
        3296,
        4891,
        33708,
        289,
        23219,
        44898,
        13,
        50904
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32899999618530273,
      "compression_ratio": 1.6064982414245605,
      "no_speech_prob": 0.02193378284573555
    },
    {
      "id": 174,
      "seek": 103148,
      "start": 3681.820029296875,
      "end": 3686.9400244140625,
      "text": " In meinen Augen eine ganz normale Technologie-Adaptionskurve. Erstmal geht es nach",
      "tokens": [
        50904,
        682,
        22738,
        29692,
        3018,
        6312,
        43646,
        8337,
        20121,
        12,
        15830,
        2796,
        626,
        33503,
        303,
        13,
        31183,
        5579,
        7095,
        785,
        5168,
        51160
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32899999618530273,
      "compression_ratio": 1.6064982414245605,
      "no_speech_prob": 0.02193378284573555
    },
    {
      "id": 175,
      "seek": 103148,
      "start": 3686.9400244140625,
      "end": 3697.01998046875,
      "text": " unten und dann gibt es Produktivitätsgewinne auf lange Sicht. Also ich habe das erste",
      "tokens": [
        51160,
        25693,
        674,
        3594,
        6089,
        785,
        44599,
        592,
        13187,
        1373,
        432,
        9136,
        716,
        2501,
        18131,
        36615,
        13,
        2743,
        1893,
        6015,
        1482,
        20951,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32899999618530273,
      "compression_ratio": 1.6064982414245605,
      "no_speech_prob": 0.02193378284573555
    },
    {
      "id": 176,
      "seek": 103148,
      "start": 3697.01998046875,
      "end": 3700.3799658203125,
      "text": " deutschsprachige Spring-Buch geschrieben und ich habe auch das erste deutschsprachige",
      "tokens": [
        51664,
        23004,
        339,
        18193,
        608,
        3969,
        14013,
        12,
        33,
        625,
        47397,
        674,
        1893,
        6015,
        2168,
        1482,
        20951,
        23004,
        339,
        18193,
        608,
        3969,
        51832
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32899999618530273,
      "compression_ratio": 1.6064982414245605,
      "no_speech_prob": 0.02193378284573555
    },
    {
      "id": 177,
      "seek": 106084,
      "start": 3700.4600439453125,
      "end": 3707.340048828125,
      "text": " Buch geschrieben über Microservices. Bei Spring war es so, dass von Anfang an sofort deutlich",
      "tokens": [
        50368,
        25818,
        47397,
        4502,
        5818,
        2635,
        47480,
        13,
        16188,
        14013,
        1516,
        785,
        370,
        11,
        2658,
        2957,
        25856,
        364,
        33168,
        24344,
        50712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.313042551279068,
      "compression_ratio": 1.4504132270812988,
      "no_speech_prob": 0.03252877667546272
    },
    {
      "id": 178,
      "seek": 106084,
      "start": 3707.340048828125,
      "end": 3713.8599462890625,
      "text": " offensichtlich war, zumindest für mich, dass das die Lösung ist, die ich Java I vorziehen würde.",
      "tokens": [
        50712,
        766,
        694,
        41971,
        1516,
        11,
        38082,
        2959,
        6031,
        11,
        2658,
        1482,
        978,
        46934,
        1418,
        11,
        978,
        1893,
        10745,
        286,
        4245,
        28768,
        11942,
        13,
        51038
      ],
      "temperature": 0.0,
      "avg_logprob": -0.313042551279068,
      "compression_ratio": 1.4504132270812988,
      "no_speech_prob": 0.03252877667546272
    },
    {
      "id": 179,
      "seek": 106084,
      "start": 3713.8599462890625,
      "end": 3719.739951171875,
      "text": " Und ich will das gar nicht im Produktivitätsgewinne sozusagen ausdrücken,",
      "tokens": [
        51038,
        2719,
        1893,
        486,
        1482,
        3691,
        1979,
        566,
        44599,
        592,
        13187,
        1373,
        432,
        9136,
        716,
        33762,
        3437,
        16753,
        26037,
        11,
        51332
      ],
      "temperature": 0.0,
      "avg_logprob": -0.313042551279068,
      "compression_ratio": 1.4504132270812988,
      "no_speech_prob": 0.03252877667546272
    },
    {
      "id": 180,
      "seek": 106084,
      "start": 3719.739951171875,
      "end": 3724.9400244140625,
      "text": " das ist halt schwierig, das ist halt ein Framework. Aber die Vorteile waren halt",
      "tokens": [
        51332,
        1482,
        1418,
        12479,
        37845,
        11,
        1482,
        1418,
        12479,
        1343,
        31628,
        1902,
        13,
        5992,
        978,
        46968,
        794,
        11931,
        7523,
        83,
        51592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.313042551279068,
      "compression_ratio": 1.4504132270812988,
      "no_speech_prob": 0.03252877667546272
    },
    {
      "id": 181,
      "seek": 108540,
      "start": 3724.9400244140625,
      "end": 3732.8999853515625,
      "text": " evident. Und also mindestens mit dem Stand, also nicht Java I, hat sich auf gut Rund dessen",
      "tokens": [
        50364,
        16371,
        13,
        2719,
        611,
        1575,
        42624,
        2194,
        1371,
        9133,
        11,
        611,
        1979,
        10745,
        286,
        11,
        2385,
        3041,
        2501,
        5228,
        497,
        997,
        6874,
        268,
        50762
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3814886212348938,
      "compression_ratio": 1.4960317611694336,
      "no_speech_prob": 0.005208695773035288
    },
    {
      "id": 182,
      "seek": 108540,
      "start": 3732.8999853515625,
      "end": 3738.5800390625,
      "text": " weiterentwickelt und ist heute was anderes als damals. Aber das war klar und das hat",
      "tokens": [
        50762,
        8988,
        317,
        22295,
        25798,
        674,
        1418,
        9801,
        390,
        31426,
        3907,
        26067,
        13,
        5992,
        1482,
        1516,
        14743,
        674,
        1482,
        2385,
        51046
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3814886212348938,
      "compression_ratio": 1.4960317611694336,
      "no_speech_prob": 0.005208695773035288
    },
    {
      "id": 183,
      "seek": 108540,
      "start": 3738.5800390625,
      "end": 3743.300009765625,
      "text": " dort auch viele Leute überzeugt. Bei Microservices kann man darüber diskutieren. Meiner Ansicht nach",
      "tokens": [
        51046,
        15775,
        2168,
        9693,
        13495,
        48598,
        83,
        13,
        16188,
        5818,
        2635,
        47480,
        4028,
        587,
        21737,
        36760,
        5695,
        13,
        1923,
        4564,
        14590,
        1405,
        5168,
        51282
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3814886212348938,
      "compression_ratio": 1.4960317611694336,
      "no_speech_prob": 0.005208695773035288
    },
    {
      "id": 184,
      "seek": 108540,
      "start": 3743.300009765625,
      "end": 3748.739951171875,
      "text": " ist das eine Lösung für einige spezielle Punkte. Ich fand es interessant für bestimmte Sachen,",
      "tokens": [
        51282,
        1418,
        1482,
        3018,
        46934,
        2959,
        28338,
        48682,
        2447,
        47352,
        13,
        3141,
        38138,
        785,
        37748,
        2959,
        35180,
        975,
        26074,
        11,
        51554
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3814886212348938,
      "compression_ratio": 1.4960317611694336,
      "no_speech_prob": 0.005208695773035288
    },
    {
      "id": 185,
      "seek": 110920,
      "start": 3748.779990234375,
      "end": 3756.6199560546875,
      "text": " das war was anderes. Eine Technologie, die kein Produktivitätsgewinn, also dass das jetzt keine",
      "tokens": [
        50366,
        1482,
        1516,
        390,
        31426,
        13,
        17664,
        8337,
        20121,
        11,
        978,
        13424,
        44599,
        592,
        13187,
        1373,
        21306,
        7729,
        11,
        611,
        2658,
        1482,
        4354,
        9252,
        50758
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2737002670764923,
      "compression_ratio": 1.5805084705352783,
      "no_speech_prob": 0.04955432191491127
    },
    {
      "id": 186,
      "seek": 110920,
      "start": 3756.6199560546875,
      "end": 3761.10005859375,
      "text": " Produktivitätsgewinne verspricht oder keine großen, da scheinen wir uns ja einig zu sein.",
      "tokens": [
        50758,
        44599,
        592,
        13187,
        1373,
        432,
        9136,
        716,
        1774,
        79,
        12836,
        4513,
        9252,
        23076,
        11,
        1120,
        25690,
        5636,
        1987,
        2693,
        2784,
        1343,
        328,
        2164,
        6195,
        13,
        50982
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2737002670764923,
      "compression_ratio": 1.5805084705352783,
      "no_speech_prob": 0.04955432191491127
    },
    {
      "id": 187,
      "seek": 110920,
      "start": 3761.10005859375,
      "end": 3767.06001953125,
      "text": " Ich verstehe nicht, woher der Optimismus kommt, dass es einen Produktivitätsgewinn auf lange",
      "tokens": [
        50982,
        3141,
        22442,
        675,
        1979,
        11,
        6020,
        511,
        1163,
        35013,
        25327,
        10047,
        11,
        2658,
        785,
        4891,
        44599,
        592,
        13187,
        1373,
        21306,
        7729,
        2501,
        18131,
        51280
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2737002670764923,
      "compression_ratio": 1.5805084705352783,
      "no_speech_prob": 0.04955432191491127
    },
    {
      "id": 188,
      "seek": 110920,
      "start": 3767.06001953125,
      "end": 3775.259970703125,
      "text": " Sicht geben soll. Denn dafür gibt es halt im Moment keinen Hinweis. Es ist extrem schwer,",
      "tokens": [
        51280,
        36615,
        17191,
        7114,
        13,
        19027,
        13747,
        6089,
        785,
        12479,
        566,
        19093,
        20624,
        29571,
        35033,
        13,
        2313,
        1418,
        4040,
        23809,
        11,
        51690
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2737002670764923,
      "compression_ratio": 1.5805084705352783,
      "no_speech_prob": 0.04955432191491127
    },
    {
      "id": 189,
      "seek": 113572,
      "start": 3775.300009765625,
      "end": 3782.1800146484375,
      "text": " die Zukunft hier zu sagen, also aus offensichtlichen Gründen. Deswegen muss man das abwarten und nicht,",
      "tokens": [
        50366,
        978,
        22782,
        3296,
        2164,
        8360,
        11,
        611,
        3437,
        766,
        694,
        1405,
        10193,
        2606,
        27687,
        13,
        24864,
        6425,
        587,
        1482,
        410,
        86,
        11719,
        674,
        1979,
        11,
        50710
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26354166865348816,
      "compression_ratio": 1.5560165643692017,
      "no_speech_prob": 0.07136218249797821
    },
    {
      "id": 190,
      "seek": 113572,
      "start": 3782.1800146484375,
      "end": 3791.779990234375,
      "text": " keine Ahnung, vielleicht ist es halt so, dass wir dahin kommen, dass es da irgendetwas gibt,",
      "tokens": [
        50710,
        9252,
        2438,
        15539,
        11,
        12547,
        1418,
        785,
        12479,
        370,
        11,
        2658,
        1987,
        16800,
        259,
        11729,
        11,
        2658,
        785,
        1120,
        11093,
        302,
        6569,
        6089,
        11,
        51190
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26354166865348816,
      "compression_ratio": 1.5560165643692017,
      "no_speech_prob": 0.07136218249797821
    },
    {
      "id": 191,
      "seek": 113572,
      "start": 3791.779990234375,
      "end": 3796.2200537109375,
      "text": " aber das ist halt im Moment nicht absehbar. Und nur nochmal, um es deutlich zu sagen,",
      "tokens": [
        51190,
        4340,
        1482,
        1418,
        12479,
        566,
        19093,
        1979,
        410,
        405,
        71,
        5356,
        13,
        2719,
        4343,
        26509,
        11,
        1105,
        785,
        24344,
        2164,
        8360,
        11,
        51412
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26354166865348816,
      "compression_ratio": 1.5560165643692017,
      "no_speech_prob": 0.07136218249797821
    },
    {
      "id": 192,
      "seek": 113572,
      "start": 3796.2200537109375,
      "end": 3803.4200048828125,
      "text": " mindestens die Leute in der Mastodon-Community sagen, dass halt bei Coding eine Abnahme der",
      "tokens": [
        51412,
        1575,
        42624,
        978,
        13495,
        294,
        1163,
        376,
        525,
        378,
        266,
        12,
        39206,
        45105,
        8360,
        11,
        2658,
        12479,
        4643,
        383,
        8616,
        3018,
        2847,
        32796,
        1163,
        51772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26354166865348816,
      "compression_ratio": 1.5560165643692017,
      "no_speech_prob": 0.07136218249797821
    },
    {
      "id": 193,
      "seek": 116388,
      "start": 3803.4200048828125,
      "end": 3812.06001953125,
      "text": " Produktivität durch AI-Systeme stattfindet. Und das sind 40 Prozent. 50 Prozent haben einen",
      "tokens": [
        50364,
        44599,
        592,
        14053,
        7131,
        7318,
        12,
        50,
        9321,
        68,
        25675,
        35072,
        302,
        13,
        2719,
        1482,
        3290,
        3356,
        29726,
        13,
        2625,
        29726,
        3084,
        4891,
        50796
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2947959899902344,
      "compression_ratio": 1.3190475702285767,
      "no_speech_prob": 0.029302744194865227
    },
    {
      "id": 194,
      "seek": 116388,
      "start": 3812.06001953125,
      "end": 3819.340048828125,
      "text": " Faktor von 1 bis 2. Das ist für mich ein überraschendes Ergebnis und das ist auch",
      "tokens": [
        50796,
        479,
        5886,
        284,
        2957,
        502,
        7393,
        568,
        13,
        2846,
        1418,
        2959,
        6031,
        1343,
        4502,
        3906,
        339,
        34533,
        46229,
        674,
        1482,
        1418,
        2168,
        51160
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2947959899902344,
      "compression_ratio": 1.3190475702285767,
      "no_speech_prob": 0.029302744194865227
    },
    {
      "id": 195,
      "seek": 116388,
      "start": 3819.340048828125,
      "end": 3823.8599462890625,
      "text": " nichts, was bei LinkedIn halt reproduzierbar ist. Also es hängt sehr sicher von der sozialen Gruppe",
      "tokens": [
        51160,
        13004,
        11,
        390,
        4643,
        20657,
        12479,
        11408,
        33352,
        5356,
        1418,
        13,
        2743,
        785,
        276,
        29670,
        5499,
        18623,
        2957,
        1163,
        31541,
        268,
        10459,
        19833,
        51386
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2947959899902344,
      "compression_ratio": 1.3190475702285767,
      "no_speech_prob": 0.029302744194865227
    },
    {
      "id": 196,
      "seek": 118432,
      "start": 3823.8599462890625,
      "end": 3832.739951171875,
      "text": " ab. Aber das ist nichts, worauf man jetzt irgendwie sagen kann, wir möchten noch zwei,",
      "tokens": [
        50364,
        410,
        13,
        5992,
        1482,
        1418,
        13004,
        11,
        469,
        9507,
        587,
        4354,
        20759,
        8360,
        4028,
        11,
        1987,
        49699,
        3514,
        12002,
        11,
        50808
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39378607273101807,
      "compression_ratio": 1.5306122303009033,
      "no_speech_prob": 0.4067586362361908
    },
    {
      "id": 197,
      "seek": 118432,
      "start": 3832.739951171875,
      "end": 3838.10005859375,
      "text": " drei Sachen ändern und dann ist es besser. Keine Ahnung. Also muss man darüber diskutieren. Ich",
      "tokens": [
        50808,
        16809,
        26074,
        47775,
        674,
        3594,
        1418,
        785,
        18021,
        13,
        3189,
        533,
        2438,
        15539,
        13,
        2743,
        6425,
        587,
        21737,
        36760,
        5695,
        13,
        3141,
        51076
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39378607273101807,
      "compression_ratio": 1.5306122303009033,
      "no_speech_prob": 0.4067586362361908
    },
    {
      "id": 198,
      "seek": 118432,
      "start": 3838.10005859375,
      "end": 3845.1800146484375,
      "text": " habe mir bewusst überlegt, ob ich die Frage stelle, also welche Vorteile erwartet ihr über",
      "tokens": [
        51076,
        6015,
        3149,
        46221,
        4502,
        22745,
        11,
        1111,
        1893,
        978,
        13685,
        342,
        4434,
        11,
        611,
        24311,
        46968,
        794,
        21715,
        32347,
        5553,
        4502,
        51430
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39378607273101807,
      "compression_ratio": 1.5306122303009033,
      "no_speech_prob": 0.4067586362361908
    },
    {
      "id": 199,
      "seek": 118432,
      "start": 3845.1800146484375,
      "end": 3849.1399755859375,
      "text": " die Zukunft. Ich habe das halt gelassen, weil ich glaube, das bringt halt nichts. Also es bringt",
      "tokens": [
        51430,
        978,
        22782,
        13,
        3141,
        6015,
        1482,
        12479,
        4087,
        8356,
        11,
        7689,
        1893,
        13756,
        11,
        1482,
        36008,
        12479,
        13004,
        13,
        2743,
        785,
        36008,
        51628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39378607273101807,
      "compression_ratio": 1.5306122303009033,
      "no_speech_prob": 0.4067586362361908
    },
    {
      "id": 200,
      "seek": 120960,
      "start": 3849.1399755859375,
      "end": 3856.9400244140625,
      "text": " deswegen nichts, weil das ist halt ein totales Glaskugellesen. Da kann man halt irgendwelche",
      "tokens": [
        50364,
        26482,
        13004,
        11,
        7689,
        1482,
        1418,
        12479,
        1343,
        3217,
        279,
        29078,
        74,
        697,
        338,
        904,
        268,
        13,
        3933,
        4028,
        587,
        12479,
        26455,
        338,
        1876,
        50754
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37995532155036926,
      "compression_ratio": 1.497991919517517,
      "no_speech_prob": 0.2014339715242386
    },
    {
      "id": 201,
      "seek": 120960,
      "start": 3856.9400244140625,
      "end": 3861.739951171875,
      "text": " Zahlen schießen und das ist ja beliebig. Wir müssen uns aber tatsächlich eben in die Augen",
      "tokens": [
        50754,
        44096,
        956,
        40687,
        674,
        1482,
        1418,
        2784,
        1351,
        37660,
        13,
        4347,
        9013,
        2693,
        4340,
        20796,
        11375,
        294,
        978,
        29692,
        50994
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37995532155036926,
      "compression_ratio": 1.497991919517517,
      "no_speech_prob": 0.2014339715242386
    },
    {
      "id": 202,
      "seek": 120960,
      "start": 3861.739951171875,
      "end": 3866.8999853515625,
      "text": " gucken und halt sehen, dass im Moment mindestens die Mastodon-Community, ich unterstelle,",
      "tokens": [
        50994,
        33135,
        674,
        12479,
        11333,
        11,
        2658,
        566,
        19093,
        1575,
        42624,
        978,
        376,
        525,
        378,
        266,
        12,
        39206,
        45105,
        11,
        1893,
        8662,
        372,
        4434,
        11,
        51252
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37995532155036926,
      "compression_ratio": 1.497991919517517,
      "no_speech_prob": 0.2014339715242386
    },
    {
      "id": 203,
      "seek": 120960,
      "start": 3866.8999853515625,
      "end": 3876.779990234375,
      "text": " dass die irgendwie technischer ist. Keine Ahnung, wie ich das ausdrücken soll. Und es sind auch",
      "tokens": [
        51252,
        2658,
        978,
        20759,
        1537,
        19674,
        1418,
        13,
        3189,
        533,
        2438,
        15539,
        11,
        3355,
        1893,
        1482,
        3437,
        16753,
        26037,
        7114,
        13,
        2719,
        785,
        3290,
        2168,
        51746
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37995532155036926,
      "compression_ratio": 1.497991919517517,
      "no_speech_prob": 0.2014339715242386
    },
    {
      "id": 204,
      "seek": 123724,
      "start": 3876.9400244140625,
      "end": 3881.4999609375,
      "text": " meine Follower, also das ist eine gewisse Auslese. Aber diese 40 Prozent ist halt irgendwie krass.",
      "tokens": [
        50372,
        10946,
        479,
        1833,
        968,
        11,
        611,
        1482,
        1418,
        3018,
        6906,
        7746,
        9039,
        904,
        68,
        13,
        5992,
        6705,
        3356,
        29726,
        1418,
        12479,
        20759,
        15913,
        640,
        13,
        50600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4589725136756897,
      "compression_ratio": 1.3245033025741577,
      "no_speech_prob": 0.11271632462739944
    },
    {
      "id": 205,
      "seek": 123724,
      "start": 3881.4999609375,
      "end": 3898.97994140625,
      "text": " Also das hätte ich auch nicht erwartet. Wir haben da glaube ich noch viele spannende Sachen vor uns.",
      "tokens": [
        50600,
        2743,
        1482,
        20041,
        1893,
        2168,
        1979,
        21715,
        32347,
        13,
        4347,
        3084,
        1120,
        13756,
        1893,
        3514,
        9693,
        33360,
        5445,
        26074,
        4245,
        2693,
        13,
        51474
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4589725136756897,
      "compression_ratio": 1.3245033025741577,
      "no_speech_prob": 0.11271632462739944
    },
    {
      "id": 206,
      "seek": 125944,
      "start": 3898.97994140625,
      "end": 3907.3799658203125,
      "text": " Jetzt gucke ich mal kurz auf die Planung. Nächste Woche ist die Episode am 6. Das ist",
      "tokens": [
        50364,
        12592,
        695,
        18627,
        1893,
        2806,
        20465,
        2501,
        978,
        8112,
        1063,
        13,
        426,
        10168,
        2941,
        24511,
        1418,
        978,
        19882,
        669,
        1386,
        13,
        2846,
        1418,
        50784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4028110206127167,
      "compression_ratio": 1.1987179517745972,
      "no_speech_prob": 0.4871116280555725
    },
    {
      "id": 207,
      "seek": 125944,
      "start": 3907.3799658203125,
      "end": 3918.820029296875,
      "text": " der Donnerstag. Da spricht Lisa mit Aino darüber, ob… Moment, erstmal ist es auf Englisch. Und es",
      "tokens": [
        50784,
        1163,
        1468,
        1193,
        37077,
        13,
        3933,
        42088,
        12252,
        2194,
        316,
        2982,
        21737,
        11,
        1111,
        1260,
        19093,
        11,
        38607,
        1418,
        785,
        2501,
        2469,
        75,
        5494,
        13,
        2719,
        785,
        51356
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4028110206127167,
      "compression_ratio": 1.1987179517745972,
      "no_speech_prob": 0.4871116280555725
    },
    {
      "id": 208,
      "seek": 127928,
      "start": 3918.820029296875,
      "end": 3932.6599951171875,
      "text": " geht um das Thema Teamwork. Do we still need to talk about it? Und das wird dann, glaube ich,",
      "tokens": [
        50364,
        7095,
        1105,
        1482,
        16306,
        7606,
        1902,
        13,
        1144,
        321,
        920,
        643,
        281,
        751,
        466,
        309,
        30,
        2719,
        1482,
        4578,
        3594,
        11,
        13756,
        1893,
        11,
        51056
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33906859159469604,
      "compression_ratio": 1.3838862180709839,
      "no_speech_prob": 0.11402639001607895
    },
    {
      "id": 209,
      "seek": 127928,
      "start": 3932.6599951171875,
      "end": 3940.779990234375,
      "text": " eine besonders spannende Folge. Also wie gesagt, nächste Woche dann tatsächlich am Donnerstag zur",
      "tokens": [
        51056,
        3018,
        25258,
        33360,
        5445,
        43597,
        13,
        2743,
        3355,
        12260,
        11,
        30661,
        24511,
        3594,
        20796,
        669,
        1468,
        1193,
        37077,
        7147,
        51462
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33906859159469604,
      "compression_ratio": 1.3838862180709839,
      "no_speech_prob": 0.11402639001607895
    },
    {
      "id": 210,
      "seek": 127928,
      "start": 3940.779990234375,
      "end": 3947.8999853515625,
      "text": " gewohnten Zeit, also um 13 Uhr, nicht am Freitag. Und dann mit Lisa und Aino. Vielen Dank an dich,",
      "tokens": [
        51462,
        6906,
        1445,
        14970,
        9394,
        11,
        611,
        1105,
        3705,
        30084,
        11,
        1979,
        669,
        6142,
        270,
        559,
        13,
        2719,
        3594,
        2194,
        12252,
        674,
        316,
        2982,
        13,
        22502,
        14148,
        364,
        10390,
        11,
        51818
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33906859159469604,
      "compression_ratio": 1.3838862180709839,
      "no_speech_prob": 0.11402639001607895
    },
    {
      "id": 211,
      "seek": 130836,
      "start": 3947.97994140625,
      "end": 3953.4999609375,
      "text": " Ralf. Vielen Dank an die ZuschauerInnen. Und vielleicht sehen wir uns dann bei einer",
      "tokens": [
        50368,
        497,
        1678,
        13,
        22502,
        14148,
        364,
        978,
        48333,
        18120,
        4575,
        2866,
        13,
        2719,
        12547,
        11333,
        1987,
        2693,
        3594,
        4643,
        6850,
        50644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33432766795158386,
      "compression_ratio": 1.2578125,
      "no_speech_prob": 0.025479696691036224
    },
    {
      "id": 212,
      "seek": 130836,
      "start": 3953.4999609375,
      "end": 3957.779990234375,
      "text": " der folgenden Folgen. Bis dann. Danke für die spannende Diskussion. Tschau.",
      "tokens": [
        50644,
        1163,
        3339,
        70,
        8896,
        15255,
        1766,
        13,
        25271,
        3594,
        13,
        26508,
        2959,
        978,
        33360,
        5445,
        45963,
        313,
        13,
        44461,
        1459,
        13,
        50858
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33432766795158386,
      "compression_ratio": 1.2578125,
      "no_speech_prob": 0.025479696691036224
    }
  ],
  "language": "german"
}